*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/456) train vimp2_845_05312013_VZ
(1/456) train vimp2_823_05202013_AJ
(2/456) train vimp2_915_07112013_LC
(3/456) train vimp2_901_07052013_AS
(4/456) train vimp2_ctrl_911_07082013_TTO
(5/456) train vimp2_ctrl_925_07152013_LS
(6/456) train vimp2_869_06142013_BL
(7/456) train vimp2_ANON724_03272013
(8/456) train vimp2_819_05172013_DS
(9/456) train vimp2_ctrl_918_07112013_TQ
(10/456) train vimp2_ctrl_902_07052013_SI
(11/456) train vimp2_ANON606_20130110
(12/456) train vimp2_943_07242013_PA
(13/456) train vimp2_824_05212013_JS
(14/456) train vimp2_ANON624_20130117
(15/456) train vimp2_ctrl_920_07122013_SW
(16/456) train vimp2_884_06272013_TS
(17/456) train vimp2_668_02282013_CD
(18/456) train vimp2_964_08092013_TG
(19/456) train vimp2_ctrl_921_07122013_MP
(20/456) train vimp2_972_08152013_DC
(21/456) train vimp2_988_08302013_CB
(22/456) train vimp2_ANON702_03152013
(23/456) train vimp2_ANON714_03222013
(24/456) train vimp2_972_08152013_DC_Aug0_Rot_-1_sd0
(25/456) train vimp2_972_08152013_DC_Aug0_Rot_1_sd2
(26/456) train vimp2_972_08152013_DC_Aug0_Rot_-7_sd1
(27/456) train vimp2_972_08152013_DC_Aug1_Rot_2_sd0
(28/456) train vimp2_972_08152013_DC_Aug1_Rot_5_sd1
(29/456) train vimp2_972_08152013_DC_Aug1_Rot_6_sd2
(30/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd1
(31/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd2
(32/456) train vimp2_972_08152013_DC_Aug2_Rot_-5_sd0
(33/456) train vimp2_972_08152013_DC_Aug3_Rot_2_sd1
(34/456) train vimp2_972_08152013_DC_Aug3_Rot_-3_sd0
(35/456) train vimp2_972_08152013_DC_Aug3_Rot_-6_sd2
(36/456) train vimp2_972_08152013_DC_Aug4_Rot_-2_sd2
(37/456) train vimp2_972_08152013_DC_Aug4_Rot_3_sd0
(38/456) train vimp2_972_08152013_DC_Aug4_Rot_6_sd1
(39/456) train vimp2_972_08152013_DC_Aug5_Rot_-1_sd2
(40/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd0
(41/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd1
(42/456) train vimp2_988_08302013_CB_Aug0_Rot_-3_sd2
(43/456) train vimp2_988_08302013_CB_Aug0_Rot_4_sd0
(44/456) train vimp2_988_08302013_CB_Aug0_Rot_-5_sd1
(45/456) train vimp2_988_08302013_CB_Aug1_Rot_-2_sd2
(46/456) train vimp2_988_08302013_CB_Aug1_Rot_-3_sd0
(47/456) train vimp2_988_08302013_CB_Aug1_Rot_-6_sd1
(48/456) train vimp2_988_08302013_CB_Aug2_Rot_-2_sd0
(49/456) train vimp2_988_08302013_CB_Aug2_Rot_4_sd1
(50/456) train vimp2_988_08302013_CB_Aug2_Rot_-5_sd2
(51/456) train vimp2_988_08302013_CB_Aug3_Rot_2_sd2
(52/456) train vimp2_988_08302013_CB_Aug3_Rot_-3_sd0
(53/456) train vimp2_988_08302013_CB_Aug3_Rot_3_sd1
(54/456) train vimp2_988_08302013_CB_Aug4_Rot_-2_sd0
(55/456) train vimp2_988_08302013_CB_Aug4_Rot_-6_sd1
(56/456) train vimp2_988_08302013_CB_Aug4_Rot_7_sd2
(57/456) train vimp2_988_08302013_CB_Aug5_Rot_-1_sd0
(58/456) train vimp2_988_08302013_CB_Aug5_Rot_-6_sd1
(59/456) train vimp2_988_08302013_CB_Aug5_Rot_7_sd2
(60/456) train vimp2_ANON702_03152013_Aug0_Rot_-2_sd1
(61/456) train vimp2_ANON702_03152013_Aug0_Rot_-3_sd2
(62/456) train vimp2_ANON702_03152013_Aug0_Rot_-4_sd0
(63/456) train vimp2_ANON702_03152013_Aug1_Rot_-4_sd1
(64/456) train vimp2_ANON702_03152013_Aug1_Rot_-5_sd2
(65/456) train vimp2_ANON702_03152013_Aug1_Rot_-7_sd0
(66/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd0
(67/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd2
(68/456) train vimp2_ANON702_03152013_Aug2_Rot_-7_sd1
(69/456) train vimp2_ANON702_03152013_Aug3_Rot_-1_sd2
(70/456) train vimp2_ANON702_03152013_Aug3_Rot_-3_sd0
(71/456) train vimp2_ANON702_03152013_Aug3_Rot_-6_sd1
(72/456) train vimp2_ANON702_03152013_Aug4_Rot_-2_sd0
(73/456) train vimp2_ANON702_03152013_Aug4_Rot_-3_sd2
(74/456) train vimp2_ANON702_03152013_Aug4_Rot_-7_sd1
(75/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd0
(76/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd2
(77/456) train vimp2_ANON702_03152013_Aug5_Rot_4_sd1
(78/456) train vimp2_ANON714_03222013_Aug0_Rot_-1_sd2
(79/456) train vimp2_ANON714_03222013_Aug0_Rot_-2_sd1
(80/456) train vimp2_ANON714_03222013_Aug0_Rot_4_sd0
(81/456) train vimp2_ANON714_03222013_Aug1_Rot_0_sd0
(82/456) train vimp2_ANON714_03222013_Aug1_Rot_1_sd1
(83/456) train vimp2_ANON714_03222013_Aug1_Rot_-6_sd2
(84/456) train vimp2_ANON714_03222013_Aug2_Rot_-2_sd0
(85/456) train vimp2_ANON714_03222013_Aug2_Rot_4_sd1
(86/456) train vimp2_ANON714_03222013_Aug2_Rot_6_sd2
(87/456) train vimp2_ANON714_03222013_Aug3_Rot_2_sd0
(88/456) train vimp2_ANON714_03222013_Aug3_Rot_-3_sd2
(89/456) train vimp2_ANON714_03222013_Aug3_Rot_-7_sd1
(90/456) train vimp2_ANON714_03222013_Aug4_Rot_1_sd0
(91/456) train vimp2_ANON714_03222013_Aug4_Rot_-2_sd1
(92/456) train vimp2_ANON714_03222013_Aug4_Rot_4_sd2
(93/456) train vimp2_ANON714_03222013_Aug5_Rot_1_sd0
(94/456) train vimp2_ANON714_03222013_Aug5_Rot_6_sd1
(95/456) train vimp2_ANON714_03222013_Aug5_Rot_-7_sd2
(96/456) train vimp2_668_02282013_CD_Aug0_Rot_7_sd0
(97/456) train vimp2_668_02282013_CD_Aug1_Rot_-1_sd0
(98/456) train vimp2_668_02282013_CD_Aug2_Rot_-4_sd0
(99/456) train vimp2_668_02282013_CD_Aug3_Rot_3_sd0
(100/456) train vimp2_668_02282013_CD_Aug4_Rot_-5_sd0
(101/456) train vimp2_668_02282013_CD_Aug5_Rot_-6_sd0
(102/456) train vimp2_819_05172013_DS_Aug0_Rot_1_sd0
(103/456) train vimp2_819_05172013_DS_Aug1_Rot_5_sd0
(104/456) train vimp2_819_05172013_DS_Aug2_Rot_-4_sd0
(105/456) train vimp2_819_05172013_DS_Aug3_Rot_2_sd0
(106/456) train vimp2_819_05172013_DS_Aug4_Rot_5_sd0
(107/456) train vimp2_819_05172013_DS_Aug5_Rot_4_sd0
(108/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd0
(109/456) train vimp2_823_05202013_AJ_Aug1_Rot_7_sd0
(110/456) train vimp2_823_05202013_AJ_Aug2_Rot_3_sd0
(111/456) train vimp2_823_05202013_AJ_Aug3_Rot_-5_sd0
(112/456) train vimp2_823_05202013_AJ_Aug4_Rot_-3_sd0
(113/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd0
(114/456) train vimp2_824_05212013_JS_Aug0_Rot_-2_sd0
(115/456) train vimp2_824_05212013_JS_Aug1_Rot_6_sd0
(116/456) train vimp2_824_05212013_JS_Aug2_Rot_1_sd0
(117/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd0
(118/456) train vimp2_824_05212013_JS_Aug4_Rot_7_sd0
(119/456) train vimp2_824_05212013_JS_Aug5_Rot_2_sd0
(120/456) train vimp2_845_05312013_VZ_Aug0_Rot_1_sd0
(121/456) train vimp2_845_05312013_VZ_Aug1_Rot_5_sd0
(122/456) train vimp2_845_05312013_VZ_Aug2_Rot_-6_sd0
(123/456) train vimp2_845_05312013_VZ_Aug3_Rot_3_sd0
(124/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd0
(125/456) train vimp2_845_05312013_VZ_Aug5_Rot_5_sd0
(126/456) train vimp2_869_06142013_BL_Aug0_Rot_-2_sd0
(127/456) train vimp2_869_06142013_BL_Aug1_Rot_-4_sd0
(128/456) train vimp2_869_06142013_BL_Aug2_Rot_-1_sd0
(129/456) train vimp2_869_06142013_BL_Aug3_Rot_3_sd0
(130/456) train vimp2_869_06142013_BL_Aug4_Rot_3_sd0
(131/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd0
(132/456) train vimp2_884_06272013_TS_Aug0_Rot_-7_sd0
(133/456) train vimp2_884_06272013_TS_Aug1_Rot_7_sd0
(134/456) train vimp2_884_06272013_TS_Aug2_Rot_-5_sd0
(135/456) train vimp2_884_06272013_TS_Aug3_Rot_-2_sd0
(136/456) train vimp2_884_06272013_TS_Aug4_Rot_6_sd0
(137/456) train vimp2_884_06272013_TS_Aug5_Rot_-1_sd0
(138/456) train vimp2_901_07052013_AS_Aug0_Rot_-4_sd0
(139/456) train vimp2_901_07052013_AS_Aug1_Rot_-2_sd0
(140/456) train vimp2_901_07052013_AS_Aug2_Rot_1_sd0
(141/456) train vimp2_901_07052013_AS_Aug3_Rot_2_sd0
(142/456) train vimp2_901_07052013_AS_Aug4_Rot_-7_sd0
(143/456) train vimp2_901_07052013_AS_Aug5_Rot_-5_sd0
(144/456) train vimp2_915_07112013_LC_Aug0_Rot_-2_sd0
(145/456) train vimp2_915_07112013_LC_Aug1_Rot_4_sd0
(146/456) train vimp2_915_07112013_LC_Aug2_Rot_-2_sd0
(147/456) train vimp2_915_07112013_LC_Aug3_Rot_-1_sd0
(148/456) train vimp2_915_07112013_LC_Aug4_Rot_1_sd0
(149/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd0
(150/456) train vimp2_943_07242013_PA_Aug0_Rot_-5_sd0
(151/456) train vimp2_943_07242013_PA_Aug1_Rot_-7_sd0
(152/456) train vimp2_943_07242013_PA_Aug2_Rot_-4_sd0
(153/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd0
(154/456) train vimp2_943_07242013_PA_Aug4_Rot_6_sd0
(155/456) train vimp2_943_07242013_PA_Aug5_Rot_5_sd0
(156/456) train vimp2_964_08092013_TG_Aug0_Rot_5_sd0
(157/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd0
(158/456) train vimp2_964_08092013_TG_Aug2_Rot_7_sd0
(159/456) train vimp2_964_08092013_TG_Aug3_Rot_-1_sd0
(160/456) train vimp2_964_08092013_TG_Aug4_Rot_-1_sd0
(161/456) train vimp2_964_08092013_TG_Aug5_Rot_2_sd0
(162/456) train vimp2_ANON606_20130110_Aug0_Rot_1_sd0
(163/456) train vimp2_ANON606_20130110_Aug1_Rot_2_sd0
(164/456) train vimp2_ANON606_20130110_Aug2_Rot_-5_sd0
(165/456) train vimp2_ANON606_20130110_Aug3_Rot_-5_sd0
(166/456) train vimp2_ANON606_20130110_Aug4_Rot_3_sd0
(167/456) train vimp2_ANON606_20130110_Aug5_Rot_-1_sd0
(168/456) train vimp2_ANON624_20130117_Aug0_Rot_1_sd0
(169/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd0
(170/456) train vimp2_ANON624_20130117_Aug2_Rot_5_sd0
(171/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd0
(172/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd0
(173/456) train vimp2_ANON624_20130117_Aug5_Rot_3_sd0
(174/456) train vimp2_ANON724_03272013_Aug0_Rot_-4_sd0
(175/456) train vimp2_ANON724_03272013_Aug1_Rot_-3_sd0
(176/456) train vimp2_ANON724_03272013_Aug2_Rot_-4_sd0
(177/456) train vimp2_ANON724_03272013_Aug3_Rot_5_sd0
(178/456) train vimp2_ANON724_03272013_Aug4_Rot_5_sd0
(179/456) train vimp2_ANON724_03272013_Aug5_Rot_-6_sd0
(180/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_5_sd0
(181/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd0
(182/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_4_sd0
(183/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd0
(184/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_3_sd0
(185/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-7_sd0
(186/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_6_sd0
(187/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_1_sd0
(188/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_4_sd0
(189/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-2_sd0
(190/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd0
(191/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_-2_sd0
(192/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_5_sd0
(193/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-3_sd0
(194/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-4_sd0
(195/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_1_sd0
(196/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_3_sd0
(197/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_7_sd0
(198/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd0
(199/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-6_sd0
(200/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd0
(201/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_1_sd0
(202/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-2_sd0
(203/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_4_sd0
(204/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_-1_sd0
(205/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-3_sd0
(206/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd0
(207/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_3_sd0
(208/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_1_sd0
(209/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_-5_sd0
(210/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-5_sd0
(211/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_-2_sd0
(212/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_5_sd0
(213/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_3_sd0
(214/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_4_sd0
(215/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-7_sd0
(216/456) train vimp2_668_02282013_CD_Aug0_Rot_-5_sd1
(217/456) train vimp2_668_02282013_CD_Aug1_Rot_-6_sd1
(218/456) train vimp2_668_02282013_CD_Aug2_Rot_3_sd1
(219/456) train vimp2_668_02282013_CD_Aug3_Rot_4_sd1
(220/456) train vimp2_668_02282013_CD_Aug4_Rot_-6_sd1
(221/456) train vimp2_668_02282013_CD_Aug5_Rot_-2_sd1
(222/456) train vimp2_819_05172013_DS_Aug0_Rot_-1_sd1
(223/456) train vimp2_819_05172013_DS_Aug1_Rot_3_sd1
(224/456) train vimp2_819_05172013_DS_Aug2_Rot_6_sd1
(225/456) train vimp2_819_05172013_DS_Aug3_Rot_3_sd1
(226/456) train vimp2_819_05172013_DS_Aug4_Rot_-7_sd1
(227/456) train vimp2_819_05172013_DS_Aug5_Rot_-5_sd1
(228/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd1
(229/456) train vimp2_823_05202013_AJ_Aug1_Rot_3_sd1
(230/456) train vimp2_823_05202013_AJ_Aug2_Rot_6_sd1
(231/456) train vimp2_823_05202013_AJ_Aug3_Rot_-7_sd1
(232/456) train vimp2_823_05202013_AJ_Aug4_Rot_-4_sd1
(233/456) train vimp2_823_05202013_AJ_Aug5_Rot_-4_sd1
(234/456) train vimp2_824_05212013_JS_Aug0_Rot_7_sd1
(235/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd1
(236/456) train vimp2_824_05212013_JS_Aug2_Rot_3_sd1
(237/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd1
(238/456) train vimp2_824_05212013_JS_Aug4_Rot_4_sd1
(239/456) train vimp2_824_05212013_JS_Aug5_Rot_6_sd1
(240/456) train vimp2_845_05312013_VZ_Aug0_Rot_5_sd1
(241/456) train vimp2_845_05312013_VZ_Aug1_Rot_6_sd1
(242/456) train vimp2_845_05312013_VZ_Aug2_Rot_1_sd1
(243/456) train vimp2_845_05312013_VZ_Aug3_Rot_-6_sd1
(244/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd1
(245/456) train vimp2_845_05312013_VZ_Aug5_Rot_-6_sd1
(246/456) train vimp2_869_06142013_BL_Aug0_Rot_-4_sd1
(247/456) train vimp2_869_06142013_BL_Aug1_Rot_-3_sd1
(248/456) train vimp2_869_06142013_BL_Aug2_Rot_-4_sd1
(249/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd1
(250/456) train vimp2_869_06142013_BL_Aug4_Rot_7_sd1
(251/456) train vimp2_869_06142013_BL_Aug5_Rot_5_sd1
(252/456) train vimp2_884_06272013_TS_Aug0_Rot_5_sd1
(253/456) train vimp2_884_06272013_TS_Aug1_Rot_-1_sd1
(254/456) train vimp2_884_06272013_TS_Aug2_Rot_-1_sd1
(255/456) train vimp2_884_06272013_TS_Aug3_Rot_3_sd1
(256/456) train vimp2_884_06272013_TS_Aug4_Rot_4_sd1
(257/456) train vimp2_884_06272013_TS_Aug5_Rot_3_sd1
(258/456) train vimp2_901_07052013_AS_Aug0_Rot_3_sd1
(259/456) train vimp2_901_07052013_AS_Aug1_Rot_5_sd1
(260/456) train vimp2_901_07052013_AS_Aug2_Rot_-5_sd1
(261/456) train vimp2_901_07052013_AS_Aug3_Rot_7_sd1
(262/456) train vimp2_901_07052013_AS_Aug4_Rot_7_sd1
(263/456) train vimp2_901_07052013_AS_Aug5_Rot_6_sd1
(264/456) train vimp2_915_07112013_LC_Aug0_Rot_-6_sd1
(265/456) train vimp2_915_07112013_LC_Aug1_Rot_-5_sd1
(266/456) train vimp2_915_07112013_LC_Aug2_Rot_7_sd1
(267/456) train vimp2_915_07112013_LC_Aug3_Rot_1_sd1
(268/456) train vimp2_915_07112013_LC_Aug4_Rot_6_sd1
(269/456) train vimp2_915_07112013_LC_Aug5_Rot_-7_sd1
(270/456) train vimp2_943_07242013_PA_Aug0_Rot_1_sd1
(271/456) train vimp2_943_07242013_PA_Aug1_Rot_6_sd1
(272/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd1
(273/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd1
(274/456) train vimp2_943_07242013_PA_Aug4_Rot_3_sd1
(275/456) train vimp2_943_07242013_PA_Aug5_Rot_3_sd1
(276/456) train vimp2_964_08092013_TG_Aug0_Rot_6_sd1
(277/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd1
(278/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd1
(279/456) train vimp2_964_08092013_TG_Aug3_Rot_0_sd1
(280/456) train vimp2_964_08092013_TG_Aug4_Rot_3_sd1
(281/456) train vimp2_964_08092013_TG_Aug5_Rot_-1_sd1
(282/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd1
(283/456) train vimp2_ANON606_20130110_Aug1_Rot_7_sd1
(284/456) train vimp2_ANON606_20130110_Aug2_Rot_1_sd1
(285/456) train vimp2_ANON606_20130110_Aug3_Rot_1_sd1
(286/456) train vimp2_ANON606_20130110_Aug4_Rot_4_sd1
(287/456) train vimp2_ANON606_20130110_Aug5_Rot_4_sd1
(288/456) train vimp2_ANON624_20130117_Aug0_Rot_7_sd1
(289/456) train vimp2_ANON624_20130117_Aug1_Rot_6_sd1
(290/456) train vimp2_ANON624_20130117_Aug2_Rot_-1_sd1
(291/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd1
(292/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd1
(293/456) train vimp2_ANON624_20130117_Aug5_Rot_4_sd1
(294/456) train vimp2_ANON724_03272013_Aug0_Rot_-2_sd1
(295/456) train vimp2_ANON724_03272013_Aug1_Rot_4_sd1
(296/456) train vimp2_ANON724_03272013_Aug2_Rot_-1_sd1
(297/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd1
(298/456) train vimp2_ANON724_03272013_Aug4_Rot_-5_sd1
(299/456) train vimp2_ANON724_03272013_Aug5_Rot_-4_sd1
(300/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2_sd1
(301/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd1
(302/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_2_sd1
(303/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd1
(304/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1_sd1
(305/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-4_sd1
(306/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_7_sd1
(307/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_-1_sd1
(308/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_-5_sd1
(309/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-3_sd1
(310/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd1
(311/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_6_sd1
(312/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_1_sd1
(313/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-2_sd1
(314/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_3_sd1
(315/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_-1_sd1
(316/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_7_sd1
(317/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_6_sd1
(318/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-3_sd1
(319/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_7_sd1
(320/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd1
(321/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-1_sd1
(322/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5_sd1
(323/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_-5_sd1
(324/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_4_sd1
(325/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_3_sd1
(326/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-1_sd1
(327/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd1
(328/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_2_sd1
(329/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_4_sd1
(330/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-2_sd1
(331/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_4_sd1
(332/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_-2_sd1
(333/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_2_sd1
(334/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_3_sd1
(335/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-4_sd1
(336/456) train vimp2_668_02282013_CD_Aug0_Rot_-3_sd2
(337/456) train vimp2_668_02282013_CD_Aug1_Rot_6_sd2
(338/456) train vimp2_668_02282013_CD_Aug2_Rot_-6_sd2
(339/456) train vimp2_668_02282013_CD_Aug3_Rot_7_sd2
(340/456) train vimp2_668_02282013_CD_Aug4_Rot_1_sd2
(341/456) train vimp2_668_02282013_CD_Aug5_Rot_7_sd2
(342/456) train vimp2_819_05172013_DS_Aug0_Rot_3_sd2
(343/456) train vimp2_819_05172013_DS_Aug1_Rot_-1_sd2
(344/456) train vimp2_819_05172013_DS_Aug2_Rot_-2_sd2
(345/456) train vimp2_819_05172013_DS_Aug3_Rot_-1_sd2
(346/456) train vimp2_819_05172013_DS_Aug4_Rot_7_sd2
(347/456) train vimp2_819_05172013_DS_Aug5_Rot_3_sd2
(348/456) train vimp2_823_05202013_AJ_Aug0_Rot_-6_sd2
(349/456) train vimp2_823_05202013_AJ_Aug1_Rot_-7_sd2
(350/456) train vimp2_823_05202013_AJ_Aug2_Rot_7_sd2
(351/456) train vimp2_823_05202013_AJ_Aug3_Rot_-2_sd2
(352/456) train vimp2_823_05202013_AJ_Aug4_Rot_1_sd2
(353/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd2
(354/456) train vimp2_824_05212013_JS_Aug0_Rot_-5_sd2
(355/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd2
(356/456) train vimp2_824_05212013_JS_Aug2_Rot_5_sd2
(357/456) train vimp2_824_05212013_JS_Aug3_Rot_2_sd2
(358/456) train vimp2_824_05212013_JS_Aug4_Rot_5_sd2
(359/456) train vimp2_824_05212013_JS_Aug5_Rot_-7_sd2
(360/456) train vimp2_845_05312013_VZ_Aug0_Rot_-5_sd2
(361/456) train vimp2_845_05312013_VZ_Aug1_Rot_3_sd2
(362/456) train vimp2_845_05312013_VZ_Aug2_Rot_-3_sd2
(363/456) train vimp2_845_05312013_VZ_Aug3_Rot_-1_sd2
(364/456) train vimp2_845_05312013_VZ_Aug4_Rot_4_sd2
(365/456) train vimp2_845_05312013_VZ_Aug5_Rot_-2_sd2
(366/456) train vimp2_869_06142013_BL_Aug0_Rot_3_sd2
(367/456) train vimp2_869_06142013_BL_Aug1_Rot_7_sd2
(368/456) train vimp2_869_06142013_BL_Aug2_Rot_4_sd2
(369/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd2
(370/456) train vimp2_869_06142013_BL_Aug4_Rot_1_sd2
(371/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd2
(372/456) train vimp2_884_06272013_TS_Aug0_Rot_3_sd2
(373/456) train vimp2_884_06272013_TS_Aug1_Rot_-5_sd2
(374/456) train vimp2_884_06272013_TS_Aug2_Rot_-7_sd2
(375/456) train vimp2_884_06272013_TS_Aug3_Rot_-6_sd2
(376/456) train vimp2_884_06272013_TS_Aug4_Rot_-2_sd2
(377/456) train vimp2_884_06272013_TS_Aug5_Rot_-6_sd2
(378/456) train vimp2_901_07052013_AS_Aug0_Rot_2_sd2
(379/456) train vimp2_901_07052013_AS_Aug1_Rot_-3_sd2
(380/456) train vimp2_901_07052013_AS_Aug2_Rot_-6_sd2
(381/456) train vimp2_901_07052013_AS_Aug3_Rot_6_sd2
(382/456) train vimp2_901_07052013_AS_Aug4_Rot_-5_sd2
(383/456) train vimp2_901_07052013_AS_Aug5_Rot_1_sd2
(384/456) train vimp2_915_07112013_LC_Aug0_Rot_1_sd2
(385/456) train vimp2_915_07112013_LC_Aug1_Rot_7_sd2
(386/456) train vimp2_915_07112013_LC_Aug2_Rot_3_sd2
(387/456) train vimp2_915_07112013_LC_Aug3_Rot_6_sd2
(388/456) train vimp2_915_07112013_LC_Aug4_Rot_4_sd2
(389/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd2
(390/456) train vimp2_943_07242013_PA_Aug0_Rot_3_sd2
(391/456) train vimp2_943_07242013_PA_Aug1_Rot_-4_sd2
(392/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd2
(393/456) train vimp2_943_07242013_PA_Aug3_Rot_2_sd2
(394/456) train vimp2_943_07242013_PA_Aug4_Rot_-1_sd2
(395/456) train vimp2_943_07242013_PA_Aug5_Rot_-3_sd2
(396/456) train vimp2_964_08092013_TG_Aug0_Rot_2_sd2
(397/456) train vimp2_964_08092013_TG_Aug1_Rot_-6_sd2
(398/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd2
(399/456) train vimp2_964_08092013_TG_Aug3_Rot_-7_sd2
(400/456) train vimp2_964_08092013_TG_Aug4_Rot_-6_sd2
(401/456) train vimp2_964_08092013_TG_Aug5_Rot_5_sd2
(402/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd2
(403/456) train vimp2_ANON606_20130110_Aug1_Rot_-5_sd2
(404/456) train vimp2_ANON606_20130110_Aug2_Rot_-3_sd2
(405/456) train vimp2_ANON606_20130110_Aug3_Rot_3_sd2
(406/456) train vimp2_ANON606_20130110_Aug4_Rot_-2_sd2
(407/456) train vimp2_ANON606_20130110_Aug5_Rot_-3_sd2
(408/456) train vimp2_ANON624_20130117_Aug0_Rot_2_sd2
(409/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd2
(410/456) train vimp2_ANON624_20130117_Aug2_Rot_-6_sd2
(411/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd2
(412/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd2
(413/456) train vimp2_ANON624_20130117_Aug5_Rot_-7_sd2
(414/456) train vimp2_ANON724_03272013_Aug0_Rot_-5_sd2
(415/456) train vimp2_ANON724_03272013_Aug1_Rot_6_sd2
(416/456) train vimp2_ANON724_03272013_Aug2_Rot_-3_sd2
(417/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd2
(418/456) train vimp2_ANON724_03272013_Aug4_Rot_-1_sd2
(419/456) train vimp2_ANON724_03272013_Aug5_Rot_-7_sd2
(420/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-4_sd2
(421/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_-3_sd2
(422/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-5_sd2
(423/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5_sd2
(424/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-2_sd2
(425/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_5_sd2
(426/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_-3_sd2
(427/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_7_sd2
(428/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_3_sd2
(429/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_5_sd2
(430/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_7_sd2
(431/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_2_sd2
(432/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7_sd2
(433/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_5_sd2
(434/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_5_sd2
(435/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_4_sd2
(436/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_5_sd2
(437/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_-4_sd2
(438/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd2
(439/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-2_sd2
(440/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_1_sd2
(441/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-7_sd2
(442/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-3_sd2
(443/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_7_sd2
(444/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_1_sd2
(445/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-7_sd2
(446/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd2
(447/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd2
(448/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_-5_sd2
(449/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_6_sd2
(450/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_2_sd2
(451/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_5_sd2
(452/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_2_sd2
(453/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_5_sd2
(454/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_-4_sd2
(455/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-3_sd22019-07-07 01:37:54.689078: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-07 01:37:55.055545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 14.65GiB
2019-07-07 01:37:55.055612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 01:37:55.433371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 01:37:55.433448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 01:37:55.433461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 01:37:55.433920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:55,  1.25s/it]Loading train:   1%|          | 2/285 [00:02<05:53,  1.25s/it]Loading train:   1%|          | 3/285 [00:03<05:31,  1.18s/it]Loading train:   1%|▏         | 4/285 [00:04<05:56,  1.27s/it]Loading train:   2%|▏         | 5/285 [00:06<05:36,  1.20s/it]Loading train:   2%|▏         | 6/285 [00:07<05:53,  1.27s/it]Loading train:   2%|▏         | 7/285 [00:09<06:17,  1.36s/it]Loading train:   3%|▎         | 8/285 [00:10<06:34,  1.42s/it]Loading train:   3%|▎         | 9/285 [00:11<06:12,  1.35s/it]Loading train:   4%|▎         | 10/285 [00:12<05:43,  1.25s/it]Loading train:   4%|▍         | 11/285 [00:14<05:39,  1.24s/it]Loading train:   4%|▍         | 12/285 [00:15<05:31,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:16<05:20,  1.18s/it]Loading train:   5%|▍         | 14/285 [00:17<05:14,  1.16s/it]Loading train:   5%|▌         | 15/285 [00:18<05:00,  1.11s/it]Loading train:   6%|▌         | 16/285 [00:19<04:58,  1.11s/it]Loading train:   6%|▌         | 17/285 [00:20<04:41,  1.05s/it]Loading train:   6%|▋         | 18/285 [00:21<04:50,  1.09s/it]Loading train:   7%|▋         | 19/285 [00:22<04:37,  1.04s/it]Loading train:   7%|▋         | 20/285 [00:23<04:43,  1.07s/it]Loading train:   7%|▋         | 21/285 [00:24<04:36,  1.05s/it]Loading train:   8%|▊         | 22/285 [00:25<04:52,  1.11s/it]Loading train:   8%|▊         | 23/285 [00:26<04:36,  1.06s/it]Loading train:   8%|▊         | 24/285 [00:27<04:28,  1.03s/it]Loading train:   9%|▉         | 25/285 [00:28<04:24,  1.02s/it]Loading train:   9%|▉         | 26/285 [00:29<04:23,  1.02s/it]Loading train:   9%|▉         | 27/285 [00:30<04:29,  1.04s/it]Loading train:  10%|▉         | 28/285 [00:31<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:32<04:18,  1.01s/it]Loading train:  11%|█         | 30/285 [00:33<04:08,  1.03it/s]Loading train:  11%|█         | 31/285 [00:34<04:18,  1.02s/it]Loading train:  11%|█         | 32/285 [00:35<04:13,  1.00s/it]Loading train:  12%|█▏        | 33/285 [00:36<04:04,  1.03it/s]Loading train:  12%|█▏        | 34/285 [00:37<03:55,  1.06it/s]Loading train:  12%|█▏        | 35/285 [00:38<03:59,  1.04it/s]Loading train:  13%|█▎        | 36/285 [00:39<03:58,  1.04it/s]Loading train:  13%|█▎        | 37/285 [00:40<04:12,  1.02s/it]Loading train:  13%|█▎        | 38/285 [00:41<04:07,  1.00s/it]Loading train:  14%|█▎        | 39/285 [00:42<04:16,  1.04s/it]Loading train:  14%|█▍        | 40/285 [00:43<04:08,  1.01s/it]Loading train:  14%|█▍        | 41/285 [00:44<04:15,  1.05s/it]Loading train:  15%|█▍        | 42/285 [00:45<04:00,  1.01it/s]Loading train:  15%|█▌        | 43/285 [00:46<03:53,  1.04it/s]Loading train:  15%|█▌        | 44/285 [00:47<03:51,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:48<03:53,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:49<03:49,  1.04it/s]Loading train:  16%|█▋        | 47/285 [00:50<03:34,  1.11it/s]Loading train:  17%|█▋        | 48/285 [00:51<03:27,  1.14it/s]Loading train:  17%|█▋        | 49/285 [00:51<03:21,  1.17it/s]Loading train:  18%|█▊        | 50/285 [00:52<03:15,  1.20it/s]Loading train:  18%|█▊        | 51/285 [00:53<03:08,  1.24it/s]Loading train:  18%|█▊        | 52/285 [00:54<03:06,  1.25it/s]Loading train:  19%|█▊        | 53/285 [00:55<03:04,  1.26it/s]Loading train:  19%|█▉        | 54/285 [00:55<03:16,  1.18it/s]Loading train:  19%|█▉        | 55/285 [00:56<03:06,  1.23it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:01,  1.26it/s]Loading train:  20%|██        | 57/285 [00:58<03:10,  1.20it/s]Loading train:  20%|██        | 58/285 [00:59<03:10,  1.19it/s]Loading train:  21%|██        | 59/285 [01:00<03:12,  1.17it/s]Loading train:  21%|██        | 60/285 [01:00<03:07,  1.20it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:04,  1.21it/s]Loading train:  22%|██▏       | 62/285 [01:02<03:15,  1.14it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:04,  1.21it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:42,  1.01s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:20,  1.18s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:31,  1.24s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:00,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:46,  1.04s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:30,  1.02it/s]Loading train:  25%|██▍       | 70/285 [01:11<03:13,  1.11it/s]Loading train:  25%|██▍       | 71/285 [01:12<03:19,  1.07it/s]Loading train:  25%|██▌       | 72/285 [01:12<03:15,  1.09it/s]Loading train:  26%|██▌       | 73/285 [01:13<03:11,  1.11it/s]Loading train:  26%|██▌       | 74/285 [01:14<03:12,  1.10it/s]Loading train:  26%|██▋       | 75/285 [01:15<03:04,  1.14it/s]Loading train:  27%|██▋       | 76/285 [01:16<03:10,  1.10it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:13,  1.08it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:16,  1.06it/s]Loading train:  28%|██▊       | 79/285 [01:19<03:15,  1.05it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:10,  1.07it/s]Loading train:  28%|██▊       | 81/285 [01:21<03:11,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:22<03:15,  1.04it/s]Loading train:  29%|██▉       | 83/285 [01:23<03:08,  1.07it/s]Loading train:  29%|██▉       | 84/285 [01:24<03:19,  1.01it/s]Loading train:  30%|██▉       | 85/285 [01:25<03:40,  1.10s/it]Loading train:  30%|███       | 86/285 [01:26<03:44,  1.13s/it]Loading train:  31%|███       | 87/285 [01:28<03:59,  1.21s/it]Loading train:  31%|███       | 88/285 [01:29<04:01,  1.23s/it]Loading train:  31%|███       | 89/285 [01:30<03:59,  1.22s/it]Loading train:  32%|███▏      | 90/285 [01:31<03:58,  1.22s/it]Loading train:  32%|███▏      | 91/285 [01:33<03:49,  1.18s/it]Loading train:  32%|███▏      | 92/285 [01:34<03:56,  1.23s/it]Loading train:  33%|███▎      | 93/285 [01:35<03:55,  1.23s/it]Loading train:  33%|███▎      | 94/285 [01:36<03:55,  1.23s/it]Loading train:  33%|███▎      | 95/285 [01:38<03:52,  1.22s/it]Loading train:  34%|███▎      | 96/285 [01:39<03:51,  1.22s/it]Loading train:  34%|███▍      | 97/285 [01:40<03:58,  1.27s/it]Loading train:  34%|███▍      | 98/285 [01:41<03:57,  1.27s/it]Loading train:  35%|███▍      | 99/285 [01:43<03:54,  1.26s/it]Loading train:  35%|███▌      | 100/285 [01:44<03:51,  1.25s/it]Loading train:  35%|███▌      | 101/285 [01:45<03:48,  1.24s/it]Loading train:  36%|███▌      | 102/285 [01:46<03:50,  1.26s/it]Loading train:  36%|███▌      | 103/285 [01:47<03:40,  1.21s/it]Loading train:  36%|███▋      | 104/285 [01:49<03:50,  1.27s/it]Loading train:  37%|███▋      | 105/285 [01:50<03:37,  1.21s/it]Loading train:  37%|███▋      | 106/285 [01:51<03:34,  1.20s/it]Loading train:  38%|███▊      | 107/285 [01:52<03:24,  1.15s/it]Loading train:  38%|███▊      | 108/285 [01:53<03:16,  1.11s/it]Loading train:  38%|███▊      | 109/285 [01:54<03:13,  1.10s/it]Loading train:  39%|███▊      | 110/285 [01:55<03:18,  1.13s/it]Loading train:  39%|███▉      | 111/285 [01:57<03:24,  1.18s/it]Loading train:  39%|███▉      | 112/285 [01:58<03:23,  1.17s/it]Loading train:  40%|███▉      | 113/285 [01:59<03:30,  1.22s/it]Loading train:  40%|████      | 114/285 [02:00<03:26,  1.21s/it]Loading train:  40%|████      | 115/285 [02:02<03:34,  1.26s/it]Loading train:  41%|████      | 116/285 [02:03<03:36,  1.28s/it]Loading train:  41%|████      | 117/285 [02:04<03:33,  1.27s/it]Loading train:  41%|████▏     | 118/285 [02:06<03:35,  1.29s/it]Loading train:  42%|████▏     | 119/285 [02:07<03:38,  1.32s/it]Loading train:  42%|████▏     | 120/285 [02:09<03:42,  1.35s/it]Loading train:  42%|████▏     | 121/285 [02:10<03:45,  1.38s/it]Loading train:  43%|████▎     | 122/285 [02:11<03:48,  1.40s/it]Loading train:  43%|████▎     | 123/285 [02:13<04:05,  1.52s/it]Loading train:  44%|████▎     | 124/285 [02:15<03:59,  1.49s/it]Loading train:  44%|████▍     | 125/285 [02:16<03:47,  1.42s/it]Loading train:  44%|████▍     | 126/285 [02:17<03:45,  1.42s/it]Loading train:  45%|████▍     | 127/285 [02:19<03:40,  1.40s/it]Loading train:  45%|████▍     | 128/285 [02:20<03:21,  1.29s/it]Loading train:  45%|████▌     | 129/285 [02:21<03:22,  1.30s/it]Loading train:  46%|████▌     | 130/285 [02:22<03:17,  1.27s/it]Loading train:  46%|████▌     | 131/285 [02:24<03:19,  1.29s/it]Loading train:  46%|████▋     | 132/285 [02:25<03:13,  1.27s/it]Loading train:  47%|████▋     | 133/285 [02:26<03:13,  1.27s/it]Loading train:  47%|████▋     | 134/285 [02:27<03:15,  1.30s/it]Loading train:  47%|████▋     | 135/285 [02:29<03:04,  1.23s/it]Loading train:  48%|████▊     | 136/285 [02:30<03:01,  1.22s/it]Loading train:  48%|████▊     | 137/285 [02:31<03:00,  1.22s/it]Loading train:  48%|████▊     | 138/285 [02:32<03:00,  1.23s/it]Loading train:  49%|████▉     | 139/285 [02:34<03:12,  1.32s/it]Loading train:  49%|████▉     | 140/285 [02:35<03:08,  1.30s/it]Loading train:  49%|████▉     | 141/285 [02:36<02:57,  1.24s/it]Loading train:  50%|████▉     | 142/285 [02:37<02:47,  1.17s/it]Loading train:  50%|█████     | 143/285 [02:38<02:48,  1.19s/it]Loading train:  51%|█████     | 144/285 [02:39<02:46,  1.18s/it]Loading train:  51%|█████     | 145/285 [02:41<02:40,  1.15s/it]Loading train:  51%|█████     | 146/285 [02:42<02:34,  1.11s/it]Loading train:  52%|█████▏    | 147/285 [02:43<02:40,  1.17s/it]Loading train:  52%|█████▏    | 148/285 [02:44<02:34,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [02:45<02:36,  1.15s/it]Loading train:  53%|█████▎    | 150/285 [02:46<02:27,  1.09s/it]Loading train:  53%|█████▎    | 151/285 [02:47<02:32,  1.14s/it]Loading train:  53%|█████▎    | 152/285 [02:48<02:33,  1.15s/it]Loading train:  54%|█████▎    | 153/285 [02:50<02:32,  1.15s/it]Loading train:  54%|█████▍    | 154/285 [02:50<02:18,  1.05s/it]Loading train:  54%|█████▍    | 155/285 [02:52<02:21,  1.09s/it]Loading train:  55%|█████▍    | 156/285 [02:53<02:17,  1.07s/it]Loading train:  55%|█████▌    | 157/285 [02:54<02:23,  1.12s/it]Loading train:  55%|█████▌    | 158/285 [02:55<02:22,  1.12s/it]Loading train:  56%|█████▌    | 159/285 [02:56<02:19,  1.10s/it]Loading train:  56%|█████▌    | 160/285 [02:57<02:17,  1.10s/it]Loading train:  56%|█████▋    | 161/285 [02:58<02:13,  1.07s/it]Loading train:  57%|█████▋    | 162/285 [02:59<02:13,  1.09s/it]Loading train:  57%|█████▋    | 163/285 [03:00<02:13,  1.09s/it]Loading train:  58%|█████▊    | 164/285 [03:02<02:13,  1.10s/it]Loading train:  58%|█████▊    | 165/285 [03:03<02:08,  1.07s/it]Loading train:  58%|█████▊    | 166/285 [03:04<02:16,  1.15s/it]Loading train:  59%|█████▊    | 167/285 [03:05<02:16,  1.16s/it]Loading train:  59%|█████▉    | 168/285 [03:06<02:18,  1.19s/it]Loading train:  59%|█████▉    | 169/285 [03:07<02:18,  1.20s/it]Loading train:  60%|█████▉    | 170/285 [03:09<02:19,  1.21s/it]Loading train:  60%|██████    | 171/285 [03:10<02:18,  1.21s/it]Loading train:  60%|██████    | 172/285 [03:11<02:20,  1.25s/it]Loading train:  61%|██████    | 173/285 [03:13<02:18,  1.24s/it]Loading train:  61%|██████    | 174/285 [03:14<02:15,  1.22s/it]Loading train:  61%|██████▏   | 175/285 [03:15<02:16,  1.24s/it]Loading train:  62%|██████▏   | 176/285 [03:16<02:12,  1.22s/it]Loading train:  62%|██████▏   | 177/285 [03:17<02:12,  1.23s/it]Loading train:  62%|██████▏   | 178/285 [03:18<02:04,  1.16s/it]Loading train:  63%|██████▎   | 179/285 [03:20<02:03,  1.16s/it]Loading train:  63%|██████▎   | 180/285 [03:21<01:59,  1.14s/it]Loading train:  64%|██████▎   | 181/285 [03:22<02:02,  1.17s/it]Loading train:  64%|██████▍   | 182/285 [03:23<01:54,  1.11s/it]Loading train:  64%|██████▍   | 183/285 [03:24<01:53,  1.12s/it]Loading train:  65%|██████▍   | 184/285 [03:25<01:45,  1.04s/it]Loading train:  65%|██████▍   | 185/285 [03:26<01:50,  1.11s/it]Loading train:  65%|██████▌   | 186/285 [03:27<01:43,  1.05s/it]Loading train:  66%|██████▌   | 187/285 [03:28<01:35,  1.02it/s]Loading train:  66%|██████▌   | 188/285 [03:29<01:34,  1.02it/s]Loading train:  66%|██████▋   | 189/285 [03:30<01:36,  1.00s/it]Loading train:  67%|██████▋   | 190/285 [03:31<01:35,  1.01s/it]Loading train:  67%|██████▋   | 191/285 [03:32<01:34,  1.00s/it]Loading train:  67%|██████▋   | 192/285 [03:33<01:30,  1.03it/s]Loading train:  68%|██████▊   | 193/285 [03:34<01:24,  1.08it/s]Loading train:  68%|██████▊   | 194/285 [03:35<01:26,  1.05it/s]Loading train:  68%|██████▊   | 195/285 [03:36<01:31,  1.02s/it]Loading train:  69%|██████▉   | 196/285 [03:37<01:32,  1.03s/it]Loading train:  69%|██████▉   | 197/285 [03:38<01:32,  1.05s/it]Loading train:  69%|██████▉   | 198/285 [03:39<01:29,  1.03s/it]Loading train:  70%|██████▉   | 199/285 [03:40<01:27,  1.02s/it]Loading train:  70%|███████   | 200/285 [03:41<01:24,  1.00it/s]Loading train:  71%|███████   | 201/285 [03:42<01:25,  1.02s/it]Loading train:  71%|███████   | 202/285 [03:43<01:26,  1.04s/it]Loading train:  71%|███████   | 203/285 [03:44<01:23,  1.02s/it]Loading train:  72%|███████▏  | 204/285 [03:45<01:22,  1.02s/it]Loading train:  72%|███████▏  | 205/285 [03:46<01:27,  1.09s/it]Loading train:  72%|███████▏  | 206/285 [03:47<01:26,  1.09s/it]Loading train:  73%|███████▎  | 207/285 [03:49<01:28,  1.13s/it]Loading train:  73%|███████▎  | 208/285 [03:50<01:23,  1.09s/it]Loading train:  73%|███████▎  | 209/285 [03:51<01:23,  1.09s/it]Loading train:  74%|███████▎  | 210/285 [03:52<01:20,  1.07s/it]Loading train:  74%|███████▍  | 211/285 [03:53<01:15,  1.03s/it]Loading train:  74%|███████▍  | 212/285 [03:54<01:12,  1.00it/s]Loading train:  75%|███████▍  | 213/285 [03:55<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:55<01:08,  1.03it/s]Loading train:  75%|███████▌  | 215/285 [03:57<01:10,  1.01s/it]Loading train:  76%|███████▌  | 216/285 [03:58<01:11,  1.04s/it]Loading train:  76%|███████▌  | 217/285 [03:59<01:13,  1.08s/it]Loading train:  76%|███████▋  | 218/285 [04:00<01:09,  1.04s/it]Loading train:  77%|███████▋  | 219/285 [04:01<01:07,  1.02s/it]Loading train:  77%|███████▋  | 220/285 [04:02<01:05,  1.01s/it]Loading train:  78%|███████▊  | 221/285 [04:03<01:06,  1.04s/it]Loading train:  78%|███████▊  | 222/285 [04:04<01:05,  1.03s/it]Loading train:  78%|███████▊  | 223/285 [04:05<01:05,  1.05s/it]Loading train:  79%|███████▊  | 224/285 [04:06<01:02,  1.03s/it]Loading train:  79%|███████▉  | 225/285 [04:07<01:04,  1.08s/it]Loading train:  79%|███████▉  | 226/285 [04:08<00:58,  1.01it/s]Loading train:  80%|███████▉  | 227/285 [04:09<00:59,  1.03s/it]Loading train:  80%|████████  | 228/285 [04:10<00:57,  1.01s/it]Loading train:  80%|████████  | 229/285 [04:11<00:55,  1.01it/s]Loading train:  81%|████████  | 230/285 [04:12<00:53,  1.03it/s]Loading train:  81%|████████  | 231/285 [04:13<00:52,  1.03it/s]Loading train:  81%|████████▏ | 232/285 [04:14<00:54,  1.04s/it]Loading train:  82%|████████▏ | 233/285 [04:15<00:59,  1.15s/it]Loading train:  82%|████████▏ | 234/285 [04:17<00:56,  1.11s/it]Loading train:  82%|████████▏ | 235/285 [04:18<01:01,  1.24s/it]Loading train:  83%|████████▎ | 236/285 [04:19<00:59,  1.21s/it]Loading train:  83%|████████▎ | 237/285 [04:20<00:57,  1.21s/it]Loading train:  84%|████████▎ | 238/285 [04:22<00:58,  1.23s/it]Loading train:  84%|████████▍ | 239/285 [04:23<00:55,  1.20s/it]Loading train:  84%|████████▍ | 240/285 [04:24<00:54,  1.21s/it]Loading train:  85%|████████▍ | 241/285 [04:25<00:53,  1.22s/it]Loading train:  85%|████████▍ | 242/285 [04:26<00:52,  1.21s/it]Loading train:  85%|████████▌ | 243/285 [04:28<00:51,  1.23s/it]Loading train:  86%|████████▌ | 244/285 [04:29<00:50,  1.23s/it]Loading train:  86%|████████▌ | 245/285 [04:30<00:50,  1.27s/it]Loading train:  86%|████████▋ | 246/285 [04:31<00:46,  1.20s/it]Loading train:  87%|████████▋ | 247/285 [04:33<00:46,  1.22s/it]Loading train:  87%|████████▋ | 248/285 [04:34<00:43,  1.17s/it]Loading train:  87%|████████▋ | 249/285 [04:35<00:44,  1.24s/it]Loading train:  88%|████████▊ | 250/285 [04:36<00:40,  1.14s/it]Loading train:  88%|████████▊ | 251/285 [04:37<00:38,  1.13s/it]Loading train:  88%|████████▊ | 252/285 [04:38<00:35,  1.07s/it]Loading train:  89%|████████▉ | 253/285 [04:39<00:35,  1.11s/it]Loading train:  89%|████████▉ | 254/285 [04:40<00:32,  1.05s/it]Loading train:  89%|████████▉ | 255/285 [04:41<00:33,  1.11s/it]Loading train:  90%|████████▉ | 256/285 [04:43<00:32,  1.12s/it]Loading train:  90%|█████████ | 257/285 [04:44<00:30,  1.08s/it]Loading train:  91%|█████████ | 258/285 [04:45<00:29,  1.08s/it]Loading train:  91%|█████████ | 259/285 [04:46<00:27,  1.07s/it]Loading train:  91%|█████████ | 260/285 [04:47<00:28,  1.15s/it]Loading train:  92%|█████████▏| 261/285 [04:48<00:27,  1.15s/it]Loading train:  92%|█████████▏| 262/285 [04:49<00:25,  1.13s/it]Loading train:  92%|█████████▏| 263/285 [04:50<00:25,  1.16s/it]Loading train:  93%|█████████▎| 264/285 [04:51<00:23,  1.13s/it]Loading train:  93%|█████████▎| 265/285 [04:53<00:22,  1.11s/it]Loading train:  93%|█████████▎| 266/285 [04:54<00:21,  1.13s/it]Loading train:  94%|█████████▎| 267/285 [04:55<00:19,  1.11s/it]Loading train:  94%|█████████▍| 268/285 [04:56<00:20,  1.19s/it]Loading train:  94%|█████████▍| 269/285 [04:57<00:19,  1.21s/it]Loading train:  95%|█████████▍| 270/285 [04:59<00:19,  1.28s/it]Loading train:  95%|█████████▌| 271/285 [05:00<00:17,  1.26s/it]Loading train:  95%|█████████▌| 272/285 [05:02<00:17,  1.32s/it]Loading train:  96%|█████████▌| 273/285 [05:03<00:15,  1.30s/it]Loading train:  96%|█████████▌| 274/285 [05:04<00:14,  1.34s/it]Loading train:  96%|█████████▋| 275/285 [05:05<00:13,  1.31s/it]Loading train:  97%|█████████▋| 276/285 [05:07<00:12,  1.40s/it]Loading train:  97%|█████████▋| 277/285 [05:08<00:10,  1.32s/it]Loading train:  98%|█████████▊| 278/285 [05:09<00:08,  1.27s/it]Loading train:  98%|█████████▊| 279/285 [05:11<00:07,  1.29s/it]Loading train:  98%|█████████▊| 280/285 [05:12<00:06,  1.31s/it]Loading train:  99%|█████████▊| 281/285 [05:13<00:05,  1.31s/it]Loading train:  99%|█████████▉| 282/285 [05:15<00:04,  1.34s/it]Loading train:  99%|█████████▉| 283/285 [05:16<00:02,  1.36s/it]Loading train: 100%|█████████▉| 284/285 [05:18<00:01,  1.36s/it]Loading train: 100%|██████████| 285/285 [05:19<00:00,  1.30s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 42.90it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:05, 46.47it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:05, 49.36it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:04, 57.80it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:04, 54.02it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:04, 55.07it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:03, 61.77it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:02, 77.28it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:02, 87.86it/s]concatenating: train:  32%|███▏      | 92/285 [00:01<00:02, 88.97it/s]concatenating: train:  36%|███▌      | 103/285 [00:01<00:02, 86.83it/s]concatenating: train:  42%|████▏     | 120/285 [00:01<00:01, 101.76it/s]concatenating: train:  52%|█████▏    | 149/285 [00:01<00:01, 125.67it/s]concatenating: train:  62%|██████▏   | 178/285 [00:01<00:00, 150.88it/s]concatenating: train:  72%|███████▏  | 206/285 [00:01<00:00, 174.27it/s]concatenating: train:  80%|████████  | 229/285 [00:01<00:00, 125.16it/s]concatenating: train:  89%|████████▉ | 255/285 [00:02<00:00, 147.64it/s]concatenating: train:  99%|█████████▉| 283/285 [00:02<00:00, 171.56it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 132.33it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.54s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.48s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.47s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 407.32it/s]
(0/4) test vimp2_ctrl_991_08302013_JF
(1/4) test vimp2_967_08132013_KW
(2/4) test vimp2_765_04162013_AW
(3/4) test vimp2_ANON695_03132013
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 19s - loss: 27787.3390 - acc: 0.8390 - mDice: 0.0885 - val_loss: 30671.2683 - val_acc: 0.8679 - val_mDice: 0.1284

Epoch 00001: val_mDice improved from -inf to 0.12838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 8s - loss: 15289.7070 - acc: 0.8474 - mDice: 0.1662 - val_loss: 19768.1091 - val_acc: 0.9008 - val_mDice: 0.2089

Epoch 00002: val_mDice improved from 0.12838 to 0.20893, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 8s - loss: 8689.6876 - acc: 0.8576 - mDice: 0.2187 - val_loss: 14526.0316 - val_acc: 0.8961 - val_mDice: 0.2755

Epoch 00003: val_mDice improved from 0.20893 to 0.27549, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 8s - loss: 7547.4749 - acc: 0.8652 - mDice: 0.2561 - val_loss: 13462.2575 - val_acc: 0.9020 - val_mDice: 0.3131

Epoch 00004: val_mDice improved from 0.27549 to 0.31308, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 8s - loss: 6713.2059 - acc: 0.8722 - mDice: 0.2881 - val_loss: 9187.3343 - val_acc: 0.9060 - val_mDice: 0.3328

Epoch 00005: val_mDice improved from 0.31308 to 0.33282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 5865.7096 - acc: 0.8779 - mDice: 0.3254 - val_loss: 4495.8438 - val_acc: 0.9101 - val_mDice: 0.3854

Epoch 00006: val_mDice improved from 0.33282 to 0.38544, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 8s - loss: 5269.1414 - acc: 0.8833 - mDice: 0.3596 - val_loss: 4060.0122 - val_acc: 0.9178 - val_mDice: 0.4134

Epoch 00007: val_mDice improved from 0.38544 to 0.41341, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 8s - loss: 4917.2146 - acc: 0.8880 - mDice: 0.3841 - val_loss: 3977.7297 - val_acc: 0.9141 - val_mDice: 0.4244

Epoch 00008: val_mDice improved from 0.41341 to 0.42442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 8s - loss: 4642.9020 - acc: 0.8922 - mDice: 0.4037 - val_loss: 3701.7197 - val_acc: 0.9204 - val_mDice: 0.4471

Epoch 00009: val_mDice improved from 0.42442 to 0.44715, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 8s - loss: 4409.6581 - acc: 0.8954 - mDice: 0.4213 - val_loss: 3545.9821 - val_acc: 0.9198 - val_mDice: 0.4648

Epoch 00010: val_mDice improved from 0.44715 to 0.46485, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 8s - loss: 4201.2165 - acc: 0.8980 - mDice: 0.4376 - val_loss: 3465.8376 - val_acc: 0.9214 - val_mDice: 0.4713

Epoch 00011: val_mDice improved from 0.46485 to 0.47132, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 8s - loss: 4019.4050 - acc: 0.9002 - mDice: 0.4521 - val_loss: 3302.1457 - val_acc: 0.9221 - val_mDice: 0.4875

Epoch 00012: val_mDice improved from 0.47132 to 0.48747, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 8s - loss: 3850.2035 - acc: 0.9023 - mDice: 0.4660 - val_loss: 3133.2772 - val_acc: 0.9267 - val_mDice: 0.5000

Epoch 00013: val_mDice improved from 0.48747 to 0.50003, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 11s - loss: 3711.2831 - acc: 0.9044 - mDice: 0.4786 - val_loss: 3237.3275 - val_acc: 0.9249 - val_mDice: 0.4931

Epoch 00014: val_mDice did not improve from 0.50003
Epoch 15/300
 - 10s - loss: 3600.0438 - acc: 0.9064 - mDice: 0.4885 - val_loss: 3114.5793 - val_acc: 0.9265 - val_mDice: 0.5044

Epoch 00015: val_mDice improved from 0.50003 to 0.50438, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 10s - loss: 3491.1899 - acc: 0.9076 - mDice: 0.4985 - val_loss: 3093.9120 - val_acc: 0.9298 - val_mDice: 0.5067

Epoch 00016: val_mDice improved from 0.50438 to 0.50673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 3386.1212 - acc: 0.9092 - mDice: 0.5084 - val_loss: 2987.0071 - val_acc: 0.9318 - val_mDice: 0.5142

Epoch 00017: val_mDice improved from 0.50673 to 0.51423, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 10s - loss: 3321.6775 - acc: 0.9105 - mDice: 0.5148 - val_loss: 3114.7634 - val_acc: 0.9279 - val_mDice: 0.5047

Epoch 00018: val_mDice did not improve from 0.51423
Epoch 19/300
 - 11s - loss: 3238.5494 - acc: 0.9116 - mDice: 0.5232 - val_loss: 3076.4390 - val_acc: 0.9294 - val_mDice: 0.5068

Epoch 00019: val_mDice did not improve from 0.51423
Epoch 20/300
 - 10s - loss: 3164.9900 - acc: 0.9126 - mDice: 0.5304 - val_loss: 3032.9103 - val_acc: 0.9318 - val_mDice: 0.5087

Epoch 00020: val_mDice did not improve from 0.51423
Epoch 21/300
 - 11s - loss: 3090.5052 - acc: 0.9140 - mDice: 0.5380 - val_loss: 2990.6617 - val_acc: 0.9337 - val_mDice: 0.5122

Epoch 00021: val_mDice did not improve from 0.51423
Epoch 22/300
 - 11s - loss: 3041.7297 - acc: 0.9148 - mDice: 0.5430 - val_loss: 3086.3189 - val_acc: 0.9294 - val_mDice: 0.5085

Epoch 00022: val_mDice did not improve from 0.51423
Epoch 23/300
 - 11s - loss: 2987.4409 - acc: 0.9155 - mDice: 0.5488 - val_loss: 2956.6185 - val_acc: 0.9335 - val_mDice: 0.5170

Epoch 00023: val_mDice improved from 0.51423 to 0.51701, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 10s - loss: 2939.7525 - acc: 0.9165 - mDice: 0.5541 - val_loss: 2976.8828 - val_acc: 0.9319 - val_mDice: 0.5168

Epoch 00024: val_mDice did not improve from 0.51701
Epoch 25/300
 - 11s - loss: 2875.6453 - acc: 0.9173 - mDice: 0.5610 - val_loss: 2962.0333 - val_acc: 0.9347 - val_mDice: 0.5180

Epoch 00025: val_mDice improved from 0.51701 to 0.51800, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 11s - loss: 2839.2512 - acc: 0.9182 - mDice: 0.5651 - val_loss: 2975.7082 - val_acc: 0.9300 - val_mDice: 0.5164

Epoch 00026: val_mDice did not improve from 0.51800
Epoch 27/300
 - 11s - loss: 2780.5530 - acc: 0.9187 - mDice: 0.5713 - val_loss: 2917.3491 - val_acc: 0.9368 - val_mDice: 0.5220

Epoch 00027: val_mDice improved from 0.51800 to 0.52200, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 11s - loss: 2766.8228 - acc: 0.9191 - mDice: 0.5730 - val_loss: 2948.0283 - val_acc: 0.9329 - val_mDice: 0.5206

Epoch 00028: val_mDice did not improve from 0.52200
Epoch 29/300
 - 10s - loss: 2724.0888 - acc: 0.9199 - mDice: 0.5778 - val_loss: 2942.1432 - val_acc: 0.9326 - val_mDice: 0.5216

Epoch 00029: val_mDice did not improve from 0.52200
Epoch 30/300
 - 10s - loss: 2674.2334 - acc: 0.9207 - mDice: 0.5833 - val_loss: 2874.3741 - val_acc: 0.9362 - val_mDice: 0.5264

Epoch 00030: val_mDice improved from 0.52200 to 0.52639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 11s - loss: 2634.6527 - acc: 0.9214 - mDice: 0.5880 - val_loss: 2839.7885 - val_acc: 0.9354 - val_mDice: 0.5313

Epoch 00031: val_mDice improved from 0.52639 to 0.53126, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 10s - loss: 2615.1892 - acc: 0.9217 - mDice: 0.5902 - val_loss: 2937.0408 - val_acc: 0.9368 - val_mDice: 0.5195

Epoch 00032: val_mDice did not improve from 0.53126
Epoch 33/300
 - 11s - loss: 2582.2754 - acc: 0.9223 - mDice: 0.5940 - val_loss: 2856.7880 - val_acc: 0.9348 - val_mDice: 0.5297

Epoch 00033: val_mDice did not improve from 0.53126
Epoch 34/300
 - 11s - loss: 2545.6008 - acc: 0.9229 - mDice: 0.5983 - val_loss: 2775.2747 - val_acc: 0.9385 - val_mDice: 0.5364

Epoch 00034: val_mDice improved from 0.53126 to 0.53638, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 9s - loss: 2523.8668 - acc: 0.9232 - mDice: 0.6008 - val_loss: 2845.5596 - val_acc: 0.9367 - val_mDice: 0.5316

Epoch 00035: val_mDice did not improve from 0.53638
Epoch 36/300
 - 10s - loss: 2493.7352 - acc: 0.9238 - mDice: 0.6045 - val_loss: 2799.4239 - val_acc: 0.9392 - val_mDice: 0.5370

Epoch 00036: val_mDice improved from 0.53638 to 0.53696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 10s - loss: 2453.0632 - acc: 0.9244 - mDice: 0.6093 - val_loss: 2773.2274 - val_acc: 0.9352 - val_mDice: 0.5403

Epoch 00037: val_mDice improved from 0.53696 to 0.54028, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 9s - loss: 2438.9359 - acc: 0.9248 - mDice: 0.6110 - val_loss: 2809.9361 - val_acc: 0.9357 - val_mDice: 0.5346

Epoch 00038: val_mDice did not improve from 0.54028
Epoch 39/300
 - 8s - loss: 2414.5560 - acc: 0.9252 - mDice: 0.6139 - val_loss: 2758.0654 - val_acc: 0.9392 - val_mDice: 0.5390

Epoch 00039: val_mDice did not improve from 0.54028
Epoch 40/300
 - 9s - loss: 2381.2728 - acc: 0.9257 - mDice: 0.6179 - val_loss: 2910.4223 - val_acc: 0.9344 - val_mDice: 0.5248

Epoch 00040: val_mDice did not improve from 0.54028
Epoch 41/300
 - 8s - loss: 2356.8350 - acc: 0.9260 - mDice: 0.6209 - val_loss: 2749.1109 - val_acc: 0.9404 - val_mDice: 0.5413

Epoch 00041: val_mDice improved from 0.54028 to 0.54133, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 42/300
 - 9s - loss: 2330.8823 - acc: 0.9264 - mDice: 0.6240 - val_loss: 2678.9690 - val_acc: 0.9399 - val_mDice: 0.5473

Epoch 00042: val_mDice improved from 0.54133 to 0.54732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 43/300
 - 9s - loss: 2324.3408 - acc: 0.9268 - mDice: 0.6251 - val_loss: 2793.4946 - val_acc: 0.9375 - val_mDice: 0.5391

Epoch 00043: val_mDice did not improve from 0.54732
Epoch 44/300
 - 8s - loss: 2294.5042 - acc: 0.9273 - mDice: 0.6286 - val_loss: 2680.9764 - val_acc: 0.9410 - val_mDice: 0.5469

Epoch 00044: val_mDice did not improve from 0.54732
Epoch 45/300
 - 9s - loss: 2282.8298 - acc: 0.9274 - mDice: 0.6303 - val_loss: 2772.4276 - val_acc: 0.9363 - val_mDice: 0.5398

Epoch 00045: val_mDice did not improve from 0.54732
Epoch 46/300
 - 8s - loss: 2245.5819 - acc: 0.9283 - mDice: 0.6348 - val_loss: 2703.7773 - val_acc: 0.9415 - val_mDice: 0.5449

Epoch 00046: val_mDice did not improve from 0.54732
Epoch 47/300
 - 8s - loss: 2225.3946 - acc: 0.9285 - mDice: 0.6374 - val_loss: 2622.7610 - val_acc: 0.9410 - val_mDice: 0.5555

Epoch 00047: val_mDice improved from 0.54732 to 0.55546, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 8s - loss: 2215.6988 - acc: 0.9287 - mDice: 0.6384 - val_loss: 2642.9926 - val_acc: 0.9413 - val_mDice: 0.5511

Epoch 00048: val_mDice did not improve from 0.55546
Epoch 49/300
 - 8s - loss: 2181.9312 - acc: 0.9294 - mDice: 0.6428 - val_loss: 2726.2370 - val_acc: 0.9407 - val_mDice: 0.5417

Epoch 00049: val_mDice did not improve from 0.55546
Epoch 50/300
 - 8s - loss: 2177.2327 - acc: 0.9294 - mDice: 0.6435 - val_loss: 2594.1162 - val_acc: 0.9414 - val_mDice: 0.5570

Epoch 00050: val_mDice improved from 0.55546 to 0.55696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 51/300
 - 8s - loss: 2164.5149 - acc: 0.9299 - mDice: 0.6451 - val_loss: 2764.6725 - val_acc: 0.9401 - val_mDice: 0.5374

Epoch 00051: val_mDice did not improve from 0.55696
Epoch 52/300
 - 8s - loss: 2138.4281 - acc: 0.9302 - mDice: 0.6486 - val_loss: 2629.7385 - val_acc: 0.9409 - val_mDice: 0.5530

Epoch 00052: val_mDice did not improve from 0.55696
Epoch 53/300
 - 8s - loss: 2116.9429 - acc: 0.9305 - mDice: 0.6512 - val_loss: 2613.7332 - val_acc: 0.9421 - val_mDice: 0.5542

Epoch 00053: val_mDice did not improve from 0.55696
Epoch 54/300
 - 8s - loss: 2099.4043 - acc: 0.9309 - mDice: 0.6535 - val_loss: 2632.6622 - val_acc: 0.9431 - val_mDice: 0.5522

Epoch 00054: val_mDice did not improve from 0.55696
Epoch 55/300
 - 8s - loss: 2086.2629 - acc: 0.9312 - mDice: 0.6552 - val_loss: 2697.8299 - val_acc: 0.9406 - val_mDice: 0.5474

Epoch 00055: val_mDice did not improve from 0.55696
Epoch 56/300
 - 8s - loss: 2063.6428 - acc: 0.9315 - mDice: 0.6581 - val_loss: 2656.9251 - val_acc: 0.9435 - val_mDice: 0.5488

Epoch 00056: val_mDice did not improve from 0.55696
Epoch 57/300
 - 8s - loss: 2057.0156 - acc: 0.9317 - mDice: 0.6590 - val_loss: 2601.3353 - val_acc: 0.9430 - val_mDice: 0.5552

Epoch 00057: val_mDice did not improve from 0.55696
Epoch 58/300
 - 8s - loss: 2049.1625 - acc: 0.9318 - mDice: 0.6601 - val_loss: 2602.0282 - val_acc: 0.9432 - val_mDice: 0.5563

Epoch 00058: val_mDice did not improve from 0.55696
Epoch 59/300
 - 8s - loss: 2035.2393 - acc: 0.9322 - mDice: 0.6620 - val_loss: 2639.8744 - val_acc: 0.9432 - val_mDice: 0.5496

Epoch 00059: val_mDice did not improve from 0.55696
Epoch 60/300
 - 8s - loss: 2018.7882 - acc: 0.9324 - mDice: 0.6641 - val_loss: 2670.5048 - val_acc: 0.9426 - val_mDice: 0.5484

Epoch 00060: val_mDice did not improve from 0.55696
Epoch 61/300
 - 8s - loss: 2004.8367 - acc: 0.9327 - mDice: 0.6660 - val_loss: 2615.8373 - val_acc: 0.9448 - val_mDice: 0.5511

Epoch 00061: val_mDice did not improve from 0.55696
Epoch 62/300
 - 8s - loss: 2000.7095 - acc: 0.9327 - mDice: 0.6665 - val_loss: 2624.0046 - val_acc: 0.9421 - val_mDice: 0.5523

Epoch 00062: val_mDice did not improve from 0.55696
Epoch 63/300
 - 8s - loss: 1976.3444 - acc: 0.9330 - mDice: 0.6696 - val_loss: 2794.7179 - val_acc: 0.9438 - val_mDice: 0.5308

Epoch 00063: val_mDice did not improve from 0.55696
Epoch 64/300
 - 8s - loss: 1972.5471 - acc: 0.9330 - mDice: 0.6701 - val_loss: 2614.7530 - val_acc: 0.9444 - val_mDice: 0.5518

Epoch 00064: val_mDice did not improve from 0.55696
Epoch 65/300
 - 8s - loss: 1957.3238 - acc: 0.9335 - mDice: 0.6723 - val_loss: 2639.3158 - val_acc: 0.9430 - val_mDice: 0.5505

Epoch 00065: val_mDice did not improve from 0.55696
Epoch 66/300
 - 8s - loss: 1946.4386 - acc: 0.9337 - mDice: 0.6737 - val_loss: 2557.7734 - val_acc: 0.9437 - val_mDice: 0.5592

Epoch 00066: val_mDice improved from 0.55696 to 0.55921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 67/300
 - 8s - loss: 1927.6172 - acc: 0.9338 - mDice: 0.6762 - val_loss: 2614.0175 - val_acc: 0.9442 - val_mDice: 0.5532

Epoch 00067: val_mDice did not improve from 0.55921
Epoch 68/300
 - 8s - loss: 1924.4211 - acc: 0.9341 - mDice: 0.6767 - val_loss: 2647.7047 - val_acc: 0.9439 - val_mDice: 0.5484

Epoch 00068: val_mDice did not improve from 0.55921
Epoch 69/300
 - 8s - loss: 1910.0880 - acc: 0.9343 - mDice: 0.6786 - val_loss: 2611.6575 - val_acc: 0.9450 - val_mDice: 0.5527

Epoch 00069: val_mDice did not improve from 0.55921
Epoch 70/300
 - 8s - loss: 1908.8068 - acc: 0.9343 - mDice: 0.6787 - val_loss: 2839.2771 - val_acc: 0.9446 - val_mDice: 0.5273

Epoch 00070: val_mDice did not improve from 0.55921
Epoch 71/300
 - 8s - loss: 1894.1542 - acc: 0.9344 - mDice: 0.6806 - val_loss: 2750.0268 - val_acc: 0.9443 - val_mDice: 0.5352

Epoch 00071: val_mDice did not improve from 0.55921
Epoch 72/300
 - 8s - loss: 1877.0925 - acc: 0.9348 - mDice: 0.6832 - val_loss: 2553.2117 - val_acc: 0.9430 - val_mDice: 0.5610

Epoch 00072: val_mDice improved from 0.55921 to 0.56100, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 73/300
 - 8s - loss: 1870.2567 - acc: 0.9350 - mDice: 0.6840 - val_loss: 2539.6671 - val_acc: 0.9443 - val_mDice: 0.5606

Epoch 00073: val_mDice did not improve from 0.56100
Epoch 74/300
 - 8s - loss: 1855.4398 - acc: 0.9352 - mDice: 0.6859 - val_loss: 2483.5676 - val_acc: 0.9451 - val_mDice: 0.5661

Epoch 00074: val_mDice improved from 0.56100 to 0.56606, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 75/300
 - 8s - loss: 1854.7411 - acc: 0.9353 - mDice: 0.6860 - val_loss: 2509.4583 - val_acc: 0.9454 - val_mDice: 0.5634

Epoch 00075: val_mDice did not improve from 0.56606
Epoch 76/300
 - 8s - loss: 1842.9622 - acc: 0.9356 - mDice: 0.6877 - val_loss: 2614.1904 - val_acc: 0.9457 - val_mDice: 0.5530

Epoch 00076: val_mDice did not improve from 0.56606
Epoch 77/300
 - 8s - loss: 1835.9089 - acc: 0.9354 - mDice: 0.6886 - val_loss: 2539.2930 - val_acc: 0.9447 - val_mDice: 0.5609

Epoch 00077: val_mDice did not improve from 0.56606
Epoch 78/300
 - 8s - loss: 1829.1680 - acc: 0.9357 - mDice: 0.6896 - val_loss: 2798.9853 - val_acc: 0.9447 - val_mDice: 0.5323

Epoch 00078: val_mDice did not improve from 0.56606
Epoch 79/300
 - 8s - loss: 1820.9634 - acc: 0.9358 - mDice: 0.6907 - val_loss: 2665.9200 - val_acc: 0.9439 - val_mDice: 0.5500

Epoch 00079: val_mDice did not improve from 0.56606
Epoch 80/300
 - 8s - loss: 1805.5148 - acc: 0.9361 - mDice: 0.6928 - val_loss: 2523.2774 - val_acc: 0.9446 - val_mDice: 0.5639

Epoch 00080: val_mDice did not improve from 0.56606
Epoch 81/300
 - 8s - loss: 1805.4324 - acc: 0.9361 - mDice: 0.6928 - val_loss: 2584.5313 - val_acc: 0.9435 - val_mDice: 0.5592

Epoch 00081: val_mDice did not improve from 0.56606
Epoch 82/300
 - 8s - loss: 1789.0537 - acc: 0.9362 - mDice: 0.6951 - val_loss: 2652.4601 - val_acc: 0.9453 - val_mDice: 0.5466

Epoch 00082: val_mDice did not improve from 0.56606
Epoch 83/300
 - 8s - loss: 1796.3767 - acc: 0.9362 - mDice: 0.6941 - val_loss: 2523.7037 - val_acc: 0.9461 - val_mDice: 0.5625

Epoch 00083: val_mDice did not improve from 0.56606
Epoch 84/300
 - 8s - loss: 1780.2194 - acc: 0.9364 - mDice: 0.6964 - val_loss: 2516.3810 - val_acc: 0.9460 - val_mDice: 0.5630

Epoch 00084: val_mDice did not improve from 0.56606
Epoch 85/300
 - 8s - loss: 1763.6559 - acc: 0.9368 - mDice: 0.6986 - val_loss: 2520.8781 - val_acc: 0.9457 - val_mDice: 0.5629

Epoch 00085: val_mDice did not improve from 0.56606
Epoch 86/300
 - 8s - loss: 1767.3701 - acc: 0.9367 - mDice: 0.6982 - val_loss: 2668.1878 - val_acc: 0.9418 - val_mDice: 0.5491

Epoch 00086: val_mDice did not improve from 0.56606
Epoch 87/300
 - 8s - loss: 1756.9996 - acc: 0.9368 - mDice: 0.6997 - val_loss: 2494.3898 - val_acc: 0.9449 - val_mDice: 0.5680

Epoch 00087: val_mDice improved from 0.56606 to 0.56804, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 88/300
 - 8s - loss: 1747.7895 - acc: 0.9370 - mDice: 0.7009 - val_loss: 2446.9040 - val_acc: 0.9463 - val_mDice: 0.5718

Epoch 00088: val_mDice improved from 0.56804 to 0.57180, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 89/300
 - 8s - loss: 1745.9140 - acc: 0.9370 - mDice: 0.7012 - val_loss: 2604.4758 - val_acc: 0.9416 - val_mDice: 0.5554

Epoch 00089: val_mDice did not improve from 0.57180
Epoch 90/300
 - 8s - loss: 1740.1141 - acc: 0.9371 - mDice: 0.7020 - val_loss: 2490.9921 - val_acc: 0.9450 - val_mDice: 0.5671

Epoch 00090: val_mDice did not improve from 0.57180
Epoch 91/300
 - 8s - loss: 1727.3253 - acc: 0.9373 - mDice: 0.7037 - val_loss: 2582.8388 - val_acc: 0.9445 - val_mDice: 0.5571

Epoch 00091: val_mDice did not improve from 0.57180
Epoch 92/300
 - 8s - loss: 1719.6368 - acc: 0.9375 - mDice: 0.7049 - val_loss: 2654.2640 - val_acc: 0.9464 - val_mDice: 0.5489

Epoch 00092: val_mDice did not improve from 0.57180
Epoch 93/300
 - 8s - loss: 1719.8663 - acc: 0.9374 - mDice: 0.7048 - val_loss: 3023.9844 - val_acc: 0.9439 - val_mDice: 0.5104

Epoch 00093: val_mDice did not improve from 0.57180
Epoch 94/300
 - 8s - loss: 1707.7818 - acc: 0.9375 - mDice: 0.7065 - val_loss: 2602.9973 - val_acc: 0.9445 - val_mDice: 0.5556

Epoch 00094: val_mDice did not improve from 0.57180
Epoch 95/300
 - 8s - loss: 1702.3338 - acc: 0.9378 - mDice: 0.7072 - val_loss: 2572.4174 - val_acc: 0.9438 - val_mDice: 0.5596

Epoch 00095: val_mDice did not improve from 0.57180
Epoch 96/300
 - 8s - loss: 1702.1814 - acc: 0.9378 - mDice: 0.7073 - val_loss: 2547.0269 - val_acc: 0.9452 - val_mDice: 0.5601

Epoch 00096: val_mDice did not improve from 0.57180
Epoch 97/300
 - 8s - loss: 1689.0168 - acc: 0.9378 - mDice: 0.7092 - val_loss: 2580.2785 - val_acc: 0.9434 - val_mDice: 0.5579

Epoch 00097: val_mDice did not improve from 0.57180
Epoch 98/300
 - 8s - loss: 1683.2676 - acc: 0.9379 - mDice: 0.7100 - val_loss: 2635.0842 - val_acc: 0.9457 - val_mDice: 0.5523

Epoch 00098: val_mDice did not improve from 0.57180
Epoch 99/300
 - 8s - loss: 1674.3897 - acc: 0.9381 - mDice: 0.7111 - val_loss: 2806.8333 - val_acc: 0.9457 - val_mDice: 0.5329

Epoch 00099: val_mDice did not improve from 0.57180
Epoch 100/300
 - 8s - loss: 1668.2812 - acc: 0.9383 - mDice: 0.7121 - val_loss: 2819.2291 - val_acc: 0.9399 - val_mDice: 0.5327

Epoch 00100: val_mDice did not improve from 0.57180
Epoch 101/300
 - 8s - loss: 1670.9317 - acc: 0.9384 - mDice: 0.7117 - val_loss: 2616.6965 - val_acc: 0.9446 - val_mDice: 0.5525

Epoch 00101: val_mDice did not improve from 0.57180
Epoch 102/300
 - 8s - loss: 1666.3047 - acc: 0.9383 - mDice: 0.7124 - val_loss: 2562.5319 - val_acc: 0.9453 - val_mDice: 0.5585

Epoch 00102: val_mDice did not improve from 0.57180
Epoch 103/300
 - 8s - loss: 1664.1383 - acc: 0.9382 - mDice: 0.7126 - val_loss: 2542.1431 - val_acc: 0.9468 - val_mDice: 0.5634

Epoch 00103: val_mDice did not improve from 0.57180
Epoch 104/300
 - 8s - loss: 1651.5728 - acc: 0.9385 - mDice: 0.7144 - val_loss: 2551.9017 - val_acc: 0.9449 - val_mDice: 0.5592

Epoch 00104: val_mDice did not improve from 0.57180
Epoch 105/300
 - 8s - loss: 1648.0238 - acc: 0.9385 - mDice: 0.7149 - val_loss: 2497.2265 - val_acc: 0.9470 - val_mDice: 0.5648

Epoch 00105: val_mDice did not improve from 0.57180
Epoch 106/300
 - 8s - loss: 1635.5340 - acc: 0.9388 - mDice: 0.7167 - val_loss: 2581.7701 - val_acc: 0.9458 - val_mDice: 0.5562

Epoch 00106: val_mDice did not improve from 0.57180
Epoch 107/300
 - 8s - loss: 1629.4106 - acc: 0.9391 - mDice: 0.7176 - val_loss: 2638.6104 - val_acc: 0.9466 - val_mDice: 0.5489

Epoch 00107: val_mDice did not improve from 0.57180
Epoch 108/300
 - 8s - loss: 1634.9243 - acc: 0.9388 - mDice: 0.7168 - val_loss: 2462.6951 - val_acc: 0.9451 - val_mDice: 0.5706

Epoch 00108: val_mDice did not improve from 0.57180
Epoch 109/300
 - 8s - loss: 1630.3324 - acc: 0.9388 - mDice: 0.7175 - val_loss: 2700.7313 - val_acc: 0.9458 - val_mDice: 0.5453

Epoch 00109: val_mDice did not improve from 0.57180
Epoch 110/300
 - 8s - loss: 1615.7246 - acc: 0.9393 - mDice: 0.7196 - val_loss: 2465.9841 - val_acc: 0.9458 - val_mDice: 0.5687

Epoch 00110: val_mDice did not improve from 0.57180
Epoch 111/300
 - 8s - loss: 1622.3891 - acc: 0.9390 - mDice: 0.7186 - val_loss: 2620.0356 - val_acc: 0.9436 - val_mDice: 0.5534

Epoch 00111: val_mDice did not improve from 0.57180
Epoch 112/300
 - 8s - loss: 1619.1895 - acc: 0.9391 - mDice: 0.7191 - val_loss: 2645.5105 - val_acc: 0.9438 - val_mDice: 0.5521

Epoch 00112: val_mDice did not improve from 0.57180
Epoch 113/300
 - 8s - loss: 1606.7071 - acc: 0.9395 - mDice: 0.7209 - val_loss: 2606.4857 - val_acc: 0.9446 - val_mDice: 0.5534

Epoch 00113: val_mDice did not improve from 0.57180
Epoch 114/300
 - 8s - loss: 1607.7032 - acc: 0.9394 - mDice: 0.7208 - val_loss: 2728.2311 - val_acc: 0.9417 - val_mDice: 0.5411

Epoch 00114: val_mDice did not improve from 0.57180
Epoch 115/300
 - 8s - loss: 1602.4492 - acc: 0.9396 - mDice: 0.7215 - val_loss: 2513.8077 - val_acc: 0.9447 - val_mDice: 0.5642

Epoch 00115: val_mDice did not improve from 0.57180
Epoch 116/300
 - 8s - loss: 1590.9928 - acc: 0.9397 - mDice: 0.7231 - val_loss: 2699.0496 - val_acc: 0.9440 - val_mDice: 0.5444

Epoch 00116: val_mDice did not improve from 0.57180
Epoch 117/300
 - 8s - loss: 1594.5398 - acc: 0.9394 - mDice: 0.7226 - val_loss: 2951.2177 - val_acc: 0.9441 - val_mDice: 0.5160

Epoch 00117: val_mDice did not improve from 0.57180
Epoch 118/300
 - 8s - loss: 1594.3784 - acc: 0.9396 - mDice: 0.7226 - val_loss: 2606.2453 - val_acc: 0.9448 - val_mDice: 0.5522

Epoch 00118: val_mDice did not improve from 0.57180
Restoring model weights from the end of the best epoch
Epoch 00118: early stopping
{'val_loss': [30671.26828729539, 19768.10906110491, 14526.031552269345, 13462.257486979166, 9187.334344773066, 4495.843784877232, 4060.012201218378, 3977.7296549479165, 3701.71969749814, 3545.982131231399, 3465.837599981399, 3302.145728701637, 3133.2771577380954, 3237.3275088355654, 3114.5792701357886, 3093.9120279947915, 2987.007144019717, 3114.763404482887, 3076.439028785342, 3032.910313197545, 2990.661699567522, 3086.318894159226, 2956.6185186476932, 2976.882795061384, 2962.0332786923364, 2975.708234514509, 2917.349057152158, 2948.028265090216, 2942.1431884765625, 2874.3740960984005, 2839.7884637741818, 2937.0408296130954, 2856.7879551478795, 2775.274658203125, 2845.559634254092, 2799.4239211309523, 2773.2273995535716, 2809.9361339750744, 2758.065420968192, 2910.4223022460938, 2749.11092703683, 2678.968962169829, 2793.494634719122, 2680.9764084588915, 2772.42764718192, 2703.77725655692, 2622.7610299246653, 2642.9925653366818, 2726.2369762602307, 2594.116193498884, 2764.6724853515625, 2629.738534109933, 2613.733224051339, 2632.662150065104, 2697.8299066452755, 2656.925057547433, 2601.3353097098216, 2602.0282360258557, 2639.8744230724515, 2670.5047752743676, 2615.837299891881, 2624.004616873605, 2794.717931111654, 2614.7530408586777, 2639.3158089773997, 2557.773390997024, 2614.01749819801, 2647.7046726771764, 2611.6575215657554, 2839.2770545596168, 2750.0267573765345, 2553.211707705543, 2539.6671360560827, 2483.5675920758927, 2509.4583195277623, 2614.190442766462, 2539.2929571242557, 2798.985326857794, 2665.9200381324404, 2523.27737281436, 2584.531319754464, 2652.4601077125185, 2523.7037426176526, 2516.3809967041016, 2520.8781077067056, 2668.1878473191036, 2494.389828636533, 2446.9039786202566, 2604.4758097330728, 2490.9920668829054, 2582.838827950614, 2654.2640351795017, 3023.9844498407274, 2602.997317359561, 2572.4174049014136, 2547.0269324893043, 2580.2785208565847, 2635.084243774414, 2806.833300635928, 2819.229066394624, 2616.696501958938, 2562.5318559919083, 2542.143053327288, 2551.9016861688524, 2497.226514543806, 2581.7701183500744, 2638.610368274507, 2462.695060366676, 2700.7312614804223, 2465.984114147368, 2620.035642351423, 2645.510511125837, 2606.4857308523997, 2728.2310660226003, 2513.8077022007533, 2699.049593970889, 2951.217724754697, 2606.24533589681], 'val_acc': [0.8679235378901163, 0.9007761222975594, 0.8960806074596587, 0.9019620021184286, 0.9059775500070482, 0.9101007495607648, 0.9178410910424732, 0.9141117249216352, 0.9203914716130212, 0.919764206522987, 0.9213942459651402, 0.9221245220729283, 0.9266735088257563, 0.9249450280552819, 0.9265453247796922, 0.9298053752808344, 0.9317742728051686, 0.9279487104642958, 0.9293979008992513, 0.9317925827843803, 0.9336882091703869, 0.9294116213208153, 0.9334592762447539, 0.931932250658671, 0.9347023992311387, 0.9300251830191839, 0.9367559552192688, 0.9328914767219907, 0.9325938849222093, 0.9361607375599089, 0.935407505148933, 0.9367605135554359, 0.9348053903806777, 0.9385302180335635, 0.936675835223425, 0.9391895617757525, 0.9351831532659984, 0.9356570527667091, 0.9391918494587853, 0.934411625067393, 0.94043497244517, 0.93987637758255, 0.9374748269716898, 0.9409569587026324, 0.9363118069512504, 0.9415270430701119, 0.9409660980814979, 0.9413484391712007, 0.9407211712428502, 0.9414057022049314, 0.9400801062583923, 0.9409386430467878, 0.942074199517568, 0.9430769142650423, 0.9406410001573109, 0.9435050232069833, 0.9430425876662845, 0.9431547806376502, 0.9432326271420434, 0.9425847303299677, 0.9448374765259879, 0.9420650005340576, 0.9437912134897142, 0.9444253728503272, 0.9430448725110009, 0.943676749865214, 0.9442032689139956, 0.9439377131916228, 0.9449564814567566, 0.9445924702144805, 0.9442513982454935, 0.9429555904297602, 0.9443497998373849, 0.945064073517209, 0.9454464117685953, 0.9457119845208668, 0.9447161016010103, 0.9447023953710284, 0.9438988140651158, 0.9446245289984203, 0.943473009836106, 0.9452541413761321, 0.9460531189328149, 0.9460439738773164, 0.9457257361639113, 0.9418223216420128, 0.9448557609603518, 0.9462591579982212, 0.9416163194747198, 0.9449793980235145, 0.9444574316342672, 0.946449149222601, 0.9439331718853542, 0.9444986411503383, 0.9438347248804002, 0.9451556546347482, 0.9434455292565482, 0.945741784004938, 0.9456753645624433, 0.9399176041285197, 0.9446062133425758, 0.9452609959102812, 0.9468086134819758, 0.9449061495917184, 0.9469917785553705, 0.9458356386139279, 0.9465728061539787, 0.9450755601837522, 0.9458104343641371, 0.945826442468734, 0.9435508307956514, 0.9438301069395882, 0.9446062360491071, 0.9417491072700137, 0.9447183836074102, 0.9440453222819737, 0.9441231489181519, 0.9448076770419166], 'val_mDice': [0.1283830688113258, 0.20893147574471577, 0.27549197365130695, 0.3130829625186466, 0.33282096063097316, 0.3854368103756791, 0.4134106689265796, 0.42441886840831666, 0.4471481116045089, 0.4648481321831544, 0.4713207490387417, 0.48747385949605987, 0.500028974066178, 0.4931107858816783, 0.5043800114875748, 0.5067272674114931, 0.5142325915041424, 0.504671723360107, 0.5068408655268806, 0.5086833698054155, 0.5122414756388891, 0.5084836793442568, 0.5170063245154563, 0.5167923676116126, 0.518003618433362, 0.5164483677418459, 0.5219975844735191, 0.5205792823717708, 0.5215510229269663, 0.5263948857429481, 0.5312636292406491, 0.5194739640823433, 0.529686301237061, 0.5363781053040709, 0.531638039542096, 0.5369554834351653, 0.5402806213214284, 0.5345796921423503, 0.5389847434347584, 0.5248300786174479, 0.5413277819752693, 0.5473248369636989, 0.5390825463192803, 0.5469300239568665, 0.5398214959672519, 0.5449165245961576, 0.5554559805563518, 0.5510531060752415, 0.5417128884721369, 0.5569600388407707, 0.5373925818573861, 0.552974155261403, 0.5542182776899565, 0.5521540604531765, 0.547358565919456, 0.5488469242340043, 0.5552420456494603, 0.5562638881660643, 0.5496486870660668, 0.5483723637603578, 0.551139367833024, 0.5523447598375025, 0.5308416900890214, 0.5517508548994859, 0.5505214360143457, 0.5592061203150522, 0.5531971791670436, 0.5483631974174863, 0.5526948925994691, 0.5272831283509731, 0.5351530448311851, 0.5610005394333885, 0.5606056854483628, 0.5660621350010236, 0.5634442039188885, 0.5529550099301905, 0.5608866262648787, 0.5323178420464197, 0.549995195120573, 0.5639472374958652, 0.5592272930911609, 0.5466389294181552, 0.5625028792946112, 0.5630037809411684, 0.5629384808597111, 0.5491399119297663, 0.5680437645032292, 0.5717975444027356, 0.5553986270512853, 0.5671426238758224, 0.5571277272843179, 0.5489129459574109, 0.5103860447804133, 0.555590220505283, 0.5596105885647592, 0.5600560406843821, 0.5579094338629927, 0.5522667359383333, 0.5329318364106473, 0.5327398713145938, 0.5525151581636497, 0.5585423147394544, 0.5633564137277149, 0.5592437987881047, 0.564783150596278, 0.5561565770989373, 0.548879956205686, 0.5705855545543489, 0.5453031481731505, 0.5686539972112292, 0.5534482435101554, 0.5521235004777, 0.5534019122521082, 0.5411202673401151, 0.5641938980136599, 0.5444369420763993, 0.5159568981755347, 0.5522217048066003], 'loss': [27787.339023264292, 15289.706969120518, 8689.68757559087, 7547.474877849672, 6713.2059401245, 5865.709603457637, 5269.141414609239, 4917.214596691172, 4642.902028678216, 4409.658086396882, 4201.2165471803755, 4019.4049917838465, 3850.2035372667697, 3711.2830646515627, 3600.0438447757015, 3491.189866380193, 3386.121164163413, 3321.6774567221087, 3238.54944438357, 3164.9900477512138, 3090.5051971311996, 3041.7297492246994, 2987.4408878924323, 2939.752537706948, 2875.645273320772, 2839.2511717761577, 2780.553041209921, 2766.8227712742646, 2724.08884301819, 2674.233403097211, 2634.652735142205, 2615.189179425803, 2582.2754327271377, 2545.600841962742, 2523.8667861294234, 2493.7352084764193, 2453.06324338867, 2438.9359457274495, 2414.5559727330647, 2381.2728282780645, 2356.8350302448202, 2330.882281951875, 2324.3408483884364, 2294.5042107550653, 2282.8297871048567, 2245.5818817627, 2225.3945595612754, 2215.6987754890906, 2181.9311569093256, 2177.2327124244657, 2164.5148657730188, 2138.428142452736, 2116.942852737312, 2099.404255737752, 2086.2628918911237, 2063.6427921657737, 2057.0156390262014, 2049.1625158524316, 2035.239328743659, 2018.7882181273874, 2004.8367051991834, 2000.7094784691221, 1976.3444095374027, 1972.54712563598, 1957.3238055418744, 1946.4385890074495, 1927.6172184470718, 1924.4210747063723, 1910.087995797976, 1908.8067570942455, 1894.1542126236566, 1877.0924597542157, 1870.2566787075486, 1855.4397782457572, 1854.7410665099874, 1842.9621753828683, 1835.908939830044, 1829.167978822507, 1820.9633976156963, 1805.5147857813101, 1805.4324062061328, 1789.053685167885, 1796.3767454148442, 1780.2194097962756, 1763.6558600904305, 1767.3700729673117, 1756.9995655172336, 1747.7895061845193, 1745.9140118550583, 1740.1141295527732, 1727.3253227014727, 1719.6368178041635, 1719.866279844744, 1707.7818192143143, 1702.3338111184662, 1702.1814300907768, 1689.0168462914723, 1683.2675980817428, 1674.3896607927948, 1668.2812203002247, 1670.9316564162434, 1666.3047383802807, 1664.1383135714511, 1651.5728425819657, 1648.0237746230434, 1635.5339996532045, 1629.4106251628546, 1634.9242617605462, 1630.332358677079, 1615.7246186002867, 1622.3890577132058, 1619.18945493711, 1606.707144471568, 1607.7031668903328, 1602.4492437665301, 1590.9928271277277, 1594.5397598563718, 1594.3784121088102], 'acc': [0.8390160612410058, 0.8473563263796418, 0.8575521657548246, 0.8651778995818385, 0.8722226710615532, 0.8779035228305822, 0.883253621473601, 0.8879987482898654, 0.8922426696799959, 0.8954108154380714, 0.8980107199761916, 0.9002484489388151, 0.9023385940430962, 0.9043681912852409, 0.9063530226812809, 0.907587014263665, 0.909240275856983, 0.9104778638620562, 0.9115604761824894, 0.9125689791994148, 0.9140472736734633, 0.914769912021156, 0.9154884043469786, 0.9164626146870494, 0.9172748338056939, 0.9182242072913283, 0.9186825905895104, 0.9191156976687694, 0.9198507291631293, 0.9206784545214668, 0.9214218497644023, 0.9216590580830851, 0.9223218713855614, 0.9229411120379801, 0.9231693550803561, 0.923814227373264, 0.9244372929156068, 0.924776508315395, 0.9252014110974087, 0.9256905206301917, 0.9260096398419398, 0.9263856974161956, 0.9268376404595141, 0.9273177859685268, 0.9273949477606848, 0.928311047571023, 0.9284531627635356, 0.9286622654065614, 0.929363859120375, 0.9294485736150652, 0.9298624693025899, 0.9302146116248992, 0.9305205979810552, 0.9309392883204439, 0.9312103737037214, 0.9314862128648084, 0.9316546487192301, 0.9318188924492498, 0.9321995340998701, 0.9323990911515389, 0.9327057705625119, 0.9326960387798962, 0.9330279080307459, 0.93303487964832, 0.9335221172597152, 0.933710571518518, 0.9338420027824227, 0.9340784931219633, 0.9343124798136179, 0.9343427441840414, 0.9344116127488699, 0.934840504686934, 0.9349992036221918, 0.9352370618808608, 0.9352604631332389, 0.9355657069536448, 0.9354038077419333, 0.9356726928899025, 0.935839576920678, 0.9360991236054417, 0.9361112426075145, 0.9361730685394026, 0.9361924611352325, 0.9363764197191614, 0.9367892750775352, 0.9367151480891329, 0.9368498679275615, 0.9369981450245792, 0.9370327894917936, 0.9371028108267695, 0.9372829272380702, 0.9374615123374443, 0.9374173014798742, 0.9375374900345539, 0.9377664982962292, 0.9377661300850025, 0.9378195589324608, 0.9379084720785319, 0.9381424842805607, 0.9382589461028013, 0.9383567312514366, 0.9383168983992662, 0.9381840121362258, 0.9384837167006088, 0.9385243132207719, 0.9388159993229424, 0.939061757822774, 0.9388334705279424, 0.938836134649872, 0.939251654451928, 0.9390307540881604, 0.9390562258521463, 0.9394629115839558, 0.9394438172066996, 0.9396048608326328, 0.9396645747928094, 0.9394324170800793, 0.9395801802234933], 'mDice': [0.08849827495066215, 0.16619384769118312, 0.2186623905460936, 0.25614189737353776, 0.2880954411888435, 0.3253802152780386, 0.3596185976274905, 0.38414455258205077, 0.40369872169410054, 0.42131087363788977, 0.43764065992908024, 0.45210898600494287, 0.46599248917502245, 0.47862014516323365, 0.48845269640033956, 0.4984644771610493, 0.5083737882065685, 0.5148473167341294, 0.5232362281340773, 0.5304459573125389, 0.5380112620385507, 0.5430123205471756, 0.5488017678306768, 0.5540639037499429, 0.5610496291012026, 0.5650549829178563, 0.5713393055728481, 0.5729516014925014, 0.5777966517783416, 0.5833384434060368, 0.5880419105975091, 0.5901691347780038, 0.5940112670722301, 0.5982555269804308, 0.6008496790670443, 0.6045040758974823, 0.6092983859224725, 0.6110337708918878, 0.613929212794314, 0.6179318354955776, 0.6208792836858699, 0.6239660026734335, 0.6251256271711269, 0.6286389616176024, 0.630289920439995, 0.6348239539881674, 0.6373556294559812, 0.6383547182599772, 0.6428010908652299, 0.6434527195003282, 0.6451147932272691, 0.6485625206217592, 0.6511762609641768, 0.6534768195080578, 0.6551635758206177, 0.6580790364261948, 0.6589882117556956, 0.6600622998420181, 0.6619994424546365, 0.6641078320040463, 0.6659664263356644, 0.6665492234534327, 0.6696032096890555, 0.6701158876131329, 0.672333021809284, 0.6736859912147912, 0.6761741297815447, 0.6767009614013583, 0.6785569449759917, 0.678740407026915, 0.6806358195049859, 0.6831552751817661, 0.6839500306221201, 0.6859320478561597, 0.6860397722717883, 0.6877090562072498, 0.6886106380291106, 0.6895720030913491, 0.6907306238247615, 0.6928354367852234, 0.6927883806361016, 0.6950752662283988, 0.694114782940291, 0.6964122517411824, 0.698638812687118, 0.6981854743757113, 0.6996962824882698, 0.7008752184656973, 0.7012075186120491, 0.7019706001993271, 0.7037203549212612, 0.7048838112380479, 0.7047850774941886, 0.7064576325031381, 0.7072270737233042, 0.7072528044405714, 0.7091621877325737, 0.7099922678478425, 0.7110895608141171, 0.7120536018801443, 0.7116508627870949, 0.7123652187666039, 0.7126390016651208, 0.7144380629993436, 0.7149219423538231, 0.7166877533168216, 0.7175625075787415, 0.7168013941742952, 0.7175080303238471, 0.719634470508488, 0.7186157056447373, 0.7191181881983477, 0.7208519711507316, 0.7207760852679872, 0.7215275663343128, 0.7230583579181269, 0.722617936497459, 0.7226356153017481]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:18,  1.33s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:51,  1.46s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:56,  1.48s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:21,  1.57s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:14,  1.55s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:05,  1.75s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:12,  1.78s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:01,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:14,  1.80s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:26,  1.85s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:30,  1.87s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:32,  1.89s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:30,  1.89s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:36,  1.91s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:26,  1.88s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:30,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:53,  2.00s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:38,  1.95s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:35,  1.95s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:32,  1.94s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:20,  1.90s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:16,  1.90s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:20,  1.92s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:27,  1.95s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:24,  1.95s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:28,  1.97s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:20,  1.95s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:06,  1.90s/it]predicting train subjects:  11%|█         | 30/285 [00:55<07:58,  1.88s/it]predicting train subjects:  11%|█         | 31/285 [00:57<07:53,  1.86s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:03,  1.91s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:52,  1.88s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:44,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:35,  1.82s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:31,  1.83s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:38,  1.87s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:30,  1.84s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:35,  1.87s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:25,  1.83s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:32,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:25,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:22,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<06:56,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<06:47,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<06:28,  1.64s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<06:17,  1.60s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<06:08,  1.57s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<06:34,  1.69s/it]predicting train subjects:  18%|█▊        | 52/285 [01:34<06:26,  1.66s/it]predicting train subjects:  19%|█▊        | 53/285 [01:36<06:11,  1.60s/it]predicting train subjects:  19%|█▉        | 54/285 [01:37<06:13,  1.62s/it]predicting train subjects:  19%|█▉        | 55/285 [01:39<06:04,  1.59s/it]predicting train subjects:  20%|█▉        | 56/285 [01:40<06:08,  1.61s/it]predicting train subjects:  20%|██        | 57/285 [01:42<06:12,  1.63s/it]predicting train subjects:  20%|██        | 58/285 [01:44<06:00,  1.59s/it]predicting train subjects:  21%|██        | 59/285 [01:45<05:54,  1.57s/it]predicting train subjects:  21%|██        | 60/285 [01:47<05:57,  1.59s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<05:47,  1.55s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<05:41,  1.53s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<05:33,  1.50s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<05:35,  1.52s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:00,  1.64s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:02,  1.66s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:02,  1.66s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<05:52,  1.63s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<05:58,  1.66s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<05:50,  1.63s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<05:45,  1.61s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<05:41,  1.60s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<05:36,  1.59s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<05:36,  1.59s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<05:31,  1.58s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<05:30,  1.58s/it]predicting train subjects:  27%|██▋       | 77/285 [02:14<05:28,  1.58s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:26,  1.57s/it]predicting train subjects:  28%|██▊       | 79/285 [02:17<05:23,  1.57s/it]predicting train subjects:  28%|██▊       | 80/285 [02:19<05:35,  1.64s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:28,  1.61s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:39,  1.67s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:46,  1.72s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:44,  1.71s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:57,  1.80s/it]predicting train subjects:  31%|███       | 87/285 [02:31<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:33<06:14,  1.90s/it]predicting train subjects:  31%|███       | 89/285 [02:35<06:13,  1.91s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<06:18,  1.94s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<06:12,  1.92s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<06:06,  1.90s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<06:10,  1.93s/it]predicting train subjects:  33%|███▎      | 94/285 [02:45<06:08,  1.93s/it]predicting train subjects:  33%|███▎      | 95/285 [02:47<06:06,  1.93s/it]predicting train subjects:  34%|███▎      | 96/285 [02:49<06:10,  1.96s/it]predicting train subjects:  34%|███▍      | 97/285 [02:51<06:03,  1.93s/it]predicting train subjects:  34%|███▍      | 98/285 [02:53<06:04,  1.95s/it]predicting train subjects:  35%|███▍      | 99/285 [02:55<06:02,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [02:57<05:54,  1.91s/it]predicting train subjects:  35%|███▌      | 101/285 [02:58<05:48,  1.89s/it]predicting train subjects:  36%|███▌      | 102/285 [03:00<05:41,  1.87s/it]predicting train subjects:  36%|███▌      | 103/285 [03:02<05:33,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:04<05:30,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:06<05:28,  1.83s/it]predicting train subjects:  37%|███▋      | 106/285 [03:07<05:23,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:09<05:23,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:11<05:29,  1.86s/it]predicting train subjects:  38%|███▊      | 109/285 [03:13<05:28,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:15<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:17<05:19,  1.83s/it]predicting train subjects:  39%|███▉      | 112/285 [03:19<05:19,  1.84s/it]predicting train subjects:  40%|███▉      | 113/285 [03:20<05:15,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:22<05:09,  1.81s/it]predicting train subjects:  40%|████      | 115/285 [03:24<05:04,  1.79s/it]predicting train subjects:  41%|████      | 116/285 [03:26<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:28<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:29<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:31<04:54,  1.77s/it]predicting train subjects:  42%|████▏     | 120/285 [03:33<04:51,  1.77s/it]predicting train subjects:  42%|████▏     | 121/285 [03:34<04:42,  1.72s/it]predicting train subjects:  43%|████▎     | 122/285 [03:36<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:37<04:10,  1.54s/it]predicting train subjects:  44%|████▎     | 124/285 [03:39<04:11,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:40<04:11,  1.57s/it]predicting train subjects:  44%|████▍     | 126/285 [03:42<04:11,  1.58s/it]predicting train subjects:  45%|████▍     | 127/285 [03:43<04:06,  1.56s/it]predicting train subjects:  45%|████▍     | 128/285 [03:45<04:05,  1.56s/it]predicting train subjects:  45%|████▌     | 129/285 [03:47<04:09,  1.60s/it]predicting train subjects:  46%|████▌     | 130/285 [03:48<04:06,  1.59s/it]predicting train subjects:  46%|████▌     | 131/285 [03:50<04:03,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [03:51<03:58,  1.56s/it]predicting train subjects:  47%|████▋     | 133/285 [03:53<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [03:54<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 135/285 [03:56<03:53,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [03:58<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 137/285 [03:59<03:49,  1.55s/it]predicting train subjects:  48%|████▊     | 138/285 [04:01<03:51,  1.57s/it]predicting train subjects:  49%|████▉     | 139/285 [04:02<03:50,  1.58s/it]predicting train subjects:  49%|████▉     | 140/285 [04:04<03:49,  1.58s/it]predicting train subjects:  49%|████▉     | 141/285 [04:06<03:49,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:07<03:37,  1.52s/it]predicting train subjects:  50%|█████     | 143/285 [04:08<03:28,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:10<03:23,  1.44s/it]predicting train subjects:  51%|█████     | 145/285 [04:11<03:19,  1.42s/it]predicting train subjects:  51%|█████     | 146/285 [04:12<03:14,  1.40s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:14<03:12,  1.39s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:15<03:15,  1.43s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:17<03:11,  1.40s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:18<03:09,  1.40s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:19<03:08,  1.40s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:21<03:03,  1.38s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:22<03:10,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:24<03:09,  1.45s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:25<03:05,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:27<03:02,  1.42s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:28<03:00,  1.41s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:29<02:59,  1.41s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:31<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:32<02:53,  1.39s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:34<02:52,  1.40s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:35<02:51,  1.40s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:36<02:47,  1.37s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:38<02:44,  1.36s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:39<02:45,  1.38s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:40<02:44,  1.38s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:42<02:44,  1.40s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:43<02:42,  1.39s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:45<02:39,  1.38s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:46<02:39,  1.38s/it]predicting train subjects:  60%|██████    | 171/285 [04:47<02:38,  1.39s/it]predicting train subjects:  60%|██████    | 172/285 [04:49<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:50<02:37,  1.41s/it]predicting train subjects:  61%|██████    | 174/285 [04:52<02:35,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:53<02:33,  1.39s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:54<02:32,  1.40s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:56<02:31,  1.40s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:57<02:27,  1.38s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:25,  1.37s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:00<02:23,  1.37s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:01<02:26,  1.41s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:03<02:24,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:04<02:22,  1.39s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:20,  1.39s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:07<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:08<02:19,  1.41s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:10<02:17,  1.40s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:11<02:15,  1.40s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:13<02:14,  1.40s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:14<02:12,  1.40s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:15<02:11,  1.40s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:17<02:09,  1.39s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:18<02:07,  1.38s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:19<02:05,  1.38s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:21<02:03,  1.37s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:22<02:08,  1.45s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:24<02:14,  1.53s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:26<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:28<02:20,  1.64s/it]predicting train subjects:  70%|███████   | 200/285 [05:29<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [05:31<02:21,  1.68s/it]predicting train subjects:  71%|███████   | 202/285 [05:33<02:19,  1.68s/it]predicting train subjects:  71%|███████   | 203/285 [05:34<02:18,  1.69s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:36<02:16,  1.68s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:38<02:13,  1.67s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:39<02:12,  1.67s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:41<02:11,  1.68s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:43<02:08,  1.67s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:44<02:05,  1.66s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:46<02:04,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:48<02:02,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:49<02:00,  1.64s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:51<01:59,  1.65s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:52<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:54<01:48,  1.54s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:55<01:43,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:57<01:40,  1.48s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:58<01:37,  1.45s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:00<01:36,  1.46s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:01<01:34,  1.46s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:02<01:32,  1.44s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:04<01:29,  1.42s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:05<01:27,  1.41s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:07<01:26,  1.41s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:08<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:23,  1.42s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:11<01:22,  1.43s/it]predicting train subjects:  80%|████████  | 228/285 [06:12<01:22,  1.44s/it]predicting train subjects:  80%|████████  | 229/285 [06:14<01:21,  1.45s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:21,  1.48s/it]predicting train subjects:  81%|████████  | 231/285 [06:17<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:19<01:25,  1.61s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:21<01:27,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:23<01:29,  1.76s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:25<01:31,  1.83s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:26<01:30,  1.85s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:28<01:29,  1.86s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:30<01:27,  1.85s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:32<01:26,  1.88s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:34<01:25,  1.90s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:36<01:24,  1.91s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:38<01:22,  1.91s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:40<01:20,  1.91s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:42<01:18,  1.92s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:44<01:16,  1.92s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:45<01:14,  1.90s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:47<01:11,  1.88s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:49<01:09,  1.87s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:51<01:07,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:52<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:54<00:55,  1.63s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:55<00:51,  1.56s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:57<00:47,  1.50s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:58<00:44,  1.44s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:59<00:42,  1.42s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:01<00:40,  1.41s/it]predicting train subjects:  90%|█████████ | 257/285 [07:02<00:38,  1.38s/it]predicting train subjects:  91%|█████████ | 258/285 [07:03<00:37,  1.38s/it]predicting train subjects:  91%|█████████ | 259/285 [07:05<00:35,  1.37s/it]predicting train subjects:  91%|█████████ | 260/285 [07:06<00:34,  1.37s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:07<00:33,  1.38s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:09<00:31,  1.37s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:10<00:30,  1.37s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:11<00:28,  1.35s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:13<00:26,  1.33s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:14<00:25,  1.34s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:15<00:24,  1.35s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:17<00:25,  1.53s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:19<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:21<00:25,  1.72s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:23<00:25,  1.81s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:25<00:23,  1.82s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:27<00:21,  1.83s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:29<00:20,  1.83s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:31<00:18,  1.82s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:32<00:16,  1.80s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:34<00:14,  1.82s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:36<00:12,  1.82s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:38<00:10,  1.80s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:09,  1.82s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:41<00:07,  1.82s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:43<00:05,  1.82s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.80s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.80s/it]predicting train subjects: 100%|██████████| 285/285 [07:49<00:00,  1.81s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:51,  1.45s/it]Loading train:   1%|          | 2/285 [00:03<07:00,  1.49s/it]Loading train:   1%|          | 3/285 [00:04<06:59,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:06<07:29,  1.60s/it]Loading train:   2%|▏         | 5/285 [00:07<07:07,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:09<07:22,  1.59s/it]Loading train:   2%|▏         | 7/285 [00:11<07:55,  1.71s/it]Loading train:   3%|▎         | 8/285 [00:13<07:48,  1.69s/it]Loading train:   3%|▎         | 9/285 [00:14<07:29,  1.63s/it]Loading train:   4%|▎         | 10/285 [00:15<06:57,  1.52s/it]Loading train:   4%|▍         | 11/285 [00:17<06:32,  1.43s/it]Loading train:   4%|▍         | 12/285 [00:18<06:22,  1.40s/it]Loading train:   5%|▍         | 13/285 [00:19<05:58,  1.32s/it]Loading train:   5%|▍         | 14/285 [00:20<05:48,  1.29s/it]Loading train:   5%|▌         | 15/285 [00:22<05:47,  1.29s/it]Loading train:   6%|▌         | 16/285 [00:23<05:45,  1.28s/it]Loading train:   6%|▌         | 17/285 [00:24<05:35,  1.25s/it]Loading train:   6%|▋         | 18/285 [00:25<05:32,  1.24s/it]Loading train:   7%|▋         | 19/285 [00:27<05:46,  1.30s/it]Loading train:   7%|▋         | 20/285 [00:28<05:44,  1.30s/it]Loading train:   7%|▋         | 21/285 [00:29<05:40,  1.29s/it]Loading train:   8%|▊         | 22/285 [00:30<05:33,  1.27s/it]Loading train:   8%|▊         | 23/285 [00:32<05:28,  1.25s/it]Loading train:   8%|▊         | 24/285 [00:33<05:25,  1.25s/it]Loading train:   9%|▉         | 25/285 [00:34<05:11,  1.20s/it]Loading train:   9%|▉         | 26/285 [00:35<05:11,  1.20s/it]Loading train:   9%|▉         | 27/285 [00:36<05:17,  1.23s/it]Loading train:  10%|▉         | 28/285 [00:38<05:02,  1.18s/it]Loading train:  10%|█         | 29/285 [00:39<05:01,  1.18s/it]Loading train:  11%|█         | 30/285 [00:40<04:50,  1.14s/it]Loading train:  11%|█         | 31/285 [00:41<04:45,  1.12s/it]Loading train:  11%|█         | 32/285 [00:42<04:56,  1.17s/it]Loading train:  12%|█▏        | 33/285 [00:43<04:46,  1.14s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:45,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:46<04:52,  1.17s/it]Loading train:  13%|█▎        | 36/285 [00:47<04:43,  1.14s/it]Loading train:  13%|█▎        | 37/285 [00:48<04:35,  1.11s/it]Loading train:  13%|█▎        | 38/285 [00:49<04:34,  1.11s/it]Loading train:  14%|█▎        | 39/285 [00:50<04:28,  1.09s/it]Loading train:  14%|█▍        | 40/285 [00:51<04:28,  1.10s/it]Loading train:  14%|█▍        | 41/285 [00:52<04:19,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:53<04:22,  1.08s/it]Loading train:  15%|█▌        | 43/285 [00:54<04:13,  1.05s/it]Loading train:  15%|█▌        | 44/285 [00:55<04:06,  1.02s/it]Loading train:  16%|█▌        | 45/285 [00:56<04:12,  1.05s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:11,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:58<04:06,  1.03s/it]Loading train:  17%|█▋        | 48/285 [00:59<03:52,  1.02it/s]Loading train:  17%|█▋        | 49/285 [01:00<03:45,  1.05it/s]Loading train:  18%|█▊        | 50/285 [01:01<03:48,  1.03it/s]Loading train:  18%|█▊        | 51/285 [01:02<03:44,  1.04it/s]Loading train:  18%|█▊        | 52/285 [01:03<03:46,  1.03it/s]Loading train:  19%|█▊        | 53/285 [01:04<03:48,  1.01it/s]Loading train:  19%|█▉        | 54/285 [01:05<03:47,  1.01it/s]Loading train:  19%|█▉        | 55/285 [01:06<03:46,  1.02it/s]Loading train:  20%|█▉        | 56/285 [01:07<03:48,  1.00it/s]Loading train:  20%|██        | 57/285 [01:08<03:44,  1.02it/s]Loading train:  20%|██        | 58/285 [01:09<03:37,  1.05it/s]Loading train:  21%|██        | 59/285 [01:10<03:36,  1.04it/s]Loading train:  21%|██        | 60/285 [01:11<03:49,  1.02s/it]Loading train:  21%|██▏       | 61/285 [01:12<03:46,  1.01s/it]Loading train:  22%|██▏       | 62/285 [01:13<03:40,  1.01it/s]Loading train:  22%|██▏       | 63/285 [01:14<03:43,  1.01s/it]Loading train:  22%|██▏       | 64/285 [01:16<04:28,  1.22s/it]Loading train:  23%|██▎       | 65/285 [01:17<05:05,  1.39s/it]Loading train:  23%|██▎       | 66/285 [01:19<05:12,  1.43s/it]Loading train:  24%|██▎       | 67/285 [01:20<04:47,  1.32s/it]Loading train:  24%|██▍       | 68/285 [01:21<04:30,  1.24s/it]Loading train:  24%|██▍       | 69/285 [01:22<04:17,  1.19s/it]Loading train:  25%|██▍       | 70/285 [01:23<04:06,  1.15s/it]Loading train:  25%|██▍       | 71/285 [01:24<04:08,  1.16s/it]Loading train:  25%|██▌       | 72/285 [01:25<03:59,  1.13s/it]Loading train:  26%|██▌       | 73/285 [01:26<03:52,  1.10s/it]Loading train:  26%|██▌       | 74/285 [01:27<03:50,  1.09s/it]Loading train:  26%|██▋       | 75/285 [01:28<03:40,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:29<03:38,  1.04s/it]Loading train:  27%|██▋       | 77/285 [01:30<03:35,  1.04s/it]Loading train:  27%|██▋       | 78/285 [01:31<03:30,  1.01s/it]Loading train:  28%|██▊       | 79/285 [01:33<03:40,  1.07s/it]Loading train:  28%|██▊       | 80/285 [01:34<03:35,  1.05s/it]Loading train:  28%|██▊       | 81/285 [01:35<03:33,  1.05s/it]Loading train:  29%|██▉       | 82/285 [01:36<03:36,  1.07s/it]Loading train:  29%|██▉       | 83/285 [01:37<03:30,  1.04s/it]Loading train:  29%|██▉       | 84/285 [01:38<03:28,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:39<03:40,  1.10s/it]Loading train:  30%|███       | 86/285 [01:40<03:40,  1.11s/it]Loading train:  31%|███       | 87/285 [01:41<03:38,  1.10s/it]Loading train:  31%|███       | 88/285 [01:42<03:40,  1.12s/it]Loading train:  31%|███       | 89/285 [01:43<03:37,  1.11s/it]Loading train:  32%|███▏      | 90/285 [01:45<03:34,  1.10s/it]Loading train:  32%|███▏      | 91/285 [01:46<03:36,  1.11s/it]Loading train:  32%|███▏      | 92/285 [01:47<03:32,  1.10s/it]Loading train:  33%|███▎      | 93/285 [01:48<03:32,  1.11s/it]Loading train:  33%|███▎      | 94/285 [01:49<03:27,  1.09s/it]Loading train:  33%|███▎      | 95/285 [01:50<03:32,  1.12s/it]Loading train:  34%|███▎      | 96/285 [01:51<03:31,  1.12s/it]Loading train:  34%|███▍      | 97/285 [01:52<03:29,  1.11s/it]Loading train:  34%|███▍      | 98/285 [01:53<03:28,  1.12s/it]Loading train:  35%|███▍      | 99/285 [01:55<03:28,  1.12s/it]Loading train:  35%|███▌      | 100/285 [01:56<03:31,  1.14s/it]Loading train:  35%|███▌      | 101/285 [01:57<03:27,  1.13s/it]Loading train:  36%|███▌      | 102/285 [01:58<03:26,  1.13s/it]Loading train:  36%|███▌      | 103/285 [01:59<03:28,  1.15s/it]Loading train:  36%|███▋      | 104/285 [02:00<03:28,  1.15s/it]Loading train:  37%|███▋      | 105/285 [02:01<03:25,  1.14s/it]Loading train:  37%|███▋      | 106/285 [02:03<03:19,  1.11s/it]Loading train:  38%|███▊      | 107/285 [02:04<03:13,  1.09s/it]Loading train:  38%|███▊      | 108/285 [02:05<03:15,  1.11s/it]Loading train:  38%|███▊      | 109/285 [02:06<03:17,  1.12s/it]Loading train:  39%|███▊      | 110/285 [02:07<03:11,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:08<03:05,  1.07s/it]Loading train:  39%|███▉      | 112/285 [02:09<03:02,  1.06s/it]Loading train:  40%|███▉      | 113/285 [02:10<03:05,  1.08s/it]Loading train:  40%|████      | 114/285 [02:11<03:05,  1.09s/it]Loading train:  40%|████      | 115/285 [02:12<03:01,  1.07s/it]Loading train:  41%|████      | 116/285 [02:13<02:59,  1.06s/it]Loading train:  41%|████      | 117/285 [02:14<02:58,  1.06s/it]Loading train:  41%|████▏     | 118/285 [02:15<02:54,  1.04s/it]Loading train:  42%|████▏     | 119/285 [02:16<02:58,  1.08s/it]Loading train:  42%|████▏     | 120/285 [02:17<02:52,  1.04s/it]Loading train:  42%|████▏     | 121/285 [02:19<03:14,  1.19s/it]Loading train:  43%|████▎     | 122/285 [02:20<03:16,  1.21s/it]Loading train:  43%|████▎     | 123/285 [02:22<03:24,  1.26s/it]Loading train:  44%|████▎     | 124/285 [02:23<03:11,  1.19s/it]Loading train:  44%|████▍     | 125/285 [02:24<03:00,  1.13s/it]Loading train:  44%|████▍     | 126/285 [02:25<02:53,  1.09s/it]Loading train:  45%|████▍     | 127/285 [02:26<02:47,  1.06s/it]Loading train:  45%|████▍     | 128/285 [02:27<02:43,  1.04s/it]Loading train:  45%|████▌     | 129/285 [02:28<02:43,  1.05s/it]Loading train:  46%|████▌     | 130/285 [02:29<02:40,  1.04s/it]Loading train:  46%|████▌     | 131/285 [02:30<02:35,  1.01s/it]Loading train:  46%|████▋     | 132/285 [02:31<02:35,  1.01s/it]Loading train:  47%|████▋     | 133/285 [02:32<02:34,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:33<02:32,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:34<02:28,  1.01it/s]Loading train:  48%|████▊     | 136/285 [02:35<02:24,  1.03it/s]Loading train:  48%|████▊     | 137/285 [02:35<02:23,  1.03it/s]Loading train:  48%|████▊     | 138/285 [02:36<02:22,  1.04it/s]Loading train:  49%|████▉     | 139/285 [02:37<02:16,  1.07it/s]Loading train:  49%|████▉     | 140/285 [02:38<02:24,  1.01it/s]Loading train:  49%|████▉     | 141/285 [02:40<02:26,  1.02s/it]Loading train:  50%|████▉     | 142/285 [02:41<02:26,  1.03s/it]Loading train:  50%|█████     | 143/285 [02:41<02:20,  1.01it/s]Loading train:  51%|█████     | 144/285 [02:42<02:19,  1.01it/s]Loading train:  51%|█████     | 145/285 [02:43<02:15,  1.03it/s]Loading train:  51%|█████     | 146/285 [02:44<02:12,  1.05it/s]Loading train:  52%|█████▏    | 147/285 [02:45<02:09,  1.07it/s]Loading train:  52%|█████▏    | 148/285 [02:46<02:04,  1.10it/s]Loading train:  52%|█████▏    | 149/285 [02:47<02:03,  1.10it/s]Loading train:  53%|█████▎    | 150/285 [02:48<02:04,  1.08it/s]Loading train:  53%|█████▎    | 151/285 [02:49<02:02,  1.10it/s]Loading train:  53%|█████▎    | 152/285 [02:50<02:07,  1.04it/s]Loading train:  54%|█████▎    | 153/285 [02:51<02:05,  1.05it/s]Loading train:  54%|█████▍    | 154/285 [02:52<02:06,  1.04it/s]Loading train:  54%|█████▍    | 155/285 [02:53<02:03,  1.06it/s]Loading train:  55%|█████▍    | 156/285 [02:54<02:07,  1.01it/s]Loading train:  55%|█████▌    | 157/285 [02:55<02:02,  1.05it/s]Loading train:  55%|█████▌    | 158/285 [02:56<02:03,  1.03it/s]Loading train:  56%|█████▌    | 159/285 [02:57<02:00,  1.05it/s]Loading train:  56%|█████▌    | 160/285 [02:58<02:05,  1.00s/it]Loading train:  56%|█████▋    | 161/285 [02:59<02:01,  1.02it/s]Loading train:  57%|█████▋    | 162/285 [02:59<01:56,  1.06it/s]Loading train:  57%|█████▋    | 163/285 [03:00<01:56,  1.04it/s]Loading train:  58%|█████▊    | 164/285 [03:01<01:53,  1.07it/s]Loading train:  58%|█████▊    | 165/285 [03:02<01:48,  1.10it/s]Loading train:  58%|█████▊    | 166/285 [03:03<01:47,  1.11it/s]Loading train:  59%|█████▊    | 167/285 [03:04<01:47,  1.09it/s]Loading train:  59%|█████▉    | 168/285 [03:05<01:46,  1.10it/s]Loading train:  59%|█████▉    | 169/285 [03:06<01:42,  1.13it/s]Loading train:  60%|█████▉    | 170/285 [03:07<01:41,  1.14it/s]Loading train:  60%|██████    | 171/285 [03:08<01:44,  1.09it/s]Loading train:  60%|██████    | 172/285 [03:08<01:41,  1.11it/s]Loading train:  61%|██████    | 173/285 [03:09<01:40,  1.12it/s]Loading train:  61%|██████    | 174/285 [03:10<01:38,  1.13it/s]Loading train:  61%|██████▏   | 175/285 [03:11<01:38,  1.12it/s]Loading train:  62%|██████▏   | 176/285 [03:12<01:35,  1.14it/s]Loading train:  62%|██████▏   | 177/285 [03:13<01:33,  1.15it/s]Loading train:  62%|██████▏   | 178/285 [03:14<01:37,  1.10it/s]Loading train:  63%|██████▎   | 179/285 [03:15<01:35,  1.11it/s]Loading train:  63%|██████▎   | 180/285 [03:16<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [03:16<01:29,  1.16it/s]Loading train:  64%|██████▍   | 182/285 [03:17<01:33,  1.10it/s]Loading train:  64%|██████▍   | 183/285 [03:18<01:34,  1.08it/s]Loading train:  65%|██████▍   | 184/285 [03:19<01:36,  1.05it/s]Loading train:  65%|██████▍   | 185/285 [03:20<01:34,  1.06it/s]Loading train:  65%|██████▌   | 186/285 [03:21<01:32,  1.07it/s]Loading train:  66%|██████▌   | 187/285 [03:22<01:28,  1.11it/s]Loading train:  66%|██████▌   | 188/285 [03:23<01:26,  1.12it/s]Loading train:  66%|██████▋   | 189/285 [03:24<01:25,  1.12it/s]Loading train:  67%|██████▋   | 190/285 [03:25<01:25,  1.11it/s]Loading train:  67%|██████▋   | 191/285 [03:26<01:31,  1.03it/s]Loading train:  67%|██████▋   | 192/285 [03:27<01:28,  1.05it/s]Loading train:  68%|██████▊   | 193/285 [03:28<01:24,  1.08it/s]Loading train:  68%|██████▊   | 194/285 [03:28<01:20,  1.14it/s]Loading train:  68%|██████▊   | 195/285 [03:29<01:17,  1.16it/s]Loading train:  69%|██████▉   | 196/285 [03:30<01:25,  1.04it/s]Loading train:  69%|██████▉   | 197/285 [03:31<01:25,  1.03it/s]Loading train:  69%|██████▉   | 198/285 [03:33<01:28,  1.02s/it]Loading train:  70%|██████▉   | 199/285 [03:33<01:25,  1.01it/s]Loading train:  70%|███████   | 200/285 [03:34<01:22,  1.03it/s]Loading train:  71%|███████   | 201/285 [03:35<01:25,  1.01s/it]Loading train:  71%|███████   | 202/285 [03:37<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [03:38<01:23,  1.02s/it]Loading train:  72%|███████▏  | 204/285 [03:39<01:21,  1.01s/it]Loading train:  72%|███████▏  | 205/285 [03:39<01:19,  1.01it/s]Loading train:  72%|███████▏  | 206/285 [03:40<01:16,  1.03it/s]Loading train:  73%|███████▎  | 207/285 [03:41<01:18,  1.00s/it]Loading train:  73%|███████▎  | 208/285 [03:43<01:18,  1.02s/it]Loading train:  73%|███████▎  | 209/285 [03:43<01:16,  1.00s/it]Loading train:  74%|███████▎  | 210/285 [03:44<01:14,  1.01it/s]Loading train:  74%|███████▍  | 211/285 [03:45<01:11,  1.04it/s]Loading train:  74%|███████▍  | 212/285 [03:46<01:12,  1.01it/s]Loading train:  75%|███████▍  | 213/285 [03:47<01:11,  1.00it/s]Loading train:  75%|███████▌  | 214/285 [03:48<01:11,  1.00s/it]Loading train:  75%|███████▌  | 215/285 [03:49<01:08,  1.02it/s]Loading train:  76%|███████▌  | 216/285 [03:50<01:05,  1.06it/s]Loading train:  76%|███████▌  | 217/285 [03:51<01:03,  1.07it/s]Loading train:  76%|███████▋  | 218/285 [03:52<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [03:53<01:01,  1.08it/s]Loading train:  77%|███████▋  | 220/285 [03:54<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:55<00:55,  1.16it/s]Loading train:  78%|███████▊  | 222/285 [03:55<00:53,  1.18it/s]Loading train:  78%|███████▊  | 223/285 [03:56<00:52,  1.18it/s]Loading train:  79%|███████▊  | 224/285 [03:57<00:51,  1.18it/s]Loading train:  79%|███████▉  | 225/285 [03:58<00:50,  1.19it/s]Loading train:  79%|███████▉  | 226/285 [03:59<00:50,  1.16it/s]Loading train:  80%|███████▉  | 227/285 [04:00<00:49,  1.18it/s]Loading train:  80%|████████  | 228/285 [04:01<00:50,  1.14it/s]Loading train:  80%|████████  | 229/285 [04:01<00:48,  1.15it/s]Loading train:  81%|████████  | 230/285 [04:02<00:48,  1.14it/s]Loading train:  81%|████████  | 231/285 [04:03<00:47,  1.15it/s]Loading train:  81%|████████▏ | 232/285 [04:04<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [04:05<00:52,  1.00s/it]Loading train:  82%|████████▏ | 234/285 [04:06<00:51,  1.01s/it]Loading train:  82%|████████▏ | 235/285 [04:08<00:51,  1.04s/it]Loading train:  83%|████████▎ | 236/285 [04:09<00:52,  1.07s/it]Loading train:  83%|████████▎ | 237/285 [04:10<00:51,  1.07s/it]Loading train:  84%|████████▎ | 238/285 [04:11<00:49,  1.04s/it]Loading train:  84%|████████▍ | 239/285 [04:12<00:49,  1.07s/it]Loading train:  84%|████████▍ | 240/285 [04:13<00:48,  1.07s/it]Loading train:  85%|████████▍ | 241/285 [04:14<00:46,  1.05s/it]Loading train:  85%|████████▍ | 242/285 [04:15<00:45,  1.06s/it]Loading train:  85%|████████▌ | 243/285 [04:16<00:43,  1.05s/it]Loading train:  86%|████████▌ | 244/285 [04:17<00:42,  1.04s/it]Loading train:  86%|████████▌ | 245/285 [04:18<00:41,  1.04s/it]Loading train:  86%|████████▋ | 246/285 [04:19<00:40,  1.04s/it]Loading train:  87%|████████▋ | 247/285 [04:20<00:39,  1.04s/it]Loading train:  87%|████████▋ | 248/285 [04:21<00:37,  1.02s/it]Loading train:  87%|████████▋ | 249/285 [04:22<00:35,  1.01it/s]Loading train:  88%|████████▊ | 250/285 [04:23<00:34,  1.02it/s]Loading train:  88%|████████▊ | 251/285 [04:24<00:32,  1.05it/s]Loading train:  88%|████████▊ | 252/285 [04:25<00:31,  1.06it/s]Loading train:  89%|████████▉ | 253/285 [04:26<00:31,  1.02it/s]Loading train:  89%|████████▉ | 254/285 [04:27<00:29,  1.04it/s]Loading train:  89%|████████▉ | 255/285 [04:28<00:27,  1.09it/s]Loading train:  90%|████████▉ | 256/285 [04:29<00:26,  1.11it/s]Loading train:  90%|█████████ | 257/285 [04:29<00:25,  1.09it/s]Loading train:  91%|█████████ | 258/285 [04:30<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [04:31<00:23,  1.10it/s]Loading train:  91%|█████████ | 260/285 [04:32<00:22,  1.13it/s]Loading train:  92%|█████████▏| 261/285 [04:33<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [04:34<00:20,  1.12it/s]Loading train:  92%|█████████▏| 263/285 [04:35<00:20,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [04:36<00:18,  1.12it/s]Loading train:  93%|█████████▎| 265/285 [04:37<00:17,  1.12it/s]Loading train:  93%|█████████▎| 266/285 [04:38<00:17,  1.06it/s]Loading train:  94%|█████████▎| 267/285 [04:38<00:16,  1.12it/s]Loading train:  94%|█████████▍| 268/285 [04:40<00:16,  1.02it/s]Loading train:  94%|█████████▍| 269/285 [04:41<00:16,  1.00s/it]Loading train:  95%|█████████▍| 270/285 [04:42<00:15,  1.02s/it]Loading train:  95%|█████████▌| 271/285 [04:43<00:14,  1.05s/it]Loading train:  95%|█████████▌| 272/285 [04:44<00:13,  1.04s/it]Loading train:  96%|█████████▌| 273/285 [04:45<00:12,  1.06s/it]Loading train:  96%|█████████▌| 274/285 [04:46<00:11,  1.09s/it]Loading train:  96%|█████████▋| 275/285 [04:47<00:10,  1.08s/it]Loading train:  97%|█████████▋| 276/285 [04:48<00:09,  1.09s/it]Loading train:  97%|█████████▋| 277/285 [04:49<00:08,  1.11s/it]Loading train:  98%|█████████▊| 278/285 [04:51<00:07,  1.10s/it]Loading train:  98%|█████████▊| 279/285 [04:52<00:06,  1.09s/it]Loading train:  98%|█████████▊| 280/285 [04:53<00:05,  1.08s/it]Loading train:  99%|█████████▊| 281/285 [04:54<00:04,  1.05s/it]Loading train:  99%|█████████▉| 282/285 [04:55<00:03,  1.05s/it]Loading train:  99%|█████████▉| 283/285 [04:56<00:02,  1.04s/it]Loading train: 100%|█████████▉| 284/285 [04:57<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [04:58<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:02, 96.17it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:02, 108.51it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:02, 113.79it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:01, 129.19it/s]concatenating: train:  27%|██▋       | 78/285 [00:00<00:01, 143.61it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:01, 159.62it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:00, 172.54it/s]concatenating: train:  51%|█████     | 145/285 [00:00<00:00, 185.91it/s]concatenating: train:  59%|█████▉    | 168/285 [00:00<00:00, 197.11it/s]concatenating: train:  66%|██████▋   | 189/285 [00:01<00:00, 194.16it/s]concatenating: train:  74%|███████▍  | 211/285 [00:01<00:00, 200.41it/s]concatenating: train:  82%|████████▏ | 233/285 [00:01<00:00, 200.83it/s]concatenating: train:  89%|████████▉ | 255/285 [00:01<00:00, 204.84it/s]concatenating: train:  97%|█████████▋| 276/285 [00:01<00:00, 168.71it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 179.46it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 63.45it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 20)   0           batch_normalization_7[0][0]      2019-07-07 02:14:02.087335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 02:14:02.087428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 02:14:02.087444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 02:14:02.087454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 02:14:02.087919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 20s - loss: 20335.6073 - acc: 0.8618 - mDice: 0.1329 - val_loss: 16431.0250 - val_acc: 0.8990 - val_mDice: 0.2200

Epoch 00001: val_mDice improved from -inf to 0.22003, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 9107.9683 - acc: 0.8783 - mDice: 0.2224 - val_loss: 5529.0034 - val_acc: 0.9089 - val_mDice: 0.3425

Epoch 00002: val_mDice improved from 0.22003 to 0.34245, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 6557.3488 - acc: 0.8899 - mDice: 0.2973 - val_loss: 4412.4517 - val_acc: 0.9160 - val_mDice: 0.4003

Epoch 00003: val_mDice improved from 0.34245 to 0.40033, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 5684.6932 - acc: 0.8982 - mDice: 0.3422 - val_loss: 4090.6350 - val_acc: 0.9216 - val_mDice: 0.4256

Epoch 00004: val_mDice improved from 0.40033 to 0.42558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 11s - loss: 5150.1218 - acc: 0.9035 - mDice: 0.3741 - val_loss: 4247.4097 - val_acc: 0.9237 - val_mDice: 0.4167

Epoch 00005: val_mDice did not improve from 0.42558
Epoch 6/300
 - 11s - loss: 4747.1854 - acc: 0.9081 - mDice: 0.4005 - val_loss: 4260.8907 - val_acc: 0.9244 - val_mDice: 0.4150

Epoch 00006: val_mDice did not improve from 0.42558
Epoch 7/300
 - 11s - loss: 4432.7173 - acc: 0.9120 - mDice: 0.4228 - val_loss: 3884.4062 - val_acc: 0.9262 - val_mDice: 0.4405

Epoch 00007: val_mDice improved from 0.42558 to 0.44051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 4155.7907 - acc: 0.9157 - mDice: 0.4436 - val_loss: 3779.5696 - val_acc: 0.9320 - val_mDice: 0.4490

Epoch 00008: val_mDice improved from 0.44051 to 0.44896, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 3946.7416 - acc: 0.9186 - mDice: 0.4619 - val_loss: 3317.4754 - val_acc: 0.9342 - val_mDice: 0.4852

Epoch 00009: val_mDice improved from 0.44896 to 0.48524, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 11s - loss: 3755.4497 - acc: 0.9212 - mDice: 0.4800 - val_loss: 3087.6330 - val_acc: 0.9386 - val_mDice: 0.5071

Epoch 00010: val_mDice improved from 0.48524 to 0.50711, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 11s - loss: 3557.7665 - acc: 0.9236 - mDice: 0.4944 - val_loss: 2864.8374 - val_acc: 0.9416 - val_mDice: 0.5308

Epoch 00011: val_mDice improved from 0.50711 to 0.53078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 3399.7446 - acc: 0.9257 - mDice: 0.5091 - val_loss: 2664.3233 - val_acc: 0.9452 - val_mDice: 0.5546

Epoch 00012: val_mDice improved from 0.53078 to 0.55461, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 11s - loss: 3251.3193 - acc: 0.9274 - mDice: 0.5230 - val_loss: 3075.9892 - val_acc: 0.9403 - val_mDice: 0.5109

Epoch 00013: val_mDice did not improve from 0.55461
Epoch 14/300
 - 11s - loss: 3169.9597 - acc: 0.9287 - mDice: 0.5320 - val_loss: 2953.0416 - val_acc: 0.9404 - val_mDice: 0.5312

Epoch 00014: val_mDice did not improve from 0.55461
Epoch 15/300
 - 11s - loss: 3115.8808 - acc: 0.9295 - mDice: 0.5383 - val_loss: 2750.4107 - val_acc: 0.9447 - val_mDice: 0.5463

Epoch 00015: val_mDice did not improve from 0.55461
Epoch 16/300
 - 11s - loss: 2988.8172 - acc: 0.9309 - mDice: 0.5506 - val_loss: 2719.5806 - val_acc: 0.9468 - val_mDice: 0.5531

Epoch 00016: val_mDice did not improve from 0.55461
Epoch 17/300
 - 11s - loss: 2902.1955 - acc: 0.9321 - mDice: 0.5598 - val_loss: 2476.4900 - val_acc: 0.9490 - val_mDice: 0.5814

Epoch 00017: val_mDice improved from 0.55461 to 0.58145, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 11s - loss: 2817.0420 - acc: 0.9332 - mDice: 0.5689 - val_loss: 2703.7221 - val_acc: 0.9487 - val_mDice: 0.5584

Epoch 00018: val_mDice did not improve from 0.58145
Epoch 19/300
 - 11s - loss: 2748.9969 - acc: 0.9341 - mDice: 0.5768 - val_loss: 2572.5222 - val_acc: 0.9500 - val_mDice: 0.5713

Epoch 00019: val_mDice did not improve from 0.58145
Epoch 20/300
 - 11s - loss: 2715.3370 - acc: 0.9346 - mDice: 0.5811 - val_loss: 2430.6354 - val_acc: 0.9498 - val_mDice: 0.5860

Epoch 00020: val_mDice improved from 0.58145 to 0.58603, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 11s - loss: 2634.0275 - acc: 0.9355 - mDice: 0.5894 - val_loss: 2516.0659 - val_acc: 0.9504 - val_mDice: 0.5788

Epoch 00021: val_mDice did not improve from 0.58603
Epoch 22/300
 - 11s - loss: 2591.9647 - acc: 0.9361 - mDice: 0.5947 - val_loss: 2392.9839 - val_acc: 0.9491 - val_mDice: 0.5894

Epoch 00022: val_mDice improved from 0.58603 to 0.58941, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 11s - loss: 2548.6012 - acc: 0.9366 - mDice: 0.5997 - val_loss: 2492.0886 - val_acc: 0.9500 - val_mDice: 0.5789

Epoch 00023: val_mDice did not improve from 0.58941
Epoch 24/300
 - 11s - loss: 2492.1613 - acc: 0.9373 - mDice: 0.6063 - val_loss: 2506.3650 - val_acc: 0.9512 - val_mDice: 0.5806

Epoch 00024: val_mDice did not improve from 0.58941
Epoch 25/300
 - 11s - loss: 2472.2335 - acc: 0.9377 - mDice: 0.6092 - val_loss: 2442.7826 - val_acc: 0.9504 - val_mDice: 0.5850

Epoch 00025: val_mDice did not improve from 0.58941
Epoch 26/300
 - 11s - loss: 2410.0359 - acc: 0.9384 - mDice: 0.6162 - val_loss: 2300.5199 - val_acc: 0.9512 - val_mDice: 0.6026

Epoch 00026: val_mDice improved from 0.58941 to 0.60260, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 11s - loss: 2389.2025 - acc: 0.9388 - mDice: 0.6189 - val_loss: 2516.9459 - val_acc: 0.9507 - val_mDice: 0.5814

Epoch 00027: val_mDice did not improve from 0.60260
Epoch 28/300
 - 11s - loss: 2374.1743 - acc: 0.9392 - mDice: 0.6213 - val_loss: 2511.3860 - val_acc: 0.9508 - val_mDice: 0.5785

Epoch 00028: val_mDice did not improve from 0.60260
Epoch 29/300
 - 12s - loss: 2322.3896 - acc: 0.9398 - mDice: 0.6272 - val_loss: 2414.5818 - val_acc: 0.9518 - val_mDice: 0.5951

Epoch 00029: val_mDice did not improve from 0.60260
Epoch 30/300
 - 11s - loss: 2280.4703 - acc: 0.9403 - mDice: 0.6319 - val_loss: 2210.8236 - val_acc: 0.9515 - val_mDice: 0.6112

Epoch 00030: val_mDice improved from 0.60260 to 0.61120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 31/300
 - 11s - loss: 2279.3495 - acc: 0.9404 - mDice: 0.6322 - val_loss: 2362.8287 - val_acc: 0.9507 - val_mDice: 0.5942

Epoch 00031: val_mDice did not improve from 0.61120
Epoch 32/300
 - 11s - loss: 2246.5106 - acc: 0.9410 - mDice: 0.6363 - val_loss: 2530.7707 - val_acc: 0.9517 - val_mDice: 0.5831

Epoch 00032: val_mDice did not improve from 0.61120
Epoch 33/300
 - 11s - loss: 2229.6901 - acc: 0.9411 - mDice: 0.6390 - val_loss: 2455.3121 - val_acc: 0.9498 - val_mDice: 0.5857

Epoch 00033: val_mDice did not improve from 0.61120
Epoch 34/300
 - 11s - loss: 2202.1467 - acc: 0.9414 - mDice: 0.6422 - val_loss: 2331.1099 - val_acc: 0.9517 - val_mDice: 0.6021

Epoch 00034: val_mDice did not improve from 0.61120
Epoch 35/300
 - 12s - loss: 2177.3028 - acc: 0.9420 - mDice: 0.6453 - val_loss: 2444.8965 - val_acc: 0.9506 - val_mDice: 0.5858

Epoch 00035: val_mDice did not improve from 0.61120
Epoch 36/300
 - 11s - loss: 2150.7841 - acc: 0.9422 - mDice: 0.6482 - val_loss: 2454.9842 - val_acc: 0.9517 - val_mDice: 0.5864

Epoch 00036: val_mDice did not improve from 0.61120
Epoch 37/300
 - 12s - loss: 2103.6328 - acc: 0.9427 - mDice: 0.6542 - val_loss: 2251.0844 - val_acc: 0.9511 - val_mDice: 0.6075

Epoch 00037: val_mDice did not improve from 0.61120
Epoch 38/300
 - 11s - loss: 2165.1363 - acc: 0.9422 - mDice: 0.6471 - val_loss: 2331.4292 - val_acc: 0.9501 - val_mDice: 0.5962

Epoch 00038: val_mDice did not improve from 0.61120
Epoch 39/300
 - 12s - loss: 2092.9946 - acc: 0.9431 - mDice: 0.6556 - val_loss: 2445.4783 - val_acc: 0.9515 - val_mDice: 0.5888

Epoch 00039: val_mDice did not improve from 0.61120
Epoch 40/300
 - 11s - loss: 2076.1177 - acc: 0.9433 - mDice: 0.6580 - val_loss: 2584.3701 - val_acc: 0.9531 - val_mDice: 0.5800

Epoch 00040: val_mDice did not improve from 0.61120
Epoch 41/300
 - 11s - loss: 2060.3301 - acc: 0.9437 - mDice: 0.6600 - val_loss: 2260.2713 - val_acc: 0.9501 - val_mDice: 0.6063

Epoch 00041: val_mDice did not improve from 0.61120
Epoch 42/300
 - 12s - loss: 2030.1134 - acc: 0.9438 - mDice: 0.6637 - val_loss: 2222.2073 - val_acc: 0.9522 - val_mDice: 0.6119

Epoch 00042: val_mDice improved from 0.61120 to 0.61187, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 11s - loss: 2016.9310 - acc: 0.9441 - mDice: 0.6657 - val_loss: 2215.5547 - val_acc: 0.9513 - val_mDice: 0.6123

Epoch 00043: val_mDice improved from 0.61187 to 0.61232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 44/300
 - 11s - loss: 1992.9591 - acc: 0.9445 - mDice: 0.6688 - val_loss: 2340.0417 - val_acc: 0.9518 - val_mDice: 0.5979

Epoch 00044: val_mDice did not improve from 0.61232
Epoch 45/300
 - 11s - loss: 1967.4450 - acc: 0.9448 - mDice: 0.6717 - val_loss: 2650.7930 - val_acc: 0.9511 - val_mDice: 0.5711

Epoch 00045: val_mDice did not improve from 0.61232
Epoch 46/300
 - 11s - loss: 1954.7236 - acc: 0.9449 - mDice: 0.6734 - val_loss: 2372.8085 - val_acc: 0.9514 - val_mDice: 0.5947

Epoch 00046: val_mDice did not improve from 0.61232
Epoch 47/300
 - 11s - loss: 1940.1272 - acc: 0.9452 - mDice: 0.6755 - val_loss: 2377.6829 - val_acc: 0.9502 - val_mDice: 0.5923

Epoch 00047: val_mDice did not improve from 0.61232
Epoch 48/300
 - 12s - loss: 1934.7556 - acc: 0.9451 - mDice: 0.6765 - val_loss: 2448.4969 - val_acc: 0.9525 - val_mDice: 0.5937

Epoch 00048: val_mDice did not improve from 0.61232
Epoch 49/300
 - 11s - loss: 1907.3007 - acc: 0.9455 - mDice: 0.6798 - val_loss: 2553.5554 - val_acc: 0.9514 - val_mDice: 0.5823

Epoch 00049: val_mDice did not improve from 0.61232
Epoch 50/300
 - 11s - loss: 1892.1435 - acc: 0.9458 - mDice: 0.6817 - val_loss: 2335.7125 - val_acc: 0.9520 - val_mDice: 0.5992

Epoch 00050: val_mDice did not improve from 0.61232
Epoch 51/300
 - 11s - loss: 1895.4963 - acc: 0.9457 - mDice: 0.6815 - val_loss: 2278.0056 - val_acc: 0.9516 - val_mDice: 0.6047

Epoch 00051: val_mDice did not improve from 0.61232
Epoch 52/300
 - 12s - loss: 1872.8019 - acc: 0.9460 - mDice: 0.6845 - val_loss: 2376.8845 - val_acc: 0.9528 - val_mDice: 0.5978

Epoch 00052: val_mDice did not improve from 0.61232
Epoch 53/300
 - 11s - loss: 1866.1856 - acc: 0.9462 - mDice: 0.6854 - val_loss: 2396.0938 - val_acc: 0.9526 - val_mDice: 0.5913

Epoch 00053: val_mDice did not improve from 0.61232
Epoch 54/300
 - 11s - loss: 1849.1329 - acc: 0.9463 - mDice: 0.6877 - val_loss: 2249.9990 - val_acc: 0.9534 - val_mDice: 0.6079

Epoch 00054: val_mDice did not improve from 0.61232
Epoch 55/300
 - 16s - loss: 1841.9164 - acc: 0.9464 - mDice: 0.6887 - val_loss: 2405.8876 - val_acc: 0.9517 - val_mDice: 0.5921

Epoch 00055: val_mDice did not improve from 0.61232
Epoch 56/300
 - 15s - loss: 1859.0134 - acc: 0.9463 - mDice: 0.6867 - val_loss: 2365.4922 - val_acc: 0.9503 - val_mDice: 0.5930

Epoch 00056: val_mDice did not improve from 0.61232
Epoch 57/300
 - 16s - loss: 1821.2913 - acc: 0.9468 - mDice: 0.6914 - val_loss: 2254.1443 - val_acc: 0.9537 - val_mDice: 0.6116

Epoch 00057: val_mDice did not improve from 0.61232
Epoch 58/300
 - 17s - loss: 1801.3088 - acc: 0.9470 - mDice: 0.6942 - val_loss: 2340.8263 - val_acc: 0.9519 - val_mDice: 0.5966

Epoch 00058: val_mDice did not improve from 0.61232
Epoch 59/300
 - 15s - loss: 1791.6363 - acc: 0.9471 - mDice: 0.6954 - val_loss: 2450.3300 - val_acc: 0.9512 - val_mDice: 0.5854

Epoch 00059: val_mDice did not improve from 0.61232
Epoch 60/300
 - 16s - loss: 1787.2128 - acc: 0.9472 - mDice: 0.6960 - val_loss: 2439.5242 - val_acc: 0.9524 - val_mDice: 0.5869

Epoch 00060: val_mDice did not improve from 0.61232
Epoch 61/300
 - 17s - loss: 1772.9230 - acc: 0.9474 - mDice: 0.6980 - val_loss: 2327.1178 - val_acc: 0.9522 - val_mDice: 0.6012

Epoch 00061: val_mDice did not improve from 0.61232
Epoch 62/300
 - 16s - loss: 1758.2861 - acc: 0.9477 - mDice: 0.7000 - val_loss: 2409.6023 - val_acc: 0.9522 - val_mDice: 0.5897

Epoch 00062: val_mDice did not improve from 0.61232
Epoch 63/300
 - 17s - loss: 1765.2212 - acc: 0.9476 - mDice: 0.6993 - val_loss: 2423.5370 - val_acc: 0.9525 - val_mDice: 0.5921

Epoch 00063: val_mDice did not improve from 0.61232
Epoch 64/300
 - 16s - loss: 1745.4344 - acc: 0.9478 - mDice: 0.7019 - val_loss: 2445.9418 - val_acc: 0.9537 - val_mDice: 0.5897

Epoch 00064: val_mDice did not improve from 0.61232
Epoch 65/300
 - 15s - loss: 1748.4085 - acc: 0.9478 - mDice: 0.7013 - val_loss: 2316.2890 - val_acc: 0.9527 - val_mDice: 0.6034

Epoch 00065: val_mDice did not improve from 0.61232
Epoch 66/300
 - 15s - loss: 1738.0352 - acc: 0.9478 - mDice: 0.7027 - val_loss: 2300.3605 - val_acc: 0.9528 - val_mDice: 0.6042

Epoch 00066: val_mDice did not improve from 0.61232
Epoch 67/300
 - 16s - loss: 1718.3518 - acc: 0.9482 - mDice: 0.7055 - val_loss: 2331.5786 - val_acc: 0.9527 - val_mDice: 0.5985

Epoch 00067: val_mDice did not improve from 0.61232
Epoch 68/300
 - 16s - loss: 1728.8829 - acc: 0.9480 - mDice: 0.7041 - val_loss: 2447.3230 - val_acc: 0.9527 - val_mDice: 0.5922

Epoch 00068: val_mDice did not improve from 0.61232
Epoch 69/300
 - 15s - loss: 1716.3285 - acc: 0.9482 - mDice: 0.7059 - val_loss: 2420.6820 - val_acc: 0.9522 - val_mDice: 0.5927

Epoch 00069: val_mDice did not improve from 0.61232
Epoch 70/300
 - 17s - loss: 1709.7516 - acc: 0.9484 - mDice: 0.7068 - val_loss: 2326.5226 - val_acc: 0.9524 - val_mDice: 0.6011

Epoch 00070: val_mDice did not improve from 0.61232
Epoch 71/300
 - 17s - loss: 1709.2893 - acc: 0.9484 - mDice: 0.7071 - val_loss: 2252.9288 - val_acc: 0.9526 - val_mDice: 0.6076

Epoch 00071: val_mDice did not improve from 0.61232
Epoch 72/300
 - 16s - loss: 1694.6136 - acc: 0.9486 - mDice: 0.7089 - val_loss: 2279.0050 - val_acc: 0.9528 - val_mDice: 0.6050

Epoch 00072: val_mDice did not improve from 0.61232
Epoch 73/300
 - 15s - loss: 1679.2693 - acc: 0.9487 - mDice: 0.7110 - val_loss: 2327.7290 - val_acc: 0.9536 - val_mDice: 0.6041

Epoch 00073: val_mDice did not improve from 0.61232
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
{'val_loss': [16431.024954172484, 5529.003398873952, 4412.451717440643, 4090.6350438634777, 4247.409708886174, 4260.890731385301, 3884.406188623865, 3779.569589625524, 3317.4753758947277, 3087.6330252706007, 2864.837415982891, 2664.3232912884077, 3075.9892359898745, 2953.0416116554643, 2750.4106922682436, 2719.580555494937, 2476.4899615921786, 2703.722143418296, 2572.5222481668993, 2430.6353889337465, 2516.0658606843576, 2392.9838935383204, 2492.0886421416726, 2506.3650175126572, 2442.7826466480446, 2300.5199499716305, 2516.9459248974335, 2511.3860149703214, 2414.5818252989698, 2210.823561343401, 2362.828730577863, 2530.7706783017634, 2455.3121099205655, 2331.109941024354, 2444.896483011086, 2454.9842099663933, 2251.0844030966305, 2331.4292374083448, 2445.478297398743, 2584.3700953648745, 2260.2713452557614, 2222.2073476780724, 2215.554667041288, 2340.0416880346543, 2650.7929728417425, 2372.8085200986384, 2377.682870875524, 2448.496856177985, 2553.555383096194, 2335.7125278238477, 2278.0056220539454, 2376.884507845234, 2396.0938441100734, 2249.998956605709, 2405.8875507376047, 2365.4921943195704, 2254.1443062041726, 2340.8262605294167, 2450.329992198411, 2439.5241508270774, 2327.1178217200595, 2409.6023372032123, 2423.536997534043, 2445.941827699459, 2316.289022946491, 2300.3604852260823, 2331.578601006023, 2447.323034872556, 2420.6819843313547, 2326.522578234113, 2252.9287818610337, 2279.005041026536, 2327.729044823673], 'val_acc': [0.8989785516728236, 0.9088521999353804, 0.9159945023126442, 0.9216079602028404, 0.9237421864237865, 0.9243930038793127, 0.9262255939691426, 0.9319919284495561, 0.9341509338863735, 0.9386301456882967, 0.9416011155650602, 0.9452104818221577, 0.940307752380158, 0.9404461973206291, 0.9446795316381827, 0.9468364658968409, 0.9489665414367974, 0.9487041714471146, 0.950036790450858, 0.9497702481360409, 0.9504396512521712, 0.9490512582842864, 0.9499520569540268, 0.9512288833463658, 0.9504416984552778, 0.9511710495256179, 0.9506999570564185, 0.950766069929027, 0.9517846503737253, 0.9514809240841998, 0.9506503786454653, 0.9516834147149624, 0.9497764410253343, 0.9516999308623415, 0.9506007999015254, 0.951689611600098, 0.9511007959616251, 0.9501359715808038, 0.9514871316249144, 0.9530966175335079, 0.9501297300754312, 0.9521875278243805, 0.9513362915822248, 0.9518197621713137, 0.9511317870470398, 0.9513631816016895, 0.9502041253297688, 0.9525056837657311, 0.9514251397974665, 0.9519623434743402, 0.9516007687126458, 0.9528238740047263, 0.9525738604907883, 0.9533548411710302, 0.9517123236336522, 0.9502908930432197, 0.9536957454415007, 0.9518982927892461, 0.9511917240126839, 0.9523817320775719, 0.9521937443557398, 0.9522185265684927, 0.9524540335106451, 0.9536502784190897, 0.9526916469275618, 0.952801143323909, 0.9526751201246038, 0.9526585873278826, 0.9522474607941824, 0.9523920756478549, 0.9526275912476652, 0.9528424743167515, 0.953590389403551], 'val_mDice': [0.22003160342157885, 0.3424508438430019, 0.40032639799837294, 0.4255830382501613, 0.4166969295653551, 0.4149560891716174, 0.4405061466067863, 0.4489614034498204, 0.48523822410146616, 0.5071118718751982, 0.5307769142715625, 0.5546079521072643, 0.5109496909146868, 0.5312326670358967, 0.5462920432650177, 0.5530811271853953, 0.5814464378623323, 0.5584345749636602, 0.571273819361319, 0.5860295075944016, 0.5787677385287577, 0.5894067776935726, 0.5788744291779715, 0.5805893154117648, 0.5850463486250552, 0.6025995225879733, 0.5813613657178826, 0.5785275927469051, 0.5951420198605714, 0.611200572392128, 0.5942087100204809, 0.5831120959873306, 0.5857327124259991, 0.6020533169448042, 0.585782658787413, 0.586402942015472, 0.6075134237385329, 0.5961650283642987, 0.5887508798577932, 0.5800077935170861, 0.6063284664180691, 0.6118713290997724, 0.6123181904494429, 0.597850250132257, 0.5710611033706026, 0.594748187331514, 0.5922657491108558, 0.5936805948864814, 0.582326022939309, 0.5991907346182029, 0.6046541396466047, 0.5978038494147402, 0.5912568808933876, 0.6078959124048329, 0.5921073376133456, 0.5929980268025531, 0.6116078549257203, 0.5966001459340143, 0.5853799734701658, 0.5869310997717874, 0.6011917367993787, 0.5896819157307375, 0.5920709791130194, 0.589745538860726, 0.6034210400874388, 0.6042305450865676, 0.5984861837419052, 0.5921925968964007, 0.5927136174127376, 0.601117643564107, 0.6076499117153317, 0.6050362300606413, 0.6040948795872694], 'loss': [20335.60725888411, 9107.968269537207, 6557.348801494379, 5684.693243121992, 5150.121761443562, 4747.185445753631, 4432.717337492043, 4155.79068913794, 3946.7415900129904, 3755.4496610911674, 3557.7664693002703, 3399.7445541921184, 3251.3193473394163, 3169.959678442557, 3115.880841477648, 2988.8171854629463, 2902.195536157066, 2817.0419629813086, 2748.9969059653445, 2715.3370085022793, 2634.0275324766467, 2591.964700172283, 2548.601233300414, 2492.16133009557, 2472.2335211061636, 2410.035879297705, 2389.202453802759, 2374.174319431248, 2322.3896309124552, 2280.470303040731, 2279.3495004617675, 2246.5106348366294, 2229.690078136169, 2202.146675661261, 2177.3027945358986, 2150.7841255566527, 2103.632819361095, 2165.136274813229, 2092.9945671829896, 2076.117663694554, 2060.3301312120566, 2030.113414017504, 2016.9309815543454, 1992.959106458609, 1967.445023137314, 1954.7236072030646, 1940.1271944400771, 1934.7556430776553, 1907.3007067519395, 1892.1434740962288, 1895.4962985656482, 1872.8019133638916, 1866.1855962921686, 1849.1329433926699, 1841.9164354482136, 1859.0134006091164, 1821.2913314880002, 1801.308813132178, 1791.63629050333, 1787.2127596126597, 1772.9229753547345, 1758.286067080286, 1765.2212455238005, 1745.434413531164, 1748.4085449763913, 1738.0352427250589, 1718.3518342246198, 1728.8829283208656, 1716.3285193899594, 1709.7516014606474, 1709.2892995534862, 1694.613624391171, 1679.2692604129347], 'acc': [0.8617572263658232, 0.878295429991933, 0.8899184837462589, 0.8981860815735335, 0.9034940363255651, 0.9081287697167784, 0.9119757231196887, 0.9156598274558856, 0.9186351468546069, 0.9211596305233598, 0.9236299329402368, 0.9256697482750064, 0.9274419805990716, 0.9286939298091816, 0.9294662450459857, 0.9309492387398156, 0.9320889609512255, 0.9331642090673703, 0.9340824897684931, 0.9346413014566293, 0.9354617767529799, 0.936075071436434, 0.9366280229501582, 0.9373390668975029, 0.9376859915366224, 0.9383889538654476, 0.9388277620916292, 0.9392222382554717, 0.9397677977284694, 0.9403090874202552, 0.9403977533433635, 0.9409623445557402, 0.941140538291418, 0.9414242543132014, 0.9419580328036651, 0.9421966920055587, 0.9427124615990968, 0.9422231758123233, 0.9430540238880565, 0.9433153029536313, 0.943688147556002, 0.9438277502431569, 0.944138959357762, 0.9444875327611462, 0.9447906653765895, 0.9448859776964141, 0.945242807529609, 0.94511819011109, 0.9455153039776742, 0.9457938843715893, 0.9457161168693476, 0.946004184231468, 0.9461658223217709, 0.9463147116242382, 0.9464387045785185, 0.946278255156303, 0.9467721899917498, 0.9470217055396885, 0.9471279128036314, 0.947210775722275, 0.9474139287804059, 0.9477380660324144, 0.9476476524443767, 0.9477591762569474, 0.9477781280992883, 0.9478469517364604, 0.9482283368491639, 0.9479848831887144, 0.9481868854594071, 0.9483829044963298, 0.9484032881713745, 0.9486399124432322, 0.948700274301701], 'mDice': [0.1328939734732142, 0.2224019592746879, 0.2972618932769057, 0.3422097818477891, 0.3740721132285091, 0.4005160705176231, 0.4227522754680876, 0.4436387397301404, 0.46191635911783213, 0.47998363779791103, 0.4943625380820058, 0.5090996185540309, 0.5230256377576152, 0.5319984935284517, 0.5383390554980018, 0.5506013764527932, 0.5597550035347562, 0.5688860252605895, 0.5767611950468727, 0.5811228228513923, 0.5893710331228341, 0.5946720346283351, 0.5996795604934192, 0.6062944042456059, 0.6092215271746889, 0.6161919789281548, 0.6189225641485588, 0.6213047958252691, 0.6272348768018597, 0.6319446661530623, 0.6322203260752041, 0.6362679945566213, 0.6390195315092336, 0.6422305346690949, 0.6452887483615968, 0.648242674240859, 0.6542246671168609, 0.6470941781582159, 0.6555670531550093, 0.6579817013831175, 0.6600184332966694, 0.6636585836758262, 0.6656691844242213, 0.6687930043528889, 0.6716567040541536, 0.6734421372212367, 0.6754916632274781, 0.6765049670647773, 0.6798402177801216, 0.6817353207634839, 0.6814815275426667, 0.6845499118891983, 0.6854148599019946, 0.6876579193525874, 0.6886997136030378, 0.6866880852856295, 0.6914202682878852, 0.6941548251526579, 0.6954473965529373, 0.6960483428913942, 0.697976690522012, 0.6999952106147048, 0.6992953832577623, 0.7018710206480926, 0.701317315459102, 0.7027204555270784, 0.705520637206383, 0.7040832391992048, 0.7058755134641523, 0.7068470658887726, 0.7070641153927794, 0.7089022037984369, 0.7109688347795223]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.48s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:06<00:03,  3.20s/it]predicting test subjects: 100%|██████████| 3/3 [00:07<00:00,  2.83s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:16,  2.17s/it]predicting train subjects:   1%|          | 2/285 [00:05<11:16,  2.39s/it]predicting train subjects:   1%|          | 3/285 [00:07<10:46,  2.29s/it]predicting train subjects:   1%|▏         | 4/285 [00:10<11:46,  2.51s/it]predicting train subjects:   2%|▏         | 5/285 [00:12<11:12,  2.40s/it]predicting train subjects:   2%|▏         | 6/285 [00:14<11:18,  2.43s/it]predicting train subjects:   2%|▏         | 7/285 [00:17<11:53,  2.57s/it]predicting train subjects:   3%|▎         | 8/285 [00:20<11:31,  2.50s/it]predicting train subjects:   3%|▎         | 9/285 [00:22<11:12,  2.44s/it]predicting train subjects:   4%|▎         | 10/285 [00:25<11:33,  2.52s/it]predicting train subjects:   4%|▍         | 11/285 [00:28<12:25,  2.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:31<12:53,  2.84s/it]predicting train subjects:   5%|▍         | 13/285 [00:34<13:48,  3.05s/it]predicting train subjects:   5%|▍         | 14/285 [00:38<13:57,  3.09s/it]predicting train subjects:   5%|▌         | 15/285 [00:40<13:35,  3.02s/it]predicting train subjects:   6%|▌         | 16/285 [00:44<13:42,  3.06s/it]predicting train subjects:   6%|▌         | 17/285 [00:47<13:32,  3.03s/it]predicting train subjects:   6%|▋         | 18/285 [00:49<13:06,  2.95s/it]predicting train subjects:   7%|▋         | 19/285 [00:52<12:39,  2.86s/it]predicting train subjects:   7%|▋         | 20/285 [00:55<12:38,  2.86s/it]predicting train subjects:   7%|▋         | 21/285 [00:58<13:33,  3.08s/it]predicting train subjects:   8%|▊         | 22/285 [01:01<12:29,  2.85s/it]predicting train subjects:   8%|▊         | 23/285 [01:04<12:28,  2.86s/it]predicting train subjects:   8%|▊         | 24/285 [01:06<12:29,  2.87s/it]predicting train subjects:   9%|▉         | 25/285 [01:09<11:50,  2.73s/it]predicting train subjects:   9%|▉         | 26/285 [01:11<11:05,  2.57s/it]predicting train subjects:   9%|▉         | 27/285 [01:13<10:34,  2.46s/it]predicting train subjects:  10%|▉         | 28/285 [01:15<10:03,  2.35s/it]predicting train subjects:  10%|█         | 29/285 [01:17<09:33,  2.24s/it]predicting train subjects:  11%|█         | 30/285 [01:19<09:03,  2.13s/it]predicting train subjects:  11%|█         | 31/285 [01:21<08:41,  2.05s/it]predicting train subjects:  11%|█         | 32/285 [01:23<08:28,  2.01s/it]predicting train subjects:  12%|█▏        | 33/285 [01:25<08:34,  2.04s/it]predicting train subjects:  12%|█▏        | 34/285 [01:27<08:27,  2.02s/it]predicting train subjects:  12%|█▏        | 35/285 [01:29<08:32,  2.05s/it]predicting train subjects:  13%|█▎        | 36/285 [01:31<08:23,  2.02s/it]predicting train subjects:  13%|█▎        | 37/285 [01:33<08:21,  2.02s/it]predicting train subjects:  13%|█▎        | 38/285 [01:35<08:14,  2.00s/it]predicting train subjects:  14%|█▎        | 39/285 [01:37<08:16,  2.02s/it]predicting train subjects:  14%|█▍        | 40/285 [01:39<08:06,  1.98s/it]predicting train subjects:  14%|█▍        | 41/285 [01:41<07:57,  1.96s/it]predicting train subjects:  15%|█▍        | 42/285 [01:43<07:53,  1.95s/it]predicting train subjects:  15%|█▌        | 43/285 [01:45<07:57,  1.97s/it]predicting train subjects:  15%|█▌        | 44/285 [01:47<07:49,  1.95s/it]predicting train subjects:  16%|█▌        | 45/285 [01:49<07:54,  1.98s/it]predicting train subjects:  16%|█▌        | 46/285 [01:51<07:31,  1.89s/it]predicting train subjects:  16%|█▋        | 47/285 [01:52<07:28,  1.89s/it]predicting train subjects:  17%|█▋        | 48/285 [01:54<07:14,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:56<07:08,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:58<07:00,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:59<06:48,  1.74s/it]predicting train subjects:  18%|█▊        | 52/285 [02:01<06:41,  1.72s/it]predicting train subjects:  19%|█▊        | 53/285 [02:03<06:31,  1.69s/it]predicting train subjects:  19%|█▉        | 54/285 [02:04<06:28,  1.68s/it]predicting train subjects:  19%|█▉        | 55/285 [02:06<06:27,  1.68s/it]predicting train subjects:  20%|█▉        | 56/285 [02:08<06:18,  1.65s/it]predicting train subjects:  20%|██        | 57/285 [02:09<06:15,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [02:11<06:14,  1.65s/it]predicting train subjects:  21%|██        | 59/285 [02:12<06:07,  1.63s/it]predicting train subjects:  21%|██        | 60/285 [02:14<06:04,  1.62s/it]predicting train subjects:  21%|██▏       | 61/285 [02:16<06:03,  1.62s/it]predicting train subjects:  22%|██▏       | 62/285 [02:17<06:08,  1.65s/it]predicting train subjects:  22%|██▏       | 63/285 [02:19<06:07,  1.66s/it]predicting train subjects:  22%|██▏       | 64/285 [02:21<06:11,  1.68s/it]predicting train subjects:  23%|██▎       | 65/285 [02:23<06:22,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [02:25<06:30,  1.78s/it]predicting train subjects:  24%|██▎       | 67/285 [02:26<06:29,  1.79s/it]predicting train subjects:  24%|██▍       | 68/285 [02:28<06:33,  1.81s/it]predicting train subjects:  24%|██▍       | 69/285 [02:30<06:24,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:32<06:17,  1.76s/it]predicting train subjects:  25%|██▍       | 71/285 [02:33<06:14,  1.75s/it]predicting train subjects:  25%|██▌       | 72/285 [02:35<06:08,  1.73s/it]predicting train subjects:  26%|██▌       | 73/285 [02:37<06:02,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:38<06:07,  1.74s/it]predicting train subjects:  26%|██▋       | 75/285 [02:40<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 76/285 [02:42<06:01,  1.73s/it]predicting train subjects:  27%|██▋       | 77/285 [02:44<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:45<05:49,  1.69s/it]predicting train subjects:  28%|██▊       | 79/285 [02:47<05:47,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:49<05:45,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:50<05:43,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:52<05:47,  1.71s/it]predicting train subjects:  29%|██▉       | 83/285 [02:54<05:48,  1.73s/it]predicting train subjects:  29%|██▉       | 84/285 [02:56<05:47,  1.73s/it]predicting train subjects:  30%|██▉       | 85/285 [02:57<05:49,  1.75s/it]predicting train subjects:  30%|███       | 86/285 [02:59<05:55,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [03:01<06:00,  1.82s/it]predicting train subjects:  31%|███       | 88/285 [03:03<05:59,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [03:05<05:56,  1.82s/it]predicting train subjects:  32%|███▏      | 90/285 [03:07<06:00,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [03:09<05:58,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [03:10<05:57,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [03:12<05:56,  1.86s/it]predicting train subjects:  33%|███▎      | 94/285 [03:14<05:50,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [03:16<05:42,  1.80s/it]predicting train subjects:  34%|███▎      | 96/285 [03:18<05:38,  1.79s/it]predicting train subjects:  34%|███▍      | 97/285 [03:19<05:42,  1.82s/it]predicting train subjects:  34%|███▍      | 98/285 [03:21<05:43,  1.83s/it]predicting train subjects:  35%|███▍      | 99/285 [03:23<05:43,  1.85s/it]predicting train subjects:  35%|███▌      | 100/285 [03:25<05:42,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [03:27<05:40,  1.85s/it]predicting train subjects:  36%|███▌      | 102/285 [03:29<05:38,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:31<05:38,  1.86s/it]predicting train subjects:  36%|███▋      | 104/285 [03:32<05:36,  1.86s/it]predicting train subjects:  37%|███▋      | 105/285 [03:34<05:30,  1.84s/it]predicting train subjects:  37%|███▋      | 106/285 [03:36<05:24,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:38<05:22,  1.81s/it]predicting train subjects:  38%|███▊      | 108/285 [03:40<05:19,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:41<05:17,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:43<05:12,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:45<05:14,  1.80s/it]predicting train subjects:  39%|███▉      | 112/285 [03:47<05:11,  1.80s/it]predicting train subjects:  40%|███▉      | 113/285 [03:49<05:09,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:50<05:07,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:52<05:04,  1.79s/it]predicting train subjects:  41%|████      | 116/285 [03:54<05:01,  1.78s/it]predicting train subjects:  41%|████      | 117/285 [03:56<05:05,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:58<05:06,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [04:00<05:05,  1.84s/it]predicting train subjects:  42%|████▏     | 120/285 [04:01<05:01,  1.83s/it]predicting train subjects:  42%|████▏     | 121/285 [04:03<04:48,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [04:04<04:33,  1.68s/it]predicting train subjects:  43%|████▎     | 123/285 [04:06<04:17,  1.59s/it]predicting train subjects:  44%|████▎     | 124/285 [04:07<04:19,  1.61s/it]predicting train subjects:  44%|████▍     | 125/285 [04:09<04:22,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [04:11<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [04:13<04:21,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [04:14<04:19,  1.65s/it]predicting train subjects:  45%|████▌     | 129/285 [04:16<04:18,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [04:17<04:17,  1.66s/it]predicting train subjects:  46%|████▌     | 131/285 [04:19<04:13,  1.65s/it]predicting train subjects:  46%|████▋     | 132/285 [04:21<04:11,  1.65s/it]predicting train subjects:  47%|████▋     | 133/285 [04:22<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:24<04:09,  1.65s/it]predicting train subjects:  47%|████▋     | 135/285 [04:26<04:07,  1.65s/it]predicting train subjects:  48%|████▊     | 136/285 [04:27<04:02,  1.63s/it]predicting train subjects:  48%|████▊     | 137/285 [04:29<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [04:30<03:56,  1.61s/it]predicting train subjects:  49%|████▉     | 139/285 [04:32<03:52,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [04:34<03:51,  1.60s/it]predicting train subjects:  49%|████▉     | 141/285 [04:35<03:48,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:37<03:41,  1.55s/it]predicting train subjects:  50%|█████     | 143/285 [04:38<03:36,  1.53s/it]predicting train subjects:  51%|█████     | 144/285 [04:40<03:30,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:41<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:43<03:26,  1.49s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:44<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:45<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:47<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:48<03:20,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:50<03:16,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:51<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:53<03:13,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:54<03:14,  1.49s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:56<03:11,  1.47s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:57<03:08,  1.46s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:59<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:00<03:09,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:02<03:11,  1.52s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:03<03:09,  1.51s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:05<03:04,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:06<02:59,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:08<02:57,  1.46s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:09<02:56,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:11<02:59,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:12<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:14<02:55,  1.49s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:15<02:51,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:17<02:51,  1.48s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:18<02:50,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [05:20<02:50,  1.49s/it]predicting train subjects:  60%|██████    | 172/285 [05:21<02:50,  1.51s/it]predicting train subjects:  61%|██████    | 173/285 [05:23<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:24<02:46,  1.50s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:25<02:41,  1.47s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:27<02:39,  1.47s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:28<02:37,  1.45s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:30<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:31<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:33<02:31,  1.45s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:34<02:30,  1.45s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:36<02:30,  1.46s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:37<02:31,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:39<02:30,  1.49s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:40<02:27,  1.48s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:42<02:25,  1.47s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:43<02:25,  1.48s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:45<02:24,  1.49s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:46<02:24,  1.50s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:48<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:49<02:19,  1.48s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:51<02:18,  1.48s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:52<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:53<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:55<02:12,  1.48s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:57<02:16,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:59<02:24,  1.64s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:00<02:26,  1.68s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:02<02:26,  1.70s/it]predicting train subjects:  70%|███████   | 200/285 [06:04<02:24,  1.71s/it]predicting train subjects:  71%|███████   | 201/285 [06:05<02:23,  1.71s/it]predicting train subjects:  71%|███████   | 202/285 [06:07<02:19,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [06:09<02:15,  1.66s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:10<02:13,  1.65s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:12<02:15,  1.69s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:14<02:13,  1.70s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:16<02:12,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:17<02:12,  1.72s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:19<02:13,  1.76s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:21<02:12,  1.76s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:23<02:08,  1.73s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:24<02:06,  1.73s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:26<02:06,  1.75s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:28<01:57,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:29<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:30<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:32<01:43,  1.52s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:33<01:40,  1.50s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:35<01:38,  1.49s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:36<01:34,  1.45s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:38<01:32,  1.45s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:39<01:30,  1.44s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:41<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:42<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:44<01:27,  1.47s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:45<01:27,  1.48s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:47<01:26,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:48<01:23,  1.46s/it]predicting train subjects:  80%|████████  | 229/285 [06:49<01:22,  1.47s/it]predicting train subjects:  81%|████████  | 230/285 [06:51<01:20,  1.46s/it]predicting train subjects:  81%|████████  | 231/285 [06:52<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:54<01:24,  1.59s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:56<01:26,  1.66s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:58<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:00<01:26,  1.73s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:01<01:25,  1.75s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:03<01:24,  1.76s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:05<01:23,  1.79s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:07<01:23,  1.82s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:09<01:23,  1.86s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:11<01:21,  1.85s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:13<01:20,  1.86s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:14<01:16,  1.83s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:16<01:16,  1.85s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:18<01:13,  1.85s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:20<01:10,  1.82s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:22<01:09,  1.82s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:24<01:07,  1.82s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:25<01:06,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:27<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:28<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:30<00:52,  1.58s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:31<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:33<00:46,  1.51s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:34<00:45,  1.50s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:36<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [07:37<00:41,  1.48s/it]predicting train subjects:  91%|█████████ | 258/285 [07:39<00:40,  1.49s/it]predicting train subjects:  91%|█████████ | 259/285 [07:40<00:37,  1.46s/it]predicting train subjects:  91%|█████████ | 260/285 [07:41<00:35,  1.43s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:43<00:34,  1.43s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:44<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:46<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:47<00:30,  1.44s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:49<00:29,  1.45s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:50<00:27,  1.45s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:51<00:25,  1.42s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:53<00:26,  1.57s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:55<00:26,  1.67s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:57<00:25,  1.73s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:59<00:25,  1.79s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:01<00:24,  1.85s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:03<00:22,  1.90s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:05<00:21,  1.92s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:07<00:19,  1.90s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:09<00:17,  1.90s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:11<00:15,  1.90s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:13<00:13,  1.91s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:14<00:11,  1.89s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:16<00:09,  1.88s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:18<00:07,  1.89s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:20<00:05,  1.88s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:22<00:03,  1.87s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:24<00:01,  1.86s/it]predicting train subjects: 100%|██████████| 285/285 [08:26<00:00,  1.85s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:27,  1.15s/it]Loading train:   1%|          | 2/285 [00:02<06:01,  1.28s/it]Loading train:   1%|          | 3/285 [00:04<06:00,  1.28s/it]Loading train:   1%|▏         | 4/285 [00:05<06:33,  1.40s/it]Loading train:   2%|▏         | 5/285 [00:06<06:15,  1.34s/it]Loading train:   2%|▏         | 6/285 [00:08<06:29,  1.40s/it]Loading train:   2%|▏         | 7/285 [00:10<06:58,  1.50s/it]Loading train:   3%|▎         | 8/285 [00:11<07:05,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:13<06:50,  1.49s/it]Loading train:   4%|▎         | 10/285 [00:14<06:16,  1.37s/it]Loading train:   4%|▍         | 11/285 [00:15<06:00,  1.32s/it]Loading train:   4%|▍         | 12/285 [00:16<05:39,  1.24s/it]Loading train:   5%|▍         | 13/285 [00:17<05:16,  1.16s/it]Loading train:   5%|▍         | 14/285 [00:18<05:09,  1.14s/it]Loading train:   5%|▌         | 15/285 [00:19<04:53,  1.09s/it]Loading train:   6%|▌         | 16/285 [00:20<04:45,  1.06s/it]Loading train:   6%|▌         | 17/285 [00:21<04:45,  1.07s/it]Loading train:   6%|▋         | 18/285 [00:22<04:43,  1.06s/it]Loading train:   7%|▋         | 19/285 [00:23<04:48,  1.08s/it]Loading train:   7%|▋         | 20/285 [00:25<04:59,  1.13s/it]Loading train:   7%|▋         | 21/285 [00:26<04:48,  1.09s/it]Loading train:   8%|▊         | 22/285 [00:27<04:47,  1.09s/it]Loading train:   8%|▊         | 23/285 [00:28<04:38,  1.06s/it]Loading train:   8%|▊         | 24/285 [00:29<04:38,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:30<04:33,  1.05s/it]Loading train:   9%|▉         | 26/285 [00:31<04:25,  1.03s/it]Loading train:   9%|▉         | 27/285 [00:32<04:28,  1.04s/it]Loading train:  10%|▉         | 28/285 [00:33<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:34<04:33,  1.07s/it]Loading train:  11%|█         | 30/285 [00:35<04:19,  1.02s/it]Loading train:  11%|█         | 31/285 [00:36<04:23,  1.04s/it]Loading train:  11%|█         | 32/285 [00:37<04:13,  1.00s/it]Loading train:  12%|█▏        | 33/285 [00:38<04:29,  1.07s/it]Loading train:  12%|█▏        | 34/285 [00:39<04:14,  1.01s/it]Loading train:  12%|█▏        | 35/285 [00:40<04:10,  1.00s/it]Loading train:  13%|█▎        | 36/285 [00:41<04:08,  1.00it/s]Loading train:  13%|█▎        | 37/285 [00:42<04:17,  1.04s/it]Loading train:  13%|█▎        | 38/285 [00:43<04:06,  1.00it/s]Loading train:  14%|█▎        | 39/285 [00:44<04:08,  1.01s/it]Loading train:  14%|█▍        | 40/285 [00:45<04:09,  1.02s/it]Loading train:  14%|█▍        | 41/285 [00:46<03:57,  1.03it/s]Loading train:  15%|█▍        | 42/285 [00:47<03:50,  1.05it/s]Loading train:  15%|█▌        | 43/285 [00:48<03:57,  1.02it/s]Loading train:  15%|█▌        | 44/285 [00:49<03:51,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:50<03:54,  1.02it/s]Loading train:  16%|█▌        | 46/285 [00:51<03:57,  1.01it/s]Loading train:  16%|█▋        | 47/285 [00:52<03:45,  1.06it/s]Loading train:  17%|█▋        | 48/285 [00:53<03:49,  1.03it/s]Loading train:  17%|█▋        | 49/285 [00:53<03:36,  1.09it/s]Loading train:  18%|█▊        | 50/285 [00:54<03:29,  1.12it/s]Loading train:  18%|█▊        | 51/285 [00:55<03:28,  1.12it/s]Loading train:  18%|█▊        | 52/285 [00:56<03:35,  1.08it/s]Loading train:  19%|█▊        | 53/285 [00:57<03:41,  1.05it/s]Loading train:  19%|█▉        | 54/285 [00:58<03:41,  1.04it/s]Loading train:  19%|█▉        | 55/285 [00:59<03:44,  1.02it/s]Loading train:  20%|█▉        | 56/285 [01:00<03:46,  1.01it/s]Loading train:  20%|██        | 57/285 [01:01<03:35,  1.06it/s]Loading train:  20%|██        | 58/285 [01:02<03:33,  1.06it/s]Loading train:  21%|██        | 59/285 [01:03<03:35,  1.05it/s]Loading train:  21%|██        | 60/285 [01:04<03:34,  1.05it/s]Loading train:  21%|██▏       | 61/285 [01:05<03:30,  1.07it/s]Loading train:  22%|██▏       | 62/285 [01:06<03:33,  1.05it/s]Loading train:  22%|██▏       | 63/285 [01:07<03:28,  1.06it/s]Loading train:  22%|██▏       | 64/285 [01:08<04:05,  1.11s/it]Loading train:  23%|██▎       | 65/285 [01:10<04:33,  1.25s/it]Loading train:  23%|██▎       | 66/285 [01:11<04:50,  1.33s/it]Loading train:  24%|██▎       | 67/285 [01:12<04:24,  1.21s/it]Loading train:  24%|██▍       | 68/285 [01:13<04:12,  1.16s/it]Loading train:  24%|██▍       | 69/285 [01:14<03:50,  1.07s/it]Loading train:  25%|██▍       | 70/285 [01:15<03:55,  1.09s/it]Loading train:  25%|██▍       | 71/285 [01:16<03:37,  1.02s/it]Loading train:  25%|██▌       | 72/285 [01:17<03:38,  1.03s/it]Loading train:  26%|██▌       | 73/285 [01:18<03:24,  1.04it/s]Loading train:  26%|██▌       | 74/285 [01:19<03:24,  1.03it/s]Loading train:  26%|██▋       | 75/285 [01:20<03:19,  1.05it/s]Loading train:  27%|██▋       | 76/285 [01:21<03:12,  1.09it/s]Loading train:  27%|██▋       | 77/285 [01:22<03:07,  1.11it/s]Loading train:  27%|██▋       | 78/285 [01:22<03:03,  1.13it/s]Loading train:  28%|██▊       | 79/285 [01:23<02:55,  1.17it/s]Loading train:  28%|██▊       | 80/285 [01:24<02:59,  1.14it/s]Loading train:  28%|██▊       | 81/285 [01:25<03:01,  1.12it/s]Loading train:  29%|██▉       | 82/285 [01:26<03:06,  1.09it/s]Loading train:  29%|██▉       | 83/285 [01:27<02:59,  1.12it/s]Loading train:  29%|██▉       | 84/285 [01:28<02:56,  1.14it/s]Loading train:  30%|██▉       | 85/285 [01:29<02:58,  1.12it/s]Loading train:  30%|███       | 86/285 [01:30<03:06,  1.07it/s]Loading train:  31%|███       | 87/285 [01:31<03:10,  1.04it/s]Loading train:  31%|███       | 88/285 [01:32<03:13,  1.02it/s]Loading train:  31%|███       | 89/285 [01:33<03:06,  1.05it/s]Loading train:  32%|███▏      | 90/285 [01:34<03:13,  1.01it/s]Loading train:  32%|███▏      | 91/285 [01:35<03:11,  1.01it/s]Loading train:  32%|███▏      | 92/285 [01:36<03:08,  1.02it/s]Loading train:  33%|███▎      | 93/285 [01:37<03:08,  1.02it/s]Loading train:  33%|███▎      | 94/285 [01:38<03:03,  1.04it/s]Loading train:  33%|███▎      | 95/285 [01:39<03:08,  1.01it/s]Loading train:  34%|███▎      | 96/285 [01:40<03:01,  1.04it/s]Loading train:  34%|███▍      | 97/285 [01:41<03:07,  1.00it/s]Loading train:  34%|███▍      | 98/285 [01:42<03:02,  1.03it/s]Loading train:  35%|███▍      | 99/285 [01:43<03:06,  1.00s/it]Loading train:  35%|███▌      | 100/285 [01:44<03:04,  1.00it/s]Loading train:  35%|███▌      | 101/285 [01:45<03:06,  1.02s/it]Loading train:  36%|███▌      | 102/285 [01:46<03:05,  1.01s/it]Loading train:  36%|███▌      | 103/285 [01:47<03:12,  1.06s/it]Loading train:  36%|███▋      | 104/285 [01:48<03:15,  1.08s/it]Loading train:  37%|███▋      | 105/285 [01:49<03:11,  1.06s/it]Loading train:  37%|███▋      | 106/285 [01:50<03:09,  1.06s/it]Loading train:  38%|███▊      | 107/285 [01:51<03:06,  1.05s/it]Loading train:  38%|███▊      | 108/285 [01:52<03:08,  1.07s/it]Loading train:  38%|███▊      | 109/285 [01:53<03:01,  1.03s/it]Loading train:  39%|███▊      | 110/285 [01:54<02:54,  1.01it/s]Loading train:  39%|███▉      | 111/285 [01:55<02:52,  1.01it/s]Loading train:  39%|███▉      | 112/285 [01:56<02:52,  1.00it/s]Loading train:  40%|███▉      | 113/285 [01:57<02:45,  1.04it/s]Loading train:  40%|████      | 114/285 [01:58<02:48,  1.02it/s]Loading train:  40%|████      | 115/285 [01:59<02:45,  1.02it/s]Loading train:  41%|████      | 116/285 [02:00<02:45,  1.02it/s]Loading train:  41%|████      | 117/285 [02:01<02:43,  1.03it/s]Loading train:  41%|████▏     | 118/285 [02:02<02:45,  1.01it/s]Loading train:  42%|████▏     | 119/285 [02:03<02:43,  1.01it/s]Loading train:  42%|████▏     | 120/285 [02:04<02:40,  1.03it/s]Loading train:  42%|████▏     | 121/285 [02:05<02:57,  1.08s/it]Loading train:  43%|████▎     | 122/285 [02:06<03:09,  1.16s/it]Loading train:  43%|████▎     | 123/285 [02:08<03:12,  1.19s/it]Loading train:  44%|████▎     | 124/285 [02:09<03:08,  1.17s/it]Loading train:  44%|████▍     | 125/285 [02:10<02:47,  1.05s/it]Loading train:  44%|████▍     | 126/285 [02:10<02:33,  1.04it/s]Loading train:  45%|████▍     | 127/285 [02:11<02:28,  1.07it/s]Loading train:  45%|████▍     | 128/285 [02:12<02:22,  1.10it/s]Loading train:  45%|████▌     | 129/285 [02:13<02:25,  1.07it/s]Loading train:  46%|████▌     | 130/285 [02:14<02:22,  1.09it/s]Loading train:  46%|████▌     | 131/285 [02:15<02:28,  1.04it/s]Loading train:  46%|████▋     | 132/285 [02:16<02:18,  1.10it/s]Loading train:  47%|████▋     | 133/285 [02:17<02:21,  1.07it/s]Loading train:  47%|████▋     | 134/285 [02:18<02:14,  1.12it/s]Loading train:  47%|████▋     | 135/285 [02:18<02:13,  1.12it/s]Loading train:  48%|████▊     | 136/285 [02:19<02:12,  1.13it/s]Loading train:  48%|████▊     | 137/285 [02:20<02:16,  1.09it/s]Loading train:  48%|████▊     | 138/285 [02:21<02:11,  1.12it/s]Loading train:  49%|████▉     | 139/285 [02:22<02:13,  1.09it/s]Loading train:  49%|████▉     | 140/285 [02:23<02:06,  1.15it/s]Loading train:  49%|████▉     | 141/285 [02:24<02:04,  1.15it/s]Loading train:  50%|████▉     | 142/285 [02:25<02:05,  1.14it/s]Loading train:  50%|█████     | 143/285 [02:26<02:08,  1.11it/s]Loading train:  51%|█████     | 144/285 [02:26<02:03,  1.14it/s]Loading train:  51%|█████     | 145/285 [02:27<02:05,  1.11it/s]Loading train:  51%|█████     | 146/285 [02:28<02:06,  1.10it/s]Loading train:  52%|█████▏    | 147/285 [02:29<01:56,  1.19it/s]Loading train:  52%|█████▏    | 148/285 [02:30<01:55,  1.18it/s]Loading train:  52%|█████▏    | 149/285 [02:31<01:50,  1.23it/s]Loading train:  53%|█████▎    | 150/285 [02:31<01:48,  1.24it/s]Loading train:  53%|█████▎    | 151/285 [02:32<01:52,  1.19it/s]Loading train:  53%|█████▎    | 152/285 [02:33<01:47,  1.24it/s]Loading train:  54%|█████▎    | 153/285 [02:34<01:53,  1.17it/s]Loading train:  54%|█████▍    | 154/285 [02:35<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:36<01:51,  1.17it/s]Loading train:  55%|█████▍    | 156/285 [02:37<01:54,  1.13it/s]Loading train:  55%|█████▌    | 157/285 [02:37<01:50,  1.15it/s]Loading train:  55%|█████▌    | 158/285 [02:39<01:55,  1.10it/s]Loading train:  56%|█████▌    | 159/285 [02:39<01:47,  1.17it/s]Loading train:  56%|█████▌    | 160/285 [02:40<01:47,  1.16it/s]Loading train:  56%|█████▋    | 161/285 [02:41<01:46,  1.16it/s]Loading train:  57%|█████▋    | 162/285 [02:42<01:41,  1.22it/s]Loading train:  57%|█████▋    | 163/285 [02:43<01:46,  1.14it/s]Loading train:  58%|█████▊    | 164/285 [02:44<01:43,  1.17it/s]Loading train:  58%|█████▊    | 165/285 [02:44<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [02:45<01:39,  1.20it/s]Loading train:  59%|█████▊    | 167/285 [02:46<01:38,  1.20it/s]Loading train:  59%|█████▉    | 168/285 [02:47<01:37,  1.20it/s]Loading train:  59%|█████▉    | 169/285 [02:48<01:36,  1.20it/s]Loading train:  60%|█████▉    | 170/285 [02:48<01:35,  1.21it/s]Loading train:  60%|██████    | 171/285 [02:49<01:31,  1.25it/s]Loading train:  60%|██████    | 172/285 [02:50<01:33,  1.21it/s]Loading train:  61%|██████    | 173/285 [02:51<01:33,  1.20it/s]Loading train:  61%|██████    | 174/285 [02:52<01:35,  1.16it/s]Loading train:  61%|██████▏   | 175/285 [02:53<01:32,  1.20it/s]Loading train:  62%|██████▏   | 176/285 [02:54<01:39,  1.10it/s]Loading train:  62%|██████▏   | 177/285 [02:54<01:31,  1.17it/s]Loading train:  62%|██████▏   | 178/285 [02:56<01:38,  1.09it/s]Loading train:  63%|██████▎   | 179/285 [02:56<01:32,  1.15it/s]Loading train:  63%|██████▎   | 180/285 [02:57<01:28,  1.19it/s]Loading train:  64%|██████▎   | 181/285 [02:58<01:28,  1.17it/s]Loading train:  64%|██████▍   | 182/285 [02:59<01:23,  1.23it/s]Loading train:  64%|██████▍   | 183/285 [03:00<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [03:00<01:23,  1.20it/s]Loading train:  65%|██████▍   | 185/285 [03:01<01:23,  1.20it/s]Loading train:  65%|██████▌   | 186/285 [03:02<01:16,  1.29it/s]Loading train:  66%|██████▌   | 187/285 [03:03<01:15,  1.29it/s]Loading train:  66%|██████▌   | 188/285 [03:03<01:15,  1.28it/s]Loading train:  66%|██████▋   | 189/285 [03:04<01:12,  1.32it/s]Loading train:  67%|██████▋   | 190/285 [03:05<01:13,  1.28it/s]Loading train:  67%|██████▋   | 191/285 [03:06<01:11,  1.32it/s]Loading train:  67%|██████▋   | 192/285 [03:07<01:14,  1.26it/s]Loading train:  68%|██████▊   | 193/285 [03:07<01:11,  1.29it/s]Loading train:  68%|██████▊   | 194/285 [03:08<01:13,  1.23it/s]Loading train:  68%|██████▊   | 195/285 [03:09<01:13,  1.23it/s]Loading train:  69%|██████▉   | 196/285 [03:10<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [03:11<01:17,  1.14it/s]Loading train:  69%|██████▉   | 198/285 [03:12<01:13,  1.18it/s]Loading train:  70%|██████▉   | 199/285 [03:13<01:14,  1.16it/s]Loading train:  70%|███████   | 200/285 [03:13<01:12,  1.17it/s]Loading train:  71%|███████   | 201/285 [03:14<01:15,  1.11it/s]Loading train:  71%|███████   | 202/285 [03:15<01:12,  1.14it/s]Loading train:  71%|███████   | 203/285 [03:16<01:15,  1.09it/s]Loading train:  72%|███████▏  | 204/285 [03:17<01:14,  1.08it/s]Loading train:  72%|███████▏  | 205/285 [03:18<01:15,  1.06it/s]Loading train:  72%|███████▏  | 206/285 [03:19<01:15,  1.05it/s]Loading train:  73%|███████▎  | 207/285 [03:20<01:14,  1.05it/s]Loading train:  73%|███████▎  | 208/285 [03:21<01:09,  1.10it/s]Loading train:  73%|███████▎  | 209/285 [03:22<01:10,  1.08it/s]Loading train:  74%|███████▎  | 210/285 [03:23<01:08,  1.10it/s]Loading train:  74%|███████▍  | 211/285 [03:24<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [03:25<01:05,  1.11it/s]Loading train:  75%|███████▍  | 213/285 [03:25<01:04,  1.12it/s]Loading train:  75%|███████▌  | 214/285 [03:26<01:01,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [03:27<00:57,  1.21it/s]Loading train:  76%|███████▌  | 216/285 [03:28<00:55,  1.23it/s]Loading train:  76%|███████▌  | 217/285 [03:28<00:53,  1.27it/s]Loading train:  76%|███████▋  | 218/285 [03:29<00:51,  1.31it/s]Loading train:  77%|███████▋  | 219/285 [03:30<00:50,  1.31it/s]Loading train:  77%|███████▋  | 220/285 [03:31<00:48,  1.33it/s]Loading train:  78%|███████▊  | 221/285 [03:32<00:51,  1.25it/s]Loading train:  78%|███████▊  | 222/285 [03:32<00:48,  1.29it/s]Loading train:  78%|███████▊  | 223/285 [03:33<00:50,  1.24it/s]Loading train:  79%|███████▊  | 224/285 [03:34<00:47,  1.28it/s]Loading train:  79%|███████▉  | 225/285 [03:35<00:48,  1.23it/s]Loading train:  79%|███████▉  | 226/285 [03:36<00:47,  1.24it/s]Loading train:  80%|███████▉  | 227/285 [03:36<00:47,  1.21it/s]Loading train:  80%|████████  | 228/285 [03:37<00:45,  1.25it/s]Loading train:  80%|████████  | 229/285 [03:38<00:46,  1.21it/s]Loading train:  81%|████████  | 230/285 [03:39<00:43,  1.27it/s]Loading train:  81%|████████  | 231/285 [03:40<00:42,  1.27it/s]Loading train:  81%|████████▏ | 232/285 [03:41<00:46,  1.15it/s]Loading train:  82%|████████▏ | 233/285 [03:42<00:50,  1.04it/s]Loading train:  82%|████████▏ | 234/285 [03:43<00:49,  1.04it/s]Loading train:  82%|████████▏ | 235/285 [03:45<01:02,  1.24s/it]Loading train:  83%|████████▎ | 236/285 [03:47<01:12,  1.47s/it]Loading train:  83%|████████▎ | 237/285 [03:49<01:21,  1.71s/it]Loading train:  84%|████████▎ | 238/285 [03:51<01:24,  1.79s/it]Loading train:  84%|████████▍ | 239/285 [03:53<01:27,  1.90s/it]Loading train:  84%|████████▍ | 240/285 [03:55<01:28,  1.97s/it]Loading train:  85%|████████▍ | 241/285 [03:57<01:28,  2.00s/it]Loading train:  85%|████████▍ | 242/285 [03:59<01:26,  2.01s/it]Loading train:  85%|████████▌ | 243/285 [04:01<01:23,  2.00s/it]Loading train:  86%|████████▌ | 244/285 [04:03<01:14,  1.82s/it]Loading train:  86%|████████▌ | 245/285 [04:04<01:06,  1.67s/it]Loading train:  86%|████████▋ | 246/285 [04:05<01:01,  1.57s/it]Loading train:  87%|████████▋ | 247/285 [04:07<00:56,  1.49s/it]Loading train:  87%|████████▋ | 248/285 [04:09<01:00,  1.62s/it]Loading train:  87%|████████▋ | 249/285 [04:11<01:02,  1.74s/it]Loading train:  88%|████████▊ | 250/285 [04:12<01:00,  1.73s/it]Loading train:  88%|████████▊ | 251/285 [04:14<00:55,  1.64s/it]Loading train:  88%|████████▊ | 252/285 [04:15<00:49,  1.49s/it]Loading train:  89%|████████▉ | 253/285 [04:16<00:47,  1.47s/it]Loading train:  89%|████████▉ | 254/285 [04:18<00:43,  1.41s/it]Loading train:  89%|████████▉ | 255/285 [04:19<00:40,  1.35s/it]Loading train:  90%|████████▉ | 256/285 [04:20<00:40,  1.41s/it]Loading train:  90%|█████████ | 257/285 [04:22<00:41,  1.48s/it]Loading train:  91%|█████████ | 258/285 [04:24<00:43,  1.60s/it]Loading train:  91%|█████████ | 259/285 [04:25<00:35,  1.38s/it]Loading train:  91%|█████████ | 260/285 [04:26<00:36,  1.45s/it]Loading train:  92%|█████████▏| 261/285 [04:28<00:38,  1.60s/it]Loading train:  92%|█████████▏| 262/285 [04:29<00:32,  1.43s/it]Loading train:  92%|█████████▏| 263/285 [04:30<00:29,  1.32s/it]Loading train:  93%|█████████▎| 264/285 [04:32<00:28,  1.37s/it]Loading train:  93%|█████████▎| 265/285 [04:34<00:29,  1.47s/it]Loading train:  93%|█████████▎| 266/285 [04:35<00:26,  1.39s/it]Loading train:  94%|█████████▎| 267/285 [04:36<00:25,  1.42s/it]Loading train:  94%|█████████▍| 268/285 [04:38<00:26,  1.54s/it]Loading train:  94%|█████████▍| 269/285 [04:39<00:24,  1.51s/it]Loading train:  95%|█████████▍| 270/285 [04:41<00:23,  1.56s/it]Loading train:  95%|█████████▌| 271/285 [04:43<00:22,  1.61s/it]Loading train:  95%|█████████▌| 272/285 [04:44<00:20,  1.60s/it]Loading train:  96%|█████████▌| 273/285 [04:46<00:18,  1.51s/it]Loading train:  96%|█████████▌| 274/285 [04:48<00:17,  1.59s/it]Loading train:  96%|█████████▋| 275/285 [04:49<00:16,  1.68s/it]Loading train:  97%|█████████▋| 276/285 [04:52<00:16,  1.79s/it]Loading train:  97%|█████████▋| 277/285 [04:54<00:15,  1.90s/it]Loading train:  98%|█████████▊| 278/285 [04:55<00:12,  1.73s/it]Loading train:  98%|█████████▊| 279/285 [04:56<00:09,  1.57s/it]Loading train:  98%|█████████▊| 280/285 [04:57<00:07,  1.46s/it]Loading train:  99%|█████████▊| 281/285 [04:59<00:05,  1.45s/it]Loading train:  99%|█████████▉| 282/285 [05:00<00:04,  1.45s/it]Loading train:  99%|█████████▉| 283/285 [05:02<00:03,  1.59s/it]Loading train: 100%|█████████▉| 284/285 [05:04<00:01,  1.56s/it]Loading train: 100%|██████████| 285/285 [05:05<00:00,  1.55s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:08, 33.11it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:06, 42.61it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:04, 52.31it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:06, 41.38it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:06, 35.18it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:05, 41.90it/s]concatenating: train:  20%|█▉        | 56/285 [00:01<00:05, 42.13it/s]concatenating: train:  22%|██▏       | 62/285 [00:01<00:05, 39.98it/s]concatenating: train:  24%|██▍       | 68/285 [00:01<00:04, 44.09it/s]concatenating: train:  26%|██▌       | 73/285 [00:01<00:05, 41.60it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:05, 38.87it/s]concatenating: train:  29%|██▉       | 84/285 [00:01<00:04, 40.67it/s]concatenating: train:  31%|███       | 89/285 [00:01<00:04, 41.78it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:03, 49.75it/s]concatenating: train:  38%|███▊      | 107/285 [00:02<00:03, 56.21it/s]concatenating: train:  40%|████      | 114/285 [00:02<00:03, 44.61it/s]concatenating: train:  42%|████▏     | 120/285 [00:02<00:03, 45.68it/s]concatenating: train:  45%|████▍     | 128/285 [00:02<00:03, 51.62it/s]concatenating: train:  49%|████▉     | 139/285 [00:02<00:02, 61.03it/s]concatenating: train:  52%|█████▏    | 149/285 [00:02<00:01, 68.57it/s]concatenating: train:  63%|██████▎   | 179/285 [00:02<00:01, 89.16it/s]concatenating: train:  72%|███████▏  | 205/285 [00:02<00:00, 108.84it/s]concatenating: train:  78%|███████▊  | 222/285 [00:03<00:00, 76.12it/s] concatenating: train:  83%|████████▎ | 236/285 [00:03<00:00, 76.57it/s]concatenating: train:  87%|████████▋ | 248/285 [00:03<00:00, 72.29it/s]concatenating: train:  91%|█████████ | 259/285 [00:04<00:00, 52.45it/s]concatenating: train:  94%|█████████▎| 267/285 [00:04<00:00, 50.17it/s]concatenating: train:  96%|█████████▌| 274/285 [00:04<00:00, 51.00it/s]concatenating: train:  99%|█████████▊| 281/285 [00:04<00:00, 54.48it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 62.92it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.79s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.83s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.74s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 38.85it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 20)   0           batch_normalization_7[0][0]      2019-07-07 02:43:45.097204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 02:43:45.097316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 02:43:45.097331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 02:43:45.097341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 02:43:45.097834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 19s - loss: 30553.1453 - acc: 0.8543 - mDice: 0.1025 - val_loss: 14853.6922 - val_acc: 0.8913 - val_mDice: 0.1867

Epoch 00001: val_mDice improved from -inf to 0.18673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 13622.2037 - acc: 0.8665 - mDice: 0.1975 - val_loss: 9493.0820 - val_acc: 0.8949 - val_mDice: 0.2845

Epoch 00002: val_mDice improved from 0.18673 to 0.28453, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 11332.2245 - acc: 0.8729 - mDice: 0.2521 - val_loss: 8503.7979 - val_acc: 0.8996 - val_mDice: 0.3206

Epoch 00003: val_mDice improved from 0.28453 to 0.32057, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 9935.7984 - acc: 0.8804 - mDice: 0.2938 - val_loss: 7712.7743 - val_acc: 0.9012 - val_mDice: 0.3540

Epoch 00004: val_mDice improved from 0.32057 to 0.35401, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 8799.5749 - acc: 0.8900 - mDice: 0.3335 - val_loss: 6933.9478 - val_acc: 0.9138 - val_mDice: 0.3939

Epoch 00005: val_mDice improved from 0.35401 to 0.39394, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 7958.2196 - acc: 0.8982 - mDice: 0.3674 - val_loss: 6340.8853 - val_acc: 0.9188 - val_mDice: 0.4229

Epoch 00006: val_mDice improved from 0.39394 to 0.42288, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 9s - loss: 7275.4992 - acc: 0.9040 - mDice: 0.3975 - val_loss: 6142.7412 - val_acc: 0.9167 - val_mDice: 0.4362

Epoch 00007: val_mDice improved from 0.42288 to 0.43619, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 9s - loss: 6791.9970 - acc: 0.9078 - mDice: 0.4208 - val_loss: 5879.6371 - val_acc: 0.9199 - val_mDice: 0.4483

Epoch 00008: val_mDice improved from 0.43619 to 0.44830, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 6440.3538 - acc: 0.9105 - mDice: 0.4390 - val_loss: 5697.5239 - val_acc: 0.9214 - val_mDice: 0.4602

Epoch 00009: val_mDice improved from 0.44830 to 0.46018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 6139.3421 - acc: 0.9128 - mDice: 0.4550 - val_loss: 5462.3984 - val_acc: 0.9233 - val_mDice: 0.4752

Epoch 00010: val_mDice improved from 0.46018 to 0.47524, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 5857.1248 - acc: 0.9149 - mDice: 0.4710 - val_loss: 5197.5940 - val_acc: 0.9280 - val_mDice: 0.4920

Epoch 00011: val_mDice improved from 0.47524 to 0.49201, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 5672.3860 - acc: 0.9160 - mDice: 0.4815 - val_loss: 5112.5873 - val_acc: 0.9280 - val_mDice: 0.4981

Epoch 00012: val_mDice improved from 0.49201 to 0.49809, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 5441.0727 - acc: 0.9175 - mDice: 0.4948 - val_loss: 5276.2392 - val_acc: 0.9242 - val_mDice: 0.4858

Epoch 00013: val_mDice did not improve from 0.49809
Epoch 14/300
 - 9s - loss: 5295.2317 - acc: 0.9184 - mDice: 0.5038 - val_loss: 4972.8472 - val_acc: 0.9297 - val_mDice: 0.5041

Epoch 00014: val_mDice improved from 0.49809 to 0.50412, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 9s - loss: 5123.5435 - acc: 0.9198 - mDice: 0.5141 - val_loss: 5037.3316 - val_acc: 0.9280 - val_mDice: 0.5005

Epoch 00015: val_mDice did not improve from 0.50412
Epoch 16/300
 - 9s - loss: 4976.7529 - acc: 0.9207 - mDice: 0.5232 - val_loss: 4718.6595 - val_acc: 0.9310 - val_mDice: 0.5214

Epoch 00016: val_mDice improved from 0.50412 to 0.52142, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 12s - loss: 4868.7649 - acc: 0.9216 - mDice: 0.5304 - val_loss: 4744.1168 - val_acc: 0.9317 - val_mDice: 0.5179

Epoch 00017: val_mDice did not improve from 0.52142
Epoch 18/300
 - 13s - loss: 4746.3746 - acc: 0.9225 - mDice: 0.5386 - val_loss: 4647.9180 - val_acc: 0.9302 - val_mDice: 0.5233

Epoch 00018: val_mDice improved from 0.52142 to 0.52327, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 12s - loss: 4699.8400 - acc: 0.9231 - mDice: 0.5421 - val_loss: 4600.6656 - val_acc: 0.9306 - val_mDice: 0.5257

Epoch 00019: val_mDice improved from 0.52327 to 0.52573, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 11s - loss: 4561.8031 - acc: 0.9242 - mDice: 0.5513 - val_loss: 4578.6181 - val_acc: 0.9320 - val_mDice: 0.5287

Epoch 00020: val_mDice improved from 0.52573 to 0.52868, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 13s - loss: 4516.9714 - acc: 0.9247 - mDice: 0.5546 - val_loss: 4562.6196 - val_acc: 0.9312 - val_mDice: 0.5298

Epoch 00021: val_mDice improved from 0.52868 to 0.52977, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 11s - loss: 4402.1274 - acc: 0.9254 - mDice: 0.5623 - val_loss: 4505.6668 - val_acc: 0.9331 - val_mDice: 0.5337

Epoch 00022: val_mDice improved from 0.52977 to 0.53373, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 14s - loss: 4315.8804 - acc: 0.9262 - mDice: 0.5683 - val_loss: 4486.8841 - val_acc: 0.9355 - val_mDice: 0.5346

Epoch 00023: val_mDice improved from 0.53373 to 0.53459, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 11s - loss: 4259.8186 - acc: 0.9266 - mDice: 0.5727 - val_loss: 4468.1380 - val_acc: 0.9339 - val_mDice: 0.5344

Epoch 00024: val_mDice did not improve from 0.53459
Epoch 25/300
 - 11s - loss: 4188.7865 - acc: 0.9273 - mDice: 0.5774 - val_loss: 4451.1290 - val_acc: 0.9336 - val_mDice: 0.5378

Epoch 00025: val_mDice improved from 0.53459 to 0.53776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 13s - loss: 4123.3431 - acc: 0.9277 - mDice: 0.5825 - val_loss: 4445.3135 - val_acc: 0.9339 - val_mDice: 0.5378

Epoch 00026: val_mDice did not improve from 0.53776
Epoch 27/300
 - 11s - loss: 4081.8221 - acc: 0.9279 - mDice: 0.5853 - val_loss: 4390.3997 - val_acc: 0.9332 - val_mDice: 0.5408

Epoch 00027: val_mDice improved from 0.53776 to 0.54083, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 12s - loss: 4013.4429 - acc: 0.9288 - mDice: 0.5909 - val_loss: 4506.9100 - val_acc: 0.9296 - val_mDice: 0.5317

Epoch 00028: val_mDice did not improve from 0.54083
Epoch 29/300
 - 12s - loss: 3963.7011 - acc: 0.9290 - mDice: 0.5944 - val_loss: 4427.9848 - val_acc: 0.9330 - val_mDice: 0.5369

Epoch 00029: val_mDice did not improve from 0.54083
Epoch 30/300
 - 12s - loss: 3907.6848 - acc: 0.9297 - mDice: 0.5988 - val_loss: 4222.0631 - val_acc: 0.9340 - val_mDice: 0.5520

Epoch 00030: val_mDice improved from 0.54083 to 0.55203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 12s - loss: 3868.1621 - acc: 0.9299 - mDice: 0.6017 - val_loss: 4518.3459 - val_acc: 0.9303 - val_mDice: 0.5303

Epoch 00031: val_mDice did not improve from 0.55203
Epoch 32/300
 - 12s - loss: 3808.9020 - acc: 0.9303 - mDice: 0.6061 - val_loss: 4197.1990 - val_acc: 0.9337 - val_mDice: 0.5544

Epoch 00032: val_mDice improved from 0.55203 to 0.55436, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 12s - loss: 3791.1260 - acc: 0.9307 - mDice: 0.6080 - val_loss: 4297.0455 - val_acc: 0.9325 - val_mDice: 0.5462

Epoch 00033: val_mDice did not improve from 0.55436
Epoch 34/300
 - 13s - loss: 3740.1833 - acc: 0.9313 - mDice: 0.6116 - val_loss: 4221.9743 - val_acc: 0.9341 - val_mDice: 0.5530

Epoch 00034: val_mDice did not improve from 0.55436
Epoch 35/300
 - 13s - loss: 3704.1357 - acc: 0.9315 - mDice: 0.6143 - val_loss: 4365.9570 - val_acc: 0.9338 - val_mDice: 0.5422

Epoch 00035: val_mDice did not improve from 0.55436
Epoch 36/300
 - 12s - loss: 3668.9775 - acc: 0.9320 - mDice: 0.6174 - val_loss: 4142.7516 - val_acc: 0.9363 - val_mDice: 0.5599

Epoch 00036: val_mDice improved from 0.55436 to 0.55989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 14s - loss: 3626.9445 - acc: 0.9323 - mDice: 0.6205 - val_loss: 4356.9565 - val_acc: 0.9330 - val_mDice: 0.5445

Epoch 00037: val_mDice did not improve from 0.55989
Epoch 38/300
 - 12s - loss: 3572.0108 - acc: 0.9326 - mDice: 0.6248 - val_loss: 4162.5369 - val_acc: 0.9354 - val_mDice: 0.5565

Epoch 00038: val_mDice did not improve from 0.55989
Epoch 39/300
 - 13s - loss: 3558.6701 - acc: 0.9330 - mDice: 0.6262 - val_loss: 4318.7855 - val_acc: 0.9324 - val_mDice: 0.5473

Epoch 00039: val_mDice did not improve from 0.55989
Epoch 40/300
 - 12s - loss: 3547.1982 - acc: 0.9331 - mDice: 0.6267 - val_loss: 4197.9330 - val_acc: 0.9338 - val_mDice: 0.5542

Epoch 00040: val_mDice did not improve from 0.55989
Epoch 41/300
 - 12s - loss: 3509.3353 - acc: 0.9333 - mDice: 0.6301 - val_loss: 4135.5361 - val_acc: 0.9349 - val_mDice: 0.5594

Epoch 00041: val_mDice did not improve from 0.55989
Epoch 42/300
 - 12s - loss: 3473.3359 - acc: 0.9337 - mDice: 0.6328 - val_loss: 4145.1405 - val_acc: 0.9352 - val_mDice: 0.5580

Epoch 00042: val_mDice did not improve from 0.55989
Epoch 43/300
 - 11s - loss: 3454.8506 - acc: 0.9339 - mDice: 0.6344 - val_loss: 4136.9490 - val_acc: 0.9339 - val_mDice: 0.5598

Epoch 00043: val_mDice did not improve from 0.55989
Epoch 44/300
 - 10s - loss: 3427.1906 - acc: 0.9342 - mDice: 0.6368 - val_loss: 4164.7440 - val_acc: 0.9393 - val_mDice: 0.5586

Epoch 00044: val_mDice did not improve from 0.55989
Epoch 45/300
 - 11s - loss: 3385.5242 - acc: 0.9346 - mDice: 0.6400 - val_loss: 4210.3590 - val_acc: 0.9356 - val_mDice: 0.5553

Epoch 00045: val_mDice did not improve from 0.55989
Epoch 46/300
 - 12s - loss: 3372.3829 - acc: 0.9350 - mDice: 0.6413 - val_loss: 3967.2078 - val_acc: 0.9404 - val_mDice: 0.5716

Epoch 00046: val_mDice improved from 0.55989 to 0.57158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 10s - loss: 3339.5694 - acc: 0.9349 - mDice: 0.6438 - val_loss: 4169.1865 - val_acc: 0.9364 - val_mDice: 0.5583

Epoch 00047: val_mDice did not improve from 0.57158
Epoch 48/300
 - 12s - loss: 3315.8601 - acc: 0.9352 - mDice: 0.6458 - val_loss: 4217.2384 - val_acc: 0.9368 - val_mDice: 0.5534

Epoch 00048: val_mDice did not improve from 0.57158
Epoch 49/300
 - 10s - loss: 3287.7560 - acc: 0.9357 - mDice: 0.6483 - val_loss: 4180.3759 - val_acc: 0.9351 - val_mDice: 0.5570

Epoch 00049: val_mDice did not improve from 0.57158
Epoch 50/300
 - 11s - loss: 3270.1150 - acc: 0.9360 - mDice: 0.6497 - val_loss: 4063.3085 - val_acc: 0.9362 - val_mDice: 0.5646

Epoch 00050: val_mDice did not improve from 0.57158
Epoch 51/300
 - 11s - loss: 3251.0704 - acc: 0.9361 - mDice: 0.6512 - val_loss: 4204.5322 - val_acc: 0.9342 - val_mDice: 0.5557

Epoch 00051: val_mDice did not improve from 0.57158
Epoch 52/300
 - 9s - loss: 3226.4138 - acc: 0.9361 - mDice: 0.6533 - val_loss: 4068.0604 - val_acc: 0.9376 - val_mDice: 0.5638

Epoch 00052: val_mDice did not improve from 0.57158
Epoch 53/300
 - 9s - loss: 3208.6790 - acc: 0.9364 - mDice: 0.6551 - val_loss: 3989.1908 - val_acc: 0.9361 - val_mDice: 0.5706

Epoch 00053: val_mDice did not improve from 0.57158
Epoch 54/300
 - 9s - loss: 3186.5666 - acc: 0.9365 - mDice: 0.6567 - val_loss: 4093.3937 - val_acc: 0.9390 - val_mDice: 0.5634

Epoch 00054: val_mDice did not improve from 0.57158
Epoch 55/300
 - 8s - loss: 3165.8373 - acc: 0.9368 - mDice: 0.6584 - val_loss: 4219.6363 - val_acc: 0.9353 - val_mDice: 0.5533

Epoch 00055: val_mDice did not improve from 0.57158
Epoch 56/300
 - 9s - loss: 3152.0415 - acc: 0.9370 - mDice: 0.6595 - val_loss: 4063.9647 - val_acc: 0.9373 - val_mDice: 0.5651

Epoch 00056: val_mDice did not improve from 0.57158
Epoch 57/300
 - 8s - loss: 3145.1877 - acc: 0.9372 - mDice: 0.6602 - val_loss: 3976.6060 - val_acc: 0.9408 - val_mDice: 0.5726

Epoch 00057: val_mDice improved from 0.57158 to 0.57261, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 8s - loss: 3132.1400 - acc: 0.9372 - mDice: 0.6613 - val_loss: 4083.5058 - val_acc: 0.9372 - val_mDice: 0.5631

Epoch 00058: val_mDice did not improve from 0.57261
Epoch 59/300
 - 9s - loss: 3084.1043 - acc: 0.9376 - mDice: 0.6654 - val_loss: 3947.8193 - val_acc: 0.9389 - val_mDice: 0.5745

Epoch 00059: val_mDice improved from 0.57261 to 0.57454, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 60/300
 - 8s - loss: 3066.8550 - acc: 0.9379 - mDice: 0.6670 - val_loss: 4003.0403 - val_acc: 0.9387 - val_mDice: 0.5693

Epoch 00060: val_mDice did not improve from 0.57454
Epoch 61/300
 - 9s - loss: 3045.0810 - acc: 0.9381 - mDice: 0.6687 - val_loss: 4004.7823 - val_acc: 0.9398 - val_mDice: 0.5679

Epoch 00061: val_mDice did not improve from 0.57454
Epoch 62/300
 - 8s - loss: 3020.6789 - acc: 0.9382 - mDice: 0.6708 - val_loss: 4132.3248 - val_acc: 0.9383 - val_mDice: 0.5595

Epoch 00062: val_mDice did not improve from 0.57454
Epoch 63/300
 - 8s - loss: 3029.4104 - acc: 0.9383 - mDice: 0.6702 - val_loss: 4172.0747 - val_acc: 0.9352 - val_mDice: 0.5568

Epoch 00063: val_mDice did not improve from 0.57454
Epoch 64/300
 - 8s - loss: 3016.9948 - acc: 0.9383 - mDice: 0.6712 - val_loss: 4409.6915 - val_acc: 0.9339 - val_mDice: 0.5423

Epoch 00064: val_mDice did not improve from 0.57454
Epoch 65/300
 - 8s - loss: 3004.3768 - acc: 0.9386 - mDice: 0.6725 - val_loss: 4128.0700 - val_acc: 0.9358 - val_mDice: 0.5606

Epoch 00065: val_mDice did not improve from 0.57454
Epoch 66/300
 - 8s - loss: 2990.5106 - acc: 0.9386 - mDice: 0.6735 - val_loss: 3859.6185 - val_acc: 0.9398 - val_mDice: 0.5808

Epoch 00066: val_mDice improved from 0.57454 to 0.58080, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 67/300
 - 8s - loss: 2982.1479 - acc: 0.9389 - mDice: 0.6744 - val_loss: 4098.8154 - val_acc: 0.9392 - val_mDice: 0.5629

Epoch 00067: val_mDice did not improve from 0.58080
Epoch 68/300
 - 8s - loss: 2985.4305 - acc: 0.9389 - mDice: 0.6743 - val_loss: 4630.0466 - val_acc: 0.9423 - val_mDice: 0.5403

Epoch 00068: val_mDice did not improve from 0.58080
Epoch 69/300
 - 8s - loss: 2949.9417 - acc: 0.9392 - mDice: 0.6771 - val_loss: 4083.0328 - val_acc: 0.9379 - val_mDice: 0.5627

Epoch 00069: val_mDice did not improve from 0.58080
Epoch 70/300
 - 8s - loss: 2919.4382 - acc: 0.9393 - mDice: 0.6798 - val_loss: 4161.8172 - val_acc: 0.9365 - val_mDice: 0.5578

Epoch 00070: val_mDice did not improve from 0.58080
Epoch 71/300
 - 8s - loss: 2903.2773 - acc: 0.9394 - mDice: 0.6812 - val_loss: 4119.5279 - val_acc: 0.9368 - val_mDice: 0.5603

Epoch 00071: val_mDice did not improve from 0.58080
Epoch 72/300
 - 8s - loss: 2886.7181 - acc: 0.9396 - mDice: 0.6826 - val_loss: 4089.3034 - val_acc: 0.9394 - val_mDice: 0.5626

Epoch 00072: val_mDice did not improve from 0.58080
Epoch 73/300
 - 9s - loss: 2876.4634 - acc: 0.9396 - mDice: 0.6835 - val_loss: 4284.9895 - val_acc: 0.9345 - val_mDice: 0.5479

Epoch 00073: val_mDice did not improve from 0.58080
Epoch 74/300
 - 8s - loss: 2885.6910 - acc: 0.9398 - mDice: 0.6827 - val_loss: 4090.5845 - val_acc: 0.9362 - val_mDice: 0.5624

Epoch 00074: val_mDice did not improve from 0.58080
Epoch 75/300
 - 9s - loss: 2869.5637 - acc: 0.9398 - mDice: 0.6843 - val_loss: 4021.8916 - val_acc: 0.9415 - val_mDice: 0.5679

Epoch 00075: val_mDice did not improve from 0.58080
Epoch 76/300
 - 8s - loss: 2855.1830 - acc: 0.9400 - mDice: 0.6855 - val_loss: 4009.0834 - val_acc: 0.9382 - val_mDice: 0.5696

Epoch 00076: val_mDice did not improve from 0.58080
Epoch 77/300
 - 9s - loss: 2853.0276 - acc: 0.9400 - mDice: 0.6856 - val_loss: 4155.2880 - val_acc: 0.9378 - val_mDice: 0.5585

Epoch 00077: val_mDice did not improve from 0.58080
Epoch 78/300
 - 8s - loss: 2856.5365 - acc: 0.9400 - mDice: 0.6855 - val_loss: 4141.0360 - val_acc: 0.9388 - val_mDice: 0.5594

Epoch 00078: val_mDice did not improve from 0.58080
Epoch 79/300
 - 9s - loss: 2813.6098 - acc: 0.9404 - mDice: 0.6892 - val_loss: 4179.9490 - val_acc: 0.9409 - val_mDice: 0.5601

Epoch 00079: val_mDice did not improve from 0.58080
Epoch 80/300
 - 8s - loss: 2822.1714 - acc: 0.9404 - mDice: 0.6885 - val_loss: 3980.4118 - val_acc: 0.9404 - val_mDice: 0.5693

Epoch 00080: val_mDice did not improve from 0.58080
Epoch 81/300
 - 8s - loss: 2796.0332 - acc: 0.9406 - mDice: 0.6908 - val_loss: 3931.7941 - val_acc: 0.9404 - val_mDice: 0.5742

Epoch 00081: val_mDice did not improve from 0.58080
Epoch 82/300
 - 8s - loss: 2797.5405 - acc: 0.9407 - mDice: 0.6905 - val_loss: 4088.2532 - val_acc: 0.9387 - val_mDice: 0.5636

Epoch 00082: val_mDice did not improve from 0.58080
Epoch 83/300
 - 8s - loss: 2796.8313 - acc: 0.9405 - mDice: 0.6906 - val_loss: 3875.2316 - val_acc: 0.9386 - val_mDice: 0.5784

Epoch 00083: val_mDice did not improve from 0.58080
Epoch 84/300
 - 8s - loss: 2778.0047 - acc: 0.9407 - mDice: 0.6923 - val_loss: 4014.0332 - val_acc: 0.9383 - val_mDice: 0.5699

Epoch 00084: val_mDice did not improve from 0.58080
Epoch 85/300
 - 8s - loss: 2741.1234 - acc: 0.9412 - mDice: 0.6957 - val_loss: 4124.9777 - val_acc: 0.9388 - val_mDice: 0.5607

Epoch 00085: val_mDice did not improve from 0.58080
Epoch 86/300
 - 8s - loss: 2738.7205 - acc: 0.9411 - mDice: 0.6959 - val_loss: 4150.0970 - val_acc: 0.9401 - val_mDice: 0.5585

Epoch 00086: val_mDice did not improve from 0.58080
Epoch 87/300
 - 8s - loss: 2746.1704 - acc: 0.9412 - mDice: 0.6954 - val_loss: 4115.3344 - val_acc: 0.9393 - val_mDice: 0.5622

Epoch 00087: val_mDice did not improve from 0.58080
Epoch 88/300
 - 9s - loss: 2726.2977 - acc: 0.9413 - mDice: 0.6971 - val_loss: 3925.2613 - val_acc: 0.9421 - val_mDice: 0.5755

Epoch 00088: val_mDice did not improve from 0.58080
Epoch 89/300
 - 8s - loss: 2720.8643 - acc: 0.9414 - mDice: 0.6977 - val_loss: 3883.9819 - val_acc: 0.9400 - val_mDice: 0.5781

Epoch 00089: val_mDice did not improve from 0.58080
Epoch 90/300
 - 9s - loss: 2728.5886 - acc: 0.9413 - mDice: 0.6969 - val_loss: 4063.2042 - val_acc: 0.9391 - val_mDice: 0.5662

Epoch 00090: val_mDice did not improve from 0.58080
Epoch 91/300
 - 8s - loss: 2713.0194 - acc: 0.9413 - mDice: 0.6983 - val_loss: 4200.2706 - val_acc: 0.9420 - val_mDice: 0.5561

Epoch 00091: val_mDice did not improve from 0.58080
Epoch 92/300
 - 9s - loss: 2699.4896 - acc: 0.9415 - mDice: 0.6994 - val_loss: 4110.0347 - val_acc: 0.9391 - val_mDice: 0.5603

Epoch 00092: val_mDice did not improve from 0.58080
Epoch 93/300
 - 8s - loss: 2691.8113 - acc: 0.9416 - mDice: 0.7002 - val_loss: 4092.4860 - val_acc: 0.9392 - val_mDice: 0.5635

Epoch 00093: val_mDice did not improve from 0.58080
Epoch 94/300
 - 9s - loss: 2674.0541 - acc: 0.9419 - mDice: 0.7019 - val_loss: 4133.8417 - val_acc: 0.9393 - val_mDice: 0.5615

Epoch 00094: val_mDice did not improve from 0.58080
Epoch 95/300
 - 8s - loss: 2686.9320 - acc: 0.9417 - mDice: 0.7006 - val_loss: 4028.6623 - val_acc: 0.9417 - val_mDice: 0.5692

Epoch 00095: val_mDice did not improve from 0.58080
Epoch 96/300
 - 8s - loss: 2660.0350 - acc: 0.9418 - mDice: 0.7030 - val_loss: 3934.6984 - val_acc: 0.9439 - val_mDice: 0.5740

Epoch 00096: val_mDice did not improve from 0.58080
Restoring model weights from the end of the best epoch
Epoch 00096: early stopping
{'val_loss': [14853.692232572115, 9493.082040640023, 8503.7978515625, 7712.774282602163, 6933.947763296274, 6340.885319636418, 6142.741248497596, 5879.637099045974, 5697.523897611178, 5462.398423414964, 5197.593961275541, 5112.587266188401, 5276.239206167368, 4972.84721491887, 5037.331613393931, 4718.6594801682695, 4744.116750863882, 4647.917996920072, 4600.665607158954, 4578.61807016226, 4562.619624211238, 4505.666832557092, 4486.884098933293, 4468.1380286583535, 4451.129009540265, 4445.3135000375605, 4390.399733323317, 4506.9099848820615, 4427.984750600962, 4222.063100961538, 4518.3459237905645, 4197.199009821965, 4297.045480581431, 4221.9742760291465, 4365.95698429988, 4142.751647949219, 4356.956538273738, 4162.536919227014, 4318.785536545974, 4197.932978703426, 4135.536081167368, 4145.140479454627, 4136.949049729567, 4164.744032639724, 4210.358971228967, 3967.207754281851, 4169.1865234375, 4217.238445575421, 4180.375901442308, 4063.3085327148438, 4204.532221867488, 4068.0604060246396, 3989.1907724233774, 4093.393728402945, 4219.636258638822, 4063.9647310697114, 3976.605966421274, 4083.5057936448316, 3947.8192514272837, 4003.040269118089, 4004.7823345477764, 4132.324782151442, 4172.074725811298, 4409.691518930288, 4128.070035494291, 3859.6185349684497, 4098.815354567308, 4630.046626164363, 4083.03276179387, 4161.817180926983, 4119.5279212364785, 4089.3033541165864, 4284.989469088041, 4090.5845336914062, 4021.89157808744, 4009.0834303635816, 4155.287959172176, 4141.036006047176, 4179.9490309495195, 3980.411794809195, 3931.7941378079927, 4088.253178523137, 3875.2316237229566, 4014.033207820012, 4124.977698692908, 4150.096961388221, 4115.334435096154, 3925.2613290640024, 3883.981914813702, 4063.2042424128604, 4200.2706298828125, 4110.034719613882, 4092.4859619140625, 4133.8417405348555, 4028.662273700421, 3934.6983924278848], 'val_acc': [0.891343870988259, 0.8949334117082449, 0.8996024269324082, 0.9011742014151353, 0.9138383154685681, 0.9187684723964105, 0.9166836394713476, 0.9199057060938615, 0.9214127247150128, 0.9233473814450778, 0.9280371941052951, 0.9279562624601218, 0.9241817524799933, 0.929726793215825, 0.9279678463935852, 0.9309587547412286, 0.9316845696706039, 0.93023298566158, 0.9306305555196909, 0.9319873245862814, 0.9311714286987598, 0.9331384117786701, 0.9355052892978375, 0.9339335262775421, 0.9335706371527451, 0.9338665191943829, 0.9332354573103098, 0.9295673232812148, 0.9330436128836411, 0.9339889746445876, 0.9302838582258958, 0.9336515573354868, 0.9325397748213547, 0.9340629806885352, 0.933771740931731, 0.9362726463721349, 0.9330112590239599, 0.9354012539753547, 0.9323617930595691, 0.9338295253423544, 0.9348974021581503, 0.9351539153319138, 0.9338595339885125, 0.9393005669116974, 0.9356347047365628, 0.9404238989719977, 0.9363766885720767, 0.9367719109241779, 0.9351261922946343, 0.9361824943469121, 0.9342340116317456, 0.9375854982779577, 0.9360762009253869, 0.9389816247499906, 0.9353157098476703, 0.9373197234593905, 0.9407590398421655, 0.9372249520741976, 0.9389122541134174, 0.9387273673827832, 0.939806750187507, 0.9382743354027088, 0.9352163489048297, 0.9338734127007998, 0.935778028689898, 0.9398298836671389, 0.9391549504720248, 0.9422660905581254, 0.9379160243731278, 0.9364622028974386, 0.9368134897488815, 0.9394415433590229, 0.9344651423967801, 0.9361871458016909, 0.9414848135067866, 0.9381749377800868, 0.9378120417778308, 0.9387943698809698, 0.9409116346102494, 0.9404308612530048, 0.9404239287743201, 0.9386787918897775, 0.938639528476275, 0.9383113223772782, 0.9387666330887721, 0.940070276076977, 0.9392843704957229, 0.9421019966785724, 0.9400148208324726, 0.939129535968487, 0.9420141554795779, 0.9391018175161802, 0.9391942391028771, 0.9393236728814932, 0.9417229271852053, 0.9439187324964083], 'val_mDice': [0.18673037723279917, 0.284531715970773, 0.3205681818609054, 0.3540123514831066, 0.39393872767686844, 0.4228819746237535, 0.4361940650985791, 0.4483027939613049, 0.46017611427949023, 0.4752445713831828, 0.49201373068185955, 0.49809375634560216, 0.48579026013612747, 0.5041216978659997, 0.5004660544487146, 0.5214191692379805, 0.5179087972411742, 0.5232716695620463, 0.5257348785033593, 0.5286767585919454, 0.5297742784023285, 0.5337315545632288, 0.5345919722547898, 0.5344033166766167, 0.5377563599210519, 0.5377546268013808, 0.5408265057664651, 0.5316949142859533, 0.5368984931936631, 0.5520305080482593, 0.5302504719449923, 0.5543606074956747, 0.5462190560423411, 0.552994423187696, 0.5421508596493647, 0.5598906381772115, 0.5445024967193604, 0.556528774018471, 0.5473406074138788, 0.5542480687682445, 0.5594370021269872, 0.5579806382839496, 0.559758532505769, 0.5585518419169463, 0.5553010243635911, 0.5715810765440648, 0.5582558031265552, 0.5533862916322855, 0.556987654704314, 0.5645910954246154, 0.555710989695329, 0.5638168746462235, 0.5706246649989715, 0.5634442092134402, 0.5533188280577843, 0.565138018475129, 0.5726094108361465, 0.5631132317850223, 0.5745398780474296, 0.5692856019506087, 0.5678702524075141, 0.5595242730700053, 0.5567533683318359, 0.5423347892669531, 0.5606086537815057, 0.580796636067904, 0.5628554144730935, 0.5402698413683817, 0.5627313875235044, 0.5577735270445163, 0.5602615985732812, 0.5625528595768489, 0.5478975130961492, 0.5623606208425301, 0.5678526100057822, 0.5696487506994834, 0.5585030815922297, 0.5594168328321897, 0.5601331327970211, 0.5692860160309535, 0.5742269169825774, 0.5636266693472862, 0.5783589917879838, 0.5698972378785794, 0.5606648876116826, 0.5584592876526026, 0.562231254692261, 0.5755401471486459, 0.5780731393740728, 0.5662167823085418, 0.5560734521311063, 0.5603399193630769, 0.5634625685902742, 0.5614542674559814, 0.569191442659268, 0.5740163807685559], 'loss': [30553.145317102262, 13622.203678307362, 11332.224502694351, 9935.798400028929, 8799.574948154735, 7958.219616346844, 7275.499170579341, 6791.996987678903, 6440.353756005458, 6139.342108631073, 5857.124768378252, 5672.385950122451, 5441.07270975244, 5295.23166509085, 5123.543510889442, 4976.752881998683, 4868.764923199839, 4746.374614774329, 4699.839985476751, 4561.80311235053, 4516.971438541498, 4402.127404108552, 4315.880441546209, 4259.818626268009, 4188.7864566146145, 4123.343141269587, 4081.822067191787, 4013.442944326931, 3963.701134993847, 3907.6848052666105, 3868.162062935819, 3808.902035765352, 3791.1259992923683, 3740.1832828720503, 3704.1356717462986, 3668.97752008154, 3626.9445494226366, 3572.010800143598, 3558.6700753438276, 3547.198177690514, 3509.3352941287726, 3473.335854145892, 3454.8505586594065, 3427.1906477208618, 3385.524180875893, 3372.3828610331657, 3339.5694413685133, 3315.8600680864815, 3287.755979081136, 3270.1150115232213, 3251.0703651198137, 3226.413792105758, 3208.6790054576, 3186.5665759753556, 3165.8372583654022, 3152.0415384795165, 3145.1876589402077, 3132.1399652371488, 3084.1042854346374, 3066.8550360043814, 3045.0810188195655, 3020.6789136149728, 3029.4103972158737, 3016.9948032811526, 3004.3768310997193, 2990.5106081612093, 2982.147868622848, 2985.430503219693, 2949.9417370320643, 2919.438152929255, 2903.277262354781, 2886.718110557809, 2876.4634341716896, 2885.6909582498142, 2869.5637028817373, 2855.1829522701137, 2853.027577780956, 2856.536546397031, 2813.609822257159, 2822.1714326513215, 2796.0331951881217, 2797.540459356789, 2796.831300201599, 2778.004691167851, 2741.1234388892353, 2738.7204675179264, 2746.1704373330217, 2726.2977105787754, 2720.864290066622, 2728.588635171723, 2713.019373165399, 2699.489605627893, 2691.811304829981, 2674.0541006213325, 2686.931970168686, 2660.0349809744584], 'acc': [0.8543225990102089, 0.8665251285016378, 0.8728672651075673, 0.8804116135240315, 0.8899522868731382, 0.8982477633537297, 0.9040323796334284, 0.9077814299110599, 0.9105237822223499, 0.9127820638738237, 0.9148544550579676, 0.9160446245314329, 0.9174913473370264, 0.9183714563673101, 0.9197551256603479, 0.9206530115299424, 0.921648980099524, 0.9225026405100606, 0.9231081183222973, 0.9242029379162414, 0.924678141897283, 0.9253712745485937, 0.9262384354523998, 0.926605478853996, 0.9272978077853483, 0.9277221774039075, 0.9279286461233553, 0.9287675843625384, 0.928970235487769, 0.9297471275895127, 0.9299087178648854, 0.9303012748139707, 0.9307229640265513, 0.9312698854892597, 0.9314903615146153, 0.9319711095576774, 0.9322726804700207, 0.9325888629253418, 0.9329641026609731, 0.9330654888039617, 0.9333166447796637, 0.9337045049399102, 0.9339486108619569, 0.9342454645308931, 0.9346079999182614, 0.9350164330974228, 0.9348997982524807, 0.9352412091611574, 0.9356610582101986, 0.935958526632085, 0.936052013623212, 0.9361256857887137, 0.9363965098569613, 0.9365401898518398, 0.9368002616390579, 0.9369588645085257, 0.9371585461207886, 0.9372313931607721, 0.9375803418664335, 0.9378940839065152, 0.9380551692217597, 0.9382258528637554, 0.9382647148942547, 0.9382768195350265, 0.9386243508561977, 0.9386240854910199, 0.9389106284854136, 0.9388733144221156, 0.9392146389994313, 0.9392528366385093, 0.9394117941674321, 0.9396467428964673, 0.939584450210294, 0.9397761498134778, 0.9397755736114244, 0.939960065626146, 0.9400189932197659, 0.9399970907198815, 0.9404270034054928, 0.9404417241970837, 0.9406302739396852, 0.9407124787494836, 0.9404879915343762, 0.9407010650729315, 0.9411846489623982, 0.9411345665705311, 0.9411809242410457, 0.9413165815046086, 0.9413739307267766, 0.941279469441853, 0.9413281316622194, 0.9415486974930792, 0.9415864707809483, 0.9419020550184822, 0.9416893390418308, 0.941846916736695], 'mDice': [0.10253436351096203, 0.19746332290943705, 0.25209547868708804, 0.2938366715817679, 0.3334671692782021, 0.36737970748225185, 0.3975009212197715, 0.4207581808940188, 0.43898543798757483, 0.4550099627322776, 0.47100044957201587, 0.4814575452992785, 0.49476039236479996, 0.5037927027009438, 0.5141208708687571, 0.5231767146281515, 0.5304364506899074, 0.5385916002955723, 0.5421194432571806, 0.5512649106614366, 0.5545796943053893, 0.5623064177244954, 0.5683488949060023, 0.5726649188296135, 0.5774429766968873, 0.5824941185955894, 0.5853051446762338, 0.5908865674355808, 0.5944214446797732, 0.5988297477305446, 0.60173676688546, 0.6060929691110998, 0.607961599917844, 0.6115667267632003, 0.614347044297781, 0.6173599838858699, 0.6204888795691531, 0.6248279356773979, 0.6261802051303286, 0.6267187753847733, 0.6300649302181454, 0.6327733710046779, 0.6343571066548549, 0.6368462808741466, 0.6400082318652855, 0.6413219730143594, 0.6437652667356155, 0.6458033217304606, 0.6482980916126951, 0.6496510096529935, 0.6511750384515187, 0.6533004305057725, 0.6550775351839224, 0.6566971478334248, 0.6584288441562063, 0.6594673102108478, 0.6602420187475804, 0.6612834245321068, 0.6654218797873694, 0.6670089154888604, 0.6687110832374518, 0.6707942638847536, 0.6702063433701598, 0.6712376883875826, 0.6724664903287352, 0.6734853223726163, 0.6743717222188239, 0.6743332607592426, 0.6771349148656636, 0.6797690150824176, 0.681204070758415, 0.6826364430380321, 0.6834674076566526, 0.6827326649549998, 0.6842799965200483, 0.68547398199908, 0.68562581556085, 0.685496220177064, 0.6891827831670255, 0.6884736074827853, 0.690769240264247, 0.6905441281156304, 0.6905994906610617, 0.6923482603531179, 0.6956778689744804, 0.6958689194570814, 0.6953637714119049, 0.6970539750356268, 0.697650871373164, 0.6968822524104074, 0.6982798864895772, 0.6994092124398757, 0.7001805286241239, 0.7018747358956284, 0.7006485932847181, 0.7030128966857176]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.18s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.76s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:24,  1.36s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:46,  1.44s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:46,  1.44s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:07,  1.52s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<06:47,  1.45s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:01,  1.51s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:21,  1.59s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:30,  1.63s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:19,  1.59s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:44,  1.69s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:50,  1.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:59,  1.76s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<08:05,  1.79s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:04,  1.79s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:04,  1.79s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:06,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<08:07,  1.82s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<08:04,  1.82s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<08:02,  1.81s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<08:06,  1.84s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:04,  1.83s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<08:03,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<08:01,  1.84s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:52,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:55,  1.83s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:48,  1.81s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:44,  1.80s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:36,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:32,  1.77s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:30,  1.77s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:28,  1.76s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:28,  1.77s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:22,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:18,  1.75s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:15,  1.74s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:16,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:09,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:03,  1.71s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<06:59,  1.71s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<06:53,  1.69s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:54,  1.70s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:55,  1.71s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:55,  1.72s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<07:07,  1.78s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<06:50,  1.72s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:29,  1.64s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:21,  1.61s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:13,  1.58s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:03,  1.55s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<05:52,  1.51s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<05:48,  1.50s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<05:48,  1.50s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<05:43,  1.49s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<05:41,  1.48s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<05:35,  1.46s/it]predicting train subjects:  20%|██        | 57/285 [01:35<05:31,  1.45s/it]predicting train subjects:  20%|██        | 58/285 [01:37<05:30,  1.46s/it]predicting train subjects:  21%|██        | 59/285 [01:38<05:30,  1.46s/it]predicting train subjects:  21%|██        | 60/285 [01:40<05:33,  1.48s/it]predicting train subjects:  21%|██▏       | 61/285 [01:41<05:37,  1.50s/it]predicting train subjects:  22%|██▏       | 62/285 [01:43<05:36,  1.51s/it]predicting train subjects:  22%|██▏       | 63/285 [01:45<05:34,  1.50s/it]predicting train subjects:  22%|██▏       | 64/285 [01:46<05:33,  1.51s/it]predicting train subjects:  23%|██▎       | 65/285 [01:48<05:42,  1.56s/it]predicting train subjects:  23%|██▎       | 66/285 [01:49<05:47,  1.59s/it]predicting train subjects:  24%|██▎       | 67/285 [01:51<05:40,  1.56s/it]predicting train subjects:  24%|██▍       | 68/285 [01:52<05:31,  1.53s/it]predicting train subjects:  24%|██▍       | 69/285 [01:54<05:26,  1.51s/it]predicting train subjects:  25%|██▍       | 70/285 [01:55<05:30,  1.54s/it]predicting train subjects:  25%|██▍       | 71/285 [01:57<05:25,  1.52s/it]predicting train subjects:  25%|██▌       | 72/285 [01:58<05:24,  1.52s/it]predicting train subjects:  26%|██▌       | 73/285 [02:00<05:19,  1.51s/it]predicting train subjects:  26%|██▌       | 74/285 [02:01<05:14,  1.49s/it]predicting train subjects:  26%|██▋       | 75/285 [02:03<05:12,  1.49s/it]predicting train subjects:  27%|██▋       | 76/285 [02:04<05:10,  1.49s/it]predicting train subjects:  27%|██▋       | 77/285 [02:06<05:10,  1.49s/it]predicting train subjects:  27%|██▋       | 78/285 [02:07<05:08,  1.49s/it]predicting train subjects:  28%|██▊       | 79/285 [02:09<05:09,  1.50s/it]predicting train subjects:  28%|██▊       | 80/285 [02:10<05:08,  1.51s/it]predicting train subjects:  28%|██▊       | 81/285 [02:12<05:08,  1.51s/it]predicting train subjects:  29%|██▉       | 82/285 [02:13<05:05,  1.51s/it]predicting train subjects:  29%|██▉       | 83/285 [02:15<05:04,  1.51s/it]predicting train subjects:  29%|██▉       | 84/285 [02:16<05:04,  1.51s/it]predicting train subjects:  30%|██▉       | 85/285 [02:18<05:14,  1.57s/it]predicting train subjects:  30%|███       | 86/285 [02:20<05:25,  1.63s/it]predicting train subjects:  31%|███       | 87/285 [02:22<05:27,  1.65s/it]predicting train subjects:  31%|███       | 88/285 [02:23<05:28,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:25<05:28,  1.68s/it]predicting train subjects:  32%|███▏      | 90/285 [02:27<05:30,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:28<05:28,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:30<05:24,  1.68s/it]predicting train subjects:  33%|███▎      | 93/285 [02:32<05:21,  1.68s/it]predicting train subjects:  33%|███▎      | 94/285 [02:33<05:16,  1.66s/it]predicting train subjects:  33%|███▎      | 95/285 [02:35<05:13,  1.65s/it]predicting train subjects:  34%|███▎      | 96/285 [02:37<05:13,  1.66s/it]predicting train subjects:  34%|███▍      | 97/285 [02:38<05:14,  1.67s/it]predicting train subjects:  34%|███▍      | 98/285 [02:40<05:13,  1.68s/it]predicting train subjects:  35%|███▍      | 99/285 [02:42<05:13,  1.69s/it]predicting train subjects:  35%|███▌      | 100/285 [02:43<05:13,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:45<05:12,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:47<05:09,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:48<05:06,  1.68s/it]predicting train subjects:  36%|███▋      | 104/285 [02:50<05:03,  1.68s/it]predicting train subjects:  37%|███▋      | 105/285 [02:52<05:00,  1.67s/it]predicting train subjects:  37%|███▋      | 106/285 [02:53<04:57,  1.66s/it]predicting train subjects:  38%|███▊      | 107/285 [02:55<04:56,  1.67s/it]predicting train subjects:  38%|███▊      | 108/285 [02:57<04:54,  1.66s/it]predicting train subjects:  38%|███▊      | 109/285 [02:58<04:50,  1.65s/it]predicting train subjects:  39%|███▊      | 110/285 [03:00<04:49,  1.66s/it]predicting train subjects:  39%|███▉      | 111/285 [03:02<04:50,  1.67s/it]predicting train subjects:  39%|███▉      | 112/285 [03:03<04:44,  1.65s/it]predicting train subjects:  40%|███▉      | 113/285 [03:05<04:42,  1.64s/it]predicting train subjects:  40%|████      | 114/285 [03:07<04:40,  1.64s/it]predicting train subjects:  40%|████      | 115/285 [03:08<04:36,  1.63s/it]predicting train subjects:  41%|████      | 116/285 [03:10<04:35,  1.63s/it]predicting train subjects:  41%|████      | 117/285 [03:12<04:34,  1.63s/it]predicting train subjects:  41%|████▏     | 118/285 [03:13<04:33,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:15<04:32,  1.64s/it]predicting train subjects:  42%|████▏     | 120/285 [03:17<04:37,  1.68s/it]predicting train subjects:  42%|████▏     | 121/285 [03:18<04:27,  1.63s/it]predicting train subjects:  43%|████▎     | 122/285 [03:19<04:11,  1.54s/it]predicting train subjects:  43%|████▎     | 123/285 [03:21<03:58,  1.47s/it]predicting train subjects:  44%|████▎     | 124/285 [03:22<03:56,  1.47s/it]predicting train subjects:  44%|████▍     | 125/285 [03:24<03:56,  1.48s/it]predicting train subjects:  44%|████▍     | 126/285 [03:25<03:57,  1.50s/it]predicting train subjects:  45%|████▍     | 127/285 [03:27<03:55,  1.49s/it]predicting train subjects:  45%|████▍     | 128/285 [03:28<03:53,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:30<03:51,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:31<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 131/285 [03:33<03:51,  1.50s/it]predicting train subjects:  46%|████▋     | 132/285 [03:34<03:49,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:36<03:50,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [03:37<03:49,  1.52s/it]predicting train subjects:  47%|████▋     | 135/285 [03:39<03:46,  1.51s/it]predicting train subjects:  48%|████▊     | 136/285 [03:40<03:44,  1.50s/it]predicting train subjects:  48%|████▊     | 137/285 [03:42<03:42,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:43<03:42,  1.51s/it]predicting train subjects:  49%|████▉     | 139/285 [03:45<03:38,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [03:46<03:41,  1.53s/it]predicting train subjects:  49%|████▉     | 141/285 [03:48<03:36,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [03:49<03:27,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [03:50<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [03:52<03:15,  1.39s/it]predicting train subjects:  51%|█████     | 145/285 [03:53<03:12,  1.37s/it]predicting train subjects:  51%|█████     | 146/285 [03:54<03:09,  1.36s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:56<03:06,  1.35s/it]predicting train subjects:  52%|█████▏    | 148/285 [03:57<03:04,  1.35s/it]predicting train subjects:  52%|█████▏    | 149/285 [03:58<03:01,  1.34s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:00<02:59,  1.33s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:01<03:00,  1.35s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:03<02:59,  1.35s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:04<02:57,  1.35s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:05<02:54,  1.33s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:06<02:52,  1.32s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:08<02:49,  1.31s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:09<02:47,  1.31s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:10<02:46,  1.31s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:12<02:47,  1.33s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:13<02:46,  1.33s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:14<02:48,  1.36s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:16<02:44,  1.34s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:17<02:42,  1.33s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:18<02:41,  1.33s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:20<02:41,  1.34s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:21<02:40,  1.34s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:23<02:40,  1.36s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:24<02:37,  1.35s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:25<02:36,  1.35s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:27<02:40,  1.39s/it]predicting train subjects:  60%|██████    | 171/285 [04:28<02:37,  1.38s/it]predicting train subjects:  60%|██████    | 172/285 [04:29<02:33,  1.36s/it]predicting train subjects:  61%|██████    | 173/285 [04:31<02:30,  1.35s/it]predicting train subjects:  61%|██████    | 174/285 [04:32<02:27,  1.33s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:33<02:26,  1.34s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:35<02:27,  1.35s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:36<02:25,  1.35s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:37<02:21,  1.33s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:39<02:20,  1.32s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:40<02:17,  1.31s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:41<02:16,  1.31s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:43<02:14,  1.31s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:44<02:13,  1.31s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:45<02:12,  1.31s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:46<02:10,  1.30s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:48<02:08,  1.30s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:49<02:07,  1.30s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:50<02:04,  1.28s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:52<02:02,  1.28s/it]predicting train subjects:  67%|██████▋   | 190/285 [04:53<02:02,  1.29s/it]predicting train subjects:  67%|██████▋   | 191/285 [04:54<01:59,  1.28s/it]predicting train subjects:  67%|██████▋   | 192/285 [04:55<01:59,  1.29s/it]predicting train subjects:  68%|██████▊   | 193/285 [04:57<01:58,  1.28s/it]predicting train subjects:  68%|██████▊   | 194/285 [04:58<01:58,  1.30s/it]predicting train subjects:  68%|██████▊   | 195/285 [04:59<01:58,  1.32s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:01<02:02,  1.38s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:02<02:06,  1.43s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:04<02:08,  1.47s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:06<02:08,  1.49s/it]predicting train subjects:  70%|███████   | 200/285 [05:07<02:07,  1.50s/it]predicting train subjects:  71%|███████   | 201/285 [05:09<02:08,  1.53s/it]predicting train subjects:  71%|███████   | 202/285 [05:10<02:07,  1.53s/it]predicting train subjects:  71%|███████   | 203/285 [05:12<02:06,  1.55s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:13<02:05,  1.55s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:15<02:03,  1.54s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:16<02:01,  1.54s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:18<01:59,  1.53s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:19<01:57,  1.53s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:21<01:56,  1.54s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:23<01:55,  1.54s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:24<01:54,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:26<01:52,  1.55s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:27<01:51,  1.55s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:28<01:44,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:30<01:38,  1.41s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:31<01:34,  1.38s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:32<01:33,  1.37s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:34<01:30,  1.35s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:35<01:29,  1.35s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:36<01:28,  1.35s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:38<01:26,  1.35s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:39<01:25,  1.35s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:40<01:24,  1.36s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:42<01:22,  1.36s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:43<01:21,  1.35s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:45<01:19,  1.35s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:46<01:20,  1.38s/it]predicting train subjects:  80%|████████  | 228/285 [05:47<01:17,  1.36s/it]predicting train subjects:  80%|████████  | 229/285 [05:49<01:15,  1.35s/it]predicting train subjects:  81%|████████  | 230/285 [05:50<01:13,  1.34s/it]predicting train subjects:  81%|████████  | 231/285 [05:51<01:12,  1.35s/it]predicting train subjects:  81%|████████▏ | 232/285 [05:53<01:17,  1.47s/it]predicting train subjects:  82%|████████▏ | 233/285 [05:55<01:19,  1.52s/it]predicting train subjects:  82%|████████▏ | 234/285 [05:56<01:19,  1.56s/it]predicting train subjects:  82%|████████▏ | 235/285 [05:58<01:19,  1.60s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:00<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:01<01:18,  1.64s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:03<01:18,  1.66s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:05<01:15,  1.65s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:07<01:15,  1.68s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:08<01:13,  1.68s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:10<01:11,  1.67s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:12<01:10,  1.68s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:13<01:08,  1.67s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:15<01:07,  1.68s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:17<01:05,  1.68s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:18<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:20<01:01,  1.66s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:22<01:00,  1.67s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:23<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:24<00:49,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:25<00:46,  1.40s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:27<00:44,  1.38s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:28<00:42,  1.36s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:29<00:40,  1.35s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:31<00:38,  1.32s/it]predicting train subjects:  90%|█████████ | 257/285 [06:32<00:36,  1.30s/it]predicting train subjects:  91%|█████████ | 258/285 [06:33<00:34,  1.29s/it]predicting train subjects:  91%|█████████ | 259/285 [06:34<00:33,  1.29s/it]predicting train subjects:  91%|█████████ | 260/285 [06:36<00:32,  1.28s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:37<00:30,  1.27s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:38<00:29,  1.28s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:40<00:28,  1.29s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:41<00:26,  1.28s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:42<00:25,  1.27s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:43<00:24,  1.27s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:45<00:22,  1.27s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:46<00:23,  1.40s/it]predicting train subjects:  94%|█████████▍| 269/285 [06:48<00:23,  1.48s/it]predicting train subjects:  95%|█████████▍| 270/285 [06:50<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [06:51<00:21,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [06:53<00:21,  1.65s/it]predicting train subjects:  96%|█████████▌| 273/285 [06:55<00:20,  1.67s/it]predicting train subjects:  96%|█████████▌| 274/285 [06:56<00:18,  1.68s/it]predicting train subjects:  96%|█████████▋| 275/285 [06:58<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:00<00:15,  1.69s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:02<00:13,  1.70s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:03<00:11,  1.71s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:05<00:10,  1.71s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:07<00:08,  1.73s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:09<00:06,  1.75s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:10<00:05,  1.73s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:12<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:14<00:01,  1.72s/it]predicting train subjects: 100%|██████████| 285/285 [07:15<00:00,  1.69s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:35,  1.18s/it]Loading train:   1%|          | 2/285 [00:02<05:50,  1.24s/it]Loading train:   1%|          | 3/285 [00:03<05:46,  1.23s/it]Loading train:   1%|▏         | 4/285 [00:05<06:12,  1.32s/it]Loading train:   2%|▏         | 5/285 [00:06<05:43,  1.23s/it]Loading train:   2%|▏         | 6/285 [00:07<06:07,  1.32s/it]Loading train:   2%|▏         | 7/285 [00:09<06:31,  1.41s/it]Loading train:   3%|▎         | 8/285 [00:10<06:37,  1.43s/it]Loading train:   3%|▎         | 9/285 [00:12<06:20,  1.38s/it]Loading train:   4%|▎         | 10/285 [00:13<05:54,  1.29s/it]Loading train:   4%|▍         | 11/285 [00:14<05:31,  1.21s/it]Loading train:   4%|▍         | 12/285 [00:15<05:06,  1.12s/it]Loading train:   5%|▍         | 13/285 [00:16<04:50,  1.07s/it]Loading train:   5%|▍         | 14/285 [00:17<04:43,  1.05s/it]Loading train:   5%|▌         | 15/285 [00:18<04:29,  1.00it/s]Loading train:   6%|▌         | 16/285 [00:18<04:17,  1.04it/s]Loading train:   6%|▌         | 17/285 [00:19<04:16,  1.04it/s]Loading train:   6%|▋         | 18/285 [00:20<04:16,  1.04it/s]Loading train:   7%|▋         | 19/285 [00:21<04:11,  1.06it/s]Loading train:   7%|▋         | 20/285 [00:22<04:12,  1.05it/s]Loading train:   7%|▋         | 21/285 [00:23<04:12,  1.05it/s]Loading train:   8%|▊         | 22/285 [00:24<04:16,  1.02it/s]Loading train:   8%|▊         | 23/285 [00:25<04:22,  1.00s/it]Loading train:   8%|▊         | 24/285 [00:26<04:16,  1.02it/s]Loading train:   9%|▉         | 25/285 [00:27<04:20,  1.00s/it]Loading train:   9%|▉         | 26/285 [00:28<04:14,  1.02it/s]Loading train:   9%|▉         | 27/285 [00:29<04:11,  1.03it/s]Loading train:  10%|▉         | 28/285 [00:30<04:23,  1.03s/it]Loading train:  10%|█         | 29/285 [00:31<04:13,  1.01it/s]Loading train:  11%|█         | 30/285 [00:32<04:08,  1.03it/s]Loading train:  11%|█         | 31/285 [00:33<03:58,  1.06it/s]Loading train:  11%|█         | 32/285 [00:34<03:52,  1.09it/s]Loading train:  12%|█▏        | 33/285 [00:35<03:44,  1.12it/s]Loading train:  12%|█▏        | 34/285 [00:35<03:36,  1.16it/s]Loading train:  12%|█▏        | 35/285 [00:36<03:35,  1.16it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:35,  1.15it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:32,  1.17it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:36,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:37,  1.13it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:39,  1.12it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:38,  1.12it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:38,  1.11it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:42,  1.09it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:43,  1.08it/s]Loading train:  16%|█▌        | 45/285 [00:45<03:44,  1.07it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:38,  1.09it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:23,  1.17it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:15,  1.21it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:12,  1.23it/s]Loading train:  18%|█▊        | 50/285 [00:49<03:08,  1.24it/s]Loading train:  18%|█▊        | 51/285 [00:50<03:09,  1.23it/s]Loading train:  18%|█▊        | 52/285 [00:51<03:02,  1.28it/s]Loading train:  19%|█▊        | 53/285 [00:52<03:00,  1.29it/s]Loading train:  19%|█▉        | 54/285 [00:52<02:54,  1.32it/s]Loading train:  19%|█▉        | 55/285 [00:53<02:54,  1.32it/s]Loading train:  20%|█▉        | 56/285 [00:54<02:47,  1.37it/s]Loading train:  20%|██        | 57/285 [00:55<02:47,  1.36it/s]Loading train:  20%|██        | 58/285 [00:55<02:48,  1.35it/s]Loading train:  21%|██        | 59/285 [00:56<02:49,  1.34it/s]Loading train:  21%|██        | 60/285 [00:57<02:53,  1.30it/s]Loading train:  21%|██▏       | 61/285 [00:58<02:48,  1.33it/s]Loading train:  22%|██▏       | 62/285 [00:58<02:50,  1.31it/s]Loading train:  22%|██▏       | 63/285 [00:59<02:47,  1.32it/s]Loading train:  22%|██▏       | 64/285 [01:01<03:27,  1.07it/s]Loading train:  23%|██▎       | 65/285 [01:02<04:16,  1.16s/it]Loading train:  23%|██▎       | 66/285 [01:04<04:25,  1.21s/it]Loading train:  24%|██▎       | 67/285 [01:04<04:03,  1.12s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:41,  1.02s/it]Loading train:  24%|██▍       | 69/285 [01:06<03:27,  1.04it/s]Loading train:  25%|██▍       | 70/285 [01:07<03:16,  1.09it/s]Loading train:  25%|██▍       | 71/285 [01:08<03:06,  1.15it/s]Loading train:  25%|██▌       | 72/285 [01:08<03:02,  1.16it/s]Loading train:  26%|██▌       | 73/285 [01:09<02:55,  1.21it/s]Loading train:  26%|██▌       | 74/285 [01:10<02:50,  1.24it/s]Loading train:  26%|██▋       | 75/285 [01:11<02:51,  1.23it/s]Loading train:  27%|██▋       | 76/285 [01:12<02:50,  1.23it/s]Loading train:  27%|██▋       | 77/285 [01:13<02:56,  1.18it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:49,  1.22it/s]Loading train:  28%|██▊       | 79/285 [01:14<02:50,  1.21it/s]Loading train:  28%|██▊       | 80/285 [01:15<02:44,  1.25it/s]Loading train:  28%|██▊       | 81/285 [01:16<02:43,  1.25it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:44,  1.23it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:46,  1.21it/s]Loading train:  29%|██▉       | 84/285 [01:18<02:42,  1.24it/s]Loading train:  30%|██▉       | 85/285 [01:19<03:01,  1.10it/s]Loading train:  30%|███       | 86/285 [01:20<03:01,  1.10it/s]Loading train:  31%|███       | 87/285 [01:21<03:02,  1.08it/s]Loading train:  31%|███       | 88/285 [01:22<03:01,  1.09it/s]Loading train:  31%|███       | 89/285 [01:23<03:00,  1.08it/s]Loading train:  32%|███▏      | 90/285 [01:24<03:04,  1.06it/s]Loading train:  32%|███▏      | 91/285 [01:25<03:05,  1.05it/s]Loading train:  32%|███▏      | 92/285 [01:26<03:10,  1.01it/s]Loading train:  33%|███▎      | 93/285 [01:27<03:05,  1.03it/s]Loading train:  33%|███▎      | 94/285 [01:28<02:59,  1.06it/s]Loading train:  33%|███▎      | 95/285 [01:29<03:00,  1.05it/s]Loading train:  34%|███▎      | 96/285 [01:30<03:02,  1.03it/s]Loading train:  34%|███▍      | 97/285 [01:31<03:04,  1.02it/s]Loading train:  34%|███▍      | 98/285 [01:32<03:05,  1.01it/s]Loading train:  35%|███▍      | 99/285 [01:33<03:10,  1.02s/it]Loading train:  35%|███▌      | 100/285 [01:34<03:09,  1.02s/it]Loading train:  35%|███▌      | 101/285 [01:35<03:00,  1.02it/s]Loading train:  36%|███▌      | 102/285 [01:36<02:59,  1.02it/s]Loading train:  36%|███▌      | 103/285 [01:37<03:00,  1.01it/s]Loading train:  36%|███▋      | 104/285 [01:38<02:59,  1.01it/s]Loading train:  37%|███▋      | 105/285 [01:39<02:50,  1.05it/s]Loading train:  37%|███▋      | 106/285 [01:40<02:46,  1.07it/s]Loading train:  38%|███▊      | 107/285 [01:40<02:42,  1.10it/s]Loading train:  38%|███▊      | 108/285 [01:41<02:37,  1.13it/s]Loading train:  38%|███▊      | 109/285 [01:42<02:37,  1.12it/s]Loading train:  39%|███▊      | 110/285 [01:43<02:34,  1.13it/s]Loading train:  39%|███▉      | 111/285 [01:44<02:34,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:45<02:31,  1.14it/s]Loading train:  40%|███▉      | 113/285 [01:46<02:27,  1.16it/s]Loading train:  40%|████      | 114/285 [01:46<02:27,  1.16it/s]Loading train:  40%|████      | 115/285 [01:47<02:25,  1.16it/s]Loading train:  41%|████      | 116/285 [01:48<02:23,  1.17it/s]Loading train:  41%|████      | 117/285 [01:49<02:21,  1.18it/s]Loading train:  41%|████▏     | 118/285 [01:50<02:24,  1.15it/s]Loading train:  42%|████▏     | 119/285 [01:51<02:23,  1.15it/s]Loading train:  42%|████▏     | 120/285 [01:52<02:22,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:53<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [01:54<02:43,  1.01s/it]Loading train:  43%|████▎     | 123/285 [01:55<02:49,  1.05s/it]Loading train:  44%|████▎     | 124/285 [01:56<02:39,  1.01it/s]Loading train:  44%|████▍     | 125/285 [01:57<02:29,  1.07it/s]Loading train:  44%|████▍     | 126/285 [01:58<02:23,  1.10it/s]Loading train:  45%|████▍     | 127/285 [01:58<02:21,  1.12it/s]Loading train:  45%|████▍     | 128/285 [01:59<02:14,  1.17it/s]Loading train:  45%|████▌     | 129/285 [02:00<02:09,  1.21it/s]Loading train:  46%|████▌     | 130/285 [02:01<02:06,  1.22it/s]Loading train:  46%|████▌     | 131/285 [02:02<02:04,  1.24it/s]Loading train:  46%|████▋     | 132/285 [02:02<02:01,  1.26it/s]Loading train:  47%|████▋     | 133/285 [02:03<02:00,  1.27it/s]Loading train:  47%|████▋     | 134/285 [02:04<02:01,  1.25it/s]Loading train:  47%|████▋     | 135/285 [02:05<02:02,  1.23it/s]Loading train:  48%|████▊     | 136/285 [02:06<01:59,  1.24it/s]Loading train:  48%|████▊     | 137/285 [02:06<01:57,  1.26it/s]Loading train:  48%|████▊     | 138/285 [02:07<01:53,  1.30it/s]Loading train:  49%|████▉     | 139/285 [02:08<01:53,  1.29it/s]Loading train:  49%|████▉     | 140/285 [02:09<01:51,  1.30it/s]Loading train:  49%|████▉     | 141/285 [02:09<01:51,  1.29it/s]Loading train:  50%|████▉     | 142/285 [02:10<01:54,  1.25it/s]Loading train:  50%|█████     | 143/285 [02:11<01:48,  1.31it/s]Loading train:  51%|█████     | 144/285 [02:12<01:45,  1.34it/s]Loading train:  51%|█████     | 145/285 [02:12<01:42,  1.37it/s]Loading train:  51%|█████     | 146/285 [02:13<01:37,  1.42it/s]Loading train:  52%|█████▏    | 147/285 [02:14<01:36,  1.43it/s]Loading train:  52%|█████▏    | 148/285 [02:14<01:36,  1.41it/s]Loading train:  52%|█████▏    | 149/285 [02:15<01:33,  1.45it/s]Loading train:  53%|█████▎    | 150/285 [02:16<01:33,  1.45it/s]Loading train:  53%|█████▎    | 151/285 [02:16<01:33,  1.44it/s]Loading train:  53%|█████▎    | 152/285 [02:17<01:34,  1.40it/s]Loading train:  54%|█████▎    | 153/285 [02:18<01:33,  1.42it/s]Loading train:  54%|█████▍    | 154/285 [02:19<01:35,  1.37it/s]Loading train:  54%|█████▍    | 155/285 [02:19<01:34,  1.38it/s]Loading train:  55%|█████▍    | 156/285 [02:20<01:32,  1.39it/s]Loading train:  55%|█████▌    | 157/285 [02:21<01:29,  1.44it/s]Loading train:  55%|█████▌    | 158/285 [02:21<01:27,  1.45it/s]Loading train:  56%|█████▌    | 159/285 [02:22<01:26,  1.46it/s]Loading train:  56%|█████▌    | 160/285 [02:23<01:29,  1.40it/s]Loading train:  56%|█████▋    | 161/285 [02:24<01:31,  1.35it/s]Loading train:  57%|█████▋    | 162/285 [02:24<01:32,  1.33it/s]Loading train:  57%|█████▋    | 163/285 [02:25<01:30,  1.34it/s]Loading train:  58%|█████▊    | 164/285 [02:26<01:30,  1.34it/s]Loading train:  58%|█████▊    | 165/285 [02:27<01:30,  1.33it/s]Loading train:  58%|█████▊    | 166/285 [02:27<01:27,  1.36it/s]Loading train:  59%|█████▊    | 167/285 [02:28<01:26,  1.36it/s]Loading train:  59%|█████▉    | 168/285 [02:29<01:25,  1.37it/s]Loading train:  59%|█████▉    | 169/285 [02:30<01:22,  1.41it/s]Loading train:  60%|█████▉    | 170/285 [02:30<01:22,  1.39it/s]Loading train:  60%|██████    | 171/285 [02:31<01:22,  1.38it/s]Loading train:  60%|██████    | 172/285 [02:32<01:23,  1.35it/s]Loading train:  61%|██████    | 173/285 [02:32<01:22,  1.35it/s]Loading train:  61%|██████    | 174/285 [02:33<01:22,  1.34it/s]Loading train:  61%|██████▏   | 175/285 [02:34<01:23,  1.32it/s]Loading train:  62%|██████▏   | 176/285 [02:35<01:22,  1.32it/s]Loading train:  62%|██████▏   | 177/285 [02:36<01:22,  1.31it/s]Loading train:  62%|██████▏   | 178/285 [02:36<01:26,  1.24it/s]Loading train:  63%|██████▎   | 179/285 [02:37<01:22,  1.29it/s]Loading train:  63%|██████▎   | 180/285 [02:38<01:21,  1.29it/s]Loading train:  64%|██████▎   | 181/285 [02:39<01:17,  1.33it/s]Loading train:  64%|██████▍   | 182/285 [02:39<01:13,  1.40it/s]Loading train:  64%|██████▍   | 183/285 [02:40<01:13,  1.38it/s]Loading train:  65%|██████▍   | 184/285 [02:41<01:10,  1.42it/s]Loading train:  65%|██████▍   | 185/285 [02:41<01:06,  1.49it/s]Loading train:  65%|██████▌   | 186/285 [02:42<01:05,  1.50it/s]Loading train:  66%|██████▌   | 187/285 [02:43<01:06,  1.47it/s]Loading train:  66%|██████▌   | 188/285 [02:43<01:05,  1.49it/s]Loading train:  66%|██████▋   | 189/285 [02:44<01:03,  1.52it/s]Loading train:  67%|██████▋   | 190/285 [02:45<01:02,  1.52it/s]Loading train:  67%|██████▋   | 191/285 [02:45<01:01,  1.53it/s]Loading train:  67%|██████▋   | 192/285 [02:46<01:02,  1.49it/s]Loading train:  68%|██████▊   | 193/285 [02:47<01:00,  1.51it/s]Loading train:  68%|██████▊   | 194/285 [02:47<01:00,  1.50it/s]Loading train:  68%|██████▊   | 195/285 [02:48<01:00,  1.49it/s]Loading train:  69%|██████▉   | 196/285 [02:49<01:04,  1.38it/s]Loading train:  69%|██████▉   | 197/285 [02:50<01:06,  1.32it/s]Loading train:  69%|██████▉   | 198/285 [02:50<01:07,  1.29it/s]Loading train:  70%|██████▉   | 199/285 [02:51<01:06,  1.29it/s]Loading train:  70%|███████   | 200/285 [02:52<01:04,  1.32it/s]Loading train:  71%|███████   | 201/285 [02:53<01:05,  1.29it/s]Loading train:  71%|███████   | 202/285 [02:54<01:04,  1.29it/s]Loading train:  71%|███████   | 203/285 [02:54<01:01,  1.33it/s]Loading train:  72%|███████▏  | 204/285 [02:55<01:01,  1.31it/s]Loading train:  72%|███████▏  | 205/285 [02:56<01:01,  1.31it/s]Loading train:  72%|███████▏  | 206/285 [02:57<00:59,  1.32it/s]Loading train:  73%|███████▎  | 207/285 [02:57<01:00,  1.29it/s]Loading train:  73%|███████▎  | 208/285 [02:58<01:01,  1.26it/s]Loading train:  73%|███████▎  | 209/285 [02:59<01:00,  1.26it/s]Loading train:  74%|███████▎  | 210/285 [03:00<00:59,  1.25it/s]Loading train:  74%|███████▍  | 211/285 [03:00<00:57,  1.29it/s]Loading train:  74%|███████▍  | 212/285 [03:01<00:56,  1.30it/s]Loading train:  75%|███████▍  | 213/285 [03:02<00:54,  1.32it/s]Loading train:  75%|███████▌  | 214/285 [03:03<00:53,  1.32it/s]Loading train:  75%|███████▌  | 215/285 [03:03<00:51,  1.36it/s]Loading train:  76%|███████▌  | 216/285 [03:04<00:50,  1.38it/s]Loading train:  76%|███████▌  | 217/285 [03:05<00:48,  1.39it/s]Loading train:  76%|███████▋  | 218/285 [03:06<00:47,  1.41it/s]Loading train:  77%|███████▋  | 219/285 [03:06<00:47,  1.40it/s]Loading train:  77%|███████▋  | 220/285 [03:07<00:46,  1.39it/s]Loading train:  78%|███████▊  | 221/285 [03:08<00:46,  1.39it/s]Loading train:  78%|███████▊  | 222/285 [03:08<00:45,  1.39it/s]Loading train:  78%|███████▊  | 223/285 [03:09<00:43,  1.42it/s]Loading train:  79%|███████▊  | 224/285 [03:10<00:42,  1.45it/s]Loading train:  79%|███████▉  | 225/285 [03:10<00:41,  1.46it/s]Loading train:  79%|███████▉  | 226/285 [03:11<00:40,  1.47it/s]Loading train:  80%|███████▉  | 227/285 [03:12<00:39,  1.48it/s]Loading train:  80%|████████  | 228/285 [03:12<00:39,  1.43it/s]Loading train:  80%|████████  | 229/285 [03:13<00:39,  1.42it/s]Loading train:  81%|████████  | 230/285 [03:14<00:38,  1.44it/s]Loading train:  81%|████████  | 231/285 [03:15<00:38,  1.42it/s]Loading train:  81%|████████▏ | 232/285 [03:16<00:41,  1.29it/s]Loading train:  82%|████████▏ | 233/285 [03:16<00:41,  1.24it/s]Loading train:  82%|████████▏ | 234/285 [03:17<00:42,  1.20it/s]Loading train:  82%|████████▏ | 235/285 [03:18<00:42,  1.17it/s]Loading train:  83%|████████▎ | 236/285 [03:19<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [03:20<00:41,  1.16it/s]Loading train:  84%|████████▎ | 238/285 [03:21<00:41,  1.13it/s]Loading train:  84%|████████▍ | 239/285 [03:22<00:40,  1.12it/s]Loading train:  84%|████████▍ | 240/285 [03:23<00:40,  1.11it/s]Loading train:  85%|████████▍ | 241/285 [03:24<00:40,  1.10it/s]Loading train:  85%|████████▍ | 242/285 [03:25<00:39,  1.09it/s]Loading train:  85%|████████▌ | 243/285 [03:26<00:38,  1.09it/s]Loading train:  86%|████████▌ | 244/285 [03:27<00:38,  1.06it/s]Loading train:  86%|████████▌ | 245/285 [03:28<00:38,  1.04it/s]Loading train:  86%|████████▋ | 246/285 [03:28<00:37,  1.04it/s]Loading train:  87%|████████▋ | 247/285 [03:29<00:36,  1.04it/s]Loading train:  87%|████████▋ | 248/285 [03:30<00:35,  1.06it/s]Loading train:  87%|████████▋ | 249/285 [03:31<00:33,  1.08it/s]Loading train:  88%|████████▊ | 250/285 [03:32<00:29,  1.17it/s]Loading train:  88%|████████▊ | 251/285 [03:33<00:27,  1.25it/s]Loading train:  88%|████████▊ | 252/285 [03:33<00:24,  1.32it/s]Loading train:  89%|████████▉ | 253/285 [03:34<00:23,  1.36it/s]Loading train:  89%|████████▉ | 254/285 [03:35<00:22,  1.37it/s]Loading train:  89%|████████▉ | 255/285 [03:35<00:21,  1.38it/s]Loading train:  90%|████████▉ | 256/285 [03:36<00:21,  1.37it/s]Loading train:  90%|█████████ | 257/285 [03:37<00:20,  1.38it/s]Loading train:  91%|█████████ | 258/285 [03:38<00:19,  1.40it/s]Loading train:  91%|█████████ | 259/285 [03:38<00:18,  1.43it/s]Loading train:  91%|█████████ | 260/285 [03:39<00:17,  1.41it/s]Loading train:  92%|█████████▏| 261/285 [03:40<00:16,  1.41it/s]Loading train:  92%|█████████▏| 262/285 [03:40<00:16,  1.42it/s]Loading train:  92%|█████████▏| 263/285 [03:41<00:15,  1.42it/s]Loading train:  93%|█████████▎| 264/285 [03:42<00:14,  1.44it/s]Loading train:  93%|█████████▎| 265/285 [03:42<00:14,  1.40it/s]Loading train:  93%|█████████▎| 266/285 [03:43<00:13,  1.38it/s]Loading train:  94%|█████████▎| 267/285 [03:44<00:12,  1.40it/s]Loading train:  94%|█████████▍| 268/285 [03:45<00:14,  1.20it/s]Loading train:  94%|█████████▍| 269/285 [03:46<00:13,  1.19it/s]Loading train:  95%|█████████▍| 270/285 [03:47<00:12,  1.16it/s]Loading train:  95%|█████████▌| 271/285 [03:48<00:12,  1.16it/s]Loading train:  95%|█████████▌| 272/285 [03:49<00:11,  1.15it/s]Loading train:  96%|█████████▌| 273/285 [03:49<00:10,  1.17it/s]Loading train:  96%|█████████▌| 274/285 [03:50<00:09,  1.13it/s]Loading train:  96%|█████████▋| 275/285 [03:51<00:08,  1.13it/s]Loading train:  97%|█████████▋| 276/285 [03:52<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [03:53<00:06,  1.16it/s]Loading train:  98%|█████████▊| 278/285 [03:54<00:06,  1.14it/s]Loading train:  98%|█████████▊| 279/285 [03:55<00:05,  1.14it/s]Loading train:  98%|█████████▊| 280/285 [03:56<00:04,  1.13it/s]Loading train:  99%|█████████▊| 281/285 [03:57<00:03,  1.11it/s]Loading train:  99%|█████████▉| 282/285 [03:57<00:02,  1.08it/s]Loading train:  99%|█████████▉| 283/285 [03:58<00:01,  1.09it/s]Loading train: 100%|█████████▉| 284/285 [03:59<00:00,  1.09it/s]Loading train: 100%|██████████| 285/285 [04:00<00:00,  1.06it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:01, 176.88it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:01, 157.55it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:01, 166.73it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:01, 176.33it/s]concatenating: train:  32%|███▏      | 92/285 [00:00<00:01, 181.71it/s]concatenating: train:  41%|████      | 116/285 [00:00<00:00, 195.41it/s]concatenating: train:  48%|████▊     | 138/285 [00:00<00:00, 202.00it/s]concatenating: train:  58%|█████▊    | 164/285 [00:00<00:00, 215.34it/s]concatenating: train:  67%|██████▋   | 190/285 [00:00<00:00, 226.98it/s]concatenating: train:  76%|███████▌  | 216/285 [00:01<00:00, 234.01it/s]concatenating: train:  84%|████████▍ | 240/285 [00:01<00:00, 235.22it/s]concatenating: train:  93%|█████████▎| 264/285 [00:01<00:00, 220.85it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 216.49it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.23s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.23s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 177.34it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-07 03:11:54.446966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 03:11:54.447073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 03:11:54.447088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 03:11:54.447097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 03:11:54.447547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 18s - loss: 11264.6255 - acc: 0.8499 - mDice: 0.1986 - val_loss: 5993.8310 - val_acc: 0.9009 - val_mDice: 0.3014

Epoch 00001: val_mDice improved from -inf to 0.30137, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 9s - loss: 5331.2567 - acc: 0.8732 - mDice: 0.3539 - val_loss: 4329.1613 - val_acc: 0.9126 - val_mDice: 0.3956

Epoch 00002: val_mDice improved from 0.30137 to 0.39556, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 4178.3703 - acc: 0.8898 - mDice: 0.4352 - val_loss: 3947.4153 - val_acc: 0.9197 - val_mDice: 0.4300

Epoch 00003: val_mDice improved from 0.39556 to 0.42996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 3658.2075 - acc: 0.9009 - mDice: 0.4804 - val_loss: 3690.9791 - val_acc: 0.9263 - val_mDice: 0.4501

Epoch 00004: val_mDice improved from 0.42996 to 0.45013, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 3326.7688 - acc: 0.9080 - mDice: 0.5125 - val_loss: 3446.9498 - val_acc: 0.9268 - val_mDice: 0.4729

Epoch 00005: val_mDice improved from 0.45013 to 0.47290, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 3094.2429 - acc: 0.9126 - mDice: 0.5364 - val_loss: 3306.3645 - val_acc: 0.9295 - val_mDice: 0.4841

Epoch 00006: val_mDice improved from 0.47290 to 0.48406, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 2895.8515 - acc: 0.9164 - mDice: 0.5574 - val_loss: 3144.4927 - val_acc: 0.9283 - val_mDice: 0.5026

Epoch 00007: val_mDice improved from 0.48406 to 0.50260, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 9s - loss: 2748.3138 - acc: 0.9194 - mDice: 0.5738 - val_loss: 3085.1709 - val_acc: 0.9341 - val_mDice: 0.5069

Epoch 00008: val_mDice improved from 0.50260 to 0.50687, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 10s - loss: 2623.9220 - acc: 0.9218 - mDice: 0.5882 - val_loss: 3044.4565 - val_acc: 0.9360 - val_mDice: 0.5103

Epoch 00009: val_mDice improved from 0.50687 to 0.51034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 2525.5971 - acc: 0.9238 - mDice: 0.5999 - val_loss: 2863.4117 - val_acc: 0.9356 - val_mDice: 0.5314

Epoch 00010: val_mDice improved from 0.51034 to 0.53144, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 2432.0007 - acc: 0.9255 - mDice: 0.6111 - val_loss: 2838.6495 - val_acc: 0.9345 - val_mDice: 0.5356

Epoch 00011: val_mDice improved from 0.53144 to 0.53562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 2372.7466 - acc: 0.9269 - mDice: 0.6181 - val_loss: 2876.0695 - val_acc: 0.9351 - val_mDice: 0.5295

Epoch 00012: val_mDice did not improve from 0.53562
Epoch 13/300
 - 9s - loss: 2285.2993 - acc: 0.9286 - mDice: 0.6293 - val_loss: 2759.6186 - val_acc: 0.9417 - val_mDice: 0.5424

Epoch 00013: val_mDice improved from 0.53562 to 0.54237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 9s - loss: 2246.6636 - acc: 0.9295 - mDice: 0.6342 - val_loss: 2737.3918 - val_acc: 0.9401 - val_mDice: 0.5441

Epoch 00014: val_mDice improved from 0.54237 to 0.54407, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 9s - loss: 2184.0265 - acc: 0.9308 - mDice: 0.6423 - val_loss: 2848.1087 - val_acc: 0.9327 - val_mDice: 0.5336

Epoch 00015: val_mDice did not improve from 0.54407
Epoch 16/300
 - 9s - loss: 2122.6540 - acc: 0.9318 - mDice: 0.6499 - val_loss: 2781.6149 - val_acc: 0.9438 - val_mDice: 0.5390

Epoch 00016: val_mDice did not improve from 0.54407
Epoch 17/300
 - 9s - loss: 2078.3886 - acc: 0.9328 - mDice: 0.6559 - val_loss: 2812.2233 - val_acc: 0.9431 - val_mDice: 0.5375

Epoch 00017: val_mDice did not improve from 0.54407
Epoch 18/300
 - 9s - loss: 2044.7928 - acc: 0.9334 - mDice: 0.6603 - val_loss: 2680.6311 - val_acc: 0.9408 - val_mDice: 0.5507

Epoch 00018: val_mDice improved from 0.54407 to 0.55069, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 9s - loss: 1988.9711 - acc: 0.9345 - mDice: 0.6676 - val_loss: 2713.4148 - val_acc: 0.9430 - val_mDice: 0.5485

Epoch 00019: val_mDice did not improve from 0.55069
Epoch 20/300
 - 9s - loss: 1961.6188 - acc: 0.9351 - mDice: 0.6713 - val_loss: 2715.3718 - val_acc: 0.9427 - val_mDice: 0.5469

Epoch 00020: val_mDice did not improve from 0.55069
Epoch 21/300
 - 9s - loss: 1940.2153 - acc: 0.9356 - mDice: 0.6742 - val_loss: 2771.0273 - val_acc: 0.9457 - val_mDice: 0.5410

Epoch 00021: val_mDice did not improve from 0.55069
Epoch 22/300
 - 9s - loss: 1900.9407 - acc: 0.9365 - mDice: 0.6795 - val_loss: 2596.9426 - val_acc: 0.9447 - val_mDice: 0.5592

Epoch 00022: val_mDice improved from 0.55069 to 0.55916, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 9s - loss: 1884.8914 - acc: 0.9367 - mDice: 0.6818 - val_loss: 2627.3536 - val_acc: 0.9447 - val_mDice: 0.5542

Epoch 00023: val_mDice did not improve from 0.55916
Epoch 24/300
 - 9s - loss: 1852.6671 - acc: 0.9374 - mDice: 0.6861 - val_loss: 2727.8422 - val_acc: 0.9458 - val_mDice: 0.5475

Epoch 00024: val_mDice did not improve from 0.55916
Epoch 25/300
 - 9s - loss: 1820.8458 - acc: 0.9379 - mDice: 0.6905 - val_loss: 2722.7857 - val_acc: 0.9467 - val_mDice: 0.5445

Epoch 00025: val_mDice did not improve from 0.55916
Epoch 26/300
 - 9s - loss: 1803.3343 - acc: 0.9383 - mDice: 0.6930 - val_loss: 2761.4022 - val_acc: 0.9405 - val_mDice: 0.5426

Epoch 00026: val_mDice did not improve from 0.55916
Epoch 27/300
 - 9s - loss: 1782.3317 - acc: 0.9387 - mDice: 0.6959 - val_loss: 2882.3060 - val_acc: 0.9445 - val_mDice: 0.5257

Epoch 00027: val_mDice did not improve from 0.55916
Epoch 28/300
 - 9s - loss: 1773.2887 - acc: 0.9389 - mDice: 0.6972 - val_loss: 2744.7892 - val_acc: 0.9459 - val_mDice: 0.5392

Epoch 00028: val_mDice did not improve from 0.55916
Epoch 29/300
 - 9s - loss: 1732.7380 - acc: 0.9397 - mDice: 0.7028 - val_loss: 2749.6021 - val_acc: 0.9474 - val_mDice: 0.5414

Epoch 00029: val_mDice did not improve from 0.55916
Epoch 30/300
 - 9s - loss: 1724.9204 - acc: 0.9400 - mDice: 0.7039 - val_loss: 2755.0078 - val_acc: 0.9448 - val_mDice: 0.5401

Epoch 00030: val_mDice did not improve from 0.55916
Epoch 31/300
 - 9s - loss: 1701.1107 - acc: 0.9405 - mDice: 0.7074 - val_loss: 2719.9767 - val_acc: 0.9465 - val_mDice: 0.5456

Epoch 00031: val_mDice did not improve from 0.55916
Epoch 32/300
 - 9s - loss: 1678.1400 - acc: 0.9410 - mDice: 0.7106 - val_loss: 3133.9798 - val_acc: 0.9438 - val_mDice: 0.4964

Epoch 00032: val_mDice did not improve from 0.55916
Epoch 33/300
 - 9s - loss: 1662.9708 - acc: 0.9412 - mDice: 0.7127 - val_loss: 2849.6821 - val_acc: 0.9476 - val_mDice: 0.5273

Epoch 00033: val_mDice did not improve from 0.55916
Epoch 34/300
 - 9s - loss: 1647.9581 - acc: 0.9416 - mDice: 0.7149 - val_loss: 2807.2221 - val_acc: 0.9473 - val_mDice: 0.5316

Epoch 00034: val_mDice did not improve from 0.55916
Epoch 35/300
 - 9s - loss: 1634.7128 - acc: 0.9417 - mDice: 0.7168 - val_loss: 2708.6054 - val_acc: 0.9466 - val_mDice: 0.5482

Epoch 00035: val_mDice did not improve from 0.55916
Epoch 36/300
 - 9s - loss: 1611.5811 - acc: 0.9422 - mDice: 0.7202 - val_loss: 2757.3533 - val_acc: 0.9457 - val_mDice: 0.5409

Epoch 00036: val_mDice did not improve from 0.55916
Epoch 37/300
 - 9s - loss: 1604.4233 - acc: 0.9422 - mDice: 0.7211 - val_loss: 2765.9633 - val_acc: 0.9460 - val_mDice: 0.5383

Epoch 00037: val_mDice did not improve from 0.55916
Epoch 38/300
 - 9s - loss: 1586.6725 - acc: 0.9427 - mDice: 0.7237 - val_loss: 2709.2776 - val_acc: 0.9443 - val_mDice: 0.5454

Epoch 00038: val_mDice did not improve from 0.55916
Epoch 39/300
 - 9s - loss: 1570.7924 - acc: 0.9432 - mDice: 0.7261 - val_loss: 2827.9229 - val_acc: 0.9447 - val_mDice: 0.5336

Epoch 00039: val_mDice did not improve from 0.55916
Epoch 40/300
 - 9s - loss: 1554.9702 - acc: 0.9433 - mDice: 0.7284 - val_loss: 2827.0686 - val_acc: 0.9456 - val_mDice: 0.5310

Epoch 00040: val_mDice did not improve from 0.55916
Epoch 41/300
 - 9s - loss: 1541.4967 - acc: 0.9437 - mDice: 0.7304 - val_loss: 2747.8659 - val_acc: 0.9479 - val_mDice: 0.5444

Epoch 00041: val_mDice did not improve from 0.55916
Epoch 42/300
 - 9s - loss: 1528.1453 - acc: 0.9440 - mDice: 0.7323 - val_loss: 3022.2418 - val_acc: 0.9461 - val_mDice: 0.5099

Epoch 00042: val_mDice did not improve from 0.55916
Epoch 43/300
 - 9s - loss: 1523.3024 - acc: 0.9439 - mDice: 0.7330 - val_loss: 2974.9256 - val_acc: 0.9470 - val_mDice: 0.5178

Epoch 00043: val_mDice did not improve from 0.55916
Epoch 44/300
 - 9s - loss: 1496.0196 - acc: 0.9445 - mDice: 0.7370 - val_loss: 2637.6157 - val_acc: 0.9465 - val_mDice: 0.5519

Epoch 00044: val_mDice did not improve from 0.55916
Epoch 45/300
 - 9s - loss: 1490.5618 - acc: 0.9447 - mDice: 0.7379 - val_loss: 2702.8950 - val_acc: 0.9483 - val_mDice: 0.5466

Epoch 00045: val_mDice did not improve from 0.55916
Epoch 46/300
 - 9s - loss: 1480.0952 - acc: 0.9449 - mDice: 0.7395 - val_loss: 2814.7988 - val_acc: 0.9496 - val_mDice: 0.5358

Epoch 00046: val_mDice did not improve from 0.55916
Epoch 47/300
 - 9s - loss: 1460.0270 - acc: 0.9453 - mDice: 0.7424 - val_loss: 2731.0482 - val_acc: 0.9471 - val_mDice: 0.5416

Epoch 00047: val_mDice did not improve from 0.55916
Epoch 48/300
 - 9s - loss: 1454.1746 - acc: 0.9453 - mDice: 0.7432 - val_loss: 2682.3808 - val_acc: 0.9469 - val_mDice: 0.5487

Epoch 00048: val_mDice did not improve from 0.55916
Epoch 49/300
 - 9s - loss: 1450.1173 - acc: 0.9454 - mDice: 0.7438 - val_loss: 2646.9587 - val_acc: 0.9473 - val_mDice: 0.5528

Epoch 00049: val_mDice did not improve from 0.55916
Epoch 50/300
 - 9s - loss: 1439.2979 - acc: 0.9455 - mDice: 0.7455 - val_loss: 2842.8944 - val_acc: 0.9470 - val_mDice: 0.5299

Epoch 00050: val_mDice did not improve from 0.55916
Epoch 51/300
 - 9s - loss: 1424.9270 - acc: 0.9459 - mDice: 0.7476 - val_loss: 3035.3110 - val_acc: 0.9474 - val_mDice: 0.5103

Epoch 00051: val_mDice did not improve from 0.55916
Epoch 52/300
 - 9s - loss: 1423.5380 - acc: 0.9458 - mDice: 0.7479 - val_loss: 3063.2801 - val_acc: 0.9472 - val_mDice: 0.5095

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.05s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:27,  1.36s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:47,  1.44s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:50,  1.46s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:02,  1.51s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:38,  1.64s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:59,  1.73s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:09,  1.77s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:46,  1.69s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:00,  1.75s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:11,  1.79s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:13,  1.81s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:22,  1.85s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:28,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:32,  1.90s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:28,  1.89s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:30,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:27,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:25,  1.90s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:32,  1.93s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:30,  1.93s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:26,  1.93s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:28,  1.94s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<08:24,  1.93s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:21,  1.93s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:22,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:17,  1.93s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:13,  1.92s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:09,  1.91s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:09,  1.92s/it]predicting train subjects:  11%|█         | 31/285 [00:57<07:58,  1.88s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:55,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:52,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:43,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:40,  1.84s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:40,  1.85s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:39,  1.85s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:36,  1.85s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:33,  1.84s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:32,  1.85s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:29,  1.85s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:29,  1.86s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:25,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:18,  1.83s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:01,  1.76s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<06:39,  1.68s/it]predicting train subjects:  17%|█▋        | 48/285 [01:27<06:24,  1.62s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<06:18,  1.60s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<06:11,  1.58s/it]predicting train subjects:  18%|█▊        | 51/285 [01:32<06:06,  1.57s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<06:04,  1.56s/it]predicting train subjects:  19%|█▊        | 53/285 [01:35<06:02,  1.56s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<05:55,  1.54s/it]predicting train subjects:  19%|█▉        | 55/285 [01:38<05:54,  1.54s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<05:54,  1.55s/it]predicting train subjects:  20%|██        | 57/285 [01:41<05:55,  1.56s/it]predicting train subjects:  20%|██        | 58/285 [01:42<05:53,  1.56s/it]predicting train subjects:  21%|██        | 59/285 [01:44<05:50,  1.55s/it]predicting train subjects:  21%|██        | 60/285 [01:46<05:49,  1.55s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<05:47,  1.55s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<05:45,  1.55s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<05:47,  1.56s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<05:50,  1.59s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:08,  1.68s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:10,  1.69s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:04,  1.67s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<05:58,  1.65s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<05:56,  1.65s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<05:56,  1.66s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<05:49,  1.63s/it]predicting train subjects:  25%|██▌       | 72/285 [02:05<05:46,  1.63s/it]predicting train subjects:  26%|██▌       | 73/285 [02:07<05:49,  1.65s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<05:46,  1.64s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<05:40,  1.62s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<05:37,  1.61s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:41,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:45,  1.67s/it]predicting train subjects:  28%|██▊       | 79/285 [02:17<05:48,  1.69s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:42,  1.67s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:39,  1.66s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:35,  1.66s/it]predicting train subjects:  29%|██▉       | 84/285 [02:25<05:35,  1.67s/it]predicting train subjects:  30%|██▉       | 85/285 [02:27<05:47,  1.74s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:54,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:55,  1.79s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:59,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:35<06:01,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<06:01,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<06:01,  1.86s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:59,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:58,  1.87s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:54,  1.86s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:51,  1.85s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:53,  1.87s/it]predicting train subjects:  34%|███▍      | 97/285 [02:50<05:51,  1.87s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:49,  1.87s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:46,  1.86s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:42,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [02:57<05:39,  1.85s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:38,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:01<05:32,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:29,  1.82s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:23,  1.80s/it]predicting train subjects:  37%|███▋      | 106/285 [03:06<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:08<05:15,  1.77s/it]predicting train subjects:  38%|███▊      | 108/285 [03:09<05:12,  1.77s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<05:09,  1.76s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:07,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:15<05:04,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<05:03,  1.76s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<05:01,  1.76s/it]predicting train subjects:  40%|████      | 114/285 [03:20<05:00,  1.75s/it]predicting train subjects:  40%|████      | 115/285 [03:22<04:58,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:23<04:56,  1.75s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:54,  1.76s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:53,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:51,  1.76s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:50,  1.76s/it]predicting train subjects:  42%|████▏     | 121/285 [03:32<04:43,  1.73s/it]predicting train subjects:  43%|████▎     | 122/285 [03:33<04:29,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:35<04:15,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:36<04:14,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:15,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:40<04:15,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<04:12,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:43<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:45<04:11,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [03:46<04:11,  1.62s/it]predicting train subjects:  46%|████▌     | 131/285 [03:48<04:07,  1.61s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<04:06,  1.61s/it]predicting train subjects:  47%|████▋     | 133/285 [03:51<04:05,  1.61s/it]predicting train subjects:  47%|████▋     | 134/285 [03:53<04:07,  1.64s/it]predicting train subjects:  47%|████▋     | 135/285 [03:54<04:04,  1.63s/it]predicting train subjects:  48%|████▊     | 136/285 [03:56<03:59,  1.61s/it]predicting train subjects:  48%|████▊     | 137/285 [03:57<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [03:59<03:53,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:01<03:51,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [04:02<03:50,  1.59s/it]predicting train subjects:  49%|████▉     | 141/285 [04:04<03:48,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:05<03:40,  1.54s/it]predicting train subjects:  50%|█████     | 143/285 [04:07<03:34,  1.51s/it]predicting train subjects:  51%|█████     | 144/285 [04:08<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:09<03:22,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [04:11<03:18,  1.43s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:12<03:16,  1.42s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:14<03:13,  1.41s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:15<03:11,  1.41s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:17<03:12,  1.42s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:18<03:11,  1.43s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:19<03:09,  1.43s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:21<03:08,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:22<03:07,  1.43s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:24<03:05,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:25<03:04,  1.43s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:27<03:02,  1.43s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:28<03:01,  1.43s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:29<03:00,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:31<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:32<02:56,  1.42s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:34<02:55,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:35<02:53,  1.42s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:36<02:50,  1.41s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:38<02:45,  1.38s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:39<02:46,  1.40s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<02:43,  1.39s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:42<02:42,  1.39s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:43<02:42,  1.40s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:45<02:42,  1.41s/it]predicting train subjects:  60%|██████    | 171/285 [04:46<02:40,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:48<02:36,  1.39s/it]predicting train subjects:  61%|██████    | 173/285 [04:49<02:35,  1.38s/it]predicting train subjects:  61%|██████    | 174/285 [04:50<02:37,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:52<02:36,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:53<02:35,  1.43s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:55<02:35,  1.44s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:56<02:34,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:32,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:59<02:29,  1.42s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:00<02:26,  1.41s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:02<02:24,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:03<02:23,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:21,  1.40s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:06<02:19,  1.40s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:07<02:17,  1.39s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:09<02:15,  1.38s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:10<02:11,  1.36s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:11<02:10,  1.36s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:13<02:08,  1.35s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:14<02:05,  1.34s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:15<02:04,  1.34s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:17<02:03,  1.34s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:18<02:02,  1.34s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:19<02:00,  1.34s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:21<02:07,  1.43s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:23<02:11,  1.50s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:24<02:13,  1.53s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:26<02:12,  1.55s/it]predicting train subjects:  70%|███████   | 200/285 [05:28<02:14,  1.59s/it]predicting train subjects:  71%|███████   | 201/285 [05:29<02:15,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:31<02:16,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:33<02:15,  1.65s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:34<02:13,  1.65s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:36<02:12,  1.66s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:38<02:11,  1.67s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:39<02:11,  1.68s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:41<02:09,  1.68s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:43<02:05,  1.65s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:44<02:03,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:46<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:47<01:58,  1.63s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:49<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:51<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:52<01:48,  1.56s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:54<01:47,  1.56s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:55<01:45,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:57<01:44,  1.56s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:58<01:42,  1.55s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:00<01:39,  1.54s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:01<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:03<01:34,  1.50s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:04<01:33,  1.51s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:06<01:30,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:07<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:28,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:10<01:25,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:12<01:24,  1.48s/it]predicting train subjects:  80%|████████  | 229/285 [06:13<01:22,  1.47s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:21,  1.49s/it]predicting train subjects:  81%|████████  | 231/285 [06:16<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:18<01:25,  1.62s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:20<01:28,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:22<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:24<01:30,  1.81s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:26<01:30,  1.84s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:28<01:29,  1.85s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:29<01:27,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:31<01:25,  1.87s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:33<01:23,  1.86s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:35<01:22,  1.87s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:37<01:20,  1.87s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:39<01:19,  1.89s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:41<01:17,  1.88s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:43<01:15,  1.89s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:44<01:12,  1.85s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:46<01:09,  1.82s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:48<01:07,  1.82s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:50<01:05,  1.83s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:51<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:53<00:54,  1.59s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:54<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:55<00:46,  1.47s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:57<00:44,  1.43s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:58<00:42,  1.43s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:59<00:41,  1.43s/it]predicting train subjects:  90%|█████████ | 257/285 [07:01<00:40,  1.45s/it]predicting train subjects:  91%|█████████ | 258/285 [07:02<00:38,  1.42s/it]predicting train subjects:  91%|█████████ | 259/285 [07:04<00:37,  1.42s/it]predicting train subjects:  91%|█████████ | 260/285 [07:05<00:35,  1.44s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:07<00:33,  1.42s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:08<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:09<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:11<00:29,  1.42s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:12<00:28,  1.41s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:14<00:26,  1.42s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:15<00:25,  1.42s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:17<00:26,  1.54s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:19<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:21<00:25,  1.70s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:22<00:24,  1.77s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:24<00:23,  1.81s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:26<00:21,  1.83s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:28<00:20,  1.86s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:30<00:18,  1.86s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:32<00:17,  1.89s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:34<00:15,  1.89s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:36<00:13,  1.88s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:38<00:11,  1.89s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:09,  1.88s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:41<00:07,  1.87s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:43<00:05,  1.86s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.87s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.90s/it]predicting train subjects: 100%|██████████| 285/285 [07:49<00:00,  1.91s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:57,  1.47s/it]Loading train:   1%|          | 2/285 [00:03<07:03,  1.50s/it]Loading train:   1%|          | 3/285 [00:04<06:58,  1.48s/it]Loading train:   1%|▏         | 4/285 [00:06<07:18,  1.56s/it]Loading train:   2%|▏         | 5/285 [00:07<07:06,  1.52s/it]Loading train:   2%|▏         | 6/285 [00:09<07:27,  1.61s/it]Loading train:   2%|▏         | 7/285 [00:11<07:56,  1.71s/it]Loading train:   3%|▎         | 8/285 [00:13<08:15,  1.79s/it]Loading train:   3%|▎         | 9/285 [00:14<07:53,  1.71s/it]Loading train:   4%|▎         | 10/285 [00:16<07:20,  1.60s/it]Loading train:   4%|▍         | 11/285 [00:17<06:58,  1.53s/it]Loading train:   4%|▍         | 12/285 [00:18<06:23,  1.41s/it]Loading train:   5%|▍         | 13/285 [00:20<06:18,  1.39s/it]Loading train:   5%|▍         | 14/285 [00:21<06:05,  1.35s/it]Loading train:   5%|▌         | 15/285 [00:22<05:50,  1.30s/it]Loading train:   6%|▌         | 16/285 [00:23<05:48,  1.29s/it]Loading train:   6%|▌         | 17/285 [00:25<05:45,  1.29s/it]Loading train:   6%|▋         | 18/285 [00:26<05:40,  1.28s/it]Loading train:   7%|▋         | 19/285 [00:27<05:37,  1.27s/it]Loading train:   7%|▋         | 20/285 [00:28<05:32,  1.25s/it]Loading train:   7%|▋         | 21/285 [00:30<05:39,  1.29s/it]Loading train:   8%|▊         | 22/285 [00:31<05:40,  1.30s/it]Loading train:   8%|▊         | 23/285 [00:32<05:26,  1.25s/it]Loading train:   8%|▊         | 24/285 [00:34<05:44,  1.32s/it]Loading train:   9%|▉         | 25/285 [00:35<05:37,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:36<05:31,  1.28s/it]Loading train:   9%|▉         | 27/285 [00:38<05:42,  1.33s/it]Loading train:  10%|▉         | 28/285 [00:39<05:39,  1.32s/it]Loading train:  10%|█         | 29/285 [00:40<05:22,  1.26s/it]Loading train:  11%|█         | 30/285 [00:41<05:13,  1.23s/it]Loading train:  11%|█         | 31/285 [00:42<05:05,  1.20s/it]Loading train:  11%|█         | 32/285 [00:43<05:00,  1.19s/it]Loading train:  12%|█▏        | 33/285 [00:44<04:52,  1.16s/it]Loading train:  12%|█▏        | 34/285 [00:46<04:47,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:47<04:39,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:48<04:34,  1.10s/it]Loading train:  13%|█▎        | 37/285 [00:49<04:31,  1.09s/it]Loading train:  13%|█▎        | 38/285 [00:50<04:31,  1.10s/it]Loading train:  14%|█▎        | 39/285 [00:51<04:40,  1.14s/it]Loading train:  14%|█▍        | 40/285 [00:52<04:26,  1.09s/it]Loading train:  14%|█▍        | 41/285 [00:53<04:37,  1.14s/it]Loading train:  15%|█▍        | 42/285 [00:54<04:31,  1.12s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:32,  1.13s/it]Loading train:  15%|█▌        | 44/285 [00:57<04:21,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:58<04:26,  1.11s/it]Loading train:  16%|█▌        | 46/285 [00:59<04:17,  1.08s/it]Loading train:  16%|█▋        | 47/285 [01:00<04:10,  1.05s/it]Loading train:  17%|█▋        | 48/285 [01:01<04:07,  1.04s/it]Loading train:  17%|█▋        | 49/285 [01:02<03:56,  1.00s/it]Loading train:  18%|█▊        | 50/285 [01:03<04:00,  1.02s/it]Loading train:  18%|█▊        | 51/285 [01:04<03:52,  1.01it/s]Loading train:  18%|█▊        | 52/285 [01:05<03:57,  1.02s/it]Loading train:  19%|█▊        | 53/285 [01:06<03:55,  1.02s/it]Loading train:  19%|█▉        | 54/285 [01:07<04:07,  1.07s/it]Loading train:  19%|█▉        | 55/285 [01:08<03:59,  1.04s/it]Loading train:  20%|█▉        | 56/285 [01:09<03:59,  1.04s/it]Loading train:  20%|██        | 57/285 [01:10<03:52,  1.02s/it]Loading train:  20%|██        | 58/285 [01:11<03:50,  1.01s/it]Loading train:  21%|██        | 59/285 [01:12<03:47,  1.01s/it]Loading train:  21%|██        | 60/285 [01:13<03:58,  1.06s/it]Loading train:  21%|██▏       | 61/285 [01:14<04:04,  1.09s/it]Loading train:  22%|██▏       | 62/285 [01:15<03:55,  1.06s/it]Loading train:  22%|██▏       | 63/285 [01:16<03:55,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:18<04:30,  1.22s/it]Loading train:  23%|██▎       | 65/285 [01:20<05:15,  1.43s/it]Loading train:  23%|██▎       | 66/285 [01:21<05:23,  1.48s/it]Loading train:  24%|██▎       | 67/285 [01:23<05:21,  1.48s/it]Loading train:  24%|██▍       | 68/285 [01:24<04:49,  1.33s/it]Loading train:  24%|██▍       | 69/285 [01:25<04:36,  1.28s/it]Loading train:  25%|██▍       | 70/285 [01:26<04:27,  1.25s/it]Loading train:  25%|██▍       | 71/285 [01:27<04:25,  1.24s/it]Loading train:  25%|██▌       | 72/285 [01:28<04:11,  1.18s/it]Loading train:  26%|██▌       | 73/285 [01:30<04:10,  1.18s/it]Loading train:  26%|██▌       | 74/285 [01:31<04:01,  1.14s/it]Loading train:  26%|██▋       | 75/285 [01:32<03:51,  1.10s/it]Loading train:  27%|██▋       | 76/285 [01:33<03:49,  1.10s/it]Loading train:  27%|██▋       | 77/285 [01:34<03:47,  1.09s/it]Loading train:  27%|██▋       | 78/285 [01:35<03:41,  1.07s/it]Loading train:  28%|██▊       | 79/285 [01:36<03:40,  1.07s/it]Loading train:  28%|██▊       | 80/285 [01:37<03:39,  1.07s/it]Loading train:  28%|██▊       | 81/285 [01:38<03:40,  1.08s/it]Loading train:  29%|██▉       | 82/285 [01:39<03:43,  1.10s/it]Loading train:  29%|██▉       | 83/285 [01:40<03:39,  1.09s/it]Loading train:  29%|██▉       | 84/285 [01:41<03:38,  1.09s/it]Loading train:  30%|██▉       | 85/285 [01:43<03:53,  1.17s/it]Loading train:  30%|███       | 86/285 [01:44<03:49,  1.15s/it]Loading train:  31%|███       | 87/285 [01:45<03:40,  1.11s/it]Loading train:  31%|███       | 88/285 [01:46<03:49,  1.16s/it]Loading train:  31%|███       | 89/285 [01:47<03:41,  1.13s/it]Loading train:  32%|███▏      | 90/285 [01:48<03:41,  1.14s/it]Loading train:  32%|███▏      | 91/285 [01:50<03:43,  1.15s/it]Loading train:  32%|███▏      | 92/285 [01:51<03:43,  1.16s/it]Loading train:  33%|███▎      | 93/285 [01:52<03:41,  1.16s/it]Loading train:  33%|███▎      | 94/285 [01:53<03:37,  1.14s/it]Loading train:  33%|███▎      | 95/285 [01:54<03:43,  1.18s/it]Loading train:  34%|███▎      | 96/285 [01:55<03:32,  1.13s/it]Loading train:  34%|███▍      | 97/285 [01:57<03:35,  1.15s/it]Loading train:  34%|███▍      | 98/285 [01:58<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [01:59<03:32,  1.14s/it]Loading train:  35%|███▌      | 100/285 [02:00<03:29,  1.14s/it]Loading train:  35%|███▌      | 101/285 [02:01<03:33,  1.16s/it]Loading train:  36%|███▌      | 102/285 [02:02<03:35,  1.18s/it]Loading train:  36%|███▌      | 103/285 [02:04<03:41,  1.22s/it]Loading train:  36%|███▋      | 104/285 [02:05<03:37,  1.20s/it]Loading train:  37%|███▋      | 105/285 [02:06<03:26,  1.14s/it]Loading train:  37%|███▋      | 106/285 [02:07<03:27,  1.16s/it]Loading train:  38%|███▊      | 107/285 [02:08<03:27,  1.17s/it]Loading train:  38%|███▊      | 108/285 [02:09<03:29,  1.18s/it]Loading train:  38%|███▊      | 109/285 [02:10<03:21,  1.15s/it]Loading train:  39%|███▊      | 110/285 [02:12<03:21,  1.15s/it]Loading train:  39%|███▉      | 111/285 [02:13<03:21,  1.16s/it]Loading train:  39%|███▉      | 112/285 [02:14<03:20,  1.16s/it]Loading train:  40%|███▉      | 113/285 [02:15<03:13,  1.12s/it]Loading train:  40%|████      | 114/285 [02:16<03:12,  1.13s/it]Loading train:  40%|████      | 115/285 [02:17<03:08,  1.11s/it]Loading train:  41%|████      | 116/285 [02:18<03:15,  1.16s/it]Loading train:  41%|████      | 117/285 [02:20<03:10,  1.14s/it]Loading train:  41%|████▏     | 118/285 [02:21<03:13,  1.16s/it]Loading train:  42%|████▏     | 119/285 [02:22<03:17,  1.19s/it]Loading train:  42%|████▏     | 120/285 [02:23<03:15,  1.19s/it]Loading train:  42%|████▏     | 121/285 [02:25<03:34,  1.31s/it]Loading train:  43%|████▎     | 122/285 [02:26<03:36,  1.33s/it]Loading train:  43%|████▎     | 123/285 [02:28<03:37,  1.34s/it]Loading train:  44%|████▎     | 124/285 [02:28<03:13,  1.20s/it]Loading train:  44%|████▍     | 125/285 [02:29<02:57,  1.11s/it]Loading train:  44%|████▍     | 126/285 [02:30<02:49,  1.07s/it]Loading train:  45%|████▍     | 127/285 [02:31<02:40,  1.01s/it]Loading train:  45%|████▍     | 128/285 [02:32<02:41,  1.03s/it]Loading train:  45%|████▌     | 129/285 [02:33<02:44,  1.05s/it]Loading train:  46%|████▌     | 130/285 [02:34<02:35,  1.00s/it]Loading train:  46%|████▌     | 131/285 [02:35<02:32,  1.01it/s]Loading train:  46%|████▋     | 132/285 [02:36<02:34,  1.01s/it]Loading train:  47%|████▋     | 133/285 [02:37<02:39,  1.05s/it]Loading train:  47%|████▋     | 134/285 [02:38<02:31,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:39<02:35,  1.04s/it]Loading train:  48%|████▊     | 136/285 [02:40<02:34,  1.04s/it]Loading train:  48%|████▊     | 137/285 [02:42<02:35,  1.05s/it]Loading train:  48%|████▊     | 138/285 [02:42<02:28,  1.01s/it]Loading train:  49%|████▉     | 139/285 [02:43<02:27,  1.01s/it]Loading train:  49%|████▉     | 140/285 [02:44<02:27,  1.01s/it]Loading train:  49%|████▉     | 141/285 [02:45<02:22,  1.01it/s]Loading train:  50%|████▉     | 142/285 [02:46<02:18,  1.03it/s]Loading train:  50%|█████     | 143/285 [02:47<02:17,  1.04it/s]Loading train:  51%|█████     | 144/285 [02:48<02:14,  1.05it/s]Loading train:  51%|█████     | 145/285 [02:49<02:19,  1.00it/s]Loading train:  51%|█████     | 146/285 [02:50<02:20,  1.01s/it]Loading train:  52%|█████▏    | 147/285 [02:51<02:17,  1.01it/s]Loading train:  52%|█████▏    | 148/285 [02:52<02:19,  1.02s/it]Loading train:  52%|█████▏    | 149/285 [02:53<02:15,  1.00it/s]Loading train:  53%|█████▎    | 150/285 [02:54<02:12,  1.02it/s]Loading train:  53%|█████▎    | 151/285 [02:55<02:13,  1.00it/s]Loading train:  53%|█████▎    | 152/285 [02:56<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [02:57<02:09,  1.02it/s]Loading train:  54%|█████▍    | 154/285 [02:58<02:09,  1.01it/s]Loading train:  54%|█████▍    | 155/285 [02:59<02:04,  1.05it/s]Loading train:  55%|█████▍    | 156/285 [03:00<02:09,  1.01s/it]Loading train:  55%|█████▌    | 157/285 [03:01<02:10,  1.02s/it]Loading train:  55%|█████▌    | 158/285 [03:02<02:05,  1.01it/s]Loading train:  56%|█████▌    | 159/285 [03:03<02:07,  1.01s/it]Loading train:  56%|█████▌    | 160/285 [03:04<02:05,  1.00s/it]Loading train:  56%|█████▋    | 161/285 [03:05<01:57,  1.06it/s]Loading train:  57%|█████▋    | 162/285 [03:06<01:54,  1.07it/s]Loading train:  57%|█████▋    | 163/285 [03:07<01:49,  1.12it/s]Loading train:  58%|█████▊    | 164/285 [03:08<01:46,  1.14it/s]Loading train:  58%|█████▊    | 165/285 [03:09<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [03:10<01:50,  1.07it/s]Loading train:  59%|█████▊    | 167/285 [03:10<01:47,  1.09it/s]Loading train:  59%|█████▉    | 168/285 [03:12<01:55,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [03:13<01:52,  1.03it/s]Loading train:  60%|█████▉    | 170/285 [03:14<01:51,  1.03it/s]Loading train:  60%|██████    | 171/285 [03:14<01:43,  1.10it/s]Loading train:  60%|██████    | 172/285 [03:15<01:45,  1.07it/s]Loading train:  61%|██████    | 173/285 [03:16<01:46,  1.05it/s]Loading train:  61%|██████    | 174/285 [03:17<01:48,  1.02it/s]Loading train:  61%|██████▏   | 175/285 [03:18<01:49,  1.01it/s]Loading train:  62%|██████▏   | 176/285 [03:19<01:47,  1.01it/s]Loading train:  62%|██████▏   | 177/285 [03:20<01:48,  1.00s/it]Loading train:  62%|██████▏   | 178/285 [03:21<01:45,  1.01it/s]Loading train:  63%|██████▎   | 179/285 [03:22<01:46,  1.00s/it]Loading train:  63%|██████▎   | 180/285 [03:23<01:41,  1.04it/s]Loading train:  64%|██████▎   | 181/285 [03:24<01:43,  1.01it/s]Loading train:  64%|██████▍   | 182/285 [03:25<01:37,  1.05it/s]Loading train:  64%|██████▍   | 183/285 [03:26<01:43,  1.02s/it]Loading train:  65%|██████▍   | 184/285 [03:27<01:42,  1.01s/it]Loading train:  65%|██████▍   | 185/285 [03:28<01:41,  1.02s/it]Loading train:  65%|██████▌   | 186/285 [03:29<01:37,  1.02it/s]Loading train:  66%|██████▌   | 187/285 [03:30<01:32,  1.05it/s]Loading train:  66%|██████▌   | 188/285 [03:31<01:34,  1.03it/s]Loading train:  66%|██████▋   | 189/285 [03:32<01:28,  1.08it/s]Loading train:  67%|██████▋   | 190/285 [03:33<01:30,  1.05it/s]Loading train:  67%|██████▋   | 191/285 [03:34<01:27,  1.07it/s]Loading train:  67%|██████▋   | 192/285 [03:35<01:31,  1.01it/s]Loading train:  68%|██████▊   | 193/285 [03:36<01:27,  1.06it/s]Loading train:  68%|██████▊   | 194/285 [03:37<01:28,  1.03it/s]Loading train:  68%|██████▊   | 195/285 [03:38<01:25,  1.05it/s]Loading train:  69%|██████▉   | 196/285 [03:39<01:30,  1.02s/it]Loading train:  69%|██████▉   | 197/285 [03:40<01:36,  1.09s/it]Loading train:  69%|██████▉   | 198/285 [03:41<01:37,  1.12s/it]Loading train:  70%|██████▉   | 199/285 [03:42<01:34,  1.10s/it]Loading train:  70%|███████   | 200/285 [03:43<01:30,  1.06s/it]Loading train:  71%|███████   | 201/285 [03:44<01:30,  1.07s/it]Loading train:  71%|███████   | 202/285 [03:46<01:34,  1.14s/it]Loading train:  71%|███████   | 203/285 [03:47<01:30,  1.10s/it]Loading train:  72%|███████▏  | 204/285 [03:48<01:26,  1.06s/it]Loading train:  72%|███████▏  | 205/285 [03:49<01:23,  1.04s/it]Loading train:  72%|███████▏  | 206/285 [03:50<01:21,  1.03s/it]Loading train:  73%|███████▎  | 207/285 [03:51<01:20,  1.04s/it]Loading train:  73%|███████▎  | 208/285 [03:52<01:20,  1.05s/it]Loading train:  73%|███████▎  | 209/285 [03:53<01:19,  1.04s/it]Loading train:  74%|███████▎  | 210/285 [03:54<01:22,  1.10s/it]Loading train:  74%|███████▍  | 211/285 [03:55<01:20,  1.08s/it]Loading train:  74%|███████▍  | 212/285 [03:56<01:16,  1.05s/it]Loading train:  75%|███████▍  | 213/285 [03:57<01:15,  1.05s/it]Loading train:  75%|███████▌  | 214/285 [03:58<01:12,  1.03s/it]Loading train:  75%|███████▌  | 215/285 [03:59<01:13,  1.04s/it]Loading train:  76%|███████▌  | 216/285 [04:00<01:10,  1.02s/it]Loading train:  76%|███████▌  | 217/285 [04:01<01:05,  1.04it/s]Loading train:  76%|███████▋  | 218/285 [04:02<01:08,  1.02s/it]Loading train:  77%|███████▋  | 219/285 [04:03<01:04,  1.03it/s]Loading train:  77%|███████▋  | 220/285 [04:04<01:04,  1.02it/s]Loading train:  78%|███████▊  | 221/285 [04:05<01:00,  1.05it/s]Loading train:  78%|███████▊  | 222/285 [04:06<01:01,  1.03it/s]Loading train:  78%|███████▊  | 223/285 [04:07<01:00,  1.02it/s]Loading train:  79%|███████▊  | 224/285 [04:08<00:57,  1.07it/s]Loading train:  79%|███████▉  | 225/285 [04:09<00:59,  1.01it/s]Loading train:  79%|███████▉  | 226/285 [04:10<00:56,  1.04it/s]Loading train:  80%|███████▉  | 227/285 [04:11<00:55,  1.05it/s]Loading train:  80%|████████  | 228/285 [04:12<00:54,  1.05it/s]Loading train:  80%|████████  | 229/285 [04:13<00:53,  1.06it/s]Loading train:  81%|████████  | 230/285 [04:14<00:51,  1.06it/s]Loading train:  81%|████████  | 231/285 [04:14<00:49,  1.10it/s]Loading train:  81%|████████▏ | 232/285 [04:16<00:52,  1.02it/s]Loading train:  82%|████████▏ | 233/285 [04:17<00:54,  1.06s/it]Loading train:  82%|████████▏ | 234/285 [04:18<00:55,  1.08s/it]Loading train:  82%|████████▏ | 235/285 [04:19<00:55,  1.11s/it]Loading train:  83%|████████▎ | 236/285 [04:20<00:53,  1.09s/it]Loading train:  83%|████████▎ | 237/285 [04:21<00:54,  1.13s/it]Loading train:  84%|████████▎ | 238/285 [04:23<00:53,  1.13s/it]Loading train:  84%|████████▍ | 239/285 [04:24<00:51,  1.13s/it]Loading train:  84%|████████▍ | 240/285 [04:25<00:52,  1.17s/it]Loading train:  85%|████████▍ | 241/285 [04:26<00:49,  1.11s/it]Loading train:  85%|████████▍ | 242/285 [04:27<00:48,  1.14s/it]Loading train:  85%|████████▌ | 243/285 [04:28<00:46,  1.10s/it]Loading train:  86%|████████▌ | 244/285 [04:29<00:44,  1.07s/it]Loading train:  86%|████████▌ | 245/285 [04:30<00:41,  1.04s/it]Loading train:  86%|████████▋ | 246/285 [04:31<00:41,  1.05s/it]Loading train:  87%|████████▋ | 247/285 [04:32<00:39,  1.05s/it]Loading train:  87%|████████▋ | 248/285 [04:33<00:39,  1.07s/it]Loading train:  87%|████████▋ | 249/285 [04:34<00:39,  1.09s/it]Loading train:  88%|████████▊ | 250/285 [04:35<00:37,  1.07s/it]Loading train:  88%|████████▊ | 251/285 [04:36<00:34,  1.03s/it]Loading train:  88%|████████▊ | 252/285 [04:37<00:32,  1.02it/s]Loading train:  89%|████████▉ | 253/285 [04:38<00:30,  1.06it/s]Loading train:  89%|████████▉ | 254/285 [04:39<00:30,  1.01it/s]Loading train:  89%|████████▉ | 255/285 [04:40<00:30,  1.00s/it]Loading train:  90%|████████▉ | 256/285 [04:41<00:29,  1.01s/it]Loading train:  90%|█████████ | 257/285 [04:42<00:26,  1.04it/s]Loading train:  91%|█████████ | 258/285 [04:43<00:26,  1.02it/s]Loading train:  91%|█████████ | 259/285 [04:44<00:25,  1.01it/s]Loading train:  91%|█████████ | 260/285 [04:45<00:24,  1.01it/s]Loading train:  92%|█████████▏| 261/285 [04:46<00:22,  1.05it/s]Loading train:  92%|█████████▏| 262/285 [04:47<00:21,  1.08it/s]Loading train:  92%|█████████▏| 263/285 [04:48<00:19,  1.11it/s]Loading train:  93%|█████████▎| 264/285 [04:49<00:19,  1.07it/s]Loading train:  93%|█████████▎| 265/285 [04:50<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [04:51<00:17,  1.08it/s]Loading train:  94%|█████████▎| 267/285 [04:52<00:16,  1.06it/s]Loading train:  94%|█████████▍| 268/285 [04:53<00:17,  1.00s/it]Loading train:  94%|█████████▍| 269/285 [04:54<00:17,  1.07s/it]Loading train:  95%|█████████▍| 270/285 [04:55<00:15,  1.06s/it]Loading train:  95%|█████████▌| 271/285 [04:56<00:15,  1.08s/it]Loading train:  95%|█████████▌| 272/285 [04:57<00:13,  1.05s/it]Loading train:  96%|█████████▌| 273/285 [04:58<00:13,  1.13s/it]Loading train:  96%|█████████▌| 274/285 [05:00<00:13,  1.20s/it]Loading train:  96%|█████████▋| 275/285 [05:01<00:11,  1.18s/it]Loading train:  97%|█████████▋| 276/285 [05:02<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [05:03<00:09,  1.20s/it]Loading train:  98%|█████████▊| 278/285 [05:04<00:08,  1.19s/it]Loading train:  98%|█████████▊| 279/285 [05:06<00:06,  1.15s/it]Loading train:  98%|█████████▊| 280/285 [05:07<00:05,  1.16s/it]Loading train:  99%|█████████▊| 281/285 [05:08<00:04,  1.18s/it]Loading train:  99%|█████████▉| 282/285 [05:09<00:03,  1.15s/it]Loading train:  99%|█████████▉| 283/285 [05:10<00:02,  1.15s/it]Loading train: 100%|█████████▉| 284/285 [05:11<00:01,  1.14s/it]Loading train: 100%|██████████| 285/285 [05:12<00:00,  1.09s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:12, 21.92it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:09, 28.58it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:06, 38.71it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:04, 51.53it/s]concatenating: train:  29%|██▉       | 83/285 [00:00<00:03, 67.32it/s]concatenating: train:  38%|███▊      | 108/285 [00:00<00:02, 86.11it/s]concatenating: train:  47%|████▋     | 133/285 [00:00<00:01, 107.12it/s]concatenating: train:  55%|█████▌    | 157/285 [00:00<00:00, 128.21it/s]concatenating: train:  64%|██████▎   | 181/285 [00:00<00:00, 147.68it/s]concatenating: train:  73%|███████▎  | 207/285 [00:01<00:00, 169.49it/s]concatenating: train:  82%|████████▏ | 235/285 [00:01<00:00, 190.59it/s]concatenating: train:  92%|█████████▏| 262/285 [00:01<00:00, 208.36it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 205.35it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.81s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.69s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 33.26it/s]
Epoch 00052: val_mDice did not improve from 0.55916
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [5993.830984933035, 4329.16130719866, 3947.415329706101, 3690.979073660714, 3446.94979422433, 3306.3644670758927, 3144.492716471354, 3085.170892624628, 3044.4564906529017, 2863.4117373511904, 2838.6495419456846, 2876.069516136533, 2759.618611653646, 2737.3917875744046, 2848.108689081101, 2781.614920479911, 2812.223347981771, 2680.631103515625, 2713.414800734747, 2715.371820359003, 2771.0272681826636, 2596.942563011533, 2627.3536493210568, 2727.84219796317, 2722.7857113792784, 2761.402169363839, 2882.3060491652714, 2744.7891918364026, 2749.602106003534, 2755.00778343564, 2719.9766613188244, 3133.97975449335, 2849.682091122582, 2807.2220509847007, 2708.6054019019716, 2757.353294735863, 2765.9632771809897, 2709.277550106957, 2827.922884986514, 2827.06857081822, 2747.8659232003347, 3022.2417740594774, 2974.925559634254, 2637.6156630743117, 2702.894971575056, 2814.798780168806, 2731.0482468377977, 2682.3808085123696, 2646.958743140811, 2842.8943713960193, 3035.3109690348306, 3063.280124482654], 'val_acc': [0.9008631223724002, 0.9126213164556594, 0.9197183819044203, 0.9262614562397912, 0.9268315207390558, 0.9295489646139599, 0.9282646803628831, 0.9341071304820833, 0.9360256592432658, 0.9356364692960467, 0.9344574042728969, 0.9351075830913725, 0.941689548038301, 0.9401167404083979, 0.9327449741817656, 0.9437774675233024, 0.9431387384732565, 0.9407852490743002, 0.9430448611577352, 0.9427426542554583, 0.94572343145098, 0.9446726356233869, 0.9446520266078767, 0.9457784039633614, 0.9467262086414155, 0.9405036653791156, 0.9445466853323436, 0.9459386666615804, 0.9473855296770731, 0.9448030959992182, 0.9464697752680097, 0.9438484680084955, 0.947603029864175, 0.9472619209970746, 0.9465842502457755, 0.9457097280593145, 0.9460118895485288, 0.9443475263459342, 0.9446519982247126, 0.9456410351253691, 0.9479418510482425, 0.9461469934100196, 0.9470123733792987, 0.9464858145940871, 0.9483493736812046, 0.9495650075730824, 0.9470993791307721, 0.9468727140199571, 0.9473122727303278, 0.94695740654355, 0.9473992586135864, 0.9471703200113206], 'val_mDice': [0.30137479518141064, 0.3955573056425367, 0.4299550331419423, 0.450130191942056, 0.4729017095551604, 0.484061197865577, 0.5026001011331876, 0.5068687205868108, 0.51033791970639, 0.5314359301257701, 0.5356153725158601, 0.5295079361115184, 0.5423670333056223, 0.5440674472068038, 0.5335816916610513, 0.5389807788389069, 0.5375071735609145, 0.5506857250417981, 0.5484779785786357, 0.5469459132069633, 0.5409712009131908, 0.5591592072021394, 0.5542407677996726, 0.5474973212750185, 0.5445363904748645, 0.5425938110621202, 0.5257448160222599, 0.5392128264620191, 0.5413822247868493, 0.540124040274393, 0.5456062596113909, 0.4963551514915058, 0.5272786074451038, 0.53156307552542, 0.5481837604727063, 0.5409193063775698, 0.5383221539003509, 0.5453975220166501, 0.5336435364470595, 0.5310219565317744, 0.5444364505154746, 0.5098663914416518, 0.5177848438421885, 0.5518830360046455, 0.5465779190971738, 0.5358134117864427, 0.5416393258741924, 0.5487412969980922, 0.5527610115352131, 0.5299375266546295, 0.51033906070959, 0.5094733695898738], 'loss': [11264.625524805855, 5331.25672584594, 4178.3702727936125, 3658.207496703372, 3326.7688458959146, 3094.2429188863834, 2895.8515324236823, 2748.313809802451, 2623.9219999885154, 2525.5970751981367, 2432.000737622866, 2372.7466236862438, 2285.2992903306945, 2246.663625381437, 2184.0265472217957, 2122.653994746858, 2078.3886146641016, 2044.7928326299523, 1988.971124711192, 1961.6187927469666, 1940.2153073206605, 1900.9406615904998, 1884.8913746251521, 1852.6670983959673, 1820.8458296667525, 1803.3342805961342, 1782.331713048208, 1773.288662400254, 1732.7379713792068, 1724.9203646181636, 1701.1106695289532, 1678.1400392413575, 1662.9708067918068, 1647.9581037837231, 1634.7127671897215, 1611.5810577233724, 1604.4232958824346, 1586.6724663832433, 1570.7924000063636, 1554.9701851204409, 1541.496697300267, 1528.1452639542817, 1523.3023638573598, 1496.0196016163457, 1490.561834273183, 1480.0951975934051, 1460.0270223946661, 1454.17460825008, 1450.117309005499, 1439.297861376134, 1424.9269515435224, 1423.5379772815077], 'acc': [0.8499416767206407, 0.873239311772963, 0.8898466583021762, 0.9008745724281089, 0.9079885139776972, 0.9125753314319961, 0.9164061689505532, 0.9194001351129992, 0.9218022872171169, 0.9237530081401286, 0.9255338347047791, 0.9269136922631117, 0.928568185099706, 0.929504305026608, 0.9307844806480481, 0.9317982485580701, 0.9328133800550534, 0.9333882290709793, 0.9344678976321142, 0.9351294761750196, 0.9356190480201351, 0.9364768022031069, 0.9366802030821308, 0.9373985067346042, 0.9378706805389327, 0.9383399341638226, 0.9387411552402172, 0.9389085446981559, 0.9397367074904655, 0.9399990629938404, 0.9404603136580919, 0.9409624772056211, 0.9411709015369875, 0.9415931910109792, 0.9416803852634346, 0.9422260137543826, 0.9422174833495194, 0.9427085168586431, 0.9431988614842408, 0.9433392558870964, 0.943693625862621, 0.9439685544182576, 0.9439191085675881, 0.9445195124975307, 0.9447497015562916, 0.9449105133021156, 0.9452707425394752, 0.9452519503682248, 0.945353792459261, 0.9455198894949899, 0.9459259053726337, 0.9458357646719486], 'mDice': [0.19863934248559434, 0.35386299340049726, 0.43517355028779053, 0.4804365441809276, 0.5125149356990231, 0.536436841589926, 0.5574347273288077, 0.5737936200722348, 0.5882177331416805, 0.5999238197803957, 0.6110595907345888, 0.6181416383868862, 0.629302254641518, 0.634185742270126, 0.6422550365923456, 0.6498684641228767, 0.655900988800346, 0.6602719160134746, 0.6675960965208955, 0.6712712608529167, 0.6741603470869048, 0.6795139508783323, 0.6817932131204482, 0.6861496942682672, 0.6905356214550711, 0.693021677145729, 0.6959089513617442, 0.6972136915775767, 0.7028106919873857, 0.7039445317938352, 0.7074257266850101, 0.7105614172830871, 0.7127143429243566, 0.7149254532478116, 0.7168045151502567, 0.7201531830150221, 0.7211004092970495, 0.7237368060693544, 0.7261293847045619, 0.7283800767064209, 0.7303934516487541, 0.7322687237667674, 0.7330038305282225, 0.737032195955015, 0.7379319816741591, 0.7394526509597901, 0.742424763499231, 0.7432419938091508, 0.743805311756693, 0.7454501763804928, 0.7476452267512389, 0.7479301415727114]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 15)   4200        concatenate_6[0][0]              2019-07-07 03:33:42.277855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 03:33:42.277991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 03:33:42.278010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 03:33:42.278023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 03:33:42.278616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 23s - loss: 9706.4526 - acc: 0.8845 - mDice: 0.2389 - val_loss: 4470.8405 - val_acc: 0.9200 - val_mDice: 0.3965

Epoch 00001: val_mDice improved from -inf to 0.39647, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 4585.8371 - acc: 0.9133 - mDice: 0.4176 - val_loss: 3111.5789 - val_acc: 0.9375 - val_mDice: 0.5086

Epoch 00002: val_mDice improved from 0.39647 to 0.50857, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 3387.6737 - acc: 0.9265 - mDice: 0.5119 - val_loss: 2686.6688 - val_acc: 0.9440 - val_mDice: 0.5515

Epoch 00003: val_mDice improved from 0.50857 to 0.55151, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 2960.9505 - acc: 0.9323 - mDice: 0.5547 - val_loss: 2508.8673 - val_acc: 0.9464 - val_mDice: 0.5724

Epoch 00004: val_mDice improved from 0.55151 to 0.57242, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 13s - loss: 2694.2704 - acc: 0.9359 - mDice: 0.5836 - val_loss: 2482.6959 - val_acc: 0.9472 - val_mDice: 0.5756

Epoch 00005: val_mDice improved from 0.57242 to 0.57564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 2529.4289 - acc: 0.9381 - mDice: 0.6027 - val_loss: 2394.5046 - val_acc: 0.9487 - val_mDice: 0.5872

Epoch 00006: val_mDice improved from 0.57564 to 0.58716, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 2391.4567 - acc: 0.9399 - mDice: 0.6188 - val_loss: 2353.8873 - val_acc: 0.9494 - val_mDice: 0.5918

Epoch 00007: val_mDice improved from 0.58716 to 0.59183, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 19s - loss: 2284.7785 - acc: 0.9415 - mDice: 0.6318 - val_loss: 2337.4380 - val_acc: 0.9502 - val_mDice: 0.5950

Epoch 00008: val_mDice improved from 0.59183 to 0.59499, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 19s - loss: 2214.2781 - acc: 0.9425 - mDice: 0.6406 - val_loss: 2300.1939 - val_acc: 0.9504 - val_mDice: 0.5994

Epoch 00009: val_mDice improved from 0.59499 to 0.59942, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 20s - loss: 2121.2848 - acc: 0.9438 - mDice: 0.6519 - val_loss: 2204.7238 - val_acc: 0.9515 - val_mDice: 0.6117

Epoch 00010: val_mDice improved from 0.59942 to 0.61171, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 21s - loss: 2064.2427 - acc: 0.9448 - mDice: 0.6594 - val_loss: 2198.3447 - val_acc: 0.9510 - val_mDice: 0.6123

Epoch 00011: val_mDice improved from 0.61171 to 0.61232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 2018.2604 - acc: 0.9454 - mDice: 0.6654 - val_loss: 2178.0310 - val_acc: 0.9524 - val_mDice: 0.6150

Epoch 00012: val_mDice improved from 0.61232 to 0.61500, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 1981.6182 - acc: 0.9463 - mDice: 0.6705 - val_loss: 2183.5159 - val_acc: 0.9521 - val_mDice: 0.6142

Epoch 00013: val_mDice did not improve from 0.61500
Epoch 14/300
 - 20s - loss: 1944.0748 - acc: 0.9469 - mDice: 0.6755 - val_loss: 2280.7403 - val_acc: 0.9514 - val_mDice: 0.6023

Epoch 00014: val_mDice did not improve from 0.61500
Epoch 15/300
 - 19s - loss: 1895.2661 - acc: 0.9474 - mDice: 0.6818 - val_loss: 2169.3594 - val_acc: 0.9517 - val_mDice: 0.6168

Epoch 00015: val_mDice improved from 0.61500 to 0.61675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 17s - loss: 1856.3797 - acc: 0.9480 - mDice: 0.6870 - val_loss: 2131.3575 - val_acc: 0.9523 - val_mDice: 0.6215

Epoch 00016: val_mDice improved from 0.61675 to 0.62146, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 18s - loss: 1816.1269 - acc: 0.9488 - mDice: 0.6925 - val_loss: 2194.3211 - val_acc: 0.9526 - val_mDice: 0.6136

Epoch 00017: val_mDice did not improve from 0.62146
Epoch 18/300
 - 16s - loss: 1784.1005 - acc: 0.9491 - mDice: 0.6970 - val_loss: 2292.4356 - val_acc: 0.9508 - val_mDice: 0.6011

Epoch 00018: val_mDice did not improve from 0.62146
Epoch 19/300
 - 14s - loss: 1760.7768 - acc: 0.9495 - mDice: 0.7006 - val_loss: 2208.2289 - val_acc: 0.9520 - val_mDice: 0.6117

Epoch 00019: val_mDice did not improve from 0.62146
Epoch 20/300
 - 14s - loss: 1730.1281 - acc: 0.9499 - mDice: 0.7044 - val_loss: 2182.8448 - val_acc: 0.9515 - val_mDice: 0.6151

Epoch 00020: val_mDice did not improve from 0.62146
Epoch 21/300
 - 14s - loss: 1706.4562 - acc: 0.9503 - mDice: 0.7077 - val_loss: 2161.2344 - val_acc: 0.9528 - val_mDice: 0.6181

Epoch 00021: val_mDice did not improve from 0.62146
Epoch 22/300
 - 14s - loss: 1675.6995 - acc: 0.9508 - mDice: 0.7120 - val_loss: 2301.3879 - val_acc: 0.9518 - val_mDice: 0.6024

Epoch 00022: val_mDice did not improve from 0.62146
Epoch 23/300
 - 14s - loss: 1654.4063 - acc: 0.9510 - mDice: 0.7151 - val_loss: 2182.1011 - val_acc: 0.9517 - val_mDice: 0.6154

Epoch 00023: val_mDice did not improve from 0.62146
Epoch 24/300
 - 13s - loss: 1640.7076 - acc: 0.9514 - mDice: 0.7172 - val_loss: 2223.6154 - val_acc: 0.9519 - val_mDice: 0.6103

Epoch 00024: val_mDice did not improve from 0.62146
Epoch 25/300
 - 14s - loss: 1612.8364 - acc: 0.9518 - mDice: 0.7209 - val_loss: 2221.9975 - val_acc: 0.9530 - val_mDice: 0.6112

Epoch 00025: val_mDice did not improve from 0.62146
Epoch 26/300
 - 14s - loss: 1592.8775 - acc: 0.9520 - mDice: 0.7238 - val_loss: 2124.4960 - val_acc: 0.9515 - val_mDice: 0.6227

Epoch 00026: val_mDice improved from 0.62146 to 0.62268, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 14s - loss: 1573.7303 - acc: 0.9522 - mDice: 0.7265 - val_loss: 2159.9355 - val_acc: 0.9533 - val_mDice: 0.6198

Epoch 00027: val_mDice did not improve from 0.62268
Epoch 28/300
 - 14s - loss: 1556.6028 - acc: 0.9526 - mDice: 0.7291 - val_loss: 2128.9725 - val_acc: 0.9528 - val_mDice: 0.6231

Epoch 00028: val_mDice improved from 0.62268 to 0.62308, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 13s - loss: 1539.1012 - acc: 0.9527 - mDice: 0.7314 - val_loss: 2223.1319 - val_acc: 0.9511 - val_mDice: 0.6134

Epoch 00029: val_mDice did not improve from 0.62308
Epoch 30/300
 - 13s - loss: 1516.4767 - acc: 0.9531 - mDice: 0.7348 - val_loss: 2180.8689 - val_acc: 0.9530 - val_mDice: 0.6161

Epoch 00030: val_mDice did not improve from 0.62308
Epoch 31/300
 - 12s - loss: 1509.9486 - acc: 0.9533 - mDice: 0.7360 - val_loss: 2160.7433 - val_acc: 0.9525 - val_mDice: 0.6195

Epoch 00031: val_mDice did not improve from 0.62308
Epoch 32/300
 - 13s - loss: 1494.3638 - acc: 0.9535 - mDice: 0.7380 - val_loss: 2202.7467 - val_acc: 0.9527 - val_mDice: 0.6153

Epoch 00032: val_mDice did not improve from 0.62308
Epoch 33/300
 - 13s - loss: 1473.4219 - acc: 0.9538 - mDice: 0.7411 - val_loss: 2225.9047 - val_acc: 0.9503 - val_mDice: 0.6123

Epoch 00033: val_mDice did not improve from 0.62308
Epoch 34/300
 - 13s - loss: 1469.0580 - acc: 0.9538 - mDice: 0.7419 - val_loss: 2300.6929 - val_acc: 0.9517 - val_mDice: 0.6050

Epoch 00034: val_mDice did not improve from 0.62308
Epoch 35/300
 - 12s - loss: 1450.9583 - acc: 0.9542 - mDice: 0.7446 - val_loss: 2265.1207 - val_acc: 0.9514 - val_mDice: 0.6083

Epoch 00035: val_mDice did not improve from 0.62308
Epoch 36/300
 - 12s - loss: 1439.9300 - acc: 0.9543 - mDice: 0.7460 - val_loss: 2309.9425 - val_acc: 0.9499 - val_mDice: 0.5993

Epoch 00036: val_mDice did not improve from 0.62308
Epoch 37/300
 - 12s - loss: 1424.0380 - acc: 0.9546 - mDice: 0.7485 - val_loss: 2274.1590 - val_acc: 0.9514 - val_mDice: 0.6051

Epoch 00037: val_mDice did not improve from 0.62308
Epoch 38/300
 - 13s - loss: 1418.1006 - acc: 0.9547 - mDice: 0.7494 - val_loss: 2255.0354 - val_acc: 0.9513 - val_mDice: 0.6082

Epoch 00038: val_mDice did not improve from 0.62308
Epoch 39/300
 - 12s - loss: 1392.7484 - acc: 0.9551 - mDice: 0.7532 - val_loss: 2355.4896 - val_acc: 0.9525 - val_mDice: 0.5986

Epoch 00039: val_mDice did not improve from 0.62308
Epoch 40/300
 - 12s - loss: 1384.3404 - acc: 0.9551 - mDice: 0.7546 - val_loss: 2167.3682 - val_acc: 0.9515 - val_mDice: 0.6162

Epoch 00040: val_mDice did not improve from 0.62308
Epoch 41/300
 - 13s - loss: 1372.9974 - acc: 0.9553 - mDice: 0.7562 - val_loss: 2243.1127 - val_acc: 0.9519 - val_mDice: 0.6086

Epoch 00041: val_mDice did not improve from 0.62308
Epoch 42/300
 - 12s - loss: 1365.8185 - acc: 0.9553 - mDice: 0.7573 - val_loss: 2227.3632 - val_acc: 0.9518 - val_mDice: 0.6141

Epoch 00042: val_mDice did not improve from 0.62308
Epoch 43/300
 - 12s - loss: 1356.1167 - acc: 0.9555 - mDice: 0.7588 - val_loss: 2238.1669 - val_acc: 0.9508 - val_mDice: 0.6110

Epoch 00043: val_mDice did not improve from 0.62308
Epoch 44/300
 - 12s - loss: 1342.6165 - acc: 0.9557 - mDice: 0.7608 - val_loss: 2232.5275 - val_acc: 0.9528 - val_mDice: 0.6114

Epoch 00044: val_mDice did not improve from 0.62308
Epoch 45/300
 - 12s - loss: 1344.6595 - acc: 0.9558 - mDice: 0.7605 - val_loss: 2294.3649 - val_acc: 0.9518 - val_mDice: 0.6026

Epoch 00045: val_mDice did not improve from 0.62308
Epoch 46/300
 - 12s - loss: 1333.2178 - acc: 0.9558 - mDice: 0.7621 - val_loss: 2360.4640 - val_acc: 0.9526 - val_mDice: 0.5999

Epoch 00046: val_mDice did not improve from 0.62308
Epoch 47/300
 - 12s - loss: 1312.7447 - acc: 0.9561 - mDice: 0.7653 - val_loss: 2176.7836 - val_acc: 0.9525 - val_mDice: 0.6163

Epoch 00047: val_mDice did not improve from 0.62308
Epoch 48/300
 - 12s - loss: 1307.0546 - acc: 0.9562 - mDice: 0.7663 - val_loss: 2256.0716 - val_acc: 0.9518 - val_mDice: 0.6099

Epoch 00048: val_mDice did not improve from 0.62308
Epoch 49/300
 - 12s - loss: 1294.4787 - acc: 0.9563 - mDice: 0.7681 - val_loss: 2302.3055 - val_acc: 0.9515 - val_mDice: 0.6048

Epoch 00049: val_mDice did not improve from 0.62308
Epoch 50/300
 - 12s - loss: 1289.5595 - acc: 0.9565 - mDice: 0.7689 - val_loss: 2164.1307 - val_acc: 0.9521 - val_mDice: 0.6167

Epoch 00050: val_mDice did not improve from 0.62308
Epoch 51/300
 - 12s - loss: 1289.8500 - acc: 0.9564 - mDice: 0.7690 - val_loss: 2290.2059 - val_acc: 0.9522 - val_mDice: 0.6043

Epoch 00051: val_mDice did not improve from 0.62308
Epoch 52/300
 - 12s - loss: 1278.4520 - acc: 0.9567 - mDice: 0.7707 - val_loss: 2254.4384 - val_acc: 0.9501 - val_mDice: 0.6053

Epoch 00052: val_mDice did not improve from 0.62308
Epoch 53/300
 - 12s - loss: 1268.8915 - acc: 0.9568 - mDice: 0.7722 - val_loss: 2350.9069 - val_acc: 0.9523 - val_mDice: 0.5964

Epoch 00053: val_mDice did not improve from 0.62308
Epoch 54/300
 - 12s - loss: 1265.7194 - acc: 0.9568 - mDice: 0.7726 - val_loss: 2360.4184 - val_acc: 0.9532 - val_mDice: 0.5999

Epoch 00054: val_mDice did not improve from 0.62308
Epoch 55/300
 - 12s - loss: 1258.8677 - acc: 0.9571 - mDice: 0.7737 - val_loss: 2318.7081 - val_acc: 0.9520 - val_mDice: 0.6005

Epoch 00055: val_mDice did not improve from 0.62308
Epoch 56/300
 - 12s - loss: 1251.4762 - acc: 0.9570 - mDice: 0.7748 - val_loss: 2220.4517 - val_acc: 0.9530 - val_mDice: 0.6108

Epoch 00056: val_mDice did not improve from 0.62308
Epoch 57/300
 - 12s - loss: 1239.9491 - acc: 0.9572 - mDice: 0.7766 - val_loss: 2223.5842 - val_acc: 0.9516 - val_mDice: 0.6092

Epoch 00057: val_mDice did not improve from 0.62308
Epoch 58/300
 - 12s - loss: 1246.1213 - acc: 0.9572 - mDice: 0.7757 - val_loss: 2289.0189 - val_acc: 0.9524 - val_mDice: 0.6049

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.19s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:27,  1.57s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:46,  1.65s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:38,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:55,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:36,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:50,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:18,  1.79s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:24,  1.82s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:05,  1.76s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:26,  1.84s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:41,  1.90s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:53,  1.95s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:57,  1.98s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<09:02,  2.00s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<09:06,  2.02s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:06,  2.03s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<09:07,  2.04s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<09:09,  2.06s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<09:09,  2.07s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<09:02,  2.05s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:53,  2.02s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:48,  2.01s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:43,  2.00s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<08:41,  2.00s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:41,  2.01s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:42,  2.02s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:46,  2.04s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:28,  1.98s/it]predicting train subjects:  10%|█         | 29/285 [00:56<08:15,  1.94s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:03,  1.90s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:00,  1.89s/it]predicting train subjects:  11%|█         | 32/285 [01:01<07:55,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<07:50,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<07:42,  1.84s/it]predicting train subjects:  12%|█▏        | 35/285 [01:06<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:08<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:10<07:33,  1.83s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<07:36,  1.85s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:32,  1.85s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:33,  1.86s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:32,  1.86s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:34,  1.88s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<07:29,  1.86s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:27,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:11,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:28<06:57,  1.75s/it]predicting train subjects:  17%|█▋        | 48/285 [01:30<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<06:35,  1.67s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<06:25,  1.64s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<06:21,  1.63s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<06:22,  1.64s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<06:19,  1.64s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<06:12,  1.61s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<06:14,  1.63s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<06:09,  1.61s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:06,  1.61s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:05,  1.61s/it]predicting train subjects:  21%|██        | 59/285 [01:48<06:02,  1.60s/it]predicting train subjects:  21%|██        | 60/285 [01:49<05:59,  1.60s/it]predicting train subjects:  21%|██▏       | 61/285 [01:51<05:57,  1.60s/it]predicting train subjects:  22%|██▏       | 62/285 [01:52<05:59,  1.61s/it]predicting train subjects:  22%|██▏       | 63/285 [01:54<05:56,  1.61s/it]predicting train subjects:  22%|██▏       | 64/285 [01:56<05:58,  1.62s/it]predicting train subjects:  23%|██▎       | 65/285 [01:58<06:09,  1.68s/it]predicting train subjects:  23%|██▎       | 66/285 [01:59<06:18,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<06:14,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [02:03<06:12,  1.72s/it]predicting train subjects:  24%|██▍       | 69/285 [02:05<06:11,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:06<06:09,  1.72s/it]predicting train subjects:  25%|██▍       | 71/285 [02:08<06:08,  1.72s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<06:07,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:11<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:13<06:01,  1.71s/it]predicting train subjects:  26%|██▋       | 75/285 [02:15<06:03,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:17<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 77/285 [02:18<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 78/285 [02:20<05:57,  1.72s/it]predicting train subjects:  28%|██▊       | 79/285 [02:22<05:54,  1.72s/it]predicting train subjects:  28%|██▊       | 80/285 [02:23<05:50,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:25<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:27<05:49,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:29<05:47,  1.72s/it]predicting train subjects:  29%|██▉       | 84/285 [02:30<05:45,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:32<05:51,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:34<05:54,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:36<05:55,  1.79s/it]predicting train subjects:  31%|███       | 88/285 [02:38<05:59,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:40<06:01,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:41<05:58,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:43<05:57,  1.84s/it]predicting train subjects:  32%|███▏      | 92/285 [02:45<05:56,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:47<05:56,  1.86s/it]predicting train subjects:  33%|███▎      | 94/285 [02:49<05:57,  1.87s/it]predicting train subjects:  33%|███▎      | 95/285 [02:51<05:57,  1.88s/it]predicting train subjects:  34%|███▎      | 96/285 [02:53<05:56,  1.89s/it]predicting train subjects:  34%|███▍      | 97/285 [02:55<05:52,  1.88s/it]predicting train subjects:  34%|███▍      | 98/285 [02:56<05:51,  1.88s/it]predicting train subjects:  35%|███▍      | 99/285 [02:58<05:50,  1.89s/it]predicting train subjects:  35%|███▌      | 100/285 [03:00<05:45,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:02<05:40,  1.85s/it]predicting train subjects:  36%|███▌      | 102/285 [03:04<05:40,  1.86s/it]predicting train subjects:  36%|███▌      | 103/285 [03:06<05:39,  1.86s/it]predicting train subjects:  36%|███▋      | 104/285 [03:08<05:32,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:09<05:28,  1.83s/it]predicting train subjects:  37%|███▋      | 106/285 [03:11<05:26,  1.82s/it]predicting train subjects:  38%|███▊      | 107/285 [03:13<05:21,  1.81s/it]predicting train subjects:  38%|███▊      | 108/285 [03:15<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:17<05:17,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:18<05:12,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:20<05:09,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:22<05:08,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:24<05:06,  1.78s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:06,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:27<05:06,  1.80s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:03,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:31<05:00,  1.79s/it]predicting train subjects:  41%|████▏     | 118/285 [03:33<04:59,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:34<04:56,  1.79s/it]predicting train subjects:  42%|████▏     | 120/285 [03:36<04:57,  1.80s/it]predicting train subjects:  42%|████▏     | 121/285 [03:38<04:46,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:39<04:28,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:41<04:18,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:42<04:17,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:44<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 126/285 [03:45<04:12,  1.59s/it]predicting train subjects:  45%|████▍     | 127/285 [03:47<04:12,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:49<04:13,  1.62s/it]predicting train subjects:  45%|████▌     | 129/285 [03:51<04:18,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [03:52<04:18,  1.67s/it]predicting train subjects:  46%|████▌     | 131/285 [03:54<04:15,  1.66s/it]predicting train subjects:  46%|████▋     | 132/285 [03:55<04:09,  1.63s/it]predicting train subjects:  47%|████▋     | 133/285 [03:57<04:02,  1.60s/it]predicting train subjects:  47%|████▋     | 134/285 [03:59<04:01,  1.60s/it]predicting train subjects:  47%|████▋     | 135/285 [04:00<03:59,  1.60s/it]predicting train subjects:  48%|████▊     | 136/285 [04:02<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 137/285 [04:03<03:56,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [04:05<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:07<03:59,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:08<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:10<03:57,  1.65s/it]predicting train subjects:  50%|████▉     | 142/285 [04:11<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:13<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:14<03:37,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:16<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:17<03:32,  1.53s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:19<03:28,  1.51s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:20<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:22<03:20,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:23<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:25<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:26<03:18,  1.49s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:28<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:29<03:19,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:31<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:32<03:16,  1.52s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:34<03:14,  1.52s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:36<03:14,  1.53s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:37<03:13,  1.54s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:39<03:10,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:40<03:05,  1.50s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:41<03:03,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:43<03:00,  1.48s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:44<02:57,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:46<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:47<02:52,  1.45s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:49<02:50,  1.45s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:50<02:50,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:52<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:53<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:55<02:45,  1.45s/it]predicting train subjects:  60%|██████    | 172/285 [04:56<02:43,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [04:57<02:41,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [04:59<02:40,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:00<02:36,  1.43s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:02<02:35,  1.43s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:03<02:33,  1.42s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:04<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:06<02:30,  1.42s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:07<02:30,  1.44s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:09<02:31,  1.46s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:10<02:29,  1.45s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:12<02:26,  1.43s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:13<02:24,  1.43s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:15<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:16<02:21,  1.43s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:17<02:19,  1.42s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:19<02:18,  1.43s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:20<02:19,  1.45s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:22<02:18,  1.46s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:23<02:18,  1.47s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:25<02:18,  1.49s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:26<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:28<02:12,  1.46s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:29<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:31<02:18,  1.56s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:33<02:23,  1.63s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:35<02:25,  1.67s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:36<02:24,  1.68s/it]predicting train subjects:  70%|███████   | 200/285 [05:38<02:26,  1.72s/it]predicting train subjects:  71%|███████   | 201/285 [05:40<02:26,  1.74s/it]predicting train subjects:  71%|███████   | 202/285 [05:42<02:24,  1.74s/it]predicting train subjects:  71%|███████   | 203/285 [05:43<02:24,  1.77s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:45<02:23,  1.77s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:47<02:20,  1.75s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:49<02:20,  1.77s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:50<02:16,  1.75s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:52<02:17,  1.79s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:54<02:14,  1.77s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:56<02:12,  1.77s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:58<02:10,  1.77s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:59<02:11,  1.80s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:01<02:07,  1.77s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:03<02:02,  1.73s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:04<01:56,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:06<01:51,  1.61s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:07<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:09<01:45,  1.57s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:10<01:44,  1.58s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:12<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:13<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:15<01:37,  1.55s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:17<01:36,  1.55s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:18<01:35,  1.57s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:20<01:33,  1.56s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:21<01:30,  1.54s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:23<01:27,  1.52s/it]predicting train subjects:  80%|████████  | 228/285 [06:24<01:26,  1.51s/it]predicting train subjects:  80%|████████  | 229/285 [06:26<01:24,  1.51s/it]predicting train subjects:  81%|████████  | 230/285 [06:27<01:24,  1.53s/it]predicting train subjects:  81%|████████  | 231/285 [06:29<01:23,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:31<01:27,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:33<01:30,  1.74s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:35<01:30,  1.78s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:36<01:30,  1.81s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:38<01:30,  1.85s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:40<01:29,  1.87s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:42<01:27,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:44<01:26,  1.88s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:46<01:25,  1.89s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:48<01:23,  1.89s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:50<01:21,  1.90s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:52<01:20,  1.92s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:54<01:18,  1.90s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:56<01:16,  1.91s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:57<01:14,  1.91s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:59<01:12,  1.92s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:01<01:10,  1.91s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:03<01:08,  1.89s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:05<01:01,  1.77s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:06<00:57,  1.68s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:08<00:53,  1.63s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:09<00:50,  1.59s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:11<00:48,  1.57s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:12<00:46,  1.54s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:14<00:44,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:15<00:42,  1.51s/it]predicting train subjects:  91%|█████████ | 258/285 [07:17<00:40,  1.51s/it]predicting train subjects:  91%|█████████ | 259/285 [07:18<00:38,  1.48s/it]predicting train subjects:  91%|█████████ | 260/285 [07:20<00:37,  1.50s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:21<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:23<00:34,  1.51s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:24<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:26<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:27<00:30,  1.51s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:29<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:30<00:27,  1.53s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:32<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:34<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:36<00:26,  1.79s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:38<00:25,  1.84s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:40<00:24,  1.87s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:42<00:22,  1.87s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:20,  1.87s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:46<00:19,  1.91s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:48<00:17,  1.90s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:50<00:15,  1.93s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:51<00:13,  1.94s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:53<00:11,  1.93s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:55<00:09,  1.93s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:57<00:07,  1.92s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:59<00:05,  1.93s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:01<00:03,  1.92s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:03<00:01,  1.94s/it]predicting train subjects: 100%|██████████| 285/285 [08:05<00:00,  1.93s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:59,  1.48s/it]Loading train:   1%|          | 2/285 [00:03<07:12,  1.53s/it]Loading train:   1%|          | 3/285 [00:04<07:02,  1.50s/it]Loading train:   1%|▏         | 4/285 [00:06<07:20,  1.57s/it]Loading train:   2%|▏         | 5/285 [00:07<07:12,  1.54s/it]Loading train:   2%|▏         | 6/285 [00:09<07:28,  1.61s/it]Loading train:   2%|▏         | 7/285 [00:11<07:41,  1.66s/it]Loading train:   3%|▎         | 8/285 [00:12<07:38,  1.66s/it]Loading train:   3%|▎         | 9/285 [00:14<07:27,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<06:59,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:17<06:48,  1.49s/it]Loading train:   4%|▍         | 12/285 [00:18<06:35,  1.45s/it]Loading train:   5%|▍         | 13/285 [00:19<06:20,  1.40s/it]Loading train:   5%|▍         | 14/285 [00:21<06:17,  1.39s/it]Loading train:   5%|▌         | 15/285 [00:22<05:57,  1.33s/it]Loading train:   6%|▌         | 16/285 [00:23<05:50,  1.30s/it]Loading train:   6%|▌         | 17/285 [00:25<05:59,  1.34s/it]Loading train:   6%|▋         | 18/285 [00:26<05:58,  1.34s/it]Loading train:   7%|▋         | 19/285 [00:27<05:59,  1.35s/it]Loading train:   7%|▋         | 20/285 [00:29<06:07,  1.39s/it]Loading train:   7%|▋         | 21/285 [00:30<05:56,  1.35s/it]Loading train:   8%|▊         | 22/285 [00:31<05:57,  1.36s/it]Loading train:   8%|▊         | 23/285 [00:33<06:02,  1.38s/it]Loading train:   8%|▊         | 24/285 [00:34<05:52,  1.35s/it]Loading train:   9%|▉         | 25/285 [00:35<05:37,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:37<05:57,  1.38s/it]Loading train:   9%|▉         | 27/285 [00:38<05:50,  1.36s/it]Loading train:  10%|▉         | 28/285 [00:40<05:48,  1.36s/it]Loading train:  10%|█         | 29/285 [00:41<05:48,  1.36s/it]Loading train:  11%|█         | 30/285 [00:42<05:50,  1.37s/it]Loading train:  11%|█         | 31/285 [00:43<05:28,  1.29s/it]Loading train:  11%|█         | 32/285 [00:45<05:24,  1.28s/it]Loading train:  12%|█▏        | 33/285 [00:46<05:04,  1.21s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:04,  1.22s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:24,  1.30s/it]Loading train:  13%|█▎        | 36/285 [00:50<05:19,  1.28s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:29,  1.33s/it]Loading train:  13%|█▎        | 38/285 [00:52<05:30,  1.34s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:16,  1.29s/it]Loading train:  14%|█▍        | 40/285 [00:55<05:22,  1.32s/it]Loading train:  14%|█▍        | 41/285 [00:56<05:22,  1.32s/it]Loading train:  15%|█▍        | 42/285 [00:58<05:25,  1.34s/it]Loading train:  15%|█▌        | 43/285 [00:59<05:18,  1.31s/it]Loading train:  15%|█▌        | 44/285 [01:00<05:10,  1.29s/it]Loading train:  16%|█▌        | 45/285 [01:01<05:06,  1.28s/it]Loading train:  16%|█▌        | 46/285 [01:03<04:53,  1.23s/it]Loading train:  16%|█▋        | 47/285 [01:04<04:49,  1.22s/it]Loading train:  17%|█▋        | 48/285 [01:05<04:47,  1.22s/it]Loading train:  17%|█▋        | 49/285 [01:06<04:41,  1.19s/it]Loading train:  18%|█▊        | 50/285 [01:07<04:45,  1.21s/it]Loading train:  18%|█▊        | 51/285 [01:09<04:47,  1.23s/it]Loading train:  18%|█▊        | 52/285 [01:10<04:38,  1.19s/it]Loading train:  19%|█▊        | 53/285 [01:11<04:39,  1.21s/it]Loading train:  19%|█▉        | 54/285 [01:12<04:43,  1.23s/it]Loading train:  19%|█▉        | 55/285 [01:14<04:45,  1.24s/it]Loading train:  20%|█▉        | 56/285 [01:15<04:39,  1.22s/it]Loading train:  20%|██        | 57/285 [01:16<04:41,  1.23s/it]Loading train:  20%|██        | 58/285 [01:17<04:34,  1.21s/it]Loading train:  21%|██        | 59/285 [01:18<04:31,  1.20s/it]Loading train:  21%|██        | 60/285 [01:20<04:32,  1.21s/it]Loading train:  21%|██▏       | 61/285 [01:21<04:33,  1.22s/it]Loading train:  22%|██▏       | 62/285 [01:22<04:41,  1.26s/it]Loading train:  22%|██▏       | 63/285 [01:23<04:39,  1.26s/it]Loading train:  22%|██▏       | 64/285 [01:25<05:01,  1.37s/it]Loading train:  23%|██▎       | 65/285 [01:27<05:17,  1.44s/it]
Epoch 00058: val_mDice did not improve from 0.62308
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [4470.840482061802, 3111.578896975384, 2686.6688402911136, 2508.867319799668, 2482.6958607934707, 2394.504571840084, 2353.8873025052376, 2337.438025106931, 2300.1938803901885, 2204.7237678399965, 2198.344737473813, 2178.0309717615223, 2183.515893691079, 2280.7403066624474, 2169.3593722721716, 2131.3574764315645, 2194.3210517414454, 2292.4355523306563, 2208.2289302548884, 2182.84475656861, 2161.23440500611, 2301.387883532647, 2182.1010933135476, 2223.61541713949, 2221.9974535723636, 2124.495965542074, 2159.935507321491, 2128.9724653020253, 2223.1319300475734, 2180.8689278543993, 2160.7432977260823, 2202.7467279700595, 2225.904723780115, 2300.692886096805, 2265.1206545696577, 2309.9425055647694, 2274.1590091982366, 2255.0354181215084, 2355.4896315249653, 2167.368174973813, 2243.1127043143333, 2227.3631966873254, 2238.166889893942, 2232.5274883248953, 2294.364926130412, 2360.4640063067386, 2176.783589112692, 2256.071639588425, 2302.3055194876047, 2164.130718891847, 2290.205885562151, 2254.4384492842178, 2350.9068733087465, 2360.4183629211766, 2318.708073280377, 2220.4517201684707, 2223.58421351257, 2289.018864296002], 'val_acc': [0.9199985155846153, 0.9375144576227199, 0.9439646631645757, 0.9463901959318023, 0.9472269342598303, 0.9486587117504142, 0.9493983594398925, 0.9501979387672254, 0.9504355428605106, 0.9514912846368119, 0.9510429474894561, 0.9523838002588496, 0.9520821424835887, 0.9514417025630034, 0.9516544741625227, 0.9522970178939777, 0.9525904119347727, 0.950840468513233, 0.951952008561715, 0.9515367313470254, 0.9528073491996893, 0.951774311465258, 0.9516937686078375, 0.9518507815606101, 0.9530490733391745, 0.9515450017412281, 0.9533155836872549, 0.9527908260595865, 0.9510801314641644, 0.9530387614026415, 0.952513979133947, 0.9527123260764436, 0.950272291732234, 0.9516793113181045, 0.9514044952792162, 0.9499375830149518, 0.951421012092569, 0.9513260072835997, 0.9525036348976903, 0.9514850897495973, 0.9519313597146359, 0.9517867182220161, 0.9508115492719512, 0.9528465993577542, 0.9518362936360876, 0.9525656297220199, 0.9524850355846256, 0.9518218646502362, 0.9515491351069019, 0.9520986985893889, 0.9521647998074579, 0.950129762375155, 0.9523052939489567, 0.953166834801935, 0.9520429292870634, 0.9529602267888672, 0.9516379560172225, 0.9524230590745724], 'val_mDice': [0.3964745938444937, 0.5085717805937016, 0.5515131490856575, 0.5724215564115087, 0.5756365833335748, 0.5871640070856616, 0.5918337120024185, 0.5949860185218256, 0.5994234428059455, 0.6117148472610132, 0.612316040353402, 0.61500321353614, 0.614217268022079, 0.602261071764557, 0.6167527363952978, 0.621460474070224, 0.6136163886032957, 0.6011438769335188, 0.6116741582668027, 0.6151118112009997, 0.6180692151938071, 0.6024000394943706, 0.615440767237594, 0.6103139552990151, 0.6111782522840873, 0.6226821335334352, 0.6197579146763466, 0.6230813744347855, 0.6133509661232293, 0.6160964912542418, 0.6195082684468957, 0.6153152048920786, 0.6123181068697455, 0.6049635217176469, 0.6083426622039113, 0.5992724266132163, 0.6050708500366637, 0.6082090359160354, 0.5986131149963294, 0.6162099455321968, 0.6086401053647089, 0.6141404399658714, 0.611002667656158, 0.6114097540605001, 0.6025602531166716, 0.5998712308579983, 0.6162784798851226, 0.6098717514363081, 0.6048114276465091, 0.6166747805126552, 0.6043379000445318, 0.6053315028132007, 0.5964034026561502, 0.5999060303139288, 0.6005006422543658, 0.6108226709525678, 0.6092379186406481, 0.6048631777976479], 'loss': [9706.452574902412, 4585.837054861208, 3387.6737090597408, 2960.9505245652726, 2694.2703578457204, 2529.428906146286, 2391.456660371922, 2284.778533338858, 2214.2781259679996, 2121.284834709311, 2064.2427397051133, 2018.2603512114672, 1981.618164960027, 1944.074828649475, 1895.2660830578614, 1856.379748595656, 1816.1268962217919, 1784.100533801157, 1760.7767745716549, 1730.1281491760517, 1706.4562149658668, 1675.6995088573012, 1654.4062591481265, 1640.7075991385657, 1612.8364279486113, 1592.877526033068, 1573.7303084417156, 1556.6028034207504, 1539.1011725744063, 1516.4767119880985, 1509.9486233306266, 1494.363762477353, 1473.4218970791628, 1469.0580258215443, 1450.9582652498204, 1439.9299626784364, 1424.0379906467322, 1418.1005592344113, 1392.7483643867904, 1384.3404016627198, 1372.997443457664, 1365.8185163192204, 1356.1166788581852, 1342.616532149096, 1344.6594588217033, 1333.217834469332, 1312.7446546320316, 1307.0545981495309, 1294.4787433707995, 1289.5595328823024, 1289.849976131102, 1278.4520156434025, 1268.8915278323238, 1265.7193861205583, 1258.8677082118902, 1251.4762046427113, 1239.9490629027569, 1246.121292635322], 'acc': [0.8844713494705093, 0.9133373038596456, 0.9265236195788963, 0.9322821824426362, 0.9358685003452251, 0.9381300141774883, 0.9399487132191444, 0.9414784964097948, 0.9425395445187142, 0.9437905867130536, 0.9447623052879341, 0.9454313959407168, 0.9462653832052289, 0.9468741268479521, 0.9474479442139829, 0.9480061528632197, 0.9487576213162694, 0.9491344546058924, 0.9494996204380636, 0.949911943153192, 0.9502601543612148, 0.9508121190660108, 0.9510465301652404, 0.9513845074755273, 0.9517655455626588, 0.9520086977555987, 0.9522280839298372, 0.9525656377163518, 0.952687294536034, 0.9530799165997044, 0.9533278619332171, 0.953459771618553, 0.9537766602822206, 0.9538407718607442, 0.9541761137211962, 0.954274262132666, 0.9546201572842304, 0.9546680126657128, 0.9550530240917626, 0.9550545519976359, 0.9552582890715619, 0.955327997692114, 0.9554710667297333, 0.9556793887970605, 0.9557605822792332, 0.9557812272427837, 0.9561198102214433, 0.956226885033085, 0.9563469670254008, 0.9564675345645999, 0.9564136764782588, 0.9566623280331574, 0.9568171166762062, 0.9568342807038301, 0.9570593003204501, 0.9570298352621199, 0.9572150166969233, 0.9571538270087901], 'mDice': [0.238894883259002, 0.4176061819528911, 0.5118697691207864, 0.554746133700337, 0.5836314486526247, 0.602713405199738, 0.618784034481353, 0.6317927962288047, 0.6405718639248708, 0.6519119695610525, 0.6593837205098024, 0.6654256307431461, 0.6705495289653535, 0.6755099679206907, 0.6818128546743402, 0.6870239064568924, 0.6925374960809756, 0.6969506883892603, 0.70061089490521, 0.704443966282147, 0.707744481737438, 0.7120217460704573, 0.7150857592030266, 0.7171652006542012, 0.7208827596676582, 0.7237685417617357, 0.7265200967408494, 0.7291472186957054, 0.7313508300387543, 0.7347813931453411, 0.7359925006367102, 0.7380461904855993, 0.7411350985509846, 0.7418842252891091, 0.7445923696512958, 0.7460469527705798, 0.7485107458772031, 0.7494223323706403, 0.7532415167548209, 0.7546141642409013, 0.7562056219069424, 0.7572798486901462, 0.7588377233249132, 0.7608036327210136, 0.7604668354340144, 0.7621486340951481, 0.765348601874284, 0.7663072309400006, 0.7681221116323447, 0.7689157994891633, 0.7689605114195226, 0.7706566308521314, 0.7721727727954213, 0.7725738765990693, 0.773715802286518, 0.7747589992961361, 0.776638228041071, 0.775663053549217]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGNLoading train:  23%|██▎       | 66/285 [01:28<05:31,  1.51s/it]Loading train:  24%|██▎       | 67/285 [01:29<05:02,  1.39s/it]Loading train:  24%|██▍       | 68/285 [01:31<04:47,  1.32s/it]Loading train:  24%|██▍       | 69/285 [01:32<04:30,  1.25s/it]Loading train:  25%|██▍       | 70/285 [01:33<04:10,  1.17s/it]Loading train:  25%|██▍       | 71/285 [01:34<04:09,  1.17s/it]Loading train:  25%|██▌       | 72/285 [01:35<04:05,  1.15s/it]Loading train:  26%|██▌       | 73/285 [01:36<03:58,  1.12s/it]Loading train:  26%|██▌       | 74/285 [01:37<03:58,  1.13s/it]Loading train:  26%|██▋       | 75/285 [01:38<04:00,  1.14s/it]Loading train:  27%|██▋       | 76/285 [01:39<03:55,  1.12s/it]Loading train:  27%|██▋       | 77/285 [01:40<03:50,  1.11s/it]Loading train:  27%|██▋       | 78/285 [01:41<03:40,  1.06s/it]Loading train:  28%|██▊       | 79/285 [01:42<03:35,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:43<03:32,  1.04s/it]Loading train:  28%|██▊       | 81/285 [01:45<03:35,  1.06s/it]Loading train:  29%|██▉       | 82/285 [01:46<03:31,  1.04s/it]Loading train:  29%|██▉       | 83/285 [01:47<03:28,  1.03s/it]Loading train:  29%|██▉       | 84/285 [01:48<03:28,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:49<03:38,  1.09s/it]Loading train:  30%|███       | 86/285 [01:50<03:46,  1.14s/it]Loading train:  31%|███       | 87/285 [01:51<03:45,  1.14s/it]Loading train:  31%|███       | 88/285 [01:52<03:47,  1.16s/it]Loading train:  31%|███       | 89/285 [01:54<03:56,  1.21s/it]Loading train:  32%|███▏      | 90/285 [01:55<03:45,  1.15s/it]Loading train:  32%|███▏      | 91/285 [01:56<03:39,  1.13s/it]Loading train:  32%|███▏      | 92/285 [01:57<03:44,  1.17s/it]Loading train:  33%|███▎      | 93/285 [01:58<03:49,  1.19s/it]Loading train:  33%|███▎      | 94/285 [01:59<03:43,  1.17s/it]Loading train:  33%|███▎      | 95/285 [02:01<03:47,  1.20s/it]Loading train:  34%|███▎      | 96/285 [02:02<03:50,  1.22s/it]Loading train:  34%|███▍      | 97/285 [02:04<04:15,  1.36s/it]Loading train:  34%|███▍      | 98/285 [02:05<04:19,  1.39s/it]Loading train:  35%|███▍      | 99/285 [02:07<04:18,  1.39s/it]Loading train:  35%|███▌      | 100/285 [02:08<04:20,  1.41s/it]Loading train:  35%|███▌      | 101/285 [02:09<04:07,  1.35s/it]Loading train:  36%|███▌      | 102/285 [02:10<04:03,  1.33s/it]Loading train:  36%|███▌      | 103/285 [02:12<04:26,  1.46s/it]Loading train:  36%|███▋      | 104/285 [02:13<04:12,  1.40s/it]Loading train:  37%|███▋      | 105/285 [02:15<04:03,  1.35s/it]Loading train:  37%|███▋      | 106/285 [02:16<04:02,  1.35s/it]Loading train:  38%|███▊      | 107/285 [02:17<03:57,  1.33s/it]Loading train:  38%|███▊      | 108/285 [02:19<03:49,  1.30s/it]Loading train:  38%|███▊      | 109/285 [02:20<03:36,  1.23s/it]Loading train:  39%|███▊      | 110/285 [02:21<03:41,  1.27s/it]Loading train:  39%|███▉      | 111/285 [02:22<03:46,  1.30s/it]Loading train:  39%|███▉      | 112/285 [02:24<03:40,  1.27s/it]Loading train:  40%|███▉      | 113/285 [02:25<03:47,  1.32s/it]Loading train:  40%|████      | 114/285 [02:26<03:37,  1.27s/it]Loading train:  40%|████      | 115/285 [02:27<03:32,  1.25s/it]Loading train:  41%|████      | 116/285 [02:29<03:36,  1.28s/it]Loading train:  41%|████      | 117/285 [02:30<03:28,  1.24s/it]Loading train:  41%|████▏     | 118/285 [02:31<03:31,  1.26s/it]Loading train:  42%|████▏     | 119/285 [02:33<03:39,  1.32s/it]Loading train:  42%|████▏     | 120/285 [02:34<03:39,  1.33s/it]Loading train:  42%|████▏     | 121/285 [02:36<03:50,  1.41s/it]Loading train:  43%|████▎     | 122/285 [02:37<03:50,  1.42s/it]Loading train:  43%|████▎     | 123/285 [02:38<03:46,  1.40s/it]Loading train:  44%|████▎     | 124/285 [02:39<03:30,  1.31s/it]Loading train:  44%|████▍     | 125/285 [02:41<03:25,  1.28s/it]Loading train:  44%|████▍     | 126/285 [02:42<03:14,  1.22s/it]Loading train:  45%|████▍     | 127/285 [02:43<03:09,  1.20s/it]Loading train:  45%|████▍     | 128/285 [02:44<03:08,  1.20s/it]Loading train:  45%|████▌     | 129/285 [02:45<03:02,  1.17s/it]Loading train:  46%|████▌     | 130/285 [02:47<03:05,  1.20s/it]Loading train:  46%|████▌     | 131/285 [02:48<02:58,  1.16s/it]Loading train:  46%|████▋     | 132/285 [02:49<02:56,  1.15s/it]Loading train:  47%|████▋     | 133/285 [02:50<02:57,  1.17s/it]Loading train:  47%|████▋     | 134/285 [02:51<02:53,  1.15s/it]Loading train:  47%|████▋     | 135/285 [02:52<02:52,  1.15s/it]Loading train:  48%|████▊     | 136/285 [02:53<02:44,  1.10s/it]Loading train:  48%|████▊     | 137/285 [02:54<02:53,  1.17s/it]Loading train:  48%|████▊     | 138/285 [02:56<02:52,  1.18s/it]Loading train:  49%|████▉     | 139/285 [02:57<02:48,  1.16s/it]Loading train:  49%|████▉     | 140/285 [02:58<02:45,  1.14s/it]Loading train:  49%|████▉     | 141/285 [02:59<02:40,  1.11s/it]Loading train:  50%|████▉     | 142/285 [03:00<02:41,  1.13s/it]Loading train:  50%|█████     | 143/285 [03:02<02:51,  1.21s/it]Loading train:  51%|█████     | 144/285 [03:03<02:47,  1.19s/it]Loading train:  51%|█████     | 145/285 [03:04<02:45,  1.18s/it]Loading train:  51%|█████     | 146/285 [03:05<02:37,  1.13s/it]Loading train:  52%|█████▏    | 147/285 [03:06<02:36,  1.13s/it]Loading train:  52%|█████▏    | 148/285 [03:07<02:34,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [03:08<02:39,  1.17s/it]Loading train:  53%|█████▎    | 150/285 [03:09<02:35,  1.15s/it]Loading train:  53%|█████▎    | 151/285 [03:11<02:34,  1.15s/it]Loading train:  53%|█████▎    | 152/285 [03:12<02:40,  1.21s/it]Loading train:  54%|█████▎    | 153/285 [03:14<02:53,  1.31s/it]Loading train:  54%|█████▍    | 154/285 [03:15<02:50,  1.30s/it]Loading train:  54%|█████▍    | 155/285 [03:16<02:44,  1.26s/it]Loading train:  55%|█████▍    | 156/285 [03:17<02:39,  1.23s/it]Loading train:  55%|█████▌    | 157/285 [03:18<02:33,  1.20s/it]Loading train:  55%|█████▌    | 158/285 [03:19<02:27,  1.16s/it]Loading train:  56%|█████▌    | 159/285 [03:20<02:14,  1.07s/it]Loading train:  56%|█████▌    | 160/285 [03:21<02:15,  1.09s/it]Loading train:  56%|█████▋    | 161/285 [03:22<02:11,  1.06s/it]Loading train:  57%|█████▋    | 162/285 [03:23<02:10,  1.06s/it]Loading train:  57%|█████▋    | 163/285 [03:24<02:12,  1.08s/it]Loading train:  58%|█████▊    | 164/285 [03:26<02:12,  1.09s/it]Loading train:  58%|█████▊    | 165/285 [03:27<02:10,  1.08s/it]Loading train:  58%|█████▊    | 166/285 [03:28<02:03,  1.04s/it]Loading train:  59%|█████▊    | 167/285 [03:29<01:59,  1.01s/it]Loading train:  59%|█████▉    | 168/285 [03:30<02:02,  1.05s/it]Loading train:  59%|█████▉    | 169/285 [03:31<01:58,  1.02s/it]Loading train:  60%|█████▉    | 170/285 [03:32<01:57,  1.02s/it]Loading train:  60%|██████    | 171/285 [03:33<01:58,  1.04s/it]Loading train:  60%|██████    | 172/285 [03:34<01:56,  1.03s/it]Loading train:  61%|██████    | 173/285 [03:35<01:57,  1.05s/it]Loading train:  61%|██████    | 174/285 [03:36<01:58,  1.07s/it]Loading train:  61%|██████▏   | 175/285 [03:37<01:58,  1.08s/it]Loading train:  62%|██████▏   | 176/285 [03:38<01:58,  1.09s/it]Loading train:  62%|██████▏   | 177/285 [03:39<01:57,  1.09s/it]Loading train:  62%|██████▏   | 178/285 [03:40<01:54,  1.07s/it]Loading train:  63%|██████▎   | 179/285 [03:41<01:52,  1.06s/it]Loading train:  63%|██████▎   | 180/285 [03:42<01:52,  1.07s/it]Loading train:  64%|██████▎   | 181/285 [03:44<01:51,  1.07s/it]Loading train:  64%|██████▍   | 182/285 [03:45<01:48,  1.06s/it]Loading train:  64%|██████▍   | 183/285 [03:46<01:54,  1.13s/it]Loading train:  65%|██████▍   | 184/285 [03:47<01:46,  1.05s/it]Loading train:  65%|██████▍   | 185/285 [03:48<01:46,  1.06s/it]Loading train:  65%|██████▌   | 186/285 [03:49<01:45,  1.07s/it]Loading train:  66%|██████▌   | 187/285 [03:50<01:49,  1.11s/it]Loading train:  66%|██████▌   | 188/285 [03:51<01:52,  1.16s/it]Loading train:  66%|██████▋   | 189/285 [03:52<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [03:53<01:44,  1.09s/it]Loading train:  67%|██████▋   | 191/285 [03:54<01:40,  1.07s/it]Loading train:  67%|██████▋   | 192/285 [03:56<01:40,  1.08s/it]Loading train:  68%|██████▊   | 193/285 [03:57<01:40,  1.09s/it]Loading train:  68%|██████▊   | 194/285 [03:58<01:39,  1.09s/it]Loading train:  68%|██████▊   | 195/285 [03:59<01:39,  1.10s/it]Loading train:  69%|██████▉   | 196/285 [04:00<01:39,  1.11s/it]Loading train:  69%|██████▉   | 197/285 [04:01<01:35,  1.09s/it]Loading train:  69%|██████▉   | 198/285 [04:02<01:36,  1.11s/it]Loading train:  70%|██████▉   | 199/285 [04:03<01:35,  1.11s/it]Loading train:  70%|███████   | 200/285 [04:04<01:30,  1.06s/it]Loading train:  71%|███████   | 201/285 [04:05<01:31,  1.09s/it]Loading train:  71%|███████   | 202/285 [04:07<01:35,  1.15s/it]Loading train:  71%|███████   | 203/285 [04:08<01:41,  1.24s/it]Loading train:  72%|███████▏  | 204/285 [04:09<01:38,  1.22s/it]Loading train:  72%|███████▏  | 205/285 [04:10<01:34,  1.18s/it]Loading train:  72%|███████▏  | 206/285 [04:11<01:31,  1.15s/it]Loading train:  73%|███████▎  | 207/285 [04:13<01:30,  1.16s/it]Loading train:  73%|███████▎  | 208/285 [04:14<01:28,  1.15s/it]Loading train:  73%|███████▎  | 209/285 [04:15<01:25,  1.12s/it]Loading train:  74%|███████▎  | 210/285 [04:16<01:27,  1.17s/it]Loading train:  74%|███████▍  | 211/285 [04:17<01:23,  1.13s/it]Loading train:  74%|███████▍  | 212/285 [04:18<01:24,  1.15s/it]Loading train:  75%|███████▍  | 213/285 [04:20<01:23,  1.16s/it]Loading train:  75%|███████▌  | 214/285 [04:21<01:18,  1.11s/it]Loading train:  75%|███████▌  | 215/285 [04:22<01:17,  1.11s/it]Loading train:  76%|███████▌  | 216/285 [04:23<01:13,  1.06s/it]Loading train:  76%|███████▌  | 217/285 [04:24<01:11,  1.05s/it]Loading train:  76%|███████▋  | 218/285 [04:25<01:16,  1.14s/it]Loading train:  77%|███████▋  | 219/285 [04:26<01:11,  1.08s/it]Loading train:  77%|███████▋  | 220/285 [04:27<01:09,  1.07s/it]Loading train:  78%|███████▊  | 221/285 [04:28<01:11,  1.11s/it]Loading train:  78%|███████▊  | 222/285 [04:29<01:05,  1.04s/it]Loading train:  78%|███████▊  | 223/285 [04:30<01:09,  1.12s/it]Loading train:  79%|███████▊  | 224/285 [04:32<01:09,  1.14s/it]Loading train:  79%|███████▉  | 225/285 [04:33<01:08,  1.15s/it]Loading train:  79%|███████▉  | 226/285 [04:34<01:07,  1.15s/it]Loading train:  80%|███████▉  | 227/285 [04:35<01:06,  1.15s/it]Loading train:  80%|████████  | 228/285 [04:36<01:05,  1.15s/it]Loading train:  80%|████████  | 229/285 [04:37<01:05,  1.17s/it]Loading train:  81%|████████  | 230/285 [04:38<01:02,  1.14s/it]Loading train:  81%|████████  | 231/285 [04:40<01:00,  1.13s/it]Loading train:  81%|████████▏ | 232/285 [04:41<01:03,  1.19s/it]Loading train:  82%|████████▏ | 233/285 [04:42<01:02,  1.19s/it]Loading train:  82%|████████▏ | 234/285 [04:43<00:59,  1.16s/it]Loading train:  82%|████████▏ | 235/285 [04:44<00:59,  1.18s/it]Loading train:  83%|████████▎ | 236/285 [04:46<01:00,  1.23s/it]Loading train:  83%|████████▎ | 237/285 [04:47<00:58,  1.22s/it]Loading train:  84%|████████▎ | 238/285 [04:48<01:00,  1.28s/it]Loading train:  84%|████████▍ | 239/285 [04:50<01:01,  1.34s/it]Loading train:  84%|████████▍ | 240/285 [04:51<00:58,  1.31s/it]Loading train:  85%|████████▍ | 241/285 [04:53<00:59,  1.35s/it]Loading train:  85%|████████▍ | 242/285 [04:54<00:57,  1.33s/it]Loading train:  85%|████████▌ | 243/285 [04:55<00:54,  1.31s/it]Loading train:  86%|████████▌ | 244/285 [04:56<00:52,  1.29s/it]Loading train:  86%|████████▌ | 245/285 [04:58<00:50,  1.26s/it]Loading train:  86%|████████▋ | 246/285 [04:59<00:49,  1.27s/it]Loading train:  87%|████████▋ | 247/285 [05:00<00:48,  1.28s/it]Loading train:  87%|████████▋ | 248/285 [05:01<00:47,  1.29s/it]Loading train:  87%|████████▋ | 249/285 [05:03<00:45,  1.28s/it]Loading train:  88%|████████▊ | 250/285 [05:04<00:45,  1.29s/it]Loading train:  88%|████████▊ | 251/285 [05:05<00:41,  1.23s/it]Loading train:  88%|████████▊ | 252/285 [05:06<00:38,  1.17s/it]Loading train:  89%|████████▉ | 253/285 [05:07<00:34,  1.08s/it]Loading train:  89%|████████▉ | 254/285 [05:08<00:32,  1.06s/it]Loading train:  89%|████████▉ | 255/285 [05:09<00:30,  1.02s/it]Loading train:  90%|████████▉ | 256/285 [05:10<00:28,  1.00it/s]Loading train:  90%|█████████ | 257/285 [05:11<00:27,  1.03it/s]Loading train:  91%|█████████ | 258/285 [05:12<00:27,  1.02s/it]Loading train:  91%|█████████ | 259/285 [05:13<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [05:14<00:24,  1.00it/s]Loading train:  92%|█████████▏| 261/285 [05:15<00:23,  1.01it/s]Loading train:  92%|█████████▏| 262/285 [05:16<00:23,  1.01s/it]Loading train:  92%|█████████▏| 263/285 [05:17<00:22,  1.00s/it]Loading train:  93%|█████████▎| 264/285 [05:18<00:20,  1.02it/s]Loading train:  93%|█████████▎| 265/285 [05:19<00:19,  1.00it/s]Loading train:  93%|█████████▎| 266/285 [05:20<00:19,  1.03s/it]Loading train:  94%|█████████▎| 267/285 [05:21<00:19,  1.08s/it]Loading train:  94%|█████████▍| 268/285 [05:22<00:19,  1.13s/it]Loading train:  94%|█████████▍| 269/285 [05:24<00:18,  1.15s/it]Loading train:  95%|█████████▍| 270/285 [05:25<00:17,  1.16s/it]Loading train:  95%|█████████▌| 271/285 [05:26<00:16,  1.15s/it]Loading train:  95%|█████████▌| 272/285 [05:27<00:15,  1.17s/it]Loading train:  96%|█████████▌| 273/285 [05:28<00:14,  1.21s/it]Loading train:  96%|█████████▌| 274/285 [05:30<00:13,  1.26s/it]Loading train:  96%|█████████▋| 275/285 [05:31<00:12,  1.27s/it]Loading train:  97%|█████████▋| 276/285 [05:32<00:11,  1.31s/it]Loading train:  97%|█████████▋| 277/285 [05:34<00:10,  1.29s/it]Loading train:  98%|█████████▊| 278/285 [05:35<00:08,  1.27s/it]Loading train:  98%|█████████▊| 279/285 [05:36<00:07,  1.26s/it]Loading train:  98%|█████████▊| 280/285 [05:37<00:06,  1.21s/it]Loading train:  99%|█████████▊| 281/285 [05:39<00:05,  1.27s/it]Loading train:  99%|█████████▉| 282/285 [05:40<00:03,  1.23s/it]Loading train:  99%|█████████▉| 283/285 [05:41<00:02,  1.21s/it]Loading train: 100%|█████████▉| 284/285 [05:42<00:01,  1.22s/it]Loading train: 100%|██████████| 285/285 [05:43<00:00,  1.20s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 111.95it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:03, 84.46it/s] concatenating: train:   8%|▊         | 24/285 [00:00<00:03, 73.86it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:03, 77.39it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:03, 69.72it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:03, 76.40it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:02, 79.92it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:02, 81.56it/s]concatenating: train:  27%|██▋       | 77/285 [00:00<00:02, 84.84it/s]concatenating: train:  31%|███       | 89/285 [00:01<00:02, 93.01it/s]concatenating: train:  35%|███▍      | 99/285 [00:01<00:01, 95.00it/s]concatenating: train:  40%|████      | 115/285 [00:01<00:01, 107.65it/s]concatenating: train:  46%|████▋     | 132/285 [00:01<00:01, 119.52it/s]concatenating: train:  51%|█████     | 145/285 [00:01<00:01, 98.98it/s] concatenating: train:  55%|█████▌    | 157/285 [00:01<00:01, 98.31it/s]concatenating: train:  59%|█████▉    | 168/285 [00:01<00:01, 101.47it/s]concatenating: train:  63%|██████▎   | 179/285 [00:01<00:01, 77.66it/s] concatenating: train:  66%|██████▋   | 189/285 [00:02<00:01, 77.08it/s]concatenating: train:  69%|██████▉   | 198/285 [00:02<00:01, 74.83it/s]concatenating: train:  73%|███████▎  | 209/285 [00:02<00:00, 82.03it/s]concatenating: train:  77%|███████▋  | 220/285 [00:02<00:00, 87.96it/s]concatenating: train:  84%|████████▎ | 238/285 [00:02<00:00, 99.82it/s]concatenating: train:  87%|████████▋ | 249/285 [00:02<00:00, 92.23it/s]concatenating: train:  91%|█████████ | 260/285 [00:02<00:00, 84.43it/s]concatenating: train:  95%|█████████▌| 271/285 [00:02<00:00, 89.87it/s]concatenating: train:  99%|█████████▊| 281/285 [00:03<00:00, 89.72it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 91.49it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.67s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.58s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.50s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 53.33it/s]
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 106)  0           concatenate_5[0][0]              2019-07-07 04:02:10.499986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 04:02:10.500092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 04:02:10.500107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 04:02:10.500117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 04:02:10.500564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 18s - loss: 35182.2133 - acc: 0.8538 - mDice: 0.0816 - val_loss: 23964.5316 - val_acc: 0.8777 - val_mDice: 0.1712

Epoch 00001: val_mDice improved from -inf to 0.17120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 9s - loss: 17606.9831 - acc: 0.8535 - mDice: 0.1643 - val_loss: 13531.4885 - val_acc: 0.8774 - val_mDice: 0.2538

Epoch 00002: val_mDice improved from 0.17120 to 0.25383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 12369.9831 - acc: 0.8662 - mDice: 0.2508 - val_loss: 9545.3951 - val_acc: 0.8846 - val_mDice: 0.3081

Epoch 00003: val_mDice improved from 0.25383 to 0.30812, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 9510.0574 - acc: 0.8835 - mDice: 0.3173 - val_loss: 6936.0481 - val_acc: 0.9056 - val_mDice: 0.3886

Epoch 00004: val_mDice improved from 0.30812 to 0.38857, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 7838.9143 - acc: 0.8966 - mDice: 0.3760 - val_loss: 6214.4809 - val_acc: 0.9141 - val_mDice: 0.4259

Epoch 00005: val_mDice improved from 0.38857 to 0.42592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 7024.7749 - acc: 0.9038 - mDice: 0.4134 - val_loss: 5739.1333 - val_acc: 0.9185 - val_mDice: 0.4532

Epoch 00006: val_mDice improved from 0.42592 to 0.45318, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 6481.5096 - acc: 0.9083 - mDice: 0.4405 - val_loss: 5473.3916 - val_acc: 0.9199 - val_mDice: 0.4699

Epoch 00007: val_mDice improved from 0.45318 to 0.46989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 6087.5589 - acc: 0.9116 - mDice: 0.4618 - val_loss: 5412.7571 - val_acc: 0.9207 - val_mDice: 0.4734

Epoch 00008: val_mDice improved from 0.46989 to 0.47338, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 5752.6902 - acc: 0.9143 - mDice: 0.4796 - val_loss: 5236.4036 - val_acc: 0.9226 - val_mDice: 0.4840

Epoch 00009: val_mDice improved from 0.47338 to 0.48400, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 5488.7308 - acc: 0.9166 - mDice: 0.4949 - val_loss: 4874.1891 - val_acc: 0.9250 - val_mDice: 0.5078

Epoch 00010: val_mDice improved from 0.48400 to 0.50784, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 9s - loss: 5264.1564 - acc: 0.9184 - mDice: 0.5079 - val_loss: 5016.1881 - val_acc: 0.9235 - val_mDice: 0.4968

Epoch 00011: val_mDice did not improve from 0.50784
Epoch 12/300
 - 9s - loss: 5054.3287 - acc: 0.9201 - mDice: 0.5208 - val_loss: 4740.3021 - val_acc: 0.9275 - val_mDice: 0.5159

Epoch 00012: val_mDice improved from 0.50784 to 0.51590, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 9s - loss: 4882.2008 - acc: 0.9218 - mDice: 0.5317 - val_loss: 4765.0481 - val_acc: 0.9277 - val_mDice: 0.5120

Epoch 00013: val_mDice did not improve from 0.51590
Epoch 14/300
 - 9s - loss: 4743.0097 - acc: 0.9230 - mDice: 0.5410 - val_loss: 4676.0959 - val_acc: 0.9289 - val_mDice: 0.5197

Epoch 00014: val_mDice improved from 0.51590 to 0.51973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 10s - loss: 4610.3007 - acc: 0.9240 - mDice: 0.5497 - val_loss: 4609.7249 - val_acc: 0.9280 - val_mDice: 0.5228

Epoch 00015: val_mDice improved from 0.51973 to 0.52276, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 9s - loss: 4467.9351 - acc: 0.9252 - mDice: 0.5592 - val_loss: 4599.1383 - val_acc: 0.9277 - val_mDice: 0.5243

Epoch 00016: val_mDice improved from 0.52276 to 0.52432, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 9s - loss: 4376.6877 - acc: 0.9260 - mDice: 0.5658 - val_loss: 4492.4696 - val_acc: 0.9305 - val_mDice: 0.5333

Epoch 00017: val_mDice improved from 0.52432 to 0.53329, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 9s - loss: 4245.1909 - acc: 0.9271 - mDice: 0.5748 - val_loss: 4586.8251 - val_acc: 0.9289 - val_mDice: 0.5243

Epoch 00018: val_mDice did not improve from 0.53329
Epoch 19/300
 - 9s - loss: 4169.1302 - acc: 0.9280 - mDice: 0.5803 - val_loss: 4423.5085 - val_acc: 0.9327 - val_mDice: 0.5362

Epoch 00019: val_mDice improved from 0.53329 to 0.53615, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 9s - loss: 4068.8904 - acc: 0.9290 - mDice: 0.5877 - val_loss: 4419.7812 - val_acc: 0.9321 - val_mDice: 0.5371

Epoch 00020: val_mDice improved from 0.53615 to 0.53705, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 9s - loss: 3983.2400 - acc: 0.9297 - mDice: 0.5939 - val_loss: 4446.1854 - val_acc: 0.9321 - val_mDice: 0.5352

Epoch 00021: val_mDice did not improve from 0.53705
Epoch 22/300
 - 10s - loss: 3905.3205 - acc: 0.9305 - mDice: 0.5997 - val_loss: 4379.4799 - val_acc: 0.9330 - val_mDice: 0.5380

Epoch 00022: val_mDice improved from 0.53705 to 0.53804, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 9s - loss: 3852.7360 - acc: 0.9311 - mDice: 0.6040 - val_loss: 4415.5635 - val_acc: 0.9347 - val_mDice: 0.5372

Epoch 00023: val_mDice did not improve from 0.53804
Epoch 24/300
 - 9s - loss: 3763.2474 - acc: 0.9319 - mDice: 0.6108 - val_loss: 4350.0382 - val_acc: 0.9330 - val_mDice: 0.5401

Epoch 00024: val_mDice improved from 0.53804 to 0.54007, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 9s - loss: 3721.3375 - acc: 0.9322 - mDice: 0.6140 - val_loss: 4345.0474 - val_acc: 0.9336 - val_mDice: 0.5421

Epoch 00025: val_mDice improved from 0.54007 to 0.54208, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 9s - loss: 3655.2717 - acc: 0.9327 - mDice: 0.6192 - val_loss: 4292.3912 - val_acc: 0.9340 - val_mDice: 0.5456

Epoch 00026: val_mDice improved from 0.54208 to 0.54557, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 10s - loss: 3573.3500 - acc: 0.9337 - mDice: 0.6255 - val_loss: 4277.8786 - val_acc: 0.9352 - val_mDice: 0.5469

Epoch 00027: val_mDice improved from 0.54557 to 0.54686, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 9s - loss: 3544.4845 - acc: 0.9339 - mDice: 0.6279 - val_loss: 4301.1021 - val_acc: 0.9343 - val_mDice: 0.5444

Epoch 00028: val_mDice did not improve from 0.54686
Epoch 29/300
 - 9s - loss: 3492.9698 - acc: 0.9346 - mDice: 0.6320 - val_loss: 4233.7531 - val_acc: 0.9347 - val_mDice: 0.5502

Epoch 00029: val_mDice improved from 0.54686 to 0.55017, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 9s - loss: 3446.1536 - acc: 0.9351 - mDice: 0.6358 - val_loss: 4335.1810 - val_acc: 0.9359 - val_mDice: 0.5436

Epoch 00030: val_mDice did not improve from 0.55017
Epoch 31/300
 - 9s - loss: 3383.5982 - acc: 0.9354 - mDice: 0.6408 - val_loss: 4243.6366 - val_acc: 0.9373 - val_mDice: 0.5504

Epoch 00031: val_mDice improved from 0.55017 to 0.55037, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 9s - loss: 3342.4920 - acc: 0.9361 - mDice: 0.6443 - val_loss: 4313.8407 - val_acc: 0.9340 - val_mDice: 0.5442

Epoch 00032: val_mDice did not improve from 0.55037
Epoch 33/300
 - 9s - loss: 3310.2625 - acc: 0.9363 - mDice: 0.6467 - val_loss: 4251.6393 - val_acc: 0.9357 - val_mDice: 0.5503

Epoch 00033: val_mDice did not improve from 0.55037
Epoch 34/300
 - 10s - loss: 3264.9378 - acc: 0.9367 - mDice: 0.6507 - val_loss: 4164.8849 - val_acc: 0.9370 - val_mDice: 0.5551

Epoch 00034: val_mDice improved from 0.55037 to 0.55514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 9s - loss: 3233.2519 - acc: 0.9372 - mDice: 0.6535 - val_loss: 4201.9582 - val_acc: 0.9366 - val_mDice: 0.5529

Epoch 00035: val_mDice did not improve from 0.55514
Epoch 36/300
 - 9s - loss: 3184.6190 - acc: 0.9376 - mDice: 0.6574 - val_loss: 4253.5902 - val_acc: 0.9359 - val_mDice: 0.5508

Epoch 00036: val_mDice did not improve from 0.55514
Epoch 37/300
 - 9s - loss: 3157.1374 - acc: 0.9378 - mDice: 0.6598 - val_loss: 4198.9854 - val_acc: 0.9366 - val_mDice: 0.5533

Epoch 00037: val_mDice did not improve from 0.55514
Epoch 38/300
 - 9s - loss: 3118.6817 - acc: 0.9383 - mDice: 0.6630 - val_loss: 4194.8060 - val_acc: 0.9376 - val_mDice: 0.5533

Epoch 00038: val_mDice did not improve from 0.55514
Epoch 39/300
 - 9s - loss: 3087.2198 - acc: 0.9385 - mDice: 0.6658 - val_loss: 4133.8493 - val_acc: 0.9380 - val_mDice: 0.5572

Epoch 00039: val_mDice improved from 0.55514 to 0.55716, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 40/300
 - 9s - loss: 3052.3188 - acc: 0.9389 - mDice: 0.6686 - val_loss: 4112.7844 - val_acc: 0.9399 - val_mDice: 0.5587

Epoch 00040: val_mDice improved from 0.55716 to 0.55870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 9s - loss: 3016.5685 - acc: 0.9393 - mDice: 0.6719 - val_loss: 4137.0283 - val_acc: 0.9398 - val_mDice: 0.5582

Epoch 00041: val_mDice did not improve from 0.55870
Epoch 42/300
 - 10s - loss: 3002.5520 - acc: 0.9396 - mDice: 0.6731 - val_loss: 4218.6137 - val_acc: 0.9382 - val_mDice: 0.5532

Epoch 00042: val_mDice did not improve from 0.55870
Epoch 43/300
 - 9s - loss: 2956.7902 - acc: 0.9398 - mDice: 0.6769 - val_loss: 4542.8087 - val_acc: 0.9374 - val_mDice: 0.5342

Epoch 00043: val_mDice did not improve from 0.55870
Epoch 44/300
 - 9s - loss: 2925.3537 - acc: 0.9401 - mDice: 0.6797 - val_loss: 4028.9533 - val_acc: 0.9380 - val_mDice: 0.5659

Epoch 00044: val_mDice improved from 0.55870 to 0.56592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 45/300
 - 9s - loss: 2903.6901 - acc: 0.9403 - mDice: 0.6818 - val_loss: 4121.4085 - val_acc: 0.9396 - val_mDice: 0.5591

Epoch 00045: val_mDice did not improve from 0.56592
Epoch 46/300
 - 10s - loss: 2873.8643 - acc: 0.9406 - mDice: 0.6843 - val_loss: 4172.1289 - val_acc: 0.9385 - val_mDice: 0.5561

Epoch 00046: val_mDice did not improve from 0.56592
Epoch 47/300
 - 9s - loss: 2846.3165 - acc: 0.9410 - mDice: 0.6867 - val_loss: 4137.6409 - val_acc: 0.9381 - val_mDice: 0.5594

Epoch 00047: val_mDice did not improve from 0.56592
Epoch 48/300
 - 9s - loss: 2817.2382 - acc: 0.9413 - mDice: 0.6893 - val_loss: 4201.8562 - val_acc: 0.9363 - val_mDice: 0.5554

Epoch 00048: val_mDice did not improve from 0.56592
Epoch 49/300
 - 9s - loss: 2799.0813 - acc: 0.9416 - mDice: 0.6909 - val_loss: 4129.8505 - val_acc: 0.9389 - val_mDice: 0.5600

Epoch 00049: val_mDice did not improve from 0.56592
Epoch 50/300
 - 10s - loss: 2781.6502 - acc: 0.9417 - mDice: 0.6925 - val_loss: 4043.1856 - val_acc: 0.9391 - val_mDice: 0.5657

Epoch 00050: val_mDice did not improve from 0.56592
Epoch 51/300
 - 9s - loss: 2756.6437 - acc: 0.9419 - mDice: 0.6948 - val_loss: 4094.9669 - val_acc: 0.9359 - val_mDice: 0.5627

Epoch 00051: val_mDice did not improve from 0.56592
Epoch 52/300
 - 9s - loss: 2733.1661 - acc: 0.9422 - mDice: 0.6969 - val_loss: 3977.8800 - val_acc: 0.9363 - val_mDice: 0.5702

Epoch 00052: val_mDice improved from 0.56592 to 0.57024, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 53/300
 - 9s - loss: 2716.0670 - acc: 0.9425 - mDice: 0.6984 - val_loss: 4171.4292 - val_acc: 0.9363 - val_mDice: 0.5550

Epoch 00053: val_mDice did not improve from 0.57024
Epoch 54/300
 - 9s - loss: 2675.3632 - acc: 0.9428 - mDice: 0.7020 - val_loss: 4154.9411 - val_acc: 0.9398 - val_mDice: 0.5584

Epoch 00054: val_mDice did not improve from 0.57024
Epoch 55/300
 - 9s - loss: 2671.6402 - acc: 0.9429 - mDice: 0.7024 - val_loss: 4097.6407 - val_acc: 0.9335 - val_mDice: 0.5597

Epoch 00055: val_mDice did not improve from 0.57024
Epoch 56/300
 - 10s - loss: 2643.3645 - acc: 0.9433 - mDice: 0.7050 - val_loss: 3977.0378 - val_acc: 0.9393 - val_mDice: 0.5705

Epoch 00056: val_mDice improved from 0.57024 to 0.57055, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 57/300
 - 9s - loss: 2637.6700 - acc: 0.9434 - mDice: 0.7055 - val_loss: 4160.8235 - val_acc: 0.9396 - val_mDice: 0.5592

Epoch 00057: val_mDice did not improve from 0.57055
Epoch 58/300
 - 9s - loss: 2602.3499 - acc: 0.9436 - mDice: 0.7087 - val_loss: 4207.4754 - val_acc: 0.9334 - val_mDice: 0.5526

Epoch 00058: val_mDice did not improve from 0.57055
Epoch 59/300
 - 9s - loss: 2593.3417 - acc: 0.9438 - mDice: 0.7095 - val_loss: 4040.5695 - val_acc: 0.9356 - val_mDice: 0.5654

Epoch 00059: val_mDice did not improve from 0.57055
Epoch 60/300
 - 9s - loss: 2571.7476 - acc: 0.9441 - mDice: 0.7116 - val_loss: 3946.6861 - val_acc: 0.9397 - val_mDice: 0.5716

Epoch 00060: val_mDice improved from 0.57055 to 0.57155, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 61/300
 - 9s - loss: 2559.2886 - acc: 0.9441 - mDice: 0.7127 - val_loss: 4220.3821 - val_acc: 0.9359 - val_mDice: 0.5536

Epoch 00061: val_mDice did not improve from 0.57155
Epoch 62/300
 - 10s - loss: 2548.8114 - acc: 0.9443 - mDice: 0.7136 - val_loss: 4021.1275 - val_acc: 0.9398 - val_mDice: 0.5681

Epoch 00062: val_mDice did not improve from 0.57155
Epoch 63/300
 - 10s - loss: 2516.4439 - acc: 0.9447 - mDice: 0.7167 - val_loss: 4162.6188 - val_acc: 0.9407 - val_mDice: 0.5583

Epoch 00063: val_mDice did not improve from 0.57155
Epoch 64/300
 - 10s - loss: 2504.0329 - acc: 0.9449 - mDice: 0.7177 - val_loss: 4078.0953 - val_acc: 0.9391 - val_mDice: 0.5648

Epoch 00064: val_mDice did not improve from 0.57155
Epoch 65/300
 - 10s - loss: 2497.9898 - acc: 0.9449 - mDice: 0.7185 - val_loss: 4058.5907 - val_acc: 0.9397 - val_mDice: 0.5668

Epoch 00065: val_mDice did not improve from 0.57155
Epoch 66/300
 - 10s - loss: 2476.9944 - acc: 0.9451 - mDice: 0.7205 - val_loss: 4149.5166 - val_acc: 0.9387 - val_mDice: 0.5583

Epoch 00066: val_mDice did not improve from 0.57155
Epoch 67/300
 - 10s - loss: 2453.0461 - acc: 0.9454 - mDice: 0.7226 - val_loss: 4211.9398 - val_acc: 0.9370 - val_mDice: 0.5556

Epoch 00067: val_mDice did not improve from 0.57155
Epoch 68/300
 - 10s - loss: 2443.7653 - acc: 0.9454 - mDice: 0.7235 - val_loss: 4154.5649 - val_acc: 0.9409 - val_mDice: 0.5608

Epoch 00068: val_mDice did not improve from 0.57155
Epoch 69/300
 - 10s - loss: 2429.0722 - acc: 0.9457 - mDice: 0.7248 - val_loss: 4137.3292 - val_acc: 0.9414 - val_mDice: 0.5629

Epoch 00069: val_mDice did not improve from 0.57155
Epoch 70/300
 - 9s - loss: 2424.8798 - acc: 0.9458 - mDice: 0.7253 - val_loss: 4287.9023 - val_acc: 0.9361 - val_mDice: 0.5498

Epoch 00070: val_mDice did not improve from 0.57155
Epoch 71/300
 - 10s - loss: 2408.4483 - acc: 0.9459 - mDice: 0.7269 - val_loss: 4147.3679 - val_acc: 0.9402 - val_mDice: 0.5589

Epoch 00071: val_mDice did not improve from 0.57155
Epoch 72/300
 - 10s - loss: 2395.0113 - acc: 0.9460 - mDice: 0.7283 - val_loss: 4373.9620 - val_acc: 0.9406 - val_mDice: 0.5473

Epoch 00072: val_mDice did not improve from 0.57155
Epoch 73/300
 - 10s - loss: 2384.0940 - acc: 0.9460 - mDice: 0.7291 - val_loss: 4011.4742 - val_acc: 0.9395 - val_mDice: 0.5703

Epoch 00073: val_mDice did not improve from 0.57155
Epoch 74/300
 - 10s - loss: 2378.2309 - acc: 0.9463 - mDice: 0.7297 - val_loss: 3986.4069 - val_acc: 0.9377 - val_mDice: 0.5696

Epoch 00074: val_mDice did not improve from 0.57155
Epoch 75/300
 - 10s - loss: 2362.2874 - acc: 0.9463 - mDice: 0.7312 - val_loss: 4388.5327 - val_acc: 0.9365 - val_mDice: 0.5430

Epoch 00075: val_mDice did not improve from 0.57155
Epoch 76/300
 - 10s - loss: 2341.2802 - acc: 0.9466 - mDice: 0.7332 - val_loss: 4199.2224 - val_acc: 0.9422 - val_mDice: 0.5579

Epoch 00076: val_mDice did not improve from 0.57155
Epoch 77/300
 - 10s - loss: 2332.2416 - acc: 0.9467 - mDice: 0.7339 - val_loss: 4017.4941 - val_acc: 0.9418 - val_mDice: 0.5695

Epoch 00077: val_mDice did not improve from 0.57155
Epoch 78/300
 - 10s - loss: 2317.5061 - acc: 0.9470 - mDice: 0.7355 - val_loss: 4161.4385 - val_acc: 0.9408 - val_mDice: 0.5570

Epoch 00078: val_mDice did not improve from 0.57155
Epoch 79/300
 - 10s - loss: 2305.2907 - acc: 0.9468 - mDice: 0.7366 - val_loss: 4073.0745 - val_acc: 0.9414 - val_mDice: 0.5646

Epoch 00079: val_mDice did not improve from 0.57155
Epoch 80/300
 - 10s - loss: 2302.3750 - acc: 0.9471 - mDice: 0.7369 - val_loss: 4048.1584 - val_acc: 0.9416 - val_mDice: 0.5650

Epoch 00080: val_mDice did not improve from 0.57155
Epoch 81/300
 - 10s - loss: 2284.2786 - acc: 0.9473 - mDice: 0.7387 - val_loss: 4280.7492 - val_acc: 0.9405 - val_mDice: 0.5519

Epoch 00081: val_mDice did not improve from 0.57155
Epoch 82/300
 - 10s - loss: 2284.6962 - acc: 0.9473 - mDice: 0.7387 - val_loss: 3913.9324 - val_acc: 0.9387 - val_mDice: 0.5766

Epoch 00082: val_mDice improved from 0.57155 to 0.57656, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 83/300
 - 10s - loss: 2261.5439 - acc: 0.9474 - mDice: 0.7408 - val_loss: 4052.5315 - val_acc: 0.9400 - val_mDice: 0.5666

Epoch 00083: val_mDice did not improve from 0.57656
Epoch 84/300
 - 9s - loss: 2267.3472 - acc: 0.9475 - mDice: 0.7403 - val_loss: 4156.2413 - val_acc: 0.9399 - val_mDice: 0.5593

Epoch 00084: val_mDice did not improve from 0.57656
Epoch 85/300
 - 10s - loss: 2247.7557 - acc: 0.9478 - mDice: 0.7422 - val_loss: 4108.7673 - val_acc: 0.9414 - val_mDice: 0.5650

Epoch 00085: val_mDice did not improve from 0.57656
Epoch 86/300
 - 9s - loss: 2238.0372 - acc: 0.9478 - mDice: 0.7431 - val_loss: 3908.2989 - val_acc: 0.9430 - val_mDice: 0.5764

Epoch 00086: val_mDice did not improve from 0.57656
Epoch 87/300
 - 9s - loss: 2220.0990 - acc: 0.9480 - mDice: 0.7448 - val_loss: 4220.5090 - val_acc: 0.9418 - val_mDice: 0.5578

Epoch 00087: val_mDice did not improve from 0.57656
Epoch 88/300
 - 10s - loss: 2227.5792 - acc: 0.9479 - mDice: 0.7442 - val_loss: 4130.6395 - val_acc: 0.9397 - val_mDice: 0.5627

Epoch 00088: val_mDice did not improve from 0.57656
Epoch 89/300
 - 10s - loss: 2197.1223 - acc: 0.9482 - mDice: 0.7471 - val_loss: 4344.4954 - val_acc: 0.9432 - val_mDice: 0.5514

Epoch 00089: val_mDice did not improve from 0.57656
Epoch 90/300
 - 10s - loss: 2194.8060 - acc: 0.9482 - mDice: 0.7473 - val_loss: 3901.2621 - val_acc: 0.9444 - val_mDice: 0.5764

Epoch 00090: val_mDice did not improve from 0.57656
Epoch 91/300
 - 10s - loss: 2196.7832 - acc: 0.9481 - mDice: 0.7471 - val_loss: 4046.0296 - val_acc: 0.9449 - val_mDice: 0.5687

Epoch 00091: val_mDice did not improve from 0.57656
Epoch 92/300
 - 9s - loss: 2180.0014 - acc: 0.9484 - mDice: 0.7488 - val_loss: 4057.1201 - val_acc: 0.9424 - val_mDice: 0.5683

Epoch 00092: val_mDice did not improve from 0.57656
Epoch 93/300
 - 10s - loss: 2163.8115 - acc: 0.9486 - mDice: 0.7503 - val_loss: 4047.7879 - val_acc: 0.9417 - val_mDice: 0.5683

Epoch 00093: val_mDice did not improve from 0.57656
Epoch 94/300
 - 10s - loss: 2168.4300 - acc: 0.9485 - mDice: 0.7499 - val_loss: 4159.1601 - val_acc: 0.9427 - val_mDice: 0.5617

Epoch 00094: val_mDice did not improve from 0.57656
Epoch 95/300
 - 10s - loss: 2155.1756 - acc: 0.9487 - mDice: 0.7512 - val_loss: 4927.5848 - val_acc: 0.9430 - val_mDice: 0.5298

Epoch 00095: val_mDice did not improve from 0.57656
Epoch 96/300
 - 10s - loss: 2149.2792 - acc: 0.9487 - mDice: 0.7518 - val_loss: 4198.3389 - val_acc: 0.9368 - val_mDice: 0.5568

Epoch 00096: val_mDice did not improve from 0.57656
Epoch 97/300
 - 10s - loss: 2143.9286 - acc: 0.9489 - mDice: 0.7523 - val_loss: 4153.7815 - val_acc: 0.9415 - val_mDice: 0.5608

Epoch 00097: val_mDice did not improve from 0.57656
Epoch 98/300
 - 10s - loss: 2134.3359 - acc: 0.9489 - mDice: 0.7532 - val_loss: 3973.9043 - val_acc: 0.9391 - val_mDice: 0.5725

Epoch 00098: val_mDice did not improve from 0.57656
Epoch 99/300
 - 10s - loss: 2143.4762 - acc: 0.9489 - mDice: 0.7523 - val_loss: 4262.9646 - val_acc: 0.9418 - val_mDice: 0.5549

Epoch 00099: val_mDice did not improve from 0.57656
Epoch 100/300
 - 10s - loss: 2119.3910 - acc: 0.9491 - mDice: 0.7548 - val_loss: 4150.5133 - val_acc: 0.9406 - val_mDice: 0.5614

Epoch 00100: val_mDice did not improve from 0.57656
Epoch 101/300
 - 10s - loss: 2117.8431 - acc: 0.9491 - mDice: 0.7549 - val_loss: 4261.0090 - val_acc: 0.9398 - val_mDice: 0.5547

Epoch 00101: val_mDice did not improve from 0.57656
Epoch 102/300
 - 10s - loss: 2105.2964 - acc: 0.9493 - mDice: 0.7561 - val_loss: 4173.1357 - val_acc: 0.9437 - val_mDice: 0.5600

Epoch 00102: val_mDice did not improve from 0.57656
Epoch 103/300
 - 10s - loss: 2088.5565 - acc: 0.9495 - mDice: 0.7578 - val_loss: 4155.4495 - val_acc: 0.9415 - val_mDice: 0.5599

Epoch 00103: val_mDice did not improve from 0.57656
Epoch 104/300
 - 10s - loss: 2094.6520 - acc: 0.9494 - mDice: 0.7572 - val_loss: 4124.1963 - val_acc: 0.9439 - val_mDice: 0.5603

Epoch 00104: val_mDice did not improve from 0.57656
Epoch 105/300
 - 10s - loss: 2090.8337 - acc: 0.9497 - mDice: 0.7576 - val_loss: 4112.5474 - val_acc: 0.9419 - val_mDice: 0.5635

Epoch 00105: val_mDice did not improve from 0.57656
Epoch 106/300
 - 9s - loss: 2077.8218 - acc: 0.9496 - mDice: 0.7588 - val_loss: 3979.8836 - val_acc: 0.9416 - val_mDice: 0.5716

Epoch 00106: val_mDice did not improve from 0.57656
Epoch 107/300
 - 10s - loss: 2080.1438 - acc: 0.9496 - mDice: 0.7587 - val_loss: 4095.8861 - val_acc: 0.9410 - val_mDice: 0.5624

Epoch 00107: val_mDice did not improve from 0.57656
Epoch 108/300
 - 9s - loss: 2062.2250 - acc: 0.9498 - mDice: 0.7605 - val_loss: 4203.4091 - val_acc: 0.9428 - val_mDice: 0.5574

Epoch 00108: val_mDice did not improve from 0.57656
Epoch 109/300
 - 10s - loss: 2049.6089 - acc: 0.9498 - mDice: 0.7616 - val_loss: 4136.8634 - val_acc: 0.9427 - val_mDice: 0.5602

Epoch 00109: val_mDice did not improve from 0.57656
Epoch 110/300
 - 9s - loss: 2068.6789 - acc: 0.9498 - mDice: 0.7597 - val_loss: 4082.4513 - val_acc: 0.9419 - val_mDice: 0.5649

Epoch 00110: val_mDice did not improve from 0.57656
Epoch 111/300
 - 10s - loss: 2049.6859 - acc: 0.9500 - mDice: 0.7617 - val_loss: 4274.5212 - val_acc: 0.9431 - val_mDice: 0.5521

Epoch 00111: val_mDice did not improve from 0.57656
Epoch 112/300
 - 10s - loss: 2042.2683 - acc: 0.9500 - mDice: 0.7624 - val_loss: 4156.4415 - val_acc: 0.9432 - val_mDice: 0.5636

Epoch 00112: val_mDice did not improve from 0.57656
Restoring model weights from the end of the best epoch
Epoch 00112: early stopping
{'val_loss': [23964.531634990984, 13531.488459660457, 9545.395066481371, 6936.048105093149, 6214.480928861178, 5739.133343036358, 5473.391620342548, 5412.757075383113, 5236.403583233173, 4874.189126821665, 5016.188131479116, 4740.302102895884, 4765.048081618089, 4676.095939049354, 4609.724915724534, 4599.138288057768, 4492.469615055965, 4586.825077937199, 4423.5085050142725, 4419.78116431603, 4446.185411893404, 4379.479947603666, 4415.563496516301, 4350.0381587101865, 4345.0473867563105, 4292.391237699068, 4277.878615159255, 4301.102111816406, 4233.753063495343, 4335.181025578426, 4243.636627197266, 4313.840721717248, 4251.639324481671, 4164.884850135217, 4201.958233173077, 4253.590184138371, 4198.985438420223, 4194.805966890775, 4133.849315936749, 4112.7844003530645, 4137.028334397536, 4218.61367563101, 4542.8086829552285, 4028.9533174954927, 4121.408531775842, 4172.128943810096, 4137.640878530649, 4201.856182391827, 4129.850473257212, 4043.1856126051684, 4094.9668579101562, 3977.8799649752104, 4171.429166353666, 4154.941129244291, 4097.640742375301, 3977.0378136268027, 4160.823519193209, 4207.475388746995, 4040.5694580078125, 3946.6860774113584, 4220.3821364182695, 4021.127478966346, 4162.618835449219, 4078.0952993539663, 4058.5906865046572, 4149.5166250375605, 4211.939781775842, 4154.564889761118, 4137.329209547776, 4287.902348445012, 4147.367915226863, 4373.961975097656, 4011.4742384690503, 3986.4068744365986, 4388.53271484375, 4199.222444974459, 4017.494147667518, 4161.438462477464, 4073.074493408203, 4048.158367450421, 4280.749206542969, 3913.932412954477, 4052.531541090745, 4156.241271972656, 4108.767254169171, 3908.2988703801084, 4220.508958082933, 4130.639540452224, 4344.495431753306, 3901.2620966984678, 4046.0296067457934, 4057.120114839994, 4047.7878934420073, 4159.160095214844, 4927.58483182467, 4198.338921180139, 4153.781484750601, 3973.904296875, 4262.964594914363, 4150.513300969051, 4261.008990948017, 4173.135699932392, 4155.4495192307695, 4124.19634775015, 4112.547424316406, 3979.883591871995, 4095.8861318734976, 4203.409076397235, 4136.863408015324, 4082.4512775127705, 4274.521165114183, 4156.4414625901445], 'val_acc': [0.8777389778540685, 0.8774454593658447, 0.884638481415235, 0.9056397676467896, 0.9140648154112009, 0.9185280960339767, 0.9199403776572301, 0.9206661513218513, 0.922616972373082, 0.9249676443063296, 0.9234559788153722, 0.9274685703791105, 0.9277158700502836, 0.9289201291707846, 0.9279886117348304, 0.9276650272882901, 0.9305404149568998, 0.9289062321186066, 0.9326784243950477, 0.9321237321083362, 0.9320959563438709, 0.9330066648813394, 0.9347217105902158, 0.9330459420497601, 0.9336330661406884, 0.9340328940978417, 0.9351585599092337, 0.9342709894363697, 0.9346592953571906, 0.9358889850286337, 0.9373012162171878, 0.9340097950055049, 0.9356762996086707, 0.9369868750755603, 0.9365962537435385, 0.9358542882479154, 0.9366355492518499, 0.9376410131271069, 0.9380362194318038, 0.9398714739542741, 0.9397559326428634, 0.9381795365076798, 0.937368250810183, 0.9380292869531192, 0.9396126086895282, 0.9384846664392031, 0.9381495072291448, 0.9363234845491556, 0.9388914291675274, 0.9391433894634247, 0.9359143834847671, 0.9363350638976464, 0.9363004060891958, 0.9398483473521012, 0.9334527552127838, 0.9393306374549866, 0.9396264805243566, 0.9333557028036851, 0.9356369972229004, 0.9396935334572425, 0.9359444242257339, 0.9398252551372235, 0.9406596651444068, 0.9391410602973058, 0.9397189250359168, 0.9386556859199817, 0.9370492811386402, 0.940900050676786, 0.9413507695381458, 0.9360576707583207, 0.9402066537967095, 0.9406250142134153, 0.9395039861018841, 0.937703393972837, 0.9364506258414342, 0.9422037028349363, 0.9418361714253058, 0.9407567588182596, 0.9414478632119986, 0.9416350676463201, 0.9405348461407882, 0.9387273719677558, 0.940024027457604, 0.9398506925656245, 0.9414386199070857, 0.9430357538736783, 0.9417621837212489, 0.9397281798032614, 0.9431536885408255, 0.9443694307253911, 0.944864096549841, 0.9424232588364527, 0.9416674650632418, 0.9427052392409399, 0.9430265128612518, 0.9367973093803112, 0.941503304701585, 0.9391087064376245, 0.941838454741698, 0.9405695406290201, 0.9397651621928582, 0.9437130162349114, 0.9414640504580277, 0.9439349334973556, 0.9418893112586095, 0.9415726776306446, 0.94102720113901, 0.9428161795322711, 0.9427306904242589, 0.9419471163016099, 0.9431421160697937, 0.9432091139830076], 'val_mDice': [0.17119676139778817, 0.25382523181346744, 0.3081178223857513, 0.38857249170541763, 0.4259161725640297, 0.4531762869312213, 0.4698947392977201, 0.47337755388938463, 0.4840021546070392, 0.5078374691880666, 0.49683033904204, 0.5159035135920231, 0.5120469251504312, 0.5197271429575406, 0.5227571645608315, 0.5243156133936002, 0.5332941882885419, 0.5243389228215585, 0.5361530173283356, 0.5370538951112673, 0.5351967227000457, 0.5380403147293971, 0.5372107092004555, 0.5400712650555831, 0.5420813784003258, 0.5455696628643916, 0.5468609441931431, 0.5444039501822912, 0.5501739187882497, 0.5436340415707002, 0.5503714262292936, 0.5441563622309611, 0.5503310870665771, 0.5551445380999491, 0.5528890874523383, 0.5508288855736072, 0.5533276102863826, 0.5533390366114103, 0.5571570511047657, 0.558698409738449, 0.5582491778410398, 0.553204052723371, 0.5341776030567976, 0.5659234071007142, 0.5590553295153838, 0.5560950828859439, 0.5594274814312274, 0.5553797790064261, 0.5600185703772765, 0.5657443283842161, 0.5626549577483764, 0.5702367167060192, 0.5549617753579066, 0.5583773490328056, 0.5596547854634432, 0.5705480237419789, 0.5592131815277613, 0.5525599345564842, 0.565435508122811, 0.571551100565837, 0.5535921420042331, 0.5681157587812498, 0.5583393997870959, 0.5648032747782193, 0.5667616289395553, 0.5583197159262804, 0.5555788691227252, 0.5608104283993061, 0.5628557600654088, 0.5498448816629556, 0.5588516452564642, 0.5472779786930635, 0.5702694356441498, 0.5696106478571892, 0.5430163781230266, 0.5578542827413633, 0.5695455469764196, 0.557044661962069, 0.5646284024875897, 0.5649864556124577, 0.5519420951604843, 0.5765572952536436, 0.5666325957729266, 0.5592947109387472, 0.5649869453448516, 0.5764269490654652, 0.5578117880683678, 0.5627463230719933, 0.551382335046163, 0.576396657870366, 0.5686991191827334, 0.5682937118869561, 0.5683136261426486, 0.5616735231417876, 0.5297955968059026, 0.5567540778563573, 0.5607966035604477, 0.5725402746063012, 0.5549242324554003, 0.561412248473901, 0.5546572666901809, 0.5599538191006734, 0.5599337581258553, 0.560281637769479, 0.5634994638653902, 0.5715755648337878, 0.5624245932469001, 0.5573805891550504, 0.5602493286132812, 0.5648526572264158, 0.5520585391383904, 0.5635700334723179], 'loss': [35182.213256104165, 17606.98311289001, 12369.98306272444, 9510.057391870223, 7838.914307541264, 7024.774890883123, 6481.509558388044, 6087.558895959302, 5752.690205360926, 5488.730808605998, 5264.156444357823, 5054.32869879689, 4882.20082303513, 4743.00972950939, 4610.300653719566, 4467.935052739599, 4376.687702553635, 4245.190863029792, 4169.130243293124, 4068.8904430372168, 3983.2399614927435, 3905.3204836888935, 3852.7360474409616, 3763.2474062394626, 3721.3375256299246, 3655.2716830333725, 3573.349974482655, 3544.484543926039, 3492.969805289577, 3446.1535756097865, 3383.5981724848225, 3342.4920028353004, 3310.262537317963, 3264.9377868871875, 3233.25186425448, 3184.6190351376968, 3157.1374107782312, 3118.6816591331244, 3087.219770130895, 3052.318775695221, 3016.5684557208206, 3002.5520392170497, 2956.790161279166, 2925.3537073371967, 2903.690094188341, 2873.8642709505666, 2846.316458824782, 2817.238186615393, 2799.081319711684, 2781.6501640243127, 2756.6437112973053, 2733.1660967725434, 2716.067036280517, 2675.363157704892, 2671.64022821238, 2643.3644670533768, 2637.6699643738866, 2602.349899211779, 2593.3417278072725, 2571.747565190928, 2559.2886046265626, 2548.811391156197, 2516.4439011879604, 2504.0329432907465, 2497.9898177170394, 2476.994441922406, 2453.0461076783768, 2443.765252349496, 2429.0722234413365, 2424.8798373415057, 2408.448288435295, 2395.011275478167, 2384.093983473686, 2378.23086006624, 2362.287429501383, 2341.2801599908025, 2332.2415598336593, 2317.5060844671175, 2305.2906936354207, 2302.3749929581313, 2284.278623546279, 2284.6961609185055, 2261.5439052959987, 2267.347216451255, 2247.755697310702, 2238.0371761517276, 2220.0989554381554, 2227.5791887668383, 2197.122318449709, 2194.8060150188703, 2196.783190296528, 2180.0014290152185, 2163.8114635450293, 2168.4300269844853, 2155.175598769349, 2149.2791958346, 2143.928586559301, 2134.335896498425, 2143.476196221515, 2119.3909730686973, 2117.843112437892, 2105.2963655987733, 2088.5565461254887, 2094.651973187852, 2090.8337322018037, 2077.8218200677966, 2080.1437709139554, 2062.22501224756, 2049.6089032173245, 2068.6788565201105, 2049.6859176566786, 2042.2682659427453], 'acc': [0.8538106144667441, 0.8535263814807851, 0.8661881067826939, 0.8834596627655477, 0.8965511485888906, 0.9038257573095732, 0.908284233618649, 0.9116385799486413, 0.914268754026189, 0.9166338041096301, 0.918399388055943, 0.9200573397509497, 0.9218058294226605, 0.9229865374022455, 0.9240065612806602, 0.925215844259066, 0.9260213541047859, 0.9271402943291523, 0.9279772828428505, 0.9290463864489982, 0.9297078629376911, 0.930475041285373, 0.9310601377282692, 0.9318588864184345, 0.9321577787113445, 0.9327313947708396, 0.9337251650982542, 0.9338992863995205, 0.9346369375472775, 0.9350640306742795, 0.9353925380596406, 0.9360805246362297, 0.9363454299791926, 0.9366872644969747, 0.9371710267386225, 0.9375869257747165, 0.9378471755513096, 0.9383330656397467, 0.9384606301394224, 0.938899032889087, 0.9393159989928953, 0.9395952689398108, 0.939775037664357, 0.9401070298517936, 0.940313407930184, 0.9405897300830244, 0.9410242755276949, 0.9413208610884193, 0.9415522637616156, 0.9417184450843398, 0.9419246927449308, 0.9421804401967553, 0.9424637635068833, 0.9427650763706386, 0.9428771605991211, 0.9432659936074367, 0.9434247489928935, 0.943641904259502, 0.9438469031744752, 0.9440905007776889, 0.9440684225092424, 0.9442643543610348, 0.9447092760821875, 0.9448730428478522, 0.9449301289751292, 0.9451431791566675, 0.9453631446698622, 0.945360040374428, 0.9457343758103549, 0.9458079789657385, 0.94592762921862, 0.9460400695357938, 0.9459915662629792, 0.9463471876105006, 0.946320050786059, 0.9466064150159917, 0.9466751833897856, 0.9469533907820749, 0.9468172938744762, 0.9471121036202708, 0.9472664920790965, 0.9472710614075556, 0.9473970492673538, 0.9474981661532447, 0.947811975482864, 0.9477668367968729, 0.9479619052745887, 0.9478689948153388, 0.9481728728171767, 0.9482427746741895, 0.9481229697779558, 0.9483711566364789, 0.9485832768195473, 0.948490408072005, 0.9486502723138425, 0.9486959409496062, 0.9488924737127463, 0.9489116973788121, 0.9488777317409749, 0.9490841992895487, 0.9491341909084287, 0.9493005051336242, 0.9495220887620301, 0.9494174047995348, 0.9496572156250614, 0.9496413418136926, 0.9495948970367314, 0.9497562018166847, 0.9498144652112805, 0.949824061438154, 0.9499537983273136, 0.949986874831841], 'mDice': [0.0815525643254716, 0.16426236103499695, 0.2507909406026351, 0.3173386709920751, 0.37603820785488423, 0.4133923988159563, 0.4404739328969023, 0.4618051848727751, 0.4796334283577058, 0.49487935358842755, 0.5079365252464513, 0.5208222710409035, 0.5316715078260212, 0.5409831621325193, 0.549734430010552, 0.5592441116599242, 0.5658288980051456, 0.5747664206408162, 0.5802990921438812, 0.587661526469873, 0.5939287687319842, 0.5997207883505279, 0.6040214732499577, 0.6108176347009482, 0.614028953267982, 0.6192266053295021, 0.625498540296135, 0.6279099358850923, 0.6320460693627103, 0.6357668796324877, 0.6407692593797308, 0.6442894468412599, 0.6467371411531556, 0.650696502563688, 0.6535455520595229, 0.6574435335215768, 0.6597864739813291, 0.6630182121387764, 0.665780080559838, 0.6686091207714744, 0.671854177156102, 0.673089345420824, 0.6769272335877577, 0.6797019485056119, 0.6817789865432823, 0.6842991369990727, 0.6867481820325861, 0.6892522518830272, 0.6909142546819539, 0.6925260777470371, 0.6948081267382467, 0.6969244439234914, 0.6983719767211911, 0.7019868515013417, 0.7024056349558814, 0.7050343811825326, 0.70551155223229, 0.7087088221939883, 0.7094944763214377, 0.7116307029092619, 0.712740721016982, 0.7136238026385882, 0.7166600393642086, 0.7177461103122964, 0.7184824043178673, 0.720461267975548, 0.722605956812291, 0.7234707335028208, 0.7248038729156481, 0.7252536944596296, 0.7268899851077093, 0.7282564582930691, 0.7290823183507813, 0.7296890066985571, 0.731200804044584, 0.7332116759022388, 0.7339117008195332, 0.735544973190207, 0.7366062049154183, 0.7369439454686869, 0.7387263573349528, 0.7386519681986304, 0.7408480051972599, 0.7403396882221925, 0.7422366537291835, 0.7431473460439759, 0.7448485259320214, 0.7441807325548389, 0.7470542197076638, 0.7473337755183018, 0.7471497816198659, 0.7488181633086461, 0.7503478064326401, 0.7499221825604068, 0.7511713691251608, 0.7517909327303584, 0.7523184593649772, 0.7532161063597363, 0.752283703387031, 0.7548070391099809, 0.7548789255383554, 0.7561058472258946, 0.7577564675056174, 0.7572032241136135, 0.7576264154973708, 0.7588253927870693, 0.7586589332800185, 0.7604553979898548, 0.7616082241776397, 0.7597095592099121, 0.7616599938927305, 0.7623978814911185]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.13s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:42,  1.42s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:15,  1.54s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:16,  1.55s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:39,  1.63s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:19,  1.57s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:48,  1.68s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:21,  1.81s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:07,  1.76s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:28,  1.85s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:45,  1.92s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:41,  1.91s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:56,  1.97s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:58,  1.99s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:55,  1.98s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:37,  1.92s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:45,  1.96s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:43,  1.96s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:45,  1.97s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:55,  2.02s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<09:00,  2.05s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<09:07,  2.08s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<09:05,  2.08s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<09:17,  2.14s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<09:02,  2.09s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:47,  2.04s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:28,  1.97s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:23,  1.96s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:15,  1.94s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:15,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:14,  1.95s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:17,  1.97s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<08:20,  1.99s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<08:12,  1.96s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<08:04,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<07:51,  1.89s/it]predicting train subjects:  13%|█▎        | 37/285 [01:11<08:03,  1.95s/it]predicting train subjects:  13%|█▎        | 38/285 [01:13<07:54,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:15<07:56,  1.94s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:47,  1.91s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:40,  1.89s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:35,  1.87s/it]predicting train subjects:  15%|█▌        | 43/285 [01:22<07:40,  1.90s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:26<07:35,  1.90s/it]predicting train subjects:  16%|█▌        | 46/285 [01:28<07:27,  1.87s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<07:15,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<07:03,  1.79s/it]predicting train subjects:  17%|█▋        | 49/285 [01:33<06:59,  1.78s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<06:55,  1.77s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<06:53,  1.77s/it]predicting train subjects:  18%|█▊        | 52/285 [01:38<06:42,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<06:38,  1.72s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<06:19,  1.64s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<06:31,  1.70s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<06:29,  1.70s/it]predicting train subjects:  20%|██        | 57/285 [01:46<06:28,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:48<06:22,  1.68s/it]predicting train subjects:  21%|██        | 59/285 [01:50<06:20,  1.68s/it]predicting train subjects:  21%|██        | 60/285 [01:52<06:21,  1.69s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:20,  1.70s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:28,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:26,  1.74s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:24,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:42,  1.83s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:45,  1.85s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:37,  1.82s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:24,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:18,  1.76s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:06,  1.71s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<06:03,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<05:59,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<05:59,  1.71s/it]predicting train subjects:  27%|██▋       | 76/285 [02:19<05:52,  1.69s/it]predicting train subjects:  27%|██▋       | 77/285 [02:21<05:59,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<05:54,  1.71s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<05:49,  1.70s/it]predicting train subjects:  28%|██▊       | 80/285 [02:26<05:44,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<05:44,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:31<05:45,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:33<05:39,  1.69s/it]predicting train subjects:  30%|██▉       | 85/285 [02:35<05:51,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:37<05:56,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [02:39<06:01,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:41<06:00,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:43<06:02,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<06:11,  1.91s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<06:07,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [02:48<06:01,  1.87s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<06:05,  1.90s/it]predicting train subjects:  33%|███▎      | 94/285 [02:52<06:05,  1.91s/it]predicting train subjects:  33%|███▎      | 95/285 [02:54<06:06,  1.93s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<06:13,  1.98s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<06:07,  1.96s/it]predicting train subjects:  34%|███▍      | 98/285 [03:00<05:58,  1.92s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<06:02,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<06:06,  1.98s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<06:04,  1.98s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<06:06,  2.00s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:59,  1.98s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:53,  1.95s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:42,  1.90s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:42,  1.91s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:44,  1.94s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:34,  1.89s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:35,  1.91s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:36,  1.92s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:30,  1.90s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:39,  1.96s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:36,  1.95s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:30,  1.93s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:23,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:35<05:21,  1.90s/it]predicting train subjects:  41%|████      | 117/285 [03:37<05:17,  1.89s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:12,  1.87s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:16,  1.90s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<05:15,  1.91s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<05:01,  1.84s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:55,  1.81s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:35,  1.70s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:37,  1.72s/it]predicting train subjects:  44%|████▍     | 125/285 [03:51<04:37,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:34,  1.73s/it]predicting train subjects:  45%|████▍     | 127/285 [03:54<04:29,  1.71s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:32,  1.73s/it]predicting train subjects:  45%|████▌     | 129/285 [03:58<04:24,  1.69s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:22,  1.70s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:23,  1.71s/it]predicting train subjects:  46%|████▋     | 132/285 [04:03<04:20,  1.70s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:16,  1.69s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:15,  1.69s/it]predicting train subjects:  47%|████▋     | 135/285 [04:08<04:20,  1.73s/it]predicting train subjects:  48%|████▊     | 136/285 [04:10<04:21,  1.75s/it]predicting train subjects:  48%|████▊     | 137/285 [04:12<04:24,  1.79s/it]predicting train subjects:  48%|████▊     | 138/285 [04:13<04:19,  1.76s/it]predicting train subjects:  49%|████▉     | 139/285 [04:15<04:19,  1.77s/it]predicting train subjects:  49%|████▉     | 140/285 [04:17<04:19,  1.79s/it]predicting train subjects:  49%|████▉     | 141/285 [04:19<04:13,  1.76s/it]predicting train subjects:  50%|████▉     | 142/285 [04:20<04:05,  1.72s/it]predicting train subjects:  50%|█████     | 143/285 [04:22<03:55,  1.66s/it]predicting train subjects:  51%|█████     | 144/285 [04:23<03:54,  1.66s/it]predicting train subjects:  51%|█████     | 145/285 [04:25<03:46,  1.62s/it]predicting train subjects:  51%|█████     | 146/285 [04:26<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:28<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:30<03:39,  1.60s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:31<03:25,  1.51s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:21,  1.50s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:34<03:19,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:37<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:38<03:06,  1.43s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:39<03:04,  1.42s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:41<03:00,  1.40s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<02:56,  1.38s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<02:53,  1.37s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:45<02:51,  1.36s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<02:50,  1.36s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:47<02:49,  1.37s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<02:46,  1.36s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<02:45,  1.36s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<02:45,  1.37s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<02:42,  1.35s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:54<02:41,  1.36s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:56<02:41,  1.37s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<02:36,  1.34s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:58<02:33,  1.33s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:00<02:32,  1.32s/it]predicting train subjects:  60%|██████    | 171/285 [05:01<02:30,  1.32s/it]predicting train subjects:  60%|██████    | 172/285 [05:02<02:29,  1.32s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:27,  1.32s/it]predicting train subjects:  61%|██████    | 174/285 [05:05<02:27,  1.33s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:26,  1.33s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:25,  1.33s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:24,  1.34s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:10<02:21,  1.33s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:11<02:19,  1.31s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:13<02:16,  1.30s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:14<02:13,  1.29s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:15<02:11,  1.28s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:17<02:11,  1.28s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:18<02:08,  1.27s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:19<02:07,  1.27s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:20<02:06,  1.28s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:22<02:06,  1.29s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:23<02:03,  1.27s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:24<02:01,  1.26s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:25<01:59,  1.25s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:27<01:58,  1.26s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:28<01:57,  1.26s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:29<01:57,  1.28s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:30<01:56,  1.28s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:32<01:56,  1.30s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:33<02:03,  1.39s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:35<02:06,  1.44s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:37<02:09,  1.49s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:38<02:09,  1.50s/it]predicting train subjects:  70%|███████   | 200/285 [05:40<02:09,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:41<02:09,  1.55s/it]predicting train subjects:  71%|███████   | 202/285 [05:43<02:09,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:44<02:07,  1.55s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:46<02:05,  1.55s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:48<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:49<02:04,  1.57s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:51<02:02,  1.57s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:52<02:00,  1.57s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:54<01:57,  1.54s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:55<01:53,  1.52s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:57<01:51,  1.51s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:58<01:51,  1.52s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:00<01:50,  1.53s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:01<01:44,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:03<01:40,  1.43s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:04<01:36,  1.40s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:05<01:34,  1.39s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:07<01:32,  1.38s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:08<01:30,  1.37s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:09<01:29,  1.37s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:11<01:26,  1.35s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:12<01:25,  1.35s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:13<01:23,  1.35s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:15<01:22,  1.35s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:16<01:20,  1.34s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:17<01:18,  1.34s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:19<01:17,  1.34s/it]predicting train subjects:  80%|████████  | 228/285 [06:20<01:16,  1.34s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:15,  1.35s/it]predicting train subjects:  81%|████████  | 230/285 [06:23<01:15,  1.37s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:14,  1.37s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:26<01:18,  1.48s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:28<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:29<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:23,  1.66s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:23,  1.69s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:36<01:20,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:38<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:40<01:17,  1.71s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:42<01:15,  1.73s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:43<01:14,  1.72s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:45<01:11,  1.71s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:47<01:09,  1.70s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:48<01:08,  1.71s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:50<01:05,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:52<01:03,  1.68s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:53<01:03,  1.71s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:55<01:01,  1.71s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:56<00:55,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:58<00:50,  1.48s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:59<00:47,  1.43s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:00<00:44,  1.38s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:01<00:41,  1.34s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:03<00:39,  1.32s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:04<00:38,  1.32s/it]predicting train subjects:  90%|█████████ | 257/285 [07:05<00:37,  1.32s/it]predicting train subjects:  91%|█████████ | 258/285 [07:07<00:35,  1.31s/it]predicting train subjects:  91%|█████████ | 259/285 [07:08<00:33,  1.28s/it]predicting train subjects:  91%|█████████ | 260/285 [07:09<00:32,  1.30s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:11<00:31,  1.30s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:12<00:29,  1.29s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:13<00:28,  1.30s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:14<00:27,  1.29s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:16<00:25,  1.26s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:17<00:23,  1.25s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:18<00:22,  1.24s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:20<00:23,  1.37s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:21<00:23,  1.47s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:23<00:23,  1.54s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:25<00:21,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:26<00:20,  1.61s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:28<00:19,  1.62s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:30<00:18,  1.68s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:32<00:16,  1.69s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:33<00:15,  1.70s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:35<00:13,  1.69s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:37<00:11,  1.71s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:39<00:10,  1.73s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:08,  1.74s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:42<00:06,  1.74s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:44<00:05,  1.73s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.70s/it]predicting train subjects: 100%|██████████| 285/285 [07:49<00:00,  1.70s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:56,  1.47s/it]Loading train:   1%|          | 2/285 [00:02<06:46,  1.44s/it]Loading train:   1%|          | 3/285 [00:04<06:26,  1.37s/it]Loading train:   1%|▏         | 4/285 [00:05<06:43,  1.44s/it]Loading train:   2%|▏         | 5/285 [00:06<06:07,  1.31s/it]Loading train:   2%|▏         | 6/285 [00:08<06:26,  1.38s/it]Loading train:   2%|▏         | 7/285 [00:09<06:44,  1.45s/it]Loading train:   3%|▎         | 8/285 [00:11<06:49,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:12<06:39,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<05:56,  1.30s/it]Loading train:   4%|▍         | 11/285 [00:14<05:30,  1.21s/it]Loading train:   4%|▍         | 12/285 [00:15<05:13,  1.15s/it]Loading train:   5%|▍         | 13/285 [00:16<05:00,  1.11s/it]Loading train:   5%|▍         | 14/285 [00:17<04:48,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:18<04:42,  1.05s/it]Loading train:   6%|▌         | 16/285 [00:19<04:35,  1.03s/it]Loading train:   6%|▌         | 17/285 [00:20<04:31,  1.01s/it]Loading train:   6%|▋         | 18/285 [00:21<04:30,  1.01s/it]Loading train:   7%|▋         | 19/285 [00:22<04:33,  1.03s/it]Loading train:   7%|▋         | 20/285 [00:23<04:24,  1.00it/s]Loading train:   7%|▋         | 21/285 [00:24<04:30,  1.02s/it]Loading train:   8%|▊         | 22/285 [00:25<04:26,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:26<04:35,  1.05s/it]Loading train:   8%|▊         | 24/285 [00:27<04:27,  1.03s/it]Loading train:   9%|▉         | 25/285 [00:28<04:27,  1.03s/it]Loading train:   9%|▉         | 26/285 [00:29<04:27,  1.03s/it]Loading train:   9%|▉         | 27/285 [00:30<04:29,  1.04s/it]Loading train:  10%|▉         | 28/285 [00:32<04:29,  1.05s/it]Loading train:  10%|█         | 29/285 [00:33<04:25,  1.04s/it]Loading train:  11%|█         | 30/285 [00:34<04:24,  1.04s/it]Loading train:  11%|█         | 31/285 [00:34<04:11,  1.01it/s]Loading train:  11%|█         | 32/285 [00:36<04:27,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:37<04:15,  1.02s/it]Loading train:  12%|█▏        | 34/285 [00:38<04:08,  1.01it/s]Loading train:  12%|█▏        | 35/285 [00:38<04:06,  1.02it/s]Loading train:  13%|█▎        | 36/285 [00:39<03:57,  1.05it/s]Loading train:  13%|█▎        | 37/285 [00:40<04:01,  1.03it/s]Loading train:  13%|█▎        | 38/285 [00:41<04:07,  1.00s/it]Loading train:  14%|█▎        | 39/285 [00:42<04:05,  1.00it/s]Loading train:  14%|█▍        | 40/285 [00:43<04:06,  1.01s/it]Loading train:  14%|█▍        | 41/285 [00:45<04:14,  1.04s/it]Loading train:  15%|█▍        | 42/285 [00:46<04:05,  1.01s/it]Loading train:  15%|█▌        | 43/285 [00:47<04:06,  1.02s/it]Loading train:  15%|█▌        | 44/285 [00:48<03:58,  1.01it/s]Loading train:  16%|█▌        | 45/285 [00:48<03:52,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:49<03:43,  1.07it/s]Loading train:  16%|█▋        | 47/285 [00:50<03:30,  1.13it/s]Loading train:  17%|█▋        | 48/285 [00:51<03:17,  1.20it/s]Loading train:  17%|█▋        | 49/285 [00:52<03:12,  1.23it/s]Loading train:  18%|█▊        | 50/285 [00:52<03:07,  1.25it/s]Loading train:  18%|█▊        | 51/285 [00:53<03:22,  1.15it/s]Loading train:  18%|█▊        | 52/285 [00:54<03:20,  1.16it/s]Loading train:  19%|█▊        | 53/285 [00:55<03:24,  1.14it/s]Loading train:  19%|█▉        | 54/285 [00:56<03:14,  1.18it/s]Loading train:  19%|█▉        | 55/285 [00:57<03:12,  1.19it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:08,  1.22it/s]Loading train:  20%|██        | 57/285 [00:58<03:10,  1.20it/s]Loading train:  20%|██        | 58/285 [00:59<03:03,  1.24it/s]Loading train:  21%|██        | 59/285 [01:00<02:58,  1.27it/s]Loading train:  21%|██        | 60/285 [01:01<02:58,  1.26it/s]Loading train:  21%|██▏       | 61/285 [01:01<02:58,  1.25it/s]Loading train:  22%|██▏       | 62/285 [01:02<02:57,  1.26it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:01,  1.22it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:36,  1.02it/s]Loading train:  23%|██▎       | 65/285 [01:06<04:17,  1.17s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:26,  1.22s/it]Loading train:  24%|██▎       | 67/285 [01:08<03:59,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:46,  1.04s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:29,  1.03it/s]Loading train:  25%|██▍       | 70/285 [01:11<03:21,  1.07it/s]Loading train:  25%|██▍       | 71/285 [01:12<03:11,  1.12it/s]Loading train:  25%|██▌       | 72/285 [01:12<03:03,  1.16it/s]Loading train:  26%|██▌       | 73/285 [01:13<03:10,  1.12it/s]Loading train:  26%|██▌       | 74/285 [01:14<03:02,  1.16it/s]Loading train:  26%|██▋       | 75/285 [01:15<02:56,  1.19it/s]Loading train:  27%|██▋       | 76/285 [01:16<02:59,  1.17it/s]Loading train:  27%|██▋       | 77/285 [01:17<02:55,  1.19it/s]Loading train:  27%|██▋       | 78/285 [01:17<02:50,  1.22it/s]Loading train:  28%|██▊       | 79/285 [01:18<02:44,  1.25it/s]Loading train:  28%|██▊       | 80/285 [01:19<02:46,  1.23it/s]Loading train:  28%|██▊       | 81/285 [01:20<02:41,  1.26it/s]Loading train:  29%|██▉       | 82/285 [01:21<02:41,  1.26it/s]Loading train:  29%|██▉       | 83/285 [01:21<02:43,  1.23it/s]Loading train:  29%|██▉       | 84/285 [01:22<02:41,  1.24it/s]Loading train:  30%|██▉       | 85/285 [01:23<02:50,  1.17it/s]Loading train:  30%|███       | 86/285 [01:24<02:59,  1.11it/s]Loading train:  31%|███       | 87/285 [01:25<03:09,  1.05it/s]Loading train:  31%|███       | 88/285 [01:26<03:13,  1.02it/s]Loading train:  31%|███       | 89/285 [01:27<03:17,  1.01s/it]Loading train:  32%|███▏      | 90/285 [01:28<03:15,  1.00s/it]Loading train:  32%|███▏      | 91/285 [01:29<03:10,  1.02it/s]Loading train:  32%|███▏      | 92/285 [01:30<03:14,  1.01s/it]Loading train:  33%|███▎      | 93/285 [01:31<03:11,  1.00it/s]Loading train:  33%|███▎      | 94/285 [01:32<03:13,  1.01s/it]Loading train:  33%|███▎      | 95/285 [01:33<03:08,  1.01it/s]Loading train:  34%|███▎      | 96/285 [01:34<03:08,  1.00it/s]Loading train:  34%|███▍      | 97/285 [01:35<03:06,  1.01it/s]Loading train:  34%|███▍      | 98/285 [01:36<03:06,  1.00it/s]Loading train:  35%|███▍      | 99/285 [01:37<03:04,  1.01it/s]Loading train:  35%|███▌      | 100/285 [01:38<03:05,  1.00s/it]Loading train:  35%|███▌      | 101/285 [01:39<03:06,  1.01s/it]Loading train:  36%|███▌      | 102/285 [01:40<03:08,  1.03s/it]Loading train:  36%|███▌      | 103/285 [01:41<03:03,  1.01s/it]Loading train:  36%|███▋      | 104/285 [01:42<03:05,  1.03s/it]Loading train:  37%|███▋      | 105/285 [01:43<02:58,  1.01it/s]Loading train:  37%|███▋      | 106/285 [01:44<03:01,  1.01s/it]Loading train:  38%|███▊      | 107/285 [01:45<02:51,  1.04it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:49,  1.04it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:44,  1.07it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:43,  1.07it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:40,  1.09it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:36,  1.10it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:38,  1.09it/s]Loading train:  40%|████      | 114/285 [01:52<02:37,  1.08it/s]Loading train:  40%|████      | 115/285 [01:53<02:35,  1.09it/s]Loading train:  41%|████      | 116/285 [01:53<02:29,  1.13it/s]Loading train:  41%|████      | 117/285 [01:54<02:27,  1.14it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:24,  1.15it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:22,  1.16it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:23,  1.15it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [01:59<02:48,  1.03s/it]Loading train:  43%|████▎     | 123/285 [02:00<02:54,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:44,  1.02s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:29,  1.07it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:27,  1.08it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:18,  1.14it/s]Loading train:  45%|████▍     | 128/285 [02:04<02:13,  1.18it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:10,  1.19it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:11,  1.18it/s]Loading train:  46%|████▌     | 131/285 [02:07<02:04,  1.24it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:04,  1.23it/s]Loading train:  47%|████▋     | 133/285 [02:08<02:03,  1.24it/s]Loading train:  47%|████▋     | 134/285 [02:09<02:02,  1.23it/s]Loading train:  47%|████▋     | 135/285 [02:10<02:01,  1.24it/s]Loading train:  48%|████▊     | 136/285 [02:11<02:02,  1.21it/s]Loading train:  48%|████▊     | 137/285 [02:12<01:57,  1.26it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:55,  1.28it/s]Loading train:  49%|████▉     | 139/285 [02:13<01:59,  1.23it/s]Loading train:  49%|████▉     | 140/285 [02:14<01:55,  1.25it/s]Loading train:  49%|████▉     | 141/285 [02:15<01:57,  1.22it/s]Loading train:  50%|████▉     | 142/285 [02:16<01:54,  1.25it/s]Loading train:  50%|█████     | 143/285 [02:17<01:54,  1.24it/s]Loading train:  51%|█████     | 144/285 [02:17<01:52,  1.26it/s]Loading train:  51%|█████     | 145/285 [02:18<01:53,  1.23it/s]Loading train:  51%|█████     | 146/285 [02:19<01:53,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:20<01:52,  1.23it/s]Loading train:  52%|█████▏    | 148/285 [02:21<01:47,  1.27it/s]Loading train:  52%|█████▏    | 149/285 [02:21<01:43,  1.31it/s]Loading train:  53%|█████▎    | 150/285 [02:22<01:48,  1.25it/s]Loading train:  53%|█████▎    | 151/285 [02:23<01:43,  1.30it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:46,  1.24it/s]Loading train:  54%|█████▎    | 153/285 [02:24<01:42,  1.29it/s]Loading train:  54%|█████▍    | 154/285 [02:25<01:44,  1.26it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:39,  1.31it/s]Loading train:  55%|█████▍    | 156/285 [02:27<01:37,  1.33it/s]Loading train:  55%|█████▌    | 157/285 [02:27<01:37,  1.31it/s]Loading train:  55%|█████▌    | 158/285 [02:28<01:33,  1.36it/s]Loading train:  56%|█████▌    | 159/285 [02:29<01:37,  1.29it/s]Loading train:  56%|█████▌    | 160/285 [02:30<01:38,  1.27it/s]Loading train:  56%|█████▋    | 161/285 [02:31<01:43,  1.20it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:40,  1.22it/s]Loading train:  57%|█████▋    | 163/285 [02:32<01:37,  1.25it/s]Loading train:  58%|█████▊    | 164/285 [02:33<01:34,  1.29it/s]Loading train:  58%|█████▊    | 165/285 [02:34<01:29,  1.34it/s]Loading train:  58%|█████▊    | 166/285 [02:35<01:35,  1.25it/s]Loading train:  59%|█████▊    | 167/285 [02:35<01:31,  1.28it/s]Loading train:  59%|█████▉    | 168/285 [02:36<01:29,  1.30it/s]Loading train:  59%|█████▉    | 169/285 [02:37<01:31,  1.26it/s]Loading train:  60%|█████▉    | 170/285 [02:38<01:27,  1.31it/s]Loading train:  60%|██████    | 171/285 [02:38<01:24,  1.35it/s]Loading train:  60%|██████    | 172/285 [02:39<01:27,  1.29it/s]Loading train:  61%|██████    | 173/285 [02:40<01:23,  1.34it/s]Loading train:  61%|██████    | 174/285 [02:41<01:20,  1.37it/s]Loading train:  61%|██████▏   | 175/285 [02:41<01:23,  1.32it/s]Loading train:  62%|██████▏   | 176/285 [02:42<01:21,  1.34it/s]Loading train:  62%|██████▏   | 177/285 [02:43<01:19,  1.36it/s]Loading train:  62%|██████▏   | 178/285 [02:44<01:25,  1.25it/s]Loading train:  63%|██████▎   | 179/285 [02:44<01:23,  1.26it/s]Loading train:  63%|██████▎   | 180/285 [02:45<01:20,  1.31it/s]Loading train:  64%|██████▎   | 181/285 [02:46<01:21,  1.27it/s]Loading train:  64%|██████▍   | 182/285 [02:47<01:18,  1.32it/s]Loading train:  64%|██████▍   | 183/285 [02:47<01:17,  1.32it/s]Loading train:  65%|██████▍   | 184/285 [02:48<01:16,  1.31it/s]Loading train:  65%|██████▍   | 185/285 [02:49<01:15,  1.32it/s]Loading train:  65%|██████▌   | 186/285 [02:50<01:12,  1.36it/s]Loading train:  66%|██████▌   | 187/285 [02:50<01:10,  1.39it/s]Loading train:  66%|██████▌   | 188/285 [02:51<01:07,  1.44it/s]Loading train:  66%|██████▋   | 189/285 [02:52<01:05,  1.46it/s]Loading train:  67%|██████▋   | 190/285 [02:52<01:07,  1.42it/s]Loading train:  67%|██████▋   | 191/285 [02:53<01:02,  1.50it/s]Loading train:  67%|██████▋   | 192/285 [02:54<01:01,  1.51it/s]Loading train:  68%|██████▊   | 193/285 [02:55<01:08,  1.34it/s]Loading train:  68%|██████▊   | 194/285 [02:55<01:07,  1.34it/s]Loading train:  68%|██████▊   | 195/285 [02:56<01:06,  1.36it/s]Loading train:  69%|██████▉   | 196/285 [02:57<01:09,  1.28it/s]Loading train:  69%|██████▉   | 197/285 [02:58<01:08,  1.28it/s]Loading train:  69%|██████▉   | 198/285 [02:59<01:11,  1.22it/s]Loading train:  70%|██████▉   | 199/285 [02:59<01:08,  1.26it/s]Loading train:  70%|███████   | 200/285 [03:00<01:07,  1.26it/s]Loading train:  71%|███████   | 201/285 [03:01<01:08,  1.22it/s]Loading train:  71%|███████   | 202/285 [03:02<01:07,  1.23it/s]Loading train:  71%|███████   | 203/285 [03:03<01:06,  1.24it/s]Loading train:  72%|███████▏  | 204/285 [03:03<01:03,  1.27it/s]Loading train:  72%|███████▏  | 205/285 [03:04<01:01,  1.30it/s]Loading train:  72%|███████▏  | 206/285 [03:05<01:01,  1.29it/s]Loading train:  73%|███████▎  | 207/285 [03:06<01:02,  1.26it/s]Loading train:  73%|███████▎  | 208/285 [03:07<01:02,  1.24it/s]Loading train:  73%|███████▎  | 209/285 [03:07<01:03,  1.20it/s]Loading train:  74%|███████▎  | 210/285 [03:08<01:02,  1.20it/s]Loading train:  74%|███████▍  | 211/285 [03:09<01:01,  1.20it/s]Loading train:  74%|███████▍  | 212/285 [03:10<00:59,  1.23it/s]Loading train:  75%|███████▍  | 213/285 [03:11<00:58,  1.23it/s]Loading train:  75%|███████▌  | 214/285 [03:12<01:00,  1.17it/s]Loading train:  75%|███████▌  | 215/285 [03:12<00:56,  1.24it/s]Loading train:  76%|███████▌  | 216/285 [03:13<00:54,  1.28it/s]Loading train:  76%|███████▌  | 217/285 [03:14<00:53,  1.26it/s]Loading train:  76%|███████▋  | 218/285 [03:15<00:52,  1.28it/s]Loading train:  77%|███████▋  | 219/285 [03:15<00:50,  1.30it/s]Loading train:  77%|███████▋  | 220/285 [03:16<00:51,  1.26it/s]Loading train:  78%|███████▊  | 221/285 [03:17<00:48,  1.31it/s]Loading train:  78%|███████▊  | 222/285 [03:18<00:46,  1.34it/s]Loading train:  78%|███████▊  | 223/285 [03:18<00:46,  1.34it/s]Loading train:  79%|███████▊  | 224/285 [03:19<00:47,  1.28it/s]Loading train:  79%|███████▉  | 225/285 [03:20<00:45,  1.31it/s]Loading train:  79%|███████▉  | 226/285 [03:21<00:43,  1.35it/s]Loading train:  80%|███████▉  | 227/285 [03:21<00:44,  1.31it/s]Loading train:  80%|████████  | 228/285 [03:22<00:43,  1.32it/s]Loading train:  80%|████████  | 229/285 [03:23<00:42,  1.32it/s]Loading train:  81%|████████  | 230/285 [03:24<00:41,  1.32it/s]Loading train:  81%|████████  | 231/285 [03:25<00:43,  1.25it/s]Loading train:  81%|████████▏ | 232/285 [03:26<00:44,  1.20it/s]Loading train:  82%|████████▏ | 233/285 [03:26<00:44,  1.16it/s]Loading train:  82%|████████▏ | 234/285 [03:27<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:28<00:45,  1.10it/s]Loading train:  83%|████████▎ | 236/285 [03:29<00:46,  1.05it/s]Loading train:  83%|████████▎ | 237/285 [03:30<00:44,  1.07it/s]Loading train:  84%|████████▎ | 238/285 [03:31<00:43,  1.09it/s]Loading train:  84%|████████▍ | 239/285 [03:32<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [03:33<00:42,  1.06it/s]Loading train:  85%|████████▍ | 241/285 [03:34<00:41,  1.07it/s]Loading train:  85%|████████▍ | 242/285 [03:35<00:42,  1.02it/s]Loading train:  85%|████████▌ | 243/285 [03:36<00:40,  1.05it/s]Loading train:  86%|████████▌ | 244/285 [03:37<00:37,  1.09it/s]Loading train:  86%|████████▌ | 245/285 [03:38<00:38,  1.03it/s]Loading train:  86%|████████▋ | 246/285 [03:39<00:36,  1.06it/s]Loading train:  87%|████████▋ | 247/285 [03:40<00:35,  1.06it/s]Loading train:  87%|████████▋ | 248/285 [03:41<00:36,  1.02it/s]Loading train:  87%|████████▋ | 249/285 [03:42<00:33,  1.06it/s]Loading train:  88%|████████▊ | 250/285 [03:43<00:31,  1.11it/s]Loading train:  88%|████████▊ | 251/285 [03:43<00:29,  1.17it/s]Loading train:  88%|████████▊ | 252/285 [03:44<00:27,  1.21it/s]Loading train:  89%|████████▉ | 253/285 [03:45<00:24,  1.29it/s]Loading train:  89%|████████▉ | 254/285 [03:45<00:23,  1.30it/s]Loading train:  89%|████████▉ | 255/285 [03:46<00:21,  1.37it/s]Loading train:  90%|████████▉ | 256/285 [03:47<00:20,  1.40it/s]Loading train:  90%|█████████ | 257/285 [03:48<00:20,  1.37it/s]Loading train:  91%|█████████ | 258/285 [03:48<00:19,  1.36it/s]Loading train:  91%|█████████ | 259/285 [03:49<00:18,  1.40it/s]Loading train:  91%|█████████ | 260/285 [03:50<00:19,  1.30it/s]Loading train:  92%|█████████▏| 261/285 [03:51<00:18,  1.27it/s]Loading train:  92%|█████████▏| 262/285 [03:52<00:18,  1.23it/s]Loading train:  92%|█████████▏| 263/285 [03:52<00:17,  1.26it/s]Loading train:  93%|█████████▎| 264/285 [03:53<00:15,  1.32it/s]Loading train:  93%|█████████▎| 265/285 [03:54<00:15,  1.29it/s]Loading train:  93%|█████████▎| 266/285 [03:54<00:14,  1.33it/s]Loading train:  94%|█████████▎| 267/285 [03:55<00:13,  1.34it/s]Loading train:  94%|█████████▍| 268/285 [03:56<00:13,  1.24it/s]Loading train:  94%|█████████▍| 269/285 [03:57<00:13,  1.18it/s]Loading train:  95%|█████████▍| 270/285 [03:58<00:13,  1.12it/s]Loading train:  95%|█████████▌| 271/285 [03:59<00:12,  1.13it/s]Loading train:  95%|█████████▌| 272/285 [04:00<00:12,  1.06it/s]Loading train:  96%|█████████▌| 273/285 [04:01<00:11,  1.07it/s]Loading train:  96%|█████████▌| 274/285 [04:02<00:10,  1.04it/s]Loading train:  96%|█████████▋| 275/285 [04:03<00:10,  1.01s/it]Loading train:  97%|█████████▋| 276/285 [04:04<00:09,  1.03s/it]Loading train:  97%|█████████▋| 277/285 [04:05<00:08,  1.04s/it]Loading train:  98%|█████████▊| 278/285 [04:06<00:07,  1.04s/it]Loading train:  98%|█████████▊| 279/285 [04:07<00:06,  1.05s/it]Loading train:  98%|█████████▊| 280/285 [04:08<00:05,  1.03s/it]Loading train:  99%|█████████▊| 281/285 [04:09<00:04,  1.02s/it]Loading train:  99%|█████████▉| 282/285 [04:10<00:03,  1.04s/it]Loading train:  99%|█████████▉| 283/285 [04:11<00:02,  1.01s/it]Loading train: 100%|█████████▉| 284/285 [04:12<00:00,  1.01it/s]Loading train: 100%|██████████| 285/285 [04:13<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 60.51it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:03, 76.86it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:02, 99.54it/s]concatenating: train:  32%|███▏      | 92/285 [00:00<00:01, 125.45it/s]concatenating: train:  44%|████▎     | 124/285 [00:00<00:01, 153.42it/s]concatenating: train:  55%|█████▌    | 157/285 [00:00<00:00, 182.51it/s]concatenating: train:  68%|██████▊   | 194/285 [00:00<00:00, 214.93it/s]concatenating: train:  81%|████████  | 230/285 [00:00<00:00, 244.37it/s]concatenating: train:  93%|█████████▎| 264/285 [00:00<00:00, 265.83it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 289.62it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.31s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 514.13it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-07 04:33:06.126880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 04:33:06.126990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 04:33:06.127006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 04:33:06.127016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 04:33:06.127471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 20s - loss: 14027.0852 - acc: 0.8640 - mDice: 0.1664 - val_loss: 9137.4275 - val_acc: 0.8971 - val_mDice: 0.2655

Epoch 00001: val_mDice improved from -inf to 0.26548, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 6418.7477 - acc: 0.8767 - mDice: 0.3213 - val_loss: 4851.3806 - val_acc: 0.9056 - val_mDice: 0.3733

Epoch 00002: val_mDice improved from 0.26548 to 0.37330, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 4395.4019 - acc: 0.8891 - mDice: 0.4270 - val_loss: 4202.6926 - val_acc: 0.9153 - val_mDice: 0.4184

Epoch 00003: val_mDice improved from 0.37330 to 0.41840, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 3553.2984 - acc: 0.9014 - mDice: 0.4931 - val_loss: 3703.8902 - val_acc: 0.9260 - val_mDice: 0.4531

Epoch 00004: val_mDice improved from 0.41840 to 0.45305, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 11s - loss: 3125.1539 - acc: 0.9102 - mDice: 0.5340 - val_loss: 3447.8843 - val_acc: 0.9283 - val_mDice: 0.4759

Epoch 00005: val_mDice improved from 0.45305 to 0.47586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 2876.0141 - acc: 0.9152 - mDice: 0.5607 - val_loss: 3263.1103 - val_acc: 0.9332 - val_mDice: 0.4896

Epoch 00006: val_mDice improved from 0.47586 to 0.48964, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 11s - loss: 2695.1156 - acc: 0.9191 - mDice: 0.5807 - val_loss: 3148.1996 - val_acc: 0.9337 - val_mDice: 0.5002

Epoch 00007: val_mDice improved from 0.48964 to 0.50018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 2569.4723 - acc: 0.9220 - mDice: 0.5952 - val_loss: 3091.8203 - val_acc: 0.9341 - val_mDice: 0.5052

Epoch 00008: val_mDice improved from 0.50018 to 0.50523, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 2449.5549 - acc: 0.9243 - mDice: 0.6093 - val_loss: 3032.4577 - val_acc: 0.9360 - val_mDice: 0.5102

Epoch 00009: val_mDice improved from 0.50523 to 0.51021, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 11s - loss: 2352.9550 - acc: 0.9265 - mDice: 0.6215 - val_loss: 2926.5014 - val_acc: 0.9362 - val_mDice: 0.5199

Epoch 00010: val_mDice improved from 0.51021 to 0.51987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 11s - loss: 2277.2264 - acc: 0.9279 - mDice: 0.6306 - val_loss: 2994.2425 - val_acc: 0.9356 - val_mDice: 0.5123

Epoch 00011: val_mDice did not improve from 0.51987
Epoch 12/300
 - 11s - loss: 2206.4507 - acc: 0.9294 - mDice: 0.6396 - val_loss: 2954.3256 - val_acc: 0.9381 - val_mDice: 0.5167

Epoch 00012: val_mDice did not improve from 0.51987
Epoch 13/300
 - 11s - loss: 2137.6187 - acc: 0.9306 - mDice: 0.6484 - val_loss: 2944.2693 - val_acc: 0.9373 - val_mDice: 0.5175

Epoch 00013: val_mDice did not improve from 0.51987
Epoch 14/300
 - 11s - loss: 2068.3425 - acc: 0.9320 - mDice: 0.6574 - val_loss: 2896.5174 - val_acc: 0.9367 - val_mDice: 0.5231

Epoch 00014: val_mDice improved from 0.51987 to 0.52311, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 11s - loss: 2011.7551 - acc: 0.9332 - mDice: 0.6648 - val_loss: 2953.0848 - val_acc: 0.9387 - val_mDice: 0.5172

Epoch 00015: val_mDice did not improve from 0.52311
Epoch 16/300
 - 11s - loss: 1959.5435 - acc: 0.9343 - mDice: 0.6717 - val_loss: 2925.1795 - val_acc: 0.9391 - val_mDice: 0.5206

Epoch 00016: val_mDice did not improve from 0.52311
Epoch 17/300
 - 11s - loss: 1921.9489 - acc: 0.9349 - mDice: 0.6767 - val_loss: 2803.0872 - val_acc: 0.9393 - val_mDice: 0.5323

Epoch 00017: val_mDice improved from 0.52311 to 0.53234, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 11s - loss: 1875.1819 - acc: 0.9360 - mDice: 0.6830 - val_loss: 2780.1454 - val_acc: 0.9398 - val_mDice: 0.5346

Epoch 00018: val_mDice improved from 0.53234 to 0.53458, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 11s - loss: 1837.2538 - acc: 0.9367 - mDice: 0.6882 - val_loss: 2876.0346 - val_acc: 0.9405 - val_mDice: 0.5241

Epoch 00019: val_mDice did not improve from 0.53458
Epoch 20/300
 - 11s - loss: 1795.6654 - acc: 0.9376 - mDice: 0.6941 - val_loss: 2894.7588 - val_acc: 0.9386 - val_mDice: 0.5240

Epoch 00020: val_mDice did not improve from 0.53458
Epoch 21/300
 - 11s - loss: 1752.2049 - acc: 0.9383 - mDice: 0.7001 - val_loss: 2680.2441 - val_acc: 0.9410 - val_mDice: 0.5454

Epoch 00021: val_mDice improved from 0.53458 to 0.54539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 11s - loss: 1728.5980 - acc: 0.9390 - mDice: 0.7034 - val_loss: 2689.5132 - val_acc: 0.9401 - val_mDice: 0.5448

Epoch 00022: val_mDice did not improve from 0.54539
Epoch 23/300
 - 11s - loss: 1702.3489 - acc: 0.9396 - mDice: 0.7072 - val_loss: 2769.2043 - val_acc: 0.9408 - val_mDice: 0.5360

Epoch 00023: val_mDice did not improve from 0.54539
Epoch 24/300
 - 11s - loss: 1662.8743 - acc: 0.9404 - mDice: 0.7127 - val_loss: 2798.0257 - val_acc: 0.9403 - val_mDice: 0.5334

Epoch 00024: val_mDice did not improve from 0.54539
Epoch 25/300
 - 11s - loss: 1633.9931 - acc: 0.9407 - mDice: 0.7169 - val_loss: 2742.8403 - val_acc: 0.9412 - val_mDice: 0.5408

Epoch 00025: val_mDice did not improve from 0.54539
Epoch 26/300
 - 11s - loss: 1615.2815 - acc: 0.9415 - mDice: 0.7195 - val_loss: 2681.7558 - val_acc: 0.9427 - val_mDice: 0.5475

Epoch 00026: val_mDice improved from 0.54539 to 0.54745, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 27/300
 - 11s - loss: 1587.2670 - acc: 0.9419 - mDice: 0.7236 - val_loss: 2743.6736 - val_acc: 0.9440 - val_mDice: 0.5380

Epoch 00027: val_mDice did not improve from 0.54745
Epoch 28/300
 - 11s - loss: 1564.9591 - acc: 0.9424 - mDice: 0.7269 - val_loss: 2726.8950 - val_acc: 0.9397 - val_mDice: 0.5419

Epoch 00028: val_mDice did not improve from 0.54745
Epoch 29/300
 - 11s - loss: 1541.9362 - acc: 0.9428 - mDice: 0.7303 - val_loss: 2938.4613 - val_acc: 0.9417 - val_mDice: 0.5161

Epoch 00029: val_mDice did not improve from 0.54745
Epoch 30/300
 - 11s - loss: 1517.8809 - acc: 0.9432 - mDice: 0.7338 - val_loss: 2763.3543 - val_acc: 0.9436 - val_mDice: 0.5376

Epoch 00030: val_mDice did not improve from 0.54745
Epoch 31/300
 - 11s - loss: 1490.1668 - acc: 0.9438 - mDice: 0.7378 - val_loss: 2835.8615 - val_acc: 0.9428 - val_mDice: 0.5270

Epoch 00031: val_mDice did not improve from 0.54745
Epoch 32/300
 - 11s - loss: 1471.7743 - acc: 0.9443 - mDice: 0.7406 - val_loss: 2788.3150 - val_acc: 0.9431 - val_mDice: 0.5335

Epoch 00032: val_mDice did not improve from 0.54745
Epoch 33/300
 - 11s - loss: 1453.0968 - acc: 0.9447 - mDice: 0.7434 - val_loss: 2939.8424 - val_acc: 0.9428 - val_mDice: 0.5167

Epoch 00033: val_mDice did not improve from 0.54745
Epoch 34/300
 - 11s - loss: 1434.1806 - acc: 0.9449 - mDice: 0.7462 - val_loss: 2773.4422 - val_acc: 0.9438 - val_mDice: 0.5390

Epoch 00034: val_mDice did not improve from 0.54745
Epoch 35/300
 - 12s - loss: 1417.1528 - acc: 0.9454 - mDice: 0.7488 - val_loss: 2779.1117 - val_acc: 0.9441 - val_mDice: 0.5366

Epoch 00035: val_mDice did not improve from 0.54745
Epoch 36/300
 - 11s - loss: 1405.4252 - acc: 0.9456 - mDice: 0.7505 - val_loss: 2778.6673 - val_acc: 0.9435 - val_mDice: 0.5373

Epoch 00036: val_mDice did not improve from 0.54745
Epoch 37/300
 - 11s - loss: 1388.1507 - acc: 0.9459 - mDice: 0.7532 - val_loss: 2828.9680 - val_acc: 0.9448 - val_mDice: 0.5298

Epoch 00037: val_mDice did not improve from 0.54745
Epoch 38/300
 - 12s - loss: 1368.5993 - acc: 0.9463 - mDice: 0.7561 - val_loss: 2647.3247 - val_acc: 0.9450 - val_mDice: 0.5491

Epoch 00038: val_mDice improved from 0.54745 to 0.54915, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 39/300
 - 11s - loss: 1354.6129 - acc: 0.9468 - mDice: 0.7583 - val_loss: 3092.5715 - val_acc: 0.9422 - val_mDice: 0.4993

Epoch 00039: val_mDice did not improve from 0.54915
Epoch 40/300
 - 11s - loss: 1346.1605 - acc: 0.9470 - mDice: 0.7596 - val_loss: 2905.7638 - val_acc: 0.9433 - val_mDice: 0.5243

Epoch 00040: val_mDice did not improve from 0.54915
Epoch 41/300
 - 11s - loss: 1330.8878 - acc: 0.9473 - mDice: 0.7620 - val_loss: 2700.7934 - val_acc: 0.9455 - val_mDice: 0.5443

Epoch 00041: val_mDice did not improve from 0.54915
Epoch 42/300
 - 12s - loss: 1311.3625 - acc: 0.9476 - mDice: 0.7649 - val_loss: 2881.6225 - val_acc: 0.9451 - val_mDice: 0.5242

Epoch 00042: val_mDice did not improve from 0.54915
Epoch 43/300
 - 12s - loss: 1305.2355 - acc: 0.9478 - mDice: 0.7659 - val_loss: 2649.0483 - val_acc: 0.9445 - val_mDice: 0.5500

Epoch 00043: val_mDice improved from 0.54915 to 0.54997, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 44/300
 - 14s - loss: 1293.2782 - acc: 0.9480 - mDice: 0.7678 - val_loss: 2822.8284 - val_acc: 0.9446 - val_mDice: 0.5315

Epoch 00044: val_mDice did not improve from 0.54997
Epoch 45/300
 - 13s - loss: 1282.8747 - acc: 0.9483 - mDice: 0.7694 - val_loss: 2816.4571 - val_acc: 0.9439 - val_mDice: 0.5318

Epoch 00045: val_mDice did not improve from 0.54997
Epoch 46/300
 - 14s - loss: 1271.6568 - acc: 0.9485 - mDice: 0.7711 - val_loss: 2893.3554 - val_acc: 0.9429 - val_mDice: 0.5225

Epoch 00046: val_mDice did not improve from 0.54997
Epoch 47/300
 - 13s - loss: 1257.0630 - acc: 0.9488 - mDice: 0.7734 - val_loss: 3141.6350 - val_acc: 0.9433 - val_mDice: 0.4958

Epoch 00047: val_mDice did not improve from 0.54997
Epoch 48/300
 - 14s - loss: 1247.2403 - acc: 0.9490 - mDice: 0.7750 - val_loss: 2896.4874 - val_acc: 0.9439 - val_mDice: 0.5209

Epoch 00048: val_mDice did not improve from 0.54997
Epoch 49/300
 - 14s - loss: 1241.8080 - acc: 0.9491 - mDice: 0.7758 - val_loss: 2866.5678 - val_acc: 0.9440 - val_mDice: 0.5260

Epoch 00049: val_mDice did not improve from 0.54997
Epoch 50/300
 - 13s - loss: 1227.0583 - acc: 0.9495 - mDice: 0.7782 - val_loss: 3049.4957 - val_acc: 0.9429 - val_mDice: 0.5102

Epoch 00050: val_mDice did not improve from 0.54997
Epoch 51/300
 - 14s - loss: 1220.1294 - acc: 0.9495 - mDice: 0.7793 - val_loss: 2733.6716 - val_acc: 0.9440 - val_mDice: 0.5412

Epoch 00051: val_mDice did not improve from 0.54997
Epoch 52/300
 - 14s - loss: 1211.2600 - acc: 0.9497 - mDice: 0.7807 - val_loss: 3074.4628 - val_acc: 0.9416 - val_mDice: 0.5053

Epoch 00052: val_mDice did not improve from 0.54997
Epoch 53/300
 - 14s - loss: 1195.7076 - acc: 0.9501 - mDice: 0.7831 - val_loss: 2926.3606 - val_acc: 0.9446 - val_mDice: 0.5206

Epoch 00053: val_mDice did not improve from 0.54997
Epoch 54/300
 - 14s - loss: 1185.8500 - acc: 0.9503 - mDice: 0.7846 - val_loss: 2979.9384 - val_acc: 0.9430 - val_mDice: 0.5176

Epoch 00054: val_mDice did not improve from 0.54997
Epoch 55/300
 - 13s - loss: 1178.6089 - acc: 0.9505 - mDice: 0.7858 - val_loss: 3030.0283 - val_acc: 0.9457 - val_mDice: 0.5098

Epoch 00055: val_mDice did not improve from 0.54997
Epoch 56/300
 - 14s - loss: 1171.2324 - acc: 0.9507 - mDice: 0.7870 - val_loss: 2886.7381 - val_acc: 0.9446 - val_mDice: 0.5246

Epoch 00056: val_mDice did not improve from 0.54997
Epoch 57/300
 - 14s - loss: 1160.6618 - acc: 0.9508 - mDice: 0.7887 - val_loss: 2983.1345 - val_acc: 0.9439 - val_mDice: 0.5150

Epoch 00057: val_mDice did not improve from 0.54997
Epoch 58/300
 - 13s - loss: 1155.0082 - acc: 0.9510 - mDice: 0.7896 - val_loss: 3094.6819 - val_acc: 0.9445 - val_mDice: 0.5071

Epoch 00058: val_mDice did not improve from 0.54997
Epoch 59/300
 - 14s - loss: 1149.8248 - acc: 0.9512 - mDice: 0.7904 - val_loss: 2804.7844 - val_acc: 0.9418 - val_mDice: 0.5355

Epoch 00059: val_mDice did not improve from 0.54997
Epoch 60/300
 - 13s - loss: 1138.8742 - acc: 0.9514 - mDice: 0.7922 - val_loss: 2987.7357 - val_acc: 0.9443 - val_mDice: 0.5134

Epoch 00060: val_mDice did not improve from 0.54997
Epoch 61/300
 - 14s - loss: 1131.8717 - acc: 0.9515 - mDice: 0.7933 - val_loss: 2925.0686 - val_acc: 0.9446 - val_mDice: 0.5188

Epoch 00061: val_mDice did not improve from 0.54997
Epoch 62/300
 - 14s - loss: 1128.7470 - acc: 0.9516 - mDice: 0.7938 - val_loss: 2967.1533 - val_acc: 0.9432 - val_mDice: 0.5196

Epoch 00062: val_mDice did not improve from 0.54997
Epoch 63/300
 - 15s - loss: 1120.0174 - acc: 0.9518 - mDice: 0.7951 - val_loss: 2805.7469 - val_acc: 0.9437 - val_mDice: 0.5318

Epoch 00063: val_mDice did not improve from 0.54997
Epoch 64/300
 - 16s - loss: 1115.1459 - acc: 0.9520 - mDice: 0.7959 - val_loss: 2932.8023 - val_acc: 0.9450 - val_mDice: 0.5212

Epoch 00064: val_mDice did not improve from 0.54997
Epoch 65/300
 - 16s - loss: 1108.7037 - acc: 0.9520 - mDice: 0.7970 - val_loss: 3073.6645 - val_acc: 0.9437 - val_mDice: 0.5090

Epoch 00065: val_mDice did not improve from 0.54997
Epoch 66/300
 - 15s - loss: 1098.1676 - acc: 0.9522 - mDice: 0.7987 - val_loss: 3070.9748 - val_acc: 0.9450 - val_mDice: 0.5089

Epoch 00066: val_mDice did not improve from 0.54997
Epoch 67/300
 - 16s - loss: 1098.7933 - acc: 0.9523 - mDice: 0.7986 - val_loss: 2982.1676 - val_acc: 0.9430 - val_mDice: 0.5167

Epoch 00067: val_mDice did not improve from 0.54997
Epoch 68/300
 - 17s - loss: 1081.2721 - acc: 0.9526 - mDice: 0.8014 - val_loss: 2852.4753 - val_acc: 0.9434 - val_mDice: 0.5325

Epoch 00068: val_mDice did not improve from 0.54997
Epoch 69/300
 - 15s - loss: 1080.5489 - acc: 0.9526 - mDice: 0.8016 - val_loss: 3056.4866 - val_acc: 0.9399 - val_mDice: 0.5109

Epoch 00069: val_mDice did not improve from 0.54997
Epoch 70/300
 - 16s - loss: 1067.7460 - acc: 0.9528 - mDice: 0.8037 - val_loss: 3044.6611 - val_acc: 0.9393 - val_mDice: 0.5143

Epoch 00070: val_mDice did not improve from 0.54997
Epoch 71/300
 - 16s - loss: 1074.7978 - acc: 0.9527 - mDice: 0.8025 - val_loss: 3139.7970 - val_acc: 0.9383 - val_mDice: 0.5048

Epoch 00071: val_mDice did not improve from 0.54997
Epoch 72/300
 - 13s - loss: 1070.7699 - acc: 0.9528 - mDice: 0.8032 - val_loss: 2865.1529 - val_acc: 0.9455 - val_mDice: 0.5304

Epoch 00072: val_mDice did not improve from 0.54997
Epoch 73/300
 - 13s - loss: 1058.5922 - acc: 0.9531 - mDice: 0.8052 - val_loss: 2997.6795 - val_acc: 0.9436 - val_mDice: 0.5206

Epoch 00073: val_mDice did not improve from 0.54997
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
{'val_loss': [9137.427548363095, 4851.380615234375, 4202.69255719866, 3703.890159970238, 3447.88427734375, 3263.110345749628, 3148.1995558965773, 3091.8203241257443, 3032.4576648530506, 2926.5013718377977, 2994.242518833705, 2954.3255615234375, 2944.2693074544272, 2896.517374674479, 2953.084803989955, 2925.1795421781994, 2803.087184361049, 2780.145443870908, 2876.0345924014136, 2894.7588471912204, 2680.244137718564, 2689.51319812593, 2769.204313732329, 2798.025721958705, 2742.84030296689, 2681.7557634626114, 2743.673614501953, 2726.894981747582, 2938.4612819126673, 2763.3543061755954, 2835.8614945184618, 2788.314954485212, 2939.8424050467356, 2773.4422433035716, 2779.1117204938614, 2778.667285737537, 2828.968038649786, 2647.324737548828, 3092.5714903331937, 2905.7637706938244, 2700.793377830869, 2881.6224728538878, 2649.048338390532, 2822.828370593843, 2816.4570908319383, 2893.3554324195497, 3141.63503519694, 2896.4873780750095, 2866.5677679152714, 3049.495651971726, 2733.671638125465, 3074.4627583821616, 2926.3605680919827, 2979.9384242466517, 3030.028336297898, 2886.7381453741164, 2983.134547642299, 3094.6818963913693, 2804.7844034830728, 2987.7356610979355, 2925.06855628604, 2967.1533203125, 2805.74685160319, 2932.802308582124, 3073.664504278274, 3070.974849155971, 2982.1676388695128, 2852.4752575102307, 3056.486569359189, 3044.661077590216, 3139.7970203218006, 2865.152864002046, 2997.6795102074034], 'val_acc': [0.8971291439873832, 0.905595220270611, 0.9153204957644144, 0.9259844422340393, 0.9283150150662377, 0.9331982731819153, 0.9336561390331813, 0.9340521749996004, 0.9360096397854033, 0.9362339661234901, 0.9356295750254676, 0.9381456091290429, 0.9373283074015663, 0.9366941395260039, 0.9386561456180754, 0.9391071285520282, 0.9393497932524908, 0.9398076988401867, 0.9404738999548412, 0.9385714474178496, 0.9410050341061184, 0.9400664085433597, 0.9408424894014994, 0.9402792794363839, 0.9412499722980318, 0.9427472267832074, 0.9439995345615205, 0.9397298324675787, 0.9417445290656317, 0.9436149398485819, 0.9428205149514335, 0.9430608834539141, 0.9427930343718756, 0.9437889314833141, 0.9441391939208621, 0.943498188541049, 0.9447710769517081, 0.9450343620209467, 0.9422161352066767, 0.9433356324831644, 0.9455219649133229, 0.9451076246443249, 0.9445054758162725, 0.9445925127892267, 0.9439194145656767, 0.9428777666318984, 0.9433264476912362, 0.9439469036601839, 0.9440407611074901, 0.9429166402135577, 0.9439583392370314, 0.9416437489645821, 0.9445512606984093, 0.943028864406404, 0.9456845209712074, 0.9446039568810236, 0.9438598865554446, 0.944489442166828, 0.9417788414728074, 0.9442582329114279, 0.9445627076285226, 0.943184514840444, 0.9437408645947775, 0.945036646865663, 0.9436927437782288, 0.9449702103932699, 0.9429716269175211, 0.9434432217053005, 0.9399404610906329, 0.9393040481067839, 0.938298986071632, 0.9454624340647743, 0.9435737133026123], 'val_mDice': [0.26548338929812115, 0.3732998014560768, 0.4184045028828439, 0.45305261707731653, 0.4758615766962369, 0.4896364392978804, 0.500178146042994, 0.5052324489113831, 0.5102125434648423, 0.5198665463498661, 0.5122609830328396, 0.5167438214023908, 0.5175343908014751, 0.5231071444494384, 0.5171717231472334, 0.5205914007411117, 0.5323368074993292, 0.5345809417111533, 0.5241313378016154, 0.5240241594257808, 0.545394785347439, 0.5448087109696298, 0.535965241137005, 0.5334355692778315, 0.540798035405931, 0.5474514413092818, 0.537969990500382, 0.5418741899941649, 0.5161208061590081, 0.5376347789452189, 0.5270200455117793, 0.5335310135214102, 0.5166667896722045, 0.5390267173449198, 0.5365747993900662, 0.5372827294326964, 0.5297770980922949, 0.5491471645377931, 0.4992902342762266, 0.5243270579902899, 0.5443025430043539, 0.5242187244196733, 0.5499733166680449, 0.5315306080239159, 0.5318298464020094, 0.5224666137780462, 0.4957978842513902, 0.5208932878006072, 0.526004250560488, 0.510160295736222, 0.5412385845113368, 0.5052696633197012, 0.5205731182580903, 0.5175761365819544, 0.5097523363573211, 0.5245784696723733, 0.5150080839438098, 0.5071317771715778, 0.5354970668752989, 0.5134154018901643, 0.5187782400420734, 0.5196044530187335, 0.5317955348818075, 0.5211898432601065, 0.5089542787699473, 0.5089274524223237, 0.5166703189412752, 0.5325417248975663, 0.5109213886871224, 0.514323737294901, 0.5047649216084253, 0.5304187711860452, 0.5206287104104247], 'loss': [14027.085232801053, 6418.74765611821, 4395.401925505621, 3553.2984406629553, 3125.1538881383144, 2876.0140800704057, 2695.1156000681917, 2569.472349015003, 2449.5549006229517, 2352.9550163955937, 2277.2263526953275, 2206.450650010882, 2137.61873603028, 2068.3424983262694, 2011.755103678103, 1959.5434565370383, 1921.948867177145, 1875.1819297388981, 1837.253761681284, 1795.665380068636, 1752.2048651197179, 1728.5980101762443, 1702.3489063469597, 1662.8743259421842, 1633.9930697621835, 1615.2815412554824, 1587.2669871889007, 1564.9590903010605, 1541.936185773177, 1517.8808680354732, 1490.166818060212, 1471.774335553427, 1453.0968167606704, 1434.1805790580718, 1417.1528113684903, 1405.4252325807759, 1388.1506738554244, 1368.5993205435086, 1354.6128873161344, 1346.1605121648586, 1330.8877781988776, 1311.3624711662721, 1305.2354673374957, 1293.2781817213934, 1282.8746646537656, 1271.6567668631653, 1257.0630275828544, 1247.2403067887944, 1241.8079620531948, 1227.0582580625241, 1220.12939117767, 1211.259960968094, 1195.707604100301, 1185.8500123458812, 1178.6088863186737, 1171.2323690767068, 1160.6617526952898, 1155.0081805701152, 1149.8248409155776, 1138.8741545565952, 1131.8716889104335, 1128.7469755650393, 1120.0173582713544, 1115.145877259348, 1108.7036611256583, 1098.167616988874, 1098.7932841865595, 1081.2721402293482, 1080.5489186834272, 1067.7460255370058, 1074.7978260988257, 1070.7699357388174, 1058.5921673691064], 'acc': [0.8640380801436573, 0.8767314904890287, 0.8890712562613067, 0.9014358663917484, 0.9102359480289727, 0.9152293650198929, 0.9190642766371522, 0.921996859185425, 0.9242806311331205, 0.9264735432173996, 0.9278688827001316, 0.9294464430736397, 0.9305591519246195, 0.9319717564954219, 0.9331915672284595, 0.9342642158172207, 0.9348514127506097, 0.936011742908922, 0.9367016121696272, 0.9375797561742402, 0.9382978548244265, 0.9390415268893966, 0.9395899146605668, 0.9404312834496992, 0.9407435445995121, 0.9414864359091352, 0.9418861730401631, 0.9423941468742052, 0.9428414092464715, 0.9432498849562099, 0.9438168510136771, 0.9442861726547405, 0.944687396316646, 0.9448964973738917, 0.9454237496620753, 0.9456290261856227, 0.9459261137533216, 0.9462768438695736, 0.946809955477048, 0.9469843227348048, 0.9472791174254667, 0.9475641294851316, 0.9478087519574354, 0.9479621982951373, 0.9482631560624025, 0.948467853948609, 0.9488324849780686, 0.9489903311658645, 0.9491253315724457, 0.9494652845208209, 0.9495025228185416, 0.9497307901417379, 0.9501248499849341, 0.9503472270546379, 0.9505370980929795, 0.9507026837835979, 0.9508365510699145, 0.9509582942750657, 0.9512443492608836, 0.9514070197937, 0.9514506954849858, 0.9515818706224345, 0.9517532731725091, 0.952042645035577, 0.9520283259705631, 0.9522235909247412, 0.9522827483450766, 0.9526087298245244, 0.9525995794601102, 0.952827217918107, 0.9527118742316588, 0.9528263639296, 0.9530658176898129], 'mDice': [0.16642261734036598, 0.32129724534325044, 0.4269776880419367, 0.49312469065016995, 0.5340058466407728, 0.5606954197835803, 0.5806525622646956, 0.5951925834893307, 0.6092916306374687, 0.6214619662367771, 0.6306442814983797, 0.639615681041797, 0.6483650920890719, 0.6574362559150312, 0.66475988254856, 0.6716742919478225, 0.6767009459227663, 0.6829748041302983, 0.6881919066777734, 0.6940650577395321, 0.7001009995201454, 0.7033712488046289, 0.7071631862429127, 0.7127438941189428, 0.7168781848824367, 0.7195125305057376, 0.7235535273828648, 0.7268781816658313, 0.7302785266082319, 0.7337844468206484, 0.7378309368972308, 0.7406206096967612, 0.7433808595660291, 0.7461940265699276, 0.7488456308807232, 0.7505221755972988, 0.7532141221174046, 0.7561386204970143, 0.7582914473028203, 0.7595790999804891, 0.761960735136267, 0.7649146335672409, 0.7659193440648386, 0.7677540141469325, 0.7694027935789802, 0.7710996997225416, 0.7734023853834824, 0.7749722918518159, 0.7757903417457108, 0.7781789704556867, 0.7792808167709651, 0.780664442200088, 0.7830721898784015, 0.7846434871907269, 0.7857770707213352, 0.7870232141590173, 0.7886565562983296, 0.7895628285587282, 0.7903976673010757, 0.7921523211639879, 0.7932594118951165, 0.7938124885420269, 0.7951361434478532, 0.7959278622113926, 0.7970378765922901, 0.7986866001313376, 0.7986460230542167, 0.8014322928502561, 0.8015984770694128, 0.8037008495259106, 0.8025360538455271, 0.8032048631546377, 0.8051953095334422]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.37s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:05<00:02,  2.94s/it]predicting test subjects: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:36,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:04<09:10,  1.95s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:54,  1.90s/it]predicting train subjects:   1%|▏         | 4/285 [00:08<09:39,  2.06s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:06,  1.95s/it]predicting train subjects:   2%|▏         | 6/285 [00:12<09:41,  2.08s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<10:10,  2.19s/it]predicting train subjects:   3%|▎         | 8/285 [00:17<10:42,  2.32s/it]predicting train subjects:   3%|▎         | 9/285 [00:19<10:18,  2.24s/it]predicting train subjects:   4%|▎         | 10/285 [00:22<10:41,  2.33s/it]predicting train subjects:   4%|▍         | 11/285 [00:24<10:56,  2.39s/it]predicting train subjects:   4%|▍         | 12/285 [00:26<10:51,  2.39s/it]predicting train subjects:   5%|▍         | 13/285 [00:29<11:12,  2.47s/it]predicting train subjects:   5%|▍         | 14/285 [00:32<11:23,  2.52s/it]predicting train subjects:   5%|▌         | 15/285 [00:34<11:32,  2.56s/it]predicting train subjects:   6%|▌         | 16/285 [00:37<11:35,  2.58s/it]predicting train subjects:   6%|▌         | 17/285 [00:39<11:19,  2.54s/it]predicting train subjects:   6%|▋         | 18/285 [00:42<11:13,  2.52s/it]predicting train subjects:   7%|▋         | 19/285 [00:45<11:16,  2.54s/it]predicting train subjects:   7%|▋         | 20/285 [00:47<11:10,  2.53s/it]predicting train subjects:   7%|▋         | 21/285 [00:50<11:11,  2.54s/it]predicting train subjects:   8%|▊         | 22/285 [00:52<11:08,  2.54s/it]predicting train subjects:   8%|▊         | 23/285 [00:55<10:52,  2.49s/it]predicting train subjects:   8%|▊         | 24/285 [00:57<11:06,  2.55s/it]predicting train subjects:   9%|▉         | 25/285 [01:00<11:26,  2.64s/it]predicting train subjects:   9%|▉         | 26/285 [01:03<11:09,  2.58s/it]predicting train subjects:   9%|▉         | 27/285 [01:05<11:08,  2.59s/it]predicting train subjects:  10%|▉         | 28/285 [01:07<10:39,  2.49s/it]predicting train subjects:  10%|█         | 29/285 [01:09<10:05,  2.37s/it]predicting train subjects:  11%|█         | 30/285 [01:12<09:48,  2.31s/it]predicting train subjects:  11%|█         | 31/285 [01:14<09:40,  2.28s/it]predicting train subjects:  11%|█         | 32/285 [01:16<09:28,  2.25s/it]predicting train subjects:  12%|█▏        | 33/285 [01:18<09:21,  2.23s/it]predicting train subjects:  12%|█▏        | 34/285 [01:20<09:09,  2.19s/it]predicting train subjects:  12%|█▏        | 35/285 [01:23<09:08,  2.19s/it]predicting train subjects:  13%|█▎        | 36/285 [01:25<09:07,  2.20s/it]predicting train subjects:  13%|█▎        | 37/285 [01:27<08:50,  2.14s/it]predicting train subjects:  13%|█▎        | 38/285 [01:29<08:45,  2.13s/it]predicting train subjects:  14%|█▎        | 39/285 [01:31<08:47,  2.15s/it]predicting train subjects:  14%|█▍        | 40/285 [01:33<08:37,  2.11s/it]predicting train subjects:  14%|█▍        | 41/285 [01:35<08:32,  2.10s/it]predicting train subjects:  15%|█▍        | 42/285 [01:37<08:32,  2.11s/it]predicting train subjects:  15%|█▌        | 43/285 [01:39<08:33,  2.12s/it]predicting train subjects:  15%|█▌        | 44/285 [01:41<08:21,  2.08s/it]predicting train subjects:  16%|█▌        | 45/285 [01:44<08:25,  2.11s/it]predicting train subjects:  16%|█▌        | 46/285 [01:45<08:05,  2.03s/it]predicting train subjects:  16%|█▋        | 47/285 [01:47<07:39,  1.93s/it]predicting train subjects:  17%|█▋        | 48/285 [01:49<07:22,  1.87s/it]predicting train subjects:  17%|█▋        | 49/285 [01:51<07:10,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:52<07:05,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:54<07:07,  1.83s/it]predicting train subjects:  18%|█▊        | 52/285 [01:56<06:59,  1.80s/it]predicting train subjects:  19%|█▊        | 53/285 [01:58<06:53,  1.78s/it]predicting train subjects:  19%|█▉        | 54/285 [01:59<06:49,  1.77s/it]predicting train subjects:  19%|█▉        | 55/285 [02:01<06:38,  1.73s/it]predicting train subjects:  20%|█▉        | 56/285 [02:03<06:58,  1.83s/it]predicting train subjects:  20%|██        | 57/285 [02:05<06:52,  1.81s/it]predicting train subjects:  20%|██        | 58/285 [02:07<06:45,  1.79s/it]predicting train subjects:  21%|██        | 59/285 [02:08<06:46,  1.80s/it]predicting train subjects:  21%|██        | 60/285 [02:10<06:35,  1.76s/it]predicting train subjects:  21%|██▏       | 61/285 [02:12<06:45,  1.81s/it]predicting train subjects:  22%|██▏       | 62/285 [02:14<06:40,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [02:16<06:44,  1.82s/it]predicting train subjects:  22%|██▏       | 64/285 [02:18<06:44,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [02:20<06:58,  1.90s/it]predicting train subjects:  23%|██▎       | 66/285 [02:22<07:03,  1.94s/it]predicting train subjects:  24%|██▎       | 67/285 [02:23<06:57,  1.92s/it]predicting train subjects:  24%|██▍       | 68/285 [02:25<06:40,  1.85s/it]predicting train subjects:  24%|██▍       | 69/285 [02:27<06:45,  1.88s/it]predicting train subjects:  25%|██▍       | 70/285 [02:29<06:38,  1.85s/it]predicting train subjects:  25%|██▍       | 71/285 [02:31<06:43,  1.89s/it]predicting train subjects:  25%|██▌       | 72/285 [02:33<06:43,  1.89s/it]predicting train subjects:  26%|██▌       | 73/285 [02:35<06:41,  1.89s/it]predicting train subjects:  26%|██▌       | 74/285 [02:36<06:31,  1.86s/it]predicting train subjects:  26%|██▋       | 75/285 [02:38<06:22,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:40<06:17,  1.81s/it]predicting train subjects:  27%|██▋       | 77/285 [02:42<06:17,  1.81s/it]predicting train subjects:  27%|██▋       | 78/285 [02:44<06:20,  1.84s/it]predicting train subjects:  28%|██▊       | 79/285 [02:46<06:21,  1.85s/it]predicting train subjects:  28%|██▊       | 80/285 [02:48<06:33,  1.92s/it]predicting train subjects:  28%|██▊       | 81/285 [02:50<06:35,  1.94s/it]predicting train subjects:  29%|██▉       | 82/285 [02:52<06:31,  1.93s/it]predicting train subjects:  29%|██▉       | 83/285 [02:53<06:23,  1.90s/it]predicting train subjects:  29%|██▉       | 84/285 [02:55<06:27,  1.93s/it]predicting train subjects:  30%|██▉       | 85/285 [02:58<06:40,  2.00s/it]predicting train subjects:  30%|███       | 86/285 [03:00<06:49,  2.06s/it]predicting train subjects:  31%|███       | 87/285 [03:02<06:56,  2.10s/it]predicting train subjects:  31%|███       | 88/285 [03:04<07:06,  2.16s/it]predicting train subjects:  31%|███       | 89/285 [03:06<07:00,  2.15s/it]predicting train subjects:  32%|███▏      | 90/285 [03:08<06:53,  2.12s/it]predicting train subjects:  32%|███▏      | 91/285 [03:11<06:58,  2.16s/it]predicting train subjects:  32%|███▏      | 92/285 [03:13<07:00,  2.18s/it]predicting train subjects:  33%|███▎      | 93/285 [03:15<06:58,  2.18s/it]predicting train subjects:  33%|███▎      | 94/285 [03:17<06:53,  2.17s/it]predicting train subjects:  33%|███▎      | 95/285 [03:19<06:46,  2.14s/it]predicting train subjects:  34%|███▎      | 96/285 [03:21<06:40,  2.12s/it]predicting train subjects:  34%|███▍      | 97/285 [03:23<06:35,  2.10s/it]predicting train subjects:  34%|███▍      | 98/285 [03:26<06:34,  2.11s/it]predicting train subjects:  35%|███▍      | 99/285 [03:28<06:32,  2.11s/it]predicting train subjects:  35%|███▌      | 100/285 [03:30<06:29,  2.11s/it]predicting train subjects:  35%|███▌      | 101/285 [03:32<06:28,  2.11s/it]predicting train subjects:  36%|███▌      | 102/285 [03:34<06:29,  2.13s/it]predicting train subjects:  36%|███▌      | 103/285 [03:36<06:19,  2.08s/it]predicting train subjects:  36%|███▋      | 104/285 [03:38<06:27,  2.14s/it]predicting train subjects:  37%|███▋      | 105/285 [03:40<06:22,  2.13s/it]predicting train subjects:  37%|███▋      | 106/285 [03:42<06:12,  2.08s/it]predicting train subjects:  38%|███▊      | 107/285 [03:44<06:10,  2.08s/it]predicting train subjects:  38%|███▊      | 108/285 [03:47<06:12,  2.11s/it]predicting train subjects:  38%|███▊      | 109/285 [03:49<06:07,  2.09s/it]predicting train subjects:  39%|███▊      | 110/285 [03:51<05:56,  2.04s/it]predicting train subjects:  39%|███▉      | 111/285 [03:53<05:53,  2.03s/it]predicting train subjects:  39%|███▉      | 112/285 [03:55<05:47,  2.01s/it]predicting train subjects:  40%|███▉      | 113/285 [03:57<05:49,  2.03s/it]predicting train subjects:  40%|████      | 114/285 [03:59<05:49,  2.05s/it]predicting train subjects:  40%|████      | 115/285 [04:01<05:55,  2.09s/it]predicting train subjects:  41%|████      | 116/285 [04:03<06:02,  2.14s/it]predicting train subjects:  41%|████      | 117/285 [04:05<06:06,  2.18s/it]predicting train subjects:  41%|████▏     | 118/285 [04:07<05:57,  2.14s/it]predicting train subjects:  42%|████▏     | 119/285 [04:10<05:56,  2.15s/it]predicting train subjects:  42%|████▏     | 120/285 [04:12<05:49,  2.12s/it]predicting train subjects:  42%|████▏     | 121/285 [04:14<05:40,  2.08s/it]predicting train subjects:  43%|████▎     | 122/285 [04:15<05:23,  1.98s/it]predicting train subjects:  43%|████▎     | 123/285 [04:17<05:09,  1.91s/it]predicting train subjects:  44%|████▎     | 124/285 [04:19<05:10,  1.93s/it]predicting train subjects:  44%|████▍     | 125/285 [04:21<05:06,  1.91s/it]predicting train subjects:  44%|████▍     | 126/285 [04:23<05:03,  1.91s/it]predicting train subjects:  45%|████▍     | 127/285 [04:25<05:02,  1.92s/it]predicting train subjects:  45%|████▍     | 128/285 [04:27<05:06,  1.95s/it]predicting train subjects:  45%|████▌     | 129/285 [04:29<05:08,  1.98s/it]predicting train subjects:  46%|████▌     | 130/285 [04:31<05:00,  1.94s/it]predicting train subjects:  46%|████▌     | 131/285 [04:33<05:01,  1.96s/it]predicting train subjects:  46%|████▋     | 132/285 [04:35<04:57,  1.94s/it]predicting train subjects:  47%|████▋     | 133/285 [04:37<04:57,  1.96s/it]predicting train subjects:  47%|████▋     | 134/285 [04:39<04:49,  1.92s/it]predicting train subjects:  47%|████▋     | 135/285 [04:40<04:41,  1.88s/it]predicting train subjects:  48%|████▊     | 136/285 [04:42<04:39,  1.88s/it]predicting train subjects:  48%|████▊     | 137/285 [04:44<04:42,  1.91s/it]predicting train subjects:  48%|████▊     | 138/285 [04:46<04:44,  1.93s/it]predicting train subjects:  49%|████▉     | 139/285 [04:48<04:39,  1.91s/it]predicting train subjects:  49%|████▉     | 140/285 [04:50<04:29,  1.86s/it]predicting train subjects:  49%|████▉     | 141/285 [04:52<04:33,  1.90s/it]predicting train subjects:  50%|████▉     | 142/285 [04:54<04:27,  1.87s/it]predicting train subjects:  50%|█████     | 143/285 [04:55<04:19,  1.83s/it]predicting train subjects:  51%|█████     | 144/285 [04:57<04:15,  1.81s/it]predicting train subjects:  51%|█████     | 145/285 [04:59<04:10,  1.79s/it]predicting train subjects:  51%|█████     | 146/285 [05:01<04:05,  1.77s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:02<04:01,  1.75s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:04<03:58,  1.74s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:05<03:45,  1.66s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:07<03:44,  1.66s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:09<03:40,  1.64s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:10<03:35,  1.62s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:12<03:38,  1.65s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:14<03:37,  1.66s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:15<03:37,  1.67s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:17<03:37,  1.68s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:19<03:37,  1.70s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:20<03:35,  1.70s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:22<03:31,  1.68s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:24<03:36,  1.73s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:26<03:27,  1.68s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:27<03:25,  1.67s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:29<03:26,  1.70s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:31<03:21,  1.67s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:32<03:18,  1.65s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:34<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:36<03:18,  1.68s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:37<03:13,  1.65s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:39<03:13,  1.66s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:41<03:12,  1.67s/it]predicting train subjects:  60%|██████    | 171/285 [05:42<03:13,  1.69s/it]predicting train subjects:  60%|██████    | 172/285 [05:44<03:12,  1.70s/it]predicting train subjects:  61%|██████    | 173/285 [05:46<03:05,  1.65s/it]predicting train subjects:  61%|██████    | 174/285 [05:47<03:02,  1.64s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:49<03:00,  1.64s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:50<02:57,  1.63s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:52<02:58,  1.65s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:54<02:58,  1.67s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:56<02:59,  1.69s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:57<02:50,  1.63s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:59<02:50,  1.64s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:00<02:45,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:02<02:45,  1.62s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:03<02:43,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:05<02:42,  1.63s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:07<02:42,  1.64s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:08<02:37,  1.60s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:10<02:37,  1.63s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:11<02:31,  1.58s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:13<02:31,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:15<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:16<02:24,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:18<02:28,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:19<02:22,  1.57s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:21<02:27,  1.64s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:23<02:34,  1.73s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:25<02:42,  1.84s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:27<02:44,  1.89s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:29<02:43,  1.90s/it]predicting train subjects:  70%|███████   | 200/285 [06:31<02:44,  1.94s/it]predicting train subjects:  71%|███████   | 201/285 [06:33<02:43,  1.94s/it]predicting train subjects:  71%|███████   | 202/285 [06:35<02:36,  1.88s/it]predicting train subjects:  71%|███████   | 203/285 [06:37<02:32,  1.86s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:38<02:29,  1.85s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:41<02:35,  1.94s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:42<02:31,  1.92s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:44<02:27,  1.89s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:46<02:28,  1.93s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:48<02:25,  1.91s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:50<02:22,  1.90s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:52<02:18,  1.87s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:54<02:17,  1.88s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:56<02:15,  1.88s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:57<02:09,  1.82s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:59<01:59,  1.71s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:00<01:53,  1.64s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:02<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:04<01:50,  1.66s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:05<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:07<01:49,  1.69s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:09<01:49,  1.70s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:10<01:45,  1.68s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:12<01:44,  1.68s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:14<01:40,  1.64s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:15<01:39,  1.66s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:17<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:19<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [07:20<01:34,  1.66s/it]predicting train subjects:  80%|████████  | 229/285 [07:22<01:34,  1.68s/it]predicting train subjects:  81%|████████  | 230/285 [07:24<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [07:25<01:30,  1.67s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:27<01:34,  1.79s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:30<01:38,  1.88s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:32<01:39,  1.94s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:34<01:39,  1.98s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:36<01:36,  1.97s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:38<01:36,  2.01s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:40<01:36,  2.05s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:42<01:37,  2.11s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:44<01:35,  2.12s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:46<01:32,  2.11s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:48<01:30,  2.10s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:51<01:31,  2.18s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:53<01:30,  2.21s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:55<01:26,  2.16s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:57<01:26,  2.21s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:59<01:21,  2.14s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:02<01:18,  2.13s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:04<01:16,  2.12s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:05<01:08,  1.94s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:07<01:01,  1.80s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:08<00:56,  1.71s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:10<00:53,  1.67s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:11<00:53,  1.71s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:13<00:50,  1.69s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:15<00:49,  1.71s/it]predicting train subjects:  90%|█████████ | 257/285 [08:17<00:47,  1.69s/it]predicting train subjects:  91%|█████████ | 258/285 [08:18<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [08:20<00:42,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [08:21<00:40,  1.62s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:23<00:40,  1.70s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:25<00:38,  1.68s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:26<00:35,  1.60s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:28<00:32,  1.54s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:29<00:29,  1.50s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:31<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:32<00:28,  1.57s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:34<00:29,  1.74s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:37<00:29,  1.87s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:39<00:29,  1.94s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:41<00:27,  1.95s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:43<00:25,  1.98s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:45<00:24,  2.01s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:47<00:21,  1.99s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:49<00:19,  1.95s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:50<00:17,  1.91s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:52<00:15,  1.90s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:54<00:13,  1.89s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:56<00:11,  1.93s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:58<00:09,  1.91s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:00<00:07,  1.88s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:02<00:05,  1.88s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:04<00:03,  1.87s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:05<00:01,  1.87s/it]predicting train subjects: 100%|██████████| 285/285 [09:07<00:00,  1.85s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:41,  1.41s/it]Loading train:   1%|          | 2/285 [00:02<06:47,  1.44s/it]Loading train:   1%|          | 3/285 [00:04<06:32,  1.39s/it]Loading train:   1%|▏         | 4/285 [00:05<06:49,  1.46s/it]Loading train:   2%|▏         | 5/285 [00:07<06:38,  1.42s/it]Loading train:   2%|▏         | 6/285 [00:08<06:58,  1.50s/it]Loading train:   2%|▏         | 7/285 [00:10<07:27,  1.61s/it]Loading train:   3%|▎         | 8/285 [00:12<07:32,  1.63s/it]Loading train:   3%|▎         | 9/285 [00:13<07:06,  1.54s/it]Loading train:   4%|▎         | 10/285 [00:14<06:26,  1.40s/it]Loading train:   4%|▍         | 11/285 [00:16<06:14,  1.37s/it]Loading train:   4%|▍         | 12/285 [00:17<05:57,  1.31s/it]Loading train:   5%|▍         | 13/285 [00:18<05:55,  1.31s/it]Loading train:   5%|▍         | 14/285 [00:19<05:46,  1.28s/it]Loading train:   5%|▌         | 15/285 [00:21<06:09,  1.37s/it]Loading train:   6%|▌         | 16/285 [00:22<05:55,  1.32s/it]Loading train:   6%|▌         | 17/285 [00:23<05:49,  1.31s/it]Loading train:   6%|▋         | 18/285 [00:25<05:40,  1.28s/it]Loading train:   7%|▋         | 19/285 [00:26<05:35,  1.26s/it]Loading train:   7%|▋         | 20/285 [00:27<05:33,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:28<05:32,  1.26s/it]Loading train:   8%|▊         | 22/285 [00:30<05:32,  1.26s/it]Loading train:   8%|▊         | 23/285 [00:31<05:30,  1.26s/it]Loading train:   8%|▊         | 24/285 [00:32<05:27,  1.25s/it]Loading train:   9%|▉         | 25/285 [00:33<05:25,  1.25s/it]Loading train:   9%|▉         | 26/285 [00:34<05:21,  1.24s/it]Loading train:   9%|▉         | 27/285 [00:36<05:23,  1.25s/it]Loading train:  10%|▉         | 28/285 [00:37<05:10,  1.21s/it]Loading train:  10%|█         | 29/285 [00:38<04:55,  1.15s/it]Loading train:  11%|█         | 30/285 [00:39<04:40,  1.10s/it]Loading train:  11%|█         | 31/285 [00:40<04:35,  1.09s/it]Loading train:  11%|█         | 32/285 [00:41<04:30,  1.07s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:25,  1.05s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:35,  1.10s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:39,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:30,  1.09s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:29,  1.09s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:22,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:19,  1.05s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:13,  1.03s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:13,  1.04s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:13,  1.04s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:17,  1.06s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:19,  1.08s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:13,  1.05s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:17,  1.08s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:02,  1.02s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:03,  1.03s/it]Loading train:  17%|█▋        | 49/285 [00:59<03:55,  1.00it/s]Loading train:  18%|█▊        | 50/285 [01:00<03:47,  1.03it/s]Loading train:  18%|█▊        | 51/285 [01:01<03:45,  1.04it/s]Loading train:  18%|█▊        | 52/285 [01:02<03:54,  1.01s/it]Loading train:  19%|█▊        | 53/285 [01:03<03:48,  1.02it/s]Loading train:  19%|█▉        | 54/285 [01:04<03:43,  1.03it/s]Loading train:  19%|█▉        | 55/285 [01:05<03:41,  1.04it/s]Loading train:  20%|█▉        | 56/285 [01:06<03:41,  1.03it/s]Loading train:  20%|██        | 57/285 [01:07<03:40,  1.03it/s]Loading train:  20%|██        | 58/285 [01:07<03:39,  1.03it/s]Loading train:  21%|██        | 59/285 [01:08<03:38,  1.04it/s]Loading train:  21%|██        | 60/285 [01:09<03:43,  1.01it/s]Loading train:  21%|██▏       | 61/285 [01:10<03:35,  1.04it/s]Loading train:  22%|██▏       | 62/285 [01:11<03:41,  1.01it/s]Loading train:  22%|██▏       | 63/285 [01:12<03:32,  1.04it/s]Loading train:  22%|██▏       | 64/285 [01:14<04:15,  1.15s/it]Loading train:  23%|██▎       | 65/285 [01:16<04:55,  1.34s/it]Loading train:  23%|██▎       | 66/285 [01:17<05:08,  1.41s/it]Loading train:  24%|██▎       | 67/285 [01:18<04:38,  1.28s/it]Loading train:  24%|██▍       | 68/285 [01:19<04:19,  1.20s/it]Loading train:  24%|██▍       | 69/285 [01:20<04:10,  1.16s/it]Loading train:  25%|██▍       | 70/285 [01:21<03:58,  1.11s/it]Loading train:  25%|██▍       | 71/285 [01:23<04:02,  1.13s/it]Loading train:  25%|██▌       | 72/285 [01:24<03:51,  1.09s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:48,  1.08s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:41,  1.05s/it]Loading train:  26%|██▋       | 75/285 [01:27<03:39,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:32,  1.02s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:32,  1.02s/it]Loading train:  27%|██▋       | 78/285 [01:30<03:31,  1.02s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:24,  1.01it/s]Loading train:  28%|██▊       | 80/285 [01:31<03:22,  1.01it/s]Loading train:  28%|██▊       | 81/285 [01:32<03:21,  1.01it/s]Loading train:  29%|██▉       | 82/285 [01:34<03:23,  1.00s/it]Loading train:  29%|██▉       | 83/285 [01:35<03:27,  1.03s/it]Loading train:  29%|██▉       | 84/285 [01:36<03:25,  1.02s/it]Loading train:  30%|██▉       | 85/285 [01:37<03:27,  1.04s/it]Loading train:  30%|███       | 86/285 [01:38<03:35,  1.08s/it]Loading train:  31%|███       | 87/285 [01:39<03:31,  1.07s/it]Loading train:  31%|███       | 88/285 [01:40<03:31,  1.07s/it]Loading train:  31%|███       | 89/285 [01:41<03:28,  1.06s/it]Loading train:  32%|███▏      | 90/285 [01:42<03:27,  1.06s/it]Loading train:  32%|███▏      | 91/285 [01:43<03:29,  1.08s/it]Loading train:  32%|███▏      | 92/285 [01:44<03:30,  1.09s/it]Loading train:  33%|███▎      | 93/285 [01:45<03:30,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:46<03:26,  1.08s/it]Loading train:  33%|███▎      | 95/285 [01:48<03:25,  1.08s/it]Loading train:  34%|███▎      | 96/285 [01:49<03:25,  1.09s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:28,  1.11s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:24,  1.10s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:22,  1.09s/it]Loading train:  35%|███▌      | 100/285 [01:53<03:23,  1.10s/it]Loading train:  35%|███▌      | 101/285 [01:54<03:19,  1.08s/it]Loading train:  36%|███▌      | 102/285 [01:55<03:17,  1.08s/it]Loading train:  36%|███▌      | 103/285 [01:56<03:20,  1.10s/it]Loading train:  36%|███▋      | 104/285 [01:57<03:18,  1.10s/it]Loading train:  37%|███▋      | 105/285 [01:59<03:18,  1.10s/it]Loading train:  37%|███▋      | 106/285 [02:00<03:15,  1.09s/it]Loading train:  38%|███▊      | 107/285 [02:01<03:13,  1.09s/it]Loading train:  38%|███▊      | 108/285 [02:02<03:13,  1.09s/it]Loading train:  38%|███▊      | 109/285 [02:03<03:08,  1.07s/it]Loading train:  39%|███▊      | 110/285 [02:04<03:02,  1.04s/it]Loading train:  39%|███▉      | 111/285 [02:05<02:56,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:06<02:56,  1.02s/it]Loading train:  40%|███▉      | 113/285 [02:07<02:56,  1.03s/it]Loading train:  40%|████      | 114/285 [02:08<02:56,  1.03s/it]Loading train:  40%|████      | 115/285 [02:09<02:56,  1.04s/it]Loading train:  41%|████      | 116/285 [02:10<02:51,  1.02s/it]Loading train:  41%|████      | 117/285 [02:11<02:51,  1.02s/it]Loading train:  41%|████▏     | 118/285 [02:12<02:50,  1.02s/it]Loading train:  42%|████▏     | 119/285 [02:13<02:57,  1.07s/it]Loading train:  42%|████▏     | 120/285 [02:14<02:56,  1.07s/it]Loading train:  42%|████▏     | 121/285 [02:16<03:16,  1.20s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:22,  1.24s/it]Loading train:  43%|████▎     | 123/285 [02:18<03:24,  1.26s/it]Loading train:  44%|████▎     | 124/285 [02:19<03:07,  1.16s/it]Loading train:  44%|████▍     | 125/285 [02:20<02:57,  1.11s/it]Loading train:  44%|████▍     | 126/285 [02:21<02:43,  1.03s/it]Loading train:  45%|████▍     | 127/285 [02:22<02:38,  1.00s/it]Loading train:  45%|████▍     | 128/285 [02:23<02:35,  1.01it/s]Loading train:  45%|████▌     | 129/285 [02:24<02:32,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:25<02:28,  1.04it/s]Loading train:  46%|████▌     | 131/285 [02:26<02:24,  1.06it/s]Loading train:  46%|████▋     | 132/285 [02:27<02:22,  1.08it/s]Loading train:  47%|████▋     | 133/285 [02:28<02:27,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:29<02:19,  1.08it/s]Loading train:  47%|████▋     | 135/285 [02:30<02:22,  1.05it/s]Loading train:  48%|████▊     | 136/285 [02:30<02:18,  1.08it/s]Loading train:  48%|████▊     | 137/285 [02:31<02:16,  1.09it/s]Loading train:  48%|████▊     | 138/285 [02:32<02:21,  1.04it/s]Loading train:  49%|████▉     | 139/285 [02:33<02:20,  1.04it/s]Loading train:  49%|████▉     | 140/285 [02:34<02:19,  1.04it/s]Loading train:  49%|████▉     | 141/285 [02:35<02:17,  1.05it/s]Loading train:  50%|████▉     | 142/285 [02:36<02:14,  1.06it/s]Loading train:  50%|█████     | 143/285 [02:37<02:14,  1.06it/s]Loading train:  51%|█████     | 144/285 [02:38<02:11,  1.07it/s]Loading train:  51%|█████     | 145/285 [02:39<02:15,  1.03it/s]Loading train:  51%|█████     | 146/285 [02:40<02:11,  1.05it/s]Loading train:  52%|█████▏    | 147/285 [02:41<02:07,  1.08it/s]Loading train:  52%|█████▏    | 148/285 [02:42<02:02,  1.11it/s]Loading train:  52%|█████▏    | 149/285 [02:43<02:01,  1.12it/s]Loading train:  53%|█████▎    | 150/285 [02:43<02:00,  1.12it/s]Loading train:  53%|█████▎    | 151/285 [02:45<02:06,  1.06it/s]Loading train:  53%|█████▎    | 152/285 [02:45<02:02,  1.08it/s]Loading train:  54%|█████▎    | 153/285 [02:46<02:08,  1.03it/s]Loading train:  54%|█████▍    | 154/285 [02:47<02:06,  1.04it/s]Loading train:  54%|█████▍    | 155/285 [02:48<02:05,  1.03it/s]Loading train:  55%|█████▍    | 156/285 [02:49<02:04,  1.03it/s]Loading train:  55%|█████▌    | 157/285 [02:50<02:01,  1.06it/s]Loading train:  55%|█████▌    | 158/285 [02:51<02:01,  1.05it/s]Loading train:  56%|█████▌    | 159/285 [02:52<01:54,  1.10it/s]Loading train:  56%|█████▌    | 160/285 [02:53<01:57,  1.07it/s]Loading train:  56%|█████▋    | 161/285 [02:54<01:50,  1.12it/s]Loading train:  57%|█████▋    | 162/285 [02:55<01:48,  1.13it/s]Loading train:  57%|█████▋    | 163/285 [02:55<01:43,  1.18it/s]Loading train:  58%|█████▊    | 164/285 [02:56<01:45,  1.14it/s]Loading train:  58%|█████▊    | 165/285 [02:57<01:52,  1.06it/s]Loading train:  58%|█████▊    | 166/285 [02:58<01:52,  1.06it/s]Loading train:  59%|█████▊    | 167/285 [02:59<01:51,  1.06it/s]Loading train:  59%|█████▉    | 168/285 [03:00<01:48,  1.08it/s]Loading train:  59%|█████▉    | 169/285 [03:01<01:48,  1.07it/s]Loading train:  60%|█████▉    | 170/285 [03:02<01:42,  1.12it/s]Loading train:  60%|██████    | 171/285 [03:03<01:41,  1.12it/s]Loading train:  60%|██████    | 172/285 [03:04<01:39,  1.14it/s]Loading train:  61%|██████    | 173/285 [03:05<01:39,  1.13it/s]Loading train:  61%|██████    | 174/285 [03:06<01:38,  1.13it/s]Loading train:  61%|██████▏   | 175/285 [03:06<01:37,  1.13it/s]Loading train:  62%|██████▏   | 176/285 [03:07<01:34,  1.15it/s]Loading train:  62%|██████▏   | 177/285 [03:08<01:32,  1.17it/s]Loading train:  62%|██████▏   | 178/285 [03:09<01:31,  1.17it/s]Loading train:  63%|██████▎   | 179/285 [03:10<01:29,  1.19it/s]Loading train:  63%|██████▎   | 180/285 [03:11<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [03:12<01:29,  1.17it/s]Loading train:  64%|██████▍   | 182/285 [03:12<01:28,  1.17it/s]Loading train:  64%|██████▍   | 183/285 [03:13<01:30,  1.13it/s]Loading train:  65%|██████▍   | 184/285 [03:14<01:28,  1.14it/s]Loading train:  65%|██████▍   | 185/285 [03:15<01:26,  1.15it/s]Loading train:  65%|██████▌   | 186/285 [03:16<01:26,  1.14it/s]Loading train:  66%|██████▌   | 187/285 [03:17<01:28,  1.10it/s]Loading train:  66%|██████▌   | 188/285 [03:18<01:23,  1.16it/s]Loading train:  66%|██████▋   | 189/285 [03:19<01:27,  1.10it/s]Loading train:  67%|██████▋   | 190/285 [03:20<01:26,  1.10it/s]Loading train:  67%|██████▋   | 191/285 [03:21<01:25,  1.10it/s]Loading train:  67%|██████▋   | 192/285 [03:21<01:24,  1.10it/s]Loading train:  68%|██████▊   | 193/285 [03:22<01:20,  1.14it/s]Loading train:  68%|██████▊   | 194/285 [03:23<01:19,  1.15it/s]Loading train:  68%|██████▊   | 195/285 [03:24<01:16,  1.18it/s]Loading train:  69%|██████▉   | 196/285 [03:25<01:20,  1.10it/s]Loading train:  69%|██████▉   | 197/285 [03:26<01:23,  1.06it/s]Loading train:  69%|██████▉   | 198/285 [03:27<01:23,  1.04it/s]Loading train:  70%|██████▉   | 199/285 [03:28<01:23,  1.03it/s]Loading train:  70%|███████   | 200/285 [03:29<01:23,  1.02it/s]Loading train:  71%|███████   | 201/285 [03:30<01:23,  1.01it/s]Loading train:  71%|███████   | 202/285 [03:31<01:22,  1.00it/s]Loading train:  71%|███████   | 203/285 [03:32<01:20,  1.02it/s]Loading train:  72%|███████▏  | 204/285 [03:33<01:21,  1.01s/it]Loading train:  72%|███████▏  | 205/285 [03:34<01:19,  1.01it/s]Loading train:  72%|███████▏  | 206/285 [03:35<01:19,  1.01s/it]Loading train:  73%|███████▎  | 207/285 [03:36<01:19,  1.02s/it]Loading train:  73%|███████▎  | 208/285 [03:37<01:17,  1.00s/it]Loading train:  73%|███████▎  | 209/285 [03:38<01:18,  1.03s/it]Loading train:  74%|███████▎  | 210/285 [03:39<01:14,  1.00it/s]Loading train:  74%|███████▍  | 211/285 [03:40<01:14,  1.00s/it]Loading train:  74%|███████▍  | 212/285 [03:41<01:13,  1.00s/it]Loading train:  75%|███████▍  | 213/285 [03:42<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:43<01:09,  1.02it/s]Loading train:  75%|███████▌  | 215/285 [03:44<01:06,  1.05it/s]Loading train:  76%|███████▌  | 216/285 [03:45<01:02,  1.10it/s]Loading train:  76%|███████▌  | 217/285 [03:46<01:01,  1.10it/s]Loading train:  76%|███████▋  | 218/285 [03:46<00:59,  1.12it/s]Loading train:  77%|███████▋  | 219/285 [03:47<00:57,  1.15it/s]Loading train:  77%|███████▋  | 220/285 [03:48<00:56,  1.15it/s]Loading train:  78%|███████▊  | 221/285 [03:49<00:54,  1.18it/s]Loading train:  78%|███████▊  | 222/285 [03:50<00:55,  1.14it/s]Loading train:  78%|███████▊  | 223/285 [03:51<00:54,  1.15it/s]Loading train:  79%|███████▊  | 224/285 [03:52<00:52,  1.16it/s]Loading train:  79%|███████▉  | 225/285 [03:52<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [03:53<00:49,  1.18it/s]Loading train:  80%|███████▉  | 227/285 [03:54<00:50,  1.15it/s]Loading train:  80%|████████  | 228/285 [03:55<00:49,  1.16it/s]Loading train:  80%|████████  | 229/285 [03:56<00:49,  1.13it/s]Loading train:  81%|████████  | 230/285 [03:57<00:49,  1.11it/s]Loading train:  81%|████████  | 231/285 [03:58<00:49,  1.09it/s]Loading train:  81%|████████▏ | 232/285 [03:59<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [04:00<00:50,  1.02it/s]Loading train:  82%|████████▏ | 234/285 [04:01<00:53,  1.04s/it]Loading train:  82%|████████▏ | 235/285 [04:02<00:54,  1.08s/it]Loading train:  83%|████████▎ | 236/285 [04:03<00:51,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [04:04<00:51,  1.07s/it]Loading train:  84%|████████▎ | 238/285 [04:05<00:50,  1.08s/it]Loading train:  84%|████████▍ | 239/285 [04:06<00:48,  1.06s/it]Loading train:  84%|████████▍ | 240/285 [04:08<00:47,  1.06s/it]Loading train:  85%|████████▍ | 241/285 [04:09<00:47,  1.08s/it]Loading train:  85%|████████▍ | 242/285 [04:10<00:47,  1.10s/it]Loading train:  85%|████████▌ | 243/285 [04:11<00:45,  1.09s/it]Loading train:  86%|████████▌ | 244/285 [04:12<00:45,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:13<00:43,  1.09s/it]Loading train:  86%|████████▋ | 246/285 [04:14<00:41,  1.07s/it]Loading train:  87%|████████▋ | 247/285 [04:15<00:40,  1.07s/it]Loading train:  87%|████████▋ | 248/285 [04:16<00:39,  1.06s/it]Loading train:  87%|████████▋ | 249/285 [04:17<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [04:18<00:35,  1.02s/it]Loading train:  88%|████████▊ | 251/285 [04:19<00:32,  1.04it/s]Loading train:  88%|████████▊ | 252/285 [04:20<00:31,  1.05it/s]Loading train:  89%|████████▉ | 253/285 [04:21<00:29,  1.08it/s]Loading train:  89%|████████▉ | 254/285 [04:22<00:28,  1.10it/s]Loading train:  89%|████████▉ | 255/285 [04:22<00:26,  1.12it/s]Loading train:  90%|████████▉ | 256/285 [04:23<00:25,  1.12it/s]Loading train:  90%|█████████ | 257/285 [04:24<00:25,  1.09it/s]Loading train:  91%|█████████ | 258/285 [04:25<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [04:26<00:23,  1.08it/s]Loading train:  91%|█████████ | 260/285 [04:27<00:22,  1.10it/s]Loading train:  92%|█████████▏| 261/285 [04:28<00:21,  1.13it/s]Loading train:  92%|█████████▏| 262/285 [04:29<00:20,  1.12it/s]Loading train:  92%|█████████▏| 263/285 [04:30<00:19,  1.12it/s]Loading train:  93%|█████████▎| 264/285 [04:31<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [04:32<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [04:33<00:17,  1.09it/s]Loading train:  94%|█████████▎| 267/285 [04:33<00:16,  1.10it/s]Loading train:  94%|█████████▍| 268/285 [04:35<00:16,  1.02it/s]Loading train:  94%|█████████▍| 269/285 [04:36<00:15,  1.01it/s]Loading train:  95%|█████████▍| 270/285 [04:37<00:15,  1.00s/it]Loading train:  95%|█████████▌| 271/285 [04:38<00:14,  1.02s/it]Loading train:  95%|█████████▌| 272/285 [04:39<00:13,  1.03s/it]Loading train:  96%|█████████▌| 273/285 [04:40<00:12,  1.04s/it]Loading train:  96%|█████████▌| 274/285 [04:41<00:11,  1.05s/it]Loading train:  96%|█████████▋| 275/285 [04:42<00:10,  1.08s/it]Loading train:  97%|█████████▋| 276/285 [04:43<00:09,  1.08s/it]Loading train:  97%|█████████▋| 277/285 [04:44<00:08,  1.08s/it]Loading train:  98%|█████████▊| 278/285 [04:45<00:07,  1.08s/it]Loading train:  98%|█████████▊| 279/285 [04:46<00:06,  1.08s/it]Loading train:  98%|█████████▊| 280/285 [04:47<00:05,  1.07s/it]Loading train:  99%|█████████▊| 281/285 [04:49<00:04,  1.08s/it]Loading train:  99%|█████████▉| 282/285 [04:50<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [04:51<00:02,  1.06s/it]Loading train: 100%|█████████▉| 284/285 [04:52<00:01,  1.10s/it]Loading train: 100%|██████████| 285/285 [04:53<00:00,  1.09s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:05, 50.07it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:05, 53.74it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:04, 60.63it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:03, 74.33it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:02, 94.10it/s]concatenating: train:  32%|███▏      | 91/285 [00:00<00:01, 117.42it/s]concatenating: train:  41%|████▏     | 118/285 [00:00<00:01, 141.35it/s]concatenating: train:  52%|█████▏    | 148/285 [00:00<00:00, 167.42it/s]concatenating: train:  62%|██████▏   | 176/285 [00:00<00:00, 189.32it/s]concatenating: train:  73%|███████▎  | 207/285 [00:01<00:00, 212.89it/s]concatenating: train:  82%|████████▏ | 234/285 [00:01<00:00, 227.23it/s]concatenating: train:  93%|█████████▎| 264/285 [00:01<00:00, 244.34it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 209.50it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 49.01it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      2019-07-07 05:03:12.056688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 05:03:12.056812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 05:03:12.056828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 05:03:12.056838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 05:03:12.057282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 23s - loss: 10029.7998 - acc: 0.8822 - mDice: 0.2382 - val_loss: 4153.3172 - val_acc: 0.9258 - val_mDice: 0.4123

Epoch 00001: val_mDice improved from -inf to 0.41235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 4418.9824 - acc: 0.9146 - mDice: 0.4281 - val_loss: 3191.5350 - val_acc: 0.9406 - val_mDice: 0.4993

Epoch 00002: val_mDice improved from 0.41235 to 0.49934, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 3274.7248 - acc: 0.9272 - mDice: 0.5209 - val_loss: 2685.2489 - val_acc: 0.9451 - val_mDice: 0.5518

Epoch 00003: val_mDice improved from 0.49934 to 0.55181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 2769.0733 - acc: 0.9338 - mDice: 0.5738 - val_loss: 2586.2874 - val_acc: 0.9475 - val_mDice: 0.5649

Epoch 00004: val_mDice improved from 0.55181 to 0.56487, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 2526.3682 - acc: 0.9374 - mDice: 0.6020 - val_loss: 2367.6953 - val_acc: 0.9497 - val_mDice: 0.5909

Epoch 00005: val_mDice improved from 0.56487 to 0.59094, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 15s - loss: 2354.9389 - acc: 0.9401 - mDice: 0.6230 - val_loss: 2237.0244 - val_acc: 0.9502 - val_mDice: 0.6080

Epoch 00006: val_mDice improved from 0.59094 to 0.60796, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 2221.8990 - acc: 0.9421 - mDice: 0.6395 - val_loss: 2274.6148 - val_acc: 0.9503 - val_mDice: 0.6030

Epoch 00007: val_mDice did not improve from 0.60796
Epoch 8/300
 - 14s - loss: 2120.2555 - acc: 0.9437 - mDice: 0.6522 - val_loss: 2250.1281 - val_acc: 0.9518 - val_mDice: 0.6087

Epoch 00008: val_mDice improved from 0.60796 to 0.60872, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 15s - loss: 2041.1894 - acc: 0.9449 - mDice: 0.6632 - val_loss: 2207.8986 - val_acc: 0.9509 - val_mDice: 0.6120

Epoch 00009: val_mDice improved from 0.60872 to 0.61196, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 15s - loss: 1967.4946 - acc: 0.9459 - mDice: 0.6722 - val_loss: 2198.3109 - val_acc: 0.9508 - val_mDice: 0.6148

Epoch 00010: val_mDice improved from 0.61196 to 0.61480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 1898.7978 - acc: 0.9469 - mDice: 0.6811 - val_loss: 2232.4985 - val_acc: 0.9527 - val_mDice: 0.6136

Epoch 00011: val_mDice did not improve from 0.61480
Epoch 12/300
 - 15s - loss: 1838.0605 - acc: 0.9478 - mDice: 0.6892 - val_loss: 2205.1452 - val_acc: 0.9532 - val_mDice: 0.6143

Epoch 00012: val_mDice did not improve from 0.61480
Epoch 13/300
 - 15s - loss: 1791.2464 - acc: 0.9485 - mDice: 0.6957 - val_loss: 2271.0226 - val_acc: 0.9521 - val_mDice: 0.6078

Epoch 00013: val_mDice did not improve from 0.61480
Epoch 14/300
 - 14s - loss: 1736.6819 - acc: 0.9491 - mDice: 0.7030 - val_loss: 2248.0803 - val_acc: 0.9528 - val_mDice: 0.6127

Epoch 00014: val_mDice did not improve from 0.61480
Epoch 15/300
 - 15s - loss: 1703.8355 - acc: 0.9498 - mDice: 0.7078 - val_loss: 2196.4527 - val_acc: 0.9531 - val_mDice: 0.6149

Epoch 00015: val_mDice improved from 0.61480 to 0.61487, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 14s - loss: 1660.1094 - acc: 0.9504 - mDice: 0.7137 - val_loss: 2267.5184 - val_acc: 0.9526 - val_mDice: 0.6089

Epoch 00016: val_mDice did not improve from 0.61487
Epoch 17/300
 - 15s - loss: 1631.0939 - acc: 0.9508 - mDice: 0.7179 - val_loss: 2219.1175 - val_acc: 0.9521 - val_mDice: 0.6125

Epoch 00017: val_mDice did not improve from 0.61487
Epoch 18/300
 - 15s - loss: 1598.9399 - acc: 0.9514 - mDice: 0.7226 - val_loss: 2245.5599 - val_acc: 0.9530 - val_mDice: 0.6109

Epoch 00018: val_mDice did not improve from 0.61487
Epoch 19/300
 - 14s - loss: 1581.7860 - acc: 0.9519 - mDice: 0.7270 - val_loss: 2257.9546 - val_acc: 0.9523 - val_mDice: 0.6104

Epoch 00019: val_mDice did not improve from 0.61487
Epoch 20/300
 - 15s - loss: 1527.2151 - acc: 0.9524 - mDice: 0.7328 - val_loss: 2268.6934 - val_acc: 0.9528 - val_mDice: 0.6100

Epoch 00020: val_mDice did not improve from 0.61487
Epoch 21/300
 - 15s - loss: 1503.8744 - acc: 0.9528 - mDice: 0.7362 - val_loss: 2311.9170 - val_acc: 0.9535 - val_mDice: 0.6082

Epoch 00021: val_mDice did not improve from 0.61487
Epoch 22/300
 - 15s - loss: 1485.9442 - acc: 0.9532 - mDice: 0.7392 - val_loss: 2264.5125 - val_acc: 0.9532 - val_mDice: 0.6107

Epoch 00022: val_mDice did not improve from 0.61487
Epoch 23/300
 - 15s - loss: 1448.1143 - acc: 0.9538 - mDice: 0.7446 - val_loss: 2289.1624 - val_acc: 0.9538 - val_mDice: 0.6072

Epoch 00023: val_mDice did not improve from 0.61487
Epoch 24/300
 - 15s - loss: 1431.3873 - acc: 0.9541 - mDice: 0.7471 - val_loss: 2361.4851 - val_acc: 0.9528 - val_mDice: 0.5997

Epoch 00024: val_mDice did not improve from 0.61487
Epoch 25/300
 - 15s - loss: 1409.1778 - acc: 0.9544 - mDice: 0.7504 - val_loss: 2161.2637 - val_acc: 0.9542 - val_mDice: 0.6198

Epoch 00025: val_mDice improved from 0.61487 to 0.61977, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 26/300
 - 15s - loss: 1387.5121 - acc: 0.9547 - mDice: 0.7537 - val_loss: 2231.8724 - val_acc: 0.9528 - val_mDice: 0.6129

Epoch 00026: val_mDice did not improve from 0.61977
Epoch 27/300
 - 15s - loss: 1358.8836 - acc: 0.9551 - mDice: 0.7579 - val_loss: 2202.8161 - val_acc: 0.9540 - val_mDice: 0.6175

Epoch 00027: val_mDice did not improve from 0.61977
Epoch 28/300
 - 15s - loss: 1345.2466 - acc: 0.9554 - mDice: 0.7600 - val_loss: 2315.7921 - val_acc: 0.9527 - val_mDice: 0.6014

Epoch 00028: val_mDice did not improve from 0.61977
Epoch 29/300
 - 15s - loss: 1322.2689 - acc: 0.9557 - mDice: 0.7636 - val_loss: 2269.6846 - val_acc: 0.9536 - val_mDice: 0.6106

Epoch 00029: val_mDice did not improve from 0.61977
Epoch 30/300
 - 15s - loss: 1298.7406 - acc: 0.9560 - mDice: 0.7671 - val_loss: 2446.3424 - val_acc: 0.9539 - val_mDice: 0.5975

Epoch 00030: val_mDice did not improve from 0.61977
Epoch 31/300
 - 15s - loss: 1289.2248 - acc: 0.9562 - mDice: 0.7685 - val_loss: 2292.6970 - val_acc: 0.9549 - val_mDice: 0.6082

Epoch 00031: val_mDice did not improve from 0.61977
Epoch 32/300
 - 14s - loss: 1274.8394 - acc: 0.9565 - mDice: 0.7709 - val_loss: 2551.1218 - val_acc: 0.9532 - val_mDice: 0.5927

Epoch 00032: val_mDice did not improve from 0.61977
Epoch 33/300
 - 15s - loss: 1266.8367 - acc: 0.9566 - mDice: 0.7721 - val_loss: 2290.9236 - val_acc: 0.9532 - val_mDice: 0.6066

Epoch 00033: val_mDice did not improve from 0.61977
Epoch 34/300
 - 14s - loss: 1240.3197 - acc: 0.9570 - mDice: 0.7762 - val_loss: 2350.6375 - val_acc: 0.9531 - val_mDice: 0.6052

Epoch 00034: val_mDice did not improve from 0.61977
Epoch 35/300
 - 14s - loss: 1223.5329 - acc: 0.9573 - mDice: 0.7788 - val_loss: 2260.4663 - val_acc: 0.9539 - val_mDice: 0.6123

Epoch 00035: val_mDice did not improve from 0.61977
Epoch 36/300
 - 15s - loss: 1217.1113 - acc: 0.9574 - mDice: 0.7799 - val_loss: 2128.6518 - val_acc: 0.9539 - val_mDice: 0.6240

Epoch 00036: val_mDice improved from 0.61977 to 0.62404, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 37/300
 - 15s - loss: 1203.2647 - acc: 0.9576 - mDice: 0.7821 - val_loss: 2427.2849 - val_acc: 0.9533 - val_mDice: 0.5948

Epoch 00037: val_mDice did not improve from 0.62404
Epoch 38/300
 - 14s - loss: 1192.2024 - acc: 0.9578 - mDice: 0.7838 - val_loss: 2227.2984 - val_acc: 0.9537 - val_mDice: 0.6121

Epoch 00038: val_mDice did not improve from 0.62404
Epoch 39/300
 - 15s - loss: 1175.7439 - acc: 0.9580 - mDice: 0.7864 - val_loss: 2338.3160 - val_acc: 0.9535 - val_mDice: 0.6065

Epoch 00039: val_mDice did not improve from 0.62404
Epoch 40/300
 - 15s - loss: 1161.0946 - acc: 0.9583 - mDice: 0.7887 - val_loss: 2346.3634 - val_acc: 0.9519 - val_mDice: 0.6005

Epoch 00040: val_mDice did not improve from 0.62404
Epoch 41/300
 - 14s - loss: 1157.6491 - acc: 0.9584 - mDice: 0.7893 - val_loss: 2253.2231 - val_acc: 0.9521 - val_mDice: 0.6105

Epoch 00041: val_mDice did not improve from 0.62404
Epoch 42/300
 - 15s - loss: 1157.7040 - acc: 0.9585 - mDice: 0.7894 - val_loss: 2393.6324 - val_acc: 0.9528 - val_mDice: 0.5981

Epoch 00042: val_mDice did not improve from 0.62404
Epoch 43/300
 - 19s - loss: 1131.4447 - acc: 0.9588 - mDice: 0.7934 - val_loss: 2350.0906 - val_acc: 0.9526 - val_mDice: 0.6048

Epoch 00043: val_mDice did not improve from 0.62404
Epoch 44/300
 - 19s - loss: 1130.8068 - acc: 0.9589 - mDice: 0.7936 - val_loss: 2415.7757 - val_acc: 0.9526 - val_mDice: 0.6042

Epoch 00044: val_mDice did not improve from 0.62404
Epoch 45/300
 - 19s - loss: 1118.8881 - acc: 0.9590 - mDice: 0.7954 - val_loss: 2242.9168 - val_acc: 0.9539 - val_mDice: 0.6116

Epoch 00045: val_mDice did not improve from 0.62404
Epoch 46/300
 - 19s - loss: 1109.4724 - acc: 0.9593 - mDice: 0.7970 - val_loss: 2328.6636 - val_acc: 0.9537 - val_mDice: 0.6006

Epoch 00046: val_mDice did not improve from 0.62404
Epoch 47/300
 - 19s - loss: 1100.7187 - acc: 0.9593 - mDice: 0.7984 - val_loss: 2223.1070 - val_acc: 0.9536 - val_mDice: 0.6126

Epoch 00047: val_mDice did not improve from 0.62404
Epoch 48/300
 - 19s - loss: 1095.6203 - acc: 0.9594 - mDice: 0.7992 - val_loss: 2449.6907 - val_acc: 0.9518 - val_mDice: 0.5918

Epoch 00048: val_mDice did not improve from 0.62404
Epoch 49/300
 - 20s - loss: 1079.5673 - acc: 0.9597 - mDice: 0.8018 - val_loss: 2578.2405 - val_acc: 0.9506 - val_mDice: 0.5832

Epoch 00049: val_mDice did not improve from 0.62404
Epoch 50/300
 - 19s - loss: 1084.6151 - acc: 0.9597 - mDice: 0.8010 - val_loss: 2265.0566 - val_acc: 0.9539 - val_mDice: 0.6104

Epoch 00050: val_mDice did not improve from 0.62404
Epoch 51/300
 - 19s - loss: 1075.5073 - acc: 0.9598 - mDice: 0.8025 - val_loss: 2189.6545 - val_acc: 0.9542 - val_mDice: 0.6158

Epoch 00051: val_mDice did not improve from 0.62404
Epoch 52/300
 - 20s - loss: 1068.0262 - acc: 0.9600 - mDice: 0.8037 - val_loss: 2384.4389 - val_acc: 0.9538 - val_mDice: 0.5983

Epoch 00052: val_mDice did not improve from 0.62404
Epoch 53/300
 - 19s - loss: 1054.3068 - acc: 0.9601 - mDice: 0.8059 - val_loss: 2342.9675 - val_acc: 0.9543 - val_mDice: 0.6040

Epoch 00053: val_mDice did not improve from 0.62404
Epoch 54/300
 - 20s - loss: 1054.7899 - acc: 0.9601 - mDice: 0.8058 - val_loss: 2509.2979 - val_acc: 0.9534 - val_mDice: 0.5850

Epoch 00054: val_mDice did not improve from 0.62404
Epoch 55/300
 - 20s - loss: 1045.9112 - acc: 0.9603 - mDice: 0.8074 - val_loss: 2273.4656 - val_acc: 0.9536 - val_mDice: 0.6084

Epoch 00055: val_mDice did not improve from 0.62404
Epoch 56/300
 - 19s - loss: 1046.7922 - acc: 0.9603 - mDice: 0.8073 - val_loss: 2185.8573 - val_acc: 0.9542 - val_mDice: 0.6176

Epoch 00056: val_mDice did not improve from 0.62404
Epoch 57/300
 - 19s - loss: 1033.7523 - acc: 0.9605 - mDice: 0.8093 - val_loss: 2285.3032 - val_acc: 0.9527 - val_mDice: 0.6077

Epoch 00057: val_mDice did not improve from 0.62404
Epoch 58/300
 - 18s - loss: 1031.3912 - acc: 0.9606 - mDice: 0.8098 - val_loss: 2225.0536 - val_acc: 0.9532 - val_mDice: 0.6122

Epoch 00058: val_mDice did not improve from 0.62404
Epoch 59/300
 - 19s - loss: 1012.7983 - acc: 0.9608 - mDice: 0.8127 - val_loss: 2350.4780 - val_acc: 0.9527 - val_mDice: 0.6038

Epoch 00059: val_mDice did not improve from 0.62404
Epoch 60/300
 - 20s - loss: 1013.9499 - acc: 0.9608 - mDice: 0.8125 - val_loss: 2321.1661 - val_acc: 0.9540 - val_mDice: 0.6031

Epoch 00060: val_mDice did not improve from 0.62404
Epoch 61/300
 - 20s - loss: 1012.5818 - acc: 0.9609 - mDice: 0.8128 - val_loss: 2317.3522 - val_acc: 0.9526 - val_mDice: 0.6007

Epoch 00061: val_mDice did not improve from 0.62404
Epoch 62/300
 - 16s - loss: 1004.0215 - acc: 0.9610 - mDice: 0.8141 - val_loss: 2381.2459 - val_acc: 0.9538 - val_mDice: 0.5999

Epoch 00062: val_mDice did not improve from 0.62404
Epoch 63/300
 - 15s - loss: 1008.9988 - acc: 0.9610 - mDice: 0.8134 - val_loss: 2256.7088 - val_acc: 0.9549 - val_mDice: 0.6095

Epoch 00063: val_mDice did not improve from 0.62404
Epoch 64/300
 - 15s - loss: 995.3543 - acc: 0.9612 - mDice: 0.8157 - val_loss: 2302.7939 - val_acc: 0.9521 - val_mDice: 0.6032

Epoch 00064: val_mDice did not improve from 0.62404
Epoch 65/300
 - 14s - loss: 997.3269 - acc: 0.9611 - mDice: 0.8153 - val_loss: 2277.8714 - val_acc: 0.9527 - val_mDice: 0.6058

Epoch 00065: val_mDice did not improve from 0.62404
Epoch 66/300
 - 14s - loss: 994.4424 - acc: 0.9613 - mDice: 0.8159 - val_loss: 2449.4554 - val_acc: 0.9546 - val_mDice: 0.5950

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.10s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:08,  1.51s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:27,  1.58s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:24,  1.58s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:47,  1.67s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:30,  1.61s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:56,  1.71s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:36,  1.86s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:44,  1.89s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:27,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:50,  1.93s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:04,  1.99s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:14,  2.03s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<09:14,  2.04s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<09:08,  2.02s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:05,  2.02s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:08,  2.04s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<09:06,  2.04s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<09:09,  2.06s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<09:13,  2.08s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<09:18,  2.11s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<09:15,  2.10s/it]predicting train subjects:   8%|▊         | 22/285 [00:43<09:05,  2.08s/it]predicting train subjects:   8%|▊         | 23/285 [00:45<09:08,  2.09s/it]predicting train subjects:   8%|▊         | 24/285 [00:47<09:17,  2.14s/it]predicting train subjects:   9%|▉         | 25/285 [00:49<09:15,  2.14s/it]predicting train subjects:   9%|▉         | 26/285 [00:51<09:10,  2.12s/it]predicting train subjects:   9%|▉         | 27/285 [00:53<09:08,  2.12s/it]predicting train subjects:  10%|▉         | 28/285 [00:55<08:51,  2.07s/it]predicting train subjects:  10%|█         | 29/285 [00:57<08:33,  2.01s/it]predicting train subjects:  11%|█         | 30/285 [00:59<08:28,  1.99s/it]predicting train subjects:  11%|█         | 31/285 [01:01<08:23,  1.98s/it]predicting train subjects:  11%|█         | 32/285 [01:03<08:09,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:05<08:01,  1.91s/it]predicting train subjects:  12%|█▏        | 34/285 [01:07<07:57,  1.90s/it]predicting train subjects:  12%|█▏        | 35/285 [01:09<08:00,  1.92s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<07:53,  1.90s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<07:39,  1.86s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:20<07:36,  1.87s/it]predicting train subjects:  15%|█▍        | 42/285 [01:22<07:34,  1.87s/it]predicting train subjects:  15%|█▌        | 43/285 [01:23<07:33,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:25<07:36,  1.89s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:36,  1.90s/it]predicting train subjects:  16%|█▌        | 46/285 [01:29<07:17,  1.83s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<07:05,  1.79s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<06:52,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<06:44,  1.71s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<06:41,  1.71s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<06:37,  1.70s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<06:35,  1.70s/it]predicting train subjects:  19%|█▊        | 53/285 [01:41<06:34,  1.70s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<06:30,  1.69s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<06:28,  1.69s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<06:23,  1.67s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:15,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:49<06:13,  1.64s/it]predicting train subjects:  21%|██        | 59/285 [01:50<06:07,  1.62s/it]predicting train subjects:  21%|██        | 60/285 [01:52<06:07,  1.63s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:08,  1.64s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:08,  1.65s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:11,  1.67s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:19,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:30,  1.78s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:35,  1.80s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:28,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:26,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:22,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:19,  1.77s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:13,  1.74s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:11,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:07,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:06,  1.74s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:13,  1.78s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:08,  1.77s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:06,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:05,  1.76s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:04,  1.77s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<05:59,  1.75s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<05:59,  1.76s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:01,  1.78s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:58,  1.77s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:58,  1.78s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<06:04,  1.82s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:08,  1.85s/it]predicting train subjects:  31%|███       | 87/285 [02:40<06:13,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:42<06:13,  1.89s/it]predicting train subjects:  31%|███       | 89/285 [02:44<06:13,  1.91s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<06:10,  1.90s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<06:08,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<06:02,  1.88s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:55,  1.85s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:51,  1.84s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:50,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:54,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:53,  1.88s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:55,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:54,  1.91s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:54,  1.92s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:48,  1.89s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:46,  1.89s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:43,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:37,  1.87s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:34,  1.86s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:33,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:32,  1.87s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:30,  1.87s/it]predicting train subjects:  38%|███▊      | 109/285 [03:22<05:29,  1.87s/it]predicting train subjects:  39%|███▊      | 110/285 [03:24<05:28,  1.88s/it]predicting train subjects:  39%|███▉      | 111/285 [03:26<05:39,  1.95s/it]predicting train subjects:  39%|███▉      | 112/285 [03:28<05:32,  1.92s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:25,  1.89s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:22,  1.89s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:20,  1.89s/it]predicting train subjects:  41%|████      | 116/285 [03:35<05:17,  1.88s/it]predicting train subjects:  41%|████      | 117/285 [03:37<05:14,  1.87s/it]predicting train subjects:  41%|████▏     | 118/285 [03:39<05:12,  1.87s/it]predicting train subjects:  42%|████▏     | 119/285 [03:41<05:09,  1.86s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<05:03,  1.84s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<04:54,  1.79s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:39,  1.72s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:28,  1.66s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:26,  1.66s/it]predicting train subjects:  44%|████▍     | 125/285 [03:51<04:33,  1.71s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:30,  1.70s/it]predicting train subjects:  45%|████▍     | 127/285 [03:54<04:27,  1.69s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:26,  1.70s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:21,  1.68s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:20,  1.68s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:17,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:14,  1.66s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:10,  1.66s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<04:11,  1.68s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<04:10,  1.68s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<04:04,  1.65s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<04:01,  1.65s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<04:01,  1.66s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:59,  1.65s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<03:59,  1.66s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<03:52,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<03:39,  1.56s/it]predicting train subjects:  51%|█████     | 145/285 [04:23<03:37,  1.55s/it]predicting train subjects:  51%|█████     | 146/285 [04:25<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:26<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:28<03:32,  1.55s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:29<03:29,  1.54s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:31<03:26,  1.53s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:32<03:24,  1.53s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:21,  1.52s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:35<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:38<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:40<03:22,  1.57s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<03:18,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<03:16,  1.55s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:45<03:16,  1.56s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:48<03:05,  1.50s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<03:03,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:51<03:02,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:01,  1.50s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:54<03:00,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:57<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:58<02:56,  1.51s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:00<02:55,  1.52s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<02:54,  1.51s/it]predicting train subjects:  60%|██████    | 171/285 [05:03<02:51,  1.51s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<02:50,  1.51s/it]predicting train subjects:  61%|██████    | 173/285 [05:06<02:47,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:45,  1.49s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:09<02:43,  1.49s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<02:44,  1.51s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:12<02:43,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:40,  1.50s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:37,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:35,  1.48s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:34,  1.48s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:19<02:31,  1.47s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:21<02:29,  1.47s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:22<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:23<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:25<02:23,  1.45s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:26<02:21,  1.44s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:28<02:20,  1.45s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:29<02:19,  1.46s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:31<02:17,  1.45s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:32<02:17,  1.46s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:16,  1.47s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:35<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:37<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:38<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:40<02:17,  1.55s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:42<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:43<02:23,  1.65s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:45<02:22,  1.66s/it]predicting train subjects:  70%|███████   | 200/285 [05:47<02:21,  1.67s/it]predicting train subjects:  71%|███████   | 201/285 [05:48<02:21,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [05:50<02:20,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [05:52<02:19,  1.70s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:54<02:17,  1.70s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:55<02:15,  1.69s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:57<02:15,  1.72s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:59<02:15,  1.73s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:00<02:13,  1.73s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:02<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:04<02:09,  1.73s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:06<02:07,  1.72s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:07<02:05,  1.72s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:09<02:04,  1.73s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:11<01:57,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:12<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:14<01:48,  1.57s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:15<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:17<01:42,  1.53s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:18<01:41,  1.53s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:20<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:21<01:40,  1.58s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:23<01:40,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:24<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:26<01:37,  1.60s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:28<01:35,  1.59s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:29<01:33,  1.58s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:31<01:31,  1.58s/it]predicting train subjects:  80%|████████  | 228/285 [06:32<01:29,  1.58s/it]predicting train subjects:  80%|████████  | 229/285 [06:34<01:27,  1.56s/it]predicting train subjects:  81%|████████  | 230/285 [06:35<01:25,  1.55s/it]predicting train subjects:  81%|████████  | 231/285 [06:37<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:39<01:27,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:41<01:28,  1.70s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:43<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:45<01:31,  1.84s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:46<01:30,  1.86s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:48<01:29,  1.87s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:50<01:28,  1.88s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:52<01:27,  1.90s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:54<01:25,  1.90s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:56<01:22,  1.89s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:58<01:21,  1.90s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:00<01:19,  1.88s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:02<01:16,  1.86s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:03<01:14,  1.86s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:05<01:12,  1.85s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:07<01:09,  1.84s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:09<01:08,  1.84s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:11<01:06,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:12<01:01,  1.75s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:14<00:57,  1.69s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:15<00:53,  1.63s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:17<00:51,  1.60s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:18<00:48,  1.56s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:20<00:45,  1.53s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:21<00:43,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:23<00:41,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [07:24<00:42,  1.56s/it]predicting train subjects:  91%|█████████ | 259/285 [07:26<00:40,  1.54s/it]predicting train subjects:  91%|█████████ | 260/285 [07:27<00:38,  1.54s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:29<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:30<00:34,  1.50s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:32<00:33,  1.50s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:33<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:35<00:29,  1.48s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:36<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:38<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:40<00:28,  1.66s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:42<00:27,  1.73s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:44<00:26,  1.78s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:46<00:25,  1.83s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:48<00:24,  1.87s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:50<00:22,  1.91s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:52<00:21,  1.94s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:54<00:19,  1.94s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:55<00:17,  1.94s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:58<00:15,  1.97s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:59<00:13,  1.96s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:01<00:11,  1.96s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:03<00:09,  1.94s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:05<00:07,  1.97s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:07<00:05,  1.95s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:09<00:03,  1.97s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:11<00:01,  1.96s/it]predicting train subjects: 100%|██████████| 285/285 [08:13<00:00,  1.95s/it]
Epoch 00066: val_mDice did not improve from 0.62404
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
{'val_loss': [4153.317186408869, 3191.5349543907123, 2685.2488624956354, 2586.287420347416, 2367.6953056804296, 2237.024426337727, 2274.614837475995, 2250.1281301828735, 2207.8986489066865, 2198.310917859637, 2232.4985174253666, 2205.1451641061453, 2271.022642338076, 2248.0803181738825, 2196.452702186627, 2267.5184251156597, 2219.117538025925, 2245.559878557088, 2257.9546171220322, 2268.6934439376746, 2311.9170003709846, 2264.512487997556, 2289.1623957969623, 2361.485070596194, 2161.2636909697976, 2231.872364917947, 2202.816096641498, 2315.7920972088864, 2269.6846125938373, 2446.3423683550104, 2292.696956016498, 2551.121805713163, 2290.92356898132, 2350.6375493736905, 2260.466322232891, 2128.651774997818, 2427.2848657362956, 2227.2984284981667, 2338.31602435405, 2346.3634258248953, 2253.2231104333973, 2393.6324346957927, 2350.09059117493, 2415.7756784108765, 2242.916787600384, 2328.663624683572, 2223.1069608720322, 2449.69073520426, 2578.2404703321404, 2265.0566447167425, 2189.654489186889, 2384.4389184706706, 2342.9674720124826, 2509.2978542903284, 2273.4655679883904, 2185.8573250370987, 2285.303202197538, 2225.0536427417946, 2350.4779782428423, 2321.1661151907297, 2317.35223354574, 2381.2459191689945, 2256.70883161662, 2302.79386893331, 2277.8714060863304, 2449.455363183048], 'val_acc': [0.9258227055299215, 0.9406197094384519, 0.9451009994112579, 0.947476948439742, 0.9497413398833249, 0.9502392710920152, 0.950315684912591, 0.9517536453028631, 0.9508900415963967, 0.9508012236829576, 0.9527474402049401, 0.9531813094069838, 0.952063572806353, 0.9527825520025285, 0.9531358626967702, 0.9525573639896329, 0.9521152213965048, 0.9530201427763401, 0.9523114831753949, 0.9527846255115957, 0.953495335312529, 0.9532494867980147, 0.953842430141385, 0.9527742932628653, 0.9542453049281456, 0.9528321244197184, 0.9539540120343256, 0.9526895674247315, 0.9535718070728153, 0.9539498610203493, 0.9549415700928459, 0.9532474132889476, 0.9531792155857193, 0.9531420376047742, 0.953861041441976, 0.9539188686029871, 0.9532742666798597, 0.95367507461729, 0.9534829561936788, 0.9518652475080011, 0.9520676891896978, 0.9527990578273156, 0.9526048582359399, 0.9526048682255452, 0.9538589842492642, 0.9537350042572235, 0.9536296395616158, 0.9517660600513054, 0.9505615600660526, 0.9538734382091287, 0.9541750696784291, 0.9538403749465942, 0.9542845667407499, 0.9533610430509685, 0.9536048463602972, 0.9541998442324846, 0.9526689145818102, 0.9532329480075303, 0.952697863791908, 0.9539891348204799, 0.9525718099578133, 0.953768042212758, 0.9548568609040543, 0.9521152350489653, 0.9527309140679556, 0.9545944589476346], 'val_mDice': [0.41234637105931116, 0.4993438484282467, 0.551810487022613, 0.5648661605472671, 0.5909384592285369, 0.6079571053968461, 0.6030336385332672, 0.608717037978785, 0.611959214317066, 0.6147983906655338, 0.61360516794567, 0.6142607001618966, 0.6077952747904388, 0.6127445224943108, 0.6148679036667893, 0.6089277350702765, 0.6125263728243012, 0.610881712183606, 0.6104413883646107, 0.60999033737449, 0.6081665950780474, 0.6107306979887979, 0.6072456423796755, 0.5997116758836715, 0.6197684673623666, 0.6128689783245491, 0.6175106254369853, 0.6013669807817683, 0.610559720233832, 0.5975290283810493, 0.608184630644388, 0.5927013015613876, 0.6066391534645464, 0.605221897863143, 0.6123069717897384, 0.6240402077163398, 0.5948213222306534, 0.6120871022426883, 0.6064729923642548, 0.600533795090361, 0.6105476944140216, 0.5980517224892558, 0.6048262602124135, 0.6041770753913751, 0.6115756977203838, 0.6006024399949186, 0.6125594417476121, 0.5917819478658325, 0.5831739676065285, 0.6104070870569964, 0.6157679278091346, 0.5983133922076093, 0.6039899927277804, 0.5850441918692775, 0.6083778978726051, 0.6175578992460027, 0.6076575930558104, 0.6121521428976645, 0.6037613486444484, 0.6030649879125244, 0.6006521113092007, 0.5998836242952826, 0.6094804615947788, 0.6031526586862915, 0.6057796991071221, 0.5950195682781368], 'loss': [10029.799823409247, 4418.982362066464, 3274.724773097211, 2769.073311017844, 2526.3681541298683, 2354.938897655548, 2221.8990417550276, 2120.255537262553, 2041.189435167813, 1967.4946153635658, 1898.7977848662756, 1838.0604738694938, 1791.2464497291303, 1736.6819010308077, 1703.835544170452, 1660.1094353337555, 1631.0939351298907, 1598.9398920688616, 1581.7860317576146, 1527.2150540372384, 1503.8744041085938, 1485.9441817789373, 1448.1142914564637, 1431.3872807082394, 1409.1778063101224, 1387.5121372867582, 1358.8835980687668, 1345.2465511064606, 1322.2689281517848, 1298.7405942700073, 1289.2248311439348, 1274.83941095586, 1266.8367157755292, 1240.3197036077497, 1223.5329196261564, 1217.11127619808, 1203.264706101944, 1192.202420687339, 1175.7438969763527, 1161.0946116657547, 1157.6490543436742, 1157.7039681102162, 1131.444696999292, 1130.806829684064, 1118.8880633849749, 1109.472354365151, 1100.7186929970667, 1095.6203449931347, 1079.5673034146073, 1084.61508107075, 1075.5072532276931, 1068.026216067232, 1054.3068339921936, 1054.7899227297116, 1045.9112299348876, 1046.7921964147695, 1033.7522851933477, 1031.391208149848, 1012.7982674432433, 1013.9499029480849, 1012.5817903205269, 1004.0215426012294, 1008.998757978948, 995.3542809030095, 997.3269152899179, 994.4424466599073], 'acc': [0.8822276211240687, 0.9146194071605064, 0.9271958915796826, 0.9338375877518584, 0.9374145981039813, 0.9400740141384508, 0.942105207358315, 0.9436726596975994, 0.9449302868303939, 0.9459002361786625, 0.9469158998969774, 0.9477799815404688, 0.9485102412870887, 0.9491388441547512, 0.9497570335186551, 0.9503843086905017, 0.950838141724809, 0.9514010617347476, 0.9518841633245606, 0.9524085948127176, 0.9528135229517877, 0.9531576445397323, 0.9538389004125398, 0.9540997734809193, 0.9543910228045871, 0.9546946402819522, 0.9551177784824065, 0.9553686416387415, 0.9557032784919101, 0.9560112467285309, 0.9562116161838518, 0.9565063918424415, 0.9566046808301075, 0.9569596404454319, 0.9573086944354087, 0.9574342405807088, 0.9576151906960307, 0.9578254516559335, 0.9580352902412415, 0.9583306264126783, 0.9584061588300131, 0.9584718007198911, 0.9587570250108997, 0.9588806366071249, 0.9590020333621426, 0.9592642578662633, 0.9593333013468945, 0.9594391466232369, 0.9596997609384426, 0.9596685815056154, 0.9597743483262607, 0.9599645858262594, 0.9601215120786598, 0.960144048708144, 0.9602544439085026, 0.9603221027668405, 0.9604788454268066, 0.9605766946463977, 0.9607980103607265, 0.9607862893464187, 0.9608773292652968, 0.960953744516985, 0.9610354412381773, 0.9612267677979132, 0.9611483768572521, 0.9612976644080836], 'mDice': [0.23820467600845951, 0.42807347756423925, 0.5209251530782946, 0.573836112163937, 0.6019701980231705, 0.6229546382227116, 0.6394812015983041, 0.6522020327876735, 0.6631788083407284, 0.672178935344998, 0.6811157209435214, 0.689161748721458, 0.6957192184566562, 0.7029557504085705, 0.7077552365760684, 0.7137240083199052, 0.7179217732658405, 0.7226145244438101, 0.726985190345937, 0.7327758625963727, 0.7362269461041319, 0.7391593043311127, 0.7445838543579383, 0.7471120116900375, 0.7504434901075642, 0.7536813939788309, 0.757935383887821, 0.7600420233529545, 0.7636004356600141, 0.7670758882578367, 0.7685296624374639, 0.7709269508428093, 0.7721455847020438, 0.7761954747379414, 0.7788282327711449, 0.7798654711049767, 0.7821082690463178, 0.7838485355691696, 0.7864386237275983, 0.7887026269732851, 0.7893217531958603, 0.7893793992432405, 0.7934115925558992, 0.7935842152975671, 0.7954227378844799, 0.7970094248708456, 0.7984345469571661, 0.7992456882395105, 0.8018219289446726, 0.8010106319098501, 0.802453863481818, 0.803744519976163, 0.8059376424437066, 0.8058444333390715, 0.8073535897160309, 0.807264908967237, 0.8092710092971348, 0.8097819504242604, 0.8127402690759211, 0.8125231892907679, 0.812774072427855, 0.8141108101330112, 0.8133960682272839, 0.815704086320176, 0.8153188384005813, 0.8158894832874005]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:45,  1.22s/it]Loading train:   1%|          | 2/285 [00:02<06:13,  1.32s/it]Loading train:   1%|          | 3/285 [00:03<06:01,  1.28s/it]Loading train:   1%|▏         | 4/285 [00:05<06:29,  1.39s/it]Loading train:   2%|▏         | 5/285 [00:06<06:09,  1.32s/it]Loading train:   2%|▏         | 6/285 [00:08<06:25,  1.38s/it]Loading train:   2%|▏         | 7/285 [00:09<06:39,  1.44s/it]Loading train:   3%|▎         | 8/285 [00:11<06:53,  1.49s/it]Loading train:   3%|▎         | 9/285 [00:12<06:40,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:14<06:16,  1.37s/it]Loading train:   4%|▍         | 11/285 [00:15<05:49,  1.28s/it]Loading train:   4%|▍         | 12/285 [00:16<05:33,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:17<05:13,  1.15s/it]Loading train:   5%|▍         | 14/285 [00:18<05:04,  1.12s/it]Loading train:   5%|▌         | 15/285 [00:19<04:51,  1.08s/it]Loading train:   6%|▌         | 16/285 [00:20<04:48,  1.07s/it]Loading train:   6%|▌         | 17/285 [00:21<04:45,  1.06s/it]Loading train:   6%|▋         | 18/285 [00:22<04:37,  1.04s/it]Loading train:   7%|▋         | 19/285 [00:23<04:40,  1.05s/it]Loading train:   7%|▋         | 20/285 [00:24<04:29,  1.02s/it]Loading train:   7%|▋         | 21/285 [00:25<04:33,  1.04s/it]Loading train:   8%|▊         | 22/285 [00:26<04:29,  1.02s/it]Loading train:   8%|▊         | 23/285 [00:27<04:35,  1.05s/it]Loading train:   8%|▊         | 24/285 [00:28<04:30,  1.04s/it]Loading train:   9%|▉         | 25/285 [00:29<04:31,  1.05s/it]Loading train:   9%|▉         | 26/285 [00:30<04:34,  1.06s/it]Loading train:   9%|▉         | 27/285 [00:31<04:25,  1.03s/it]Loading train:  10%|▉         | 28/285 [00:32<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:33<04:13,  1.01it/s]Loading train:  11%|█         | 30/285 [00:34<04:08,  1.03it/s]Loading train:  11%|█         | 31/285 [00:35<04:05,  1.03it/s]Loading train:  11%|█         | 32/285 [00:36<04:00,  1.05it/s]Loading train:  12%|█▏        | 33/285 [00:37<04:03,  1.03it/s]Loading train:  12%|█▏        | 34/285 [00:38<04:08,  1.01it/s]Loading train:  12%|█▏        | 35/285 [00:39<04:07,  1.01it/s]Loading train:  13%|█▎        | 36/285 [00:40<03:59,  1.04it/s]Loading train:  13%|█▎        | 37/285 [00:41<04:10,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:42<04:02,  1.02it/s]Loading train:  14%|█▎        | 39/285 [00:43<04:02,  1.01it/s]Loading train:  14%|█▍        | 40/285 [00:44<03:54,  1.04it/s]Loading train:  14%|█▍        | 41/285 [00:45<03:58,  1.02it/s]Loading train:  15%|█▍        | 42/285 [00:46<03:54,  1.04it/s]Loading train:  15%|█▌        | 43/285 [00:47<03:51,  1.05it/s]Loading train:  15%|█▌        | 44/285 [00:48<03:55,  1.02it/s]Loading train:  16%|█▌        | 45/285 [00:49<04:01,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:50<03:49,  1.04it/s]Loading train:  16%|█▋        | 47/285 [00:50<03:40,  1.08it/s]Loading train:  17%|█▋        | 48/285 [00:51<03:33,  1.11it/s]Loading train:  17%|█▋        | 49/285 [00:52<03:28,  1.13it/s]Loading train:  18%|█▊        | 50/285 [00:53<03:32,  1.11it/s]Loading train:  18%|█▊        | 51/285 [00:54<03:26,  1.13it/s]Loading train:  18%|█▊        | 52/285 [00:55<03:25,  1.13it/s]Loading train:  19%|█▊        | 53/285 [00:56<03:17,  1.18it/s]Loading train:  19%|█▉        | 54/285 [00:56<03:14,  1.19it/s]Loading train:  19%|█▉        | 55/285 [00:57<03:16,  1.17it/s]Loading train:  20%|█▉        | 56/285 [00:58<03:11,  1.19it/s]Loading train:  20%|██        | 57/285 [00:59<03:17,  1.15it/s]Loading train:  20%|██        | 58/285 [01:00<03:08,  1.20it/s]Loading train:  21%|██        | 59/285 [01:00<03:02,  1.24it/s]Loading train:  21%|██        | 60/285 [01:01<03:06,  1.21it/s]Loading train:  21%|██▏       | 61/285 [01:02<03:09,  1.18it/s]Loading train:  22%|██▏       | 62/285 [01:03<03:18,  1.13it/s]Loading train:  22%|██▏       | 63/285 [01:04<03:20,  1.11it/s]Loading train:  22%|██▏       | 64/285 [01:06<03:53,  1.05s/it]Loading train:  23%|██▎       | 65/285 [01:07<04:23,  1.20s/it]Loading train:  23%|██▎       | 66/285 [01:08<04:22,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:09<04:03,  1.12s/it]Loading train:  24%|██▍       | 68/285 [01:10<03:41,  1.02s/it]Loading train:  24%|██▍       | 69/285 [01:11<03:26,  1.05it/s]Loading train:  25%|██▍       | 70/285 [01:12<03:21,  1.07it/s]Loading train:  25%|██▍       | 71/285 [01:13<03:15,  1.09it/s]Loading train:  25%|██▌       | 72/285 [01:13<03:09,  1.13it/s]Loading train:  26%|██▌       | 73/285 [01:14<02:56,  1.20it/s]Loading train:  26%|██▌       | 74/285 [01:15<02:57,  1.19it/s]Loading train:  26%|██▋       | 75/285 [01:16<02:55,  1.20it/s]Loading train:  27%|██▋       | 76/285 [01:17<02:49,  1.23it/s]Loading train:  27%|██▋       | 77/285 [01:17<02:55,  1.18it/s]Loading train:  27%|██▋       | 78/285 [01:18<02:50,  1.21it/s]Loading train:  28%|██▊       | 79/285 [01:19<02:45,  1.25it/s]Loading train:  28%|██▊       | 80/285 [01:20<02:48,  1.21it/s]Loading train:  28%|██▊       | 81/285 [01:21<02:46,  1.23it/s]Loading train:  29%|██▉       | 82/285 [01:22<02:52,  1.18it/s]Loading train:  29%|██▉       | 83/285 [01:22<02:49,  1.19it/s]Loading train:  29%|██▉       | 84/285 [01:23<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:24<03:00,  1.11it/s]Loading train:  30%|███       | 86/285 [01:25<03:04,  1.08it/s]Loading train:  31%|███       | 87/285 [01:26<03:07,  1.06it/s]Loading train:  31%|███       | 88/285 [01:27<03:06,  1.05it/s]Loading train:  31%|███       | 89/285 [01:28<03:04,  1.06it/s]Loading train:  32%|███▏      | 90/285 [01:29<03:03,  1.06it/s]Loading train:  32%|███▏      | 91/285 [01:30<03:08,  1.03it/s]Loading train:  32%|███▏      | 92/285 [01:31<03:03,  1.05it/s]Loading train:  33%|███▎      | 93/285 [01:32<03:12,  1.00s/it]Loading train:  33%|███▎      | 94/285 [01:33<03:10,  1.00it/s]Loading train:  33%|███▎      | 95/285 [01:34<03:12,  1.01s/it]Loading train:  34%|███▎      | 96/285 [01:35<03:03,  1.03it/s]Loading train:  34%|███▍      | 97/285 [01:36<02:59,  1.05it/s]Loading train:  34%|███▍      | 98/285 [01:37<02:57,  1.05it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:56,  1.05it/s]Loading train:  35%|███▌      | 100/285 [01:39<02:54,  1.06it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:53,  1.06it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:51,  1.07it/s]Loading train:  36%|███▌      | 103/285 [01:41<02:44,  1.10it/s]Loading train:  36%|███▋      | 104/285 [01:42<02:48,  1.08it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:41,  1.12it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:53,  1.03it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:52,  1.03it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:56,  1.00it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:51,  1.03it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:49,  1.03it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:52,  1.01it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:56,  1.02s/it]Loading train:  40%|███▉      | 113/285 [01:51<02:52,  1.00s/it]Loading train:  40%|████      | 114/285 [01:52<02:45,  1.03it/s]Loading train:  40%|████      | 115/285 [01:53<02:39,  1.07it/s]Loading train:  41%|████      | 116/285 [01:54<02:41,  1.05it/s]Loading train:  41%|████      | 117/285 [01:55<02:38,  1.06it/s]Loading train:  41%|████▏     | 118/285 [01:56<02:36,  1.07it/s]Loading train:  42%|████▏     | 119/285 [01:57<02:35,  1.07it/s]Loading train:  42%|████▏     | 120/285 [01:58<02:31,  1.09it/s]Loading train:  42%|████▏     | 121/285 [01:59<02:45,  1.01s/it]Loading train:  43%|████▎     | 122/285 [02:00<02:56,  1.09s/it]Loading train:  43%|████▎     | 123/285 [02:02<03:01,  1.12s/it]Loading train:  44%|████▎     | 124/285 [02:02<02:50,  1.06s/it]Loading train:  44%|████▍     | 125/285 [02:03<02:43,  1.02s/it]Loading train:  44%|████▍     | 126/285 [02:04<02:32,  1.04it/s]Loading train:  45%|████▍     | 127/285 [02:05<02:26,  1.08it/s]Loading train:  45%|████▍     | 128/285 [02:06<02:22,  1.10it/s]Loading train:  45%|████▌     | 129/285 [02:07<02:15,  1.15it/s]Loading train:  46%|████▌     | 130/285 [02:08<02:19,  1.11it/s]Loading train:  46%|████▌     | 131/285 [02:08<02:14,  1.15it/s]Loading train:  46%|████▋     | 132/285 [02:09<02:13,  1.14it/s]Loading train:  47%|████▋     | 133/285 [02:10<02:10,  1.16it/s]Loading train:  47%|████▋     | 134/285 [02:11<02:10,  1.15it/s]Loading train:  47%|████▋     | 135/285 [02:12<02:10,  1.15it/s]Loading train:  48%|████▊     | 136/285 [02:13<02:10,  1.14it/s]Loading train:  48%|████▊     | 137/285 [02:14<02:11,  1.13it/s]Loading train:  48%|████▊     | 138/285 [02:15<02:09,  1.14it/s]Loading train:  49%|████▉     | 139/285 [02:16<02:09,  1.13it/s]Loading train:  49%|████▉     | 140/285 [02:16<02:04,  1.16it/s]Loading train:  49%|████▉     | 141/285 [02:17<02:08,  1.12it/s]Loading train:  50%|████▉     | 142/285 [02:18<02:02,  1.16it/s]Loading train:  50%|█████     | 143/285 [02:19<02:03,  1.15it/s]Loading train:  51%|█████     | 144/285 [02:20<01:54,  1.23it/s]Loading train:  51%|█████     | 145/285 [02:20<01:52,  1.25it/s]Loading train:  51%|█████     | 146/285 [02:21<01:47,  1.29it/s]Loading train:  52%|█████▏    | 147/285 [02:22<01:43,  1.34it/s]Loading train:  52%|█████▏    | 148/285 [02:23<01:49,  1.25it/s]Loading train:  52%|█████▏    | 149/285 [02:24<01:49,  1.25it/s]Loading train:  53%|█████▎    | 150/285 [02:25<01:55,  1.17it/s]Loading train:  53%|█████▎    | 151/285 [02:25<01:57,  1.14it/s]Loading train:  53%|█████▎    | 152/285 [02:26<01:56,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [02:27<01:49,  1.21it/s]Loading train:  54%|█████▍    | 154/285 [02:28<01:47,  1.22it/s]Loading train:  54%|█████▍    | 155/285 [02:29<01:47,  1.21it/s]Loading train:  55%|█████▍    | 156/285 [02:29<01:44,  1.24it/s]Loading train:  55%|█████▌    | 157/285 [02:30<01:50,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:31<01:47,  1.18it/s]Loading train:  56%|█████▌    | 159/285 [02:32<01:50,  1.14it/s]Loading train:  56%|█████▌    | 160/285 [02:33<01:46,  1.17it/s]Loading train:  56%|█████▋    | 161/285 [02:34<01:43,  1.19it/s]Loading train:  57%|█████▋    | 162/285 [02:35<01:39,  1.23it/s]Loading train:  57%|█████▋    | 163/285 [02:35<01:37,  1.25it/s]Loading train:  58%|█████▊    | 164/285 [02:36<01:38,  1.23it/s]Loading train:  58%|█████▊    | 165/285 [02:37<01:31,  1.31it/s]Loading train:  58%|█████▊    | 166/285 [02:38<01:36,  1.24it/s]Loading train:  59%|█████▊    | 167/285 [02:38<01:31,  1.28it/s]Loading train:  59%|█████▉    | 168/285 [02:39<01:33,  1.25it/s]Loading train:  59%|█████▉    | 169/285 [02:40<01:30,  1.28it/s]Loading train:  60%|█████▉    | 170/285 [02:41<01:30,  1.27it/s]Loading train:  60%|██████    | 171/285 [02:42<01:32,  1.24it/s]Loading train:  60%|██████    | 172/285 [02:42<01:29,  1.27it/s]Loading train:  61%|██████    | 173/285 [02:43<01:27,  1.28it/s]Loading train:  61%|██████    | 174/285 [02:44<01:28,  1.25it/s]Loading train:  61%|██████▏   | 175/285 [02:45<01:30,  1.22it/s]Loading train:  62%|██████▏   | 176/285 [02:46<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [02:47<01:29,  1.21it/s]Loading train:  62%|██████▏   | 178/285 [02:47<01:24,  1.26it/s]Loading train:  63%|██████▎   | 179/285 [02:48<01:23,  1.27it/s]Loading train:  63%|██████▎   | 180/285 [02:49<01:22,  1.27it/s]Loading train:  64%|██████▎   | 181/285 [02:50<01:25,  1.22it/s]Loading train:  64%|██████▍   | 182/285 [02:50<01:23,  1.24it/s]Loading train:  64%|██████▍   | 183/285 [02:51<01:19,  1.28it/s]Loading train:  65%|██████▍   | 184/285 [02:52<01:15,  1.34it/s]Loading train:  65%|██████▍   | 185/285 [02:53<01:14,  1.33it/s]Loading train:  65%|██████▌   | 186/285 [02:53<01:18,  1.26it/s]Loading train:  66%|██████▌   | 187/285 [02:54<01:16,  1.29it/s]Loading train:  66%|██████▌   | 188/285 [02:55<01:18,  1.24it/s]Loading train:  66%|██████▋   | 189/285 [02:56<01:15,  1.28it/s]Loading train:  67%|██████▋   | 190/285 [02:57<01:12,  1.30it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:12,  1.29it/s]Loading train:  67%|██████▋   | 192/285 [02:58<01:09,  1.35it/s]Loading train:  68%|██████▊   | 193/285 [02:59<01:09,  1.33it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:06,  1.37it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:11,  1.25it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:12,  1.23it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:16,  1.15it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:17,  1.13it/s]Loading train:  70%|██████▉   | 199/285 [03:04<01:17,  1.11it/s]Loading train:  70%|███████   | 200/285 [03:05<01:15,  1.13it/s]Loading train:  71%|███████   | 201/285 [03:06<01:12,  1.16it/s]Loading train:  71%|███████   | 202/285 [03:07<01:10,  1.17it/s]Loading train:  71%|███████   | 203/285 [03:07<01:08,  1.19it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:09,  1.17it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:08,  1.17it/s]Loading train:  72%|███████▏  | 206/285 [03:10<01:07,  1.17it/s]Loading train:  73%|███████▎  | 207/285 [03:11<01:05,  1.19it/s]Loading train:  73%|███████▎  | 208/285 [03:12<01:05,  1.18it/s]Loading train:  73%|███████▎  | 209/285 [03:13<01:04,  1.18it/s]Loading train:  74%|███████▎  | 210/285 [03:13<01:02,  1.20it/s]Loading train:  74%|███████▍  | 211/285 [03:14<01:06,  1.11it/s]Loading train:  74%|███████▍  | 212/285 [03:15<01:04,  1.13it/s]Loading train:  75%|███████▍  | 213/285 [03:16<01:03,  1.14it/s]Loading train:  75%|███████▌  | 214/285 [03:17<01:00,  1.18it/s]Loading train:  75%|███████▌  | 215/285 [03:18<00:58,  1.21it/s]Loading train:  76%|███████▌  | 216/285 [03:18<00:56,  1.23it/s]Loading train:  76%|███████▌  | 217/285 [03:19<00:55,  1.23it/s]Loading train:  76%|███████▋  | 218/285 [03:20<00:55,  1.20it/s]Loading train:  77%|███████▋  | 219/285 [03:21<00:52,  1.25it/s]Loading train:  77%|███████▋  | 220/285 [03:22<00:50,  1.28it/s]Loading train:  78%|███████▊  | 221/285 [03:23<00:51,  1.23it/s]Loading train:  78%|███████▊  | 222/285 [03:23<00:49,  1.27it/s]Loading train:  78%|███████▊  | 223/285 [03:24<00:51,  1.21it/s]Loading train:  79%|███████▊  | 224/285 [03:25<00:49,  1.23it/s]Loading train:  79%|███████▉  | 225/285 [03:26<00:48,  1.25it/s]Loading train:  79%|███████▉  | 226/285 [03:26<00:46,  1.28it/s]Loading train:  80%|███████▉  | 227/285 [03:27<00:44,  1.30it/s]Loading train:  80%|████████  | 228/285 [03:28<00:44,  1.29it/s]Loading train:  80%|████████  | 229/285 [03:29<00:43,  1.29it/s]Loading train:  81%|████████  | 230/285 [03:30<00:43,  1.26it/s]Loading train:  81%|████████  | 231/285 [03:30<00:41,  1.29it/s]Loading train:  81%|████████▏ | 232/285 [03:31<00:45,  1.18it/s]Loading train:  82%|████████▏ | 233/285 [03:32<00:47,  1.08it/s]Loading train:  82%|████████▏ | 234/285 [03:33<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:34<00:48,  1.04it/s]Loading train:  83%|████████▎ | 236/285 [03:35<00:46,  1.06it/s]Loading train:  83%|████████▎ | 237/285 [03:36<00:46,  1.04it/s]Loading train:  84%|████████▎ | 238/285 [03:37<00:46,  1.02it/s]Loading train:  84%|████████▍ | 239/285 [03:38<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [03:39<00:45,  1.01s/it]Loading train:  85%|████████▍ | 241/285 [03:40<00:43,  1.01it/s]Loading train:  85%|████████▍ | 242/285 [03:41<00:42,  1.02it/s]Loading train:  85%|████████▌ | 243/285 [03:42<00:41,  1.00it/s]Loading train:  86%|████████▌ | 244/285 [03:43<00:40,  1.01it/s]Loading train:  86%|████████▌ | 245/285 [03:44<00:40,  1.02s/it]Loading train:  86%|████████▋ | 246/285 [03:45<00:40,  1.03s/it]Loading train:  87%|████████▋ | 247/285 [03:46<00:38,  1.02s/it]Loading train:  87%|████████▋ | 248/285 [03:47<00:37,  1.03s/it]Loading train:  87%|████████▋ | 249/285 [03:48<00:36,  1.01s/it]Loading train:  88%|████████▊ | 250/285 [03:49<00:32,  1.07it/s]Loading train:  88%|████████▊ | 251/285 [03:50<00:30,  1.12it/s]Loading train:  88%|████████▊ | 252/285 [03:51<00:28,  1.16it/s]Loading train:  89%|████████▉ | 253/285 [03:52<00:26,  1.21it/s]Loading train:  89%|████████▉ | 254/285 [03:52<00:24,  1.26it/s]Loading train:  89%|████████▉ | 255/285 [03:53<00:23,  1.28it/s]Loading train:  90%|████████▉ | 256/285 [03:54<00:22,  1.29it/s]Loading train:  90%|█████████ | 257/285 [03:54<00:21,  1.32it/s]Loading train:  91%|█████████ | 258/285 [03:55<00:20,  1.29it/s]Loading train:  91%|█████████ | 259/285 [03:56<00:19,  1.34it/s]Loading train:  91%|█████████ | 260/285 [03:57<00:19,  1.27it/s]Loading train:  92%|█████████▏| 261/285 [03:58<00:18,  1.32it/s]Loading train:  92%|█████████▏| 262/285 [03:58<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [03:59<00:16,  1.33it/s]Loading train:  93%|█████████▎| 264/285 [04:00<00:15,  1.35it/s]Loading train:  93%|█████████▎| 265/285 [04:00<00:14,  1.38it/s]Loading train:  93%|█████████▎| 266/285 [04:01<00:13,  1.39it/s]Loading train:  94%|█████████▎| 267/285 [04:02<00:13,  1.32it/s]Loading train:  94%|█████████▍| 268/285 [04:03<00:13,  1.23it/s]Loading train:  94%|█████████▍| 269/285 [04:04<00:13,  1.20it/s]Loading train:  95%|█████████▍| 270/285 [04:05<00:12,  1.16it/s]Loading train:  95%|█████████▌| 271/285 [04:06<00:12,  1.12it/s]Loading train:  95%|█████████▌| 272/285 [04:07<00:11,  1.11it/s]Loading train:  96%|█████████▌| 273/285 [04:08<00:10,  1.13it/s]Loading train:  96%|█████████▌| 274/285 [04:08<00:09,  1.10it/s]Loading train:  96%|█████████▋| 275/285 [04:09<00:09,  1.09it/s]Loading train:  97%|█████████▋| 276/285 [04:10<00:08,  1.07it/s]Loading train:  97%|█████████▋| 277/285 [04:11<00:07,  1.06it/s]Loading train:  98%|█████████▊| 278/285 [04:12<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:13<00:05,  1.09it/s]Loading train:  98%|█████████▊| 280/285 [04:14<00:04,  1.09it/s]Loading train:  99%|█████████▊| 281/285 [04:15<00:03,  1.06it/s]Loading train:  99%|█████████▉| 282/285 [04:16<00:02,  1.06it/s]Loading train:  99%|█████████▉| 283/285 [04:17<00:01,  1.03it/s]Loading train: 100%|█████████▉| 284/285 [04:18<00:00,  1.05it/s]Loading train: 100%|██████████| 285/285 [04:19<00:00,  1.02it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:01, 188.34it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:01, 176.37it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:01, 158.66it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:01, 186.71it/s]concatenating: train:  40%|████      | 114/285 [00:00<00:00, 212.47it/s]concatenating: train:  50%|████▉     | 142/285 [00:00<00:00, 228.00it/s]concatenating: train:  60%|██████    | 172/285 [00:00<00:00, 244.36it/s]concatenating: train:  72%|███████▏  | 205/285 [00:00<00:00, 263.95it/s]concatenating: train:  82%|████████▏ | 233/285 [00:00<00:00, 258.93it/s]concatenating: train:  93%|█████████▎| 266/285 [00:01<00:00, 274.80it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 260.70it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.29s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 66.37it/s]  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________2019-07-07 05:34:09.666011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 05:34:09.666120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 05:34:09.666135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 05:34:09.666144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 05:34:09.666598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 14497.3191 - acc: 0.8612 - mDice: 0.2461 - val_loss: 7626.6654 - val_acc: 0.8891 - val_mDice: 0.3543

Epoch 00001: val_mDice improved from -inf to 0.35433, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 6545.1558 - acc: 0.9028 - mDice: 0.4313 - val_loss: 5727.4298 - val_acc: 0.9198 - val_mDice: 0.4561

Epoch 00002: val_mDice improved from 0.35433 to 0.45610, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 5119.0406 - acc: 0.9191 - mDice: 0.5137 - val_loss: 5029.5702 - val_acc: 0.9263 - val_mDice: 0.4987

Epoch 00003: val_mDice improved from 0.45610 to 0.49866, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 4474.6435 - acc: 0.9249 - mDice: 0.5570 - val_loss: 4615.7100 - val_acc: 0.9292 - val_mDice: 0.5242

Epoch 00004: val_mDice improved from 0.49866 to 0.52422, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 11s - loss: 4095.7038 - acc: 0.9289 - mDice: 0.5845 - val_loss: 4520.4781 - val_acc: 0.9303 - val_mDice: 0.5320

Epoch 00005: val_mDice improved from 0.52422 to 0.53201, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 3780.3297 - acc: 0.9318 - mDice: 0.6083 - val_loss: 4349.1500 - val_acc: 0.9315 - val_mDice: 0.5419

Epoch 00006: val_mDice improved from 0.53201 to 0.54188, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 12s - loss: 3578.4887 - acc: 0.9338 - mDice: 0.6245 - val_loss: 4293.8077 - val_acc: 0.9328 - val_mDice: 0.5470

Epoch 00007: val_mDice improved from 0.54188 to 0.54695, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 3427.6790 - acc: 0.9354 - mDice: 0.6368 - val_loss: 4193.6003 - val_acc: 0.9318 - val_mDice: 0.5521

Epoch 00008: val_mDice improved from 0.54695 to 0.55206, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 3276.8113 - acc: 0.9370 - mDice: 0.6493 - val_loss: 4184.7063 - val_acc: 0.9314 - val_mDice: 0.5534

Epoch 00009: val_mDice improved from 0.55206 to 0.55344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 11s - loss: 3151.7978 - acc: 0.9382 - mDice: 0.6599 - val_loss: 4070.1601 - val_acc: 0.9328 - val_mDice: 0.5621

Epoch 00010: val_mDice improved from 0.55344 to 0.56213, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 11s - loss: 3054.2634 - acc: 0.9393 - mDice: 0.6683 - val_loss: 4058.0683 - val_acc: 0.9343 - val_mDice: 0.5645

Epoch 00011: val_mDice improved from 0.56213 to 0.56452, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 2983.1007 - acc: 0.9400 - mDice: 0.6746 - val_loss: 3991.7298 - val_acc: 0.9344 - val_mDice: 0.5687

Epoch 00012: val_mDice improved from 0.56452 to 0.56870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 11s - loss: 2909.8081 - acc: 0.9408 - mDice: 0.6810 - val_loss: 3955.3906 - val_acc: 0.9357 - val_mDice: 0.5716

Epoch 00013: val_mDice improved from 0.56870 to 0.57158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 11s - loss: 2824.5845 - acc: 0.9417 - mDice: 0.6884 - val_loss: 3944.9911 - val_acc: 0.9364 - val_mDice: 0.5727

Epoch 00014: val_mDice improved from 0.57158 to 0.57272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 11s - loss: 2787.6748 - acc: 0.9421 - mDice: 0.6919 - val_loss: 3864.0141 - val_acc: 0.9360 - val_mDice: 0.5790

Epoch 00015: val_mDice improved from 0.57272 to 0.57900, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 11s - loss: 2703.7189 - acc: 0.9429 - mDice: 0.6992 - val_loss: 4000.5964 - val_acc: 0.9348 - val_mDice: 0.5700

Epoch 00016: val_mDice did not improve from 0.57900
Epoch 17/300
 - 11s - loss: 2647.1640 - acc: 0.9435 - mDice: 0.7044 - val_loss: 4102.3782 - val_acc: 0.9362 - val_mDice: 0.5619

Epoch 00017: val_mDice did not improve from 0.57900
Epoch 18/300
 - 11s - loss: 2602.5005 - acc: 0.9440 - mDice: 0.7085 - val_loss: 3847.1424 - val_acc: 0.9403 - val_mDice: 0.5820

Epoch 00018: val_mDice improved from 0.57900 to 0.58199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 11s - loss: 2543.2240 - acc: 0.9447 - mDice: 0.7139 - val_loss: 4061.3364 - val_acc: 0.9383 - val_mDice: 0.5661

Epoch 00019: val_mDice did not improve from 0.58199
Epoch 20/300
 - 11s - loss: 2504.2972 - acc: 0.9450 - mDice: 0.7176 - val_loss: 4205.9476 - val_acc: 0.9338 - val_mDice: 0.5527

Epoch 00020: val_mDice did not improve from 0.58199
Epoch 21/300
 - 11s - loss: 2465.3796 - acc: 0.9455 - mDice: 0.7212 - val_loss: 4269.3324 - val_acc: 0.9358 - val_mDice: 0.5510

Epoch 00021: val_mDice did not improve from 0.58199
Epoch 22/300
 - 11s - loss: 2415.9986 - acc: 0.9460 - mDice: 0.7258 - val_loss: 4017.2929 - val_acc: 0.9384 - val_mDice: 0.5670

Epoch 00022: val_mDice did not improve from 0.58199
Epoch 23/300
 - 11s - loss: 2387.6959 - acc: 0.9463 - mDice: 0.7285 - val_loss: 3996.6988 - val_acc: 0.9360 - val_mDice: 0.5685

Epoch 00023: val_mDice did not improve from 0.58199
Epoch 24/300
 - 11s - loss: 2349.5448 - acc: 0.9468 - mDice: 0.7321 - val_loss: 4067.8968 - val_acc: 0.9380 - val_mDice: 0.5628

Epoch 00024: val_mDice did not improve from 0.58199
Epoch 25/300
 - 11s - loss: 2320.0565 - acc: 0.9471 - mDice: 0.7350 - val_loss: 4076.0170 - val_acc: 0.9342 - val_mDice: 0.5620

Epoch 00025: val_mDice did not improve from 0.58199
Epoch 26/300
 - 11s - loss: 2281.7069 - acc: 0.9475 - mDice: 0.7386 - val_loss: 3990.2145 - val_acc: 0.9392 - val_mDice: 0.5697

Epoch 00026: val_mDice did not improve from 0.58199
Epoch 27/300
 - 11s - loss: 2250.9859 - acc: 0.9480 - mDice: 0.7416 - val_loss: 4160.0039 - val_acc: 0.9370 - val_mDice: 0.5564

Epoch 00027: val_mDice did not improve from 0.58199
Epoch 28/300
 - 12s - loss: 2228.8931 - acc: 0.9483 - mDice: 0.7438 - val_loss: 4030.8382 - val_acc: 0.9389 - val_mDice: 0.5682

Epoch 00028: val_mDice did not improve from 0.58199
Epoch 29/300
 - 11s - loss: 2198.5980 - acc: 0.9485 - mDice: 0.7467 - val_loss: 4072.1644 - val_acc: 0.9373 - val_mDice: 0.5629

Epoch 00029: val_mDice did not improve from 0.58199
Epoch 30/300
 - 11s - loss: 2157.0223 - acc: 0.9489 - mDice: 0.7508 - val_loss: 4020.1963 - val_acc: 0.9397 - val_mDice: 0.5673

Epoch 00030: val_mDice did not improve from 0.58199
Epoch 31/300
 - 11s - loss: 2142.8494 - acc: 0.9491 - mDice: 0.7522 - val_loss: 4059.7914 - val_acc: 0.9387 - val_mDice: 0.5656

Epoch 00031: val_mDice did not improve from 0.58199
Epoch 32/300
 - 11s - loss: 2124.8638 - acc: 0.9494 - mDice: 0.7540 - val_loss: 4157.6902 - val_acc: 0.9398 - val_mDice: 0.5567

Epoch 00032: val_mDice did not improve from 0.58199
Epoch 33/300
 - 11s - loss: 2094.7840 - acc: 0.9496 - mDice: 0.7568 - val_loss: 4205.8146 - val_acc: 0.9381 - val_mDice: 0.5542

Epoch 00033: val_mDice did not improve from 0.58199
Epoch 34/300
 - 11s - loss: 2071.8791 - acc: 0.9498 - mDice: 0.7591 - val_loss: 4228.7093 - val_acc: 0.9346 - val_mDice: 0.5503

Epoch 00034: val_mDice did not improve from 0.58199
Epoch 35/300
 - 11s - loss: 2055.9369 - acc: 0.9501 - mDice: 0.7608 - val_loss: 3934.9374 - val_acc: 0.9406 - val_mDice: 0.5747

Epoch 00035: val_mDice did not improve from 0.58199
Epoch 36/300
 - 11s - loss: 2028.8514 - acc: 0.9505 - mDice: 0.7635 - val_loss: 4085.0213 - val_acc: 0.9422 - val_mDice: 0.5654

Epoch 00036: val_mDice did not improve from 0.58199
Epoch 37/300
 - 11s - loss: 2012.4115 - acc: 0.9506 - mDice: 0.7652 - val_loss: 4221.3534 - val_acc: 0.9403 - val_mDice: 0.5564

Epoch 00037: val_mDice did not improve from 0.58199
Epoch 38/300
 - 11s - loss: 1992.1830 - acc: 0.9509 - mDice: 0.7672 - val_loss: 4284.9755 - val_acc: 0.9370 - val_mDice: 0.5589

Epoch 00038: val_mDice did not improve from 0.58199
Epoch 39/300
 - 11s - loss: 1977.3094 - acc: 0.9511 - mDice: 0.7687 - val_loss: 4087.8529 - val_acc: 0.9381 - val_mDice: 0.5645

Epoch 00039: val_mDice did not improve from 0.58199
Epoch 40/300
 - 11s - loss: 1951.6450 - acc: 0.9514 - mDice: 0.7713 - val_loss: 4088.5957 - val_acc: 0.9404 - val_mDice: 0.5628

Epoch 00040: val_mDice did not improve from 0.58199
Epoch 41/300
 - 11s - loss: 1939.7640 - acc: 0.9515 - mDice: 0.7725 - val_loss: 4085.9418 - val_acc: 0.9392 - val_mDice: 0.5656

Epoch 00041: val_mDice did not improve from 0.58199
Epoch 42/300
 - 11s - loss: 1927.1269 - acc: 0.9518 - mDice: 0.7738 - val_loss: 4146.0480 - val_acc: 0.9421 - val_mDice: 0.5595

Epoch 00042: val_mDice did not improve from 0.58199
Epoch 43/300
 - 11s - loss: 1914.8289 - acc: 0.9520 - mDice: 0.7750 - val_loss: 4155.8852 - val_acc: 0.9415 - val_mDice: 0.5600

Epoch 00043: val_mDice did not improve from 0.58199
Epoch 44/300
 - 11s - loss: 1888.0016 - acc: 0.9522 - mDice: 0.7777 - val_loss: 4022.0589 - val_acc: 0.9401 - val_mDice: 0.5714

Epoch 00044: val_mDice did not improve from 0.58199
Epoch 45/300
 - 11s - loss: 1873.3680 - acc: 0.9523 - mDice: 0.7792 - val_loss: 4239.4913 - val_acc: 0.9379 - val_mDice: 0.5571

Epoch 00045: val_mDice did not improve from 0.58199
Epoch 46/300
 - 11s - loss: 1863.3746 - acc: 0.9523 - mDice: 0.7802 - val_loss: 3955.4720 - val_acc: 0.9400 - val_mDice: 0.5741

Epoch 00046: val_mDice did not improve from 0.58199
Epoch 47/300
 - 11s - loss: 1845.3674 - acc: 0.9526 - mDice: 0.7821 - val_loss: 4130.7665 - val_acc: 0.9436 - val_mDice: 0.5624

Epoch 00047: val_mDice did not improve from 0.58199
Epoch 48/300
 - 12s - loss: 1832.6219 - acc: 0.9529 - mDice: 0.7834 - val_loss: 4100.8052 - val_acc: 0.9412 - val_mDice: 0.5644

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.26s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:17,  1.33s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:49,  1.45s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:49,  1.45s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:13,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:00,  1.50s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:22,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:45,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:59,  1.73s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:03,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:10,  1.79s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:19,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:27,  1.86s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:34,  1.90s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:38,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:39,  1.93s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:31,  1.91s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:31,  1.91s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:28,  1.91s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:31,  1.93s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:25,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:23,  1.91s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:25,  1.93s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<08:22,  1.92s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:15,  1.91s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:13,  1.90s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:11,  1.91s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:03,  1.88s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:57,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:54<07:49,  1.84s/it]predicting train subjects:  11%|█         | 31/285 [00:56<07:44,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:36,  1.80s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:36,  1.81s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:30,  1.80s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:32,  1.81s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:31,  1.81s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:24,  1.79s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:20,  1.78s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:20,  1.79s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:19,  1.79s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:17,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:16<07:16,  1.80s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:16,  1.80s/it]predicting train subjects:  15%|█▌        | 44/285 [01:20<07:26,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:33,  1.89s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:14,  1.82s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<06:48,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<06:38,  1.68s/it]predicting train subjects:  17%|█▋        | 49/285 [01:28<06:45,  1.72s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<06:33,  1.67s/it]predicting train subjects:  18%|█▊        | 51/285 [01:31<06:18,  1.62s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<06:08,  1.58s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<06:07,  1.58s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<06:01,  1.57s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:01,  1.57s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<05:59,  1.57s/it]predicting train subjects:  20%|██        | 57/285 [01:40<05:56,  1.56s/it]predicting train subjects:  20%|██        | 58/285 [01:42<05:56,  1.57s/it]predicting train subjects:  21%|██        | 59/285 [01:44<05:53,  1.56s/it]predicting train subjects:  21%|██        | 60/285 [01:45<05:55,  1.58s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<05:54,  1.58s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<05:53,  1.58s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<05:50,  1.58s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<05:51,  1.59s/it]predicting train subjects:  23%|██▎       | 65/285 [01:53<06:04,  1.66s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:09,  1.69s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:02,  1.66s/it]predicting train subjects:  24%|██▍       | 68/285 [01:58<05:56,  1.64s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<05:50,  1.62s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<05:49,  1.63s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<05:46,  1.62s/it]predicting train subjects:  25%|██▌       | 72/285 [02:05<05:41,  1.60s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<05:38,  1.60s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<05:35,  1.59s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<05:33,  1.59s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<05:29,  1.58s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:25,  1.57s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:24,  1.57s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:18,  1.55s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:20,  1.57s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:19,  1.57s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:18,  1.57s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:20,  1.59s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:19,  1.59s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:32,  1.66s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:36,  1.69s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:39,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:39,  1.72s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:36,  1.72s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:34,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:31,  1.71s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:31,  1.72s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:33,  1.74s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:34,  1.75s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:34,  1.76s/it]predicting train subjects:  34%|███▎      | 96/285 [02:45<05:33,  1.76s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:30,  1.76s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:26,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:28,  1.76s/it]predicting train subjects:  35%|███▌      | 100/285 [02:52<05:28,  1.78s/it]predicting train subjects:  35%|███▌      | 101/285 [02:54<05:27,  1.78s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:26,  1.79s/it]predicting train subjects:  36%|███▌      | 103/285 [02:57<05:26,  1.79s/it]predicting train subjects:  36%|███▋      | 104/285 [02:59<05:23,  1.79s/it]predicting train subjects:  37%|███▋      | 105/285 [03:01<05:19,  1.78s/it]predicting train subjects:  37%|███▋      | 106/285 [03:02<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:04<05:18,  1.79s/it]predicting train subjects:  38%|███▊      | 108/285 [03:06<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:08<05:15,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:10<05:14,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:11<05:12,  1.80s/it]predicting train subjects:  39%|███▉      | 112/285 [03:13<05:10,  1.79s/it]predicting train subjects:  40%|███▉      | 113/285 [03:15<05:07,  1.79s/it]predicting train subjects:  40%|████      | 114/285 [03:17<05:05,  1.79s/it]predicting train subjects:  40%|████      | 115/285 [03:19<05:03,  1.78s/it]predicting train subjects:  41%|████      | 116/285 [03:20<04:57,  1.76s/it]predicting train subjects:  41%|████      | 117/285 [03:22<04:56,  1.76s/it]predicting train subjects:  41%|████▏     | 118/285 [03:24<04:54,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:26<04:50,  1.75s/it]predicting train subjects:  42%|████▏     | 120/285 [03:27<04:45,  1.73s/it]predicting train subjects:  42%|████▏     | 121/285 [03:29<04:39,  1.70s/it]predicting train subjects:  43%|████▎     | 122/285 [03:30<04:28,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:32<04:16,  1.59s/it]predicting train subjects:  44%|████▎     | 124/285 [03:33<04:17,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:35<04:16,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:37<04:17,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:38<04:14,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [03:40<04:10,  1.59s/it]predicting train subjects:  45%|████▌     | 129/285 [03:41<04:05,  1.57s/it]predicting train subjects:  46%|████▌     | 130/285 [03:43<04:09,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<04:07,  1.61s/it]predicting train subjects:  46%|████▋     | 132/285 [03:46<04:04,  1.60s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<04:02,  1.59s/it]predicting train subjects:  47%|████▋     | 134/285 [03:49<03:59,  1.59s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<04:00,  1.60s/it]predicting train subjects:  48%|████▊     | 136/285 [03:53<03:58,  1.60s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [03:56<03:57,  1.62s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:52,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [04:01<03:47,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:04<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:34,  1.52s/it]predicting train subjects:  51%|█████     | 145/285 [04:07<03:31,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:10<03:29,  1.52s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:13<03:23,  1.49s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:14<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:16<03:18,  1.48s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:11,  1.46s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:08,  1.45s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:06,  1.45s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:07,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:26<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:27<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:29<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<02:59,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<02:55,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<02:52,  1.41s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<02:52,  1.42s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:49,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:37<02:47,  1.41s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:38<02:44,  1.40s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:40<02:46,  1.43s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:41<02:43,  1.41s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:43<02:41,  1.41s/it]predicting train subjects:  60%|██████    | 171/285 [04:44<02:40,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:46<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:47<02:39,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [04:48<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:50<02:36,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:51<02:34,  1.42s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:53<02:33,  1.42s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:54<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:55<02:29,  1.41s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:57<02:25,  1.39s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:58<02:25,  1.39s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:00<02:23,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:01<02:22,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:02<02:21,  1.40s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:04<02:20,  1.40s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:05<02:18,  1.40s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:07<02:17,  1.40s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:08<02:13,  1.38s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:09<02:10,  1.36s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:11<02:08,  1.36s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:12<02:07,  1.35s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:13<02:05,  1.35s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:15<02:05,  1.37s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:16<02:03,  1.36s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:17<02:02,  1.36s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:19<02:08,  1.44s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:21<02:13,  1.51s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:22<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:24<02:17,  1.60s/it]predicting train subjects:  70%|███████   | 200/285 [05:26<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:27<02:17,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:29<02:15,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:31<02:13,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:32<02:10,  1.62s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:34<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:35<02:07,  1.61s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:37<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:39<02:05,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:40<02:05,  1.66s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:42<02:06,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:44<02:04,  1.68s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:46<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:47<01:59,  1.67s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:49<01:53,  1.60s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:50<01:49,  1.57s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:52<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:53<01:42,  1.51s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:55<01:41,  1.52s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:56<01:37,  1.48s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:57<01:36,  1.48s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:59<01:33,  1.47s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:00<01:31,  1.45s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:02<01:29,  1.44s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:03<01:26,  1.42s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:05<01:25,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:06<01:24,  1.43s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:07<01:23,  1.43s/it]predicting train subjects:  80%|████████  | 228/285 [06:09<01:22,  1.44s/it]predicting train subjects:  80%|████████  | 229/285 [06:10<01:20,  1.44s/it]predicting train subjects:  81%|████████  | 230/285 [06:12<01:19,  1.44s/it]predicting train subjects:  81%|████████  | 231/285 [06:13<01:18,  1.45s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:15<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:17<01:25,  1.64s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:19<01:25,  1.68s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:20<01:24,  1.70s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:22<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:24<01:24,  1.75s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:26<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:28<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:29<01:19,  1.76s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:31<01:17,  1.76s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:33<01:14,  1.73s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:35<01:14,  1.77s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:36<01:12,  1.76s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:38<01:10,  1.76s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:40<01:07,  1.74s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:42<01:06,  1.74s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:43<01:04,  1.74s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:45<01:02,  1.75s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:46<00:56,  1.62s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:48<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:49<00:47,  1.45s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:50<00:45,  1.44s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:52<00:44,  1.42s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:53<00:41,  1.39s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:54<00:39,  1.38s/it]predicting train subjects:  90%|█████████ | 257/285 [06:56<00:38,  1.36s/it]predicting train subjects:  91%|█████████ | 258/285 [06:57<00:36,  1.36s/it]predicting train subjects:  91%|█████████ | 259/285 [06:58<00:35,  1.35s/it]predicting train subjects:  91%|█████████ | 260/285 [07:00<00:33,  1.35s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:01<00:32,  1.34s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:03<00:31,  1.36s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:04<00:29,  1.35s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:05<00:28,  1.35s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:07<00:26,  1.34s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:08<00:25,  1.33s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:09<00:24,  1.34s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:11<00:25,  1.47s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:13<00:25,  1.57s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:15<00:24,  1.63s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:16<00:23,  1.68s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:18<00:22,  1.71s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:20<00:20,  1.72s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:22<00:19,  1.73s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:23<00:17,  1.77s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:25<00:16,  1.78s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:27<00:14,  1.78s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:29<00:12,  1.78s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:31<00:10,  1.77s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:32<00:08,  1.77s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:34<00:07,  1.76s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:36<00:05,  1.77s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:38<00:03,  1.78s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:39<00:01,  1.78s/it]predicting train subjects: 100%|██████████| 285/285 [07:41<00:00,  1.79s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:46,  1.22s/it]Loading train:   1%|          | 2/285 [00:02<06:00,  1.27s/it]Loading train:   1%|          | 3/285 [00:03<05:55,  1.26s/it]Loading train:   1%|▏         | 4/285 [00:05<06:16,  1.34s/it]Loading train:   2%|▏         | 5/285 [00:06<05:49,  1.25s/it]Loading train:   2%|▏         | 6/285 [00:07<06:06,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:28,  1.40s/it]Loading train:   3%|▎         | 8/285 [00:10<06:33,  1.42s/it]Loading train:   3%|▎         | 9/285 [00:12<06:12,  1.35s/it]Loading train:   4%|▎         | 10/285 [00:13<05:42,  1.25s/it]Loading train:   4%|▍         | 11/285 [00:14<05:22,  1.18s/it]Loading train:   4%|▍         | 12/285 [00:15<05:09,  1.13s/it]Loading train:   5%|▍         | 13/285 [00:16<04:52,  1.07s/it]Loading train:   5%|▍         | 14/285 [00:17<04:46,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:18<04:38,  1.03s/it]Loading train:   6%|▌         | 16/285 [00:19<04:31,  1.01s/it]Loading train:   6%|▌         | 17/285 [00:20<04:33,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:21<04:27,  1.00s/it]Loading train:   7%|▋         | 19/285 [00:22<04:24,  1.00it/s]Loading train:   7%|▋         | 20/285 [00:23<04:27,  1.01s/it]Loading train:   7%|▋         | 21/285 [00:24<04:26,  1.01s/it]Loading train:   8%|▊         | 22/285 [00:25<04:24,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:26<04:25,  1.01s/it]Loading train:   8%|▊         | 24/285 [00:27<04:15,  1.02it/s]Loading train:   9%|▉         | 25/285 [00:27<04:11,  1.03it/s]Loading train:   9%|▉         | 26/285 [00:28<04:09,  1.04it/s]Loading train:   9%|▉         | 27/285 [00:29<04:10,  1.03it/s]Loading train:  10%|▉         | 28/285 [00:30<04:08,  1.03it/s]Loading train:  10%|█         | 29/285 [00:31<03:59,  1.07it/s]Loading train:  11%|█         | 30/285 [00:32<03:49,  1.11it/s]Loading train:  11%|█         | 31/285 [00:33<03:45,  1.13it/s]Loading train:  11%|█         | 32/285 [00:34<03:45,  1.12it/s]Loading train:  12%|█▏        | 33/285 [00:35<03:48,  1.10it/s]Loading train:  12%|█▏        | 34/285 [00:36<03:47,  1.10it/s]Loading train:  12%|█▏        | 35/285 [00:37<03:48,  1.09it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:47,  1.09it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:45,  1.10it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:42,  1.11it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:39,  1.12it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:35,  1.14it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:39,  1.11it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:34,  1.13it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:40,  1.10it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:41,  1.09it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:41,  1.08it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:30,  1.14it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:14,  1.23it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:05,  1.28it/s]Loading train:  17%|█▋        | 49/285 [00:48<02:59,  1.32it/s]Loading train:  18%|█▊        | 50/285 [00:49<02:53,  1.35it/s]Loading train:  18%|█▊        | 51/285 [00:50<02:49,  1.38it/s]Loading train:  18%|█▊        | 52/285 [00:51<02:47,  1.39it/s]Loading train:  19%|█▊        | 53/285 [00:51<02:49,  1.37it/s]Loading train:  19%|█▉        | 54/285 [00:52<02:45,  1.40it/s]Loading train:  19%|█▉        | 55/285 [00:53<02:50,  1.35it/s]Loading train:  20%|█▉        | 56/285 [00:54<02:46,  1.37it/s]Loading train:  20%|██        | 57/285 [00:54<02:50,  1.34it/s]Loading train:  20%|██        | 58/285 [00:55<02:51,  1.32it/s]Loading train:  21%|██        | 59/285 [00:56<02:51,  1.32it/s]Loading train:  21%|██        | 60/285 [00:57<02:52,  1.30it/s]Loading train:  21%|██▏       | 61/285 [00:57<02:51,  1.30it/s]Loading train:  22%|██▏       | 62/285 [00:58<02:49,  1.32it/s]Loading train:  22%|██▏       | 63/285 [00:59<02:53,  1.28it/s]Loading train:  22%|██▏       | 64/285 [01:00<03:26,  1.07it/s]Loading train:  23%|██▎       | 65/285 [01:02<04:04,  1.11s/it]
Epoch 00048: val_mDice did not improve from 0.58199
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
{'val_loss': [7626.665414663462, 5727.429818960337, 5029.570199819712, 4615.709979717548, 4520.4781165489785, 4349.1499586838945, 4293.8076735276445, 4193.6003183218145, 4184.706251878005, 4070.1601280799277, 4058.0682936448316, 3991.7298208383413, 3955.390587439904, 3944.9910560021035, 3864.0140944260816, 4000.596430851863, 4102.3781503530645, 3847.1423997145434, 4061.336444561298, 4205.947645920974, 4269.3324303260215, 4017.29294527494, 3996.69877741887, 4067.896784855769, 4076.0169818584736, 3990.2144822340747, 4160.003887469952, 4030.8382333608774, 4072.1643676757812, 4020.196274977464, 4059.7913677509014, 4157.690190241887, 4205.814626840444, 4228.70933180589, 3934.9373732346753, 4085.021259014423, 4221.353365384615, 4284.975524902344, 4087.8529146634614, 4088.595670259916, 4085.9418053260215, 4146.048044057993, 4155.8851647010215, 4022.058851975661, 4239.491342397837, 3955.4719895582934, 4130.766535832332, 4100.805180476262], 'val_acc': [0.8890809783568749, 0.9197716231529529, 0.9263082513442407, 0.9292067472751324, 0.9303115996030661, 0.931501927284094, 0.9328032296437484, 0.9317538646551279, 0.9313887059688568, 0.9328471834842975, 0.9342524982415713, 0.9343773057827582, 0.9357225551055028, 0.9363789581335508, 0.9360253467009618, 0.9348326738064106, 0.9361686385594882, 0.9403360738204076, 0.9383182456860175, 0.9337624678244958, 0.9357733772351191, 0.9384245620324061, 0.9360045378024762, 0.9379784625310165, 0.934166995378641, 0.9391965453441327, 0.9370053869027358, 0.9388914337525001, 0.9373358694406656, 0.9396796684998733, 0.9387342838140634, 0.9398368230232825, 0.9380847674149734, 0.9345737879092877, 0.9405810557878934, 0.9422429570784936, 0.9403060330794408, 0.9369752980195559, 0.9381055717284863, 0.9404169550308814, 0.9391619127530318, 0.942083484851397, 0.9415379785574399, 0.9400772108481481, 0.9378721576470596, 0.9400356022211221, 0.9436136002723987, 0.9411727900688465], 'val_mDice': [0.3543315971126923, 0.4561029913333746, 0.49866027442308575, 0.5242186119923224, 0.5320140971587255, 0.5418835545961673, 0.5469525152674088, 0.5520631739726434, 0.5534374771209863, 0.5621297267767099, 0.5645162572081273, 0.5687017710163043, 0.5715768274206382, 0.5727156526767291, 0.5790027173665854, 0.5699656410859182, 0.5619171198744041, 0.5819856621898137, 0.5661370972028146, 0.552664753049612, 0.5510249103491123, 0.5669673589559702, 0.5684583164178408, 0.5628102691127703, 0.5619555299098675, 0.5697155291071305, 0.5563765827279824, 0.5682107261740245, 0.5629303627289258, 0.5673296600580215, 0.5655859422225219, 0.5566900108869259, 0.5541744447098329, 0.5502511618229059, 0.5747180222891844, 0.565391464302173, 0.5563568962881198, 0.5588933630631521, 0.5645491618376511, 0.5627931740421516, 0.5656203521558871, 0.5594945807869618, 0.5599895159785564, 0.5713887352209824, 0.5570741272889651, 0.5741424669439976, 0.5624461013537186, 0.5643851891733133], 'loss': [14497.319120324604, 6545.1558412676595, 5119.040571339949, 4474.643450303479, 4095.7037960433504, 3780.3296716442565, 3578.4887152677707, 3427.678973271026, 3276.8113367801375, 3151.7978109436963, 3054.263401503274, 2983.100728486084, 2909.8080822435304, 2824.584539269737, 2787.6748382137744, 2703.718917034698, 2647.164045601767, 2602.500525151145, 2543.223995229497, 2504.2971898745336, 2465.3795725649975, 2415.998647499665, 2387.69586749043, 2349.5447985888254, 2320.056530904695, 2281.7069201731083, 2250.9858987342604, 2228.893134927965, 2198.5980440368626, 2157.022312129477, 2142.849350379466, 2124.863789992635, 2094.7839702946403, 2071.8791029663707, 2055.9368568426744, 2028.8514204861701, 2012.411527641231, 1992.1830090947842, 1977.3094380593416, 1951.6450442425232, 1939.7640355303754, 1927.1268998747391, 1914.8289224817602, 1888.0015731680649, 1873.368001981315, 1863.3745809328311, 1845.367422133258, 1832.621879371475], 'acc': [0.8611911745580659, 0.9027598678026759, 0.9191445730098178, 0.9249108779818482, 0.9289268060912618, 0.9318009346632855, 0.933845723817613, 0.9354183457494277, 0.9369708574380007, 0.9382471327443938, 0.9393360821026383, 0.9399669395869128, 0.94083669947971, 0.941671267878819, 0.9421167465293252, 0.9429381954860151, 0.9435438021109089, 0.9440499088547166, 0.9446904118360325, 0.9449757996228176, 0.9455289757582662, 0.9459776875773315, 0.946292472162733, 0.9468366503880427, 0.9471130350809591, 0.947519181966012, 0.9479881566542492, 0.9482666928148309, 0.9485076530375715, 0.9489095425964182, 0.9491177417250628, 0.9494226166246167, 0.9496026980055662, 0.949834347540829, 0.9500779050099919, 0.9504934264254022, 0.9506105088136584, 0.9508557225696321, 0.9511111595803693, 0.9514429712222972, 0.9515173063994575, 0.9517720616040806, 0.9519533602159908, 0.952174171314769, 0.9523019103901441, 0.9523460516177189, 0.9525769485721924, 0.952856128202377], 'mDice': [0.24607170577211088, 0.4312856767952228, 0.5136625940571256, 0.5569819768372468, 0.5844574236489415, 0.6083086933650336, 0.624454492134306, 0.636823796092458, 0.6493088629790407, 0.6599267987453837, 0.6682747045610374, 0.6745981949397936, 0.6810190841235392, 0.6884040711639134, 0.6919417253754779, 0.6992146884296737, 0.7043835794552988, 0.7084710799624183, 0.7139226735699147, 0.7175754320519245, 0.7211565987206051, 0.7258145526074884, 0.7285041143387806, 0.7320943828890335, 0.7349875562197387, 0.7385840214762116, 0.7415845482087515, 0.7438175227274196, 0.7467005005250456, 0.7507930679601859, 0.7521512262618686, 0.7539938598950938, 0.7567876396853799, 0.759137058768184, 0.7607791341451616, 0.7634870160124041, 0.7651853269452397, 0.7671510409431507, 0.7686621702257188, 0.7712675566043535, 0.7724957411924456, 0.773807162784688, 0.7750206259270387, 0.777743130661207, 0.7792311804734131, 0.7802385219643282, 0.7821366005384492, 0.7834257816604326]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0     Loading train:  23%|██▎       | 66/285 [01:03<04:10,  1.15s/it]Loading train:  24%|██▎       | 67/285 [01:04<03:49,  1.05s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:32,  1.02it/s]Loading train:  24%|██▍       | 69/285 [01:05<03:19,  1.08it/s]Loading train:  25%|██▍       | 70/285 [01:06<03:07,  1.15it/s]Loading train:  25%|██▍       | 71/285 [01:07<03:00,  1.19it/s]Loading train:  25%|██▌       | 72/285 [01:08<02:56,  1.20it/s]Loading train:  26%|██▌       | 73/285 [01:09<02:49,  1.25it/s]Loading train:  26%|██▌       | 74/285 [01:09<02:51,  1.23it/s]Loading train:  26%|██▋       | 75/285 [01:10<02:49,  1.24it/s]Loading train:  27%|██▋       | 76/285 [01:11<02:45,  1.26it/s]Loading train:  27%|██▋       | 77/285 [01:12<02:52,  1.21it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:47,  1.24it/s]Loading train:  28%|██▊       | 79/285 [01:13<02:43,  1.26it/s]Loading train:  28%|██▊       | 80/285 [01:14<02:43,  1.25it/s]Loading train:  28%|██▊       | 81/285 [01:15<02:41,  1.26it/s]Loading train:  29%|██▉       | 82/285 [01:16<02:43,  1.24it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:41,  1.25it/s]Loading train:  29%|██▉       | 84/285 [01:17<02:40,  1.25it/s]Loading train:  30%|██▉       | 85/285 [01:18<02:52,  1.16it/s]Loading train:  30%|███       | 86/285 [01:19<02:59,  1.11it/s]Loading train:  31%|███       | 87/285 [01:20<02:59,  1.10it/s]Loading train:  31%|███       | 88/285 [01:21<03:02,  1.08it/s]Loading train:  31%|███       | 89/285 [01:22<03:04,  1.06it/s]Loading train:  32%|███▏      | 90/285 [01:23<03:02,  1.07it/s]Loading train:  32%|███▏      | 91/285 [01:24<03:04,  1.05it/s]Loading train:  32%|███▏      | 92/285 [01:25<03:06,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:26<03:10,  1.01it/s]Loading train:  33%|███▎      | 94/285 [01:27<03:08,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:28<03:03,  1.04it/s]Loading train:  34%|███▎      | 96/285 [01:29<03:00,  1.05it/s]Loading train:  34%|███▍      | 97/285 [01:30<02:56,  1.06it/s]Loading train:  34%|███▍      | 98/285 [01:31<02:59,  1.04it/s]Loading train:  35%|███▍      | 99/285 [01:32<03:00,  1.03it/s]Loading train:  35%|███▌      | 100/285 [01:33<03:00,  1.03it/s]Loading train:  35%|███▌      | 101/285 [01:34<02:59,  1.02it/s]Loading train:  36%|███▌      | 102/285 [01:35<02:53,  1.05it/s]Loading train:  36%|███▌      | 103/285 [01:36<02:49,  1.07it/s]Loading train:  36%|███▋      | 104/285 [01:37<02:45,  1.09it/s]Loading train:  37%|███▋      | 105/285 [01:37<02:46,  1.08it/s]Loading train:  37%|███▋      | 106/285 [01:38<02:47,  1.07it/s]Loading train:  38%|███▊      | 107/285 [01:39<02:42,  1.09it/s]Loading train:  38%|███▊      | 108/285 [01:40<02:41,  1.09it/s]Loading train:  38%|███▊      | 109/285 [01:41<02:36,  1.12it/s]Loading train:  39%|███▊      | 110/285 [01:42<02:32,  1.15it/s]Loading train:  39%|███▉      | 111/285 [01:43<02:26,  1.19it/s]Loading train:  39%|███▉      | 112/285 [01:43<02:24,  1.19it/s]Loading train:  40%|███▉      | 113/285 [01:44<02:24,  1.19it/s]Loading train:  40%|████      | 114/285 [01:45<02:26,  1.16it/s]Loading train:  40%|████      | 115/285 [01:46<02:27,  1.16it/s]Loading train:  41%|████      | 116/285 [01:47<02:24,  1.17it/s]Loading train:  41%|████      | 117/285 [01:48<02:19,  1.20it/s]Loading train:  41%|████▏     | 118/285 [01:49<02:20,  1.19it/s]Loading train:  42%|████▏     | 119/285 [01:50<02:24,  1.15it/s]Loading train:  42%|████▏     | 120/285 [01:50<02:21,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:52<02:39,  1.03it/s]Loading train:  43%|████▎     | 122/285 [01:53<02:47,  1.02s/it]Loading train:  43%|████▎     | 123/285 [01:54<02:49,  1.04s/it]Loading train:  44%|████▎     | 124/285 [01:55<02:36,  1.03it/s]Loading train:  44%|████▍     | 125/285 [01:55<02:25,  1.10it/s]Loading train:  44%|████▍     | 126/285 [01:56<02:16,  1.16it/s]Loading train:  45%|████▍     | 127/285 [01:57<02:09,  1.22it/s]Loading train:  45%|████▍     | 128/285 [01:58<02:04,  1.26it/s]Loading train:  45%|████▌     | 129/285 [01:58<02:04,  1.26it/s]Loading train:  46%|████▌     | 130/285 [01:59<02:01,  1.27it/s]Loading train:  46%|████▌     | 131/285 [02:00<01:59,  1.29it/s]Loading train:  46%|████▋     | 132/285 [02:01<02:00,  1.27it/s]Loading train:  47%|████▋     | 133/285 [02:01<01:56,  1.31it/s]Loading train:  47%|████▋     | 134/285 [02:02<01:57,  1.28it/s]Loading train:  47%|████▋     | 135/285 [02:03<01:57,  1.27it/s]Loading train:  48%|████▊     | 136/285 [02:04<02:00,  1.23it/s]Loading train:  48%|████▊     | 137/285 [02:05<02:02,  1.20it/s]Loading train:  48%|████▊     | 138/285 [02:06<02:01,  1.21it/s]Loading train:  49%|████▉     | 139/285 [02:06<01:58,  1.24it/s]Loading train:  49%|████▉     | 140/285 [02:07<01:56,  1.24it/s]Loading train:  49%|████▉     | 141/285 [02:08<01:53,  1.27it/s]Loading train:  50%|████▉     | 142/285 [02:09<01:52,  1.28it/s]Loading train:  50%|█████     | 143/285 [02:09<01:49,  1.29it/s]Loading train:  51%|█████     | 144/285 [02:10<01:46,  1.33it/s]Loading train:  51%|█████     | 145/285 [02:11<01:46,  1.32it/s]Loading train:  51%|█████     | 146/285 [02:12<01:43,  1.35it/s]Loading train:  52%|█████▏    | 147/285 [02:12<01:41,  1.36it/s]Loading train:  52%|█████▏    | 148/285 [02:13<01:38,  1.39it/s]Loading train:  52%|█████▏    | 149/285 [02:14<01:37,  1.39it/s]Loading train:  53%|█████▎    | 150/285 [02:14<01:37,  1.39it/s]Loading train:  53%|█████▎    | 151/285 [02:15<01:37,  1.37it/s]Loading train:  53%|█████▎    | 152/285 [02:16<01:34,  1.40it/s]Loading train:  54%|█████▎    | 153/285 [02:17<01:33,  1.41it/s]Loading train:  54%|█████▍    | 154/285 [02:17<01:33,  1.40it/s]Loading train:  54%|█████▍    | 155/285 [02:18<01:33,  1.39it/s]Loading train:  55%|█████▍    | 156/285 [02:19<01:31,  1.41it/s]Loading train:  55%|█████▌    | 157/285 [02:19<01:28,  1.45it/s]Loading train:  55%|█████▌    | 158/285 [02:20<01:30,  1.41it/s]Loading train:  56%|█████▌    | 159/285 [02:21<01:28,  1.43it/s]Loading train:  56%|█████▌    | 160/285 [02:22<01:29,  1.39it/s]Loading train:  56%|█████▋    | 161/285 [02:22<01:29,  1.39it/s]Loading train:  57%|█████▋    | 162/285 [02:23<01:29,  1.37it/s]Loading train:  57%|█████▋    | 163/285 [02:24<01:27,  1.40it/s]Loading train:  58%|█████▊    | 164/285 [02:24<01:26,  1.41it/s]Loading train:  58%|█████▊    | 165/285 [02:25<01:25,  1.40it/s]Loading train:  58%|█████▊    | 166/285 [02:26<01:27,  1.36it/s]Loading train:  59%|█████▊    | 167/285 [02:27<01:26,  1.36it/s]Loading train:  59%|█████▉    | 168/285 [02:27<01:28,  1.32it/s]Loading train:  59%|█████▉    | 169/285 [02:28<01:24,  1.37it/s]Loading train:  60%|█████▉    | 170/285 [02:29<01:23,  1.37it/s]Loading train:  60%|██████    | 171/285 [02:29<01:19,  1.44it/s]Loading train:  60%|██████    | 172/285 [02:30<01:16,  1.48it/s]Loading train:  61%|██████    | 173/285 [02:31<01:17,  1.45it/s]Loading train:  61%|██████    | 174/285 [02:32<01:16,  1.46it/s]Loading train:  61%|██████▏   | 175/285 [02:32<01:14,  1.47it/s]Loading train:  62%|██████▏   | 176/285 [02:33<01:15,  1.45it/s]Loading train:  62%|██████▏   | 177/285 [02:34<01:13,  1.47it/s]Loading train:  62%|██████▏   | 178/285 [02:34<01:15,  1.42it/s]Loading train:  63%|██████▎   | 179/285 [02:35<01:14,  1.43it/s]Loading train:  63%|██████▎   | 180/285 [02:36<01:11,  1.46it/s]Loading train:  64%|██████▎   | 181/285 [02:36<01:10,  1.48it/s]Loading train:  64%|██████▍   | 182/285 [02:37<01:11,  1.43it/s]Loading train:  64%|██████▍   | 183/285 [02:38<01:11,  1.43it/s]Loading train:  65%|██████▍   | 184/285 [02:38<01:09,  1.45it/s]Loading train:  65%|██████▍   | 185/285 [02:39<01:09,  1.45it/s]Loading train:  65%|██████▌   | 186/285 [02:40<01:09,  1.42it/s]Loading train:  66%|██████▌   | 187/285 [02:41<01:08,  1.43it/s]Loading train:  66%|██████▌   | 188/285 [02:41<01:06,  1.46it/s]Loading train:  66%|██████▋   | 189/285 [02:42<01:05,  1.47it/s]Loading train:  67%|██████▋   | 190/285 [02:43<01:03,  1.49it/s]Loading train:  67%|██████▋   | 191/285 [02:43<01:02,  1.50it/s]Loading train:  67%|██████▋   | 192/285 [02:44<01:01,  1.52it/s]Loading train:  68%|██████▊   | 193/285 [02:45<01:01,  1.49it/s]Loading train:  68%|██████▊   | 194/285 [02:45<01:00,  1.51it/s]Loading train:  68%|██████▊   | 195/285 [02:46<01:00,  1.50it/s]Loading train:  69%|██████▉   | 196/285 [02:47<01:03,  1.41it/s]Loading train:  69%|██████▉   | 197/285 [02:47<01:03,  1.39it/s]Loading train:  69%|██████▉   | 198/285 [02:48<01:04,  1.34it/s]Loading train:  70%|██████▉   | 199/285 [02:49<01:04,  1.32it/s]Loading train:  70%|███████   | 200/285 [02:50<01:07,  1.26it/s]Loading train:  71%|███████   | 201/285 [02:51<01:05,  1.27it/s]Loading train:  71%|███████   | 202/285 [02:51<01:05,  1.26it/s]Loading train:  71%|███████   | 203/285 [02:52<01:04,  1.27it/s]Loading train:  72%|███████▏  | 204/285 [02:53<01:03,  1.28it/s]Loading train:  72%|███████▏  | 205/285 [02:54<01:02,  1.29it/s]Loading train:  72%|███████▏  | 206/285 [02:54<01:00,  1.31it/s]Loading train:  73%|███████▎  | 207/285 [02:55<00:57,  1.35it/s]Loading train:  73%|███████▎  | 208/285 [02:56<00:58,  1.31it/s]Loading train:  73%|███████▎  | 209/285 [02:57<00:58,  1.29it/s]Loading train:  74%|███████▎  | 210/285 [02:58<00:58,  1.28it/s]Loading train:  74%|███████▍  | 211/285 [02:58<00:58,  1.27it/s]Loading train:  74%|███████▍  | 212/285 [02:59<00:57,  1.28it/s]Loading train:  75%|███████▍  | 213/285 [03:00<00:56,  1.28it/s]Loading train:  75%|███████▌  | 214/285 [03:01<00:54,  1.30it/s]Loading train:  75%|███████▌  | 215/285 [03:01<00:52,  1.33it/s]Loading train:  76%|███████▌  | 216/285 [03:02<00:51,  1.34it/s]Loading train:  76%|███████▌  | 217/285 [03:03<00:49,  1.36it/s]Loading train:  76%|███████▋  | 218/285 [03:04<00:48,  1.39it/s]Loading train:  77%|███████▋  | 219/285 [03:04<00:47,  1.38it/s]Loading train:  77%|███████▋  | 220/285 [03:05<00:47,  1.38it/s]Loading train:  78%|███████▊  | 221/285 [03:06<00:46,  1.39it/s]Loading train:  78%|███████▊  | 222/285 [03:06<00:44,  1.40it/s]Loading train:  78%|███████▊  | 223/285 [03:07<00:43,  1.42it/s]Loading train:  79%|███████▊  | 224/285 [03:08<00:43,  1.41it/s]Loading train:  79%|███████▉  | 225/285 [03:09<00:43,  1.37it/s]Loading train:  79%|███████▉  | 226/285 [03:09<00:43,  1.36it/s]Loading train:  80%|███████▉  | 227/285 [03:10<00:42,  1.38it/s]Loading train:  80%|████████  | 228/285 [03:11<00:40,  1.39it/s]Loading train:  80%|████████  | 229/285 [03:11<00:39,  1.41it/s]Loading train:  81%|████████  | 230/285 [03:12<00:39,  1.39it/s]Loading train:  81%|████████  | 231/285 [03:13<00:39,  1.38it/s]Loading train:  81%|████████▏ | 232/285 [03:14<00:40,  1.30it/s]Loading train:  82%|████████▏ | 233/285 [03:15<00:41,  1.26it/s]Loading train:  82%|████████▏ | 234/285 [03:16<00:42,  1.20it/s]Loading train:  82%|████████▏ | 235/285 [03:16<00:42,  1.18it/s]Loading train:  83%|████████▎ | 236/285 [03:17<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [03:18<00:41,  1.15it/s]Loading train:  84%|████████▎ | 238/285 [03:19<00:40,  1.15it/s]Loading train:  84%|████████▍ | 239/285 [03:20<00:40,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [03:21<00:40,  1.12it/s]Loading train:  85%|████████▍ | 241/285 [03:22<00:39,  1.11it/s]Loading train:  85%|████████▍ | 242/285 [03:23<00:38,  1.12it/s]Loading train:  85%|████████▌ | 243/285 [03:24<00:37,  1.13it/s]Loading train:  86%|████████▌ | 244/285 [03:24<00:36,  1.14it/s]Loading train:  86%|████████▌ | 245/285 [03:25<00:35,  1.12it/s]Loading train:  86%|████████▋ | 246/285 [03:26<00:35,  1.11it/s]Loading train:  87%|████████▋ | 247/285 [03:27<00:33,  1.13it/s]Loading train:  87%|████████▋ | 248/285 [03:28<00:33,  1.11it/s]Loading train:  87%|████████▋ | 249/285 [03:29<00:32,  1.12it/s]Loading train:  88%|████████▊ | 250/285 [03:30<00:29,  1.18it/s]Loading train:  88%|████████▊ | 251/285 [03:30<00:27,  1.22it/s]Loading train:  88%|████████▊ | 252/285 [03:31<00:26,  1.24it/s]Loading train:  89%|████████▉ | 253/285 [03:32<00:24,  1.30it/s]Loading train:  89%|████████▉ | 254/285 [03:33<00:23,  1.33it/s]Loading train:  89%|████████▉ | 255/285 [03:33<00:22,  1.35it/s]Loading train:  90%|████████▉ | 256/285 [03:34<00:20,  1.41it/s]Loading train:  90%|█████████ | 257/285 [03:35<00:19,  1.44it/s]Loading train:  91%|█████████ | 258/285 [03:35<00:18,  1.45it/s]Loading train:  91%|█████████ | 259/285 [03:36<00:17,  1.46it/s]Loading train:  91%|█████████ | 260/285 [03:37<00:17,  1.44it/s]Loading train:  92%|█████████▏| 261/285 [03:37<00:16,  1.46it/s]Loading train:  92%|█████████▏| 262/285 [03:38<00:16,  1.43it/s]Loading train:  92%|█████████▏| 263/285 [03:39<00:15,  1.39it/s]Loading train:  93%|█████████▎| 264/285 [03:39<00:14,  1.42it/s]Loading train:  93%|█████████▎| 265/285 [03:40<00:13,  1.43it/s]Loading train:  93%|█████████▎| 266/285 [03:41<00:13,  1.42it/s]Loading train:  94%|█████████▎| 267/285 [03:42<00:12,  1.45it/s]Loading train:  94%|█████████▍| 268/285 [03:42<00:12,  1.32it/s]Loading train:  94%|█████████▍| 269/285 [03:43<00:12,  1.28it/s]Loading train:  95%|█████████▍| 270/285 [03:44<00:11,  1.26it/s]Loading train:  95%|█████████▌| 271/285 [03:45<00:11,  1.18it/s]Loading train:  95%|█████████▌| 272/285 [03:46<00:11,  1.15it/s]Loading train:  96%|█████████▌| 273/285 [03:47<00:10,  1.14it/s]Loading train:  96%|█████████▌| 274/285 [03:48<00:09,  1.13it/s]Loading train:  96%|█████████▋| 275/285 [03:49<00:08,  1.11it/s]Loading train:  97%|█████████▋| 276/285 [03:50<00:08,  1.11it/s]Loading train:  97%|█████████▋| 277/285 [03:51<00:07,  1.09it/s]Loading train:  98%|█████████▊| 278/285 [03:52<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [03:52<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [03:53<00:04,  1.11it/s]Loading train:  99%|█████████▊| 281/285 [03:54<00:03,  1.13it/s]Loading train:  99%|█████████▉| 282/285 [03:55<00:02,  1.14it/s]Loading train:  99%|█████████▉| 283/285 [03:56<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [03:57<00:00,  1.13it/s]Loading train: 100%|██████████| 285/285 [03:58<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:00, 319.45it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:00, 274.84it/s]concatenating: train:  25%|██▍       | 71/285 [00:00<00:00, 237.03it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:00, 249.29it/s]concatenating: train:  45%|████▌     | 129/285 [00:00<00:00, 259.48it/s]concatenating: train:  56%|█████▌    | 159/285 [00:00<00:00, 267.88it/s]concatenating: train:  67%|██████▋   | 192/285 [00:00<00:00, 283.37it/s]concatenating: train:  78%|███████▊  | 222/285 [00:00<00:00, 286.70it/s]concatenating: train:  89%|████████▉ | 253/285 [00:00<00:00, 292.67it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 298.79it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.21s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 186.10it/s] 11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________2019-07-07 05:55:51.260916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 05:55:51.261021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 05:55:51.261036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 05:55:51.261046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 05:55:51.261456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 23s - loss: 14372.7842 - acc: 0.8448 - mDice: 0.1664 - val_loss: 6130.5326 - val_acc: 0.8798 - val_mDice: 0.2821

Epoch 00001: val_mDice improved from -inf to 0.28206, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 5476.3305 - acc: 0.8653 - mDice: 0.3428 - val_loss: 4694.0142 - val_acc: 0.9022 - val_mDice: 0.3728

Epoch 00002: val_mDice improved from 0.28206 to 0.37280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 4215.3463 - acc: 0.8838 - mDice: 0.4313 - val_loss: 3872.1978 - val_acc: 0.9190 - val_mDice: 0.4367

Epoch 00003: val_mDice improved from 0.37280 to 0.43672, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 3508.0512 - acc: 0.8984 - mDice: 0.4929 - val_loss: 3496.0254 - val_acc: 0.9269 - val_mDice: 0.4693

Epoch 00004: val_mDice improved from 0.43672 to 0.46927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 13s - loss: 3090.4308 - acc: 0.9081 - mDice: 0.5346 - val_loss: 3222.9522 - val_acc: 0.9307 - val_mDice: 0.4953

Epoch 00005: val_mDice improved from 0.46927 to 0.49531, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 13s - loss: 2805.2622 - acc: 0.9147 - mDice: 0.5658 - val_loss: 3014.5822 - val_acc: 0.9333 - val_mDice: 0.5160

Epoch 00006: val_mDice improved from 0.49531 to 0.51596, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 13s - loss: 2593.6344 - acc: 0.9194 - mDice: 0.5905 - val_loss: 2896.5492 - val_acc: 0.9349 - val_mDice: 0.5278

Epoch 00007: val_mDice improved from 0.51596 to 0.52782, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 2441.3098 - acc: 0.9231 - mDice: 0.6090 - val_loss: 2866.1715 - val_acc: 0.9368 - val_mDice: 0.5303

Epoch 00008: val_mDice improved from 0.52782 to 0.53027, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 13s - loss: 2316.7440 - acc: 0.9260 - mDice: 0.6245 - val_loss: 2793.4471 - val_acc: 0.9379 - val_mDice: 0.5391

Epoch 00009: val_mDice improved from 0.53027 to 0.53906, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 13s - loss: 2214.3801 - acc: 0.9286 - mDice: 0.6376 - val_loss: 2731.6619 - val_acc: 0.9388 - val_mDice: 0.5451

Epoch 00010: val_mDice improved from 0.53906 to 0.54506, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 13s - loss: 2118.6382 - acc: 0.9308 - mDice: 0.6501 - val_loss: 2738.9454 - val_acc: 0.9408 - val_mDice: 0.5438

Epoch 00011: val_mDice did not improve from 0.54506
Epoch 12/300
 - 13s - loss: 2037.5952 - acc: 0.9327 - mDice: 0.6609 - val_loss: 2674.3463 - val_acc: 0.9400 - val_mDice: 0.5518

Epoch 00012: val_mDice improved from 0.54506 to 0.55181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 14s - loss: 1973.9757 - acc: 0.9342 - mDice: 0.6693 - val_loss: 2757.5329 - val_acc: 0.9414 - val_mDice: 0.5409

Epoch 00013: val_mDice did not improve from 0.55181
Epoch 14/300
 - 13s - loss: 1919.6954 - acc: 0.9357 - mDice: 0.6767 - val_loss: 2592.3195 - val_acc: 0.9414 - val_mDice: 0.5602

Epoch 00014: val_mDice improved from 0.55181 to 0.56020, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 13s - loss: 1856.9670 - acc: 0.9368 - mDice: 0.6852 - val_loss: 2611.8389 - val_acc: 0.9421 - val_mDice: 0.5579

Epoch 00015: val_mDice did not improve from 0.56020
Epoch 16/300
 - 13s - loss: 1789.3924 - acc: 0.9380 - mDice: 0.6945 - val_loss: 2700.2362 - val_acc: 0.9422 - val_mDice: 0.5478

Epoch 00016: val_mDice did not improve from 0.56020
Epoch 17/300
 - 13s - loss: 1747.4653 - acc: 0.9390 - mDice: 0.7005 - val_loss: 2727.2561 - val_acc: 0.9433 - val_mDice: 0.5465

Epoch 00017: val_mDice did not improve from 0.56020
Epoch 18/300
 - 13s - loss: 1700.9251 - acc: 0.9402 - mDice: 0.7071 - val_loss: 2692.5296 - val_acc: 0.9446 - val_mDice: 0.5499

Epoch 00018: val_mDice did not improve from 0.56020
Epoch 19/300
 - 14s - loss: 1670.0684 - acc: 0.9408 - mDice: 0.7115 - val_loss: 2665.3193 - val_acc: 0.9447 - val_mDice: 0.5532

Epoch 00019: val_mDice did not improve from 0.56020
Epoch 20/300
 - 14s - loss: 1625.4844 - acc: 0.9417 - mDice: 0.7179 - val_loss: 2876.4996 - val_acc: 0.9407 - val_mDice: 0.5282

Epoch 00020: val_mDice did not improve from 0.56020
Epoch 21/300
 - 13s - loss: 1583.3570 - acc: 0.9426 - mDice: 0.7240 - val_loss: 2798.7012 - val_acc: 0.9398 - val_mDice: 0.5381

Epoch 00021: val_mDice did not improve from 0.56020
Epoch 22/300
 - 13s - loss: 1551.6234 - acc: 0.9431 - mDice: 0.7287 - val_loss: 2795.0823 - val_acc: 0.9450 - val_mDice: 0.5369

Epoch 00022: val_mDice did not improve from 0.56020
Epoch 23/300
 - 13s - loss: 1513.3802 - acc: 0.9439 - mDice: 0.7343 - val_loss: 2694.1120 - val_acc: 0.9421 - val_mDice: 0.5506

Epoch 00023: val_mDice did not improve from 0.56020
Epoch 24/300
 - 13s - loss: 1487.8486 - acc: 0.9445 - mDice: 0.7379 - val_loss: 2802.2559 - val_acc: 0.9434 - val_mDice: 0.5373

Epoch 00024: val_mDice did not improve from 0.56020
Epoch 25/300
 - 14s - loss: 1454.0092 - acc: 0.9452 - mDice: 0.7431 - val_loss: 2703.5610 - val_acc: 0.9467 - val_mDice: 0.5475

Epoch 00025: val_mDice did not improve from 0.56020
Epoch 26/300
 - 14s - loss: 1432.5149 - acc: 0.9457 - mDice: 0.7464 - val_loss: 2759.6656 - val_acc: 0.9423 - val_mDice: 0.5415

Epoch 00026: val_mDice did not improve from 0.56020
Epoch 27/300
 - 14s - loss: 1405.4753 - acc: 0.9463 - mDice: 0.7504 - val_loss: 2692.8480 - val_acc: 0.9442 - val_mDice: 0.5511

Epoch 00027: val_mDice did not improve from 0.56020
Epoch 28/300
 - 13s - loss: 1379.7815 - acc: 0.9469 - mDice: 0.7543 - val_loss: 2965.0169 - val_acc: 0.9411 - val_mDice: 0.5186

Epoch 00028: val_mDice did not improve from 0.56020
Epoch 29/300
 - 13s - loss: 1355.3128 - acc: 0.9473 - mDice: 0.7580 - val_loss: 2889.3865 - val_acc: 0.9416 - val_mDice: 0.5276

Epoch 00029: val_mDice did not improve from 0.56020
Epoch 30/300
 - 13s - loss: 1333.9418 - acc: 0.9477 - mDice: 0.7613 - val_loss: 2929.9001 - val_acc: 0.9432 - val_mDice: 0.5236

Epoch 00030: val_mDice did not improve from 0.56020
Epoch 31/300
 - 13s - loss: 1323.8407 - acc: 0.9481 - mDice: 0.7629 - val_loss: 2848.0177 - val_acc: 0.9409 - val_mDice: 0.5307

Epoch 00031: val_mDice did not improve from 0.56020
Epoch 32/300
 - 13s - loss: 1293.8125 - acc: 0.9487 - mDice: 0.7675 - val_loss: 2695.0216 - val_acc: 0.9459 - val_mDice: 0.5494

Epoch 00032: val_mDice did not improve from 0.56020
Epoch 33/300
 - 13s - loss: 1273.9612 - acc: 0.9490 - mDice: 0.7705 - val_loss: 2818.0033 - val_acc: 0.9437 - val_mDice: 0.5366

Epoch 00033: val_mDice did not improve from 0.56020
Epoch 34/300
 - 14s - loss: 1258.0625 - acc: 0.9493 - mDice: 0.7730 - val_loss: 2861.5330 - val_acc: 0.9462 - val_mDice: 0.5321

Epoch 00034: val_mDice did not improve from 0.56020
Epoch 35/300
 - 14s - loss: 1238.6802 - acc: 0.9497 - mDice: 0.7761 - val_loss: 2670.0235 - val_acc: 0.9464 - val_mDice: 0.5531

Epoch 00035: val_mDice did not improve from 0.56020
Epoch 36/300
 - 14s - loss: 1224.7871 - acc: 0.9500 - mDice: 0.7783 - val_loss: 3084.4864 - val_acc: 0.9367 - val_mDice: 0.5078

Epoch 00036: val_mDice did not improve from 0.56020
Epoch 37/300
 - 14s - loss: 1195.8148 - acc: 0.9506 - mDice: 0.7829 - val_loss: 2904.4088 - val_acc: 0.9440 - val_mDice: 0.5283

Epoch 00037: val_mDice did not improve from 0.56020
Epoch 38/300
 - 14s - loss: 1185.5240 - acc: 0.9508 - mDice: 0.7845 - val_loss: 2835.4048 - val_acc: 0.9442 - val_mDice: 0.5357

Epoch 00038: val_mDice did not improve from 0.56020
Epoch 39/300
 - 14s - loss: 1167.0075 - acc: 0.9512 - mDice: 0.7874 - val_loss: 2724.4802 - val_acc: 0.9418 - val_mDice: 0.5453

Epoch 00039: val_mDice did not improve from 0.56020
Epoch 40/300
 - 14s - loss: 1156.6052 - acc: 0.9514 - mDice: 0.7891 - val_loss: 2645.3117 - val_acc: 0.9478 - val_mDice: 0.5562

Epoch 00040: val_mDice did not improve from 0.56020
Epoch 41/300
 - 14s - loss: 1145.9939 - acc: 0.9517 - mDice: 0.7908 - val_loss: 2818.5483 - val_acc: 0.9469 - val_mDice: 0.5356

Epoch 00041: val_mDice did not improve from 0.56020
Epoch 42/300
 - 14s - loss: 1128.5044 - acc: 0.9521 - mDice: 0.7936 - val_loss: 2969.6072 - val_acc: 0.9458 - val_mDice: 0.5201

Epoch 00042: val_mDice did not improve from 0.56020
Epoch 43/300
 - 14s - loss: 1111.1635 - acc: 0.9524 - mDice: 0.7963 - val_loss: 2741.1824 - val_acc: 0.9448 - val_mDice: 0.5440

Epoch 00043: val_mDice did not improve from 0.56020
Epoch 44/300
 - 14s - loss: 1099.4677 - acc: 0.9527 - mDice: 0.7982 - val_loss: 2867.0531 - val_acc: 0.9453 - val_mDice: 0.5308

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:26,  1.36s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:50,  1.45s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:51,  1.46s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:21,  1.57s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:06,  1.52s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:39,  1.65s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:24,  1.82s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:13,  1.79s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:24,  1.84s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:37,  1.89s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:48,  1.93s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:55,  1.97s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:55,  1.98s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:58,  2.00s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:45,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:42,  1.95s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:51,  1.99s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:44,  1.98s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:35,  1.95s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:26,  1.93s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:27,  1.94s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:28,  1.95s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:38,  2.00s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:38,  2.00s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:33,  1.99s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:29,  1.98s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:13,  1.93s/it]predicting train subjects:  11%|█         | 30/285 [00:56<07:59,  1.88s/it]predicting train subjects:  11%|█         | 31/285 [00:58<07:51,  1.86s/it]predicting train subjects:  11%|█         | 32/285 [01:00<07:51,  1.86s/it]predicting train subjects:  12%|█▏        | 33/285 [01:02<07:45,  1.85s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:37,  1.82s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<07:37,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:34,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:39,  1.85s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:34,  1.84s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:36,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:29,  1.84s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:26,  1.83s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:27,  1.84s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:27,  1.85s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:31,  1.87s/it]predicting train subjects:  16%|█▌        | 45/285 [01:24<07:27,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:04,  1.78s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<06:44,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<06:29,  1.64s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<06:21,  1.62s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<06:27,  1.65s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<06:21,  1.63s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<06:23,  1.65s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<06:21,  1.64s/it]predicting train subjects:  19%|█▉        | 54/285 [01:38<06:19,  1.64s/it]predicting train subjects:  19%|█▉        | 55/285 [01:40<06:14,  1.63s/it]predicting train subjects:  20%|█▉        | 56/285 [01:41<06:10,  1.62s/it]predicting train subjects:  20%|██        | 57/285 [01:43<06:07,  1.61s/it]predicting train subjects:  20%|██        | 58/285 [01:45<06:10,  1.63s/it]predicting train subjects:  21%|██        | 59/285 [01:46<05:58,  1.59s/it]predicting train subjects:  21%|██        | 60/285 [01:48<05:54,  1.58s/it]predicting train subjects:  21%|██▏       | 61/285 [01:49<05:55,  1.59s/it]predicting train subjects:  22%|██▏       | 62/285 [01:51<05:57,  1.60s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<05:51,  1.58s/it]predicting train subjects:  22%|██▏       | 64/285 [01:54<05:59,  1.63s/it]predicting train subjects:  23%|██▎       | 65/285 [01:56<06:14,  1.70s/it]predicting train subjects:  23%|██▎       | 66/285 [01:58<06:19,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [02:00<06:17,  1.73s/it]predicting train subjects:  24%|██▍       | 68/285 [02:01<06:13,  1.72s/it]predicting train subjects:  24%|██▍       | 69/285 [02:03<06:06,  1.70s/it]predicting train subjects:  25%|██▍       | 70/285 [02:05<06:01,  1.68s/it]predicting train subjects:  25%|██▍       | 71/285 [02:06<06:02,  1.69s/it]predicting train subjects:  25%|██▌       | 72/285 [02:08<06:03,  1.71s/it]predicting train subjects:  26%|██▌       | 73/285 [02:10<06:00,  1.70s/it]predicting train subjects:  26%|██▌       | 74/285 [02:11<05:56,  1.69s/it]predicting train subjects:  26%|██▋       | 75/285 [02:13<05:53,  1.68s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<05:51,  1.68s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<05:48,  1.67s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<05:42,  1.66s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<05:37,  1.64s/it]predicting train subjects:  28%|██▊       | 80/285 [02:21<05:35,  1.64s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:33,  1.64s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:33,  1.64s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:34,  1.66s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:32,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:45,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:48,  1.75s/it]predicting train subjects:  31%|███       | 87/285 [02:34<05:58,  1.81s/it]predicting train subjects:  31%|███       | 88/285 [02:35<06:02,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:37<06:03,  1.86s/it]predicting train subjects:  32%|███▏      | 90/285 [02:39<05:59,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:41<06:03,  1.87s/it]predicting train subjects:  32%|███▏      | 92/285 [02:43<06:11,  1.92s/it]predicting train subjects:  33%|███▎      | 93/285 [02:45<06:11,  1.93s/it]predicting train subjects:  33%|███▎      | 94/285 [02:47<06:06,  1.92s/it]predicting train subjects:  33%|███▎      | 95/285 [02:49<06:03,  1.91s/it]predicting train subjects:  34%|███▎      | 96/285 [02:51<06:02,  1.92s/it]predicting train subjects:  34%|███▍      | 97/285 [02:53<06:00,  1.92s/it]predicting train subjects:  34%|███▍      | 98/285 [02:55<05:53,  1.89s/it]predicting train subjects:  35%|███▍      | 99/285 [02:56<05:50,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [02:58<05:48,  1.88s/it]predicting train subjects:  35%|███▌      | 101/285 [03:00<05:47,  1.89s/it]predicting train subjects:  36%|███▌      | 102/285 [03:02<05:46,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:04<05:40,  1.87s/it]predicting train subjects:  36%|███▋      | 104/285 [03:06<05:32,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:07<05:26,  1.81s/it]predicting train subjects:  37%|███▋      | 106/285 [03:09<05:25,  1.82s/it]predicting train subjects:  38%|███▊      | 107/285 [03:11<05:24,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:13<05:21,  1.81s/it]predicting train subjects:  38%|███▊      | 109/285 [03:15<05:19,  1.81s/it]predicting train subjects:  39%|███▊      | 110/285 [03:16<05:15,  1.80s/it]predicting train subjects:  39%|███▉      | 111/285 [03:18<05:14,  1.81s/it]predicting train subjects:  39%|███▉      | 112/285 [03:20<05:11,  1.80s/it]predicting train subjects:  40%|███▉      | 113/285 [03:22<05:12,  1.82s/it]predicting train subjects:  40%|████      | 114/285 [03:24<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:26<05:12,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:28<05:14,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:29<05:08,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:31<05:07,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [03:33<05:04,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:35<05:03,  1.84s/it]predicting train subjects:  42%|████▏     | 121/285 [03:36<04:48,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [03:38<04:34,  1.69s/it]predicting train subjects:  43%|████▎     | 123/285 [03:39<04:21,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:41<04:20,  1.62s/it]predicting train subjects:  44%|████▍     | 125/285 [03:43<04:20,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:44<04:19,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:46<04:20,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [03:48<04:20,  1.66s/it]predicting train subjects:  45%|████▌     | 129/285 [03:49<04:19,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [03:51<04:18,  1.67s/it]predicting train subjects:  46%|████▌     | 131/285 [03:53<04:17,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [03:54<04:15,  1.67s/it]predicting train subjects:  47%|████▋     | 133/285 [03:56<04:13,  1.66s/it]predicting train subjects:  47%|████▋     | 134/285 [03:58<04:10,  1.66s/it]predicting train subjects:  47%|████▋     | 135/285 [03:59<04:12,  1.68s/it]predicting train subjects:  48%|████▊     | 136/285 [04:01<04:06,  1.66s/it]predicting train subjects:  48%|████▊     | 137/285 [04:03<04:01,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:04<04:01,  1.64s/it]predicting train subjects:  49%|████▉     | 139/285 [04:06<04:01,  1.65s/it]predicting train subjects:  49%|████▉     | 140/285 [04:08<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:09<03:56,  1.64s/it]predicting train subjects:  50%|████▉     | 142/285 [04:11<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:12<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:14<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:15<03:35,  1.54s/it]predicting train subjects:  51%|█████     | 146/285 [04:17<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:18<03:27,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:20<03:23,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:21<03:20,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:23<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:24<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:26<03:19,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:27<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:29<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:30<03:11,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:31<03:10,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:33<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:34<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:36<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:37<03:03,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:39<03:00,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:40<02:59,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:42<03:00,  1.48s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:43<02:57,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:45<02:54,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:46<02:55,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:48<02:52,  1.46s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:49<02:50,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:50<02:48,  1.46s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:52<02:47,  1.46s/it]predicting train subjects:  60%|██████    | 171/285 [04:53<02:44,  1.44s/it]predicting train subjects:  60%|██████    | 172/285 [04:55<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:56<02:38,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [04:58<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:59<02:33,  1.39s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:00<02:34,  1.41s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:02<02:32,  1.41s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:03<02:29,  1.40s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:05<02:29,  1.41s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:06<02:27,  1.40s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:07<02:25,  1.40s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:09<02:25,  1.41s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:10<02:22,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:12<02:25,  1.44s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:13<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:14<02:17,  1.39s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:16<02:18,  1.41s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:17<02:16,  1.41s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:19<02:14,  1.41s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:20<02:13,  1.41s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:21<02:11,  1.40s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:23<02:10,  1.40s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:24<02:10,  1.42s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:26<02:09,  1.42s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:27<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:29<02:12,  1.49s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:30<02:18,  1.57s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:32<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:34<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:35<02:17,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [05:37<02:16,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:39<02:15,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:40<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:42<02:12,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:44<02:13,  1.67s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:45<02:12,  1.68s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:47<02:11,  1.68s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:49<02:10,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:51<02:09,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:52<02:06,  1.69s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:54<02:03,  1.67s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:56<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:57<02:01,  1.69s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:59<01:56,  1.64s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:00<01:50,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:02<01:47,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:03<01:44,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:05<01:42,  1.53s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:06<01:39,  1.51s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:08<01:37,  1.50s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:09<01:35,  1.50s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:11<01:34,  1.51s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:12<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:14<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:15<01:29,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:17<01:27,  1.48s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:18<01:26,  1.50s/it]predicting train subjects:  80%|████████  | 228/285 [06:20<01:25,  1.51s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:23,  1.49s/it]predicting train subjects:  81%|████████  | 230/285 [06:23<01:21,  1.48s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:19,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:26<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:28<01:26,  1.67s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:30<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:27,  1.75s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:27,  1.78s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:27,  1.81s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:37<01:25,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:39<01:25,  1.86s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:41<01:24,  1.87s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:43<01:23,  1.89s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:45<01:22,  1.92s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:47<01:20,  1.91s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:48<01:16,  1.87s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:50<01:16,  1.91s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:52<01:13,  1.89s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:54<01:10,  1.86s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:56<01:08,  1.86s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:58<01:06,  1.85s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:59<01:00,  1.73s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:01<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:02<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:04<00:49,  1.54s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:05<00:46,  1.52s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:06<00:44,  1.49s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:08<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [07:09<00:40,  1.44s/it]predicting train subjects:  91%|█████████ | 258/285 [07:11<00:39,  1.45s/it]predicting train subjects:  91%|█████████ | 259/285 [07:12<00:36,  1.42s/it]predicting train subjects:  91%|█████████ | 260/285 [07:14<00:35,  1.43s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:15<00:34,  1.42s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:16<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:18<00:30,  1.40s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:19<00:29,  1.39s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:20<00:27,  1.39s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:22<00:26,  1.38s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:23<00:24,  1.37s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:25<00:26,  1.56s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:27<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:29<00:25,  1.70s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:31<00:24,  1.74s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:33<00:23,  1.79s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:34<00:21,  1.82s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:36<00:20,  1.84s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:38<00:18,  1.88s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:40<00:16,  1.88s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:42<00:15,  1.88s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:44<00:13,  1.86s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:46<00:11,  1.86s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:48<00:09,  1.87s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:50<00:07,  1.87s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:51<00:05,  1.88s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:53<00:03,  1.88s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:55<00:01,  1.90s/it]predicting train subjects: 100%|██████████| 285/285 [07:57<00:00,  1.89s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:27,  1.36s/it]Loading train:   1%|          | 2/285 [00:02<06:45,  1.43s/it]Loading train:   1%|          | 3/285 [00:04<06:31,  1.39s/it]Loading train:   1%|▏         | 4/285 [00:05<06:47,  1.45s/it]Loading train:   2%|▏         | 5/285 [00:07<06:26,  1.38s/it]Loading train:   2%|▏         | 6/285 [00:08<06:48,  1.47s/it]Loading train:   2%|▏         | 7/285 [00:10<07:22,  1.59s/it]Loading train:   3%|▎         | 8/285 [00:12<07:24,  1.60s/it]Loading train:   3%|▎         | 9/285 [00:13<06:56,  1.51s/it]Loading train:   4%|▎         | 10/285 [00:14<06:27,  1.41s/it]Loading train:   4%|▍         | 11/285 [00:15<06:05,  1.33s/it]Loading train:   4%|▍         | 12/285 [00:17<05:53,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:18<05:38,  1.24s/it]Loading train:   5%|▍         | 14/285 [00:19<05:32,  1.23s/it]Loading train:   5%|▌         | 15/285 [00:20<05:26,  1.21s/it]Loading train:   6%|▌         | 16/285 [00:21<05:20,  1.19s/it]Loading train:   6%|▌         | 17/285 [00:22<05:17,  1.19s/it]Loading train:   6%|▋         | 18/285 [00:24<05:18,  1.19s/it]Loading train:   7%|▋         | 19/285 [00:25<05:12,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:26<05:07,  1.16s/it]Loading train:   7%|▋         | 21/285 [00:27<05:07,  1.16s/it]Loading train:   8%|▊         | 22/285 [00:28<04:56,  1.13s/it]Loading train:   8%|▊         | 23/285 [00:29<05:00,  1.15s/it]Loading train:   8%|▊         | 24/285 [00:30<05:01,  1.15s/it]Loading train:   9%|▉         | 25/285 [00:32<04:59,  1.15s/it]Loading train:   9%|▉         | 26/285 [00:33<05:00,  1.16s/it]Loading train:   9%|▉         | 27/285 [00:34<05:05,  1.18s/it]Loading train:  10%|▉         | 28/285 [00:35<04:57,  1.16s/it]Loading train:  10%|█         | 29/285 [00:36<04:46,  1.12s/it]Loading train:  11%|█         | 30/285 [00:37<04:34,  1.08s/it]Loading train:  11%|█         | 31/285 [00:38<04:36,  1.09s/it]Loading train:  11%|█         | 32/285 [00:39<04:31,  1.07s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:30,  1.07s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:26,  1.06s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:21,  1.05s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:18,  1.04s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:13,  1.02s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:09,  1.01s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:18,  1.05s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:18,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:18,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:19,  1.07s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:20,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:21,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:16,  1.07s/it]Loading train:  16%|█▌        | 46/285 [00:54<04:09,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:55<03:59,  1.01s/it]Loading train:  17%|█▋        | 48/285 [00:56<03:51,  1.03it/s]Loading train:  17%|█▋        | 49/285 [00:57<03:42,  1.06it/s]Loading train:  18%|█▊        | 50/285 [00:58<03:37,  1.08it/s]Loading train:  18%|█▊        | 51/285 [00:58<03:37,  1.07it/s]Loading train:  18%|█▊        | 52/285 [00:59<03:38,  1.07it/s]Loading train:  19%|█▊        | 53/285 [01:00<03:38,  1.06it/s]Loading train:  19%|█▉        | 54/285 [01:01<03:32,  1.09it/s]Loading train:  19%|█▉        | 55/285 [01:02<03:34,  1.07it/s]Loading train:  20%|█▉        | 56/285 [01:03<03:32,  1.08it/s]Loading train:  20%|██        | 57/285 [01:04<03:38,  1.04it/s]Loading train:  20%|██        | 58/285 [01:05<03:38,  1.04it/s]Loading train:  21%|██        | 59/285 [01:06<03:40,  1.02it/s]Loading train:  21%|██        | 60/285 [01:07<03:34,  1.05it/s]Loading train:  21%|██▏       | 61/285 [01:08<03:33,  1.05it/s]Loading train:  22%|██▏       | 62/285 [01:09<03:27,  1.07it/s]Loading train:  22%|██▏       | 63/285 [01:10<03:25,  1.08it/s]Loading train:  22%|██▏       | 64/285 [01:11<04:02,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:13<04:37,  1.26s/it]Loading train:  23%|██▎       | 66/285 [01:14<04:52,  1.33s/it]Loading train:  24%|██▎       | 67/285 [01:15<04:20,  1.20s/it]Loading train:  24%|██▍       | 68/285 [01:16<03:59,  1.10s/it]Loading train:  24%|██▍       | 69/285 [01:17<03:43,  1.03s/it]Loading train:  25%|██▍       | 70/285 [01:18<03:31,  1.02it/s]Loading train:  25%|██▍       | 71/285 [01:19<03:27,  1.03it/s]Loading train:  25%|██▌       | 72/285 [01:20<03:23,  1.04it/s]Loading train:  26%|██▌       | 73/285 [01:21<03:21,  1.05it/s]Loading train:  26%|██▌       | 74/285 [01:22<03:27,  1.01it/s]Loading train:  26%|██▋       | 75/285 [01:23<03:20,  1.05it/s]Loading train:  27%|██▋       | 76/285 [01:24<03:23,  1.03it/s]Loading train:  27%|██▋       | 77/285 [01:25<03:22,  1.03it/s]Loading train:  27%|██▋       | 78/285 [01:26<03:21,  1.03it/s]Loading train:  28%|██▊       | 79/285 [01:27<03:20,  1.03it/s]Loading train:  28%|██▊       | 80/285 [01:28<03:16,  1.04it/s]Loading train:  28%|██▊       | 81/285 [01:28<03:12,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:29<03:13,  1.05it/s]Loading train:  29%|██▉       | 83/285 [01:30<03:15,  1.03it/s]Loading train:  29%|██▉       | 84/285 [01:31<03:14,  1.03it/s]Loading train:  30%|██▉       | 85/285 [01:32<03:19,  1.00it/s]Loading train:  30%|███       | 86/285 [01:34<03:23,  1.02s/it]Loading train:  31%|███       | 87/285 [01:35<03:24,  1.04s/it]Loading train:  31%|███       | 88/285 [01:36<03:25,  1.04s/it]Loading train:  31%|███       | 89/285 [01:37<03:21,  1.03s/it]Loading train:  32%|███▏      | 90/285 [01:38<03:20,  1.03s/it]Loading train:  32%|███▏      | 91/285 [01:39<03:17,  1.02s/it]Loading train:  32%|███▏      | 92/285 [01:40<03:17,  1.02s/it]Loading train:  33%|███▎      | 93/285 [01:41<03:17,  1.03s/it]Loading train:  33%|███▎      | 94/285 [01:42<03:21,  1.06s/it]Loading train:  33%|███▎      | 95/285 [01:43<03:17,  1.04s/it]Loading train:  34%|███▎      | 96/285 [01:44<03:17,  1.04s/it]Loading train:  34%|███▍      | 97/285 [01:45<03:22,  1.08s/it]Loading train:  34%|███▍      | 98/285 [01:46<03:21,  1.08s/it]Loading train:  35%|███▍      | 99/285 [01:47<03:15,  1.05s/it]Loading train:  35%|███▌      | 100/285 [01:48<03:09,  1.02s/it]Loading train:  35%|███▌      | 101/285 [01:49<03:09,  1.03s/it]Loading train:  36%|███▌      | 102/285 [01:50<03:08,  1.03s/it]Loading train:  36%|███▌      | 103/285 [01:51<03:08,  1.04s/it]Loading train:  36%|███▋      | 104/285 [01:52<03:07,  1.04s/it]Loading train:  37%|███▋      | 105/285 [01:53<03:01,  1.01s/it]Loading train:  37%|███▋      | 106/285 [01:54<02:55,  1.02it/s]Loading train:  38%|███▊      | 107/285 [01:55<02:57,  1.00it/s]Loading train:  38%|███▊      | 108/285 [01:56<03:00,  1.02s/it]Loading train:  38%|███▊      | 109/285 [01:57<02:58,  1.01s/it]Loading train:  39%|███▊      | 110/285 [01:58<02:57,  1.01s/it]Loading train:  39%|███▉      | 111/285 [01:59<02:56,  1.02s/it]Loading train:  39%|███▉      | 112/285 [02:00<02:57,  1.02s/it]Loading train:  40%|███▉      | 113/285 [02:01<03:02,  1.06s/it]Loading train:  40%|████      | 114/285 [02:03<03:04,  1.08s/it]Loading train:  40%|████      | 115/285 [02:04<03:04,  1.09s/it]Loading train:  41%|████      | 116/285 [02:05<03:01,  1.07s/it]Loading train:  41%|████      | 117/285 [02:06<03:03,  1.09s/it]Loading train:  41%|████▏     | 118/285 [02:07<03:02,  1.09s/it]Loading train:  42%|████▏     | 119/285 [02:08<02:59,  1.08s/it]Loading train:  42%|████▏     | 120/285 [02:09<02:56,  1.07s/it]Loading train:  42%|████▏     | 121/285 [02:10<03:08,  1.15s/it]Loading train:  43%|████▎     | 122/285 [02:12<03:10,  1.17s/it]Loading train:  43%|████▎     | 123/285 [02:13<03:14,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:14<03:04,  1.14s/it]Loading train:  44%|████▍     | 125/285 [02:15<02:54,  1.09s/it]Loading train:  44%|████▍     | 126/285 [02:16<02:50,  1.07s/it]Loading train:  45%|████▍     | 127/285 [02:17<02:37,  1.00it/s]Loading train:  45%|████▍     | 128/285 [02:18<02:32,  1.03it/s]Loading train:  45%|████▌     | 129/285 [02:19<02:33,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:20<02:31,  1.03it/s]Loading train:  46%|████▌     | 131/285 [02:20<02:27,  1.04it/s]Loading train:  46%|████▋     | 132/285 [02:21<02:26,  1.05it/s]Loading train:  47%|████▋     | 133/285 [02:22<02:27,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:23<02:28,  1.01it/s]Loading train:  47%|████▋     | 135/285 [02:24<02:26,  1.02it/s]Loading train:  48%|████▊     | 136/285 [02:25<02:24,  1.03it/s]Loading train:  48%|████▊     | 137/285 [02:26<02:18,  1.06it/s]Loading train:  48%|████▊     | 138/285 [02:27<02:17,  1.07it/s]Loading train:  49%|████▉     | 139/285 [02:28<02:13,  1.09it/s]Loading train:  49%|████▉     | 140/285 [02:29<02:15,  1.07it/s]Loading train:  49%|████▉     | 141/285 [02:30<02:13,  1.08it/s]Loading train:  50%|████▉     | 142/285 [02:31<02:13,  1.07it/s]Loading train:  50%|█████     | 143/285 [02:32<02:09,  1.09it/s]Loading train:  51%|█████     | 144/285 [02:33<02:11,  1.07it/s]Loading train:  51%|█████     | 145/285 [02:34<02:09,  1.08it/s]Loading train:  51%|█████     | 146/285 [02:35<02:07,  1.09it/s]Loading train:  52%|█████▏    | 147/285 [02:35<02:02,  1.12it/s]Loading train:  52%|█████▏    | 148/285 [02:36<02:05,  1.09it/s]Loading train:  52%|█████▏    | 149/285 [02:37<02:06,  1.07it/s]Loading train:  53%|█████▎    | 150/285 [02:38<02:03,  1.09it/s]Loading train:  53%|█████▎    | 151/285 [02:39<01:59,  1.13it/s]Loading train:  53%|█████▎    | 152/285 [02:40<01:55,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [02:41<01:57,  1.12it/s]Loading train:  54%|█████▍    | 154/285 [02:42<01:56,  1.12it/s]Loading train:  54%|█████▍    | 155/285 [02:43<01:55,  1.13it/s]Loading train:  55%|█████▍    | 156/285 [02:43<01:55,  1.11it/s]Loading train:  55%|█████▌    | 157/285 [02:44<01:50,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:45<01:46,  1.19it/s]Loading train:  56%|█████▌    | 159/285 [02:46<01:44,  1.20it/s]Loading train:  56%|█████▌    | 160/285 [02:47<01:45,  1.19it/s]Loading train:  56%|█████▋    | 161/285 [02:48<01:45,  1.17it/s]Loading train:  57%|█████▋    | 162/285 [02:48<01:46,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:49<01:46,  1.15it/s]Loading train:  58%|█████▊    | 164/285 [02:50<01:44,  1.16it/s]Loading train:  58%|█████▊    | 165/285 [02:51<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [02:52<01:41,  1.17it/s]Loading train:  59%|█████▊    | 167/285 [02:53<01:43,  1.14it/s]Loading train:  59%|█████▉    | 168/285 [02:54<01:41,  1.15it/s]Loading train:  59%|█████▉    | 169/285 [02:55<01:41,  1.14it/s]Loading train:  60%|█████▉    | 170/285 [02:55<01:41,  1.13it/s]Loading train:  60%|██████    | 171/285 [02:56<01:39,  1.14it/s]Loading train:  60%|██████    | 172/285 [02:57<01:39,  1.14it/s]Loading train:  61%|██████    | 173/285 [02:58<01:37,  1.15it/s]Loading train:  61%|██████    | 174/285 [02:59<01:35,  1.17it/s]Loading train:  61%|██████▏   | 175/285 [03:00<01:32,  1.19it/s]Loading train:  62%|██████▏   | 176/285 [03:01<01:32,  1.18it/s]Loading train:  62%|██████▏   | 177/285 [03:01<01:31,  1.18it/s]Loading train:  62%|██████▏   | 178/285 [03:02<01:32,  1.16it/s]Loading train:  63%|██████▎   | 179/285 [03:03<01:32,  1.15it/s]Loading train:  63%|██████▎   | 180/285 [03:04<01:29,  1.17it/s]Loading train:  64%|██████▎   | 181/285 [03:05<01:28,  1.18it/s]Loading train:  64%|██████▍   | 182/285 [03:06<01:27,  1.18it/s]Loading train:  64%|██████▍   | 183/285 [03:07<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [03:07<01:25,  1.18it/s]Loading train:  65%|██████▍   | 185/285 [03:08<01:24,  1.19it/s]Loading train:  65%|██████▌   | 186/285 [03:09<01:22,  1.20it/s]Loading train:  66%|██████▌   | 187/285 [03:10<01:20,  1.21it/s]Loading train:  66%|██████▌   | 188/285 [03:11<01:22,  1.18it/s]Loading train:  66%|██████▋   | 189/285 [03:12<01:22,  1.17it/s]Loading train:  67%|██████▋   | 190/285 [03:12<01:20,  1.18it/s]Loading train:  67%|██████▋   | 191/285 [03:13<01:19,  1.18it/s]Loading train:  67%|██████▋   | 192/285 [03:14<01:15,  1.23it/s]Loading train:  68%|██████▊   | 193/285 [03:15<01:14,  1.23it/s]Loading train:  68%|██████▊   | 194/285 [03:16<01:13,  1.24it/s]Loading train:  68%|██████▊   | 195/285 [03:17<01:14,  1.20it/s]Loading train:  69%|██████▉   | 196/285 [03:17<01:18,  1.14it/s]Loading train:  69%|██████▉   | 197/285 [03:18<01:17,  1.13it/s]Loading train:  69%|██████▉   | 198/285 [03:19<01:19,  1.09it/s]Loading train:  70%|██████▉   | 199/285 [03:20<01:19,  1.08it/s]Loading train:  70%|███████   | 200/285 [03:21<01:18,  1.09it/s]Loading train:  71%|███████   | 201/285 [03:22<01:17,  1.09it/s]Loading train:  71%|███████   | 202/285 [03:23<01:16,  1.08it/s]Loading train:  71%|███████   | 203/285 [03:24<01:16,  1.07it/s]Loading train:  72%|███████▏  | 204/285 [03:25<01:17,  1.05it/s]Loading train:  72%|███████▏  | 205/285 [03:26<01:17,  1.03it/s]Loading train:  72%|███████▏  | 206/285 [03:27<01:15,  1.05it/s]Loading train:  73%|███████▎  | 207/285 [03:28<01:13,  1.06it/s]Loading train:  73%|███████▎  | 208/285 [03:29<01:14,  1.04it/s]Loading train:  73%|███████▎  | 209/285 [03:30<01:12,  1.05it/s]Loading train:  74%|███████▎  | 210/285 [03:31<01:10,  1.06it/s]Loading train:  74%|███████▍  | 211/285 [03:32<01:08,  1.09it/s]Loading train:  74%|███████▍  | 212/285 [03:33<01:08,  1.07it/s]Loading train:  75%|███████▍  | 213/285 [03:34<01:07,  1.07it/s]Loading train:  75%|███████▌  | 214/285 [03:34<01:05,  1.08it/s]Loading train:  75%|███████▌  | 215/285 [03:35<01:03,  1.10it/s]Loading train:  76%|███████▌  | 216/285 [03:36<01:01,  1.12it/s]Loading train:  76%|███████▌  | 217/285 [03:37<00:59,  1.13it/s]Loading train:  76%|███████▋  | 218/285 [03:38<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [03:39<00:58,  1.12it/s]Loading train:  77%|███████▋  | 220/285 [03:40<00:56,  1.14it/s]Loading train:  78%|███████▊  | 221/285 [03:41<00:55,  1.16it/s]Loading train:  78%|███████▊  | 222/285 [03:41<00:54,  1.17it/s]Loading train:  78%|███████▊  | 223/285 [03:42<00:53,  1.17it/s]Loading train:  79%|███████▊  | 224/285 [03:43<00:52,  1.16it/s]Loading train:  79%|███████▉  | 225/285 [03:44<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [03:45<00:50,  1.18it/s]Loading train:  80%|███████▉  | 227/285 [03:46<00:48,  1.20it/s]Loading train:  80%|████████  | 228/285 [03:46<00:48,  1.17it/s]Loading train:  80%|████████  | 229/285 [03:47<00:47,  1.17it/s]Loading train:  81%|████████  | 230/285 [03:48<00:46,  1.18it/s]Loading train:  81%|████████  | 231/285 [03:49<00:46,  1.17it/s]Loading train:  81%|████████▏ | 232/285 [03:50<00:48,  1.09it/s]Loading train:  82%|████████▏ | 233/285 [03:51<00:48,  1.08it/s]Loading train:  82%|████████▏ | 234/285 [03:52<00:47,  1.08it/s]Loading train:  82%|████████▏ | 235/285 [03:53<00:47,  1.06it/s]Loading train:  83%|████████▎ | 236/285 [03:54<00:47,  1.03it/s]Loading train:  83%|████████▎ | 237/285 [03:55<00:46,  1.03it/s]Loading train:  84%|████████▎ | 238/285 [03:56<00:47,  1.01s/it]Loading train:  84%|████████▍ | 239/285 [03:57<00:47,  1.03s/it]Loading train:  84%|████████▍ | 240/285 [03:58<00:46,  1.03s/it]Loading train:  85%|████████▍ | 241/285 [03:59<00:46,  1.05s/it]Loading train:  85%|████████▍ | 242/285 [04:00<00:45,  1.07s/it]Loading train:  85%|████████▌ | 243/285 [04:01<00:44,  1.05s/it]Loading train:  86%|████████▌ | 244/285 [04:02<00:42,  1.04s/it]Loading train:  86%|████████▌ | 245/285 [04:03<00:41,  1.03s/it]Loading train:  86%|████████▋ | 246/285 [04:04<00:39,  1.02s/it]Loading train:  87%|████████▋ | 247/285 [04:06<00:40,  1.06s/it]Loading train:  87%|████████▋ | 248/285 [04:07<00:38,  1.05s/it]Loading train:  87%|████████▋ | 249/285 [04:08<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [04:09<00:35,  1.01s/it]Loading train:  88%|████████▊ | 251/285 [04:09<00:33,  1.02it/s]Loading train:  88%|████████▊ | 252/285 [04:10<00:30,  1.08it/s]Loading train:  89%|████████▉ | 253/285 [04:11<00:28,  1.12it/s]Loading train:  89%|████████▉ | 254/285 [04:12<00:27,  1.12it/s]Loading train:  89%|████████▉ | 255/285 [04:13<00:26,  1.14it/s]Loading train:  90%|████████▉ | 256/285 [04:14<00:25,  1.16it/s]Loading train:  90%|█████████ | 257/285 [04:15<00:24,  1.14it/s]Loading train:  91%|█████████ | 258/285 [04:15<00:23,  1.16it/s]Loading train:  91%|█████████ | 259/285 [04:16<00:22,  1.14it/s]Loading train:  91%|█████████ | 260/285 [04:17<00:21,  1.16it/s]Loading train:  92%|█████████▏| 261/285 [04:18<00:20,  1.15it/s]Loading train:  92%|█████████▏| 262/285 [04:19<00:20,  1.14it/s]Loading train:  92%|█████████▏| 263/285 [04:20<00:19,  1.14it/s]Loading train:  93%|█████████▎| 264/285 [04:21<00:18,  1.16it/s]Loading train:  93%|█████████▎| 265/285 [04:21<00:16,  1.18it/s]Loading train:  93%|█████████▎| 266/285 [04:22<00:16,  1.16it/s]Loading train:  94%|█████████▎| 267/285 [04:23<00:15,  1.16it/s]Loading train:  94%|█████████▍| 268/285 [04:24<00:16,  1.06it/s]Loading train:  94%|█████████▍| 269/285 [04:25<00:15,  1.02it/s]Loading train:  95%|█████████▍| 270/285 [04:26<00:15,  1.02s/it]Loading train:  95%|█████████▌| 271/285 [04:28<00:14,  1.02s/it]Loading train:  95%|█████████▌| 272/285 [04:29<00:13,  1.05s/it]Loading train:  96%|█████████▌| 273/285 [04:30<00:13,  1.09s/it]Loading train:  96%|█████████▌| 274/285 [04:31<00:12,  1.13s/it]Loading train:  96%|█████████▋| 275/285 [04:32<00:10,  1.09s/it]Loading train:  97%|█████████▋| 276/285 [04:33<00:09,  1.05s/it]Loading train:  97%|█████████▋| 277/285 [04:34<00:08,  1.07s/it]Loading train:  98%|█████████▊| 278/285 [04:35<00:07,  1.04s/it]Loading train:  98%|█████████▊| 279/285 [04:36<00:06,  1.07s/it]Loading train:  98%|█████████▊| 280/285 [04:37<00:05,  1.07s/it]Loading train:  99%|█████████▊| 281/285 [04:38<00:04,  1.05s/it]Loading train:  99%|█████████▉| 282/285 [04:39<00:03,  1.04s/it]Loading train:  99%|█████████▉| 283/285 [04:40<00:02,  1.04s/it]Loading train: 100%|█████████▉| 284/285 [04:41<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [04:42<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:02, 96.84it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:02, 114.12it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:01, 139.20it/s]concatenating: train:  30%|██▉       | 85/285 [00:00<00:01, 160.81it/s]concatenating: train:  40%|███▉      | 113/285 [00:00<00:00, 182.57it/s]concatenating: train:  50%|████▉     | 142/285 [00:00<00:00, 204.06it/s]concatenating: train:  60%|█████▉    | 170/285 [00:00<00:00, 220.87it/s]concatenating: train:  70%|███████   | 200/285 [00:00<00:00, 237.10it/s]concatenating: train:  79%|███████▉  | 226/285 [00:00<00:00, 243.02it/s]concatenating: train:  89%|████████▉ | 254/285 [00:01<00:00, 252.84it/s]concatenating: train:  99%|█████████▊| 281/285 [00:01<00:00, 251.97it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 248.41it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.40s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 62.12it/s]
Epoch 00044: val_mDice did not improve from 0.56020
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
{'val_loss': [6130.532586960566, 4694.014171781994, 3872.1978120349704, 3496.0253789992557, 3222.952194940476, 3014.5821591331846, 2896.5492350260415, 2866.1715146019346, 2793.447062174479, 2731.661859421503, 2738.9454345703125, 2674.3463367280506, 2757.5328776041665, 2592.3194986979165, 2611.8388671875, 2700.2362467447915, 2727.256074451265, 2692.5296165829614, 2665.319318498884, 2876.499575660342, 2798.7011602492557, 2795.082345145089, 2694.111996605283, 2802.255868094308, 2703.5609770275296, 2759.6655883789062, 2692.8479933965773, 2965.0169387090773, 2889.3865327380954, 2929.9001116071427, 2848.0176827566966, 2695.021641322545, 2818.003339494978, 2861.5330171130954, 2670.0235217866443, 3084.4863717215403, 2904.4088367280506, 2835.404753185454, 2724.480178106399, 2645.311703636533, 2818.548316592262, 2969.607195172991, 2741.1824457077755, 2867.0530511765255], 'val_acc': [0.8797779281934103, 0.9021817502521333, 0.9190178570293245, 0.9269345033736456, 0.930734898362841, 0.9332967258635021, 0.9348786473274231, 0.9368383685747782, 0.937877723148891, 0.9388095424288795, 0.9408035704067775, 0.9399542184103102, 0.9413667519887289, 0.9414377127374921, 0.9421016687438601, 0.9422092579659962, 0.9433150092760721, 0.9445764876547313, 0.9447229873566401, 0.9406616233644032, 0.9397504329681396, 0.9450206047012693, 0.9421039649418422, 0.9434272221156529, 0.946721613407135, 0.9423489116487049, 0.9441849617731004, 0.9410966038703918, 0.9415682242030189, 0.9432188527924674, 0.9409340676807222, 0.9458905799048287, 0.9437202527409508, 0.9461698617253985, 0.9463896297273182, 0.9367284604481289, 0.9439858056250072, 0.9442239176659357, 0.9417605314935956, 0.9477930608249846, 0.9468658367792765, 0.9457966940743583, 0.9448283116022745, 0.9452999205816359], 'val_mDice': [0.28206480755692437, 0.37280098987477167, 0.43672379532030653, 0.4692673223714034, 0.4953105009737469, 0.5159564529146466, 0.527823401703721, 0.5302735004751455, 0.539064300202188, 0.5450569863120714, 0.5437846645003274, 0.5518061798952875, 0.5408648131858735, 0.5601968364346595, 0.5579259897626582, 0.5478378417236465, 0.5464888864329883, 0.5498702827663648, 0.5532400161027908, 0.528214288254579, 0.5381271665294965, 0.5369413230745566, 0.5506294417594161, 0.5372862083216509, 0.5475361372033755, 0.5414708774714243, 0.5511491878756455, 0.5185599309347925, 0.5276019670778797, 0.5235665133666425, 0.5307350293511436, 0.5493571073526428, 0.5366464526880355, 0.5320747500019414, 0.5530780225637413, 0.5077516752339545, 0.5283381073247819, 0.5357004780144918, 0.545315171813681, 0.5562034119807538, 0.5355664190082323, 0.5200792781653858, 0.5440269002602214, 0.5307587353246552], 'loss': [14372.784153988487, 5476.330509595427, 4215.346286341982, 3508.0512395490678, 3090.4307968407347, 2805.262241249533, 2593.6343698554906, 2441.309816029896, 2316.7439717693046, 2214.3801436857243, 2118.638165449117, 2037.5951546911149, 1973.9757066193126, 1919.6953868435737, 1856.9669883703023, 1789.3924190594048, 1747.4653408564607, 1700.9250511579805, 1670.0683698240493, 1625.484352807537, 1583.3570375900313, 1551.623352297887, 1513.3801592533957, 1487.8486452148625, 1454.0091582151745, 1432.5149103462156, 1405.4753487040732, 1379.78147800814, 1355.3127800180478, 1333.941826482993, 1323.840702195882, 1293.8125179563617, 1273.9612047509097, 1258.062549915391, 1238.6801996799202, 1224.787127719671, 1195.8148023444655, 1185.5240353315305, 1167.0075199383864, 1156.6051517837375, 1145.9938890358974, 1128.5043930486147, 1111.163471281494, 1099.4677342064974], 'acc': [0.8447885609256847, 0.8653246438271144, 0.8837673410368214, 0.8984235966391754, 0.9081212651621566, 0.9147339278571013, 0.9193727676983809, 0.923081301599425, 0.9259648518638618, 0.9285731659658111, 0.9308394861055841, 0.9326508325006269, 0.9342409981935728, 0.9357218614014353, 0.9367805164122779, 0.9380356884080825, 0.9390457212890484, 0.9402257025942813, 0.9408142465788527, 0.9417039746031127, 0.9425921948033765, 0.9431296684550301, 0.943913246134193, 0.9444894846611361, 0.9451597988525061, 0.9457040586314358, 0.9462580021714254, 0.9468593810688032, 0.9473000156389901, 0.9476751487609484, 0.9481480855782735, 0.948667645764668, 0.9489802718622183, 0.9492904785191, 0.9497248799625747, 0.9499972883000731, 0.9505899519457944, 0.9507890475010031, 0.9511844051787453, 0.9513743916572761, 0.9516858436341044, 0.9520919291826487, 0.9523586364800883, 0.9526570006351791], 'mDice': [0.1664411054540972, 0.34277820014323895, 0.431269501109148, 0.4929491240715783, 0.5346230168964952, 0.5658345478266357, 0.5904995245650391, 0.6090499269426822, 0.6245461978824102, 0.6376110790022679, 0.6501299162257584, 0.6608909154204888, 0.6693084258575396, 0.6767198206809805, 0.6852229646297004, 0.6945322189851374, 0.7004853730167707, 0.7071276681717821, 0.7114674711999623, 0.7178551864826268, 0.7239790483318084, 0.7286531938301338, 0.7342573423732194, 0.7379416319729621, 0.7430527417536115, 0.7463740994527157, 0.7503827699053051, 0.7542519901031838, 0.7579950842642247, 0.7613249528791856, 0.7628778921332873, 0.7674929103755712, 0.77051991264508, 0.7730177804434117, 0.7760889402170367, 0.7783209885593919, 0.7828538289689733, 0.7845283324993804, 0.7874010279846485, 0.7890590753586554, 0.7908037021850974, 0.79358984972669, 0.7963121830670158, 0.7982384042747223]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     2019-07-07 06:19:16.093986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 06:19:16.094093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 06:19:16.094108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 06:19:16.094118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 06:19:16.094535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 26s - loss: 10583.9450 - acc: 0.8875 - mDice: 0.2589 - val_loss: 3910.5546 - val_acc: 0.9305 - val_mDice: 0.4380

Epoch 00001: val_mDice improved from -inf to 0.43798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 3646.7433 - acc: 0.9211 - mDice: 0.4874 - val_loss: 3065.3637 - val_acc: 0.9413 - val_mDice: 0.5129

Epoch 00002: val_mDice improved from 0.43798 to 0.51289, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 17s - loss: 2807.8618 - acc: 0.9325 - mDice: 0.5703 - val_loss: 2610.3739 - val_acc: 0.9461 - val_mDice: 0.5622

Epoch 00003: val_mDice improved from 0.51289 to 0.56216, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 18s - loss: 2430.1096 - acc: 0.9382 - mDice: 0.6135 - val_loss: 2650.3100 - val_acc: 0.9476 - val_mDice: 0.5592

Epoch 00004: val_mDice did not improve from 0.56216
Epoch 5/300
 - 17s - loss: 2210.6741 - acc: 0.9420 - mDice: 0.6408 - val_loss: 2407.0807 - val_acc: 0.9500 - val_mDice: 0.5899

Epoch 00005: val_mDice improved from 0.56216 to 0.58992, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 2044.5221 - acc: 0.9447 - mDice: 0.6616 - val_loss: 2298.9053 - val_acc: 0.9517 - val_mDice: 0.6036

Epoch 00006: val_mDice improved from 0.58992 to 0.60361, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 17s - loss: 1928.0584 - acc: 0.9467 - mDice: 0.6772 - val_loss: 2346.4722 - val_acc: 0.9531 - val_mDice: 0.5993

Epoch 00007: val_mDice did not improve from 0.60361
Epoch 8/300
 - 18s - loss: 1833.3772 - acc: 0.9481 - mDice: 0.6899 - val_loss: 2276.5374 - val_acc: 0.9531 - val_mDice: 0.6063

Epoch 00008: val_mDice improved from 0.60361 to 0.60632, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 17s - loss: 1751.7823 - acc: 0.9494 - mDice: 0.7013 - val_loss: 2264.0385 - val_acc: 0.9544 - val_mDice: 0.6093

Epoch 00009: val_mDice improved from 0.60632 to 0.60928, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 17s - loss: 1688.2370 - acc: 0.9505 - mDice: 0.7101 - val_loss: 2313.9261 - val_acc: 0.9543 - val_mDice: 0.6033

Epoch 00010: val_mDice did not improve from 0.60928
Epoch 11/300
 - 17s - loss: 1620.4434 - acc: 0.9515 - mDice: 0.7196 - val_loss: 2383.7270 - val_acc: 0.9539 - val_mDice: 0.5994

Epoch 00011: val_mDice did not improve from 0.60928
Epoch 12/300
 - 17s - loss: 1568.1209 - acc: 0.9523 - mDice: 0.7270 - val_loss: 2195.3975 - val_acc: 0.9529 - val_mDice: 0.6169

Epoch 00012: val_mDice improved from 0.60928 to 0.61686, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 18s - loss: 1521.4999 - acc: 0.9529 - mDice: 0.7338 - val_loss: 2218.9232 - val_acc: 0.9533 - val_mDice: 0.6183

Epoch 00013: val_mDice improved from 0.61686 to 0.61828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 17s - loss: 1475.8104 - acc: 0.9536 - mDice: 0.7404 - val_loss: 2340.3293 - val_acc: 0.9554 - val_mDice: 0.6088

Epoch 00014: val_mDice did not improve from 0.61828
Epoch 15/300
 - 17s - loss: 1436.5103 - acc: 0.9542 - mDice: 0.7463 - val_loss: 2342.1005 - val_acc: 0.9537 - val_mDice: 0.6030

Epoch 00015: val_mDice did not improve from 0.61828
Epoch 16/300
 - 17s - loss: 1393.0812 - acc: 0.9549 - mDice: 0.7527 - val_loss: 2307.5514 - val_acc: 0.9556 - val_mDice: 0.6058

Epoch 00016: val_mDice did not improve from 0.61828
Epoch 17/300
 - 17s - loss: 1362.0314 - acc: 0.9554 - mDice: 0.7574 - val_loss: 2380.5951 - val_acc: 0.9538 - val_mDice: 0.5982

Epoch 00017: val_mDice did not improve from 0.61828
Epoch 18/300
 - 17s - loss: 1328.2248 - acc: 0.9559 - mDice: 0.7625 - val_loss: 2278.3471 - val_acc: 0.9548 - val_mDice: 0.6089

Epoch 00018: val_mDice did not improve from 0.61828
Epoch 19/300
 - 18s - loss: 1301.7105 - acc: 0.9564 - mDice: 0.7666 - val_loss: 2217.8049 - val_acc: 0.9542 - val_mDice: 0.6169

Epoch 00019: val_mDice did not improve from 0.61828
Epoch 20/300
 - 17s - loss: 1265.2610 - acc: 0.9569 - mDice: 0.7722 - val_loss: 2285.6424 - val_acc: 0.9547 - val_mDice: 0.6092

Epoch 00020: val_mDice did not improve from 0.61828
Epoch 21/300
 - 18s - loss: 1243.1724 - acc: 0.9573 - mDice: 0.7756 - val_loss: 2262.9982 - val_acc: 0.9550 - val_mDice: 0.6125

Epoch 00021: val_mDice did not improve from 0.61828
Epoch 22/300
 - 18s - loss: 1219.7639 - acc: 0.9577 - mDice: 0.7794 - val_loss: 2261.6991 - val_acc: 0.9535 - val_mDice: 0.6120

Epoch 00022: val_mDice did not improve from 0.61828
Epoch 23/300
 - 17s - loss: 1199.0580 - acc: 0.9580 - mDice: 0.7826 - val_loss: 2225.2752 - val_acc: 0.9521 - val_mDice: 0.6126

Epoch 00023: val_mDice did not improve from 0.61828
Epoch 24/300
 - 18s - loss: 1183.5992 - acc: 0.9584 - mDice: 0.7851 - val_loss: 2246.4125 - val_acc: 0.9555 - val_mDice: 0.6132

Epoch 00024: val_mDice did not improve from 0.61828
Epoch 25/300
 - 18s - loss: 1155.6793 - acc: 0.9587 - mDice: 0.7895 - val_loss: 2269.0209 - val_acc: 0.9559 - val_mDice: 0.6124

Epoch 00025: val_mDice did not improve from 0.61828
Epoch 26/300
 - 17s - loss: 1134.8008 - acc: 0.9591 - mDice: 0.7927 - val_loss: 2220.1570 - val_acc: 0.9552 - val_mDice: 0.6160

Epoch 00026: val_mDice did not improve from 0.61828
Epoch 27/300
 - 17s - loss: 1125.6139 - acc: 0.9593 - mDice: 0.7942 - val_loss: 2191.3841 - val_acc: 0.9542 - val_mDice: 0.6176

Epoch 00027: val_mDice did not improve from 0.61828
Epoch 28/300
 - 17s - loss: 1111.4359 - acc: 0.9596 - mDice: 0.7966 - val_loss: 2117.8524 - val_acc: 0.9544 - val_mDice: 0.6258

Epoch 00028: val_mDice improved from 0.61828 to 0.62577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 17s - loss: 1083.1164 - acc: 0.9600 - mDice: 0.8011 - val_loss: 2120.9402 - val_acc: 0.9554 - val_mDice: 0.6258

Epoch 00029: val_mDice improved from 0.62577 to 0.62577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 18s - loss: 1077.8427 - acc: 0.9602 - mDice: 0.8020 - val_loss: 2402.8134 - val_acc: 0.9533 - val_mDice: 0.5994

Epoch 00030: val_mDice did not improve from 0.62577
Epoch 31/300
 - 18s - loss: 1054.4436 - acc: 0.9605 - mDice: 0.8058 - val_loss: 2322.5642 - val_acc: 0.9548 - val_mDice: 0.6081

Epoch 00031: val_mDice did not improve from 0.62577
Epoch 32/300
 - 17s - loss: 1044.0967 - acc: 0.9608 - mDice: 0.8075 - val_loss: 2186.0629 - val_acc: 0.9559 - val_mDice: 0.6229

Epoch 00032: val_mDice did not improve from 0.62577
Epoch 33/300
 - 17s - loss: 1029.2578 - acc: 0.9610 - mDice: 0.8100 - val_loss: 2196.3775 - val_acc: 0.9546 - val_mDice: 0.6172

Epoch 00033: val_mDice did not improve from 0.62577
Epoch 34/300
 - 17s - loss: 1020.4825 - acc: 0.9612 - mDice: 0.8113 - val_loss: 2235.1885 - val_acc: 0.9558 - val_mDice: 0.6178

Epoch 00034: val_mDice did not improve from 0.62577
Epoch 35/300
 - 17s - loss: 1011.6297 - acc: 0.9613 - mDice: 0.8128 - val_loss: 2315.3863 - val_acc: 0.9561 - val_mDice: 0.6062

Epoch 00035: val_mDice did not improve from 0.62577
Epoch 36/300
 - 17s - loss: 992.9660 - acc: 0.9617 - mDice: 0.8159 - val_loss: 2234.2743 - val_acc: 0.9561 - val_mDice: 0.6128

Epoch 00036: val_mDice did not improve from 0.62577
Epoch 37/300
 - 18s - loss: 985.6099 - acc: 0.9618 - mDice: 0.8172 - val_loss: 2180.4933 - val_acc: 0.9544 - val_mDice: 0.6198

Epoch 00037: val_mDice did not improve from 0.62577
Epoch 38/300
 - 17s - loss: 972.9315 - acc: 0.9619 - mDice: 0.8192 - val_loss: 2239.3510 - val_acc: 0.9560 - val_mDice: 0.6133

Epoch 00038: val_mDice did not improve from 0.62577
Epoch 39/300
 - 17s - loss: 965.8585 - acc: 0.9622 - mDice: 0.8204 - val_loss: 2317.1453 - val_acc: 0.9557 - val_mDice: 0.6079

Epoch 00039: val_mDice did not improve from 0.62577
Epoch 40/300
 - 17s - loss: 955.3288 - acc: 0.9623 - mDice: 0.8222 - val_loss: 2227.6007 - val_acc: 0.9546 - val_mDice: 0.6158

Epoch 00040: val_mDice did not improve from 0.62577
Epoch 41/300
 - 17s - loss: 944.5222 - acc: 0.9626 - mDice: 0.8240 - val_loss: 2152.3356 - val_acc: 0.9540 - val_mDice: 0.6220

Epoch 00041: val_mDice did not improve from 0.62577
Epoch 42/300
 - 17s - loss: 935.4749 - acc: 0.9627 - mDice: 0.8254 - val_loss: 2175.2178 - val_acc: 0.9556 - val_mDice: 0.6190

Epoch 00042: val_mDice did not improve from 0.62577
Epoch 43/300
 - 18s - loss: 924.7470 - acc: 0.9630 - mDice: 0.8273 - val_loss: 2212.1227 - val_acc: 0.9546 - val_mDice: 0.6201

Epoch 00043: val_mDice did not improve from 0.62577
Epoch 44/300
 - 17s - loss: 924.7367 - acc: 0.9630 - mDice: 0.8273 - val_loss: 2114.7467 - val_acc: 0.9571 - val_mDice: 0.6284

Epoch 00044: val_mDice improved from 0.62577 to 0.62838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 17s - loss: 910.3534 - acc: 0.9632 - mDice: 0.8297 - val_loss: 2076.6909 - val_acc: 0.9554 - val_mDice: 0.6296

Epoch 00045: val_mDice improved from 0.62838 to 0.62959, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 46/300
 - 17s - loss: 907.3494 - acc: 0.9633 - mDice: 0.8303 - val_loss: 2257.1013 - val_acc: 0.9556 - val_mDice: 0.6137

Epoch 00046: val_mDice did not improve from 0.62959
Epoch 47/300
 - 17s - loss: 896.0261 - acc: 0.9635 - mDice: 0.8322 - val_loss: 2149.5420 - val_acc: 0.9565 - val_mDice: 0.6244

Epoch 00047: val_mDice did not improve from 0.62959
Epoch 48/300
 - 17s - loss: 888.1493 - acc: 0.9636 - mDice: 0.8335 - val_loss: 2095.2033 - val_acc: 0.9541 - val_mDice: 0.6287

Epoch 00048: val_mDice did not improve from 0.62959
Epoch 49/300
 - 17s - loss: 884.4155 - acc: 0.9637 - mDice: 0.8341 - val_loss: 2219.8126 - val_acc: 0.9554 - val_mDice: 0.6138

Epoch 00049: val_mDice did not improve from 0.62959
Epoch 50/300
 - 18s - loss: 882.3677 - acc: 0.9638 - mDice: 0.8345 - val_loss: 2259.8640 - val_acc: 0.9550 - val_mDice: 0.6100

Epoch 00050: val_mDice did not improve from 0.62959
Epoch 51/300
 - 17s - loss: 867.2254 - acc: 0.9640 - mDice: 0.8370 - val_loss: 2175.0760 - val_acc: 0.9551 - val_mDice: 0.6189

Epoch 00051: val_mDice did not improve from 0.62959
Epoch 52/300
 - 17s - loss: 866.2505 - acc: 0.9641 - mDice: 0.8372 - val_loss: 2201.9336 - val_acc: 0.9541 - val_mDice: 0.6163

Epoch 00052: val_mDice did not improve from 0.62959
Epoch 53/300
 - 17s - loss: 1036.6645 - acc: 0.9614 - mDice: 0.8146 - val_loss: 2572.1696 - val_acc: 0.9555 - val_mDice: 0.5797

Epoch 00053: val_mDice did not improve from 0.62959
Epoch 54/300
 - 17s - loss: 945.4534 - acc: 0.9625 - mDice: 0.8237 - val_loss: 2185.0452 - val_acc: 0.9529 - val_mDice: 0.6172

Epoch 00054: val_mDice did not improve from 0.62959
Epoch 55/300
 - 17s - loss: 897.6545 - acc: 0.9634 - mDice: 0.8318 - val_loss: 2150.2927 - val_acc: 0.9559 - val_mDice: 0.6244

Epoch 00055: val_mDice did not improve from 0.62959
Epoch 56/300
 - 18s - loss: 870.2561 - acc: 0.9639 - mDice: 0.8364 - val_loss: 2187.2728 - val_acc: 0.9556 - val_mDice: 0.6175

Epoch 00056: val_mDice did not improve from 0.62959
Epoch 57/300
 - 18s - loss: 857.2455 - acc: 0.9642 - mDice: 0.8387 - val_loss: 2102.1244 - val_acc: 0.9546 - val_mDice: 0.6300

Epoch 00057: val_mDice improved from 0.62959 to 0.62997, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 58/300
 - 17s - loss: 848.1657 - acc: 0.9644 - mDice: 0.8403 - val_loss: 2102.1843 - val_acc: 0.9559 - val_mDice: 0.6286

Epoch 00058: val_mDice did not improve from 0.62997
Epoch 59/300
 - 17s - loss: 839.6670 - acc: 0.9646 - mDice: 0.8417 - val_loss: 2193.0791 - val_acc: 0.9552 - val_mDice: 0.6167

Epoch 00059: val_mDice did not improve from 0.62997
Epoch 60/300
 - 18s - loss: 834.6935 - acc: 0.9646 - mDice: 0.8426 - val_loss: 2286.2983 - val_acc: 0.9531 - val_mDice: 0.6065

Epoch 00060: val_mDice did not improve from 0.62997
Epoch 61/300
 - 17s - loss: 829.3586 - acc: 0.9648 - mDice: 0.8435 - val_loss: 2214.5762 - val_acc: 0.9559 - val_mDice: 0.6178

Epoch 00061: val_mDice did not improve from 0.62997
Epoch 62/300
 - 17s - loss: 828.1760 - acc: 0.9648 - mDice: 0.8437 - val_loss: 2176.3631 - val_acc: 0.9556 - val_mDice: 0.6213

Epoch 00062: val_mDice did not improve from 0.62997
Epoch 63/300
 - 18s - loss: 824.6702 - acc: 0.9649 - mDice: 0.8444 - val_loss: 2145.7351 - val_acc: 0.9548 - val_mDice: 0.6237

Epoch 00063: val_mDice did not improve from 0.62997
Epoch 64/300
 - 17s - loss: 816.8336 - acc: 0.9650 - mDice: 0.8457 - val_loss: 2161.3037 - val_acc: 0.9560 - val_mDice: 0.6218

Epoch 00064: val_mDice did not improve from 0.62997
Epoch 65/300
 - 17s - loss: 816.1360 - acc: 0.9650 - mDice: 0.8458 - val_loss: 2190.4944 - val_acc: 0.9555 - val_mDice: 0.6182

Epoch 00065: val_mDice did not improve from 0.62997
Epoch 66/300
 - 17s - loss: 808.7455 - acc: 0.9651 - mDice: 0.8471 - val_loss: 2206.1088 - val_acc: 0.9543 - val_mDice: 0.6183

Epoch 00066: val_mDice did not improve from 0.62997
Epoch 67/300
 - 17s - loss: 808.0559 - acc: 0.9652 - mDice: 0.8472 - val_loss: 2232.2205 - val_acc: 0.9545 - val_mDice: 0.6136

Epoch 00067: val_mDice did not improve from 0.62997
Epoch 68/300
 - 17s - loss: 797.7621 - acc: 0.9653 - mDice: 0.8490 - val_loss: 2191.5854 - val_acc: 0.9564 - val_mDice: 0.6191

Epoch 00068: val_mDice did not improve from 0.62997
Epoch 69/300
 - 18s - loss: 801.7418 - acc: 0.9654 - mDice: 0.8483 - val_loss: 2191.5322 - val_acc: 0.9554 - val_mDice: 0.6182

Epoch 00069: val_mDice did not improve from 0.62997
Epoch 70/300
 - 18s - loss: 797.0488 - acc: 0.9653 - mDice: 0.8491 - val_loss: 2328.0725 - val_acc: 0.9554 - val_mDice: 0.6076

Epoch 00070: val_mDice did not improve from 0.62997
Epoch 71/300
 - 18s - loss: 795.3636 - acc: 0.9654 - mDice: 0.8494 - val_loss: 2208.6624 - val_acc: 0.9547 - val_mDice: 0.6154

Epoch 00071: val_mDice did not improve from 0.62997
Epoch 72/300
 - 17s - loss: 790.8050 - acc: 0.9656 - mDice: 0.8502 - val_loss: 2226.7016 - val_acc: 0.9556 - val_mDice: 0.6142

Epoch 00072: val_mDice did not improve from 0.62997
Epoch 73/300
 - 18s - loss: 784.3400 - acc: 0.9657 - mDice: 0.8513 - val_loss: 2251.5990 - val_acc: 0.9543 - val_mDice: 0.6122

Epoch 00073: val_mDice did not improve from 0.62997
Epoch 74/300
 - 17s - loss: 779.9297 - acc: 0.9657 - mDice: 0.8521 - val_loss: 2210.1918 - val_acc: 0.9552 - val_mDice: 0.6157

Epoch 00074: val_mDice did not improve from 0.62997
Epoch 75/300
 - 18s - loss: 782.8669 - acc: 0.9657 - mDice: 0.8515 - val_loss: 2052.1882 - val_acc: 0.9553 - val_mDice: 0.6335

Epoch 00075: val_mDice improved from 0.62997 to 0.63354, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 76/300
 - 18s - loss: 781.8656 - acc: 0.9657 - mDice: 0.8518 - val_loss: 2159.3480 - val_acc: 0.9571 - val_mDice: 0.6223

Epoch 00076: val_mDice did not improve from 0.63354
Epoch 77/300
 - 18s - loss: 777.1953 - acc: 0.9658 - mDice: 0.8525 - val_loss: 2189.3779 - val_acc: 0.9553 - val_mDice: 0.6175

Epoch 00077: val_mDice did not improve from 0.63354
Epoch 78/300
 - 18s - loss: 771.1333 - acc: 0.9659 - mDice: 0.8537 - val_loss: 2299.3885 - val_acc: 0.9560 - val_mDice: 0.6063

Epoch 00078: val_mDice did not improve from 0.63354
Epoch 79/300
 - 17s - loss: 770.1847 - acc: 0.9660 - mDice: 0.8538 - val_loss: 2175.4401 - val_acc: 0.9548 - val_mDice: 0.6218

Epoch 00079: val_mDice did not improve from 0.63354
Epoch 80/300
 - 18s - loss: 764.8891 - acc: 0.9660 - mDice: 0.8547 - val_loss: 2273.3883 - val_acc: 0.9542 - val_mDice: 0.6069

Epoch 00080: val_mDice did not improve from 0.63354
Epoch 81/300
 - 18s - loss: 764.3410 - acc: 0.9660 - mDice: 0.8548 - val_loss: 2089.8313 - val_acc: 0.9553 - val_mDice: 0.6306

Epoch 00081: val_mDice did not improve from 0.63354
Epoch 82/300
 - 18s - loss: 764.3547 - acc: 0.9661 - mDice: 0.8548 - val_loss: 2207.9153 - val_acc: 0.9562 - val_mDice: 0.6171

Epoch 00082: val_mDice did not improve from 0.63354
Epoch 83/300
 - 18s - loss: 756.4215 - acc: 0.9662 - mDice: 0.8562 - val_loss: 2125.2249 - val_acc: 0.9559 - val_mDice: 0.6266

Epoch 00083: val_mDice did not improve from 0.63354
Epoch 84/300
 - 18s - loss: 758.7283 - acc: 0.9662 - mDice: 0.8558 - val_loss: 2237.5983 - val_acc: 0.9549 - val_mDice: 0.6161

Epoch 00084: val_mDice did not improve from 0.63354
Epoch 85/300
 - 17s - loss: 755.6647 - acc: 0.9662 - mDice: 0.8563 - val_loss: 2371.4963 - val_acc: 0.9561 - val_mDice: 0.5992

Epoch 00085: val_mDice did not improve from 0.63354
Epoch 86/300
 - 18s - loss: 756.1609 - acc: 0.9663 - mDice: 0.8562 - val_loss: 2183.7345 - val_acc: 0.9550 - val_mDice: 0.6182

Epoch 00086: val_mDice did not improve from 0.63354
Epoch 87/300
 - 18s - loss: 748.6903 - acc: 0.9663 - mDice: 0.8575 - val_loss: 2170.9594 - val_acc: 0.9551 - val_mDice: 0.6201

Epoch 00087: val_mDice did not improve from 0.63354
Epoch 88/300
 - 17s - loss: 743.3766 - acc: 0.9664 - mDice: 0.8584 - val_loss: 2122.2699 - val_acc: 0.9555 - val_mDice: 0.6245

Epoch 00088: val_mDice did not improve from 0.63354
Epoch 89/300
 - 18s - loss: 743.2106 - acc: 0.9664 - mDice: 0.8585 - val_loss: 2235.6227 - val_acc: 0.9550 - val_mDice: 0.6109

Epoch 00089: val_mDice did not improve from 0.63354
Epoch 90/300
 - 18s - loss: 741.8720 - acc: 0.9664 - mDice: 0.8587 - val_loss: 2263.9085 - val_acc: 0.9546 - val_mDice: 0.6115

Epoch 00090: val_mDice did not improve from 0.63354
Epoch 91/300
 - 18s - loss: 739.4918 - acc: 0.9665 - mDice: 0.8591 - val_loss: 2179.3608 - val_acc: 0.9554 - val_mDice: 0.6211

Epoch 00091: val_mDice did not improve from 0.63354
Epoch 92/300
 - 18s - loss: 736.2854 - acc: 0.9665 - mDice: 0.8597 - val_loss: 2290.4480 - val_acc: 0.9542 - val_mDice: 0.6068

Epoch 00092: val_mDice did not improve from 0.63354
Epoch 93/300
 - 18s - loss: 730.4967 - acc: 0.9666 - mDice: 0.8607 - val_loss: 2288.0288 - val_acc: 0.9556 - val_mDice: 0.6101

Epoch 00093: val_mDice did not improve from 0.63354
Epoch 94/300
 - 18s - loss: 731.8930 - acc: 0.9666 - mDice: 0.8605 - val_loss: 2286.2059 - val_acc: 0.9547 - val_mDice: 0.6080

Epoch 00094: val_mDice did not improve from 0.63354
Epoch 95/300
 - 18s - loss: 727.9944 - acc: 0.9667 - mDice: 0.8611 - val_loss: 2308.3841 - val_acc: 0.9560 - val_mDice: 0.6079

Epoch 00095: val_mDice did not improve from 0.63354
Epoch 96/300
 - 18s - loss: 727.2283 - acc: 0.9667 - mDice: 0.8613 - val_loss: 2286.0438 - val_acc: 0.9548 - val_mDice: 0.6081

Epoch 00096: val_mDice did not improve from 0.63354
Epoch 97/300
 - 18s - loss: 728.0296 - acc: 0.9667 - mDice: 0.8611 - val_loss: 2293.4188 - val_acc: 0.9552 - val_mDice: 0.6093

Epoch 00097: val_mDice did not improve from 0.63354
Epoch 98/300
 - 18s - loss: 725.4822 - acc: 0.9667 - mDice: 0.8616 - val_loss: 2319.2907 - val_acc: 0.9556 - val_mDice: 0.6056

Epoch 00098: val_mDice did not improve from 0.63354
Epoch 99/300
 - 18s - loss: 723.3170 - acc: 0.9668 - mDice: 0.8620 - val_loss: 2268.4025 - val_acc: 0.9552 - val_mDice: 0.6082

Epoch 00099: val_mDice did not improve from 0.63354
Epoch 100/300
 - 18s - loss: 715.0390 - acc: 0.9669 - mDice: 0.8634 - val_loss: 2268.8889 - val_acc: 0.9547 - val_mDice: 0.6098

Epoch 00100: val_mDice did not improve from 0.63354
Epoch 101/300
 - 18s - loss: 716.9336 - acc: 0.9669 - mDice: 0.8631 - val_loss: 2278.8177 - val_acc: 0.9550 - val_mDice: 0.6082

Epoch 00101: val_mDice did not improve from 0.63354
Epoch 102/300
 - 18s - loss: 714.1685 - acc: 0.9669 - mDice: 0.8636 - val_loss: 2212.5784 - val_acc: 0.9563 - val_mDice: 0.6149

Epoch 00102: val_mDice did not improve from 0.63354
Epoch 103/300
 - 18s - loss: 708.7744 - acc: 0.9670 - mDice: 0.8645 - val_loss: 2339.4388 - val_acc: 0.9560 - val_mDice: 0.6041

Epoch 00103: val_mDice did not improve from 0.63354
Epoch 104/300
 - 18s - loss: 708.2593 - acc: 0.9670 - mDice: 0.8646 - val_loss: 2144.6873 - val_acc: 0.9557 - val_mDice: 0.6233

Epoch 00104: val_mDice did not improve from 0.63354
Epoch 105/300
 - 18s - loss: 710.3004 - acc: 0.9670 - mDice: 0.8643 - val_loss: 2167.4027 - val_acc: 0.9548 - val_mDice: 0.6185

Epoch 00105: val_mDice did not improve from 0.63354
Restoring model weights from the end of the best epoch
Epoch 00105: early stopping
{'val_loss': [3910.554647946491, 3065.3636999716305, 2610.3738761347763, 2650.3099603919345, 2407.0807027976607, 2298.905263890101, 2346.472229344885, 2276.537394433048, 2264.038461013879, 2313.9261331398393, 2383.727009863827, 2195.3975195858065, 2218.9232402780203, 2340.3292570487083, 2342.1005122861384, 2307.5514059226607, 2380.595063449284, 2278.3470793143333, 2217.804867536662, 2285.6423571709147, 2262.998175082926, 2261.6990973616444, 2225.2751642152584, 2246.4124926348636, 2269.020878797137, 2220.156956507507, 2191.384110946229, 2117.852408126746, 2120.940248286924, 2402.813364721543, 2322.5642471739698, 2186.0628696207227, 2196.377534152409, 2235.1885229355794, 2315.3863013922837, 2234.274348594623, 2180.493341371334, 2239.3510196621855, 2317.145275947102, 2227.6006677723462, 2152.335586974075, 2175.21780344361, 2212.1226567955655, 2114.7467061474335, 2076.6909016017808, 2257.1013374541726, 2149.5419949153284, 2095.20327775838, 2219.8125886544167, 2259.864015035789, 2175.0759754713686, 2201.933592386086, 2572.1696245417247, 2185.045155104312, 2150.292712334148, 2187.2728441973636, 2102.1244407952163, 2102.184300257507, 2193.0791192933834, 2286.2982825593576, 2214.576222339822, 2176.3630848463686, 2145.7351360640714, 2161.303701390101, 2190.4944434139315, 2206.108793972591, 2232.2204535287187, 2191.585363292161, 2191.5321679141935, 2328.072508401711, 2208.6624489896126, 2226.701582413146, 2251.598964243628, 2210.1918399746855, 2052.1881587705134, 2159.3479849532996, 2189.3779065009603, 2299.3885122970496, 2175.440107803771, 2273.3883295325595, 2089.831335653806, 2207.915270927898, 2125.2249271669866, 2237.598324567912, 2371.496251964036, 2183.734466382245, 2170.9594303749127, 2122.269861317214, 2235.622727719099, 2263.9084799995635, 2179.3607948345843, 2290.4479912273046, 2288.0288263246334, 2286.2059332991444, 2308.384146407996, 2286.043776187151, 2293.4187980097763, 2319.290707380412, 2268.402474685754, 2268.88893101868, 2278.8177251549405, 2212.5783664127966, 2339.4387548009777, 2144.687269498516, 2167.402690184183], 'val_acc': [0.9304692602024398, 0.94125813279072, 0.9460513605085831, 0.9475699256918284, 0.9500388479765567, 0.9517371488017077, 0.9530780058999301, 0.953100718599458, 0.954414735626242, 0.9542824932316828, 0.9539188915790793, 0.9528796279896571, 0.9533238580772997, 0.9554415341862087, 0.9536709662256294, 0.9555882458580273, 0.9537660046662698, 0.954832058379104, 0.954175046702337, 0.9546853840018118, 0.9549932253427346, 0.9534581493398997, 0.9521358679126761, 0.9555407306335492, 0.9559498053023269, 0.9551977621776432, 0.9542184565320361, 0.9544106062564104, 0.9553816621529989, 0.9532556770234134, 0.9548031591170327, 0.9559208750724792, 0.9546378511290311, 0.9557700623347106, 0.9561089010877982, 0.9560551620062503, 0.9543610301763652, 0.956009708303313, 0.9557390779090327, 0.9545862341726292, 0.9539643299646218, 0.9556398864564949, 0.9545738237530159, 0.9571481167271151, 0.9553836947046844, 0.9556068524968024, 0.956472506736244, 0.9540738150394162, 0.9553961197757188, 0.9549642841243211, 0.9551192505399608, 0.9540758832206939, 0.9554869885551197, 0.9528920597204283, 0.9558650984444432, 0.955551059885398, 0.9545738180922396, 0.9558898753294066, 0.9552328729762711, 0.9530655944813563, 0.9558650824610747, 0.9555944447410839, 0.9548052113149419, 0.9560427872162292, 0.9554746130991248, 0.9542845694046447, 0.9545159513057944, 0.9564394581251304, 0.9554353539504152, 0.9554188321422599, 0.9547390854558465, 0.955567576365764, 0.9542597525612602, 0.9551523247910612, 0.9553320521082957, 0.9571315779366307, 0.9553134834300206, 0.9559911296354325, 0.9548237983074934, 0.9541709359797685, 0.9552535491282713, 0.9561522866094578, 0.9559022807542172, 0.954873396697657, 0.9560551856483162, 0.9550221489128454, 0.9551233802427793, 0.9555221406441161, 0.9550386823755402, 0.9546151147874374, 0.9554394799903785, 0.9542329254763087, 0.9556006326355748, 0.9546812513021118, 0.9559684176018785, 0.9548176253974104, 0.9551915742831523, 0.9555572647622178, 0.9551708888075205, 0.9546977857637672, 0.9550076683140334, 0.9562927577748644, 0.9559518465116703, 0.9556729623725294, 0.9547742102399218], 'val_mDice': [0.4379775331007036, 0.5128879906744931, 0.5621620423300973, 0.5592429065171567, 0.589915593243178, 0.6036089981734419, 0.5992670688549233, 0.6063193718814317, 0.6092775733777265, 0.6032974270468984, 0.5993832336457748, 0.6168576162620629, 0.6182848504801702, 0.6087612050205635, 0.6029627296511687, 0.6057851134731783, 0.5981922522603467, 0.6089068884290131, 0.616900512959038, 0.609171289638434, 0.6125034410194312, 0.6120268276283861, 0.6125517843821862, 0.6132196740731181, 0.6124467203736971, 0.6159988508544154, 0.6176091026327464, 0.6257672486358514, 0.6257680075128651, 0.5993627596167879, 0.6081066371342323, 0.6229087334105422, 0.617239093314336, 0.6177759300397095, 0.6062066475106351, 0.6127827523806908, 0.6198054338966668, 0.6133414506912231, 0.6078746748370165, 0.6157876526177263, 0.6219843715928787, 0.619002773109095, 0.6201019583467665, 0.6283785637530535, 0.6295941132406949, 0.613657825485954, 0.6243564682965838, 0.628696713367654, 0.6138419072721257, 0.6099505987247276, 0.6189062775180326, 0.6162546033965809, 0.5796680230668138, 0.6171781434027176, 0.6243727400316207, 0.6174722703475526, 0.6299667654756728, 0.6285661052725169, 0.6167352192894706, 0.6064960670204802, 0.6177993037181193, 0.621262917638491, 0.6237026100052135, 0.6218271421986585, 0.6182151779782172, 0.6182946402933345, 0.6135970667087832, 0.6191235427749889, 0.6181632140495258, 0.6075739923802168, 0.6153708533201804, 0.6141567559881583, 0.612166502289266, 0.6156831999730797, 0.6335405837224183, 0.6222985473425029, 0.6175405556263205, 0.6063484932457268, 0.6218170197316388, 0.6068590519814517, 0.630600090799385, 0.6170752291572826, 0.62660644607171, 0.6161080582181835, 0.5992217260366045, 0.6181511242962416, 0.6200608634415952, 0.6245164521579636, 0.6109162898702994, 0.6114548791054241, 0.6211242962149934, 0.6067775581136096, 0.6100945173029128, 0.6079559049792795, 0.6079016221302181, 0.6080955739793831, 0.6093381576697919, 0.6055541611250552, 0.6081943119038417, 0.6097806555598808, 0.6081869359122974, 0.6148742563897671, 0.6040768916380472, 0.6233244298556664, 0.6185375285548205], 'loss': [10583.945028509179, 3646.7433021087922, 2807.861773218583, 2430.1096167405713, 2210.674146188603, 2044.5221473748281, 1928.058422475266, 1833.3771846138193, 1751.7822980688038, 1688.2369971116652, 1620.443431569408, 1568.1209177250216, 1521.4999470658554, 1475.8104035964582, 1436.5103302990894, 1393.0812466186503, 1362.0314154939956, 1328.224757533429, 1301.7105274432092, 1265.2610354195247, 1243.1724493075453, 1219.7638802142726, 1199.058026868659, 1183.5991579920799, 1155.679278028264, 1134.8007703600065, 1125.6139058489716, 1111.4358561095976, 1083.1164401426117, 1077.8426765611011, 1054.4436079567213, 1044.0967010685863, 1029.2577559225608, 1020.4825086758278, 1011.6296793497905, 992.9660486865683, 985.6099322877752, 972.9314775177612, 965.858549122301, 955.3287718642882, 944.5222067412491, 935.4749148732261, 924.7469902530968, 924.7366658078774, 910.3534093711067, 907.3493579245167, 896.0260540403498, 888.1492929163078, 884.4154761448242, 882.3677093254885, 867.2254470801095, 866.2505023458297, 1036.6645240449197, 945.4533961362409, 897.6544969503763, 870.2561088143582, 857.2455397764262, 848.1657261758853, 839.6670173980345, 834.69347409224, 829.358573422012, 828.1760381687493, 824.6701985659355, 816.8336406919888, 816.1360433044649, 808.7455106400423, 808.0559209729389, 797.7620520216988, 801.7417681222257, 797.0488315156573, 795.3636081725266, 790.8049926392154, 784.3400201389754, 779.9297441239776, 782.8669241024359, 781.8655662123177, 777.1953472575619, 771.1332784378154, 770.1846865189698, 764.8891128216763, 764.3410222693587, 764.3547203122554, 756.4214789778713, 758.728257469658, 755.6647007447053, 756.1608516488886, 748.6903264137286, 743.3765826956859, 743.210634298778, 741.8719579653961, 739.4917768348855, 736.2853853021999, 730.4966949484498, 731.8930175575151, 727.9944340465025, 727.2283088696963, 728.0296148687956, 725.4821769930842, 723.3169976986478, 715.0390412685016, 716.9335866545509, 714.1684925251164, 708.7743960039255, 708.2592691380269, 710.3003600937927], 'acc': [0.8875029846757243, 0.9211489113871357, 0.9324724418484213, 0.9382332416766545, 0.9419846594817342, 0.9446546096673466, 0.9467037472873723, 0.9481191286710371, 0.9494449388395889, 0.9504508161089025, 0.9514679530530277, 0.9522848826862033, 0.9529389877327387, 0.9536337759440114, 0.9542388942732374, 0.9549117895176673, 0.9554255218763223, 0.9558942435185223, 0.9563685006178851, 0.9568925493975414, 0.9572654732704214, 0.957682343481361, 0.9580450988849467, 0.9583851326609819, 0.9587435144678478, 0.9590562759911233, 0.9592604121022557, 0.9596028017112161, 0.9600445084806608, 0.9602019955088555, 0.9605432996257225, 0.9607751872647167, 0.9610122816150117, 0.961158041646035, 0.961304896914435, 0.9617044097535407, 0.9618055006983909, 0.961925284768117, 0.9621840447526658, 0.9623288851821548, 0.96255991026945, 0.9627262823079563, 0.9629600658427655, 0.9630091113012137, 0.9632356449361915, 0.9633326079842701, 0.9635001855649419, 0.963617874999353, 0.9637226915153034, 0.9638469863623538, 0.9640177090854519, 0.9641026670873948, 0.9614259708707457, 0.9625272199801257, 0.9633728077901058, 0.9638585089747731, 0.9641594256809883, 0.9644054166437409, 0.9645578097423225, 0.9646190383986031, 0.9647684722000994, 0.9648259754800556, 0.9648809857821907, 0.9650140187850829, 0.9649527694046559, 0.9651237117374821, 0.9651726368991426, 0.9653220459835883, 0.9653666199996875, 0.9653353981381959, 0.965353167282328, 0.965573596536227, 0.9656598436034496, 0.9656955547455083, 0.9656938837962786, 0.9657346294580815, 0.9657746347965002, 0.9659179816428602, 0.9659503506235123, 0.9659895237660422, 0.9660094233907313, 0.9660627802442435, 0.9661923297921087, 0.9661664287772977, 0.9662156779647529, 0.9662794448842307, 0.9663081460318257, 0.9664187052950971, 0.9664112938774235, 0.9664238217700106, 0.966485634328467, 0.9664968946655165, 0.9666136574377702, 0.9665909932625917, 0.9666517646404518, 0.9667057652702247, 0.9666948069979971, 0.9667367405065829, 0.966771687832048, 0.9668539486532085, 0.9668709271341476, 0.9669154366372517, 0.9669673659041728, 0.9670175181891585, 0.9670226542844887], 'mDice': [0.2588758522223741, 0.487426634360344, 0.570316521263507, 0.6134734057398457, 0.6408251844702395, 0.6616297803973783, 0.6771666173075066, 0.6898975074372385, 0.7012867266287387, 0.7100831427888915, 0.7195579980909224, 0.7270225191498093, 0.7338061439959184, 0.7403724439607311, 0.7462740440422151, 0.7527271818799148, 0.7574275669452444, 0.7624554249282158, 0.7666289425709104, 0.772171067458522, 0.7755880571224546, 0.7793538948106815, 0.7825809907149687, 0.7850757380221627, 0.7894993484374075, 0.7926960172012256, 0.7942405615774325, 0.7965799876303657, 0.8011110191946164, 0.8019936444043763, 0.8058226454440405, 0.8075112720491787, 0.8099537229922321, 0.8113260965780731, 0.8127998213389881, 0.8158988117405573, 0.8171829081823037, 0.8192383015794008, 0.82039630314369, 0.8222234268527646, 0.8239660249135052, 0.8254335223703263, 0.8273377467406795, 0.8273413807022229, 0.8297482371414664, 0.8302652384355614, 0.8321557472450892, 0.8334816611707162, 0.8341278018570175, 0.8344823678563956, 0.8369968539716294, 0.837221586005009, 0.8145551364910472, 0.8236685701330972, 0.8317674239615029, 0.8364193327292775, 0.8386991959850186, 0.8403058895117629, 0.8417013579253492, 0.8426201896569833, 0.8435240092052106, 0.8437327459664732, 0.8443868872348171, 0.8456865874298205, 0.8458014107965889, 0.8470929925507057, 0.8472032360531693, 0.8489887990545625, 0.848330836930791, 0.8490815924426892, 0.8493969534277221, 0.850198257041519, 0.8513081014614065, 0.8520651008560666, 0.8515276173011493, 0.8517521720333535, 0.8525320010457668, 0.8536518897815998, 0.8537646132313824, 0.8546852411401082, 0.8548152753648581, 0.8548153631697942, 0.85619251989447, 0.8557588275718595, 0.8563167958060651, 0.8562436687758685, 0.8575377124313254, 0.8584243340025046, 0.8584532557888934, 0.8586809782607643, 0.8591139339737159, 0.8596723007841585, 0.8606955882485062, 0.8604772196740057, 0.861141526824372, 0.8612782054266621, 0.8611442414797909, 0.8615742903455372, 0.8619670389907617, 0.863421016162494, 0.86308556590281, 0.8635843363756656, 0.8645119861666721, 0.8645964554209159, 0.8642782005152991]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.14s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.98s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:33,  1.60s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:55,  1.68s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:02,  1.71s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:19,  1.78s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:53,  1.69s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:07,  1.75s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:38,  1.87s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:54,  1.93s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:29,  1.85s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:53,  1.94s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:10,  2.01s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:17,  2.04s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:23,  2.07s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:28,  2.10s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:30,  2.11s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:27,  2.11s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<09:18,  2.09s/it]predicting train subjects:   6%|▋         | 18/285 [00:35<09:17,  2.09s/it]predicting train subjects:   7%|▋         | 19/285 [00:37<09:11,  2.07s/it]predicting train subjects:   7%|▋         | 20/285 [00:39<09:21,  2.12s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<09:18,  2.12s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:23,  2.14s/it]predicting train subjects:   8%|▊         | 23/285 [00:46<09:15,  2.12s/it]predicting train subjects:   8%|▊         | 24/285 [00:48<09:10,  2.11s/it]predicting train subjects:   9%|▉         | 25/285 [00:50<09:08,  2.11s/it]predicting train subjects:   9%|▉         | 26/285 [00:52<09:06,  2.11s/it]predicting train subjects:   9%|▉         | 27/285 [00:54<09:02,  2.10s/it]predicting train subjects:  10%|▉         | 28/285 [00:56<08:38,  2.02s/it]predicting train subjects:  10%|█         | 29/285 [00:58<08:23,  1.97s/it]predicting train subjects:  11%|█         | 30/285 [01:00<08:18,  1.95s/it]predicting train subjects:  11%|█         | 31/285 [01:02<08:10,  1.93s/it]predicting train subjects:  11%|█         | 32/285 [01:03<08:06,  1.92s/it]predicting train subjects:  12%|█▏        | 33/285 [01:05<08:05,  1.93s/it]predicting train subjects:  12%|█▏        | 34/285 [01:07<08:06,  1.94s/it]predicting train subjects:  12%|█▏        | 35/285 [01:09<08:10,  1.96s/it]predicting train subjects:  13%|█▎        | 36/285 [01:11<08:07,  1.96s/it]predicting train subjects:  13%|█▎        | 37/285 [01:13<07:53,  1.91s/it]predicting train subjects:  13%|█▎        | 38/285 [01:15<07:50,  1.91s/it]predicting train subjects:  14%|█▎        | 39/285 [01:17<07:53,  1.92s/it]predicting train subjects:  14%|█▍        | 40/285 [01:19<07:46,  1.90s/it]predicting train subjects:  14%|█▍        | 41/285 [01:21<07:44,  1.90s/it]predicting train subjects:  15%|█▍        | 42/285 [01:23<07:40,  1.90s/it]predicting train subjects:  15%|█▌        | 43/285 [01:25<07:47,  1.93s/it]predicting train subjects:  15%|█▌        | 44/285 [01:27<07:45,  1.93s/it]predicting train subjects:  16%|█▌        | 45/285 [01:28<07:38,  1.91s/it]predicting train subjects:  16%|█▌        | 46/285 [01:30<07:19,  1.84s/it]predicting train subjects:  16%|█▋        | 47/285 [01:32<07:08,  1.80s/it]predicting train subjects:  17%|█▋        | 48/285 [01:33<06:53,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:35<06:56,  1.76s/it]predicting train subjects:  18%|█▊        | 50/285 [01:37<06:50,  1.75s/it]predicting train subjects:  18%|█▊        | 51/285 [01:39<06:48,  1.74s/it]predicting train subjects:  18%|█▊        | 52/285 [01:40<06:43,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:42<06:38,  1.72s/it]predicting train subjects:  19%|█▉        | 54/285 [01:44<06:34,  1.71s/it]predicting train subjects:  19%|█▉        | 55/285 [01:46<06:36,  1.72s/it]predicting train subjects:  20%|█▉        | 56/285 [01:47<06:28,  1.69s/it]predicting train subjects:  20%|██        | 57/285 [01:49<06:23,  1.68s/it]predicting train subjects:  20%|██        | 58/285 [01:50<06:20,  1.68s/it]predicting train subjects:  21%|██        | 59/285 [01:52<06:17,  1.67s/it]predicting train subjects:  21%|██        | 60/285 [01:54<06:20,  1.69s/it]predicting train subjects:  21%|██▏       | 61/285 [01:56<06:15,  1.68s/it]predicting train subjects:  22%|██▏       | 62/285 [01:57<06:10,  1.66s/it]predicting train subjects:  22%|██▏       | 63/285 [01:59<06:07,  1.66s/it]predicting train subjects:  22%|██▏       | 64/285 [02:01<06:13,  1.69s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<06:24,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [02:04<06:31,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [02:06<06:31,  1.80s/it]predicting train subjects:  24%|██▍       | 68/285 [02:08<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:10<06:30,  1.81s/it]predicting train subjects:  25%|██▍       | 70/285 [02:12<06:31,  1.82s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:20,  1.78s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:14,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:08,  1.74s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:01,  1.72s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<06:05,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:25<06:02,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:27<06:05,  1.77s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:00,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<05:55,  1.74s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<05:54,  1.75s/it]predicting train subjects:  29%|██▉       | 83/285 [02:34<05:51,  1.74s/it]predicting train subjects:  29%|██▉       | 84/285 [02:36<05:48,  1.74s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<05:56,  1.78s/it]predicting train subjects:  30%|███       | 86/285 [02:40<05:59,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:42<06:02,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:44<06:14,  1.90s/it]predicting train subjects:  31%|███       | 89/285 [02:46<06:20,  1.94s/it]predicting train subjects:  32%|███▏      | 90/285 [02:48<06:16,  1.93s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<06:19,  1.96s/it]predicting train subjects:  32%|███▏      | 92/285 [02:51<06:16,  1.95s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<06:15,  1.96s/it]predicting train subjects:  33%|███▎      | 94/285 [02:55<06:17,  1.98s/it]predicting train subjects:  33%|███▎      | 95/285 [02:57<06:12,  1.96s/it]predicting train subjects:  34%|███▎      | 96/285 [02:59<06:09,  1.95s/it]predicting train subjects:  34%|███▍      | 97/285 [03:01<06:16,  2.00s/it]predicting train subjects:  34%|███▍      | 98/285 [03:03<06:05,  1.96s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<06:02,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [03:07<05:59,  1.94s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:54,  1.93s/it]predicting train subjects:  36%|███▌      | 102/285 [03:11<05:51,  1.92s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:44,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:38,  1.87s/it]predicting train subjects:  37%|███▋      | 105/285 [03:16<05:36,  1.87s/it]predicting train subjects:  37%|███▋      | 106/285 [03:18<05:33,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:20<05:36,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:32,  1.88s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:27,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:26<05:22,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:23,  1.86s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:23,  1.87s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:21,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:33<05:23,  1.89s/it]predicting train subjects:  40%|████      | 115/285 [03:35<05:22,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:37<05:19,  1.89s/it]predicting train subjects:  41%|████      | 117/285 [03:39<05:20,  1.91s/it]predicting train subjects:  41%|████▏     | 118/285 [03:41<05:16,  1.89s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<05:12,  1.88s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:11,  1.89s/it]predicting train subjects:  42%|████▏     | 121/285 [03:46<05:00,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:48<04:50,  1.78s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:39,  1.72s/it]predicting train subjects:  44%|████▎     | 124/285 [03:51<04:40,  1.74s/it]predicting train subjects:  44%|████▍     | 125/285 [03:53<04:39,  1.75s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:36,  1.74s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:34,  1.74s/it]predicting train subjects:  45%|████▍     | 128/285 [03:58<04:31,  1.73s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:30,  1.73s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:22,  1.69s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:16,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:12,  1.65s/it]predicting train subjects:  47%|████▋     | 133/285 [04:07<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<04:13,  1.68s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<04:13,  1.69s/it]predicting train subjects:  48%|████▊     | 136/285 [04:12<04:11,  1.69s/it]predicting train subjects:  48%|████▊     | 137/285 [04:13<04:11,  1.70s/it]predicting train subjects:  48%|████▊     | 138/285 [04:15<04:10,  1.70s/it]predicting train subjects:  49%|████▉     | 139/285 [04:17<04:12,  1.73s/it]predicting train subjects:  49%|████▉     | 140/285 [04:19<04:06,  1.70s/it]predicting train subjects:  49%|████▉     | 141/285 [04:20<04:00,  1.67s/it]predicting train subjects:  50%|████▉     | 142/285 [04:22<03:51,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:23<03:43,  1.58s/it]predicting train subjects:  51%|█████     | 144/285 [04:25<03:41,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:26<03:38,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:28<03:36,  1.56s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:29<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:31<03:31,  1.55s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:33<03:35,  1.59s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:34<03:34,  1.59s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:36<03:28,  1.55s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:37<03:25,  1.54s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:39<03:25,  1.55s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:40<03:27,  1.59s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:42<03:29,  1.61s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:44<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:45<03:23,  1.59s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:47<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:48<03:19,  1.58s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:50<03:15,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:51<03:11,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:53<03:08,  1.53s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:54<03:05,  1.52s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:56<03:02,  1.51s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:57<03:01,  1.51s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:59<02:59,  1.51s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<02:57,  1.50s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:02<02:53,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:05<02:50,  1.48s/it]predicting train subjects:  60%|██████    | 171/285 [05:06<02:50,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [05:08<02:49,  1.50s/it]predicting train subjects:  61%|██████    | 173/285 [05:09<02:45,  1.48s/it]predicting train subjects:  61%|██████    | 174/285 [05:11<02:44,  1.48s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:12<02:43,  1.48s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:14<02:39,  1.46s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:15<02:38,  1.47s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:17<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:18<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:19<02:34,  1.47s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:21<02:35,  1.50s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:23<02:33,  1.49s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:24<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:25<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:27<02:25,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:28<02:23,  1.45s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:30<02:24,  1.47s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:31<02:22,  1.47s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:33<02:20,  1.47s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:34<02:18,  1.46s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:36<02:16,  1.45s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:37<02:17,  1.48s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:39<02:18,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:40<02:14,  1.48s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:42<02:14,  1.49s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:43<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:45<02:24,  1.64s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:47<02:26,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:49<02:27,  1.72s/it]predicting train subjects:  70%|███████   | 200/285 [05:51<02:26,  1.72s/it]predicting train subjects:  71%|███████   | 201/285 [05:52<02:24,  1.72s/it]predicting train subjects:  71%|███████   | 202/285 [05:54<02:24,  1.74s/it]predicting train subjects:  71%|███████   | 203/285 [05:56<02:23,  1.75s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:57<02:20,  1.73s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:59<02:20,  1.76s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:01<02:18,  1.75s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:03<02:15,  1.74s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:05<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:06<02:12,  1.74s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:08<02:10,  1.74s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:10<02:10,  1.76s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:12<02:08,  1.76s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:13<02:05,  1.75s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:15<01:58,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:16<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:18<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:43,  1.52s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:21<01:41,  1.52s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:41,  1.54s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:24<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:38,  1.54s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:38,  1.56s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:28<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:30<01:33,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:33<01:30,  1.53s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:34<01:27,  1.51s/it]predicting train subjects:  80%|████████  | 228/285 [06:36<01:24,  1.49s/it]predicting train subjects:  80%|████████  | 229/285 [06:37<01:24,  1.51s/it]predicting train subjects:  81%|████████  | 230/285 [06:39<01:23,  1.52s/it]predicting train subjects:  81%|████████  | 231/285 [06:40<01:21,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:27,  1.66s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:45<01:34,  1.83s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:47<01:36,  1.89s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:49<01:38,  1.97s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:51<01:42,  2.09s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:54<01:43,  2.17s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:56<01:41,  2.15s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:58<01:40,  2.19s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:00<01:39,  2.21s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:02<01:36,  2.19s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:05<01:33,  2.18s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:07<01:31,  2.17s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:09<01:28,  2.16s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:11<01:28,  2.21s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:13<01:27,  2.24s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:16<01:23,  2.19s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:18<01:21,  2.21s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:20<01:21,  2.26s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:22<01:15,  2.17s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:24<01:10,  2.06s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:26<01:05,  1.97s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:27<01:00,  1.88s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:29<00:56,  1.83s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:31<00:54,  1.82s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:33<00:52,  1.80s/it]predicting train subjects:  90%|█████████ | 257/285 [07:34<00:47,  1.70s/it]predicting train subjects:  91%|█████████ | 258/285 [07:36<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [07:37<00:44,  1.72s/it]predicting train subjects:  91%|█████████ | 260/285 [07:39<00:43,  1.73s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:41<00:40,  1.70s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:42<00:38,  1.67s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:44<00:37,  1.72s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:46<00:35,  1.71s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:48<00:33,  1.69s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:50<00:33,  1.77s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:51<00:31,  1.77s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:54<00:32,  1.92s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:56<00:30,  1.93s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:58<00:30,  2.04s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:00<00:28,  2.07s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:02<00:27,  2.09s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:05<00:26,  2.17s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:07<00:24,  2.25s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:09<00:22,  2.30s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:12<00:20,  2.30s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:14<00:18,  2.31s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:16<00:15,  2.27s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:19<00:14,  2.34s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:21<00:11,  2.30s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:23<00:09,  2.28s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:25<00:06,  2.29s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:28<00:04,  2.28s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:30<00:02,  2.26s/it]predicting train subjects: 100%|██████████| 285/285 [08:32<00:00,  2.31s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:36,  2.03s/it]Loading train:   1%|          | 2/285 [00:04<09:34,  2.03s/it]Loading train:   1%|          | 3/285 [00:05<08:51,  1.88s/it]Loading train:   1%|▏         | 4/285 [00:07<09:16,  1.98s/it]Loading train:   2%|▏         | 5/285 [00:09<08:47,  1.88s/it]Loading train:   2%|▏         | 6/285 [00:11<09:22,  2.02s/it]Loading train:   2%|▏         | 7/285 [00:13<09:36,  2.07s/it]Loading train:   3%|▎         | 8/285 [00:15<09:22,  2.03s/it]Loading train:   3%|▎         | 9/285 [00:17<08:59,  1.96s/it]Loading train:   4%|▎         | 10/285 [00:19<08:19,  1.81s/it]Loading train:   4%|▍         | 11/285 [00:20<07:39,  1.68s/it]Loading train:   4%|▍         | 12/285 [00:21<07:05,  1.56s/it]Loading train:   5%|▍         | 13/285 [00:23<06:44,  1.49s/it]Loading train:   5%|▍         | 14/285 [00:25<07:14,  1.60s/it]Loading train:   5%|▌         | 15/285 [00:26<07:28,  1.66s/it]Loading train:   6%|▌         | 16/285 [00:28<07:37,  1.70s/it]Loading train:   6%|▌         | 17/285 [00:30<07:37,  1.71s/it]Loading train:   6%|▋         | 18/285 [00:32<07:32,  1.70s/it]Loading train:   7%|▋         | 19/285 [00:33<06:53,  1.55s/it]Loading train:   7%|▋         | 20/285 [00:34<06:47,  1.54s/it]Loading train:   7%|▋         | 21/285 [00:36<06:59,  1.59s/it]Loading train:   8%|▊         | 22/285 [00:38<07:05,  1.62s/it]Loading train:   8%|▊         | 23/285 [00:39<06:59,  1.60s/it]Loading train:   8%|▊         | 24/285 [00:41<07:08,  1.64s/it]Loading train:   9%|▉         | 25/285 [00:42<06:43,  1.55s/it]Loading train:   9%|▉         | 26/285 [00:44<06:51,  1.59s/it]Loading train:   9%|▉         | 27/285 [00:45<06:35,  1.53s/it]Loading train:  10%|▉         | 28/285 [00:47<06:59,  1.63s/it]Loading train:  10%|█         | 29/285 [00:49<06:40,  1.57s/it]Loading train:  11%|█         | 30/285 [00:50<06:12,  1.46s/it]Loading train:  11%|█         | 31/285 [00:51<06:25,  1.52s/it]Loading train:  11%|█         | 32/285 [00:53<06:13,  1.48s/it]Loading train:  12%|█▏        | 33/285 [00:55<06:30,  1.55s/it]Loading train:  12%|█▏        | 34/285 [00:56<06:19,  1.51s/it]Loading train:  12%|█▏        | 35/285 [00:57<06:01,  1.45s/it]Loading train:  13%|█▎        | 36/285 [00:59<05:41,  1.37s/it]Loading train:  13%|█▎        | 37/285 [01:00<05:45,  1.39s/it]Loading train:  13%|█▎        | 38/285 [01:01<05:26,  1.32s/it]Loading train:  14%|█▎        | 39/285 [01:02<05:20,  1.30s/it]Loading train:  14%|█▍        | 40/285 [01:04<05:52,  1.44s/it]Loading train:  14%|█▍        | 41/285 [01:06<06:09,  1.52s/it]Loading train:  15%|█▍        | 42/285 [01:08<06:24,  1.58s/it]Loading train:  15%|█▌        | 43/285 [01:09<06:07,  1.52s/it]Loading train:  15%|█▌        | 44/285 [01:10<05:37,  1.40s/it]Loading train:  16%|█▌        | 45/285 [01:11<05:35,  1.40s/it]Loading train:  16%|█▌        | 46/285 [01:13<05:37,  1.41s/it]Loading train:  16%|█▋        | 47/285 [01:14<05:30,  1.39s/it]Loading train:  17%|█▋        | 48/285 [01:15<05:10,  1.31s/it]Loading train:  17%|█▋        | 49/285 [01:17<04:59,  1.27s/it]Loading train:  18%|█▊        | 50/285 [01:18<04:48,  1.23s/it]Loading train:  18%|█▊        | 51/285 [01:19<04:40,  1.20s/it]Loading train:  18%|█▊        | 52/285 [01:20<04:59,  1.28s/it]Loading train:  19%|█▊        | 53/285 [01:21<04:39,  1.21s/it]Loading train:  19%|█▉        | 54/285 [01:23<04:50,  1.26s/it]Loading train:  19%|█▉        | 55/285 [01:24<04:42,  1.23s/it]Loading train:  20%|█▉        | 56/285 [01:25<04:45,  1.25s/it]Loading train:  20%|██        | 57/285 [01:26<04:46,  1.25s/it]Loading train:  20%|██        | 58/285 [01:27<04:30,  1.19s/it]Loading train:  21%|██        | 59/285 [01:29<04:40,  1.24s/it]Loading train:  21%|██        | 60/285 [01:30<04:28,  1.19s/it]Loading train:  21%|██▏       | 61/285 [01:31<04:16,  1.15s/it]Loading train:  22%|██▏       | 62/285 [01:32<04:22,  1.18s/it]Loading train:  22%|██▏       | 63/285 [01:34<04:39,  1.26s/it]Loading train:  22%|██▏       | 64/285 [01:35<05:03,  1.37s/it]Loading train:  23%|██▎       | 65/285 [01:37<05:36,  1.53s/it]Loading train:  23%|██▎       | 66/285 [01:39<06:24,  1.76s/it]Loading train:  24%|██▎       | 67/285 [01:41<06:14,  1.72s/it]Loading train:  24%|██▍       | 68/285 [01:42<05:33,  1.54s/it]Loading train:  24%|██▍       | 69/285 [01:43<05:17,  1.47s/it]Loading train:  25%|██▍       | 70/285 [01:45<04:53,  1.37s/it]Loading train:  25%|██▍       | 71/285 [01:46<04:42,  1.32s/it]Loading train:  25%|██▌       | 72/285 [01:47<04:31,  1.27s/it]Loading train:  26%|██▌       | 73/285 [01:48<04:17,  1.21s/it]Loading train:  26%|██▌       | 74/285 [01:49<04:29,  1.28s/it]Loading train:  26%|██▋       | 75/285 [01:51<05:05,  1.45s/it]Loading train:  27%|██▋       | 76/285 [01:53<04:48,  1.38s/it]Loading train:  27%|██▋       | 77/285 [01:54<04:33,  1.32s/it]Loading train:  27%|██▋       | 78/285 [01:55<04:56,  1.43s/it]Loading train:  28%|██▊       | 79/285 [01:57<04:42,  1.37s/it]Loading train:  28%|██▊       | 80/285 [01:58<04:23,  1.28s/it]Loading train:  28%|██▊       | 81/285 [01:59<04:35,  1.35s/it]Loading train:  29%|██▉       | 82/285 [02:01<04:44,  1.40s/it]Loading train:  29%|██▉       | 83/285 [02:03<05:12,  1.55s/it]Loading train:  29%|██▉       | 84/285 [02:04<04:54,  1.46s/it]Loading train:  30%|██▉       | 85/285 [02:05<04:47,  1.44s/it]Loading train:  30%|███       | 86/285 [02:07<04:39,  1.41s/it]Loading train:  31%|███       | 87/285 [02:08<04:27,  1.35s/it]Loading train:  31%|███       | 88/285 [02:09<04:39,  1.42s/it]Loading train:  31%|███       | 89/285 [02:11<04:48,  1.47s/it]Loading train:  32%|███▏      | 90/285 [02:12<04:47,  1.47s/it]Loading train:  32%|███▏      | 91/285 [02:14<04:33,  1.41s/it]Loading train:  32%|███▏      | 92/285 [02:15<04:23,  1.37s/it]Loading train:  33%|███▎      | 93/285 [02:16<04:14,  1.33s/it]Loading train:  33%|███▎      | 94/285 [02:17<04:07,  1.29s/it]Loading train:  33%|███▎      | 95/285 [02:19<03:59,  1.26s/it]Loading train:  34%|███▎      | 96/285 [02:20<03:56,  1.25s/it]Loading train:  34%|███▍      | 97/285 [02:22<04:15,  1.36s/it]Loading train:  34%|███▍      | 98/285 [02:23<04:29,  1.44s/it]Loading train:  35%|███▍      | 99/285 [02:25<04:54,  1.58s/it]Loading train:  35%|███▌      | 100/285 [02:27<05:05,  1.65s/it]Loading train:  35%|███▌      | 101/285 [02:28<04:50,  1.58s/it]Loading train:  36%|███▌      | 102/285 [02:29<04:23,  1.44s/it]Loading train:  36%|███▌      | 103/285 [02:31<04:25,  1.46s/it]Loading train:  36%|███▋      | 104/285 [02:32<04:31,  1.50s/it]Loading train:  37%|███▋      | 105/285 [02:34<04:43,  1.57s/it]Loading train:  37%|███▋      | 106/285 [02:35<04:24,  1.48s/it]Loading train:  38%|███▊      | 107/285 [02:37<04:40,  1.57s/it]Loading train:  38%|███▊      | 108/285 [02:39<04:29,  1.52s/it]Loading train:  38%|███▊      | 109/285 [02:40<04:12,  1.44s/it]Loading train:  39%|███▊      | 110/285 [02:41<03:59,  1.37s/it]Loading train:  39%|███▉      | 111/285 [02:43<04:10,  1.44s/it]Loading train:  39%|███▉      | 112/285 [02:44<04:00,  1.39s/it]Loading train:  40%|███▉      | 113/285 [02:45<03:50,  1.34s/it]Loading train:  40%|████      | 114/285 [02:47<03:58,  1.40s/it]Loading train:  40%|████      | 115/285 [02:48<03:54,  1.38s/it]Loading train:  41%|████      | 116/285 [02:50<04:05,  1.45s/it]Loading train:  41%|████      | 117/285 [02:51<04:13,  1.51s/it]Loading train:  41%|████▏     | 118/285 [02:53<04:03,  1.46s/it]Loading train:  42%|████▏     | 119/285 [02:54<03:43,  1.35s/it]Loading train:  42%|████▏     | 120/285 [02:55<03:46,  1.37s/it]Loading train:  42%|████▏     | 121/285 [02:57<04:01,  1.48s/it]Loading train:  43%|████▎     | 122/285 [02:58<04:04,  1.50s/it]Loading train:  43%|████▎     | 123/285 [03:00<04:09,  1.54s/it]Loading train:  44%|████▎     | 124/285 [03:01<03:44,  1.39s/it]Loading train:  44%|████▍     | 125/285 [03:02<03:31,  1.32s/it]Loading train:  44%|████▍     | 126/285 [03:04<03:29,  1.32s/it]Loading train:  45%|████▍     | 127/285 [03:05<03:16,  1.24s/it]Loading train:  45%|████▍     | 128/285 [03:06<03:02,  1.16s/it]Loading train:  45%|████▌     | 129/285 [03:07<03:14,  1.25s/it]Loading train:  46%|████▌     | 130/285 [03:09<03:19,  1.29s/it]Loading train:  46%|████▌     | 131/285 [03:09<03:03,  1.19s/it]Loading train:  46%|████▋     | 132/285 [03:11<02:59,  1.18s/it]Loading train:  47%|████▋     | 133/285 [03:12<02:57,  1.17s/it]Loading train:  47%|████▋     | 134/285 [03:13<02:58,  1.18s/it]Loading train:  47%|████▋     | 135/285 [03:14<02:51,  1.14s/it]Loading train:  48%|████▊     | 136/285 [03:16<03:05,  1.24s/it]Loading train:  48%|████▊     | 137/285 [03:17<03:15,  1.32s/it]Loading train:  48%|████▊     | 138/285 [03:18<03:04,  1.26s/it]Loading train:  49%|████▉     | 139/285 [03:19<02:57,  1.22s/it]Loading train:  49%|████▉     | 140/285 [03:20<02:54,  1.21s/it]Loading train:  49%|████▉     | 141/285 [03:22<02:56,  1.23s/it]Loading train:  50%|████▉     | 142/285 [03:23<02:50,  1.19s/it]Loading train:  50%|█████     | 143/285 [03:24<02:44,  1.16s/it]Loading train:  51%|█████     | 144/285 [03:25<03:01,  1.29s/it]Loading train:  51%|█████     | 145/285 [03:27<02:50,  1.22s/it]Loading train:  51%|█████     | 146/285 [03:28<02:59,  1.29s/it]Loading train:  52%|█████▏    | 147/285 [03:29<03:00,  1.30s/it]Loading train:  52%|█████▏    | 148/285 [03:30<02:48,  1.23s/it]Loading train:  52%|█████▏    | 149/285 [03:32<02:48,  1.24s/it]Loading train:  53%|█████▎    | 150/285 [03:33<02:53,  1.28s/it]Loading train:  53%|█████▎    | 151/285 [03:34<02:40,  1.20s/it]Loading train:  53%|█████▎    | 152/285 [03:35<02:34,  1.16s/it]Loading train:  54%|█████▎    | 153/285 [03:36<02:28,  1.12s/it]Loading train:  54%|█████▍    | 154/285 [03:37<02:23,  1.10s/it]Loading train:  54%|█████▍    | 155/285 [03:38<02:24,  1.11s/it]Loading train:  55%|█████▍    | 156/285 [03:40<02:28,  1.15s/it]Loading train:  55%|█████▌    | 157/285 [03:41<02:36,  1.22s/it]Loading train:  55%|█████▌    | 158/285 [03:43<02:50,  1.34s/it]Loading train:  56%|█████▌    | 159/285 [03:44<02:57,  1.41s/it]Loading train:  56%|█████▌    | 160/285 [03:46<03:16,  1.57s/it]Loading train:  56%|█████▋    | 161/285 [03:48<03:15,  1.58s/it]Loading train:  57%|█████▋    | 162/285 [03:49<03:08,  1.53s/it]Loading train:  57%|█████▋    | 163/285 [03:50<02:47,  1.37s/it]Loading train:  58%|█████▊    | 164/285 [03:52<02:54,  1.44s/it]Loading train:  58%|█████▊    | 165/285 [03:53<02:57,  1.48s/it]Loading train:  58%|█████▊    | 166/285 [03:54<02:37,  1.32s/it]Loading train:  59%|█████▊    | 167/285 [03:55<02:32,  1.29s/it]Loading train:  59%|█████▉    | 168/285 [03:57<02:33,  1.32s/it]Loading train:  59%|█████▉    | 169/285 [03:59<02:50,  1.47s/it]Loading train:  60%|█████▉    | 170/285 [04:00<02:36,  1.36s/it]Loading train:  60%|██████    | 171/285 [04:01<02:27,  1.29s/it]Loading train:  60%|██████    | 172/285 [04:02<02:19,  1.23s/it]Loading train:  61%|██████    | 173/285 [04:03<02:16,  1.22s/it]Loading train:  61%|██████    | 174/285 [04:04<02:14,  1.21s/it]Loading train:  61%|██████▏   | 175/285 [04:06<02:20,  1.28s/it]Loading train:  62%|██████▏   | 176/285 [04:07<02:32,  1.40s/it]Loading train:  62%|██████▏   | 177/285 [04:09<02:25,  1.35s/it]Loading train:  62%|██████▏   | 178/285 [04:10<02:20,  1.31s/it]Loading train:  63%|██████▎   | 179/285 [04:11<02:20,  1.33s/it]Loading train:  63%|██████▎   | 180/285 [04:12<02:10,  1.24s/it]Loading train:  64%|██████▎   | 181/285 [04:13<02:04,  1.20s/it]Loading train:  64%|██████▍   | 182/285 [04:15<02:07,  1.23s/it]Loading train:  64%|██████▍   | 183/285 [04:16<02:15,  1.32s/it]Loading train:  65%|██████▍   | 184/285 [04:17<02:04,  1.23s/it]Loading train:  65%|██████▍   | 185/285 [04:18<01:57,  1.17s/it]Loading train:  65%|██████▌   | 186/285 [04:20<01:57,  1.19s/it]Loading train:  66%|██████▌   | 187/285 [04:21<01:58,  1.21s/it]Loading train:  66%|██████▌   | 188/285 [04:22<01:51,  1.15s/it]Loading train:  66%|██████▋   | 189/285 [04:23<01:42,  1.07s/it]Loading train:  67%|██████▋   | 190/285 [04:24<01:37,  1.02s/it]Loading train:  67%|██████▋   | 191/285 [04:25<01:42,  1.09s/it]Loading train:  67%|██████▋   | 192/285 [04:26<01:41,  1.09s/it]Loading train:  68%|██████▊   | 193/285 [04:27<01:45,  1.14s/it]Loading train:  68%|██████▊   | 194/285 [04:28<01:46,  1.17s/it]Loading train:  68%|██████▊   | 195/285 [04:30<01:52,  1.25s/it]Loading train:  69%|██████▉   | 196/285 [04:32<02:02,  1.37s/it]Loading train:  69%|██████▉   | 197/285 [04:33<02:08,  1.46s/it]Loading train:  69%|██████▉   | 198/285 [04:34<01:58,  1.37s/it]Loading train:  70%|██████▉   | 199/285 [04:36<01:55,  1.34s/it]Loading train:  70%|███████   | 200/285 [04:37<02:00,  1.42s/it]Loading train:  71%|███████   | 201/285 [04:39<02:01,  1.45s/it]Loading train:  71%|███████   | 202/285 [04:40<02:03,  1.49s/it]Loading train:  71%|███████   | 203/285 [04:41<01:52,  1.37s/it]Loading train:  72%|███████▏  | 204/285 [04:43<01:56,  1.44s/it]Loading train:  72%|███████▏  | 205/285 [04:45<02:12,  1.66s/it]Loading train:  72%|███████▏  | 206/285 [04:46<02:00,  1.53s/it]Loading train:  73%|███████▎  | 207/285 [04:48<01:49,  1.40s/it]Loading train:  73%|███████▎  | 208/285 [04:49<01:49,  1.42s/it]Loading train:  73%|███████▎  | 209/285 [04:50<01:36,  1.27s/it]Loading train:  74%|███████▎  | 210/285 [04:51<01:35,  1.27s/it]Loading train:  74%|███████▍  | 211/285 [04:53<01:38,  1.33s/it]Loading train:  74%|███████▍  | 212/285 [04:54<01:38,  1.35s/it]Loading train:  75%|███████▍  | 213/285 [04:55<01:33,  1.29s/it]Loading train:  75%|███████▌  | 214/285 [04:57<01:33,  1.31s/it]Loading train:  75%|███████▌  | 215/285 [04:58<01:34,  1.34s/it]Loading train:  76%|███████▌  | 216/285 [05:00<01:39,  1.44s/it]Loading train:  76%|███████▌  | 217/285 [05:01<01:38,  1.46s/it]Loading train:  76%|███████▋  | 218/285 [05:03<01:45,  1.58s/it]Loading train:  77%|███████▋  | 219/285 [05:04<01:33,  1.41s/it]Loading train:  77%|███████▋  | 220/285 [05:05<01:27,  1.34s/it]Loading train:  78%|███████▊  | 221/285 [05:07<01:26,  1.35s/it]Loading train:  78%|███████▊  | 222/285 [05:08<01:30,  1.43s/it]Loading train:  78%|███████▊  | 223/285 [05:10<01:27,  1.41s/it]Loading train:  79%|███████▊  | 224/285 [05:11<01:21,  1.33s/it]Loading train:  79%|███████▉  | 225/285 [05:12<01:24,  1.42s/it]Loading train:  79%|███████▉  | 226/285 [05:14<01:23,  1.41s/it]Loading train:  80%|███████▉  | 227/285 [05:15<01:24,  1.46s/it]Loading train:  80%|████████  | 228/285 [05:16<01:18,  1.37s/it]Loading train:  80%|████████  | 229/285 [05:18<01:13,  1.31s/it]Loading train:  81%|████████  | 230/285 [05:19<01:09,  1.26s/it]Loading train:  81%|████████  | 231/285 [05:20<01:05,  1.21s/it]Loading train:  81%|████████▏ | 232/285 [05:21<01:09,  1.31s/it]Loading train:  82%|████████▏ | 233/285 [05:23<01:12,  1.40s/it]Loading train:  82%|████████▏ | 234/285 [05:24<01:10,  1.38s/it]Loading train:  82%|████████▏ | 235/285 [05:26<01:09,  1.39s/it]Loading train:  83%|████████▎ | 236/285 [05:27<01:07,  1.38s/it]Loading train:  83%|████████▎ | 237/285 [05:28<01:04,  1.34s/it]Loading train:  84%|████████▎ | 238/285 [05:30<01:08,  1.46s/it]Loading train:  84%|████████▍ | 239/285 [05:32<01:06,  1.44s/it]Loading train:  84%|████████▍ | 240/285 [05:33<01:02,  1.39s/it]Loading train:  85%|████████▍ | 241/285 [05:34<00:59,  1.35s/it]Loading train:  85%|████████▍ | 242/285 [05:35<00:58,  1.35s/it]Loading train:  85%|████████▌ | 243/285 [05:37<00:57,  1.37s/it]Loading train:  86%|████████▌ | 244/285 [05:39<01:02,  1.52s/it]Loading train:  86%|████████▌ | 245/285 [05:40<01:03,  1.59s/it]Loading train:  86%|████████▋ | 246/285 [05:42<01:06,  1.69s/it]Loading train:  87%|████████▋ | 247/285 [05:44<01:01,  1.63s/it]Loading train:  87%|████████▋ | 248/285 [05:45<00:55,  1.50s/it]Loading train:  87%|████████▋ | 249/285 [05:46<00:51,  1.43s/it]Loading train:  88%|████████▊ | 250/285 [05:47<00:45,  1.31s/it]Loading train:  88%|████████▊ | 251/285 [05:48<00:41,  1.23s/it]Loading train:  88%|████████▊ | 252/285 [05:50<00:43,  1.32s/it]Loading train:  89%|████████▉ | 253/285 [05:52<00:44,  1.40s/it]Loading train:  89%|████████▉ | 254/285 [05:53<00:42,  1.37s/it]Loading train:  89%|████████▉ | 255/285 [05:54<00:39,  1.33s/it]Loading train:  90%|████████▉ | 256/285 [05:55<00:35,  1.22s/it]Loading train:  90%|█████████ | 257/285 [05:56<00:32,  1.16s/it]Loading train:  91%|█████████ | 258/285 [05:57<00:31,  1.16s/it]Loading train:  91%|█████████ | 259/285 [05:58<00:30,  1.18s/it]Loading train:  91%|█████████ | 260/285 [05:59<00:27,  1.10s/it]Loading train:  92%|█████████▏| 261/285 [06:00<00:26,  1.09s/it]Loading train:  92%|█████████▏| 262/285 [06:01<00:24,  1.07s/it]Loading train:  92%|█████████▏| 263/285 [06:03<00:24,  1.12s/it]Loading train:  93%|█████████▎| 264/285 [06:04<00:24,  1.19s/it]Loading train:  93%|█████████▎| 265/285 [06:06<00:26,  1.34s/it]Loading train:  93%|█████████▎| 266/285 [06:07<00:25,  1.35s/it]Loading train:  94%|█████████▎| 267/285 [06:08<00:23,  1.33s/it]Loading train:  94%|█████████▍| 268/285 [06:10<00:24,  1.46s/it]Loading train:  94%|█████████▍| 269/285 [06:11<00:22,  1.43s/it]Loading train:  95%|█████████▍| 270/285 [06:13<00:20,  1.35s/it]Loading train:  95%|█████████▌| 271/285 [06:14<00:18,  1.34s/it]Loading train:  95%|█████████▌| 272/285 [06:15<00:17,  1.33s/it]Loading train:  96%|█████████▌| 273/285 [06:17<00:17,  1.44s/it]Loading train:  96%|█████████▌| 274/285 [06:19<00:16,  1.48s/it]Loading train:  96%|█████████▋| 275/285 [06:20<00:14,  1.46s/it]Loading train:  97%|█████████▋| 276/285 [06:22<00:13,  1.48s/it]Loading train:  97%|█████████▋| 277/285 [06:23<00:11,  1.45s/it]Loading train:  98%|█████████▊| 278/285 [06:24<00:09,  1.36s/it]Loading train:  98%|█████████▊| 279/285 [06:25<00:08,  1.36s/it]Loading train:  98%|█████████▊| 280/285 [06:27<00:06,  1.38s/it]Loading train:  99%|█████████▊| 281/285 [06:28<00:05,  1.43s/it]Loading train:  99%|█████████▉| 282/285 [06:30<00:04,  1.37s/it]Loading train:  99%|█████████▉| 283/285 [06:31<00:02,  1.33s/it]Loading train: 100%|█████████▉| 284/285 [06:32<00:01,  1.29s/it]Loading train: 100%|██████████| 285/285 [06:33<00:00,  1.22s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:12, 22.25it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:14, 19.29it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:13, 20.71it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:14, 19.32it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:15, 17.66it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:16, 16.02it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:16, 16.21it/s]concatenating: train:   6%|▋         | 18/285 [00:01<00:17, 15.58it/s]concatenating: train:   7%|▋         | 20/285 [00:01<00:16, 16.36it/s]concatenating: train:   9%|▉         | 26/285 [00:01<00:12, 20.66it/s]concatenating: train:  11%|█         | 32/285 [00:01<00:09, 25.46it/s]concatenating: train:  15%|█▌        | 44/285 [00:01<00:07, 33.30it/s]concatenating: train:  25%|██▍       | 71/285 [00:01<00:04, 45.16it/s]concatenating: train:  35%|███▌      | 101/285 [00:01<00:03, 60.55it/s]concatenating: train:  42%|████▏     | 119/285 [00:01<00:02, 61.12it/s]concatenating: train:  47%|████▋     | 134/285 [00:02<00:02, 51.62it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:02, 54.79it/s]concatenating: train:  54%|█████▍    | 155/285 [00:02<00:02, 49.46it/s]concatenating: train:  57%|█████▋    | 163/285 [00:02<00:02, 50.37it/s]concatenating: train:  60%|██████    | 171/285 [00:03<00:02, 53.49it/s]concatenating: train:  62%|██████▏   | 178/285 [00:03<00:01, 55.91it/s]concatenating: train:  66%|██████▌   | 187/285 [00:03<00:01, 63.02it/s]concatenating: train:  71%|███████   | 201/285 [00:03<00:01, 74.98it/s]concatenating: train:  79%|███████▉  | 226/285 [00:03<00:00, 94.76it/s]concatenating: train:  88%|████████▊ | 252/285 [00:03<00:00, 116.92it/s]concatenating: train:  97%|█████████▋| 276/285 [00:03<00:00, 137.79it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 73.63it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.82s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.82s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.68s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 148.67it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 60)   0           batch_normalization_7[0][0]      2019-07-07 07:06:04.187274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 07:06:04.187404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 07:06:04.187423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 07:06:04.187437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 07:06:04.187943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 25s - loss: 24912.2552 - acc: 0.8472 - mDice: 0.1510 - val_loss: 9433.6625 - val_acc: 0.8726 - val_mDice: 0.2812

Epoch 00001: val_mDice improved from -inf to 0.28123, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 8356.3527 - acc: 0.8856 - mDice: 0.3510 - val_loss: 6708.2236 - val_acc: 0.8980 - val_mDice: 0.3997

Epoch 00002: val_mDice improved from 0.28123 to 0.39972, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 15s - loss: 6008.6581 - acc: 0.9063 - mDice: 0.4573 - val_loss: 5819.2084 - val_acc: 0.9152 - val_mDice: 0.4496

Epoch 00003: val_mDice improved from 0.39972 to 0.44957, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 15s - loss: 5067.3108 - acc: 0.9173 - mDice: 0.5151 - val_loss: 5221.5215 - val_acc: 0.9246 - val_mDice: 0.4852

Epoch 00004: val_mDice improved from 0.44957 to 0.48521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 4533.6080 - acc: 0.9232 - mDice: 0.5516 - val_loss: 4811.9763 - val_acc: 0.9294 - val_mDice: 0.5103

Epoch 00005: val_mDice improved from 0.48521 to 0.51031, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 4192.0748 - acc: 0.9267 - mDice: 0.5767 - val_loss: 4552.8647 - val_acc: 0.9348 - val_mDice: 0.5291

Epoch 00006: val_mDice improved from 0.51031 to 0.52915, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 3943.2997 - acc: 0.9294 - mDice: 0.5956 - val_loss: 4532.7119 - val_acc: 0.9384 - val_mDice: 0.5330

Epoch 00007: val_mDice improved from 0.52915 to 0.53302, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 15s - loss: 3752.0413 - acc: 0.9314 - mDice: 0.6105 - val_loss: 4516.1695 - val_acc: 0.9396 - val_mDice: 0.5354

Epoch 00008: val_mDice improved from 0.53302 to 0.53543, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 3583.2982 - acc: 0.9333 - mDice: 0.6242 - val_loss: 4344.8217 - val_acc: 0.9406 - val_mDice: 0.5461

Epoch 00009: val_mDice improved from 0.53543 to 0.54611, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 15s - loss: 3449.4924 - acc: 0.9348 - mDice: 0.6352 - val_loss: 4343.5746 - val_acc: 0.9388 - val_mDice: 0.5447

Epoch 00010: val_mDice did not improve from 0.54611
Epoch 11/300
 - 14s - loss: 3334.3370 - acc: 0.9362 - mDice: 0.6448 - val_loss: 4152.2820 - val_acc: 0.9410 - val_mDice: 0.5588

Epoch 00011: val_mDice improved from 0.54611 to 0.55880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 14s - loss: 3205.8410 - acc: 0.9374 - mDice: 0.6554 - val_loss: 4257.0530 - val_acc: 0.9415 - val_mDice: 0.5521

Epoch 00012: val_mDice did not improve from 0.55880
Epoch 13/300
 - 14s - loss: 3117.5492 - acc: 0.9385 - mDice: 0.6630 - val_loss: 4165.9343 - val_acc: 0.9416 - val_mDice: 0.5585

Epoch 00013: val_mDice did not improve from 0.55880
Epoch 14/300
 - 14s - loss: 3026.3941 - acc: 0.9395 - mDice: 0.6708 - val_loss: 4296.0290 - val_acc: 0.9408 - val_mDice: 0.5503

Epoch 00014: val_mDice did not improve from 0.55880
Epoch 15/300
 - 14s - loss: 2948.1122 - acc: 0.9405 - mDice: 0.6780 - val_loss: 4281.6291 - val_acc: 0.9412 - val_mDice: 0.5534

Epoch 00015: val_mDice did not improve from 0.55880
Epoch 16/300
 - 14s - loss: 2882.1060 - acc: 0.9413 - mDice: 0.6837 - val_loss: 4338.9387 - val_acc: 0.9392 - val_mDice: 0.5496

Epoch 00016: val_mDice did not improve from 0.55880
Epoch 17/300
 - 14s - loss: 2805.2795 - acc: 0.9422 - mDice: 0.6905 - val_loss: 4341.2097 - val_acc: 0.9416 - val_mDice: 0.5520

Epoch 00017: val_mDice did not improve from 0.55880
Epoch 18/300
 - 14s - loss: 2742.3656 - acc: 0.9428 - mDice: 0.6961 - val_loss: 4306.2712 - val_acc: 0.9398 - val_mDice: 0.5530

Epoch 00018: val_mDice did not improve from 0.55880
Epoch 19/300
 - 14s - loss: 2691.2597 - acc: 0.9434 - mDice: 0.7007 - val_loss: 4402.5172 - val_acc: 0.9408 - val_mDice: 0.5521

Epoch 00019: val_mDice did not improve from 0.55880
Epoch 20/300
 - 14s - loss: 2636.7697 - acc: 0.9439 - mDice: 0.7056 - val_loss: 4455.8980 - val_acc: 0.9429 - val_mDice: 0.5511

Epoch 00020: val_mDice did not improve from 0.55880
Epoch 21/300
 - 14s - loss: 2572.3489 - acc: 0.9447 - mDice: 0.7116 - val_loss: 4205.6176 - val_acc: 0.9414 - val_mDice: 0.5588

Epoch 00021: val_mDice improved from 0.55880 to 0.55881, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 15s - loss: 2513.5858 - acc: 0.9453 - mDice: 0.7167 - val_loss: 4055.7878 - val_acc: 0.9420 - val_mDice: 0.5678

Epoch 00022: val_mDice improved from 0.55881 to 0.56780, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 14s - loss: 2466.7643 - acc: 0.9458 - mDice: 0.7212 - val_loss: 4149.1852 - val_acc: 0.9414 - val_mDice: 0.5617

Epoch 00023: val_mDice did not improve from 0.56780
Epoch 24/300
 - 14s - loss: 2421.1721 - acc: 0.9464 - mDice: 0.7256 - val_loss: 4255.5404 - val_acc: 0.9430 - val_mDice: 0.5552

Epoch 00024: val_mDice did not improve from 0.56780
Epoch 25/300
 - 14s - loss: 2381.3863 - acc: 0.9467 - mDice: 0.7293 - val_loss: 4185.1452 - val_acc: 0.9412 - val_mDice: 0.5594

Epoch 00025: val_mDice did not improve from 0.56780
Epoch 26/300
 - 14s - loss: 2339.7769 - acc: 0.9472 - mDice: 0.7332 - val_loss: 4134.2461 - val_acc: 0.9427 - val_mDice: 0.5627

Epoch 00026: val_mDice did not improve from 0.56780
Epoch 27/300
 - 14s - loss: 2300.0283 - acc: 0.9477 - mDice: 0.7369 - val_loss: 4225.9443 - val_acc: 0.9414 - val_mDice: 0.5572

Epoch 00027: val_mDice did not improve from 0.56780
Epoch 28/300
 - 15s - loss: 2271.7655 - acc: 0.9481 - mDice: 0.7397 - val_loss: 4101.8764 - val_acc: 0.9424 - val_mDice: 0.5667

Epoch 00028: val_mDice did not improve from 0.56780
Epoch 29/300
 - 14s - loss: 2227.6192 - acc: 0.9486 - mDice: 0.7440 - val_loss: 4085.9551 - val_acc: 0.9436 - val_mDice: 0.5671

Epoch 00029: val_mDice did not improve from 0.56780
Epoch 30/300
 - 15s - loss: 2203.0513 - acc: 0.9489 - mDice: 0.7464 - val_loss: 4398.9822 - val_acc: 0.9429 - val_mDice: 0.5501

Epoch 00030: val_mDice did not improve from 0.56780
Epoch 31/300
 - 14s - loss: 2162.7101 - acc: 0.9494 - mDice: 0.7503 - val_loss: 4198.1318 - val_acc: 0.9436 - val_mDice: 0.5587

Epoch 00031: val_mDice did not improve from 0.56780
Epoch 32/300
 - 14s - loss: 2136.6117 - acc: 0.9496 - mDice: 0.7528 - val_loss: 4411.3752 - val_acc: 0.9423 - val_mDice: 0.5534

Epoch 00032: val_mDice did not improve from 0.56780
Epoch 33/300
 - 15s - loss: 2114.0795 - acc: 0.9499 - mDice: 0.7551 - val_loss: 4459.2497 - val_acc: 0.9416 - val_mDice: 0.5486

Epoch 00033: val_mDice did not improve from 0.56780
Epoch 34/300
 - 14s - loss: 2075.4952 - acc: 0.9504 - mDice: 0.7588 - val_loss: 4431.3898 - val_acc: 0.9406 - val_mDice: 0.5472

Epoch 00034: val_mDice did not improve from 0.56780
Epoch 35/300
 - 14s - loss: 2051.8044 - acc: 0.9508 - mDice: 0.7612 - val_loss: 4198.6952 - val_acc: 0.9435 - val_mDice: 0.5572

Epoch 00035: val_mDice did not improve from 0.56780
Epoch 36/300
 - 14s - loss: 2023.8445 - acc: 0.9510 - mDice: 0.7640 - val_loss: 4390.9002 - val_acc: 0.9418 - val_mDice: 0.5529

Epoch 00036: val_mDice did not improve from 0.56780
Epoch 37/300
 - 14s - loss: 1982.4105 - acc: 0.9515 - mDice: 0.7682 - val_loss: 4021.9857 - val_acc: 0.9453 - val_mDice: 0.5724

Epoch 00037: val_mDice improved from 0.56780 to 0.57236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 15s - loss: 1962.6215 - acc: 0.9517 - mDice: 0.7702 - val_loss: 4374.9760 - val_acc: 0.9426 - val_mDice: 0.5515

Epoch 00038: val_mDice did not improve from 0.57236
Epoch 39/300
 - 14s - loss: 1937.0330 - acc: 0.9520 - mDice: 0.7727 - val_loss: 4183.0643 - val_acc: 0.9424 - val_mDice: 0.5601

Epoch 00039: val_mDice did not improve from 0.57236
Epoch 40/300
 - 14s - loss: 1918.9836 - acc: 0.9522 - mDice: 0.7746 - val_loss: 4215.4868 - val_acc: 0.9432 - val_mDice: 0.5544

Epoch 00040: val_mDice did not improve from 0.57236
Epoch 41/300
 - 15s - loss: 1891.1128 - acc: 0.9525 - mDice: 0.7774 - val_loss: 4520.1382 - val_acc: 0.9409 - val_mDice: 0.5435

Epoch 00041: val_mDice did not improve from 0.57236
Epoch 42/300
 - 14s - loss: 1869.9674 - acc: 0.9528 - mDice: 0.7795 - val_loss: 4106.9513 - val_acc: 0.9437 - val_mDice: 0.5644

Epoch 00042: val_mDice did not improve from 0.57236
Epoch 43/300
 - 14s - loss: 1854.6610 - acc: 0.9530 - mDice: 0.7811 - val_loss: 4051.0168 - val_acc: 0.9452 - val_mDice: 0.5697

Epoch 00043: val_mDice did not improve from 0.57236
Epoch 44/300
 - 15s - loss: 1830.5131 - acc: 0.9534 - mDice: 0.7837 - val_loss: 4154.5817 - val_acc: 0.9431 - val_mDice: 0.5637

Epoch 00044: val_mDice did not improve from 0.57236
Epoch 45/300
 - 14s - loss: 1805.9405 - acc: 0.9536 - mDice: 0.7860 - val_loss: 4335.3353 - val_acc: 0.9423 - val_mDice: 0.5515

Epoch 00045: val_mDice did not improve from 0.57236
Epoch 46/300
 - 14s - loss: 1792.3421 - acc: 0.9538 - mDice: 0.7876 - val_loss: 4139.8643 - val_acc: 0.9428 - val_mDice: 0.5651

Epoch 00046: val_mDice did not improve from 0.57236
Epoch 47/300
 - 14s - loss: 1768.5771 - acc: 0.9540 - mDice: 0.7901 - val_loss: 4331.9964 - val_acc: 0.9444 - val_mDice: 0.5499

Epoch 00047: val_mDice did not improve from 0.57236
Epoch 48/300
 - 14s - loss: 1762.9491 - acc: 0.9542 - mDice: 0.7906 - val_loss: 4342.8315 - val_acc: 0.9466 - val_mDice: 0.5508

Epoch 00048: val_mDice did not improve from 0.57236
Epoch 49/300
 - 14s - loss: 1748.4508 - acc: 0.9544 - mDice: 0.7922 - val_loss: 4124.8793 - val_acc: 0.9462 - val_mDice: 0.5646

Epoch 00049: val_mDice did not improve from 0.57236
Epoch 50/300
 - 14s - loss: 1724.6004 - acc: 0.9547 - mDice: 0.7947 - val_loss: 4488.0581 - val_acc: 0.9426 - val_mDice: 0.5429

Epoch 00050: val_mDice did not improve from 0.57236
Epoch 51/300
 - 15s - loss: 1700.9810 - acc: 0.9550 - mDice: 0.7972 - val_loss: 4242.1903 - val_acc: 0.9436 - val_mDice: 0.5558

Epoch 00051: val_mDice did not improve from 0.57236
Epoch 52/300
 - 14s - loss: 1687.3360 - acc: 0.9552 - mDice: 0.7986 - val_loss: 4206.1830 - val_acc: 0.9442 - val_mDice: 0.5586

Epoch 00052: val_mDice did not improve from 0.57236
Epoch 53/300
 - 14s - loss: 1681.1561 - acc: 0.9553 - mDice: 0.7992 - val_loss: 4205.5639 - val_acc: 0.9434 - val_mDice: 0.5577

Epoch 00053: val_mDice did not improve from 0.57236
Epoch 54/300
 - 14s - loss: 1668.8530 - acc: 0.9555 - mDice: 0.8006 - val_loss: 3964.5361 - val_acc: 0.9457 - val_mDice: 0.5759

Epoch 00054: val_mDice improved from 0.57236 to 0.57591, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 55/300
 - 14s - loss: 1644.4517 - acc: 0.9558 - mDice: 0.8031 - val_loss: 4352.1386 - val_acc: 0.9421 - val_mDice: 0.5473

Epoch 00055: val_mDice did not improve from 0.57591
Epoch 56/300
 - 14s - loss: 1637.9674 - acc: 0.9559 - mDice: 0.8037 - val_loss: 4241.7086 - val_acc: 0.9448 - val_mDice: 0.5587

Epoch 00056: val_mDice did not improve from 0.57591
Epoch 57/300
 - 14s - loss: 1633.3160 - acc: 0.9561 - mDice: 0.8050 - val_loss: 5838.1927 - val_acc: 0.9347 - val_mDice: 0.4471

Epoch 00057: val_mDice did not improve from 0.57591
Epoch 58/300
 - 14s - loss: 2232.8216 - acc: 0.9479 - mDice: 0.7460 - val_loss: 4725.0531 - val_acc: 0.9387 - val_mDice: 0.5300

Epoch 00058: val_mDice did not improve from 0.57591
Epoch 59/300
 - 14s - loss: 1751.4610 - acc: 0.9543 - mDice: 0.7919 - val_loss: 4261.9251 - val_acc: 0.9460 - val_mDice: 0.5613

Epoch 00059: val_mDice did not improve from 0.57591
Epoch 60/300
 - 14s - loss: 1676.2973 - acc: 0.9553 - mDice: 0.7998 - val_loss: 4297.2376 - val_acc: 0.9422 - val_mDice: 0.5529

Epoch 00060: val_mDice did not improve from 0.57591
Epoch 61/300
 - 14s - loss: 1637.9798 - acc: 0.9559 - mDice: 0.8038 - val_loss: 4227.6842 - val_acc: 0.9455 - val_mDice: 0.5571

Epoch 00061: val_mDice did not improve from 0.57591
Epoch 62/300
 - 14s - loss: 1618.7706 - acc: 0.9562 - mDice: 0.8059 - val_loss: 4067.9766 - val_acc: 0.9470 - val_mDice: 0.5710

Epoch 00062: val_mDice did not improve from 0.57591
Epoch 63/300
 - 14s - loss: 1589.1378 - acc: 0.9564 - mDice: 0.8090 - val_loss: 4006.8512 - val_acc: 0.9468 - val_mDice: 0.5749

Epoch 00063: val_mDice did not improve from 0.57591
Epoch 64/300
 - 14s - loss: 1567.1755 - acc: 0.9567 - mDice: 0.8114 - val_loss: 4311.8946 - val_acc: 0.9454 - val_mDice: 0.5536

Epoch 00064: val_mDice did not improve from 0.57591
Epoch 65/300
 - 14s - loss: 1563.1923 - acc: 0.9569 - mDice: 0.8118 - val_loss: 4272.5245 - val_acc: 0.9432 - val_mDice: 0.5547

Epoch 00065: val_mDice did not improve from 0.57591
Epoch 66/300
 - 14s - loss: 1541.6568 - acc: 0.9572 - mDice: 0.8141 - val_loss: 4182.1605 - val_acc: 0.9449 - val_mDice: 0.5585

Epoch 00066: val_mDice did not improve from 0.57591
Epoch 67/300
 - 14s - loss: 1526.9954 - acc: 0.9573 - mDice: 0.8157 - val_loss: 4136.1265 - val_acc: 0.9460 - val_mDice: 0.5661

Epoch 00067: val_mDice did not improve from 0.57591
Epoch 68/300
 - 14s - loss: 1527.3253 - acc: 0.9574 - mDice: 0.8157 - val_loss: 4100.9786 - val_acc: 0.9479 - val_mDice: 0.5652

Epoch 00068: val_mDice did not improve from 0.57591
Epoch 69/300
 - 14s - loss: 1511.4054 - acc: 0.9576 - mDice: 0.8174 - val_loss: 4170.2656 - val_acc: 0.9457 - val_mDice: 0.5631

Epoch 00069: val_mDice did not improve from 0.57591
Epoch 70/300
 - 14s - loss: 1504.1223 - acc: 0.9577 - mDice: 0.8182 - val_loss: 4516.4776 - val_acc: 0.9448 - val_mDice: 0.5448

Epoch 00070: val_mDice did not improve from 0.57591
Epoch 71/300
 - 14s - loss: 1492.6912 - acc: 0.9579 - mDice: 0.8194 - val_loss: 4383.5203 - val_acc: 0.9424 - val_mDice: 0.5477

Epoch 00071: val_mDice did not improve from 0.57591
Epoch 72/300
 - 14s - loss: 1486.0226 - acc: 0.9579 - mDice: 0.8201 - val_loss: 4268.3167 - val_acc: 0.9423 - val_mDice: 0.5571

Epoch 00072: val_mDice did not improve from 0.57591
Epoch 73/300
 - 14s - loss: 1472.9203 - acc: 0.9581 - mDice: 0.8215 - val_loss: 4066.1387 - val_acc: 0.9480 - val_mDice: 0.5720

Epoch 00073: val_mDice did not improve from 0.57591
Epoch 74/300
 - 14s - loss: 1464.9353 - acc: 0.9582 - mDice: 0.8224 - val_loss: 4029.8404 - val_acc: 0.9457 - val_mDice: 0.5699

Epoch 00074: val_mDice did not improve from 0.57591
Epoch 75/300
 - 14s - loss: 1450.3147 - acc: 0.9584 - mDice: 0.8240 - val_loss: 4118.0718 - val_acc: 0.9451 - val_mDice: 0.5656

Epoch 00075: val_mDice did not improve from 0.57591
Epoch 76/300
 - 14s - loss: 1447.3123 - acc: 0.9585 - mDice: 0.8244 - val_loss: 4436.0117 - val_acc: 0.9441 - val_mDice: 0.5411

Epoch 00076: val_mDice did not improve from 0.57591
Epoch 77/300
 - 14s - loss: 1445.4714 - acc: 0.9585 - mDice: 0.8246 - val_loss: 4358.3514 - val_acc: 0.9408 - val_mDice: 0.5475

Epoch 00077: val_mDice did not improve from 0.57591
Epoch 78/300
 - 14s - loss: 1440.9585 - acc: 0.9585 - mDice: 0.8250 - val_loss: 4449.0491 - val_acc: 0.9444 - val_mDice: 0.5460

Epoch 00078: val_mDice did not improve from 0.57591
Epoch 79/300
 - 14s - loss: 1423.9818 - acc: 0.9588 - mDice: 0.8269 - val_loss: 4383.1829 - val_acc: 0.9461 - val_mDice: 0.5572

Epoch 00079: val_mDice did not improve from 0.57591
Epoch 80/300
 - 14s - loss: 1415.0745 - acc: 0.9589 - mDice: 0.8279 - val_loss: 4495.4202 - val_acc: 0.9431 - val_mDice: 0.5491

Epoch 00080: val_mDice did not improve from 0.57591
Epoch 81/300
 - 14s - loss: 1409.7600 - acc: 0.9589 - mDice: 0.8285 - val_loss: 4331.1232 - val_acc: 0.9427 - val_mDice: 0.5535

Epoch 00081: val_mDice did not improve from 0.57591
Epoch 82/300
 - 14s - loss: 1406.6550 - acc: 0.9590 - mDice: 0.8288 - val_loss: 4429.1624 - val_acc: 0.9449 - val_mDice: 0.5454

Epoch 00082: val_mDice did not improve from 0.57591
Epoch 83/300
 - 14s - loss: 1404.3973 - acc: 0.9591 - mDice: 0.8291 - val_loss: 4093.3617 - val_acc: 0.9450 - val_mDice: 0.5678

Epoch 00083: val_mDice did not improve from 0.57591
Epoch 84/300
 - 14s - loss: 1382.4808 - acc: 0.9593 - mDice: 0.8314 - val_loss: 4227.2295 - val_acc: 0.9456 - val_mDice: 0.5595

Epoch 00084: val_mDice did not improve from 0.57591
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
{'val_loss': [9433.662475585938, 6708.223614032452, 5819.2083740234375, 5221.5215407151445, 4811.976337139423, 4552.8646897536055, 4532.711918757512, 4516.169532189002, 4344.821702223558, 4343.5745849609375, 4152.281973031851, 4257.052976168119, 4165.934305044321, 4296.028987004207, 4281.6291269155645, 4338.938669057993, 4341.2096933218145, 4306.271221454327, 4402.5171790489785, 4455.897958608774, 4205.61762883113, 4055.787804236779, 4149.185175969051, 4255.540447528546, 4185.145183856671, 4134.246096097506, 4225.944331242488, 4101.876410851111, 4085.9551438551684, 4398.9821542593145, 4198.131845327524, 4411.375234750601, 4459.249685434194, 4431.38977755033, 4198.695152869592, 4390.900174654447, 4021.9856989933896, 4374.975956843449, 4183.064349834735, 4215.486774151142, 4520.138211763822, 4106.951279860276, 4051.016808143029, 4154.581740159255, 4335.33530836839, 4139.8643470177285, 4331.996417705829, 4342.831500713642, 4124.879267765926, 4488.058091383714, 4242.190255972056, 4206.182992788462, 4205.563931978666, 3964.536095252404, 4352.138559194712, 4241.708571213942, 5838.192655123197, 4725.05308180589, 4261.925053523137, 4297.237586388221, 4227.684157151442, 4067.9766235351562, 4006.8511962890625, 4311.894564115084, 4272.52450796274, 4182.1605224609375, 4136.126497708834, 4100.978553185096, 4170.265615609976, 4516.477618877704, 4383.520334097056, 4268.316669170673, 4066.138653094952, 4029.8403977614184, 4118.071843073918, 4436.011676494892, 4358.351360614483, 4449.049142690806, 4383.182870718149, 4495.420170710637, 4331.123244065505, 4429.162419245793, 4093.3617225060098, 4227.229529747596], 'val_acc': [0.8726192460610316, 0.8980283989356115, 0.9152389902334946, 0.9245954981217017, 0.9293893048396478, 0.9347540598649245, 0.9384130147787241, 0.939619568678049, 0.9405833803690397, 0.9388244541791769, 0.9409509003162384, 0.9414987105589646, 0.9415888236119196, 0.9408468993810507, 0.9411820402512183, 0.9392474316633664, 0.9415726982630216, 0.9397674615566547, 0.9407636569096491, 0.9429340523022872, 0.9414247205624213, 0.9420118446533496, 0.9414247343173394, 0.9429826392577245, 0.9411704998749953, 0.9427329645707057, 0.9413854227616236, 0.9424278942438272, 0.9435997536549201, 0.9428555185978229, 0.9435743070565737, 0.9422799280056586, 0.9415542070682232, 0.940571835407844, 0.9434541693100562, 0.9417598774799933, 0.9453471646859095, 0.9425896658347204, 0.94240475159425, 0.9431859942582937, 0.9408515279109662, 0.9436899148500882, 0.9452431408258585, 0.943070439191965, 0.9422753384480109, 0.9428092378836411, 0.9444249318196223, 0.946574520606261, 0.946227830189925, 0.9426104724407196, 0.943602062188662, 0.9442168749295748, 0.9434426128864288, 0.9456707926896902, 0.9420557274268224, 0.944831710595351, 0.9346962823317602, 0.9386602892325475, 0.9459804846690252, 0.9421666952279898, 0.9454789138757266, 0.9470460391961611, 0.9468195392535284, 0.9453587073546189, 0.9432438199336712, 0.9448571388538067, 0.9460059220974262, 0.947949801500027, 0.9457216216967657, 0.9447877957270696, 0.942444044810075, 0.9422799669779264, 0.9479936980284177, 0.9456776953660525, 0.9450998764771682, 0.9441174933543572, 0.9407729185544528, 0.9443833484099462, 0.9460590940255386, 0.943142083974985, 0.94272603896948, 0.9448687227872702, 0.9449727191374853, 0.9456453552612891], 'val_mDice': [0.28123406062905604, 0.39972095076854414, 0.44957268925813526, 0.4852108978308164, 0.5103076209242527, 0.5291470850889499, 0.533018956390711, 0.535429838185127, 0.5461108357860491, 0.5446650970440644, 0.5587993550759095, 0.552146169428642, 0.5584677589627413, 0.550266044644209, 0.5533908043916409, 0.5495726729814823, 0.5519820428811587, 0.5530325082632211, 0.5520517241496307, 0.551126397573031, 0.5588090717792511, 0.5678042425559118, 0.5616528804485614, 0.5552443197140327, 0.5593995383152595, 0.5626525156773053, 0.5571910578470963, 0.5667150943325117, 0.5671419306443288, 0.5500981847827251, 0.558715239740335, 0.5533904685423925, 0.5486275135324552, 0.5472488380395449, 0.5571592037494366, 0.5528909288919889, 0.5723612973323235, 0.5515421147529895, 0.5600567202155406, 0.554421759568728, 0.543491827753874, 0.5643996109183018, 0.5696971502441627, 0.5636974613253887, 0.551490087635242, 0.5650610276139699, 0.549863766019161, 0.5507908761501312, 0.5646294808158507, 0.542881717475561, 0.555751886505347, 0.5586490284364957, 0.5577061113256675, 0.5759083823515818, 0.5472881816900693, 0.5587342966061372, 0.44711422748290575, 0.5299994939794908, 0.561256739955682, 0.5529284173479447, 0.5571038849078692, 0.5710388003633573, 0.5749406516551971, 0.5536099589214876, 0.5546574326088796, 0.5584817812419854, 0.5661392750648352, 0.5651748762107812, 0.5630886084758319, 0.5448273726953909, 0.5477261107701522, 0.5571333932188841, 0.5720073878765106, 0.5698701785160944, 0.5656442464544222, 0.5410706165891427, 0.547542960024797, 0.546006383231053, 0.5572487448270504, 0.5491062732270131, 0.5534853981091425, 0.5453809574246407, 0.56776374234603, 0.5594654518824357], 'loss': [24912.255156201365, 8356.352737383133, 6008.658110877085, 5067.31079171362, 4533.60799366797, 4192.074818091255, 3943.299659527064, 3752.041330837273, 3583.298206616776, 3449.4924086067913, 3334.3369641380095, 3205.8409906345287, 3117.549210142146, 3026.3940662952914, 2948.1121749617587, 2882.106004821389, 2805.2795434811233, 2742.36560838772, 2691.2596871455985, 2636.7696567877715, 2572.348860099924, 2513.5858270591843, 2466.764279400809, 2421.1720645168903, 2381.3862759172284, 2339.7768564031626, 2300.0282993613932, 2271.7654701858432, 2227.619155339184, 2203.0513100374737, 2162.7100784989902, 2136.6117379606226, 2114.0795255156336, 2075.495203761391, 2051.804433407318, 2023.8445025342621, 1982.4105064239404, 1962.621491229986, 1937.0329627614283, 1918.9835684499342, 1891.112832078984, 1869.9673537229971, 1854.6609579816488, 1830.5131198116458, 1805.9404893435533, 1792.3420939281464, 1768.5771078975022, 1762.9490894633202, 1748.4508064633794, 1724.6004160714197, 1700.9810425018588, 1687.335988723824, 1681.156135607632, 1668.8530053175057, 1644.4517198179324, 1637.9674308908434, 1633.3159814187436, 2232.8216424393368, 1751.4609670409482, 1676.2973052970071, 1637.9798066454885, 1618.7706125173734, 1589.1377587343486, 1567.175484630286, 1563.1923291344358, 1541.6567872365902, 1526.995421879188, 1527.3252791112984, 1511.4053750407988, 1504.1223439659282, 1492.6911859819286, 1486.022624279579, 1472.9203071625902, 1464.935269084263, 1450.3147449150392, 1447.312261899283, 1445.4714064562463, 1440.9585098566345, 1423.981752683588, 1415.0745364896907, 1409.759956678605, 1406.6550303888994, 1404.3972932104364, 1382.4807744549064], 'acc': [0.8471963280990732, 0.8856414363611386, 0.9062581794415631, 0.9172780497107329, 0.9232360125797366, 0.926707034438428, 0.9293641683185253, 0.9313917105393382, 0.9333358234852582, 0.9347701962062555, 0.9362266457884512, 0.9373509732656435, 0.9384951920710751, 0.9395278930817981, 0.9404896097155523, 0.9412508269171208, 0.9421899258447267, 0.9427574492079145, 0.9434128683409128, 0.9439477079756572, 0.9447340609721017, 0.9452599251357148, 0.9458137201579044, 0.9463892639381446, 0.9467469264547796, 0.947227475130392, 0.9477338285108867, 0.9480502501488788, 0.9485621058576982, 0.9488552769952338, 0.949352601016897, 0.949616533352376, 0.949908327849646, 0.950385659688471, 0.9507530547646176, 0.9509715824167656, 0.9515207411782676, 0.9517358570238282, 0.952023790950849, 0.9522205913659447, 0.952504050843799, 0.9528218967266148, 0.9529891894838417, 0.9533555011659995, 0.9535658876856106, 0.9538271774953663, 0.9540152846914831, 0.9541921978296746, 0.95439988517084, 0.9547375493479272, 0.9549797071881106, 0.9552119754122201, 0.9552589094277117, 0.9554620959832859, 0.9558030393008629, 0.9558634959462933, 0.9560631308555163, 0.9478745585018712, 0.9542775972736264, 0.9553388088191225, 0.9559125770977653, 0.9561692624693261, 0.956416359980542, 0.9567090459308819, 0.9568735649035358, 0.957160659341215, 0.9572923909383189, 0.9573608287957545, 0.9575864926625098, 0.9576708232906816, 0.9579002386549792, 0.9578888863036523, 0.9580543838193317, 0.958151905131848, 0.9583669537098592, 0.9584816979502198, 0.9585055110639921, 0.9585068377249687, 0.9587877980459774, 0.9588974879575833, 0.9589201257499966, 0.9590179172760994, 0.9590775961971785, 0.9592704476547628], 'mDice': [0.1510345104019833, 0.35099541913657173, 0.45727282953550374, 0.5151408327073285, 0.551554773507562, 0.5767462328660425, 0.5955696751312126, 0.6105003042831463, 0.6241827028753968, 0.6351563698755335, 0.6448117435544682, 0.6554431804297518, 0.6629613571739567, 0.6708479347862705, 0.677964213258785, 0.6836587411335097, 0.6904682588788358, 0.6961015338806674, 0.7006585309066358, 0.7056392409160965, 0.7115760171346357, 0.7167227455833725, 0.7211835551534557, 0.7255922647999252, 0.7292556688649885, 0.7331989832462271, 0.7369298489509578, 0.7396983022807676, 0.7439624738794384, 0.7464371479152369, 0.7502538812871812, 0.7528238155619087, 0.7550929745360845, 0.7588321447130566, 0.7611982553391992, 0.7640135292306351, 0.7681824737816381, 0.7701566271991689, 0.772707680104393, 0.7745607216826754, 0.7773999036991056, 0.7795080129130348, 0.7810748034843734, 0.7836940689059648, 0.7860314694649727, 0.7875653617355444, 0.7900594437429082, 0.7906242361601281, 0.7922046868924031, 0.7947117630366546, 0.797160891845395, 0.7985696157691862, 0.7992076753833401, 0.8005557903600973, 0.8031075541783795, 0.8037379225670472, 0.8050498557213893, 0.7460307537393466, 0.7919154922911396, 0.7997671318628092, 0.8038353649527453, 0.8058725035543494, 0.808978300961821, 0.8113679388984811, 0.8117830066248619, 0.8140899684940835, 0.815658961980092, 0.8156641693030799, 0.8173993996926079, 0.8181907772951919, 0.8193692301709988, 0.8201128870790255, 0.8215487667646375, 0.8224050499114737, 0.8240178618760475, 0.8243759359302396, 0.8245571699681608, 0.825042078292294, 0.8269134181612017, 0.8278951955041707, 0.8284615607078276, 0.8288187545339505, 0.8290685900328707, 0.8314393365788831]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.21s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.77s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:20,  1.34s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:45,  1.43s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:42,  1.43s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<06:49,  1.46s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:15,  1.56s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:43,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:51,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:37,  1.66s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:54,  1.73s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:04,  1.77s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:09,  1.79s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:17,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:24,  1.86s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:23,  1.87s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:23,  1.87s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:12,  1.84s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:10,  1.84s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<08:08,  1.84s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:19,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:10,  1.86s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<08:06,  1.85s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<08:09,  1.87s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<08:19,  1.91s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<08:13,  1.90s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:10,  1.89s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<08:03,  1.88s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:51,  1.83s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:51,  1.84s/it]predicting train subjects:  11%|█         | 30/285 [00:53<07:39,  1.80s/it]predicting train subjects:  11%|█         | 31/285 [00:55<07:31,  1.78s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:27,  1.77s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:23,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [01:00<07:21,  1.76s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:18,  1.75s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:09,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:07,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:07<07:09,  1.74s/it]predicting train subjects:  14%|█▎        | 39/285 [01:09<07:10,  1.75s/it]predicting train subjects:  14%|█▍        | 40/285 [01:11<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:12<07:14,  1.78s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<07:13,  1.78s/it]predicting train subjects:  15%|█▌        | 43/285 [01:16<07:07,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<07:03,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<07:00,  1.75s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<06:44,  1.69s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:19,  1.60s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<06:08,  1.56s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<06:10,  1.57s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<06:03,  1.55s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<05:58,  1.53s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<05:57,  1.53s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<05:56,  1.54s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<05:54,  1.53s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<05:56,  1.55s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<05:53,  1.54s/it]predicting train subjects:  20%|██        | 57/285 [01:38<05:57,  1.57s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:00,  1.59s/it]predicting train subjects:  21%|██        | 59/285 [01:41<05:53,  1.56s/it]predicting train subjects:  21%|██        | 60/285 [01:42<05:50,  1.56s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<05:48,  1.56s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<05:47,  1.56s/it]predicting train subjects:  22%|██▏       | 63/285 [01:47<05:51,  1.58s/it]predicting train subjects:  22%|██▏       | 64/285 [01:49<05:49,  1.58s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<05:55,  1.62s/it]predicting train subjects:  23%|██▎       | 66/285 [01:52<05:59,  1.64s/it]predicting train subjects:  24%|██▎       | 67/285 [01:54<05:47,  1.60s/it]predicting train subjects:  24%|██▍       | 68/285 [01:55<05:40,  1.57s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<05:38,  1.57s/it]predicting train subjects:  25%|██▍       | 70/285 [01:58<05:34,  1.56s/it]predicting train subjects:  25%|██▍       | 71/285 [02:00<05:27,  1.53s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:24,  1.52s/it]predicting train subjects:  26%|██▌       | 73/285 [02:03<05:21,  1.52s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<05:21,  1.52s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<05:22,  1.53s/it]predicting train subjects:  27%|██▋       | 76/285 [02:07<05:21,  1.54s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:19,  1.54s/it]predicting train subjects:  27%|██▋       | 78/285 [02:10<05:19,  1.54s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:18,  1.55s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:18,  1.55s/it]predicting train subjects:  28%|██▊       | 81/285 [02:15<05:16,  1.55s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:16,  1.56s/it]predicting train subjects:  29%|██▉       | 83/285 [02:18<05:13,  1.55s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:09,  1.54s/it]predicting train subjects:  30%|██▉       | 85/285 [02:21<05:17,  1.59s/it]predicting train subjects:  30%|███       | 86/285 [02:23<05:24,  1.63s/it]predicting train subjects:  31%|███       | 87/285 [02:25<05:35,  1.70s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:35,  1.70s/it]predicting train subjects:  31%|███       | 89/285 [02:29<05:40,  1.74s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:41,  1.75s/it]predicting train subjects:  32%|███▏      | 91/285 [02:32<05:35,  1.73s/it]predicting train subjects:  32%|███▏      | 92/285 [02:34<05:35,  1.74s/it]predicting train subjects:  33%|███▎      | 93/285 [02:36<05:36,  1.75s/it]predicting train subjects:  33%|███▎      | 94/285 [02:37<05:34,  1.75s/it]predicting train subjects:  33%|███▎      | 95/285 [02:39<05:28,  1.73s/it]predicting train subjects:  34%|███▎      | 96/285 [02:41<05:25,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:42<05:24,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:44<05:27,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:46<05:24,  1.74s/it]predicting train subjects:  35%|███▌      | 100/285 [02:48<05:25,  1.76s/it]predicting train subjects:  35%|███▌      | 101/285 [02:49<05:23,  1.76s/it]predicting train subjects:  36%|███▌      | 102/285 [02:51<05:18,  1.74s/it]predicting train subjects:  36%|███▌      | 103/285 [02:53<05:15,  1.73s/it]predicting train subjects:  36%|███▋      | 104/285 [02:55<05:10,  1.72s/it]predicting train subjects:  37%|███▋      | 105/285 [02:56<05:08,  1.71s/it]predicting train subjects:  37%|███▋      | 106/285 [02:58<05:08,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:00<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:01<05:03,  1.71s/it]predicting train subjects:  38%|███▊      | 109/285 [03:03<05:01,  1.71s/it]predicting train subjects:  39%|███▊      | 110/285 [03:05<05:02,  1.73s/it]predicting train subjects:  39%|███▉      | 111/285 [03:07<05:03,  1.74s/it]predicting train subjects:  39%|███▉      | 112/285 [03:08<05:00,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:10<04:58,  1.74s/it]predicting train subjects:  40%|████      | 114/285 [03:12<04:57,  1.74s/it]predicting train subjects:  40%|████      | 115/285 [03:14<04:56,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:15<04:52,  1.73s/it]predicting train subjects:  41%|████      | 117/285 [03:17<04:51,  1.73s/it]predicting train subjects:  41%|████▏     | 118/285 [03:19<04:50,  1.74s/it]predicting train subjects:  42%|████▏     | 119/285 [03:21<04:47,  1.73s/it]predicting train subjects:  42%|████▏     | 120/285 [03:22<04:46,  1.74s/it]predicting train subjects:  42%|████▏     | 121/285 [03:24<04:36,  1.68s/it]predicting train subjects:  43%|████▎     | 122/285 [03:25<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:27<04:11,  1.55s/it]predicting train subjects:  44%|████▎     | 124/285 [03:28<04:10,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:30<04:09,  1.56s/it]predicting train subjects:  44%|████▍     | 126/285 [03:31<04:09,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:33<04:08,  1.57s/it]predicting train subjects:  45%|████▍     | 128/285 [03:35<04:05,  1.56s/it]predicting train subjects:  45%|████▌     | 129/285 [03:36<04:02,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [03:38<04:03,  1.57s/it]predicting train subjects:  46%|████▌     | 131/285 [03:39<04:01,  1.57s/it]predicting train subjects:  46%|████▋     | 132/285 [03:41<03:59,  1.56s/it]predicting train subjects:  47%|████▋     | 133/285 [03:42<03:54,  1.54s/it]predicting train subjects:  47%|████▋     | 134/285 [03:44<03:50,  1.53s/it]predicting train subjects:  47%|████▋     | 135/285 [03:45<03:51,  1.54s/it]predicting train subjects:  48%|████▊     | 136/285 [03:47<03:50,  1.54s/it]predicting train subjects:  48%|████▊     | 137/285 [03:48<03:48,  1.54s/it]predicting train subjects:  48%|████▊     | 138/285 [03:50<03:46,  1.54s/it]predicting train subjects:  49%|████▉     | 139/285 [03:52<03:45,  1.55s/it]predicting train subjects:  49%|████▉     | 140/285 [03:53<03:44,  1.55s/it]predicting train subjects:  49%|████▉     | 141/285 [03:55<03:44,  1.56s/it]predicting train subjects:  50%|████▉     | 142/285 [03:56<03:40,  1.54s/it]predicting train subjects:  50%|█████     | 143/285 [03:58<03:36,  1.52s/it]predicting train subjects:  51%|█████     | 144/285 [03:59<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 145/285 [04:01<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:02<03:27,  1.49s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:04<03:22,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:05<03:20,  1.47s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:06<03:20,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:08<03:17,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:09<03:13,  1.45s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:11<03:09,  1.43s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:12<03:08,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:14<03:06,  1.42s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:15<03:05,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:16<03:03,  1.42s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:18<03:01,  1.42s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:19<03:00,  1.42s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:21<02:58,  1.42s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:22<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:24<02:59,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:25<02:56,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:26<02:54,  1.43s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:28<02:52,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:29<02:48,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:31<02:48,  1.41s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:32<02:45,  1.40s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:33<02:42,  1.39s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:35<02:41,  1.39s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:36<02:40,  1.40s/it]predicting train subjects:  60%|██████    | 171/285 [04:38<02:41,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:39<02:38,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:40<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:42<02:35,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:43<02:35,  1.41s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:45<02:32,  1.40s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:46<02:30,  1.39s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:47<02:26,  1.37s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:49<02:22,  1.35s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:50<02:20,  1.34s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:51<02:19,  1.34s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:53<02:18,  1.34s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:54<02:18,  1.35s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:55<02:17,  1.36s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:57<02:14,  1.34s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:58<02:12,  1.33s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:59<02:10,  1.33s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:01<02:12,  1.37s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:02<02:09,  1.34s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:03<02:06,  1.33s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:05<02:06,  1.35s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:06<02:05,  1.35s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:07<02:05,  1.37s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:09<02:01,  1.34s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:10<02:01,  1.35s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:12<02:06,  1.42s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:13<02:11,  1.49s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:15<02:14,  1.55s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:17<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:18<02:14,  1.58s/it]predicting train subjects:  71%|███████   | 201/285 [05:20<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:21<02:12,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [05:23<02:10,  1.59s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:25<02:09,  1.60s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:26<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:28<02:08,  1.63s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:30<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:31<02:05,  1.63s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:33<02:03,  1.63s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:35<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:36<02:00,  1.62s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:38<01:57,  1.61s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:39<01:55,  1.61s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:41<01:49,  1.54s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:42<01:45,  1.50s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:44<01:41,  1.47s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:45<01:38,  1.45s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:46<01:35,  1.43s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:48<01:33,  1.41s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:49<01:32,  1.42s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:51<01:31,  1.42s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:52<01:29,  1.43s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:53<01:28,  1.42s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:55<01:26,  1.41s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:56<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:58<01:23,  1.41s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:59<01:21,  1.41s/it]predicting train subjects:  80%|████████  | 228/285 [06:00<01:19,  1.39s/it]predicting train subjects:  80%|████████  | 229/285 [06:02<01:17,  1.39s/it]predicting train subjects:  81%|████████  | 230/285 [06:03<01:16,  1.39s/it]predicting train subjects:  81%|████████  | 231/285 [06:05<01:14,  1.38s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:06<01:20,  1.51s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:08<01:22,  1.58s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:10<01:24,  1.66s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:12<01:23,  1.68s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:13<01:23,  1.70s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:15<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:17<01:21,  1.74s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:19<01:20,  1.76s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:21<01:19,  1.78s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:22<01:17,  1.76s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:24<01:15,  1.76s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:26<01:14,  1.77s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:28<01:13,  1.79s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:29<01:11,  1.79s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:31<01:09,  1.79s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:33<01:08,  1.80s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:35<01:05,  1.78s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:37<01:03,  1.77s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:38<00:57,  1.65s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:39<00:52,  1.54s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:41<00:49,  1.51s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:42<00:47,  1.47s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:43<00:44,  1.45s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:45<00:42,  1.41s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:46<00:41,  1.43s/it]predicting train subjects:  90%|█████████ | 257/285 [06:47<00:38,  1.39s/it]predicting train subjects:  91%|█████████ | 258/285 [06:49<00:37,  1.40s/it]predicting train subjects:  91%|█████████ | 259/285 [06:50<00:35,  1.37s/it]predicting train subjects:  91%|█████████ | 260/285 [06:52<00:34,  1.38s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:53<00:32,  1.34s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:54<00:30,  1.33s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:56<00:29,  1.34s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:57<00:27,  1.33s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:58<00:26,  1.32s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:59<00:25,  1.33s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:01<00:23,  1.32s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:03<00:24,  1.44s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:04<00:24,  1.53s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:06<00:24,  1.60s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:08<00:23,  1.66s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:10<00:21,  1.69s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:11<00:20,  1.70s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:13<00:18,  1.72s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:15<00:17,  1.72s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:17<00:15,  1.75s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:18<00:14,  1.76s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:20<00:12,  1.76s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:22<00:10,  1.76s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:24<00:08,  1.76s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:25<00:06,  1.75s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:27<00:05,  1.74s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:29<00:03,  1.75s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:31<00:01,  1.76s/it]predicting train subjects: 100%|██████████| 285/285 [07:32<00:00,  1.77s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:27:58, 17.03s/it]Loading train:   1%|          | 2/311 [00:25<1:14:39, 14.50s/it]Loading train:   1%|          | 3/311 [00:36<1:08:15, 13.30s/it]Loading train:   1%|▏         | 4/311 [00:46<1:03:25, 12.39s/it]Loading train:   2%|▏         | 5/311 [00:55<58:41, 11.51s/it]  Loading train:   2%|▏         | 6/311 [01:05<55:08, 10.85s/it]Loading train:   2%|▏         | 7/311 [01:16<55:00, 10.86s/it]Loading train:   3%|▎         | 8/311 [01:28<57:17, 11.34s/it]Loading train:   3%|▎         | 9/311 [01:39<57:04, 11.34s/it]Loading train:   3%|▎         | 10/311 [01:49<54:21, 10.84s/it]Loading train:   4%|▎         | 11/311 [02:02<56:58, 11.39s/it]Loading train:   4%|▍         | 12/311 [02:12<54:34, 10.95s/it]Loading train:   4%|▍         | 13/311 [02:22<52:56, 10.66s/it]Loading train:   5%|▍         | 14/311 [02:34<54:48, 11.07s/it]Loading train:   5%|▍         | 15/311 [02:43<51:51, 10.51s/it]Loading train:   5%|▌         | 16/311 [02:52<49:48, 10.13s/it]Loading train:   5%|▌         | 17/311 [03:01<48:16,  9.85s/it]Loading train:   6%|▌         | 18/311 [03:11<47:40,  9.76s/it]Loading train:   6%|▌         | 19/311 [03:20<46:50,  9.62s/it]Loading train:   6%|▋         | 20/311 [03:29<46:11,  9.53s/it]Loading train:   7%|▋         | 21/311 [03:38<45:21,  9.38s/it]Loading train:   7%|▋         | 22/311 [03:47<44:22,  9.21s/it]Loading train:   7%|▋         | 23/311 [03:56<44:07,  9.19s/it]Loading train:   8%|▊         | 24/311 [04:06<43:48,  9.16s/it]Loading train:   8%|▊         | 25/311 [04:15<43:54,  9.21s/it]Loading train:   8%|▊         | 26/311 [04:24<43:21,  9.13s/it]Loading train:   9%|▊         | 27/311 [04:33<42:57,  9.08s/it]Loading train:   9%|▉         | 28/311 [04:42<42:22,  8.99s/it]Loading train:   9%|▉         | 29/311 [04:50<42:12,  8.98s/it]Loading train:  10%|▉         | 30/311 [04:59<41:39,  8.89s/it]Loading train:  10%|▉         | 31/311 [05:08<41:19,  8.86s/it]Loading train:  10%|█         | 32/311 [05:17<41:13,  8.87s/it]Loading train:  11%|█         | 33/311 [05:21<35:03,  7.57s/it]Loading train:  11%|█         | 34/311 [05:26<30:57,  6.71s/it]Loading train:  11%|█▏        | 35/311 [05:31<27:45,  6.03s/it]Loading train:  12%|█▏        | 36/311 [05:35<25:43,  5.61s/it]Loading train:  12%|█▏        | 37/311 [05:40<24:06,  5.28s/it]Loading train:  12%|█▏        | 38/311 [05:44<22:58,  5.05s/it]Loading train:  13%|█▎        | 39/311 [05:49<22:17,  4.92s/it]Loading train:  13%|█▎        | 40/311 [05:53<21:40,  4.80s/it]Loading train:  13%|█▎        | 41/311 [05:58<21:50,  4.85s/it]Loading train:  14%|█▎        | 42/311 [06:03<21:05,  4.71s/it]Loading train:  14%|█▍        | 43/311 [06:07<20:38,  4.62s/it]Loading train:  14%|█▍        | 44/311 [06:12<20:22,  4.58s/it]Loading train:  14%|█▍        | 45/311 [06:16<20:04,  4.53s/it]Loading train:  15%|█▍        | 46/311 [06:20<19:53,  4.50s/it]Loading train:  15%|█▌        | 47/311 [06:25<20:01,  4.55s/it]Loading train:  15%|█▌        | 48/311 [06:29<19:35,  4.47s/it]Loading train:  16%|█▌        | 49/311 [06:34<19:36,  4.49s/it]Loading train:  16%|█▌        | 50/311 [06:38<19:37,  4.51s/it]Loading train:  16%|█▋        | 51/311 [06:44<20:34,  4.75s/it]Loading train:  17%|█▋        | 52/311 [06:49<21:40,  5.02s/it]Loading train:  17%|█▋        | 53/311 [06:55<22:10,  5.16s/it]Loading train:  17%|█▋        | 54/311 [07:01<22:44,  5.31s/it]Loading train:  18%|█▊        | 55/311 [07:06<23:12,  5.44s/it]Loading train:  18%|█▊        | 56/311 [07:12<23:07,  5.44s/it]Loading train:  18%|█▊        | 57/311 [07:17<22:51,  5.40s/it]Loading train:  19%|█▊        | 58/311 [07:23<23:19,  5.53s/it]Loading train:  19%|█▉        | 59/311 [07:28<23:13,  5.53s/it]Loading train:  19%|█▉        | 60/311 [07:34<23:03,  5.51s/it]Loading train:  20%|█▉        | 61/311 [07:39<22:43,  5.46s/it]Loading train:  20%|█▉        | 62/311 [07:45<22:51,  5.51s/it]Loading train:  20%|██        | 63/311 [07:50<22:38,  5.48s/it]Loading train:  21%|██        | 64/311 [07:55<22:08,  5.38s/it]Loading train:  21%|██        | 65/311 [08:01<21:44,  5.30s/it]Loading train:  21%|██        | 66/311 [08:06<21:56,  5.37s/it]Loading train:  22%|██▏       | 67/311 [08:11<21:43,  5.34s/it]Loading train:  22%|██▏       | 68/311 [08:17<21:42,  5.36s/it]Loading train:  22%|██▏       | 69/311 [08:22<21:33,  5.35s/it]Loading train:  23%|██▎       | 70/311 [08:27<21:33,  5.37s/it]Loading train:  23%|██▎       | 71/311 [08:33<21:20,  5.33s/it]Loading train:  23%|██▎       | 72/311 [08:38<21:07,  5.30s/it]Loading train:  23%|██▎       | 73/311 [08:43<21:11,  5.34s/it]Loading train:  24%|██▍       | 74/311 [08:49<21:03,  5.33s/it]Loading train:  24%|██▍       | 75/311 [08:54<20:52,  5.31s/it]Loading train:  24%|██▍       | 76/311 [08:59<20:50,  5.32s/it]Loading train:  25%|██▍       | 77/311 [09:05<20:51,  5.35s/it]Loading train:  25%|██▌       | 78/311 [09:10<20:44,  5.34s/it]Loading train:  25%|██▌       | 79/311 [09:15<20:18,  5.25s/it]Loading train:  26%|██▌       | 80/311 [09:20<20:17,  5.27s/it]Loading train:  26%|██▌       | 81/311 [09:26<20:25,  5.33s/it]Loading train:  26%|██▋       | 82/311 [09:31<20:16,  5.31s/it]Loading train:  27%|██▋       | 83/311 [09:37<20:20,  5.35s/it]Loading train:  27%|██▋       | 84/311 [09:42<20:13,  5.34s/it]Loading train:  27%|██▋       | 85/311 [09:47<19:53,  5.28s/it]Loading train:  28%|██▊       | 86/311 [09:52<19:04,  5.09s/it]Loading train:  28%|██▊       | 87/311 [09:56<18:37,  4.99s/it]Loading train:  28%|██▊       | 88/311 [10:01<18:28,  4.97s/it]Loading train:  29%|██▊       | 89/311 [10:06<18:15,  4.93s/it]Loading train:  29%|██▉       | 90/311 [10:11<18:13,  4.95s/it]Loading train:  29%|██▉       | 91/311 [10:16<18:14,  4.98s/it]Loading train:  30%|██▉       | 92/311 [10:21<18:07,  4.97s/it]Loading train:  30%|██▉       | 93/311 [10:26<18:15,  5.02s/it]Loading train:  30%|███       | 94/311 [10:31<17:51,  4.94s/it]Loading train:  31%|███       | 95/311 [10:36<17:40,  4.91s/it]Loading train:  31%|███       | 96/311 [10:40<17:13,  4.81s/it]Loading train:  31%|███       | 97/311 [10:45<16:56,  4.75s/it]Loading train:  32%|███▏      | 98/311 [10:50<16:58,  4.78s/it]Loading train:  32%|███▏      | 99/311 [10:55<16:55,  4.79s/it]Loading train:  32%|███▏      | 100/311 [11:00<17:00,  4.83s/it]Loading train:  32%|███▏      | 101/311 [11:05<16:59,  4.85s/it]Loading train:  33%|███▎      | 102/311 [11:10<17:01,  4.89s/it]Loading train:  33%|███▎      | 103/311 [11:14<16:59,  4.90s/it]Loading train:  33%|███▎      | 104/311 [11:19<16:38,  4.82s/it]Loading train:  34%|███▍      | 105/311 [11:24<16:54,  4.92s/it]Loading train:  34%|███▍      | 106/311 [11:29<16:50,  4.93s/it]Loading train:  34%|███▍      | 107/311 [11:34<16:43,  4.92s/it]Loading train:  35%|███▍      | 108/311 [11:39<16:44,  4.95s/it]Loading train:  35%|███▌      | 109/311 [11:44<16:55,  5.03s/it]Loading train:  35%|███▌      | 110/311 [11:49<16:50,  5.03s/it]Loading train:  36%|███▌      | 111/311 [11:54<16:28,  4.94s/it]Loading train:  36%|███▌      | 112/311 [11:59<16:22,  4.94s/it]Loading train:  36%|███▋      | 113/311 [12:04<16:06,  4.88s/it]Loading train:  37%|███▋      | 114/311 [12:13<19:53,  6.06s/it]Loading train:  37%|███▋      | 115/311 [12:21<22:15,  6.81s/it]Loading train:  37%|███▋      | 116/311 [12:30<24:01,  7.39s/it]Loading train:  38%|███▊      | 117/311 [12:39<25:17,  7.82s/it]Loading train:  38%|███▊      | 118/311 [12:48<26:14,  8.16s/it]Loading train:  38%|███▊      | 119/311 [12:57<27:02,  8.45s/it]Loading train:  39%|███▊      | 120/311 [13:05<27:07,  8.52s/it]Loading train:  39%|███▉      | 121/311 [13:14<27:22,  8.65s/it]Loading train:  39%|███▉      | 122/311 [13:24<27:46,  8.82s/it]Loading train:  40%|███▉      | 123/311 [13:33<28:01,  8.94s/it]Loading train:  40%|███▉      | 124/311 [13:42<28:04,  9.01s/it]Loading train:  40%|████      | 125/311 [13:51<27:52,  8.99s/it]Loading train:  41%|████      | 126/311 [14:00<27:58,  9.07s/it]Loading train:  41%|████      | 127/311 [14:09<27:50,  9.08s/it]Loading train:  41%|████      | 128/311 [14:18<27:39,  9.07s/it]Loading train:  41%|████▏     | 129/311 [14:28<27:36,  9.10s/it]Loading train:  42%|████▏     | 130/311 [14:36<27:11,  9.01s/it]Loading train:  42%|████▏     | 131/311 [14:46<27:09,  9.05s/it]Loading train:  42%|████▏     | 132/311 [14:50<22:45,  7.63s/it]Loading train:  43%|████▎     | 133/311 [14:54<19:40,  6.63s/it]Loading train:  43%|████▎     | 134/311 [14:59<17:48,  6.04s/it]Loading train:  43%|████▎     | 135/311 [15:04<16:31,  5.64s/it]Loading train:  44%|████▎     | 136/311 [15:08<15:32,  5.33s/it]Loading train:  44%|████▍     | 137/311 [15:13<14:48,  5.10s/it]Loading train:  44%|████▍     | 138/311 [15:17<14:09,  4.91s/it]Loading train:  45%|████▍     | 139/311 [15:22<13:44,  4.79s/it]Loading train:  45%|████▌     | 140/311 [15:26<13:23,  4.70s/it]Loading train:  45%|████▌     | 141/311 [15:30<12:58,  4.58s/it]Loading train:  46%|████▌     | 142/311 [15:35<12:54,  4.58s/it]Loading train:  46%|████▌     | 143/311 [15:40<12:56,  4.62s/it]Loading train:  46%|████▋     | 144/311 [15:44<12:42,  4.56s/it]Loading train:  47%|████▋     | 145/311 [15:48<12:21,  4.47s/it]Loading train:  47%|████▋     | 146/311 [15:53<12:07,  4.41s/it]Loading train:  47%|████▋     | 147/311 [15:57<11:50,  4.33s/it]Loading train:  48%|████▊     | 148/311 [16:01<11:50,  4.36s/it]Loading train:  48%|████▊     | 149/311 [16:06<11:54,  4.41s/it]Loading train:  48%|████▊     | 150/311 [16:11<12:34,  4.69s/it]Loading train:  49%|████▊     | 151/311 [16:17<13:09,  4.93s/it]Loading train:  49%|████▉     | 152/311 [16:22<13:18,  5.02s/it]Loading train:  49%|████▉     | 153/311 [16:27<13:25,  5.10s/it]Loading train:  50%|████▉     | 154/311 [16:33<13:43,  5.24s/it]Loading train:  50%|████▉     | 155/311 [16:38<13:49,  5.31s/it]Loading train:  50%|█████     | 156/311 [16:44<13:53,  5.38s/it]Loading train:  50%|█████     | 157/311 [16:49<13:52,  5.40s/it]Loading train:  51%|█████     | 158/311 [16:55<13:50,  5.43s/it]Loading train:  51%|█████     | 159/311 [17:00<13:39,  5.39s/it]Loading train:  51%|█████▏    | 160/311 [17:05<13:32,  5.38s/it]Loading train:  52%|█████▏    | 161/311 [17:11<13:29,  5.40s/it]Loading train:  52%|█████▏    | 162/311 [17:16<13:36,  5.48s/it]Loading train:  52%|█████▏    | 163/311 [17:22<13:37,  5.52s/it]Loading train:  53%|█████▎    | 164/311 [17:27<13:26,  5.49s/it]Loading train:  53%|█████▎    | 165/311 [17:33<13:30,  5.55s/it]Loading train:  53%|█████▎    | 166/311 [17:38<13:05,  5.41s/it]Loading train:  54%|█████▎    | 167/311 [17:43<12:49,  5.34s/it]Loading train:  54%|█████▍    | 168/311 [17:49<13:00,  5.46s/it]Loading train:  54%|█████▍    | 169/311 [17:55<12:51,  5.43s/it]Loading train:  55%|█████▍    | 170/311 [18:00<12:38,  5.38s/it]Loading train:  55%|█████▍    | 171/311 [18:05<12:25,  5.33s/it]Loading train:  55%|█████▌    | 172/311 [18:11<12:29,  5.39s/it]Loading train:  56%|█████▌    | 173/311 [18:16<12:24,  5.39s/it]Loading train:  56%|█████▌    | 174/311 [18:21<12:19,  5.40s/it]Loading train:  56%|█████▋    | 175/311 [18:27<12:19,  5.44s/it]Loading train:  57%|█████▋    | 176/311 [18:32<12:12,  5.42s/it]Loading train:  57%|█████▋    | 177/311 [18:37<11:58,  5.36s/it]Loading train:  57%|█████▋    | 178/311 [18:43<11:48,  5.33s/it]Loading train:  58%|█████▊    | 179/311 [18:48<11:52,  5.40s/it]Loading train:  58%|█████▊    | 180/311 [18:53<11:30,  5.27s/it]Loading train:  58%|█████▊    | 181/311 [18:59<11:25,  5.27s/it]Loading train:  59%|█████▊    | 182/311 [19:03<11:07,  5.17s/it]Loading train:  59%|█████▉    | 183/311 [19:09<11:07,  5.22s/it]Loading train:  59%|█████▉    | 184/311 [19:14<10:51,  5.13s/it]Loading train:  59%|█████▉    | 185/311 [19:19<10:40,  5.08s/it]Loading train:  60%|█████▉    | 186/311 [19:24<10:31,  5.06s/it]Loading train:  60%|██████    | 187/311 [19:29<10:21,  5.01s/it]Loading train:  60%|██████    | 188/311 [19:33<10:05,  4.92s/it]Loading train:  61%|██████    | 189/311 [19:38<09:51,  4.85s/it]Loading train:  61%|██████    | 190/311 [19:43<09:40,  4.80s/it]Loading train:  61%|██████▏   | 191/311 [19:48<09:41,  4.85s/it]Loading train:  62%|██████▏   | 192/311 [19:53<09:42,  4.90s/it]Loading train:  62%|██████▏   | 193/311 [19:58<09:36,  4.88s/it]Loading train:  62%|██████▏   | 194/311 [20:02<09:31,  4.89s/it]Loading train:  63%|██████▎   | 195/311 [20:07<09:32,  4.93s/it]Loading train:  63%|██████▎   | 196/311 [20:12<09:27,  4.93s/it]Loading train:  63%|██████▎   | 197/311 [20:17<09:18,  4.90s/it]Loading train:  64%|██████▎   | 198/311 [20:22<09:18,  4.94s/it]Loading train:  64%|██████▍   | 199/311 [20:27<09:07,  4.89s/it]Loading train:  64%|██████▍   | 200/311 [20:32<08:58,  4.85s/it]Loading train:  65%|██████▍   | 201/311 [20:37<09:03,  4.94s/it]Loading train:  65%|██████▍   | 202/311 [20:42<09:03,  4.99s/it]Loading train:  65%|██████▌   | 203/311 [20:47<09:01,  5.01s/it]Loading train:  66%|██████▌   | 204/311 [20:52<09:00,  5.06s/it]Loading train:  66%|██████▌   | 205/311 [20:57<08:59,  5.09s/it]Loading train:  66%|██████▌   | 206/311 [21:02<08:50,  5.05s/it]Loading train:  67%|██████▋   | 207/311 [21:07<08:45,  5.05s/it]Loading train:  67%|██████▋   | 208/311 [21:13<08:45,  5.10s/it]Loading train:  67%|██████▋   | 209/311 [21:18<08:33,  5.03s/it]Loading train:  68%|██████▊   | 210/311 [21:22<08:21,  4.97s/it]Loading train:  68%|██████▊   | 211/311 [21:28<08:23,  5.03s/it]Loading train:  68%|██████▊   | 212/311 [21:32<08:08,  4.93s/it]Loading train:  68%|██████▊   | 213/311 [21:41<09:42,  5.94s/it]Loading train:  69%|██████▉   | 214/311 [21:50<11:10,  6.92s/it]Loading train:  69%|██████▉   | 215/311 [21:59<12:07,  7.58s/it]Loading train:  69%|██████▉   | 216/311 [22:08<12:38,  7.99s/it]Loading train:  70%|██████▉   | 217/311 [22:17<13:07,  8.38s/it]Loading train:  70%|███████   | 218/311 [22:26<13:10,  8.50s/it]Loading train:  70%|███████   | 219/311 [22:35<13:24,  8.74s/it]Loading train:  71%|███████   | 220/311 [22:44<13:22,  8.82s/it]Loading train:  71%|███████   | 221/311 [22:53<13:24,  8.94s/it]Loading train:  71%|███████▏  | 222/311 [23:03<13:21,  9.00s/it]Loading train:  72%|███████▏  | 223/311 [23:12<13:12,  9.00s/it]Loading train:  72%|███████▏  | 224/311 [23:21<13:11,  9.10s/it]Loading train:  72%|███████▏  | 225/311 [23:30<13:01,  9.08s/it]Loading train:  73%|███████▎  | 226/311 [23:39<12:58,  9.16s/it]Loading train:  73%|███████▎  | 227/311 [23:48<12:49,  9.16s/it]Loading train:  73%|███████▎  | 228/311 [23:58<12:43,  9.20s/it]Loading train:  74%|███████▎  | 229/311 [24:07<12:31,  9.16s/it]Loading train:  74%|███████▍  | 230/311 [24:16<12:21,  9.16s/it]Loading train:  74%|███████▍  | 231/311 [24:21<10:28,  7.86s/it]Loading train:  75%|███████▍  | 232/311 [24:26<09:08,  6.95s/it]Loading train:  75%|███████▍  | 233/311 [24:30<08:08,  6.26s/it]Loading train:  75%|███████▌  | 234/311 [24:35<07:23,  5.76s/it]Loading train:  76%|███████▌  | 235/311 [24:39<06:52,  5.43s/it]Loading train:  76%|███████▌  | 236/311 [24:44<06:31,  5.23s/it]Loading train:  76%|███████▌  | 237/311 [24:49<06:15,  5.07s/it]Loading train:  77%|███████▋  | 238/311 [24:53<05:59,  4.92s/it]Loading train:  77%|███████▋  | 239/311 [24:58<05:48,  4.84s/it]Loading train:  77%|███████▋  | 240/311 [25:03<05:43,  4.84s/it]Loading train:  77%|███████▋  | 241/311 [25:07<05:29,  4.70s/it]Loading train:  78%|███████▊  | 242/311 [25:12<05:19,  4.64s/it]Loading train:  78%|███████▊  | 243/311 [25:17<05:19,  4.70s/it]Loading train:  78%|███████▊  | 244/311 [25:21<05:10,  4.64s/it]Loading train:  79%|███████▉  | 245/311 [25:26<05:00,  4.55s/it]Loading train:  79%|███████▉  | 246/311 [25:30<04:57,  4.57s/it]Loading train:  79%|███████▉  | 247/311 [25:35<04:51,  4.56s/it]Loading train:  80%|███████▉  | 248/311 [25:39<04:45,  4.53s/it]Loading train:  80%|████████  | 249/311 [25:45<04:59,  4.83s/it]Loading train:  80%|████████  | 250/311 [25:50<05:10,  5.10s/it]Loading train:  81%|████████  | 251/311 [25:56<05:15,  5.25s/it]Loading train:  81%|████████  | 252/311 [26:02<05:15,  5.34s/it]Loading train:  81%|████████▏ | 253/311 [26:07<05:15,  5.43s/it]Loading train:  82%|████████▏ | 254/311 [26:13<05:18,  5.59s/it]Loading train:  82%|████████▏ | 255/311 [26:19<05:11,  5.56s/it]Loading train:  82%|████████▏ | 256/311 [26:24<05:09,  5.63s/it]Loading train:  83%|████████▎ | 257/311 [26:30<05:00,  5.56s/it]Loading train:  83%|████████▎ | 258/311 [26:35<04:55,  5.58s/it]Loading train:  83%|████████▎ | 259/311 [26:41<04:52,  5.62s/it]Loading train:  84%|████████▎ | 260/311 [26:47<04:46,  5.61s/it]Loading train:  84%|████████▍ | 261/311 [26:52<04:38,  5.58s/it]Loading train:  84%|████████▍ | 262/311 [26:58<04:33,  5.59s/it]Loading train:  85%|████████▍ | 263/311 [27:03<04:27,  5.57s/it]Loading train:  85%|████████▍ | 264/311 [27:09<04:23,  5.60s/it]Loading train:  85%|████████▌ | 265/311 [27:14<04:14,  5.53s/it]Loading train:  86%|████████▌ | 266/311 [27:20<04:12,  5.62s/it]Loading train:  86%|████████▌ | 267/311 [27:26<04:05,  5.58s/it]Loading train:  86%|████████▌ | 268/311 [27:31<03:58,  5.55s/it]Loading train:  86%|████████▋ | 269/311 [27:37<03:52,  5.53s/it]Loading train:  87%|████████▋ | 270/311 [27:42<03:44,  5.47s/it]Loading train:  87%|████████▋ | 271/311 [27:47<03:36,  5.41s/it]Loading train:  87%|████████▋ | 272/311 [27:53<03:33,  5.47s/it]Loading train:  88%|████████▊ | 273/311 [27:59<03:29,  5.51s/it]Loading train:  88%|████████▊ | 274/311 [28:04<03:24,  5.54s/it]Loading train:  88%|████████▊ | 275/311 [28:10<03:18,  5.50s/it]Loading train:  89%|████████▊ | 276/311 [28:15<03:10,  5.45s/it]Loading train:  89%|████████▉ | 277/311 [28:20<03:06,  5.47s/it]Loading train:  89%|████████▉ | 278/311 [28:26<03:01,  5.50s/it]Loading train:  90%|████████▉ | 279/311 [28:31<02:54,  5.44s/it]Loading train:  90%|█████████ | 280/311 [28:37<02:51,  5.52s/it]Loading train:  90%|█████████ | 281/311 [28:43<02:47,  5.59s/it]Loading train:  91%|█████████ | 282/311 [28:48<02:40,  5.53s/it]Loading train:  91%|█████████ | 283/311 [28:54<02:34,  5.53s/it]Loading train:  91%|█████████▏| 284/311 [28:59<02:27,  5.45s/it]Loading train:  92%|█████████▏| 285/311 [29:04<02:18,  5.33s/it]Loading train:  92%|█████████▏| 286/311 [29:09<02:11,  5.25s/it]Loading train:  92%|█████████▏| 287/311 [29:14<02:05,  5.23s/it]Loading train:  93%|█████████▎| 288/311 [29:19<02:00,  5.22s/it]Loading train:  93%|█████████▎| 289/311 [29:24<01:53,  5.17s/it]Loading train:  93%|█████████▎| 290/311 [29:30<01:49,  5.24s/it]Loading train:  94%|█████████▎| 291/311 [29:35<01:42,  5.11s/it]Loading train:  94%|█████████▍| 292/311 [29:40<01:36,  5.10s/it]Loading train:  94%|█████████▍| 293/311 [29:45<01:31,  5.07s/it]Loading train:  95%|█████████▍| 294/311 [29:50<01:25,  5.04s/it]Loading train:  95%|█████████▍| 295/311 [29:55<01:20,  5.03s/it]Loading train:  95%|█████████▌| 296/311 [30:00<01:16,  5.09s/it]Loading train:  95%|█████████▌| 297/311 [30:05<01:10,  5.07s/it]Loading train:  96%|█████████▌| 298/311 [30:10<01:05,  5.03s/it]Loading train:  96%|█████████▌| 299/311 [30:15<01:00,  5.05s/it]Loading train:  96%|█████████▋| 300/311 [30:20<00:54,  4.99s/it]Loading train:  97%|█████████▋| 301/311 [30:25<00:50,  5.03s/it]Loading train:  97%|█████████▋| 302/311 [30:30<00:46,  5.14s/it]Loading train:  97%|█████████▋| 303/311 [30:36<00:41,  5.17s/it]Loading train:  98%|█████████▊| 304/311 [30:41<00:35,  5.10s/it]Loading train:  98%|█████████▊| 305/311 [30:46<00:30,  5.08s/it]Loading train:  98%|█████████▊| 306/311 [30:51<00:26,  5.20s/it]Loading train:  99%|█████████▊| 307/311 [30:56<00:20,  5.19s/it]Loading train:  99%|█████████▉| 308/311 [31:02<00:15,  5.25s/it]Loading train:  99%|█████████▉| 309/311 [31:07<00:10,  5.23s/it]Loading train: 100%|█████████▉| 310/311 [31:12<00:05,  5.16s/it]Loading train: 100%|██████████| 311/311 [31:17<00:00,  5.17s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/311 [00:00<00:07, 42.89it/s]concatenating: train:   5%|▍         | 14/311 [00:00<00:05, 50.50it/s]concatenating: train:   8%|▊         | 26/311 [00:00<00:04, 60.76it/s]concatenating: train:  15%|█▌        | 47/311 [00:00<00:03, 75.76it/s]concatenating: train:  21%|██        | 66/311 [00:00<00:02, 92.37it/s]concatenating: train:  28%|██▊       | 86/311 [00:00<00:02, 109.62it/s]concatenating: train:  37%|███▋      | 114/311 [00:00<00:01, 133.56it/s]concatenating: train:  43%|████▎     | 133/311 [00:00<00:01, 143.94it/s]concatenating: train:  50%|████▉     | 155/311 [00:00<00:00, 159.68it/s]concatenating: train:  57%|█████▋    | 176/311 [00:01<00:00, 169.23it/s]concatenating: train:  63%|██████▎   | 196/311 [00:01<00:00, 149.26it/s]concatenating: train:  69%|██████▉   | 214/311 [00:01<00:00, 155.61it/s]concatenating: train:  77%|███████▋  | 238/311 [00:01<00:00, 173.88it/s]concatenating: train:  84%|████████▎ | 260/311 [00:01<00:00, 185.43it/s]concatenating: train:  91%|█████████▏| 284/311 [00:01<00:00, 197.66it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 179.49it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 11.87s/it]Loading test:  50%|█████     | 2/4 [00:22<00:23, 11.59s/it]Loading test:  75%|███████▌  | 3/4 [00:34<00:11, 11.67s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.65s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 48.34it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 20)   80          conv2d_7[0][0]                   2019-07-07 08:06:49.149686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 08:06:49.149797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 08:06:49.149812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 08:06:49.149821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 08:06:49.150218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [5.86066190e-02 2.84688586e-02 1.21642213e-01 1.04576120e-02
 3.14646619e-02 5.44310893e-03 7.20519791e-02 1.12887958e-01
 7.85252165e-02 1.27448500e-02 2.91951514e-01 1.75516909e-01
 2.38500254e-04]
Train on 12832 samples, validate on 168 samples
Epoch 1/300
 - 19s - loss: 23093.3479 - acc: 0.8626 - mDice: 0.1263 - val_loss: 20425.9468 - val_acc: 0.8767 - val_mDice: 0.2203

Epoch 00001: val_mDice improved from -inf to 0.22035, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 15585.3964 - acc: 0.8728 - mDice: 0.2245 - val_loss: 19089.6508 - val_acc: 0.8752 - val_mDice: 0.2705

Epoch 00002: val_mDice improved from 0.22035 to 0.27054, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 14224.6253 - acc: 0.8821 - mDice: 0.2798 - val_loss: 11445.9333 - val_acc: 0.8814 - val_mDice: 0.3518

Epoch 00003: val_mDice improved from 0.27054 to 0.35183, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 13182.0553 - acc: 0.8913 - mDice: 0.3398 - val_loss: 10738.1415 - val_acc: 0.8950 - val_mDice: 0.4164

Epoch 00004: val_mDice improved from 0.35183 to 0.41639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 10s - loss: 8737.8054 - acc: 0.8916 - mDice: 0.3524 - val_loss: 3880.2592 - val_acc: 0.9001 - val_mDice: 0.4387

Epoch 00005: val_mDice improved from 0.41639 to 0.43867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 4819.6618 - acc: 0.8969 - mDice: 0.3997 - val_loss: 3363.5437 - val_acc: 0.8995 - val_mDice: 0.4843

Epoch 00006: val_mDice improved from 0.43867 to 0.48430, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 4226.1958 - acc: 0.9035 - mDice: 0.4410 - val_loss: 3022.0482 - val_acc: 0.9106 - val_mDice: 0.5199

Epoch 00007: val_mDice improved from 0.48430 to 0.51989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 3872.4854 - acc: 0.9080 - mDice: 0.4708 - val_loss: 2908.9355 - val_acc: 0.9152 - val_mDice: 0.5373

Epoch 00008: val_mDice improved from 0.51989 to 0.53735, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 3646.7111 - acc: 0.9110 - mDice: 0.4913 - val_loss: 2758.5518 - val_acc: 0.9232 - val_mDice: 0.5563

Epoch 00009: val_mDice improved from 0.53735 to 0.55633, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 10s - loss: 3446.3395 - acc: 0.9140 - mDice: 0.5106 - val_loss: 2785.3872 - val_acc: 0.9201 - val_mDice: 0.5545

Epoch 00010: val_mDice did not improve from 0.55633
Epoch 11/300
 - 10s - loss: 3298.4222 - acc: 0.9163 - mDice: 0.5254 - val_loss: 2686.5099 - val_acc: 0.9252 - val_mDice: 0.5651

Epoch 00011: val_mDice improved from 0.55633 to 0.56512, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 3175.1212 - acc: 0.9182 - mDice: 0.5376 - val_loss: 2630.5231 - val_acc: 0.9272 - val_mDice: 0.5730

Epoch 00012: val_mDice improved from 0.56512 to 0.57295, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 3057.7424 - acc: 0.9200 - mDice: 0.5497 - val_loss: 2442.1264 - val_acc: 0.9345 - val_mDice: 0.5940

Epoch 00013: val_mDice improved from 0.57295 to 0.59403, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 10s - loss: 2964.0805 - acc: 0.9214 - mDice: 0.5596 - val_loss: 2432.6338 - val_acc: 0.9311 - val_mDice: 0.5923

Epoch 00014: val_mDice did not improve from 0.59403
Epoch 15/300
 - 9s - loss: 2862.6575 - acc: 0.9226 - mDice: 0.5702 - val_loss: 2422.2462 - val_acc: 0.9344 - val_mDice: 0.5946

Epoch 00015: val_mDice improved from 0.59403 to 0.59464, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 10s - loss: 2792.9720 - acc: 0.9239 - mDice: 0.5776 - val_loss: 2483.3380 - val_acc: 0.9303 - val_mDice: 0.5903

Epoch 00016: val_mDice did not improve from 0.59464
Epoch 17/300
 - 10s - loss: 2724.7275 - acc: 0.9250 - mDice: 0.5849 - val_loss: 2439.2483 - val_acc: 0.9365 - val_mDice: 0.5959

Epoch 00017: val_mDice improved from 0.59464 to 0.59592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 9s - loss: 2655.8690 - acc: 0.9261 - mDice: 0.5920 - val_loss: 2426.1942 - val_acc: 0.9312 - val_mDice: 0.5917

Epoch 00018: val_mDice did not improve from 0.59592
Epoch 19/300
 - 9s - loss: 2584.4512 - acc: 0.9268 - mDice: 0.5992 - val_loss: 2166.9456 - val_acc: 0.9380 - val_mDice: 0.6200

Epoch 00019: val_mDice improved from 0.59592 to 0.61995, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 10s - loss: 2522.2818 - acc: 0.9277 - mDice: 0.6055 - val_loss: 2062.0915 - val_acc: 0.9391 - val_mDice: 0.6318

Epoch 00020: val_mDice improved from 0.61995 to 0.63176, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 9s - loss: 2455.1404 - acc: 0.9284 - mDice: 0.6130 - val_loss: 2012.8355 - val_acc: 0.9395 - val_mDice: 0.6371

Epoch 00021: val_mDice improved from 0.63176 to 0.63707, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 9s - loss: 2404.7193 - acc: 0.9289 - mDice: 0.6183 - val_loss: 1988.6143 - val_acc: 0.9416 - val_mDice: 0.6405

Epoch 00022: val_mDice improved from 0.63707 to 0.64054, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 10s - loss: 2343.8106 - acc: 0.9299 - mDice: 0.6253 - val_loss: 2051.6726 - val_acc: 0.9381 - val_mDice: 0.6335

Epoch 00023: val_mDice did not improve from 0.64054
Epoch 24/300
 - 9s - loss: 2308.4650 - acc: 0.9303 - mDice: 0.6296 - val_loss: 2156.9457 - val_acc: 0.9373 - val_mDice: 0.6217

Epoch 00024: val_mDice did not improve from 0.64054
Epoch 25/300
 - 9s - loss: 2271.4472 - acc: 0.9309 - mDice: 0.6339 - val_loss: 2015.2778 - val_acc: 0.9389 - val_mDice: 0.6393

Epoch 00025: val_mDice did not improve from 0.64054
Epoch 26/300
 - 10s - loss: 2229.7715 - acc: 0.9315 - mDice: 0.6388 - val_loss: 2058.3946 - val_acc: 0.9409 - val_mDice: 0.6340

Epoch 00026: val_mDice did not improve from 0.64054
Epoch 27/300
 - 10s - loss: 2193.7288 - acc: 0.9319 - mDice: 0.6433 - val_loss: 1881.7612 - val_acc: 0.9444 - val_mDice: 0.6561

Epoch 00027: val_mDice improved from 0.64054 to 0.65606, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 9s - loss: 2168.4704 - acc: 0.9325 - mDice: 0.6463 - val_loss: 1928.3001 - val_acc: 0.9433 - val_mDice: 0.6493

Epoch 00028: val_mDice did not improve from 0.65606
Epoch 29/300
 - 10s - loss: 2131.4565 - acc: 0.9330 - mDice: 0.6512 - val_loss: 1982.9353 - val_acc: 0.9410 - val_mDice: 0.6429

Epoch 00029: val_mDice did not improve from 0.65606
Epoch 30/300
 - 10s - loss: 2106.0968 - acc: 0.9335 - mDice: 0.6542 - val_loss: 1852.3020 - val_acc: 0.9451 - val_mDice: 0.6580

Epoch 00030: val_mDice improved from 0.65606 to 0.65801, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 9s - loss: 2080.5482 - acc: 0.9338 - mDice: 0.6575 - val_loss: 1916.5396 - val_acc: 0.9441 - val_mDice: 0.6510

Epoch 00031: val_mDice did not improve from 0.65801
Epoch 32/300
 - 10s - loss: 2055.0753 - acc: 0.9343 - mDice: 0.6607 - val_loss: 2204.8889 - val_acc: 0.9323 - val_mDice: 0.6152

Epoch 00032: val_mDice did not improve from 0.65801
Epoch 33/300
 - 10s - loss: 2018.8757 - acc: 0.9349 - mDice: 0.6654 - val_loss: 2016.3323 - val_acc: 0.9424 - val_mDice: 0.6415

Epoch 00033: val_mDice did not improve from 0.65801
Epoch 34/300
 - 9s - loss: 2008.8685 - acc: 0.9352 - mDice: 0.6669 - val_loss: 2103.6015 - val_acc: 0.9382 - val_mDice: 0.6264

Epoch 00034: val_mDice did not improve from 0.65801
Epoch 35/300
 - 10s - loss: 1991.8051 - acc: 0.9354 - mDice: 0.6690 - val_loss: 1842.2521 - val_acc: 0.9477 - val_mDice: 0.6616

Epoch 00035: val_mDice improved from 0.65801 to 0.66156, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 36/300
 - 10s - loss: 1967.7028 - acc: 0.9358 - mDice: 0.6724 - val_loss: 1785.6296 - val_acc: 0.9475 - val_mDice: 0.6687

Epoch 00036: val_mDice improved from 0.66156 to 0.66872, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 9s - loss: 1948.9388 - acc: 0.9361 - mDice: 0.6747 - val_loss: 1902.1949 - val_acc: 0.9470 - val_mDice: 0.6524

Epoch 00037: val_mDice did not improve from 0.66872
Epoch 38/300
 - 10s - loss: 1924.1527 - acc: 0.9365 - mDice: 0.6782 - val_loss: 1912.2770 - val_acc: 0.9470 - val_mDice: 0.6537

Epoch 00038: val_mDice did not improve from 0.66872
Epoch 39/300
 - 10s - loss: 1911.1895 - acc: 0.9370 - mDice: 0.6799 - val_loss: 2228.7729 - val_acc: 0.9361 - val_mDice: 0.6149

Epoch 00039: val_mDice did not improve from 0.66872
Epoch 40/300
 - 9s - loss: 1887.5515 - acc: 0.9373 - mDice: 0.6831 - val_loss: 2105.5180 - val_acc: 0.9396 - val_mDice: 0.6307

Epoch 00040: val_mDice did not improve from 0.66872
Epoch 41/300
 - 10s - loss: 1874.6880 - acc: 0.9375 - mDice: 0.6847 - val_loss: 2363.9980 - val_acc: 0.9300 - val_mDice: 0.5951

Epoch 00041: val_mDice did not improve from 0.66872
Epoch 42/300
 - 10s - loss: 1851.1379 - acc: 0.9379 - mDice: 0.6879 - val_loss: 1827.1950 - val_acc: 0.9484 - val_mDice: 0.6641

Epoch 00042: val_mDice did not improve from 0.66872
Epoch 43/300
 - 9s - loss: 1835.0552 - acc: 0.9381 - mDice: 0.6901 - val_loss: 1901.7155 - val_acc: 0.9471 - val_mDice: 0.6554

Epoch 00043: val_mDice did not improve from 0.66872
Epoch 44/300
 - 10s - loss: 1815.8268 - acc: 0.9385 - mDice: 0.6928 - val_loss: 1969.7160 - val_acc: 0.9408 - val_mDice: 0.6450

Epoch 00044: val_mDice did not improve from 0.66872
Epoch 45/300
 - 10s - loss: 1793.3765 - acc: 0.9388 - mDice: 0.6957 - val_loss: 1778.4848 - val_acc: 0.9490 - val_mDice: 0.6721

Epoch 00045: val_mDice improved from 0.66872 to 0.67213, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 46/300
 - 9s - loss: 1789.2044 - acc: 0.9390 - mDice: 0.6965 - val_loss: 1889.3411 - val_acc: 0.9450 - val_mDice: 0.6575

Epoch 00046: val_mDice did not improve from 0.67213
Epoch 47/300
 - 10s - loss: 1769.4035 - acc: 0.9393 - mDice: 0.6991 - val_loss: 2553.5268 - val_acc: 0.9277 - val_mDice: 0.5755

Epoch 00047: val_mDice did not improve from 0.67213
Epoch 48/300
 - 10s - loss: 1766.7943 - acc: 0.9394 - mDice: 0.6996 - val_loss: 1886.9360 - val_acc: 0.9432 - val_mDice: 0.6562

Epoch 00048: val_mDice did not improve from 0.67213
Epoch 49/300
 - 9s - loss: 1745.5984 - acc: 0.9398 - mDice: 0.7023 - val_loss: 1804.8980 - val_acc: 0.9496 - val_mDice: 0.6688

Epoch 00049: val_mDice did not improve from 0.67213
Epoch 50/300
 - 10s - loss: 1730.4418 - acc: 0.9399 - mDice: 0.7044 - val_loss: 1894.6578 - val_acc: 0.9439 - val_mDice: 0.6570

Epoch 00050: val_mDice did not improve from 0.67213
Epoch 51/300
 - 10s - loss: 1719.0813 - acc: 0.9402 - mDice: 0.7061 - val_loss: 1723.6071 - val_acc: 0.9502 - val_mDice: 0.6802

Epoch 00051: val_mDice improved from 0.67213 to 0.68023, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 52/300
 - 9s - loss: 1699.8405 - acc: 0.9407 - mDice: 0.7088 - val_loss: 1781.3811 - val_acc: 0.9507 - val_mDice: 0.6728

Epoch 00052: val_mDice did not improve from 0.68023
Epoch 53/300
 - 9s - loss: 1680.7985 - acc: 0.9408 - mDice: 0.7113 - val_loss: 1830.0805 - val_acc: 0.9495 - val_mDice: 0.6655

Epoch 00053: val_mDice did not improve from 0.68023
Epoch 54/300
 - 10s - loss: 1671.2730 - acc: 0.9411 - mDice: 0.7128 - val_loss: 1736.6235 - val_acc: 0.9514 - val_mDice: 0.6788

Epoch 00054: val_mDice did not improve from 0.68023
Epoch 55/300
 - 10s - loss: 1660.1465 - acc: 0.9413 - mDice: 0.7143 - val_loss: 1818.5810 - val_acc: 0.9472 - val_mDice: 0.6672

Epoch 00055: val_mDice did not improve from 0.68023
Epoch 56/300
 - 9s - loss: 1646.2315 - acc: 0.9415 - mDice: 0.7162 - val_loss: 1790.1187 - val_acc: 0.9492 - val_mDice: 0.6713

Epoch 00056: val_mDice did not improve from 0.68023
Epoch 57/300
 - 10s - loss: 1643.6156 - acc: 0.9415 - mDice: 0.7167 - val_loss: 1889.7996 - val_acc: 0.9477 - val_mDice: 0.6585

Epoch 00057: val_mDice did not improve from 0.68023
Epoch 58/300
 - 10s - loss: 1619.9150 - acc: 0.9419 - mDice: 0.7200 - val_loss: 1780.7590 - val_acc: 0.9520 - val_mDice: 0.6738

Epoch 00058: val_mDice did not improve from 0.68023
Epoch 59/300
 - 10s - loss: 1618.2663 - acc: 0.9419 - mDice: 0.7203 - val_loss: 1790.0348 - val_acc: 0.9505 - val_mDice: 0.6713

Epoch 00059: val_mDice did not improve from 0.68023
Epoch 60/300
 - 11s - loss: 1613.4334 - acc: 0.9421 - mDice: 0.7210 - val_loss: 1845.7997 - val_acc: 0.9476 - val_mDice: 0.6631

Epoch 00060: val_mDice did not improve from 0.68023
Epoch 61/300
 - 10s - loss: 1589.5934 - acc: 0.9424 - mDice: 0.7244 - val_loss: 1722.2026 - val_acc: 0.9512 - val_mDice: 0.6801

Epoch 00061: val_mDice did not improve from 0.68023
Epoch 62/300
 - 10s - loss: 1598.3331 - acc: 0.9423 - mDice: 0.7232 - val_loss: 1796.9399 - val_acc: 0.9493 - val_mDice: 0.6714

Epoch 00062: val_mDice did not improve from 0.68023
Epoch 63/300
 - 11s - loss: 1589.0301 - acc: 0.9425 - mDice: 0.7245 - val_loss: 1852.4371 - val_acc: 0.9463 - val_mDice: 0.6632

Epoch 00063: val_mDice did not improve from 0.68023
Epoch 64/300
 - 10s - loss: 1571.8273 - acc: 0.9429 - mDice: 0.7270 - val_loss: 1899.6990 - val_acc: 0.9448 - val_mDice: 0.6564

Epoch 00064: val_mDice did not improve from 0.68023
Epoch 65/300
 - 10s - loss: 1562.1390 - acc: 0.9431 - mDice: 0.7284 - val_loss: 1718.5840 - val_acc: 0.9508 - val_mDice: 0.6810

Epoch 00065: val_mDice improved from 0.68023 to 0.68102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 66/300
 - 11s - loss: 1557.0351 - acc: 0.9432 - mDice: 0.7291 - val_loss: 1748.9479 - val_acc: 0.9476 - val_mDice: 0.6759

Epoch 00066: val_mDice did not improve from 0.68102
Epoch 67/300
 - 9s - loss: 1542.2920 - acc: 0.9434 - mDice: 0.7313 - val_loss: 1806.0415 - val_acc: 0.9457 - val_mDice: 0.6677

Epoch 00067: val_mDice did not improve from 0.68102
Epoch 68/300
 - 10s - loss: 1534.8174 - acc: 0.9435 - mDice: 0.7323 - val_loss: 1689.2782 - val_acc: 0.9539 - val_mDice: 0.6852

Epoch 00068: val_mDice improved from 0.68102 to 0.68522, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 69/300
 - 11s - loss: 1530.9160 - acc: 0.9435 - mDice: 0.7330 - val_loss: 1815.0244 - val_acc: 0.9454 - val_mDice: 0.6666

Epoch 00069: val_mDice did not improve from 0.68522
Epoch 70/300
 - 10s - loss: 1516.8483 - acc: 0.9436 - mDice: 0.7350 - val_loss: 1709.3440 - val_acc: 0.9530 - val_mDice: 0.6818

Epoch 00070: val_mDice did not improve from 0.68522
Epoch 71/300
 - 10s - loss: 1518.0221 - acc: 0.9437 - mDice: 0.7349 - val_loss: 1788.8147 - val_acc: 0.9487 - val_mDice: 0.6715

Epoch 00071: val_mDice did not improve from 0.68522
Epoch 72/300
 - 11s - loss: 1508.6094 - acc: 0.9439 - mDice: 0.7361 - val_loss: 1731.6648 - val_acc: 0.9509 - val_mDice: 0.6793

Epoch 00072: val_mDice did not improve from 0.68522
Epoch 73/300
 - 10s - loss: 1507.5613 - acc: 0.9437 - mDice: 0.7365 - val_loss: 1823.1221 - val_acc: 0.9456 - val_mDice: 0.6653

Epoch 00073: val_mDice did not improve from 0.68522
Epoch 74/300
 - 10s - loss: 1496.8809 - acc: 0.9439 - mDice: 0.7379 - val_loss: 1690.5246 - val_acc: 0.9522 - val_mDice: 0.6838

Epoch 00074: val_mDice did not improve from 0.68522
Epoch 75/300
 - 11s - loss: 1492.1110 - acc: 0.9441 - mDice: 0.7387 - val_loss: 1796.3431 - val_acc: 0.9501 - val_mDice: 0.6722

Epoch 00075: val_mDice did not improve from 0.68522
Epoch 76/300
 - 10s - loss: 1480.8107 - acc: 0.9443 - mDice: 0.7404 - val_loss: 1855.1378 - val_acc: 0.9498 - val_mDice: 0.6647

Epoch 00076: val_mDice did not improve from 0.68522
Epoch 77/300
 - 10s - loss: 1475.2914 - acc: 0.9443 - mDice: 0.7412 - val_loss: 2355.1347 - val_acc: 0.9304 - val_mDice: 0.5959

Epoch 00077: val_mDice did not improve from 0.68522
Epoch 78/300
 - 11s - loss: 1466.4996 - acc: 0.9445 - mDice: 0.7426 - val_loss: 1709.0683 - val_acc: 0.9524 - val_mDice: 0.6820

Epoch 00078: val_mDice did not improve from 0.68522
Epoch 79/300
 - 10s - loss: 1464.6563 - acc: 0.9446 - mDice: 0.7428 - val_loss: 1735.4851 - val_acc: 0.9551 - val_mDice: 0.6797

Epoch 00079: val_mDice did not improve from 0.68522
Epoch 80/300
 - 10s - loss: 1463.1858 - acc: 0.9446 - mDice: 0.7430 - val_loss: 1761.3732 - val_acc: 0.9518 - val_mDice: 0.6771

Epoch 00080: val_mDice did not improve from 0.68522
Epoch 81/300
 - 11s - loss: 1444.2714 - acc: 0.9447 - mDice: 0.7458 - val_loss: 1765.6636 - val_acc: 0.9517 - val_mDice: 0.6757

Epoch 00081: val_mDice did not improve from 0.68522
Epoch 82/300
 - 10s - loss: 1445.1200 - acc: 0.9448 - mDice: 0.7457 - val_loss: 1784.0172 - val_acc: 0.9449 - val_mDice: 0.6710

Epoch 00082: val_mDice did not improve from 0.68522
Epoch 83/300
 - 10s - loss: 1435.3973 - acc: 0.9449 - mDice: 0.7470 - val_loss: 1708.9019 - val_acc: 0.9512 - val_mDice: 0.6820

Epoch 00083: val_mDice did not improve from 0.68522
Epoch 84/300
 - 10s - loss: 1439.2585 - acc: 0.9449 - mDice: 0.7465 - val_loss: 1700.5426 - val_acc: 0.9543 - val_mDice: 0.6835

Epoch 00084: val_mDice did not improve from 0.68522
Epoch 85/300
 - 10s - loss: 1437.6439 - acc: 0.9450 - mDice: 0.7468 - val_loss: 1643.1651 - val_acc: 0.9538 - val_mDice: 0.6920

Epoch 00085: val_mDice improved from 0.68522 to 0.69199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 86/300
 - 10s - loss: 1426.8982 - acc: 0.9452 - mDice: 0.7484 - val_loss: 1711.8129 - val_acc: 0.9537 - val_mDice: 0.6832

Epoch 00086: val_mDice did not improve from 0.69199
Epoch 87/300
 - 11s - loss: 1421.3854 - acc: 0.9452 - mDice: 0.7491 - val_loss: 1641.9239 - val_acc: 0.9542 - val_mDice: 0.6920

Epoch 00087: val_mDice did not improve from 0.69199
Epoch 88/300
 - 10s - loss: 1417.7115 - acc: 0.9453 - mDice: 0.7497 - val_loss: 1694.0333 - val_acc: 0.9496 - val_mDice: 0.6843

Epoch 00088: val_mDice did not improve from 0.69199
Epoch 89/300
 - 10s - loss: 1415.5005 - acc: 0.9454 - mDice: 0.7501 - val_loss: 1720.4774 - val_acc: 0.9529 - val_mDice: 0.6819

Epoch 00089: val_mDice did not improve from 0.69199
Epoch 90/300
 - 10s - loss: 1413.9911 - acc: 0.9455 - mDice: 0.7509 - val_loss: 1792.4165 - val_acc: 0.9500 - val_mDice: 0.6709

Epoch 00090: val_mDice did not improve from 0.69199
Epoch 91/300
 - 10s - loss: 1399.9343 - acc: 0.9456 - mDice: 0.7525 - val_loss: 1719.3479 - val_acc: 0.9533 - val_mDice: 0.6812

Epoch 00091: val_mDice did not improve from 0.69199
Epoch 92/300
 - 10s - loss: 1393.1293 - acc: 0.9457 - mDice: 0.7535 - val_loss: 1679.2486 - val_acc: 0.9539 - val_mDice: 0.6854

Epoch 00092: val_mDice did not improve from 0.69199
Epoch 93/300
 - 10s - loss: 1400.9283 - acc: 0.9456 - mDice: 0.7522 - val_loss: 1699.5028 - val_acc: 0.9543 - val_mDice: 0.6828

Epoch 00093: val_mDice did not improve from 0.69199
Epoch 94/300
 - 10s - loss: 1392.0093 - acc: 0.9458 - mDice: 0.7536 - val_loss: 1787.6816 - val_acc: 0.9513 - val_mDice: 0.6708

Epoch 00094: val_mDice did not improve from 0.69199
Epoch 95/300
 - 10s - loss: 1382.4871 - acc: 0.9459 - mDice: 0.7550 - val_loss: 1726.5741 - val_acc: 0.9520 - val_mDice: 0.6818

Epoch 00095: val_mDice did not improve from 0.69199
Epoch 96/300
 - 11s - loss: 1377.1436 - acc: 0.9462 - mDice: 0.7559 - val_loss: 1801.4978 - val_acc: 0.9448 - val_mDice: 0.6677

Epoch 00096: val_mDice did not improve from 0.69199
Epoch 97/300
 - 10s - loss: 1368.9853 - acc: 0.9460 - mDice: 0.7570 - val_loss: 1695.7862 - val_acc: 0.9517 - val_mDice: 0.6838

Epoch 00097: val_mDice did not improve from 0.69199
Epoch 98/300
 - 10s - loss: 1370.9826 - acc: 0.9461 - mDice: 0.7568 - val_loss: 1683.0074 - val_acc: 0.9526 - val_mDice: 0.6852

Epoch 00098: val_mDice did not improve from 0.69199
Epoch 99/300
 - 10s - loss: 1364.4997 - acc: 0.9463 - mDice: 0.7578 - val_loss: 1647.3169 - val_acc: 0.9538 - val_mDice: 0.6910

Epoch 00099: val_mDice did not improve from 0.69199
Epoch 100/300
 - 10s - loss: 1360.8492 - acc: 0.9464 - mDice: 0.7582 - val_loss: 1687.5270 - val_acc: 0.9558 - val_mDice: 0.6858

Epoch 00100: val_mDice did not improve from 0.69199
Epoch 101/300
 - 10s - loss: 1358.6745 - acc: 0.9465 - mDice: 0.7586 - val_loss: 1921.9353 - val_acc: 0.9429 - val_mDice: 0.6522

Epoch 00101: val_mDice did not improve from 0.69199
Epoch 102/300
 - 10s - loss: 1361.0233 - acc: 0.9464 - mDice: 0.7582 - val_loss: 1665.6665 - val_acc: 0.9531 - val_mDice: 0.6889

Epoch 00102: val_mDice did not improve from 0.69199
Epoch 103/300
 - 10s - loss: 1361.2136 - acc: 0.9463 - mDice: 0.7582 - val_loss: 1788.4194 - val_acc: 0.9490 - val_mDice: 0.6709

Epoch 00103: val_mDice did not improve from 0.69199
Epoch 104/300
 - 11s - loss: 1348.9976 - acc: 0.9465 - mDice: 0.7600 - val_loss: 1676.2084 - val_acc: 0.9535 - val_mDice: 0.6864

Epoch 00104: val_mDice did not improve from 0.69199
Epoch 105/300
 - 10s - loss: 1347.7456 - acc: 0.9465 - mDice: 0.7603 - val_loss: 1688.6340 - val_acc: 0.9525 - val_mDice: 0.6858

Epoch 00105: val_mDice did not improve from 0.69199
Epoch 106/300
 - 11s - loss: 1345.0761 - acc: 0.9465 - mDice: 0.7606 - val_loss: 1681.3512 - val_acc: 0.9527 - val_mDice: 0.6873

Epoch 00106: val_mDice did not improve from 0.69199
Epoch 107/300
 - 10s - loss: 1334.2257 - acc: 0.9467 - mDice: 0.7623 - val_loss: 1651.8117 - val_acc: 0.9553 - val_mDice: 0.6911

Epoch 00107: val_mDice did not improve from 0.69199
Epoch 108/300
 - 10s - loss: 1337.8390 - acc: 0.9467 - mDice: 0.7618 - val_loss: 1616.3973 - val_acc: 0.9560 - val_mDice: 0.6948

Epoch 00108: val_mDice improved from 0.69199 to 0.69476, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 109/300
 - 11s - loss: 1329.9619 - acc: 0.9469 - mDice: 0.7630 - val_loss: 1817.3948 - val_acc: 0.9529 - val_mDice: 0.6650

Epoch 00109: val_mDice did not improve from 0.69476
Epoch 110/300
 - 10s - loss: 1330.4582 - acc: 0.9468 - mDice: 0.7628 - val_loss: 1679.1342 - val_acc: 0.9515 - val_mDice: 0.6874

Epoch 00110: val_mDice did not improve from 0.69476
Epoch 111/300
 - 11s - loss: 1326.9546 - acc: 0.9469 - mDice: 0.7634 - val_loss: 1719.4887 - val_acc: 0.9493 - val_mDice: 0.6801

Epoch 00111: val_mDice did not improve from 0.69476
Epoch 112/300
 - 10s - loss: 1326.9768 - acc: 0.9469 - mDice: 0.7634 - val_loss: 1793.9058 - val_acc: 0.9477 - val_mDice: 0.6712

Epoch 00112: val_mDice did not improve from 0.69476
Epoch 113/300
 - 10s - loss: 1323.8145 - acc: 0.9469 - mDice: 0.7639 - val_loss: 1903.5176 - val_acc: 0.9457 - val_mDice: 0.6534

Epoch 00113: val_mDice did not improve from 0.69476
Epoch 114/300
 - 11s - loss: 1320.5850 - acc: 0.9470 - mDice: 0.7644 - val_loss: 1667.1786 - val_acc: 0.9533 - val_mDice: 0.6886

Epoch 00114: val_mDice did not improve from 0.69476
Epoch 115/300
 - 9s - loss: 1313.3267 - acc: 0.9471 - mDice: 0.7655 - val_loss: 1801.0258 - val_acc: 0.9475 - val_mDice: 0.6703

Epoch 00115: val_mDice did not improve from 0.69476
Epoch 116/300
 - 10s - loss: 1309.1649 - acc: 0.9471 - mDice: 0.7661 - val_loss: 1864.1823 - val_acc: 0.9431 - val_mDice: 0.6617

Epoch 00116: val_mDice did not improve from 0.69476
Epoch 117/300
 - 10s - loss: 1311.2354 - acc: 0.9472 - mDice: 0.7659 - val_loss: 1729.5016 - val_acc: 0.9518 - val_mDice: 0.6794

Epoch 00117: val_mDice did not improve from 0.69476
Epoch 118/300
 - 10s - loss: 1304.5130 - acc: 0.9472 - mDice: 0.7668 - val_loss: 1863.0811 - val_acc: 0.9497 - val_mDice: 0.6583

Epoch 00118: val_mDice did not improve from 0.69476
Epoch 119/300
 - 11s - loss: 1308.6346 - acc: 0.9473 - mDice: 0.7662 - val_loss: 1868.3811 - val_acc: 0.9423 - val_mDice: 0.6600

Epoch 00119: val_mDice did not improve from 0.69476
Epoch 120/300
 - 10s - loss: 1304.1811 - acc: 0.9473 - mDice: 0.7669 - val_loss: 1709.6081 - val_acc: 0.9537 - val_mDice: 0.6845

Epoch 00120: val_mDice did not improve from 0.69476
Epoch 121/300
 - 10s - loss: 1306.6712 - acc: 0.9473 - mDice: 0.7666 - val_loss: 1900.8528 - val_acc: 0.9492 - val_mDice: 0.6556

Epoch 00121: val_mDice did not improve from 0.69476
Epoch 122/300
 - 10s - loss: 1298.3935 - acc: 0.9474 - mDice: 0.7678 - val_loss: 1737.2080 - val_acc: 0.9548 - val_mDice: 0.6794

Epoch 00122: val_mDice did not improve from 0.69476
Epoch 123/300
 - 10s - loss: 1293.1799 - acc: 0.9475 - mDice: 0.7686 - val_loss: 1774.2796 - val_acc: 0.9537 - val_mDice: 0.6745

Epoch 00123: val_mDice did not improve from 0.69476
Epoch 124/300
 - 11s - loss: 1284.8185 - acc: 0.9475 - mDice: 0.7699 - val_loss: 1640.3391 - val_acc: 0.9559 - val_mDice: 0.6937

Epoch 00124: val_mDice did not improve from 0.69476
Epoch 125/300
 - 10s - loss: 1290.5141 - acc: 0.9475 - mDice: 0.7690 - val_loss: 1632.1973 - val_acc: 0.9559 - val_mDice: 0.6934

Epoch 00125: val_mDice did not improve from 0.69476
Epoch 126/300
 - 11s - loss: 1282.0710 - acc: 0.9477 - mDice: 0.7703 - val_loss: 1649.0372 - val_acc: 0.9543 - val_mDice: 0.6910

Epoch 00126: val_mDice did not improve from 0.69476
Epoch 127/300
 - 10s - loss: 1278.6813 - acc: 0.9477 - mDice: 0.7708 - val_loss: 1732.7338 - val_acc: 0.9511 - val_mDice: 0.6794

Epoch 00127: val_mDice did not improve from 0.69476
Epoch 128/300
 - 11s - loss: 1281.1152 - acc: 0.9477 - mDice: 0.7704 - val_loss: 1682.0645 - val_acc: 0.9531 - val_mDice: 0.6870

Epoch 00128: val_mDice did not improve from 0.69476
Epoch 129/300
 - 10s - loss: 1284.2947 - acc: 0.9476 - mDice: 0.7699 - val_loss: 1848.2444 - val_acc: 0.9512 - val_mDice: 0.6586

Epoch 00129: val_mDice did not improve from 0.69476
Epoch 130/300
 - 10s - loss: 1277.1436 - acc: 0.9478 - mDice: 0.7711 - val_loss: 1730.7775 - val_acc: 0.9515 - val_mDice: 0.6770

Epoch 00130: val_mDice did not improve from 0.69476
Epoch 131/300
 - 10s - loss: 1275.2069 - acc: 0.9478 - mDice: 0.7713 - val_loss: 1760.4370 - val_acc: 0.9540 - val_mDice: 0.6736

Epoch 00131: val_mDice did not improve from 0.69476
Epoch 132/300
 - 10s - loss: 1274.2967 - acc: 0.9478 - mDice: 0.7715 - val_loss: 1704.0071 - val_acc: 0.9530 - val_mDice: 0.6838

Epoch 00132: val_mDice did not improve from 0.69476
Epoch 133/300
 - 10s - loss: 1275.7201 - acc: 0.9478 - mDice: 0.7713 - val_loss: 1722.6327 - val_acc: 0.9546 - val_mDice: 0.6805

Epoch 00133: val_mDice did not improve from 0.69476
Epoch 134/300
 - 9s - loss: 1266.9955 - acc: 0.9479 - mDice: 0.7726 - val_loss: 1765.3894 - val_acc: 0.9548 - val_mDice: 0.6722

Epoch 00134: val_mDice did not improve from 0.69476
Epoch 135/300
 - 10s - loss: 1267.8546 - acc: 0.9480 - mDice: 0.7726 - val_loss: 1678.2727 - val_acc: 0.9550 - val_mDice: 0.6863

Epoch 00135: val_mDice did not improve from 0.69476
Epoch 136/300
 - 10s - loss: 1260.3801 - acc: 0.9480 - mDice: 0.7737 - val_loss: 1637.8183 - val_acc: 0.9544 - val_mDice: 0.6928

Epoch 00136: val_mDice did not improve from 0.69476
Epoch 137/300
 - 10s - loss: 1264.4660 - acc: 0.9480 - mDice: 0.7731 - val_loss: 1730.2068 - val_acc: 0.9541 - val_mDice: 0.6795

Epoch 00137: val_mDice did not improve from 0.69476
Epoch 138/300
 - 11s - loss: 1265.6613 - acc: 0.9480 - mDice: 0.7729 - val_loss: 1683.6327 - val_acc: 0.9548 - val_mDice: 0.6876

Epoch 00138: val_mDice did not improve from 0.69476
Restoring model weights from the end of the best epoch
Epoch 00138: early stopping
{'val_loss': [20425.946800595237, 19089.650785900296, 11445.933268229166, 10738.141531808036, 3880.2592017764136, 3363.5436662946427, 3022.048182896205, 2908.935538155692, 2758.5518304734005, 2785.387233189174, 2686.50985281808, 2630.5231119791665, 2442.1263834635415, 2432.633783249628, 2422.2462390718006, 2483.3379516601562, 2439.248285202753, 2426.1942080543154, 2166.945606050037, 2062.091526576451, 2012.83549281529, 1988.6143246605284, 2051.672569638207, 2156.945722307478, 2015.2777855282739, 2058.394577752976, 1881.7611752464659, 1928.3000953311011, 1982.935334705171, 1852.302022298177, 1916.539562406994, 2204.888875325521, 2016.3323248000372, 2103.6014782133557, 1842.2520984468006, 1785.6295572916667, 1902.1949433826264, 1912.2770298549108, 2228.7729375930057, 2105.5179530552455, 2363.997977120536, 1827.1949724469866, 1901.7155151367188, 1969.7160063244048, 1778.4847644624256, 1889.341064453125, 2553.5267508370534, 1886.936032249814, 1804.8980131603423, 1894.6578252883185, 1723.6070847284227, 1781.381059919085, 1830.080534435454, 1736.6235060918898, 1818.5810488746279, 1790.1187104724702, 1889.799575079055, 1780.759024483817, 1790.0347551618304, 1845.7997174944196, 1722.2025902157739, 1796.9398803710938, 1852.4370960053943, 1899.698962983631, 1718.583987281436, 1748.9479399181548, 1806.041480654762, 1689.2782098679315, 1815.0243966238838, 1709.3440232049852, 1788.8147495814733, 1731.6648210797991, 1823.1220703125, 1690.5245739164807, 1796.3431134905134, 1855.1377534412202, 2355.1346842447915, 1709.0682983398438, 1735.485087076823, 1761.3732154482886, 1765.6636294410341, 1784.0172409784227, 1708.901878720238, 1700.5426374162946, 1643.1651466006324, 1711.8129388718378, 1641.9239414760045, 1694.0332670665923, 1720.4774198986236, 1792.4165416899182, 1719.3478742327009, 1679.2485874720983, 1699.5027523949034, 1787.6815941220239, 1726.5741024925596, 1801.4978201729912, 1695.786164783296, 1683.0074114118304, 1647.316874186198, 1687.5269746326264, 1921.935346330915, 1665.66651843843, 1788.4193841843378, 1676.2083769298736, 1688.634044828869, 1681.3511933826264, 1651.8117414202009, 1616.3973214285713, 1817.394784109933, 1679.1341785249256, 1719.4886648995537, 1793.9057675316221, 1903.517586844308, 1667.1786092122395, 1801.0257742745537, 1864.182341076079, 1729.5015898204986, 1863.081086658296, 1868.381083170573, 1709.6080990745909, 1900.8528209867932, 1737.2080455961682, 1774.2796398344494, 1640.339114234561, 1632.1973295665923, 1649.0372256324404, 1732.7338053385417, 1682.0645490373884, 1848.244416736421, 1730.7774890718006, 1760.4369564964659, 1704.0071178617932, 1722.6327282133557, 1765.3893519810267, 1678.272702171689, 1637.8183070591517, 1730.206772577195, 1683.6327049618676], 'val_acc': [0.8767256197475252, 0.8752418259779612, 0.8814145610446021, 0.8950434937363579, 0.9001416663328806, 0.899451983826501, 0.9105612011182875, 0.9151957531770071, 0.923234319403058, 0.92013076373509, 0.9252045920916966, 0.927193501165935, 0.9345009014720008, 0.9310825892857143, 0.934352118344534, 0.9302584060600826, 0.9364769572303409, 0.9311698504856655, 0.9380294041974204, 0.9391369152636755, 0.9395389783950079, 0.9415622012955802, 0.9381481806437174, 0.9372510356562478, 0.9389422848111108, 0.9408725414957319, 0.9443752950146085, 0.9432978388809022, 0.9410456617673238, 0.9451136120728084, 0.9441348910331726, 0.9322644826911745, 0.9424121507576534, 0.9381767809391022, 0.9476891599950337, 0.9474516141982305, 0.9469937625385466, 0.9469837290900094, 0.9360977382886977, 0.9395933647950491, 0.9300180432342348, 0.9483974434080578, 0.9471067928132557, 0.9407738191740853, 0.9490084321725936, 0.9449962959403083, 0.9277443829036894, 0.943204824413572, 0.9495607018470764, 0.9439102652527037, 0.9501516677084423, 0.9507025565419879, 0.9494562645753225, 0.9513736111777169, 0.9471640359787714, 0.9491700984182811, 0.9477435236885434, 0.951971731015614, 0.9504936252321515, 0.9475589295228323, 0.951247730425426, 0.9492702796345666, 0.9463369874727159, 0.9447974151089078, 0.9508270209743863, 0.9475603799025217, 0.9457174355075473, 0.9539377306188855, 0.9453811759040469, 0.9529532988866171, 0.9487022246633258, 0.9509257759366717, 0.9456000895727248, 0.9522307146163214, 0.9500801350389209, 0.9497624664079576, 0.930418671596618, 0.9524066944917043, 0.9551425249803633, 0.9518415232499441, 0.9516755498590923, 0.944939041421527, 0.9512162378856114, 0.954328369526636, 0.9538203804265886, 0.9537030600366139, 0.9542181548618135, 0.9495592826888675, 0.9529132317929041, 0.9499885411489577, 0.9533210396766663, 0.9539033813135964, 0.9542839910302844, 0.9512748845985958, 0.9520289571512313, 0.9448331566083998, 0.9517442215056646, 0.9525669444174993, 0.9538461736270359, 0.9557692380178542, 0.9428556859493256, 0.9530534545580546, 0.9489683437915075, 0.9535470888728187, 0.9525412136600131, 0.9526513871692476, 0.955288461276463, 0.9560425182183584, 0.9529375618412381, 0.9514766420636859, 0.9493031643685841, 0.9477163652578989, 0.9456702186947777, 0.9533439221836272, 0.9475475109758831, 0.9431161128339314, 0.9518128874756041, 0.9496566085588365, 0.9423248611745381, 0.9537145012900943, 0.9492001590274629, 0.9547862495694842, 0.9536572737353188, 0.9558651262805575, 0.9559008819716317, 0.9542868634064993, 0.9510974557626815, 0.9531164226077852, 0.951233392670041, 0.9514537467843011, 0.9539706522510165, 0.9529719026315779, 0.9545816069557553, 0.9547776650814783, 0.9550051405316308, 0.9544299415179661, 0.954149508760089, 0.9548148385116032], 'val_mDice': [0.2203499082298506, 0.27054206814084736, 0.35182708288942066, 0.41638504678294774, 0.4386688612756275, 0.48430346165384563, 0.5198879880564553, 0.5373471904368627, 0.5563322248912993, 0.5545397840795063, 0.56511719028155, 0.5729537975220453, 0.5940292420841399, 0.5922998899505252, 0.5946443478266398, 0.5902900709992364, 0.5959221522013346, 0.5916555637405032, 0.6199538977373213, 0.6317604609898159, 0.6370724113214583, 0.6405449381896428, 0.6335106577192035, 0.6217477151325771, 0.6392873852025895, 0.6340287412915911, 0.6560605693431127, 0.6492572724819183, 0.6429226597150167, 0.6580109241462889, 0.6510076735700879, 0.61517200867335, 0.6414573873792376, 0.6263743511268071, 0.6615637512434096, 0.6687230879352206, 0.6523748948460534, 0.6536617804141271, 0.6149233764126187, 0.6306937620753333, 0.5951146369888669, 0.6641153608049665, 0.6553933677219209, 0.6449881820451646, 0.6721289853254954, 0.6574712495009104, 0.5755089507216499, 0.6562322165284838, 0.6688179515656971, 0.6569564030283973, 0.6802318748973665, 0.6728162282989139, 0.665481394245511, 0.6788030437060765, 0.6672277862117404, 0.6712556197529748, 0.6584889420441219, 0.6738264929680597, 0.6713365969203767, 0.6630623269648779, 0.6801485064483824, 0.6714102228482565, 0.6631969483125777, 0.656446879818326, 0.6810167673088255, 0.6758845987774077, 0.6677011379173824, 0.6852198782421294, 0.6666159374373299, 0.6817723257201058, 0.6714591469083514, 0.6793107106572106, 0.6652926263355073, 0.6838227368536449, 0.6721932519049871, 0.6646769940853119, 0.5959010124206543, 0.6820200582345327, 0.6797160506248474, 0.6771072773706346, 0.6756866460754758, 0.6709665060043335, 0.6820107613291059, 0.683476345879691, 0.6919921012151808, 0.6831777237710499, 0.6919698190121424, 0.6843323068959373, 0.6818644177346003, 0.6708780456156958, 0.6812125430220649, 0.6854321459929148, 0.682776479494004, 0.6708056018466041, 0.6818251027947381, 0.66774425194377, 0.6838483796233222, 0.6852241825489771, 0.691024131718136, 0.685772024449848, 0.6521581595852262, 0.6888599977606819, 0.670931454215731, 0.6864329335235414, 0.685822205884116, 0.687253794499806, 0.691070515485037, 0.6947601508526575, 0.6649953112715766, 0.6874223096030099, 0.6801006822358995, 0.6712192396322886, 0.653402505885987, 0.6886175175507864, 0.6703404798394158, 0.6616599474634443, 0.6794328916640509, 0.6582834834144229, 0.6600295730999538, 0.6844853943302518, 0.6556248806771778, 0.6794287675902957, 0.6745181779066721, 0.6937309503555298, 0.6933898216202146, 0.6909969718683333, 0.6793956614675976, 0.6869828757785615, 0.6585768972124372, 0.6770198997997102, 0.6735616354715257, 0.6838343611785344, 0.6804965223584857, 0.6722075683729989, 0.6862974379743848, 0.692843442871457, 0.6794638406662714, 0.6876442829767863], 'loss': [23093.347932354172, 15585.396368088568, 14224.625301370597, 13182.055273802798, 8737.805374716285, 4819.661783499017, 4226.195794008022, 3872.48542134958, 3646.711124638964, 3446.3394904005854, 3298.422180708507, 3175.1212015128194, 3057.7424499055096, 2964.080473027027, 2862.6575256499864, 2792.9720270247235, 2724.7275465206612, 2655.868958508879, 2584.451207491525, 2522.281801066791, 2455.14043588234, 2404.7193268659407, 2343.8106467991397, 2308.464957905529, 2271.4472245290094, 2229.7715356308327, 2193.7287846134786, 2168.470376792394, 2131.4564992852343, 2106.0967951748435, 2080.5481894248146, 2055.07529668261, 2018.8757466532643, 2008.8685377696506, 1991.8051440840648, 1967.7028491241379, 1948.938755101991, 1924.1527148315733, 1911.1895381328175, 1887.5514729944548, 1874.688004757698, 1851.1379291791275, 1835.0551662302373, 1815.8268067700012, 1793.3765006124825, 1789.2044449042799, 1769.4034811576405, 1766.7942925736197, 1745.598440117967, 1730.4417594472072, 1719.0813069331675, 1699.8404851518665, 1680.7984926218999, 1671.2730306496942, 1660.146464017264, 1646.2314880447198, 1643.61561158292, 1619.9149731947598, 1618.266282535848, 1613.433420614114, 1589.5934495426472, 1598.3330961308277, 1589.030135994243, 1571.8272963830657, 1562.1389692882053, 1557.03509369277, 1542.2920268527291, 1534.8173714730508, 1530.915958166717, 1516.8482666776663, 1518.0221310660727, 1508.6093799847915, 1507.5612915115166, 1496.8809157678313, 1492.111026982714, 1480.8106627428622, 1475.2913705725919, 1466.4996345881511, 1464.6563230975905, 1463.1857828725306, 1444.2713894356516, 1445.1199521947085, 1435.3973102141497, 1439.2584766568687, 1437.643914467676, 1426.8981811066815, 1421.3853944697582, 1417.7114980417, 1415.5005489358878, 1413.9910692704884, 1399.9343473286997, 1393.1292616542141, 1400.9283114311997, 1392.0093264306274, 1382.487141521197, 1377.143574284199, 1368.9853119505315, 1370.9826399120607, 1364.4996780814079, 1360.8492399296558, 1358.6745357751252, 1361.023310673207, 1361.2135795916702, 1348.9975537992177, 1347.745576625453, 1345.0761223315003, 1334.2257464021222, 1337.8389798590072, 1329.9619275328525, 1330.45817463178, 1326.9546239001495, 1326.9768369679439, 1323.8144796851864, 1320.584975473304, 1313.3267334060479, 1309.164885104743, 1311.235360999357, 1304.5129536464624, 1308.634618935145, 1304.1811330895175, 1306.6712211932327, 1298.3935319705497, 1293.1799152783326, 1284.8185350984113, 1290.514119440778, 1282.0709509718745, 1278.681274033544, 1281.1152139411604, 1284.2947307786442, 1277.143646126079, 1275.20693813714, 1274.2966816966373, 1275.72009654057, 1266.995515780556, 1267.85461874793, 1260.3801134447208, 1264.4660303206217, 1265.6613095633109], 'acc': [0.8626328750775937, 0.872826274660906, 0.8820732306140914, 0.891296698435435, 0.8916436533566722, 0.8969153323747273, 0.9034921536198876, 0.9079686807389569, 0.9110476346012958, 0.913995810354737, 0.9163046583458967, 0.9182324773467092, 0.9200416924315795, 0.9214172536632664, 0.9226473118190159, 0.9238516753005268, 0.9250139927774891, 0.9260923335714233, 0.9268323708873735, 0.9276548498437887, 0.928381871720056, 0.9289389006477639, 0.929858810716585, 0.930338891162688, 0.9309103465139718, 0.9314811136434203, 0.9319342494642645, 0.9324614752706447, 0.9329671959887419, 0.9334655053486254, 0.9337545174761603, 0.9342524648232947, 0.9348971701396671, 0.9351998224594349, 0.9353690780606353, 0.9358158279721279, 0.936129029961001, 0.9365314344998606, 0.9369795527727229, 0.9372735370572963, 0.9374839452994137, 0.9379045436915912, 0.938087585728216, 0.9385031821238727, 0.9387803965636025, 0.9390275412961432, 0.939324876744105, 0.9394197444666056, 0.939789367807179, 0.9399174462232803, 0.9402180776148663, 0.9406854528144113, 0.9408396994718292, 0.9411467172372668, 0.9413143272263154, 0.9414922338805889, 0.9415209132091066, 0.9418774105589883, 0.94194857703703, 0.9420565342590993, 0.9424410938770694, 0.9423131832941215, 0.942468723509823, 0.9429237159187359, 0.9430573389417215, 0.9431512856721284, 0.943354544478313, 0.9435033235986928, 0.9435257666611909, 0.9436397927992064, 0.9436900158438302, 0.9439009120153667, 0.943734635791725, 0.9439087085741714, 0.9441249995234601, 0.9442802417530978, 0.9443099536837782, 0.9444779735662396, 0.9446041768514307, 0.9445791879757087, 0.9447201375392013, 0.9448434947583444, 0.9448945418074541, 0.944941471100894, 0.9450022743415654, 0.9452044252408413, 0.9451917482173057, 0.9452931856796926, 0.9453665063231068, 0.9454540656577619, 0.9455720868862775, 0.9456725905363697, 0.945600975295552, 0.9458404589918189, 0.9459025774922157, 0.9461569572030161, 0.946009149723814, 0.9461172991931587, 0.9462769231259675, 0.9463856123071953, 0.9464890768291647, 0.9463722200836624, 0.9462764741402314, 0.9465379349311391, 0.9464653393722829, 0.9464821843546525, 0.9467189357502205, 0.9467261652287997, 0.9469119024061206, 0.946832737348918, 0.9469462608978932, 0.9468997437646264, 0.9468799495043005, 0.9469987898321818, 0.9471386686859286, 0.9471357512912548, 0.947211242469023, 0.9472208341532514, 0.9472983304662003, 0.9473349565356747, 0.9472863447302, 0.9473812886678667, 0.9475028227986838, 0.9475414329336171, 0.9475225141258014, 0.9476902907217233, 0.9477249844524629, 0.9477067189732394, 0.9475755467639302, 0.9478240248716977, 0.9477652965712726, 0.9478262169031134, 0.9478287608769171, 0.9479092615946867, 0.9479508119962756, 0.9480252756256415, 0.9480101383869487, 0.9480181015154667], 'mDice': [0.12626724483148008, 0.22445696490605424, 0.27981157639433174, 0.3397561962765054, 0.3523763259059919, 0.39970567643159344, 0.44103549860250624, 0.4708239448876898, 0.49127277495000427, 0.5106199066853732, 0.525371502815488, 0.5375991997650437, 0.5497114939842735, 0.5596034803666974, 0.5702373064366957, 0.5775548563968214, 0.5849317880788646, 0.5920351907759533, 0.599200438828837, 0.6054968967327751, 0.6129515990429091, 0.6183399352015105, 0.6253305302556613, 0.6295638126030825, 0.6338754581320019, 0.6387935327621469, 0.6432748910160433, 0.6463300096163725, 0.6512149761516852, 0.654174092850483, 0.6574643903279542, 0.6606968506761917, 0.6654347954805653, 0.6669118270426617, 0.6690154915067026, 0.6723835192750814, 0.6747130809207806, 0.6781960093878451, 0.6799337590610297, 0.6831187622579851, 0.6846796116998368, 0.6878864335040202, 0.69010179409957, 0.6927601158098687, 0.6957268330112955, 0.6964767026224933, 0.6991093798059775, 0.699607527984348, 0.7023440208889897, 0.7044207221663503, 0.706109144796903, 0.7087873046349111, 0.7113467628261693, 0.7127836965340332, 0.714273052285437, 0.7162425397080079, 0.7166652980067784, 0.7199682594274642, 0.7203492015563044, 0.7209514128299722, 0.724424710501905, 0.7232287506807474, 0.7245384754236797, 0.7270246449848661, 0.7283789572535905, 0.7291470485881082, 0.7313077034163951, 0.7323422769730228, 0.7329563679094624, 0.734967515745811, 0.7348531790430707, 0.7361473638071978, 0.7364598535317138, 0.737885033028976, 0.7386933198184741, 0.7404132419988104, 0.7412058894064956, 0.742570125291175, 0.7427809069913225, 0.7430127552173976, 0.7457714895543612, 0.7456769304642653, 0.7470177924469522, 0.7465144101892623, 0.7467702904953029, 0.748381532264172, 0.7491486969396955, 0.7497034700694227, 0.7501169269407479, 0.7509325848070166, 0.7524880839144797, 0.7534559710216047, 0.7522214414955969, 0.753588205319539, 0.7549944893826273, 0.7558570381003128, 0.7570044732004627, 0.7567579756651138, 0.7577531773067472, 0.7582470280422534, 0.7586179355396296, 0.7582267104947656, 0.7582030025429262, 0.7600447693630644, 0.760331729050735, 0.7606496953421698, 0.7623001281311387, 0.7617758840619775, 0.7629918361319568, 0.7628114857987276, 0.7634342593928227, 0.7634276814034158, 0.7638706123442424, 0.7643646767683457, 0.7654883574109125, 0.7661104173471506, 0.7658714183288025, 0.7668424613235003, 0.7661929321370815, 0.7669336248440041, 0.7666010033534352, 0.7677756783893875, 0.7686366029919829, 0.7698924142932356, 0.7690226942152156, 0.7703164624900295, 0.770758779937787, 0.7704185286996668, 0.7699239807310247, 0.7710813206627481, 0.7713488223881199, 0.7715215274037566, 0.7713447194964511, 0.772576954225055, 0.7725713253392841, 0.7737102298590905, 0.7731131584827144, 0.7728906263437058]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:15<00:46, 15.47s/it]predicting test subjects:  50%|█████     | 2/4 [00:29<00:30, 15.01s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:44<00:15, 15.07s/it]predicting test subjects: 100%|██████████| 4/4 [00:59<00:00, 14.96s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:22<1:54:38, 22.19s/it]predicting train subjects:   1%|          | 2/311 [00:33<1:36:54, 18.82s/it]predicting train subjects:   1%|          | 3/311 [00:46<1:28:03, 17.15s/it]predicting train subjects:   1%|▏         | 4/311 [00:59<1:20:57, 15.82s/it]predicting train subjects:   2%|▏         | 5/311 [01:10<1:14:06, 14.53s/it]predicting train subjects:   2%|▏         | 6/311 [01:22<1:09:35, 13.69s/it]predicting train subjects:   2%|▏         | 7/311 [01:36<1:09:16, 13.67s/it]predicting train subjects:   3%|▎         | 8/311 [01:51<1:12:04, 14.27s/it]predicting train subjects:   3%|▎         | 9/311 [02:05<1:11:01, 14.11s/it]predicting train subjects:   3%|▎         | 10/311 [02:19<1:10:30, 14.06s/it]predicting train subjects:   4%|▎         | 11/311 [02:38<1:18:34, 15.71s/it]predicting train subjects:   4%|▍         | 12/311 [02:53<1:15:59, 15.25s/it]predicting train subjects:   4%|▍         | 13/311 [03:07<1:14:35, 15.02s/it]predicting train subjects:   5%|▍         | 14/311 [03:26<1:20:15, 16.21s/it]predicting train subjects:   5%|▍         | 15/311 [03:54<1:37:12, 19.70s/it]predicting train subjects:   5%|▌         | 16/311 [04:21<1:47:12, 21.81s/it]predicting train subjects:   5%|▌         | 17/311 [04:47<1:53:22, 23.14s/it]predicting train subjects:   6%|▌         | 18/311 [05:14<1:58:40, 24.30s/it]predicting train subjects:   6%|▌         | 19/311 [05:41<2:02:12, 25.11s/it]predicting train subjects:   6%|▋         | 20/311 [06:08<2:04:24, 25.65s/it]predicting train subjects:   7%|▋         | 21/311 [06:34<2:04:50, 25.83s/it]predicting train subjects:   7%|▋         | 22/311 [07:00<2:03:54, 25.73s/it]predicting train subjects:   7%|▋         | 23/311 [07:27<2:06:04, 26.27s/it]predicting train subjects:   8%|▊         | 24/311 [07:54<2:06:01, 26.35s/it]predicting train subjects:   8%|▊         | 25/311 [08:21<2:06:51, 26.61s/it]predicting train subjects:   8%|▊         | 26/311 [08:47<2:05:42, 26.46s/it]predicting train subjects:   9%|▊         | 27/311 [09:14<2:06:34, 26.74s/it]predicting train subjects:   9%|▉         | 28/311 [09:41<2:06:19, 26.78s/it]predicting train subjects:   9%|▉         | 29/311 [10:06<2:02:50, 26.14s/it]predicting train subjects:  10%|▉         | 30/311 [10:33<2:04:21, 26.55s/it]predicting train subjects:  10%|▉         | 31/311 [10:59<2:02:12, 26.19s/it]predicting train subjects:  10%|█         | 32/311 [11:20<1:55:26, 24.83s/it]predicting train subjects:  11%|█         | 33/311 [11:31<1:35:13, 20.55s/it]predicting train subjects:  11%|█         | 34/311 [11:41<1:21:01, 17.55s/it]predicting train subjects:  11%|█▏        | 35/311 [11:52<1:10:42, 15.37s/it]predicting train subjects:  12%|█▏        | 36/311 [12:02<1:03:11, 13.79s/it]predicting train subjects:  12%|█▏        | 37/311 [12:12<58:23, 12.78s/it]  predicting train subjects:  12%|█▏        | 38/311 [12:23<55:04, 12.11s/it]predicting train subjects:  13%|█▎        | 39/311 [12:33<52:26, 11.57s/it]predicting train subjects:  13%|█▎        | 40/311 [12:43<50:09, 11.10s/it]predicting train subjects:  13%|█▎        | 41/311 [12:54<49:05, 10.91s/it]predicting train subjects:  14%|█▎        | 42/311 [13:04<48:09, 10.74s/it]predicting train subjects:  14%|█▍        | 43/311 [13:14<47:14, 10.58s/it]predicting train subjects:  14%|█▍        | 44/311 [13:24<46:38, 10.48s/it]predicting train subjects:  14%|█▍        | 45/311 [13:35<46:46, 10.55s/it]predicting train subjects:  15%|█▍        | 46/311 [13:46<47:30, 10.75s/it]predicting train subjects:  15%|█▌        | 47/311 [13:57<47:08, 10.71s/it]predicting train subjects:  15%|█▌        | 48/311 [14:07<46:05, 10.52s/it]predicting train subjects:  16%|█▌        | 49/311 [14:17<45:36, 10.44s/it]predicting train subjects:  16%|█▌        | 50/311 [14:28<46:09, 10.61s/it]predicting train subjects:  16%|█▋        | 51/311 [14:41<49:17, 11.38s/it]predicting train subjects:  17%|█▋        | 52/311 [14:55<51:27, 11.92s/it]predicting train subjects:  17%|█▋        | 53/311 [15:08<53:06, 12.35s/it]predicting train subjects:  17%|█▋        | 54/311 [15:22<54:53, 12.81s/it]predicting train subjects:  18%|█▊        | 55/311 [15:35<55:04, 12.91s/it]predicting train subjects:  18%|█▊        | 56/311 [15:48<55:16, 13.01s/it]predicting train subjects:  18%|█▊        | 57/311 [16:02<56:14, 13.29s/it]predicting train subjects:  19%|█▊        | 58/311 [16:15<55:50, 13.24s/it]predicting train subjects:  19%|█▉        | 59/311 [16:29<55:57, 13.32s/it]predicting train subjects:  19%|█▉        | 60/311 [16:42<55:14, 13.20s/it]predicting train subjects:  20%|█▉        | 61/311 [16:54<54:23, 13.06s/it]predicting train subjects:  20%|█▉        | 62/311 [17:08<54:12, 13.06s/it]predicting train subjects:  20%|██        | 63/311 [17:21<54:03, 13.08s/it]predicting train subjects:  21%|██        | 64/311 [17:34<53:53, 13.09s/it]predicting train subjects:  21%|██        | 65/311 [17:47<53:41, 13.10s/it]predicting train subjects:  21%|██        | 66/311 [18:00<53:23, 13.08s/it]predicting train subjects:  22%|██▏       | 67/311 [18:14<53:46, 13.22s/it]predicting train subjects:  22%|██▏       | 68/311 [18:26<52:54, 13.06s/it]predicting train subjects:  22%|██▏       | 69/311 [18:39<52:09, 12.93s/it]predicting train subjects:  23%|██▎       | 70/311 [18:52<52:23, 13.04s/it]predicting train subjects:  23%|██▎       | 71/311 [19:05<51:39, 12.91s/it]predicting train subjects:  23%|██▎       | 72/311 [19:17<51:09, 12.84s/it]predicting train subjects:  23%|██▎       | 73/311 [19:30<50:50, 12.82s/it]predicting train subjects:  24%|██▍       | 74/311 [19:43<50:21, 12.75s/it]predicting train subjects:  24%|██▍       | 75/311 [19:56<50:23, 12.81s/it]predicting train subjects:  24%|██▍       | 76/311 [20:09<50:08, 12.80s/it]predicting train subjects:  25%|██▍       | 77/311 [20:21<49:51, 12.78s/it]predicting train subjects:  25%|██▌       | 78/311 [20:34<49:37, 12.78s/it]predicting train subjects:  25%|██▌       | 79/311 [20:47<49:31, 12.81s/it]predicting train subjects:  26%|██▌       | 80/311 [20:59<49:02, 12.74s/it]predicting train subjects:  26%|██▌       | 81/311 [21:13<49:37, 12.94s/it]predicting train subjects:  26%|██▋       | 82/311 [21:26<49:09, 12.88s/it]predicting train subjects:  27%|██▋       | 83/311 [21:38<48:35, 12.79s/it]predicting train subjects:  27%|██▋       | 84/311 [21:51<48:07, 12.72s/it]predicting train subjects:  27%|██▋       | 85/311 [22:03<47:31, 12.62s/it]predicting train subjects:  28%|██▊       | 86/311 [22:15<46:03, 12.28s/it]predicting train subjects:  28%|██▊       | 87/311 [22:26<44:25, 11.90s/it]predicting train subjects:  28%|██▊       | 88/311 [22:37<44:04, 11.86s/it]predicting train subjects:  29%|██▊       | 89/311 [22:49<43:34, 11.78s/it]predicting train subjects:  29%|██▉       | 90/311 [23:01<43:23, 11.78s/it]predicting train subjects:  29%|██▉       | 91/311 [23:12<42:39, 11.64s/it]predicting train subjects:  30%|██▉       | 92/311 [23:23<42:13, 11.57s/it]predicting train subjects:  30%|██▉       | 93/311 [23:35<42:27, 11.69s/it]predicting train subjects:  30%|███       | 94/311 [23:47<42:19, 11.70s/it]predicting train subjects:  31%|███       | 95/311 [23:59<42:01, 11.67s/it]predicting train subjects:  31%|███       | 96/311 [24:10<41:20, 11.54s/it]predicting train subjects:  31%|███       | 97/311 [24:22<41:25, 11.61s/it]predicting train subjects:  32%|███▏      | 98/311 [24:34<41:34, 11.71s/it]predicting train subjects:  32%|███▏      | 99/311 [24:45<41:05, 11.63s/it]predicting train subjects:  32%|███▏      | 100/311 [24:57<40:51, 11.62s/it]predicting train subjects:  32%|███▏      | 101/311 [25:09<41:01, 11.72s/it]predicting train subjects:  33%|███▎      | 102/311 [25:20<40:39, 11.67s/it]predicting train subjects:  33%|███▎      | 103/311 [25:32<40:51, 11.79s/it]predicting train subjects:  33%|███▎      | 104/311 [25:44<40:44, 11.81s/it]predicting train subjects:  34%|███▍      | 105/311 [25:56<40:44, 11.87s/it]predicting train subjects:  34%|███▍      | 106/311 [26:08<40:19, 11.80s/it]predicting train subjects:  34%|███▍      | 107/311 [26:20<40:17, 11.85s/it]predicting train subjects:  35%|███▍      | 108/311 [26:32<40:19, 11.92s/it]predicting train subjects:  35%|███▌      | 109/311 [26:44<40:01, 11.89s/it]predicting train subjects:  35%|███▌      | 110/311 [26:55<39:28, 11.78s/it]predicting train subjects:  36%|███▌      | 111/311 [27:07<39:21, 11.81s/it]predicting train subjects:  36%|███▌      | 112/311 [27:19<39:06, 11.79s/it]predicting train subjects:  36%|███▋      | 113/311 [27:31<39:00, 11.82s/it]predicting train subjects:  37%|███▋      | 114/311 [27:53<49:02, 14.94s/it]predicting train subjects:  37%|███▋      | 115/311 [28:16<56:17, 17.23s/it]predicting train subjects:  37%|███▋      | 116/311 [28:38<1:00:45, 18.69s/it]predicting train subjects:  38%|███▊      | 117/311 [29:00<1:03:43, 19.71s/it]predicting train subjects:  38%|███▊      | 118/311 [29:23<1:06:22, 20.64s/it]predicting train subjects:  38%|███▊      | 119/311 [29:45<1:07:20, 21.05s/it]predicting train subjects:  39%|███▊      | 120/311 [30:07<1:08:25, 21.49s/it]predicting train subjects:  39%|███▉      | 121/311 [30:30<1:09:28, 21.94s/it]predicting train subjects:  39%|███▉      | 122/311 [30:52<1:09:25, 22.04s/it]predicting train subjects:  40%|███▉      | 123/311 [31:15<1:09:59, 22.34s/it]predicting train subjects:  40%|███▉      | 124/311 [31:38<1:09:54, 22.43s/it]predicting train subjects:  40%|████      | 125/311 [32:00<1:09:04, 22.28s/it]predicting train subjects:  41%|████      | 126/311 [32:22<1:08:23, 22.18s/it]predicting train subjects:  41%|████      | 127/311 [32:44<1:08:08, 22.22s/it]predicting train subjects:  41%|████      | 128/311 [33:07<1:08:03, 22.31s/it]predicting train subjects:  41%|████▏     | 129/311 [33:29<1:07:30, 22.26s/it]predicting train subjects:  42%|████▏     | 130/311 [33:51<1:06:45, 22.13s/it]predicting train subjects:  42%|████▏     | 131/311 [34:13<1:06:12, 22.07s/it]predicting train subjects:  42%|████▏     | 132/311 [34:23<55:34, 18.63s/it]  predicting train subjects:  43%|████▎     | 133/311 [34:33<47:45, 16.10s/it]predicting train subjects:  43%|████▎     | 134/311 [34:44<42:10, 14.30s/it]predicting train subjects:  43%|████▎     | 135/311 [34:54<38:38, 13.17s/it]predicting train subjects:  44%|████▎     | 136/311 [35:05<36:03, 12.36s/it]predicting train subjects:  44%|████▍     | 137/311 [35:15<33:49, 11.67s/it]predicting train subjects:  44%|████▍     | 138/311 [35:25<32:33, 11.29s/it]predicting train subjects:  45%|████▍     | 139/311 [35:36<31:52, 11.12s/it]predicting train subjects:  45%|████▌     | 140/311 [35:47<31:41, 11.12s/it]predicting train subjects:  45%|████▌     | 141/311 [35:57<30:41, 10.83s/it]predicting train subjects:  46%|████▌     | 142/311 [36:07<30:12, 10.72s/it]predicting train subjects:  46%|████▌     | 143/311 [36:18<30:01, 10.72s/it]predicting train subjects:  46%|████▋     | 144/311 [36:29<30:11, 10.85s/it]predicting train subjects:  47%|████▋     | 145/311 [36:39<29:23, 10.63s/it]predicting train subjects:  47%|████▋     | 146/311 [36:50<29:09, 10.60s/it]predicting train subjects:  47%|████▋     | 147/311 [37:01<29:06, 10.65s/it]predicting train subjects:  48%|████▊     | 148/311 [37:11<28:52, 10.63s/it]predicting train subjects:  48%|████▊     | 149/311 [37:21<28:14, 10.46s/it]predicting train subjects:  48%|████▊     | 150/311 [37:34<30:11, 11.25s/it]predicting train subjects:  49%|████▊     | 151/311 [37:48<31:33, 11.83s/it]predicting train subjects:  49%|████▉     | 152/311 [38:01<32:28, 12.25s/it]predicting train subjects:  49%|████▉     | 153/311 [38:14<33:08, 12.58s/it]predicting train subjects:  50%|████▉     | 154/311 [38:27<33:23, 12.76s/it]predicting train subjects:  50%|████▉     | 155/311 [38:40<33:23, 12.84s/it]predicting train subjects:  50%|█████     | 156/311 [38:53<33:17, 12.89s/it]predicting train subjects:  50%|█████     | 157/311 [39:06<33:05, 12.90s/it]predicting train subjects:  51%|█████     | 158/311 [39:20<33:04, 12.97s/it]predicting train subjects:  51%|█████     | 159/311 [39:34<33:42, 13.30s/it]predicting train subjects:  51%|█████▏    | 160/311 [39:47<33:21, 13.26s/it]predicting train subjects:  52%|█████▏    | 161/311 [40:00<33:04, 13.23s/it]predicting train subjects:  52%|█████▏    | 162/311 [40:14<33:24, 13.45s/it]predicting train subjects:  52%|█████▏    | 163/311 [40:27<32:58, 13.37s/it]predicting train subjects:  53%|█████▎    | 164/311 [40:40<32:39, 13.33s/it]predicting train subjects:  53%|█████▎    | 165/311 [40:54<32:39, 13.42s/it]predicting train subjects:  53%|█████▎    | 166/311 [41:07<31:53, 13.20s/it]predicting train subjects:  54%|█████▎    | 167/311 [41:19<31:11, 12.99s/it]predicting train subjects:  54%|█████▍    | 168/311 [41:32<30:43, 12.89s/it]predicting train subjects:  54%|█████▍    | 169/311 [41:45<31:03, 13.12s/it]predicting train subjects:  55%|█████▍    | 170/311 [41:58<30:39, 13.04s/it]predicting train subjects:  55%|█████▍    | 171/311 [42:11<30:14, 12.96s/it]predicting train subjects:  55%|█████▌    | 172/311 [42:24<30:00, 12.95s/it]predicting train subjects:  56%|█████▌    | 173/311 [42:37<29:42, 12.92s/it]predicting train subjects:  56%|█████▌    | 174/311 [42:50<29:25, 12.89s/it]predicting train subjects:  56%|█████▋    | 175/311 [43:03<29:14, 12.90s/it]predicting train subjects:  57%|█████▋    | 176/311 [43:15<28:49, 12.81s/it]predicting train subjects:  57%|█████▋    | 177/311 [43:27<28:08, 12.60s/it]predicting train subjects:  57%|█████▋    | 178/311 [43:40<28:04, 12.67s/it]predicting train subjects:  58%|█████▊    | 179/311 [43:54<28:31, 12.96s/it]predicting train subjects:  58%|█████▊    | 180/311 [44:07<28:14, 12.94s/it]predicting train subjects:  58%|█████▊    | 181/311 [44:19<27:58, 12.91s/it]predicting train subjects:  59%|█████▊    | 182/311 [44:32<27:41, 12.88s/it]predicting train subjects:  59%|█████▉    | 183/311 [44:45<27:21, 12.82s/it]predicting train subjects:  59%|█████▉    | 184/311 [44:56<26:12, 12.39s/it]predicting train subjects:  59%|█████▉    | 185/311 [45:08<25:26, 12.12s/it]predicting train subjects:  60%|█████▉    | 186/311 [45:20<25:02, 12.02s/it]predicting train subjects:  60%|██████    | 187/311 [45:32<24:47, 12.00s/it]predicting train subjects:  60%|██████    | 188/311 [45:43<24:22, 11.89s/it]predicting train subjects:  61%|██████    | 189/311 [45:54<23:46, 11.69s/it]predicting train subjects:  61%|██████    | 190/311 [46:07<23:54, 11.86s/it]predicting train subjects:  61%|██████▏   | 191/311 [46:19<23:41, 11.85s/it]predicting train subjects:  62%|██████▏   | 192/311 [46:30<23:27, 11.83s/it]predicting train subjects:  62%|██████▏   | 193/311 [46:42<23:10, 11.79s/it]predicting train subjects:  62%|██████▏   | 194/311 [46:54<23:05, 11.84s/it]predicting train subjects:  63%|██████▎   | 195/311 [47:05<22:35, 11.68s/it]predicting train subjects:  63%|██████▎   | 196/311 [47:17<22:27, 11.71s/it]predicting train subjects:  63%|██████▎   | 197/311 [47:29<22:13, 11.70s/it]predicting train subjects:  64%|██████▎   | 198/311 [47:40<21:50, 11.60s/it]predicting train subjects:  64%|██████▍   | 199/311 [47:51<21:28, 11.50s/it]predicting train subjects:  64%|██████▍   | 200/311 [48:03<21:23, 11.56s/it]predicting train subjects:  65%|██████▍   | 201/311 [48:15<21:19, 11.63s/it]predicting train subjects:  65%|██████▍   | 202/311 [48:27<21:12, 11.67s/it]predicting train subjects:  65%|██████▌   | 203/311 [48:38<20:52, 11.59s/it]predicting train subjects:  66%|██████▌   | 204/311 [48:49<20:32, 11.52s/it]predicting train subjects:  66%|██████▌   | 205/311 [49:01<20:29, 11.60s/it]predicting train subjects:  66%|██████▌   | 206/311 [49:13<20:30, 11.72s/it]predicting train subjects:  67%|██████▋   | 207/311 [49:25<20:25, 11.79s/it]predicting train subjects:  67%|██████▋   | 208/311 [49:36<19:57, 11.62s/it]predicting train subjects:  67%|██████▋   | 209/311 [49:48<19:44, 11.61s/it]predicting train subjects:  68%|██████▊   | 210/311 [50:00<19:37, 11.65s/it]predicting train subjects:  68%|██████▊   | 211/311 [50:11<19:21, 11.61s/it]predicting train subjects:  68%|██████▊   | 212/311 [50:22<18:50, 11.42s/it]predicting train subjects:  68%|██████▊   | 213/311 [50:44<23:46, 14.56s/it]predicting train subjects:  69%|██████▉   | 214/311 [51:06<26:52, 16.63s/it]predicting train subjects:  69%|██████▉   | 215/311 [51:28<29:24, 18.38s/it]predicting train subjects:  69%|██████▉   | 216/311 [51:50<30:38, 19.35s/it]predicting train subjects:  70%|██████▉   | 217/311 [52:12<31:46, 20.28s/it]predicting train subjects:  70%|███████   | 218/311 [52:34<32:02, 20.67s/it]predicting train subjects:  70%|███████   | 219/311 [52:56<32:29, 21.19s/it]predicting train subjects:  71%|███████   | 220/311 [53:18<32:19, 21.31s/it]predicting train subjects:  71%|███████   | 221/311 [53:39<32:11, 21.46s/it]predicting train subjects:  71%|███████▏  | 222/311 [54:02<32:19, 21.79s/it]predicting train subjects:  72%|███████▏  | 223/311 [54:24<31:52, 21.74s/it]predicting train subjects:  72%|███████▏  | 224/311 [54:46<31:49, 21.95s/it]predicting train subjects:  72%|███████▏  | 225/311 [55:09<31:49, 22.21s/it]predicting train subjects:  73%|███████▎  | 226/311 [55:31<31:35, 22.30s/it]predicting train subjects:  73%|███████▎  | 227/311 [55:53<31:02, 22.17s/it]predicting train subjects:  73%|███████▎  | 228/311 [56:16<30:56, 22.36s/it]predicting train subjects:  74%|███████▎  | 229/311 [56:39<30:39, 22.44s/it]predicting train subjects:  74%|███████▍  | 230/311 [57:00<29:59, 22.22s/it]predicting train subjects:  74%|███████▍  | 231/311 [57:11<24:58, 18.74s/it]predicting train subjects:  75%|███████▍  | 232/311 [57:21<21:16, 16.16s/it]predicting train subjects:  75%|███████▍  | 233/311 [57:31<18:43, 14.40s/it]predicting train subjects:  75%|███████▌  | 234/311 [57:42<16:58, 13.23s/it]predicting train subjects:  76%|███████▌  | 235/311 [57:52<15:39, 12.36s/it]predicting train subjects:  76%|███████▌  | 236/311 [58:02<14:34, 11.66s/it]predicting train subjects:  76%|███████▌  | 237/311 [58:13<14:02, 11.39s/it]predicting train subjects:  77%|███████▋  | 238/311 [58:24<13:32, 11.13s/it]predicting train subjects:  77%|███████▋  | 239/311 [58:34<12:57, 10.80s/it]predicting train subjects:  77%|███████▋  | 240/311 [58:44<12:35, 10.65s/it]predicting train subjects:  77%|███████▋  | 241/311 [58:55<12:27, 10.68s/it]predicting train subjects:  78%|███████▊  | 242/311 [59:05<12:09, 10.57s/it]predicting train subjects:  78%|███████▊  | 243/311 [59:15<11:49, 10.43s/it]predicting train subjects:  78%|███████▊  | 244/311 [59:26<11:44, 10.52s/it]predicting train subjects:  79%|███████▉  | 245/311 [59:36<11:36, 10.55s/it]predicting train subjects:  79%|███████▉  | 246/311 [59:46<11:16, 10.40s/it]predicting train subjects:  79%|███████▉  | 247/311 [59:58<11:20, 10.63s/it]predicting train subjects:  80%|███████▉  | 248/311 [1:00:08<11:10, 10.64s/it]predicting train subjects:  80%|████████  | 249/311 [1:00:22<11:49, 11.44s/it]predicting train subjects:  80%|████████  | 250/311 [1:00:35<12:10, 11.98s/it]predicting train subjects:  81%|████████  | 251/311 [1:00:48<12:27, 12.46s/it]predicting train subjects:  81%|████████  | 252/311 [1:01:01<12:25, 12.64s/it]predicting train subjects:  81%|████████▏ | 253/311 [1:01:15<12:20, 12.77s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:01:28<12:16, 12.93s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:01:41<12:07, 12.98s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:01:54<11:58, 13.07s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:02:07<11:47, 13.11s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:02:21<11:39, 13.20s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:02:34<11:27, 13.23s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:02:47<11:16, 13.26s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:03:01<11:10, 13.41s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:03:14<10:51, 13.30s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:03:27<10:34, 13.22s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:03:40<10:19, 13.18s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:03:53<09:59, 13.03s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:04:06<09:43, 12.96s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:04:19<09:31, 12.98s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:04:32<09:17, 12.97s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:04:45<09:01, 12.90s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:04:57<08:47, 12.85s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:05:11<08:41, 13.05s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:05:24<08:25, 12.95s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:05:36<08:11, 12.92s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:05:49<07:58, 12.92s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:06:02<07:44, 12.91s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:06:15<07:31, 12.89s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:06:28<07:18, 12.89s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:06:41<07:02, 12.79s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:06:53<06:48, 12.77s/it]predicting train subjects:  90%|█████████ | 280/311 [1:07:06<06:34, 12.73s/it]predicting train subjects:  90%|█████████ | 281/311 [1:07:20<06:30, 13.00s/it]predicting train subjects:  91%|█████████ | 282/311 [1:07:33<06:16, 13.00s/it]predicting train subjects:  91%|█████████ | 283/311 [1:07:44<05:53, 12.63s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:07:56<05:34, 12.40s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:08:08<05:14, 12.11s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:08:19<04:57, 11.91s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:08:31<04:44, 11.85s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:08:43<04:32, 11.84s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:08:54<04:19, 11.78s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:09:06<04:05, 11.71s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:09:17<03:52, 11.60s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:09:29<03:41, 11.66s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:09:41<03:30, 11.70s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:09:52<03:19, 11.72s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:10:04<03:05, 11.57s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:10:15<02:54, 11.64s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:10:28<02:46, 11.88s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:10:40<02:34, 11.87s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:10:51<02:21, 11.80s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:11:03<02:08, 11.66s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:11:14<01:56, 11.69s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:11:26<01:45, 11.73s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:11:38<01:34, 11.77s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:11:50<01:23, 11.90s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:12:02<01:10, 11.73s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:12:13<00:58, 11.71s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:12:25<00:46, 11.74s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:12:37<00:35, 11.75s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:12:48<00:23, 11.66s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:13:00<00:11, 11.56s/it]predicting train subjects: 100%|██████████| 311/311 [1:13:11<00:00, 11.58s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:16<1:24:55, 16.44s/it]Loading train:   1%|          | 2/311 [00:24<1:12:24, 14.06s/it]Loading train:   1%|          | 3/311 [00:35<1:06:34, 12.97s/it]Loading train:   1%|▏         | 4/311 [00:45<1:02:18, 12.18s/it]Loading train:   2%|▏         | 5/311 [00:54<57:37, 11.30s/it]  Loading train:   2%|▏         | 6/311 [01:04<54:43, 10.77s/it]Loading train:   2%|▏         | 7/311 [01:15<54:19, 10.72s/it]Loading train:   3%|▎         | 8/311 [01:27<56:21, 11.16s/it]Loading train:   3%|▎         | 9/311 [01:38<56:44, 11.27s/it]Loading train:   3%|▎         | 10/311 [01:48<54:10, 10.80s/it]Loading train:   4%|▎         | 11/311 [02:01<56:37, 11.33s/it]Loading train:   4%|▍         | 12/311 [02:10<54:03, 10.85s/it]Loading train:   4%|▍         | 13/311 [02:20<52:07, 10.50s/it]Loading train:   5%|▍         | 14/311 [02:32<54:17, 10.97s/it]Loading train:   5%|▍         | 15/311 [02:41<51:19, 10.40s/it]Loading train:   5%|▌         | 16/311 [02:51<49:49, 10.13s/it]Loading train:   5%|▌         | 17/311 [02:59<47:33,  9.70s/it]Loading train:   6%|▌         | 18/311 [03:08<46:19,  9.48s/it]Loading train:   6%|▌         | 19/311 [03:18<45:58,  9.45s/it]Loading train:   6%|▋         | 20/311 [03:27<45:44,  9.43s/it]Loading train:   7%|▋         | 21/311 [03:36<45:19,  9.38s/it]Loading train:   7%|▋         | 22/311 [03:46<45:05,  9.36s/it]Loading train:   7%|▋         | 23/311 [03:55<44:59,  9.37s/it]Loading train:   8%|▊         | 24/311 [04:05<45:08,  9.44s/it]Loading train:   8%|▊         | 25/311 [04:14<44:38,  9.36s/it]Loading train:   8%|▊         | 26/311 [04:23<44:18,  9.33s/it]Loading train:   9%|▊         | 27/311 [04:33<44:23,  9.38s/it]Loading train:   9%|▉         | 28/311 [04:42<44:18,  9.39s/it]Loading train:   9%|▉         | 29/311 [04:51<44:11,  9.40s/it]Loading train:  10%|▉         | 30/311 [05:01<44:07,  9.42s/it]Loading train:  10%|▉         | 31/311 [05:10<44:14,  9.48s/it]Loading train:  10%|█         | 32/311 [05:20<44:01,  9.47s/it]Loading train:  11%|█         | 33/311 [05:25<37:35,  8.11s/it]Loading train:  11%|█         | 34/311 [05:30<32:46,  7.10s/it]Loading train:  11%|█▏        | 35/311 [05:34<29:23,  6.39s/it]Loading train:  12%|█▏        | 36/311 [05:39<27:00,  5.89s/it]Loading train:  12%|█▏        | 37/311 [05:44<25:27,  5.58s/it]Loading train:  12%|█▏        | 38/311 [05:49<24:12,  5.32s/it]Loading train:  13%|█▎        | 39/311 [05:53<23:27,  5.18s/it]Loading train:  13%|█▎        | 40/311 [05:58<22:49,  5.05s/it]Loading train:  13%|█▎        | 41/311 [06:03<22:14,  4.94s/it]Loading train:  14%|█▎        | 42/311 [06:08<21:56,  4.90s/it]Loading train:  14%|█▍        | 43/311 [06:12<21:36,  4.84s/it]Loading train:  14%|█▍        | 44/311 [06:17<21:29,  4.83s/it]Loading train:  14%|█▍        | 45/311 [06:22<21:32,  4.86s/it]Loading train:  15%|█▍        | 46/311 [06:27<21:11,  4.80s/it]Loading train:  15%|█▌        | 47/311 [06:31<20:51,  4.74s/it]Loading train:  15%|█▌        | 48/311 [06:36<20:55,  4.77s/it]Loading train:  16%|█▌        | 49/311 [06:41<20:52,  4.78s/it]Loading train:  16%|█▌        | 50/311 [06:46<20:43,  4.77s/it]Loading train:  16%|█▋        | 51/311 [06:52<22:18,  5.15s/it]Loading train:  17%|█▋        | 52/311 [06:58<22:58,  5.32s/it]Loading train:  17%|█▋        | 53/311 [07:03<23:38,  5.50s/it]Loading train:  17%|█▋        | 54/311 [07:09<24:04,  5.62s/it]Loading train:  18%|█▊        | 55/311 [07:15<23:53,  5.60s/it]Loading train:  18%|█▊        | 56/311 [07:20<23:42,  5.58s/it]Loading train:  18%|█▊        | 57/311 [07:26<24:00,  5.67s/it]Loading train:  19%|█▊        | 58/311 [07:32<24:03,  5.71s/it]Loading train:  19%|█▉        | 59/311 [07:38<24:25,  5.81s/it]Loading train:  19%|█▉        | 60/311 [07:44<24:03,  5.75s/it]Loading train:  20%|█▉        | 61/311 [07:50<23:58,  5.76s/it]Loading train:  20%|█▉        | 62/311 [07:55<24:04,  5.80s/it]Loading train:  20%|██        | 63/311 [08:01<23:44,  5.75s/it]Loading train:  21%|██        | 64/311 [08:07<23:48,  5.78s/it]Loading train:  21%|██        | 65/311 [08:13<24:05,  5.88s/it]Loading train:  21%|██        | 66/311 [08:19<23:49,  5.83s/it]Loading train:  22%|██▏       | 67/311 [08:24<23:27,  5.77s/it]Loading train:  22%|██▏       | 68/311 [08:30<23:08,  5.71s/it]Loading train:  22%|██▏       | 69/311 [08:36<22:51,  5.67s/it]Loading train:  23%|██▎       | 70/311 [08:41<22:40,  5.64s/it]Loading train:  23%|██▎       | 71/311 [08:47<22:29,  5.62s/it]Loading train:  23%|██▎       | 72/311 [08:52<22:28,  5.64s/it]Loading train:  23%|██▎       | 73/311 [08:58<22:25,  5.65s/it]Loading train:  24%|██▍       | 74/311 [09:03<22:03,  5.58s/it]Loading train:  24%|██▍       | 75/311 [09:09<22:08,  5.63s/it]Loading train:  24%|██▍       | 76/311 [09:15<22:03,  5.63s/it]Loading train:  25%|██▍       | 77/311 [09:20<21:44,  5.57s/it]Loading train:  25%|██▌       | 78/311 [09:26<21:53,  5.64s/it]Loading train:  25%|██▌       | 79/311 [09:32<21:45,  5.63s/it]Loading train:  26%|██▌       | 80/311 [09:37<21:40,  5.63s/it]Loading train:  26%|██▌       | 81/311 [09:43<21:34,  5.63s/it]Loading train:  26%|██▋       | 82/311 [09:49<21:23,  5.60s/it]Loading train:  27%|██▋       | 83/311 [09:54<21:18,  5.61s/it]Loading train:  27%|██▋       | 84/311 [10:00<21:02,  5.56s/it]Loading train:  27%|██▋       | 85/311 [10:05<20:35,  5.47s/it]Loading train:  28%|██▊       | 86/311 [10:10<20:06,  5.36s/it]Loading train:  28%|██▊       | 87/311 [10:15<19:42,  5.28s/it]Loading train:  28%|██▊       | 88/311 [10:20<19:05,  5.14s/it]Loading train:  29%|██▊       | 89/311 [10:25<18:52,  5.10s/it]Loading train:  29%|██▉       | 90/311 [10:30<18:52,  5.12s/it]Loading train:  29%|██▉       | 91/311 [10:35<18:39,  5.09s/it]Loading train:  30%|██▉       | 92/311 [10:40<18:47,  5.15s/it]Loading train:  30%|██▉       | 93/311 [10:45<18:44,  5.16s/it]Loading train:  30%|███       | 94/311 [10:51<18:38,  5.15s/it]Loading train:  31%|███       | 95/311 [10:56<18:34,  5.16s/it]Loading train:  31%|███       | 96/311 [11:01<18:20,  5.12s/it]Loading train:  31%|███       | 97/311 [11:06<18:27,  5.18s/it]Loading train:  32%|███▏      | 98/311 [11:11<18:11,  5.12s/it]Loading train:  32%|███▏      | 99/311 [11:16<18:07,  5.13s/it]Loading train:  32%|███▏      | 100/311 [11:21<18:03,  5.14s/it]Loading train:  32%|███▏      | 101/311 [11:26<17:53,  5.11s/it]Loading train:  33%|███▎      | 102/311 [11:32<18:10,  5.22s/it]Loading train:  33%|███▎      | 103/311 [11:37<18:07,  5.23s/it]Loading train:  33%|███▎      | 104/311 [11:42<18:03,  5.24s/it]Loading train:  34%|███▍      | 105/311 [11:48<18:03,  5.26s/it]Loading train:  34%|███▍      | 106/311 [11:53<18:01,  5.27s/it]Loading train:  34%|███▍      | 107/311 [11:58<17:41,  5.21s/it]Loading train:  35%|███▍      | 108/311 [12:03<17:41,  5.23s/it]Loading train:  35%|███▌      | 109/311 [12:09<17:44,  5.27s/it]Loading train:  35%|███▌      | 110/311 [12:14<17:33,  5.24s/it]Loading train:  36%|███▌      | 111/311 [12:19<17:29,  5.25s/it]Loading train:  36%|███▌      | 112/311 [12:24<17:10,  5.18s/it]Loading train:  36%|███▋      | 113/311 [12:29<16:56,  5.13s/it]Loading train:  37%|███▋      | 114/311 [12:38<20:49,  6.34s/it]Loading train:  37%|███▋      | 115/311 [12:48<23:55,  7.32s/it]Loading train:  37%|███▋      | 116/311 [12:57<25:44,  7.92s/it]Loading train:  38%|███▊      | 117/311 [13:06<26:48,  8.29s/it]Loading train:  38%|███▊      | 118/311 [13:16<27:43,  8.62s/it]Loading train:  38%|███▊      | 119/311 [13:25<28:25,  8.88s/it]Loading train:  39%|███▊      | 120/311 [13:35<29:06,  9.14s/it]Loading train:  39%|███▉      | 121/311 [13:45<29:12,  9.22s/it]Loading train:  39%|███▉      | 122/311 [13:54<28:55,  9.18s/it]Loading train:  40%|███▉      | 123/311 [14:03<28:48,  9.19s/it]Loading train:  40%|███▉      | 124/311 [14:12<28:49,  9.25s/it]Loading train:  40%|████      | 125/311 [14:22<28:52,  9.31s/it]Loading train:  41%|████      | 126/311 [14:31<28:48,  9.34s/it]Loading train:  41%|████      | 127/311 [14:40<28:25,  9.27s/it]Loading train:  41%|████      | 128/311 [14:50<28:23,  9.31s/it]Loading train:  41%|████▏     | 129/311 [14:59<28:18,  9.33s/it]Loading train:  42%|████▏     | 130/311 [15:09<28:20,  9.40s/it]Loading train:  42%|████▏     | 131/311 [15:18<28:24,  9.47s/it]Loading train:  42%|████▏     | 132/311 [15:23<24:20,  8.16s/it]Loading train:  43%|████▎     | 133/311 [15:28<21:19,  7.19s/it]Loading train:  43%|████▎     | 134/311 [15:33<19:07,  6.48s/it]Loading train:  43%|████▎     | 135/311 [15:38<17:46,  6.06s/it]Loading train:  44%|████▎     | 136/311 [15:43<16:35,  5.69s/it]Loading train:  44%|████▍     | 137/311 [15:48<15:36,  5.38s/it]Loading train:  44%|████▍     | 138/311 [15:52<14:49,  5.14s/it]Loading train:  45%|████▍     | 139/311 [15:57<14:19,  5.00s/it]Loading train:  45%|████▌     | 140/311 [16:02<14:12,  4.98s/it]Loading train:  45%|████▌     | 141/311 [16:07<13:55,  4.92s/it]Loading train:  46%|████▌     | 142/311 [16:11<13:35,  4.82s/it]Loading train:  46%|████▌     | 143/311 [16:16<13:20,  4.77s/it]Loading train:  46%|████▋     | 144/311 [16:20<13:12,  4.74s/it]Loading train:  47%|████▋     | 145/311 [16:25<13:04,  4.73s/it]Loading train:  47%|████▋     | 146/311 [16:30<12:59,  4.72s/it]Loading train:  47%|████▋     | 147/311 [16:35<13:09,  4.81s/it]Loading train:  48%|████▊     | 148/311 [16:39<12:52,  4.74s/it]Loading train:  48%|████▊     | 149/311 [16:44<12:48,  4.74s/it]Loading train:  48%|████▊     | 150/311 [16:50<13:53,  5.18s/it]Loading train:  49%|████▊     | 151/311 [16:56<14:18,  5.37s/it]Loading train:  49%|████▉     | 152/311 [17:02<14:45,  5.57s/it]Loading train:  49%|████▉     | 153/311 [17:08<14:56,  5.68s/it]Loading train:  50%|████▉     | 154/311 [17:14<15:10,  5.80s/it]Loading train:  50%|████▉     | 155/311 [17:20<15:03,  5.79s/it]Loading train:  50%|█████     | 156/311 [17:26<14:49,  5.74s/it]Loading train:  50%|█████     | 157/311 [17:31<14:48,  5.77s/it]Loading train:  51%|█████     | 158/311 [17:37<14:44,  5.78s/it]Loading train:  51%|█████     | 159/311 [17:43<14:38,  5.78s/it]Loading train:  51%|█████▏    | 160/311 [17:49<14:30,  5.77s/it]Loading train:  52%|█████▏    | 161/311 [17:55<14:30,  5.80s/it]Loading train:  52%|█████▏    | 162/311 [18:01<14:28,  5.83s/it]Loading train:  52%|█████▏    | 163/311 [18:06<14:25,  5.85s/it]Loading train:  53%|█████▎    | 164/311 [18:12<14:16,  5.82s/it]Loading train:  53%|█████▎    | 165/311 [18:18<14:02,  5.77s/it]Loading train:  53%|█████▎    | 166/311 [18:24<13:54,  5.76s/it]Loading train:  54%|█████▎    | 167/311 [18:29<13:42,  5.71s/it]Loading train:  54%|█████▍    | 168/311 [18:35<13:31,  5.68s/it]Loading train:  54%|█████▍    | 169/311 [18:40<13:24,  5.67s/it]Loading train:  55%|█████▍    | 170/311 [18:46<13:14,  5.63s/it]Loading train:  55%|█████▍    | 171/311 [18:51<12:59,  5.57s/it]Loading train:  55%|█████▌    | 172/311 [18:57<12:52,  5.56s/it]Loading train:  56%|█████▌    | 173/311 [19:03<12:58,  5.64s/it]Loading train:  56%|█████▌    | 174/311 [19:08<12:51,  5.63s/it]Loading train:  56%|█████▋    | 175/311 [19:14<12:59,  5.73s/it]Loading train:  57%|█████▋    | 176/311 [19:20<12:50,  5.71s/it]Loading train:  57%|█████▋    | 177/311 [19:26<12:41,  5.69s/it]Loading train:  57%|█████▋    | 178/311 [19:31<12:37,  5.69s/it]Loading train:  58%|█████▊    | 179/311 [19:37<12:30,  5.68s/it]Loading train:  58%|█████▊    | 180/311 [19:43<12:23,  5.68s/it]Loading train:  58%|█████▊    | 181/311 [19:48<12:18,  5.68s/it]Loading train:  59%|█████▊    | 182/311 [19:54<12:16,  5.71s/it]Loading train:  59%|█████▉    | 183/311 [20:00<12:18,  5.77s/it]Loading train:  59%|█████▉    | 184/311 [20:05<11:58,  5.66s/it]Loading train:  59%|█████▉    | 185/311 [20:10<11:26,  5.45s/it]Loading train:  60%|█████▉    | 186/311 [20:16<11:24,  5.48s/it]Loading train:  60%|██████    | 187/311 [20:21<11:10,  5.40s/it]Loading train:  60%|██████    | 188/311 [20:27<11:04,  5.40s/it]Loading train:  61%|██████    | 189/311 [20:32<11:00,  5.42s/it]Loading train:  61%|██████    | 190/311 [20:37<10:45,  5.33s/it]Loading train:  61%|██████▏   | 191/311 [20:42<10:29,  5.24s/it]Loading train:  62%|██████▏   | 192/311 [20:48<10:26,  5.27s/it]Loading train:  62%|██████▏   | 193/311 [20:53<10:21,  5.27s/it]Loading train:  62%|██████▏   | 194/311 [20:58<10:10,  5.22s/it]Loading train:  63%|██████▎   | 195/311 [21:03<10:03,  5.20s/it]Loading train:  63%|██████▎   | 196/311 [21:08<09:56,  5.19s/it]Loading train:  63%|██████▎   | 197/311 [21:13<09:51,  5.19s/it]Loading train:  64%|██████▎   | 198/311 [21:19<09:49,  5.22s/it]Loading train:  64%|██████▍   | 199/311 [21:24<09:46,  5.24s/it]Loading train:  64%|██████▍   | 200/311 [21:29<09:37,  5.20s/it]Loading train:  65%|██████▍   | 201/311 [21:35<09:40,  5.28s/it]Loading train:  65%|██████▍   | 202/311 [21:40<09:38,  5.31s/it]Loading train:  65%|██████▌   | 203/311 [21:46<09:41,  5.38s/it]Loading train:  66%|██████▌   | 204/311 [21:51<09:48,  5.50s/it]Loading train:  66%|██████▌   | 205/311 [21:57<09:49,  5.56s/it]Loading train:  66%|██████▌   | 206/311 [22:03<09:41,  5.54s/it]Loading train:  67%|██████▋   | 207/311 [22:08<09:44,  5.62s/it]Loading train:  67%|██████▋   | 208/311 [22:14<09:50,  5.73s/it]Loading train:  67%|██████▋   | 209/311 [22:20<09:49,  5.78s/it]Loading train:  68%|██████▊   | 210/311 [22:26<09:36,  5.71s/it]Loading train:  68%|██████▊   | 211/311 [22:31<09:30,  5.70s/it]Loading train:  68%|██████▊   | 212/311 [22:37<09:22,  5.68s/it]Loading train:  68%|██████▊   | 213/311 [22:47<11:16,  6.90s/it]Loading train:  69%|██████▉   | 214/311 [22:57<12:44,  7.88s/it]Loading train:  69%|██████▉   | 215/311 [23:07<13:46,  8.61s/it]Loading train:  69%|██████▉   | 216/311 [23:17<14:18,  9.04s/it]Loading train:  70%|██████▉   | 217/311 [23:28<14:43,  9.40s/it]Loading train:  70%|███████   | 218/311 [23:38<14:50,  9.57s/it]Loading train:  70%|███████   | 219/311 [23:48<14:58,  9.76s/it]Loading train:  71%|███████   | 220/311 [23:58<14:47,  9.76s/it]Loading train:  71%|███████   | 221/311 [24:08<14:59,  9.99s/it]Loading train:  71%|███████▏  | 222/311 [24:18<14:49,  9.99s/it]Loading train:  72%|███████▏  | 223/311 [24:28<14:39, 10.00s/it]Loading train:  72%|███████▏  | 224/311 [24:38<14:22,  9.91s/it]Loading train:  72%|███████▏  | 225/311 [24:48<14:17,  9.97s/it]Loading train:  73%|███████▎  | 226/311 [24:58<14:06,  9.96s/it]Loading train:  73%|███████▎  | 227/311 [25:08<14:03, 10.05s/it]Loading train:  73%|███████▎  | 228/311 [25:18<13:49, 10.00s/it]Loading train:  74%|███████▎  | 229/311 [25:28<13:51, 10.14s/it]Loading train:  74%|███████▍  | 230/311 [25:38<13:37, 10.09s/it]Loading train:  74%|███████▍  | 231/311 [25:44<11:33,  8.67s/it]Loading train:  75%|███████▍  | 232/311 [25:49<09:58,  7.57s/it]Loading train:  75%|███████▍  | 233/311 [25:54<08:56,  6.88s/it]Loading train:  75%|███████▌  | 234/311 [25:59<08:11,  6.39s/it]Loading train:  76%|███████▌  | 235/311 [26:05<07:46,  6.13s/it]Loading train:  76%|███████▌  | 236/311 [26:13<08:22,  6.70s/it]Loading train:  76%|███████▌  | 237/311 [26:20<08:31,  6.92s/it]Loading train:  77%|███████▋  | 238/311 [26:28<08:34,  7.05s/it]Loading train:  77%|███████▋  | 239/311 [26:35<08:37,  7.19s/it]Loading train:  77%|███████▋  | 240/311 [26:43<08:37,  7.29s/it]Loading train:  77%|███████▋  | 241/311 [26:51<08:48,  7.55s/it]Loading train:  78%|███████▊  | 242/311 [26:58<08:42,  7.57s/it]Loading train:  78%|███████▊  | 243/311 [27:06<08:42,  7.68s/it]Loading train:  78%|███████▊  | 244/311 [27:14<08:29,  7.60s/it]Loading train:  79%|███████▉  | 245/311 [27:22<08:25,  7.65s/it]Loading train:  79%|███████▉  | 246/311 [27:28<07:58,  7.35s/it]Loading train:  79%|███████▉  | 247/311 [27:36<07:50,  7.35s/it]Loading train:  80%|███████▉  | 248/311 [27:43<07:44,  7.37s/it]Loading train:  80%|████████  | 249/311 [27:52<08:09,  7.90s/it]Loading train:  80%|████████  | 250/311 [28:01<08:13,  8.09s/it]Loading train:  81%|████████  | 251/311 [28:10<08:27,  8.46s/it]Loading train:  81%|████████  | 252/311 [28:19<08:27,  8.61s/it]Loading train:  81%|████████▏ | 253/311 [28:27<08:16,  8.56s/it]Loading train:  82%|████████▏ | 254/311 [28:37<08:18,  8.75s/it]Loading train:  82%|████████▏ | 255/311 [28:45<08:04,  8.65s/it]Loading train:  82%|████████▏ | 256/311 [28:53<07:49,  8.54s/it]Loading train:  83%|████████▎ | 257/311 [29:02<07:42,  8.56s/it]Loading train:  83%|████████▎ | 258/311 [29:10<07:34,  8.58s/it]Loading train:  83%|████████▎ | 259/311 [29:19<07:30,  8.65s/it]Loading train:  84%|████████▎ | 260/311 [29:27<07:10,  8.43s/it]Loading train:  84%|████████▍ | 261/311 [29:36<07:07,  8.56s/it]Loading train:  84%|████████▍ | 262/311 [29:44<06:49,  8.35s/it]Loading train:  85%|████████▍ | 263/311 [29:52<06:40,  8.34s/it]Loading train:  85%|████████▍ | 264/311 [30:00<06:29,  8.28s/it]Loading train:  85%|████████▌ | 265/311 [30:08<06:16,  8.18s/it]Loading train:  86%|████████▌ | 266/311 [30:17<06:12,  8.28s/it]Loading train:  86%|████████▌ | 267/311 [30:26<06:12,  8.46s/it]Loading train:  86%|████████▌ | 268/311 [30:34<05:57,  8.30s/it]Loading train:  86%|████████▋ | 269/311 [30:42<05:48,  8.30s/it]Loading train:  87%|████████▋ | 270/311 [30:50<05:34,  8.16s/it]Loading train:  87%|████████▋ | 271/311 [30:58<05:27,  8.20s/it]Loading train:  87%|████████▋ | 272/311 [31:07<05:23,  8.29s/it]Loading train:  88%|████████▊ | 273/311 [31:15<05:14,  8.28s/it]Loading train:  88%|████████▊ | 274/311 [31:23<05:05,  8.25s/it]Loading train:  88%|████████▊ | 275/311 [31:32<05:00,  8.36s/it]Loading train:  89%|████████▊ | 276/311 [31:40<04:56,  8.47s/it]Loading train:  89%|████████▉ | 277/311 [31:49<04:47,  8.46s/it]Loading train:  89%|████████▉ | 278/311 [31:57<04:39,  8.48s/it]Loading train:  90%|████████▉ | 279/311 [32:05<04:24,  8.26s/it]Loading train:  90%|█████████ | 280/311 [32:14<04:18,  8.35s/it]Loading train:  90%|█████████ | 281/311 [32:21<03:58,  7.93s/it]Loading train:  91%|█████████ | 282/311 [32:29<03:52,  8.00s/it]Loading train:  91%|█████████ | 283/311 [32:37<03:42,  7.93s/it]Loading train:  91%|█████████▏| 284/311 [32:43<03:20,  7.42s/it]Loading train:  92%|█████████▏| 285/311 [32:49<03:04,  7.10s/it]Loading train:  92%|█████████▏| 286/311 [32:55<02:52,  6.88s/it]Loading train:  92%|█████████▏| 287/311 [33:02<02:39,  6.66s/it]Loading train:  93%|█████████▎| 288/311 [33:08<02:28,  6.48s/it]Loading train:  93%|█████████▎| 289/311 [33:14<02:23,  6.52s/it]Loading train:  93%|█████████▎| 290/311 [33:21<02:15,  6.45s/it]Loading train:  94%|█████████▎| 291/311 [33:27<02:07,  6.37s/it]Loading train:  94%|█████████▍| 292/311 [33:33<01:58,  6.23s/it]Loading train:  94%|█████████▍| 293/311 [33:39<01:53,  6.30s/it]Loading train:  95%|█████████▍| 294/311 [33:45<01:45,  6.19s/it]Loading train:  95%|█████████▍| 295/311 [33:51<01:40,  6.26s/it]Loading train:  95%|█████████▌| 296/311 [33:58<01:33,  6.22s/it]Loading train:  95%|█████████▌| 297/311 [34:04<01:27,  6.24s/it]Loading train:  96%|█████████▌| 298/311 [34:10<01:20,  6.20s/it]Loading train:  96%|█████████▌| 299/311 [34:17<01:16,  6.39s/it]Loading train:  96%|█████████▋| 300/311 [34:23<01:10,  6.37s/it]Loading train:  97%|█████████▋| 301/311 [34:30<01:05,  6.52s/it]Loading train:  97%|█████████▋| 302/311 [34:36<00:58,  6.48s/it]Loading train:  97%|█████████▋| 303/311 [34:42<00:50,  6.26s/it]Loading train:  98%|█████████▊| 304/311 [34:49<00:44,  6.32s/it]Loading train:  98%|█████████▊| 305/311 [34:55<00:37,  6.31s/it]Loading train:  98%|█████████▊| 306/311 [35:02<00:32,  6.45s/it]Loading train:  99%|█████████▊| 307/311 [35:08<00:25,  6.29s/it]Loading train:  99%|█████████▉| 308/311 [35:14<00:18,  6.33s/it]Loading train:  99%|█████████▉| 309/311 [35:20<00:12,  6.37s/it]Loading train: 100%|█████████▉| 310/311 [35:27<00:06,  6.42s/it]Loading train: 100%|██████████| 311/311 [35:33<00:00,  6.36s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/311 [00:00<00:17, 17.39it/s]concatenating: train:   1%|▏         | 4/311 [00:00<00:23, 13.16it/s]concatenating: train:   2%|▏         | 6/311 [00:00<00:23, 12.84it/s]concatenating: train:   5%|▍         | 14/311 [00:00<00:17, 17.16it/s]concatenating: train:  11%|█▏        | 35/311 [00:00<00:11, 23.66it/s]concatenating: train:  20%|█▉        | 61/311 [00:00<00:07, 32.52it/s]concatenating: train:  26%|██▋       | 82/311 [00:00<00:05, 43.49it/s]concatenating: train:  35%|███▌      | 109/311 [00:00<00:03, 58.08it/s]concatenating: train:  42%|████▏     | 132/311 [00:01<00:02, 74.37it/s]concatenating: train:  49%|████▉     | 152/311 [00:01<00:02, 58.51it/s]concatenating: train:  54%|█████▎    | 167/311 [00:02<00:03, 40.89it/s]concatenating: train:  58%|█████▊    | 179/311 [00:02<00:03, 43.22it/s]concatenating: train:  66%|██████▌   | 206/311 [00:02<00:01, 57.77it/s]concatenating: train:  75%|███████▍  | 233/311 [00:02<00:01, 75.60it/s]concatenating: train:  84%|████████▍ | 261/311 [00:02<00:00, 96.60it/s]concatenating: train:  91%|█████████ | 283/311 [00:02<00:00, 99.11it/s]concatenating: train:  97%|█████████▋| 301/311 [00:03<00:00, 58.38it/s]concatenating: train: 100%|██████████| 311/311 [00:03<00:00, 80.91it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:13<00:41, 13.72s/it]Loading test:  50%|█████     | 2/4 [00:26<00:26, 13.33s/it]Loading test:  75%|███████▌  | 3/4 [00:39<00:13, 13.41s/it]Loading test: 100%|██████████| 4/4 [00:52<00:00, 13.26s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 41.80it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 10:21:25.778789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 10:21:25.778936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 10:21:25.778954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 10:21:25.778968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 10:21:25.779492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 26, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [5.88176395e-02 2.85713643e-02 1.22080201e-01 1.04952659e-02
 3.15779544e-02 5.46270752e-03 7.23535399e-02 1.13294426e-01
 7.88079565e-02 1.27907394e-02 2.93002722e-01 1.72516551e-01
 2.28932584e-04]
Train on 20529 samples, validate on 262 samples
Epoch 1/300
 - 22s - loss: 18985.6451 - acc: 0.8530 - mDice: 0.0951 - val_loss: 9460.8876 - val_acc: 0.8756 - val_mDice: 0.1813

Epoch 00001: val_mDice improved from -inf to 0.18128, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 8148.6765 - acc: 0.8723 - mDice: 0.2201 - val_loss: 5692.9602 - val_acc: 0.8879 - val_mDice: 0.3245

Epoch 00002: val_mDice improved from 0.18128 to 0.32446, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 6189.4755 - acc: 0.8882 - mDice: 0.3133 - val_loss: 4533.0896 - val_acc: 0.8976 - val_mDice: 0.3948

Epoch 00003: val_mDice improved from 0.32446 to 0.39477, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 5158.8675 - acc: 0.8997 - mDice: 0.3798 - val_loss: 4039.5677 - val_acc: 0.9015 - val_mDice: 0.4295

Epoch 00004: val_mDice improved from 0.39477 to 0.42952, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 4606.6671 - acc: 0.9058 - mDice: 0.4179 - val_loss: 3517.2699 - val_acc: 0.9077 - val_mDice: 0.4767

Epoch 00005: val_mDice improved from 0.42952 to 0.47674, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 13s - loss: 4114.4138 - acc: 0.9118 - mDice: 0.4551 - val_loss: 3197.3601 - val_acc: 0.9145 - val_mDice: 0.5067

Epoch 00006: val_mDice improved from 0.47674 to 0.50675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 3716.1717 - acc: 0.9163 - mDice: 0.4866 - val_loss: 2821.5638 - val_acc: 0.9220 - val_mDice: 0.5410

Epoch 00007: val_mDice improved from 0.50675 to 0.54097, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 12s - loss: 3369.6463 - acc: 0.9206 - mDice: 0.5172 - val_loss: 2606.6959 - val_acc: 0.9263 - val_mDice: 0.5657

Epoch 00008: val_mDice improved from 0.54097 to 0.56575, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 13s - loss: 3075.3520 - acc: 0.9243 - mDice: 0.5439 - val_loss: 2510.0422 - val_acc: 0.9297 - val_mDice: 0.5796

Epoch 00009: val_mDice improved from 0.56575 to 0.57958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 12s - loss: 2871.9534 - acc: 0.9271 - mDice: 0.5652 - val_loss: 2316.6950 - val_acc: 0.9328 - val_mDice: 0.6013

Epoch 00010: val_mDice improved from 0.57958 to 0.60129, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 13s - loss: 2707.0904 - acc: 0.9291 - mDice: 0.5826 - val_loss: 2237.1332 - val_acc: 0.9352 - val_mDice: 0.6110

Epoch 00011: val_mDice improved from 0.60129 to 0.61096, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 12s - loss: 2592.7200 - acc: 0.9311 - mDice: 0.5958 - val_loss: 2171.8803 - val_acc: 0.9369 - val_mDice: 0.6213

Epoch 00012: val_mDice improved from 0.61096 to 0.62129, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 13s - loss: 2481.5195 - acc: 0.9327 - mDice: 0.6085 - val_loss: 2104.0245 - val_acc: 0.9387 - val_mDice: 0.6318

Epoch 00013: val_mDice improved from 0.62129 to 0.63183, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 12s - loss: 2388.1537 - acc: 0.9340 - mDice: 0.6193 - val_loss: 1996.8912 - val_acc: 0.9404 - val_mDice: 0.6447

Epoch 00014: val_mDice improved from 0.63183 to 0.64471, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 13s - loss: 2340.4569 - acc: 0.9350 - mDice: 0.6257 - val_loss: 1971.5254 - val_acc: 0.9418 - val_mDice: 0.6480

Epoch 00015: val_mDice improved from 0.64471 to 0.64797, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 11s - loss: 2259.8723 - acc: 0.9361 - mDice: 0.6353 - val_loss: 2000.4225 - val_acc: 0.9435 - val_mDice: 0.6445

Epoch 00016: val_mDice did not improve from 0.64797
Epoch 17/300
 - 12s - loss: 2200.4846 - acc: 0.9371 - mDice: 0.6426 - val_loss: 1927.4783 - val_acc: 0.9433 - val_mDice: 0.6551

Epoch 00017: val_mDice improved from 0.64797 to 0.65506, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 12s - loss: 2140.5877 - acc: 0.9380 - mDice: 0.6502 - val_loss: 1886.2462 - val_acc: 0.9445 - val_mDice: 0.6605

Epoch 00018: val_mDice improved from 0.65506 to 0.66051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 11s - loss: 2090.3080 - acc: 0.9387 - mDice: 0.6566 - val_loss: 1838.4161 - val_acc: 0.9472 - val_mDice: 0.6674

Epoch 00019: val_mDice improved from 0.66051 to 0.66739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 13s - loss: 2048.5851 - acc: 0.9394 - mDice: 0.6621 - val_loss: 1876.4861 - val_acc: 0.9456 - val_mDice: 0.6630

Epoch 00020: val_mDice did not improve from 0.66739
Epoch 21/300
 - 11s - loss: 2009.0838 - acc: 0.9401 - mDice: 0.6673 - val_loss: 1819.3486 - val_acc: 0.9464 - val_mDice: 0.6709

Epoch 00021: val_mDice improved from 0.66739 to 0.67086, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 12s - loss: 1968.4484 - acc: 0.9408 - mDice: 0.6726 - val_loss: 1777.1576 - val_acc: 0.9481 - val_mDice: 0.6767

Epoch 00022: val_mDice improved from 0.67086 to 0.67675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 12s - loss: 1940.7637 - acc: 0.9414 - mDice: 0.6764 - val_loss: 1755.2143 - val_acc: 0.9496 - val_mDice: 0.6804

Epoch 00023: val_mDice improved from 0.67675 to 0.68036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 24/300
 - 12s - loss: 1897.1222 - acc: 0.9421 - mDice: 0.6822 - val_loss: 1783.1832 - val_acc: 0.9490 - val_mDice: 0.6762

Epoch 00024: val_mDice did not improve from 0.68036
Epoch 25/300
 - 12s - loss: 1866.0623 - acc: 0.9427 - mDice: 0.6864 - val_loss: 1832.1781 - val_acc: 0.9483 - val_mDice: 0.6706

Epoch 00025: val_mDice did not improve from 0.68036
Epoch 26/300
 - 11s - loss: 1850.8865 - acc: 0.9430 - mDice: 0.6885 - val_loss: 1744.4072 - val_acc: 0.9500 - val_mDice: 0.6814

Epoch 00026: val_mDice improved from 0.68036 to 0.68137, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 13s - loss: 1810.0503 - acc: 0.9434 - mDice: 0.6938 - val_loss: 1775.5068 - val_acc: 0.9478 - val_mDice: 0.6773

Epoch 00027: val_mDice did not improve from 0.68137
Epoch 28/300
 - 11s - loss: 1791.0994 - acc: 0.9440 - mDice: 0.6967 - val_loss: 1722.8688 - val_acc: 0.9522 - val_mDice: 0.6858

Epoch 00028: val_mDice improved from 0.68137 to 0.68577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 12s - loss: 1765.8161 - acc: 0.9444 - mDice: 0.7001 - val_loss: 1710.9820 - val_acc: 0.9508 - val_mDice: 0.6870

Epoch 00029: val_mDice improved from 0.68577 to 0.68697, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 12s - loss: 1746.8169 - acc: 0.9448 - mDice: 0.7029 - val_loss: 1725.6873 - val_acc: 0.9526 - val_mDice: 0.6835

Epoch 00030: val_mDice did not improve from 0.68697
Epoch 31/300
 - 11s - loss: 1726.1805 - acc: 0.9452 - mDice: 0.7057 - val_loss: 1692.6021 - val_acc: 0.9534 - val_mDice: 0.6909

Epoch 00031: val_mDice improved from 0.68697 to 0.69086, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 13s - loss: 1706.5195 - acc: 0.9453 - mDice: 0.7084 - val_loss: 1725.1525 - val_acc: 0.9505 - val_mDice: 0.6854

Epoch 00032: val_mDice did not improve from 0.69086
Epoch 33/300
 - 11s - loss: 1681.7086 - acc: 0.9459 - mDice: 0.7119 - val_loss: 1662.5201 - val_acc: 0.9554 - val_mDice: 0.6939

Epoch 00033: val_mDice improved from 0.69086 to 0.69394, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 12s - loss: 1685.5116 - acc: 0.9460 - mDice: 0.7115 - val_loss: 1748.9990 - val_acc: 0.9510 - val_mDice: 0.6826

Epoch 00034: val_mDice did not improve from 0.69394
Epoch 35/300
 - 12s - loss: 1662.9738 - acc: 0.9464 - mDice: 0.7150 - val_loss: 1877.7500 - val_acc: 0.9517 - val_mDice: 0.6655

Epoch 00035: val_mDice did not improve from 0.69394
Epoch 36/300
 - 11s - loss: 1949.7264 - acc: 0.9420 - mDice: 0.6784 - val_loss: 1969.0626 - val_acc: 0.9507 - val_mDice: 0.6525

Epoch 00036: val_mDice did not improve from 0.69394
Epoch 37/300
 - 13s - loss: 1679.4201 - acc: 0.9461 - mDice: 0.7123 - val_loss: 1685.4190 - val_acc: 0.9548 - val_mDice: 0.6907

Epoch 00037: val_mDice did not improve from 0.69394
Epoch 38/300
 - 11s - loss: 1647.2697 - acc: 0.9467 - mDice: 0.7169 - val_loss: 1723.1191 - val_acc: 0.9518 - val_mDice: 0.6867

Epoch 00038: val_mDice did not improve from 0.69394
Epoch 39/300
 - 12s - loss: 1624.9744 - acc: 0.9470 - mDice: 0.7200 - val_loss: 1706.6741 - val_acc: 0.9509 - val_mDice: 0.6879

Epoch 00039: val_mDice did not improve from 0.69394
Epoch 40/300
 - 12s - loss: 1610.1823 - acc: 0.9474 - mDice: 0.7222 - val_loss: 1638.3374 - val_acc: 0.9557 - val_mDice: 0.6980

Epoch 00040: val_mDice improved from 0.69394 to 0.69798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 41/300
 - 12s - loss: 1588.9702 - acc: 0.9477 - mDice: 0.7252 - val_loss: 1642.8498 - val_acc: 0.9537 - val_mDice: 0.6972

Epoch 00041: val_mDice did not improve from 0.69798
Epoch 42/300
 - 13s - loss: 1579.7433 - acc: 0.9479 - mDice: 0.7265 - val_loss: 1760.0468 - val_acc: 0.9548 - val_mDice: 0.6811

Epoch 00042: val_mDice did not improve from 0.69798
Epoch 43/300
 - 11s - loss: 1572.1962 - acc: 0.9479 - mDice: 0.7277 - val_loss: 1930.2475 - val_acc: 0.9521 - val_mDice: 0.6579

Epoch 00043: val_mDice did not improve from 0.69798
Epoch 44/300
 - 13s - loss: 1566.6662 - acc: 0.9482 - mDice: 0.7286 - val_loss: 1770.4992 - val_acc: 0.9549 - val_mDice: 0.6808

Epoch 00044: val_mDice did not improve from 0.69798
Epoch 45/300
 - 12s - loss: 1552.2124 - acc: 0.9483 - mDice: 0.7305 - val_loss: 1853.4548 - val_acc: 0.9553 - val_mDice: 0.6690

Epoch 00045: val_mDice did not improve from 0.69798
Epoch 46/300
 - 12s - loss: 1549.3228 - acc: 0.9484 - mDice: 0.7313 - val_loss: 1640.7312 - val_acc: 0.9552 - val_mDice: 0.6987

Epoch 00046: val_mDice improved from 0.69798 to 0.69867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 12s - loss: 1541.2026 - acc: 0.9487 - mDice: 0.7323 - val_loss: 1652.9923 - val_acc: 0.9556 - val_mDice: 0.6958

Epoch 00047: val_mDice did not improve from 0.69867
Epoch 48/300
 - 11s - loss: 1518.3477 - acc: 0.9490 - mDice: 0.7354 - val_loss: 1683.8864 - val_acc: 0.9515 - val_mDice: 0.6904

Epoch 00048: val_mDice did not improve from 0.69867
Epoch 49/300
 - 13s - loss: 1516.4533 - acc: 0.9490 - mDice: 0.7358 - val_loss: 1762.0639 - val_acc: 0.9510 - val_mDice: 0.6790

Epoch 00049: val_mDice did not improve from 0.69867
Epoch 50/300
 - 11s - loss: 1503.1748 - acc: 0.9492 - mDice: 0.7377 - val_loss: 1629.1985 - val_acc: 0.9561 - val_mDice: 0.6997

Epoch 00050: val_mDice improved from 0.69867 to 0.69975, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 51/300
 - 12s - loss: 1499.8070 - acc: 0.9493 - mDice: 0.7382 - val_loss: 1682.4088 - val_acc: 0.9533 - val_mDice: 0.6915

Epoch 00051: val_mDice did not improve from 0.69975
Epoch 52/300
 - 12s - loss: 1487.7881 - acc: 0.9494 - mDice: 0.7400 - val_loss: 1662.0295 - val_acc: 0.9551 - val_mDice: 0.6944

Epoch 00052: val_mDice did not improve from 0.69975
Epoch 53/300
 - 12s - loss: 1493.5508 - acc: 0.9494 - mDice: 0.7392 - val_loss: 1677.8971 - val_acc: 0.9512 - val_mDice: 0.6921

Epoch 00053: val_mDice did not improve from 0.69975
Epoch 54/300
 - 13s - loss: 1472.6803 - acc: 0.9497 - mDice: 0.7421 - val_loss: 1657.7623 - val_acc: 0.9557 - val_mDice: 0.6961

Epoch 00054: val_mDice did not improve from 0.69975
Epoch 55/300
 - 11s - loss: 1466.5546 - acc: 0.9498 - mDice: 0.7430 - val_loss: 1655.4488 - val_acc: 0.9560 - val_mDice: 0.6955

Epoch 00055: val_mDice did not improve from 0.69975
Epoch 56/300
 - 12s - loss: 1464.2771 - acc: 0.9500 - mDice: 0.7435 - val_loss: 1756.6678 - val_acc: 0.9568 - val_mDice: 0.6841

Epoch 00056: val_mDice did not improve from 0.69975
Epoch 57/300
 - 12s - loss: 1464.1077 - acc: 0.9500 - mDice: 0.7436 - val_loss: 1755.5713 - val_acc: 0.9550 - val_mDice: 0.6831

Epoch 00057: val_mDice did not improve from 0.69975
Epoch 58/300
 - 12s - loss: 1461.6332 - acc: 0.9499 - mDice: 0.7439 - val_loss: 1942.5707 - val_acc: 0.9547 - val_mDice: 0.6580

Epoch 00058: val_mDice did not improve from 0.69975
Epoch 59/300
 - 13s - loss: 1445.0074 - acc: 0.9502 - mDice: 0.7462 - val_loss: 1526.0752 - val_acc: 0.9588 - val_mDice: 0.7155

Epoch 00059: val_mDice improved from 0.69975 to 0.71554, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 60/300
 - 11s - loss: 1435.0250 - acc: 0.9503 - mDice: 0.7477 - val_loss: 1612.1581 - val_acc: 0.9571 - val_mDice: 0.7011

Epoch 00060: val_mDice did not improve from 0.71554
Epoch 61/300
 - 13s - loss: 1432.4319 - acc: 0.9504 - mDice: 0.7482 - val_loss: 1593.9774 - val_acc: 0.9575 - val_mDice: 0.7059

Epoch 00061: val_mDice did not improve from 0.71554
Epoch 62/300
 - 11s - loss: 1429.6060 - acc: 0.9506 - mDice: 0.7486 - val_loss: 1642.1961 - val_acc: 0.9569 - val_mDice: 0.6982

Epoch 00062: val_mDice did not improve from 0.71554
Epoch 63/300
 - 12s - loss: 1422.2185 - acc: 0.9506 - mDice: 0.7497 - val_loss: 1698.5302 - val_acc: 0.9541 - val_mDice: 0.6897

Epoch 00063: val_mDice did not improve from 0.71554
Epoch 64/300
 - 12s - loss: 1415.2885 - acc: 0.9508 - mDice: 0.7506 - val_loss: 1701.2630 - val_acc: 0.9560 - val_mDice: 0.6892

Epoch 00064: val_mDice did not improve from 0.71554
Epoch 65/300
 - 11s - loss: 1407.6562 - acc: 0.9509 - mDice: 0.7520 - val_loss: 1580.7308 - val_acc: 0.9574 - val_mDice: 0.7078

Epoch 00065: val_mDice did not improve from 0.71554
Epoch 66/300
 - 13s - loss: 1402.2251 - acc: 0.9510 - mDice: 0.7527 - val_loss: 1561.1728 - val_acc: 0.9576 - val_mDice: 0.7098

Epoch 00066: val_mDice did not improve from 0.71554
Epoch 67/300
 - 11s - loss: 1400.7131 - acc: 0.9511 - mDice: 0.7529 - val_loss: 1589.4364 - val_acc: 0.9575 - val_mDice: 0.7073

Epoch 00067: val_mDice did not improve from 0.71554
Epoch 68/300
 - 12s - loss: 1391.4147 - acc: 0.9511 - mDice: 0.7543 - val_loss: 1652.4858 - val_acc: 0.9586 - val_mDice: 0.6975

Epoch 00068: val_mDice did not improve from 0.71554
Epoch 69/300
 - 12s - loss: 1418.4388 - acc: 0.9508 - mDice: 0.7506 - val_loss: 1884.5328 - val_acc: 0.9573 - val_mDice: 0.6669

Epoch 00069: val_mDice did not improve from 0.71554
Epoch 70/300
 - 12s - loss: 1389.2506 - acc: 0.9513 - mDice: 0.7545 - val_loss: 1781.2874 - val_acc: 0.9572 - val_mDice: 0.6803

Epoch 00070: val_mDice did not improve from 0.71554
Epoch 71/300
 - 12s - loss: 1387.6604 - acc: 0.9513 - mDice: 0.7548 - val_loss: 1651.3239 - val_acc: 0.9587 - val_mDice: 0.6981

Epoch 00071: val_mDice did not improve from 0.71554
Epoch 72/300
 - 11s - loss: 1372.1030 - acc: 0.9515 - mDice: 0.7571 - val_loss: 1686.4169 - val_acc: 0.9565 - val_mDice: 0.6935

Epoch 00072: val_mDice did not improve from 0.71554
Epoch 73/300
 - 13s - loss: 1377.0746 - acc: 0.9515 - mDice: 0.7565 - val_loss: 1606.2522 - val_acc: 0.9583 - val_mDice: 0.7037

Epoch 00073: val_mDice did not improve from 0.71554
Epoch 74/300
 - 11s - loss: 1370.7189 - acc: 0.9515 - mDice: 0.7574 - val_loss: 1570.4276 - val_acc: 0.9578 - val_mDice: 0.7086

Epoch 00074: val_mDice did not improve from 0.71554
Epoch 75/300
 - 12s - loss: 1365.0344 - acc: 0.9516 - mDice: 0.7581 - val_loss: 1864.9839 - val_acc: 0.9553 - val_mDice: 0.6669

Epoch 00075: val_mDice did not improve from 0.71554
Epoch 76/300
 - 12s - loss: 1355.1327 - acc: 0.9517 - mDice: 0.7595 - val_loss: 1846.0101 - val_acc: 0.9568 - val_mDice: 0.6708

Epoch 00076: val_mDice did not improve from 0.71554
Epoch 77/300
 - 11s - loss: 1354.3578 - acc: 0.9517 - mDice: 0.7598 - val_loss: 1649.9570 - val_acc: 0.9582 - val_mDice: 0.6986

Epoch 00077: val_mDice did not improve from 0.71554
Epoch 78/300
 - 13s - loss: 1355.9273 - acc: 0.9518 - mDice: 0.7596 - val_loss: 1616.7599 - val_acc: 0.9569 - val_mDice: 0.7030

Epoch 00078: val_mDice did not improve from 0.71554
Epoch 79/300
 - 11s - loss: 1344.6357 - acc: 0.9518 - mDice: 0.7612 - val_loss: 1694.5234 - val_acc: 0.9583 - val_mDice: 0.6921

Epoch 00079: val_mDice did not improve from 0.71554
Epoch 80/300
 - 12s - loss: 1346.6984 - acc: 0.9518 - mDice: 0.7609 - val_loss: 1709.6155 - val_acc: 0.9571 - val_mDice: 0.6895

Epoch 00080: val_mDice did not improve from 0.71554
Epoch 81/300
 - 12s - loss: 1340.3624 - acc: 0.9520 - mDice: 0.7619 - val_loss: 1612.9892 - val_acc: 0.9597 - val_mDice: 0.7042

Epoch 00081: val_mDice did not improve from 0.71554
Epoch 82/300
 - 11s - loss: 1339.8194 - acc: 0.9520 - mDice: 0.7620 - val_loss: 1621.1794 - val_acc: 0.9604 - val_mDice: 0.7023

Epoch 00082: val_mDice did not improve from 0.71554
Epoch 83/300
 - 13s - loss: 1330.1516 - acc: 0.9522 - mDice: 0.7635 - val_loss: 1682.1122 - val_acc: 0.9557 - val_mDice: 0.6922

Epoch 00083: val_mDice did not improve from 0.71554
Epoch 84/300
 - 11s - loss: 1324.6038 - acc: 0.9523 - mDice: 0.7643 - val_loss: 1697.9445 - val_acc: 0.9546 - val_mDice: 0.6888

Epoch 00084: val_mDice did not improve from 0.71554
Epoch 85/300
 - 12s - loss: 1329.0183 - acc: 0.9522 - mDice: 0.7636 - val_loss: 1733.8912 - val_acc: 0.9584 - val_mDice: 0.6852

Epoch 00085: val_mDice did not improve from 0.71554
Epoch 86/300
 - 12s - loss: 1327.0867 - acc: 0.9521 - mDice: 0.7640 - val_loss: 1762.6565 - val_acc: 0.9573 - val_mDice: 0.6837

Epoch 00086: val_mDice did not improve from 0.71554
Epoch 87/300
 - 12s - loss: 1320.2232 - acc: 0.9524 - mDice: 0.7650 - val_loss: 1678.7534 - val_acc: 0.9562 - val_mDice: 0.6933

Epoch 00087: val_mDice did not improve from 0.71554
Epoch 88/300
 - 12s - loss: 1328.3219 - acc: 0.9523 - mDice: 0.7640 - val_loss: 1737.3462 - val_acc: 0.9524 - val_mDice: 0.6843

Epoch 00088: val_mDice did not improve from 0.71554
Epoch 89/300
 - 11s - loss: 1317.7799 - acc: 0.9523 - mDice: 0.7654 - val_loss: 1667.8266 - val_acc: 0.9569 - val_mDice: 0.6950

Epoch 00089: val_mDice did not improve from 0.71554
Restoring model weights from the end of the best epoch
Epoch 00089: early stopping
{'val_loss': [9460.88764312977, 5692.9601678047475, 4533.089601473044, 4039.5677425005965, 3517.2699412571565, 3197.3600887851862, 2821.5637598401718, 2606.6958976920323, 2510.042209304926, 2316.695003130964, 2237.1332225071565, 2171.880317047352, 2104.024484881918, 1996.8912400107347, 1971.5253542834566, 2000.4225021245825, 1927.4782565750238, 1886.246216752147, 1838.416078057908, 1876.4860746660306, 1819.3485946072876, 1777.157566682073, 1755.2143219227098, 1783.1831911975191, 1832.178124813633, 1744.4072088576456, 1775.5067912094466, 1722.8688275286258, 1710.9819801854724, 1725.6873005874284, 1692.602138373688, 1725.152490048008, 1662.5200707821446, 1748.99899827797, 1877.7500009318344, 1969.0626183429747, 1685.4190030862358, 1723.1191424886688, 1706.6741281756917, 1638.3373827752266, 1642.8498069239026, 1760.0468256127742, 1930.2475138656966, 1770.499151098819, 1853.4548349162094, 1640.7312160812262, 1652.9922722969347, 1683.886412176467, 1762.0639257067032, 1629.198486328125, 1682.4088321132515, 1662.0294674007037, 1677.8970984539003, 1657.7623169877147, 1655.4487565601146, 1756.6678066108063, 1755.5713337905534, 1942.5706721880963, 1526.075233051795, 1612.1580717363431, 1593.9773862416507, 1642.1961418326575, 1698.5302119364264, 1701.2629636808206, 1580.7307809145395, 1561.1727546517175, 1589.4364013671875, 1652.4858156160544, 1884.532794049678, 1781.2873572429628, 1651.3239177674739, 1686.4168794355319, 1606.2521842199428, 1570.427638396052, 1864.9839109464456, 1846.010063812023, 1649.9569883856154, 1616.7599333552005, 1694.5234375, 1709.6154831747972, 1612.9891581062143, 1621.1793529714337, 1682.1121760943463, 1697.9444999403627, 1733.891202737357, 1762.6565267548306, 1678.753363922352, 1737.3461550647066, 1667.8266042461833], 'val_acc': [0.8755617942518861, 0.8879155571224125, 0.8975520902917585, 0.9015340732254145, 0.9077123703847405, 0.9144834857860594, 0.9220493222010955, 0.9263192210488647, 0.9297309035563287, 0.9327953530631903, 0.9352189507193238, 0.9368761145431577, 0.938718150135215, 0.9404289413044471, 0.9418235384780942, 0.9435470236166743, 0.9433494223893144, 0.9444969719602861, 0.94721419438151, 0.9455782284263436, 0.9463954995606692, 0.9481119304212905, 0.9496039306844464, 0.9489588355290071, 0.9482883542548609, 0.9499949194092787, 0.947832424222058, 0.9522053822306277, 0.9508037394239702, 0.9526217911989634, 0.953395298419108, 0.950500245312698, 0.9553686507785594, 0.951043684063977, 0.9516746601985611, 0.9506724636063321, 0.9547659117756909, 0.9518355740845659, 0.9508517243479955, 0.9557328101332861, 0.9537157225244828, 0.9548152939963886, 0.9521460942639649, 0.9549338731146951, 0.9552853644349193, 0.9551724227330157, 0.9556283509458294, 0.9515433757359745, 0.9509519543356568, 0.956118166901683, 0.9533374223090311, 0.9551456079228233, 0.9512031979233254, 0.9557370461580408, 0.9560461644907944, 0.9567576128107901, 0.9550355044940045, 0.9546897015498794, 0.9587774890979738, 0.9570935414037631, 0.9574760526191187, 0.9568888636035774, 0.9541279200379175, 0.9559925471553365, 0.9574322855199566, 0.9575720493120091, 0.9574605235616669, 0.9585798742206952, 0.9572530343332364, 0.9572205761916764, 0.958736554811929, 0.9564851608895163, 0.9582806397940367, 0.9578233038196127, 0.9552867731065241, 0.9567646443388844, 0.9581648839339045, 0.9568803810891304, 0.9582820361807146, 0.9571358793564425, 0.9597119206690606, 0.9603852324813377, 0.9557356474963763, 0.9546021587066068, 0.9584302479074202, 0.9572996074006758, 0.9561957976290287, 0.9523860793987303, 0.9568733381861039], 'val_mDice': [0.18127621039179445, 0.3244619146558165, 0.3947730132641683, 0.42952374101595114, 0.4767387971168256, 0.5067488833238151, 0.540968173787794, 0.5657496516031163, 0.5795766492836348, 0.6012893196280676, 0.6109629560062904, 0.6212887431829031, 0.6318257874204912, 0.6447051144738234, 0.647972222502905, 0.6444833915652209, 0.6550575804164391, 0.6605129223743468, 0.6673935824678144, 0.6629864896526774, 0.6708555535505746, 0.6767496289187716, 0.6803576008964131, 0.676198962535567, 0.6706282637501491, 0.6813711146361955, 0.6773015465445191, 0.6857671965169543, 0.6869674884635983, 0.6835040923293311, 0.6908570241382104, 0.6853867414343449, 0.6939365308703357, 0.6825669981141127, 0.6654966123231495, 0.652467240359037, 0.6906530593187754, 0.6866904888444274, 0.6879031576273096, 0.6979760727809585, 0.6971664005563459, 0.6811152223412317, 0.6579207072731192, 0.6808068465640527, 0.6689880294654206, 0.6986701652293897, 0.6958086636230236, 0.690447577538381, 0.6789979033797752, 0.6997452460172522, 0.6914988515031246, 0.6944332964547718, 0.6921224007169708, 0.6961349849482529, 0.6954785344254879, 0.6840668498104765, 0.6831259627378624, 0.6580063013630059, 0.7155408595354502, 0.7010539933925367, 0.7058987885941076, 0.6981614364012507, 0.6896583105771597, 0.6891794996407196, 0.707828875716406, 0.7097976212283127, 0.7073227831425558, 0.697498842050101, 0.6668638273049857, 0.6802857559145862, 0.6980847265884167, 0.6935037884093423, 0.7036963896897003, 0.7086318763157794, 0.6669228213434001, 0.6707985319254053, 0.6985953987099742, 0.7029752280875927, 0.6921015377263077, 0.6895239071081612, 0.7042406114913126, 0.702320417375055, 0.6921972545958658, 0.6887976358865053, 0.6852123955733903, 0.6836918060106175, 0.6932918602273664, 0.6842993975595664, 0.6949789296579725], 'loss': [18985.645057991514, 8148.676501648582, 6189.475472489232, 5158.86753385645, 4606.667058589136, 4114.413806770158, 3716.1716812715777, 3369.6462615932605, 3075.3519593162227, 2871.953434020024, 2707.090417984115, 2592.7200314677275, 2481.519469569677, 2388.1536851052597, 2340.4569161665167, 2259.872287852631, 2200.4845644382117, 2140.5876727191753, 2090.308038876835, 2048.5850715167085, 2009.0837999791977, 1968.4484171971662, 1940.7637457124058, 1897.1222330937285, 1866.0623440212673, 1850.8865422002582, 1810.0502766938976, 1791.0994384087753, 1765.8161091224515, 1746.8168826001242, 1726.1805137386393, 1706.5194979837736, 1681.7086438339704, 1685.5116300648388, 1662.9737907861954, 1949.7263754551489, 1679.4201333574013, 1647.2696796413334, 1624.9743856418627, 1610.1822660591943, 1588.9701986402524, 1579.7433457245195, 1572.1962123753597, 1566.666165954807, 1552.2124118190798, 1549.3227962434619, 1541.2025791844412, 1518.3476748453716, 1516.4532555897845, 1503.1747591021558, 1499.807039177524, 1487.7881308464598, 1493.550842505167, 1472.6802508346616, 1466.5546297412207, 1464.277131614999, 1464.1076537396175, 1461.6332115059247, 1445.007400859807, 1435.0249612278549, 1432.4318578797115, 1429.6059753976915, 1422.2185190362377, 1415.2884575743794, 1407.6562491913116, 1402.2251346091439, 1400.71307311206, 1391.4147464332802, 1418.4387829215825, 1389.2505516339525, 1387.660396365022, 1372.1030166761998, 1377.0745963717675, 1370.7188888387027, 1365.0343929047162, 1355.1327077391852, 1354.3578345587578, 1355.927263983006, 1344.6357397658946, 1346.6984454432816, 1340.3624379382259, 1339.8193612283353, 1330.1516075136135, 1324.6038017163316, 1329.0183266017166, 1327.0866581289993, 1320.2231932963448, 1328.3218784506016, 1317.779918777129], 'acc': [0.8530010669135834, 0.8722503729027776, 0.888156754965092, 0.8996515523569171, 0.9057627131217837, 0.9117648096885711, 0.9163380236056365, 0.9205760395795745, 0.9242729313642192, 0.9270530246109986, 0.9291323423327551, 0.9310829700000497, 0.9327141594605727, 0.9339761935100791, 0.9350241581790545, 0.9361178449238611, 0.9371018046857529, 0.9380406545671742, 0.9387125121478105, 0.9394345924819322, 0.9401131116198207, 0.940754092269822, 0.941421499077068, 0.9420750309049523, 0.9426576809322406, 0.9430465090901372, 0.9433605228822702, 0.9439784980585597, 0.9443617914247817, 0.9448217068362372, 0.9452026087638842, 0.9453430315813985, 0.9458740486997189, 0.9460028558091208, 0.9463602486242768, 0.9419856438611695, 0.9460916292348591, 0.9467457604365294, 0.946976779611003, 0.9473717148133612, 0.9476681626994551, 0.9478953647493904, 0.9479496619560743, 0.9482071987257135, 0.948285308776268, 0.9483976643155975, 0.9486665729017926, 0.9490152610231523, 0.9489886378648481, 0.9491738088846706, 0.9492950996361251, 0.9494342090871111, 0.9494122530633704, 0.9496588717683895, 0.9497982876886958, 0.9499883945590191, 0.9500017074418141, 0.94993228012927, 0.9501903568451598, 0.9503421863436937, 0.9504164762036812, 0.9505790067552922, 0.9506218444964838, 0.9508117359434439, 0.950850739252713, 0.9510073592934689, 0.9510875937071027, 0.9510828369695902, 0.9508144208903992, 0.9512794143510542, 0.9513069032211672, 0.9515156221579074, 0.9514929432975572, 0.9515245225578307, 0.9515689278091409, 0.9516632178858836, 0.9517124121841462, 0.9518024893457144, 0.9518287863493999, 0.9517664568586469, 0.9519541160392194, 0.9520208963353006, 0.9522062116704267, 0.9523207145274031, 0.9521513590334661, 0.9521468911210911, 0.9523595531305351, 0.9523059956933015, 0.9523354500446499], 'mDice': [0.09509395292440075, 0.22005544561134044, 0.3132557963028857, 0.37984828732900877, 0.41786493605683345, 0.4550605262372235, 0.4866070166310772, 0.5172228241891251, 0.5439272674456673, 0.5652138379587689, 0.5825620937105846, 0.5957816204294679, 0.6085400038184992, 0.6192815729620464, 0.6257006407271835, 0.635317349014062, 0.642606379587574, 0.6502227616023261, 0.6566409765846563, 0.6621191883419312, 0.6672676581746215, 0.6725539162292641, 0.6764284898635619, 0.6821727552203267, 0.6864079650927173, 0.688463931747637, 0.6937813237160655, 0.6966887159577254, 0.7000722452752095, 0.702921959212104, 0.7056796034635887, 0.7084064730086256, 0.7118775419046344, 0.7115182613738822, 0.7149560875873825, 0.6783789772600396, 0.712314959566292, 0.7168778881384896, 0.7199966637713915, 0.7221944184686305, 0.7252135991562394, 0.726546870575674, 0.7277476455297883, 0.7285951155938898, 0.7305475011989826, 0.7313200824677297, 0.7322593711251622, 0.7354248067396488, 0.7357901133293125, 0.7376658480957936, 0.7382496351435969, 0.7399553958999994, 0.7391969219929488, 0.7421046693161637, 0.7430018073973952, 0.743510986359877, 0.7435683679915165, 0.7438562309418532, 0.7462450927984025, 0.7476796562042545, 0.7482329532217368, 0.7486268470311596, 0.7497423230785849, 0.7506028123603155, 0.7519545872721648, 0.7526612128265603, 0.7529280796785711, 0.7542781095583967, 0.7505937732661413, 0.7545112294271364, 0.7548241080946985, 0.757120415691022, 0.756547641322119, 0.7573631687057228, 0.75810833738634, 0.7595475171369436, 0.7597810131313449, 0.7596054363253055, 0.761236825260616, 0.7608915906229093, 0.761911157260038, 0.7620338647606788, 0.763499000427976, 0.7642966256208326, 0.7635982137397886, 0.7639798732901161, 0.7649797027995673, 0.7639697590331385, 0.7654235088806063]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:15<00:46, 15.41s/it]predicting test subjects:  50%|█████     | 2/4 [00:28<00:29, 14.69s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:42<00:14, 14.57s/it]predicting test subjects: 100%|██████████| 4/4 [00:56<00:00, 14.37s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:21<1:48:34, 21.01s/it]predicting train subjects:   1%|          | 2/311 [00:31<1:31:12, 17.71s/it]predicting train subjects:   1%|          | 3/311 [00:43<1:23:28, 16.26s/it]predicting train subjects:   1%|▏         | 4/311 [00:56<1:17:03, 15.06s/it]predicting train subjects:   2%|▏         | 5/311 [01:07<1:11:18, 13.98s/it]predicting train subjects:   2%|▏         | 6/311 [01:18<1:06:49, 13.15s/it]predicting train subjects:   2%|▏         | 7/311 [01:32<1:07:36, 13.34s/it]predicting train subjects:   3%|▎         | 8/311 [01:47<1:10:23, 13.94s/it]predicting train subjects:   3%|▎         | 9/311 [02:01<1:09:56, 13.89s/it]predicting train subjects:   3%|▎         | 10/311 [02:12<1:05:44, 13.10s/it]predicting train subjects:   4%|▎         | 11/311 [02:28<1:08:38, 13.73s/it]predicting train subjects:   4%|▍         | 12/311 [02:39<1:05:03, 13.05s/it]predicting train subjects:   4%|▍         | 13/311 [02:51<1:03:14, 12.73s/it]predicting train subjects:   5%|▍         | 14/311 [03:06<1:06:46, 13.49s/it]predicting train subjects:   5%|▍         | 15/311 [03:28<1:18:14, 15.86s/it]predicting train subjects:   5%|▌         | 16/311 [03:49<1:25:46, 17.45s/it]predicting train subjects:   5%|▌         | 17/311 [04:10<1:30:44, 18.52s/it]predicting train subjects:   6%|▌         | 18/311 [04:32<1:35:58, 19.65s/it]predicting train subjects:   6%|▌         | 19/311 [04:53<1:37:34, 20.05s/it]predicting train subjects:   6%|▋         | 20/311 [05:15<1:39:04, 20.43s/it]predicting train subjects:   7%|▋         | 21/311 [05:35<1:39:21, 20.56s/it]predicting train subjects:   7%|▋         | 22/311 [05:57<1:40:03, 20.77s/it]predicting train subjects:   7%|▋         | 23/311 [06:18<1:40:21, 20.91s/it]predicting train subjects:   8%|▊         | 24/311 [06:39<1:40:57, 21.11s/it]predicting train subjects:   8%|▊         | 25/311 [07:01<1:41:08, 21.22s/it]predicting train subjects:   8%|▊         | 26/311 [07:23<1:42:28, 21.57s/it]predicting train subjects:   9%|▊         | 27/311 [07:44<1:40:54, 21.32s/it]predicting train subjects:   9%|▉         | 28/311 [08:06<1:41:50, 21.59s/it]predicting train subjects:   9%|▉         | 29/311 [08:27<1:40:35, 21.40s/it]predicting train subjects:  10%|▉         | 30/311 [08:50<1:41:31, 21.68s/it]predicting train subjects:  10%|▉         | 31/311 [09:11<1:40:18, 21.49s/it]predicting train subjects:  10%|█         | 32/311 [09:33<1:40:51, 21.69s/it]predicting train subjects:  11%|█         | 33/311 [09:43<1:24:21, 18.21s/it]predicting train subjects:  11%|█         | 34/311 [09:53<1:12:19, 15.67s/it]predicting train subjects:  11%|█▏        | 35/311 [10:03<1:04:31, 14.03s/it]predicting train subjects:  12%|█▏        | 36/311 [10:14<1:00:15, 13.15s/it]predicting train subjects:  12%|█▏        | 37/311 [10:24<56:05, 12.28s/it]  predicting train subjects:  12%|█▏        | 38/311 [10:34<52:19, 11.50s/it]predicting train subjects:  13%|█▎        | 39/311 [10:44<50:01, 11.04s/it]predicting train subjects:  13%|█▎        | 40/311 [10:54<48:46, 10.80s/it]predicting train subjects:  13%|█▎        | 41/311 [11:04<47:54, 10.65s/it]predicting train subjects:  14%|█▎        | 42/311 [11:14<46:27, 10.36s/it]predicting train subjects:  14%|█▍        | 43/311 [11:24<45:46, 10.25s/it]predicting train subjects:  14%|█▍        | 44/311 [11:34<45:32, 10.23s/it]predicting train subjects:  14%|█▍        | 45/311 [11:44<44:54, 10.13s/it]predicting train subjects:  15%|█▍        | 46/311 [11:54<44:15, 10.02s/it]predicting train subjects:  15%|█▌        | 47/311 [12:04<44:11, 10.04s/it]predicting train subjects:  15%|█▌        | 48/311 [12:14<44:24, 10.13s/it]predicting train subjects:  16%|█▌        | 49/311 [12:25<44:20, 10.16s/it]predicting train subjects:  16%|█▌        | 50/311 [12:34<43:41, 10.05s/it]predicting train subjects:  16%|█▋        | 51/311 [12:47<47:08, 10.88s/it]predicting train subjects:  17%|█▋        | 52/311 [13:00<49:21, 11.44s/it]predicting train subjects:  17%|█▋        | 53/311 [13:13<51:03, 11.87s/it]predicting train subjects:  17%|█▋        | 54/311 [13:26<52:07, 12.17s/it]predicting train subjects:  18%|█▊        | 55/311 [13:38<52:45, 12.36s/it]predicting train subjects:  18%|█▊        | 56/311 [13:51<52:46, 12.42s/it]predicting train subjects:  18%|█▊        | 57/311 [14:04<52:45, 12.46s/it]predicting train subjects:  19%|█▊        | 58/311 [14:16<52:47, 12.52s/it]predicting train subjects:  19%|█▉        | 59/311 [14:29<52:49, 12.58s/it]predicting train subjects:  19%|█▉        | 60/311 [14:42<53:04, 12.69s/it]predicting train subjects:  20%|█▉        | 61/311 [14:55<52:57, 12.71s/it]predicting train subjects:  20%|█▉        | 62/311 [15:07<52:45, 12.71s/it]predicting train subjects:  20%|██        | 63/311 [15:20<52:49, 12.78s/it]predicting train subjects:  21%|██        | 64/311 [15:33<52:35, 12.77s/it]predicting train subjects:  21%|██        | 65/311 [15:46<52:43, 12.86s/it]predicting train subjects:  21%|██        | 66/311 [15:59<52:20, 12.82s/it]predicting train subjects:  22%|██▏       | 67/311 [16:11<51:24, 12.64s/it]predicting train subjects:  22%|██▏       | 68/311 [16:23<50:47, 12.54s/it]predicting train subjects:  22%|██▏       | 69/311 [16:36<50:10, 12.44s/it]predicting train subjects:  23%|██▎       | 70/311 [16:48<49:59, 12.45s/it]predicting train subjects:  23%|██▎       | 71/311 [17:01<49:59, 12.50s/it]predicting train subjects:  23%|██▎       | 72/311 [17:13<49:47, 12.50s/it]predicting train subjects:  23%|██▎       | 73/311 [17:26<49:24, 12.45s/it]predicting train subjects:  24%|██▍       | 74/311 [17:38<48:53, 12.38s/it]predicting train subjects:  24%|██▍       | 75/311 [17:50<48:27, 12.32s/it]predicting train subjects:  24%|██▍       | 76/311 [18:02<47:58, 12.25s/it]predicting train subjects:  25%|██▍       | 77/311 [18:14<47:56, 12.29s/it]predicting train subjects:  25%|██▌       | 78/311 [18:27<47:50, 12.32s/it]predicting train subjects:  25%|██▌       | 79/311 [18:39<47:40, 12.33s/it]predicting train subjects:  26%|██▌       | 80/311 [18:51<47:30, 12.34s/it]predicting train subjects:  26%|██▌       | 81/311 [19:04<47:07, 12.29s/it]predicting train subjects:  26%|██▋       | 82/311 [19:16<46:42, 12.24s/it]predicting train subjects:  27%|██▋       | 83/311 [19:28<46:21, 12.20s/it]predicting train subjects:  27%|██▋       | 84/311 [19:40<46:20, 12.25s/it]predicting train subjects:  27%|██▋       | 85/311 [19:52<45:08, 11.98s/it]predicting train subjects:  28%|██▊       | 86/311 [20:03<43:44, 11.66s/it]predicting train subjects:  28%|██▊       | 87/311 [20:14<43:05, 11.54s/it]predicting train subjects:  28%|██▊       | 88/311 [20:25<42:42, 11.49s/it]predicting train subjects:  29%|██▊       | 89/311 [20:36<42:20, 11.44s/it]predicting train subjects:  29%|██▉       | 90/311 [20:48<42:07, 11.44s/it]predicting train subjects:  29%|██▉       | 91/311 [20:59<41:28, 11.31s/it]predicting train subjects:  30%|██▉       | 92/311 [21:10<41:06, 11.26s/it]predicting train subjects:  30%|██▉       | 93/311 [21:21<40:56, 11.27s/it]predicting train subjects:  30%|███       | 94/311 [21:33<40:52, 11.30s/it]predicting train subjects:  31%|███       | 95/311 [21:44<40:38, 11.29s/it]predicting train subjects:  31%|███       | 96/311 [21:55<40:08, 11.20s/it]predicting train subjects:  31%|███       | 97/311 [22:06<39:46, 11.15s/it]predicting train subjects:  32%|███▏      | 98/311 [22:17<39:50, 11.22s/it]predicting train subjects:  32%|███▏      | 99/311 [22:29<39:44, 11.25s/it]predicting train subjects:  32%|███▏      | 100/311 [22:41<40:26, 11.50s/it]predicting train subjects:  32%|███▏      | 101/311 [22:52<39:49, 11.38s/it]predicting train subjects:  33%|███▎      | 102/311 [23:03<39:19, 11.29s/it]predicting train subjects:  33%|███▎      | 103/311 [23:14<39:11, 11.31s/it]predicting train subjects:  33%|███▎      | 104/311 [23:27<40:03, 11.61s/it]predicting train subjects:  34%|███▍      | 105/311 [23:38<39:34, 11.53s/it]predicting train subjects:  34%|███▍      | 106/311 [23:49<38:58, 11.41s/it]predicting train subjects:  34%|███▍      | 107/311 [24:00<38:38, 11.37s/it]predicting train subjects:  35%|███▍      | 108/311 [24:12<38:33, 11.40s/it]predicting train subjects:  35%|███▌      | 109/311 [24:23<38:30, 11.44s/it]predicting train subjects:  35%|███▌      | 110/311 [24:35<38:09, 11.39s/it]predicting train subjects:  36%|███▌      | 111/311 [24:46<37:36, 11.28s/it]predicting train subjects:  36%|███▌      | 112/311 [24:58<38:25, 11.59s/it]predicting train subjects:  36%|███▋      | 113/311 [25:10<38:16, 11.60s/it]predicting train subjects:  37%|███▋      | 114/311 [25:31<47:40, 14.52s/it]predicting train subjects:  37%|███▋      | 115/311 [25:52<53:52, 16.49s/it]predicting train subjects:  37%|███▋      | 116/311 [26:13<57:31, 17.70s/it]predicting train subjects:  38%|███▊      | 117/311 [26:34<1:01:11, 18.93s/it]predicting train subjects:  38%|███▊      | 118/311 [26:55<1:02:38, 19.47s/it]predicting train subjects:  38%|███▊      | 119/311 [27:18<1:05:18, 20.41s/it]predicting train subjects:  39%|███▊      | 120/311 [27:39<1:05:39, 20.63s/it]predicting train subjects:  39%|███▉      | 121/311 [28:00<1:05:43, 20.76s/it]predicting train subjects:  39%|███▉      | 122/311 [28:22<1:06:27, 21.10s/it]predicting train subjects:  40%|███▉      | 123/311 [28:43<1:06:03, 21.08s/it]predicting train subjects:  40%|███▉      | 124/311 [29:04<1:05:57, 21.16s/it]predicting train subjects:  40%|████      | 125/311 [29:27<1:06:47, 21.55s/it]predicting train subjects:  41%|████      | 126/311 [29:48<1:06:12, 21.47s/it]predicting train subjects:  41%|████      | 127/311 [30:09<1:05:16, 21.29s/it]predicting train subjects:  41%|████      | 128/311 [30:30<1:04:59, 21.31s/it]predicting train subjects:  41%|████▏     | 129/311 [30:52<1:04:42, 21.33s/it]predicting train subjects:  42%|████▏     | 130/311 [31:13<1:04:14, 21.29s/it]predicting train subjects:  42%|████▏     | 131/311 [31:35<1:04:25, 21.47s/it]predicting train subjects:  42%|████▏     | 132/311 [31:45<53:49, 18.04s/it]  predicting train subjects:  43%|████▎     | 133/311 [31:55<46:40, 15.73s/it]predicting train subjects:  43%|████▎     | 134/311 [32:05<41:01, 13.91s/it]predicting train subjects:  43%|████▎     | 135/311 [32:15<37:21, 12.74s/it]predicting train subjects:  44%|████▎     | 136/311 [32:25<35:01, 12.01s/it]predicting train subjects:  44%|████▍     | 137/311 [32:35<32:55, 11.35s/it]predicting train subjects:  44%|████▍     | 138/311 [32:45<31:42, 11.00s/it]predicting train subjects:  45%|████▍     | 139/311 [32:55<31:04, 10.84s/it]predicting train subjects:  45%|████▌     | 140/311 [33:05<29:53, 10.49s/it]predicting train subjects:  45%|████▌     | 141/311 [33:15<29:33, 10.43s/it]predicting train subjects:  46%|████▌     | 142/311 [33:26<29:20, 10.42s/it]predicting train subjects:  46%|████▌     | 143/311 [33:35<28:25, 10.15s/it]predicting train subjects:  46%|████▋     | 144/311 [33:46<28:29, 10.24s/it]predicting train subjects:  47%|████▋     | 145/311 [33:56<28:40, 10.37s/it]predicting train subjects:  47%|████▋     | 146/311 [34:06<28:02, 10.20s/it]predicting train subjects:  47%|████▋     | 147/311 [34:16<27:48, 10.17s/it]predicting train subjects:  48%|████▊     | 148/311 [34:27<27:59, 10.31s/it]predicting train subjects:  48%|████▊     | 149/311 [34:37<27:25, 10.16s/it]predicting train subjects:  48%|████▊     | 150/311 [34:50<29:22, 10.95s/it]predicting train subjects:  49%|████▊     | 151/311 [35:02<30:41, 11.51s/it]predicting train subjects:  49%|████▉     | 152/311 [35:15<31:39, 11.95s/it]predicting train subjects:  49%|████▉     | 153/311 [35:28<32:08, 12.21s/it]predicting train subjects:  50%|████▉     | 154/311 [35:41<32:24, 12.39s/it]predicting train subjects:  50%|████▉     | 155/311 [35:54<32:26, 12.47s/it]predicting train subjects:  50%|█████     | 156/311 [36:06<32:29, 12.57s/it]predicting train subjects:  50%|█████     | 157/311 [36:19<32:25, 12.63s/it]predicting train subjects:  51%|█████     | 158/311 [36:32<32:29, 12.74s/it]predicting train subjects:  51%|█████     | 159/311 [36:45<32:16, 12.74s/it]predicting train subjects:  51%|█████▏    | 160/311 [36:58<32:03, 12.74s/it]predicting train subjects:  52%|█████▏    | 161/311 [37:10<31:51, 12.74s/it]predicting train subjects:  52%|█████▏    | 162/311 [37:24<32:15, 12.99s/it]predicting train subjects:  52%|█████▏    | 163/311 [37:37<31:56, 12.95s/it]predicting train subjects:  53%|█████▎    | 164/311 [37:50<31:37, 12.91s/it]predicting train subjects:  53%|█████▎    | 165/311 [38:03<31:46, 13.06s/it]predicting train subjects:  53%|█████▎    | 166/311 [38:16<31:16, 12.94s/it]predicting train subjects:  54%|█████▎    | 167/311 [38:28<30:46, 12.82s/it]predicting train subjects:  54%|█████▍    | 168/311 [38:41<30:17, 12.71s/it]predicting train subjects:  54%|█████▍    | 169/311 [38:54<30:16, 12.79s/it]predicting train subjects:  55%|█████▍    | 170/311 [39:06<29:38, 12.61s/it]predicting train subjects:  55%|█████▍    | 171/311 [39:18<29:05, 12.47s/it]predicting train subjects:  55%|█████▌    | 172/311 [39:30<28:41, 12.39s/it]predicting train subjects:  56%|█████▌    | 173/311 [39:43<28:38, 12.45s/it]predicting train subjects:  56%|█████▌    | 174/311 [39:55<28:32, 12.50s/it]predicting train subjects:  56%|█████▋    | 175/311 [40:08<28:33, 12.60s/it]predicting train subjects:  57%|█████▋    | 176/311 [40:22<28:47, 12.79s/it]predicting train subjects:  57%|█████▋    | 177/311 [40:34<28:11, 12.62s/it]predicting train subjects:  57%|█████▋    | 178/311 [40:46<27:30, 12.41s/it]predicting train subjects:  58%|█████▊    | 179/311 [40:58<27:12, 12.37s/it]predicting train subjects:  58%|█████▊    | 180/311 [41:10<27:03, 12.39s/it]predicting train subjects:  58%|█████▊    | 181/311 [41:23<26:50, 12.39s/it]predicting train subjects:  59%|█████▊    | 182/311 [41:35<26:26, 12.30s/it]predicting train subjects:  59%|█████▉    | 183/311 [41:48<26:33, 12.45s/it]predicting train subjects:  59%|█████▉    | 184/311 [41:59<25:41, 12.14s/it]predicting train subjects:  59%|█████▉    | 185/311 [42:11<25:01, 11.92s/it]predicting train subjects:  60%|█████▉    | 186/311 [42:22<24:32, 11.78s/it]predicting train subjects:  60%|██████    | 187/311 [42:33<24:09, 11.69s/it]predicting train subjects:  60%|██████    | 188/311 [42:44<23:31, 11.48s/it]predicting train subjects:  61%|██████    | 189/311 [42:56<23:13, 11.42s/it]predicting train subjects:  61%|██████    | 190/311 [43:07<23:03, 11.43s/it]predicting train subjects:  61%|██████▏   | 191/311 [43:19<23:12, 11.61s/it]predicting train subjects:  62%|██████▏   | 192/311 [43:30<22:50, 11.52s/it]predicting train subjects:  62%|██████▏   | 193/311 [43:41<22:19, 11.35s/it]predicting train subjects:  62%|██████▏   | 194/311 [43:53<22:18, 11.44s/it]predicting train subjects:  63%|██████▎   | 195/311 [44:04<22:03, 11.41s/it]predicting train subjects:  63%|██████▎   | 196/311 [44:16<21:48, 11.38s/it]predicting train subjects:  63%|██████▎   | 197/311 [44:27<21:23, 11.25s/it]predicting train subjects:  64%|██████▎   | 198/311 [44:38<21:08, 11.22s/it]predicting train subjects:  64%|██████▍   | 199/311 [44:50<21:11, 11.35s/it]predicting train subjects:  64%|██████▍   | 200/311 [45:01<20:59, 11.35s/it]predicting train subjects:  65%|██████▍   | 201/311 [45:12<20:51, 11.38s/it]predicting train subjects:  65%|██████▍   | 202/311 [45:23<20:26, 11.25s/it]predicting train subjects:  65%|██████▌   | 203/311 [45:34<20:11, 11.22s/it]predicting train subjects:  66%|██████▌   | 204/311 [45:46<20:11, 11.33s/it]predicting train subjects:  66%|██████▌   | 205/311 [45:58<20:08, 11.40s/it]predicting train subjects:  66%|██████▌   | 206/311 [46:10<20:27, 11.69s/it]predicting train subjects:  67%|██████▋   | 207/311 [46:21<20:08, 11.62s/it]predicting train subjects:  67%|██████▋   | 208/311 [46:33<19:43, 11.49s/it]predicting train subjects:  67%|██████▋   | 209/311 [46:44<19:25, 11.42s/it]predicting train subjects:  68%|██████▊   | 210/311 [46:55<19:15, 11.44s/it]predicting train subjects:  68%|██████▊   | 211/311 [47:07<19:07, 11.47s/it]predicting train subjects:  68%|██████▊   | 212/311 [47:18<18:51, 11.43s/it]predicting train subjects:  68%|██████▊   | 213/311 [47:40<23:48, 14.57s/it]predicting train subjects:  69%|██████▉   | 214/311 [48:01<26:48, 16.59s/it]predicting train subjects:  69%|██████▉   | 215/311 [48:23<28:55, 18.08s/it]predicting train subjects:  69%|██████▉   | 216/311 [48:44<29:58, 18.93s/it]predicting train subjects:  70%|██████▉   | 217/311 [49:06<31:13, 19.93s/it]predicting train subjects:  70%|███████   | 218/311 [49:27<31:28, 20.30s/it]predicting train subjects:  70%|███████   | 219/311 [49:49<31:50, 20.76s/it]predicting train subjects:  71%|███████   | 220/311 [50:10<31:32, 20.80s/it]predicting train subjects:  71%|███████   | 221/311 [50:33<31:57, 21.30s/it]predicting train subjects:  71%|███████▏  | 222/311 [50:53<31:24, 21.17s/it]predicting train subjects:  72%|███████▏  | 223/311 [51:15<31:18, 21.35s/it]predicting train subjects:  72%|███████▏  | 224/311 [51:36<30:47, 21.24s/it]predicting train subjects:  72%|███████▏  | 225/311 [51:58<30:37, 21.37s/it]predicting train subjects:  73%|███████▎  | 226/311 [52:19<30:04, 21.22s/it]predicting train subjects:  73%|███████▎  | 227/311 [52:40<29:52, 21.34s/it]predicting train subjects:  73%|███████▎  | 228/311 [53:02<29:32, 21.35s/it]predicting train subjects:  74%|███████▎  | 229/311 [53:23<29:07, 21.30s/it]predicting train subjects:  74%|███████▍  | 230/311 [53:44<28:46, 21.31s/it]predicting train subjects:  74%|███████▍  | 231/311 [53:54<23:59, 17.99s/it]predicting train subjects:  75%|███████▍  | 232/311 [54:04<20:26, 15.53s/it]predicting train subjects:  75%|███████▍  | 233/311 [54:14<18:01, 13.87s/it]predicting train subjects:  75%|███████▌  | 234/311 [54:25<16:31, 12.88s/it]predicting train subjects:  76%|███████▌  | 235/311 [54:35<15:07, 11.94s/it]predicting train subjects:  76%|███████▌  | 236/311 [54:45<14:15, 11.41s/it]predicting train subjects:  76%|███████▌  | 237/311 [54:55<13:44, 11.14s/it]predicting train subjects:  77%|███████▋  | 238/311 [55:05<13:11, 10.84s/it]predicting train subjects:  77%|███████▋  | 239/311 [55:15<12:36, 10.51s/it]predicting train subjects:  77%|███████▋  | 240/311 [55:25<12:22, 10.46s/it]predicting train subjects:  77%|███████▋  | 241/311 [55:36<12:08, 10.41s/it]predicting train subjects:  78%|███████▊  | 242/311 [55:45<11:42, 10.18s/it]predicting train subjects:  78%|███████▊  | 243/311 [55:56<11:40, 10.30s/it]predicting train subjects:  78%|███████▊  | 244/311 [56:06<11:27, 10.26s/it]predicting train subjects:  79%|███████▉  | 245/311 [56:16<11:08, 10.12s/it]predicting train subjects:  79%|███████▉  | 246/311 [56:26<11:02, 10.19s/it]predicting train subjects:  79%|███████▉  | 247/311 [56:37<11:00, 10.33s/it]predicting train subjects:  80%|███████▉  | 248/311 [56:47<10:44, 10.23s/it]predicting train subjects:  80%|████████  | 249/311 [57:00<11:18, 10.94s/it]predicting train subjects:  80%|████████  | 250/311 [57:12<11:42, 11.51s/it]predicting train subjects:  81%|████████  | 251/311 [57:25<11:56, 11.94s/it]predicting train subjects:  81%|████████  | 252/311 [57:38<12:04, 12.28s/it]predicting train subjects:  81%|████████▏ | 253/311 [57:51<12:05, 12.50s/it]predicting train subjects:  82%|████████▏ | 254/311 [58:05<12:13, 12.87s/it]predicting train subjects:  82%|████████▏ | 255/311 [58:18<12:01, 12.88s/it]predicting train subjects:  82%|████████▏ | 256/311 [58:31<11:48, 12.89s/it]predicting train subjects:  83%|████████▎ | 257/311 [58:44<11:38, 12.93s/it]predicting train subjects:  83%|████████▎ | 258/311 [58:57<11:22, 12.88s/it]predicting train subjects:  83%|████████▎ | 259/311 [59:09<11:06, 12.83s/it]predicting train subjects:  84%|████████▎ | 260/311 [59:23<10:58, 12.90s/it]predicting train subjects:  84%|████████▍ | 261/311 [59:35<10:43, 12.86s/it]predicting train subjects:  84%|████████▍ | 262/311 [59:48<10:34, 12.95s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:00:01<10:20, 12.93s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:00:14<10:08, 12.94s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:00:27<09:47, 12.78s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:00:39<09:28, 12.63s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:00:51<09:08, 12.46s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:01:03<08:55, 12.46s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:01:16<08:42, 12.43s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:01:28<08:29, 12.43s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:01:41<08:20, 12.52s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:01:53<08:04, 12.43s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:02:05<07:50, 12.37s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:02:18<07:39, 12.42s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:02:31<07:28, 12.47s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:02:43<07:16, 12.47s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:02:55<07:00, 12.38s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:03:07<06:45, 12.29s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:03:20<06:33, 12.29s/it]predicting train subjects:  90%|█████████ | 280/311 [1:03:32<06:22, 12.34s/it]predicting train subjects:  90%|█████████ | 281/311 [1:03:44<06:11, 12.37s/it]predicting train subjects:  91%|█████████ | 282/311 [1:03:57<05:57, 12.34s/it]predicting train subjects:  91%|█████████ | 283/311 [1:04:08<05:33, 11.92s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:04:19<05:16, 11.72s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:04:30<05:01, 11.61s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:04:41<04:45, 11.43s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:04:53<04:32, 11.36s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:05:04<04:20, 11.32s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:05:15<04:09, 11.33s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:05:26<03:55, 11.22s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:05:37<03:43, 11.15s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:05:48<03:32, 11.19s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:06:00<03:22, 11.28s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:06:11<03:10, 11.18s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:06:22<03:00, 11.25s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:06:34<02:49, 11.33s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:06:45<02:40, 11.46s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:06:57<02:28, 11.44s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:07:08<02:16, 11.36s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:07:20<02:06, 11.47s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:07:32<01:56, 11.60s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:07:43<01:44, 11.67s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:07:55<01:32, 11.60s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:08:06<01:20, 11.55s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:08:18<01:09, 11.59s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:08:30<00:58, 11.64s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:08:41<00:46, 11.51s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:08:52<00:34, 11.44s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:09:04<00:23, 11.53s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:09:16<00:11, 11.67s/it]predicting train subjects: 100%|██████████| 311/311 [1:09:27<00:00, 11.58s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:29:11, 17.26s/it]Loading train:   1%|          | 2/311 [00:25<1:15:28, 14.66s/it]Loading train:   1%|          | 3/311 [00:36<1:09:21, 13.51s/it]Loading train:   1%|▏         | 4/311 [00:47<1:04:14, 12.56s/it]Loading train:   2%|▏         | 5/311 [00:56<59:21, 11.64s/it]  Loading train:   2%|▏         | 6/311 [01:06<55:59, 11.02s/it]Loading train:   2%|▏         | 7/311 [01:17<55:42, 10.99s/it]Loading train:   3%|▎         | 8/311 [01:29<58:00, 11.49s/it]Loading train:   3%|▎         | 9/311 [01:41<58:00, 11.52s/it]Loading train:   3%|▎         | 10/311 [01:50<54:59, 10.96s/it]Loading train:   4%|▎         | 11/311 [02:03<57:32, 11.51s/it]Loading train:   4%|▍         | 12/311 [02:13<55:02, 11.04s/it]Loading train:   4%|▍         | 13/311 [02:23<52:57, 10.66s/it]Loading train:   5%|▍         | 14/311 [02:36<55:49, 11.28s/it]Loading train:   5%|▍         | 15/311 [02:45<53:12, 10.78s/it]Loading train:   5%|▌         | 16/311 [02:55<51:01, 10.38s/it]Loading train:   5%|▌         | 17/311 [03:04<49:17, 10.06s/it]Loading train:   6%|▌         | 18/311 [03:13<48:04,  9.85s/it]Loading train:   6%|▌         | 19/311 [03:23<47:02,  9.67s/it]Loading train:   6%|▋         | 20/311 [03:32<46:19,  9.55s/it]Loading train:   7%|▋         | 21/311 [03:41<45:47,  9.47s/it]Loading train:   7%|▋         | 22/311 [03:51<45:36,  9.47s/it]Loading train:   7%|▋         | 23/311 [04:00<45:17,  9.44s/it]Loading train:   8%|▊         | 24/311 [04:10<45:25,  9.50s/it]Loading train:   8%|▊         | 25/311 [04:19<44:43,  9.38s/it]Loading train:   8%|▊         | 26/311 [04:28<44:18,  9.33s/it]Loading train:   9%|▊         | 27/311 [04:37<43:58,  9.29s/it]Loading train:   9%|▉         | 28/311 [04:47<43:56,  9.32s/it]Loading train:   9%|▉         | 29/311 [04:56<44:19,  9.43s/it]Loading train:  10%|▉         | 30/311 [05:06<44:25,  9.48s/it]Loading train:  10%|▉         | 31/311 [05:15<44:13,  9.48s/it]Loading train:  10%|█         | 32/311 [05:25<43:56,  9.45s/it]Loading train:  11%|█         | 33/311 [05:30<37:25,  8.08s/it]Loading train:  11%|█         | 34/311 [05:35<33:18,  7.21s/it]Loading train:  11%|█▏        | 35/311 [05:40<30:18,  6.59s/it]Loading train:  12%|█▏        | 36/311 [05:45<28:03,  6.12s/it]Loading train:  12%|█▏        | 37/311 [05:50<26:47,  5.87s/it]Loading train:  12%|█▏        | 38/311 [05:55<25:45,  5.66s/it]Loading train:  13%|█▎        | 39/311 [06:01<25:00,  5.52s/it]Loading train:  13%|█▎        | 40/311 [06:06<24:30,  5.43s/it]Loading train:  13%|█▎        | 41/311 [06:11<24:14,  5.39s/it]Loading train:  14%|█▎        | 42/311 [06:16<23:41,  5.29s/it]Loading train:  14%|█▍        | 43/311 [06:21<23:33,  5.27s/it]Loading train:  14%|█▍        | 44/311 [06:26<23:11,  5.21s/it]Loading train:  14%|█▍        | 45/311 [06:32<23:02,  5.20s/it]Loading train:  15%|█▍        | 46/311 [06:37<22:52,  5.18s/it]Loading train:  15%|█▌        | 47/311 [06:42<22:30,  5.12s/it]Loading train:  15%|█▌        | 48/311 [06:47<22:05,  5.04s/it]Loading train:  16%|█▌        | 49/311 [06:51<21:52,  5.01s/it]Loading train:  16%|█▌        | 50/311 [06:56<21:46,  5.00s/it]Loading train:  16%|█▋        | 51/311 [07:03<23:35,  5.45s/it]Loading train:  17%|█▋        | 52/311 [07:09<24:16,  5.62s/it]Loading train:  17%|█▋        | 53/311 [07:15<24:52,  5.79s/it]Loading train:  17%|█▋        | 54/311 [07:21<25:12,  5.89s/it]Loading train:  18%|█▊        | 55/311 [07:28<25:44,  6.03s/it]Loading train:  18%|█▊        | 56/311 [07:34<26:07,  6.15s/it]Loading train:  18%|█▊        | 57/311 [07:40<25:50,  6.10s/it]Loading train:  19%|█▊        | 58/311 [07:46<25:56,  6.15s/it]Loading train:  19%|█▉        | 59/311 [07:53<25:57,  6.18s/it]Loading train:  19%|█▉        | 60/311 [07:59<26:11,  6.26s/it]Loading train:  20%|█▉        | 61/311 [08:05<25:55,  6.22s/it]Loading train:  20%|█▉        | 62/311 [08:11<25:49,  6.22s/it]Loading train:  20%|██        | 63/311 [08:18<25:47,  6.24s/it]Loading train:  21%|██        | 64/311 [08:24<25:36,  6.22s/it]Loading train:  21%|██        | 65/311 [08:30<25:42,  6.27s/it]Loading train:  21%|██        | 66/311 [08:37<25:39,  6.28s/it]Loading train:  22%|██▏       | 67/311 [08:43<25:21,  6.24s/it]Loading train:  22%|██▏       | 68/311 [08:49<25:08,  6.21s/it]Loading train:  22%|██▏       | 69/311 [08:55<25:15,  6.26s/it]Loading train:  23%|██▎       | 70/311 [09:01<25:07,  6.26s/it]Loading train:  23%|██▎       | 71/311 [09:07<24:44,  6.19s/it]Loading train:  23%|██▎       | 72/311 [09:14<24:29,  6.15s/it]Loading train:  23%|██▎       | 73/311 [09:20<24:30,  6.18s/it]Loading train:  24%|██▍       | 74/311 [09:26<24:08,  6.11s/it]Loading train:  24%|██▍       | 75/311 [09:32<23:47,  6.05s/it]Loading train:  24%|██▍       | 76/311 [09:38<23:59,  6.13s/it]Loading train:  25%|██▍       | 77/311 [09:44<23:48,  6.11s/it]Loading train:  25%|██▌       | 78/311 [09:50<23:31,  6.06s/it]Loading train:  25%|██▌       | 79/311 [09:56<23:07,  5.98s/it]Loading train:  26%|██▌       | 80/311 [10:02<23:00,  5.97s/it]Loading train:  26%|██▌       | 81/311 [10:08<22:48,  5.95s/it]Loading train:  26%|██▋       | 82/311 [10:13<22:38,  5.93s/it]Loading train:  27%|██▋       | 83/311 [10:19<22:31,  5.93s/it]Loading train:  27%|██▋       | 84/311 [10:25<22:22,  5.91s/it]Loading train:  27%|██▋       | 85/311 [10:31<21:43,  5.77s/it]Loading train:  28%|██▊       | 86/311 [10:36<21:27,  5.72s/it]Loading train:  28%|██▊       | 87/311 [10:42<21:01,  5.63s/it]Loading train:  28%|██▊       | 88/311 [10:48<21:06,  5.68s/it]Loading train:  29%|██▊       | 89/311 [10:53<20:57,  5.67s/it]Loading train:  29%|██▉       | 90/311 [10:59<20:37,  5.60s/it]Loading train:  29%|██▉       | 91/311 [11:04<20:41,  5.64s/it]Loading train:  30%|██▉       | 92/311 [11:10<20:30,  5.62s/it]Loading train:  30%|██▉       | 93/311 [11:15<20:12,  5.56s/it]Loading train:  30%|███       | 94/311 [11:21<20:00,  5.53s/it]Loading train:  31%|███       | 95/311 [11:26<19:53,  5.52s/it]Loading train:  31%|███       | 96/311 [11:32<19:43,  5.51s/it]Loading train:  31%|███       | 97/311 [11:37<19:28,  5.46s/it]Loading train:  32%|███▏      | 98/311 [11:42<19:15,  5.42s/it]Loading train:  32%|███▏      | 99/311 [11:48<19:09,  5.42s/it]Loading train:  32%|███▏      | 100/311 [11:53<19:10,  5.45s/it]Loading train:  32%|███▏      | 101/311 [11:59<19:26,  5.55s/it]Loading train:  33%|███▎      | 102/311 [12:05<19:42,  5.66s/it]Loading train:  33%|███▎      | 103/311 [12:11<19:19,  5.58s/it]Loading train:  33%|███▎      | 104/311 [12:16<19:02,  5.52s/it]Loading train:  34%|███▍      | 105/311 [12:21<19:01,  5.54s/it]Loading train:  34%|███▍      | 106/311 [12:27<18:45,  5.49s/it]Loading train:  34%|███▍      | 107/311 [12:33<18:52,  5.55s/it]Loading train:  35%|███▍      | 108/311 [12:38<18:57,  5.60s/it]Loading train:  35%|███▌      | 109/311 [12:44<18:59,  5.64s/it]Loading train:  35%|███▌      | 110/311 [12:49<18:43,  5.59s/it]Loading train:  36%|███▌      | 111/311 [12:55<18:16,  5.48s/it]Loading train:  36%|███▌      | 112/311 [13:00<17:55,  5.40s/it]Loading train:  36%|███▋      | 113/311 [13:06<18:22,  5.57s/it]Loading train:  37%|███▋      | 114/311 [13:16<22:25,  6.83s/it]Loading train:  37%|███▋      | 115/311 [13:26<25:30,  7.81s/it]Loading train:  37%|███▋      | 116/311 [13:36<27:40,  8.52s/it]Loading train:  38%|███▊      | 117/311 [13:46<29:08,  9.01s/it]Loading train:  38%|███▊      | 118/311 [13:56<29:36,  9.21s/it]Loading train:  38%|███▊      | 119/311 [14:06<30:17,  9.47s/it]Loading train:  39%|███▊      | 120/311 [14:16<30:35,  9.61s/it]Loading train:  39%|███▉      | 121/311 [14:25<30:16,  9.56s/it]Loading train:  39%|███▉      | 122/311 [14:34<29:18,  9.30s/it]Loading train:  40%|███▉      | 123/311 [14:43<28:52,  9.22s/it]Loading train:  40%|███▉      | 124/311 [14:52<28:45,  9.22s/it]Loading train:  40%|████      | 125/311 [15:02<28:42,  9.26s/it]Loading train:  41%|████      | 126/311 [15:11<28:31,  9.25s/it]Loading train:  41%|████      | 127/311 [15:20<28:26,  9.28s/it]Loading train:  41%|████      | 128/311 [15:29<27:55,  9.16s/it]Loading train:  41%|████▏     | 129/311 [15:38<27:23,  9.03s/it]Loading train:  42%|████▏     | 130/311 [15:47<27:08,  9.00s/it]Loading train:  42%|████▏     | 131/311 [15:57<28:15,  9.42s/it]Loading train:  42%|████▏     | 132/311 [16:03<24:58,  8.37s/it]Loading train:  43%|████▎     | 133/311 [16:09<22:26,  7.56s/it]Loading train:  43%|████▎     | 134/311 [16:14<20:43,  7.03s/it]Loading train:  43%|████▎     | 135/311 [16:20<19:29,  6.64s/it]Loading train:  44%|████▎     | 136/311 [16:26<18:29,  6.34s/it]Loading train:  44%|████▍     | 137/311 [16:32<18:29,  6.37s/it]Loading train:  44%|████▍     | 138/311 [16:38<17:38,  6.12s/it]Loading train:  45%|████▍     | 139/311 [16:44<17:19,  6.04s/it]Loading train:  45%|████▌     | 140/311 [16:49<17:04,  5.99s/it]Loading train:  45%|████▌     | 141/311 [16:55<16:36,  5.86s/it]Loading train:  46%|████▌     | 142/311 [17:01<16:32,  5.88s/it]Loading train:  46%|████▌     | 143/311 [17:06<16:03,  5.74s/it]Loading train:  46%|████▋     | 144/311 [17:12<15:51,  5.70s/it]Loading train:  47%|████▋     | 145/311 [17:18<16:00,  5.79s/it]Loading train:  47%|████▋     | 146/311 [17:24<15:57,  5.80s/it]Loading train:  47%|████▋     | 147/311 [17:29<15:37,  5.72s/it]Loading train:  48%|████▊     | 148/311 [17:35<15:31,  5.72s/it]Loading train:  48%|████▊     | 149/311 [17:41<15:19,  5.68s/it]Loading train:  48%|████▊     | 150/311 [17:48<16:33,  6.17s/it]Loading train:  49%|████▊     | 151/311 [17:55<17:09,  6.44s/it]Loading train:  49%|████▉     | 152/311 [18:02<17:27,  6.59s/it]Loading train:  49%|████▉     | 153/311 [18:09<17:59,  6.83s/it]Loading train:  50%|████▉     | 154/311 [18:16<17:44,  6.78s/it]Loading train:  50%|████▉     | 155/311 [18:23<17:40,  6.80s/it]Loading train:  50%|█████     | 156/311 [18:30<17:40,  6.84s/it]Loading train:  50%|█████     | 157/311 [18:37<17:48,  6.94s/it]Loading train:  51%|█████     | 158/311 [18:44<17:27,  6.85s/it]Loading train:  51%|█████     | 159/311 [18:51<17:34,  6.94s/it]Loading train:  51%|█████▏    | 160/311 [18:58<17:42,  7.04s/it]Loading train:  52%|█████▏    | 161/311 [19:05<17:26,  6.98s/it]Loading train:  52%|█████▏    | 162/311 [19:12<17:09,  6.91s/it]Loading train:  52%|█████▏    | 163/311 [19:19<17:12,  6.98s/it]Loading train:  53%|█████▎    | 164/311 [19:26<17:06,  6.98s/it]Loading train:  53%|█████▎    | 165/311 [19:33<17:20,  7.13s/it]Loading train:  53%|█████▎    | 166/311 [19:40<17:19,  7.17s/it]Loading train:  54%|█████▎    | 167/311 [19:47<17:00,  7.08s/it]Loading train:  54%|█████▍    | 168/311 [19:55<17:10,  7.21s/it]Loading train:  54%|█████▍    | 169/311 [20:01<16:30,  6.97s/it]Loading train:  55%|█████▍    | 170/311 [20:08<16:33,  7.04s/it]Loading train:  55%|█████▍    | 171/311 [20:15<16:10,  6.94s/it]Loading train:  55%|█████▌    | 172/311 [20:22<16:08,  6.97s/it]Loading train:  56%|█████▌    | 173/311 [20:29<15:37,  6.79s/it]Loading train:  56%|█████▌    | 174/311 [20:36<15:41,  6.87s/it]Loading train:  56%|█████▋    | 175/311 [20:42<15:21,  6.78s/it]Loading train:  57%|█████▋    | 176/311 [20:49<15:23,  6.84s/it]Loading train:  57%|█████▋    | 177/311 [20:56<15:15,  6.83s/it]Loading train:  57%|█████▋    | 178/311 [21:03<15:10,  6.85s/it]Loading train:  58%|█████▊    | 179/311 [21:10<15:03,  6.84s/it]Loading train:  58%|█████▊    | 180/311 [21:17<15:07,  6.92s/it]Loading train:  58%|█████▊    | 181/311 [21:23<14:47,  6.82s/it]Loading train:  59%|█████▊    | 182/311 [21:30<14:47,  6.88s/it]Loading train:  59%|█████▉    | 183/311 [21:37<14:21,  6.73s/it]Loading train:  59%|█████▉    | 184/311 [21:44<14:13,  6.72s/it]Loading train:  59%|█████▉    | 185/311 [21:50<13:52,  6.61s/it]Loading train:  60%|█████▉    | 186/311 [21:57<13:47,  6.62s/it]Loading train:  60%|██████    | 187/311 [22:03<13:42,  6.63s/it]Loading train:  60%|██████    | 188/311 [22:10<13:31,  6.59s/it]Loading train:  61%|██████    | 189/311 [22:16<13:01,  6.41s/it]Loading train:  61%|██████    | 190/311 [22:22<13:05,  6.49s/it]Loading train:  61%|██████▏   | 191/311 [22:29<12:53,  6.45s/it]Loading train:  62%|██████▏   | 192/311 [22:35<12:49,  6.46s/it]Loading train:  62%|██████▏   | 193/311 [22:41<12:35,  6.40s/it]Loading train:  62%|██████▏   | 194/311 [22:48<12:48,  6.57s/it]Loading train:  63%|██████▎   | 195/311 [22:55<12:32,  6.49s/it]Loading train:  63%|██████▎   | 196/311 [23:01<12:29,  6.52s/it]Loading train:  63%|██████▎   | 197/311 [23:07<12:10,  6.41s/it]Loading train:  64%|██████▎   | 198/311 [23:14<12:07,  6.43s/it]Loading train:  64%|██████▍   | 199/311 [23:20<11:55,  6.38s/it]Loading train:  64%|██████▍   | 200/311 [23:27<12:08,  6.57s/it]Loading train:  65%|██████▍   | 201/311 [23:34<11:59,  6.54s/it]Loading train:  65%|██████▍   | 202/311 [23:41<12:02,  6.63s/it]Loading train:  65%|██████▌   | 203/311 [23:47<11:41,  6.50s/it]Loading train:  66%|██████▌   | 204/311 [23:53<11:33,  6.48s/it]Loading train:  66%|██████▌   | 205/311 [23:59<11:18,  6.40s/it]Loading train:  66%|██████▌   | 206/311 [24:06<11:05,  6.33s/it]Loading train:  67%|██████▋   | 207/311 [24:12<10:47,  6.23s/it]Loading train:  67%|██████▋   | 208/311 [24:18<10:39,  6.21s/it]Loading train:  67%|██████▋   | 209/311 [24:24<10:39,  6.27s/it]Loading train:  68%|██████▊   | 210/311 [24:30<10:33,  6.27s/it]Loading train:  68%|██████▊   | 211/311 [24:37<10:38,  6.39s/it]Loading train:  68%|██████▊   | 212/311 [24:43<10:29,  6.36s/it]Loading train:  68%|██████▊   | 213/311 [24:54<12:44,  7.80s/it]Loading train:  69%|██████▉   | 214/311 [25:05<13:58,  8.64s/it]Loading train:  69%|██████▉   | 215/311 [25:16<14:58,  9.36s/it]Loading train:  69%|██████▉   | 216/311 [25:29<16:15, 10.27s/it]Loading train:  70%|██████▉   | 217/311 [25:42<17:46, 11.34s/it]Loading train:  70%|███████   | 218/311 [25:55<18:04, 11.67s/it]Loading train:  70%|███████   | 219/311 [26:08<18:49, 12.28s/it]Loading train:  71%|███████   | 220/311 [26:20<18:23, 12.12s/it]Loading train:  71%|███████   | 221/311 [26:33<18:32, 12.36s/it]Loading train:  71%|███████▏  | 222/311 [26:43<17:23, 11.72s/it]Loading train:  72%|███████▏  | 223/311 [26:53<16:12, 11.05s/it]Loading train:  72%|███████▏  | 224/311 [27:03<15:27, 10.66s/it]Loading train:  72%|███████▏  | 225/311 [27:12<14:48, 10.33s/it]Loading train:  73%|███████▎  | 226/311 [27:23<14:38, 10.33s/it]Loading train:  73%|███████▎  | 227/311 [27:32<14:15, 10.19s/it]Loading train:  73%|███████▎  | 228/311 [27:42<13:43,  9.92s/it]Loading train:  74%|███████▎  | 229/311 [27:52<13:32,  9.91s/it]Loading train:  74%|███████▍  | 230/311 [28:01<13:11,  9.77s/it]Loading train:  74%|███████▍  | 231/311 [28:06<11:09,  8.37s/it]Loading train:  75%|███████▍  | 232/311 [28:11<09:40,  7.35s/it]Loading train:  75%|███████▍  | 233/311 [28:16<08:34,  6.59s/it]Loading train:  75%|███████▌  | 234/311 [28:21<07:56,  6.18s/it]Loading train:  76%|███████▌  | 235/311 [28:27<07:32,  5.95s/it]Loading train:  76%|███████▌  | 236/311 [28:31<07:00,  5.61s/it]Loading train:  76%|███████▌  | 237/311 [28:36<06:38,  5.39s/it]Loading train:  77%|███████▋  | 238/311 [28:41<06:28,  5.32s/it]Loading train:  77%|███████▋  | 239/311 [28:46<06:12,  5.17s/it]Loading train:  77%|███████▋  | 240/311 [28:51<05:58,  5.05s/it]Loading train:  77%|███████▋  | 241/311 [28:56<05:51,  5.02s/it]Loading train:  78%|███████▊  | 242/311 [29:01<05:47,  5.03s/it]Loading train:  78%|███████▊  | 243/311 [29:06<05:41,  5.02s/it]Loading train:  78%|███████▊  | 244/311 [29:11<05:29,  4.92s/it]Loading train:  79%|███████▉  | 245/311 [29:16<05:28,  4.98s/it]Loading train:  79%|███████▉  | 246/311 [29:21<05:23,  4.97s/it]Loading train:  79%|███████▉  | 247/311 [29:25<05:10,  4.86s/it]Loading train:  80%|███████▉  | 248/311 [29:30<05:07,  4.88s/it]Loading train:  80%|████████  | 249/311 [29:36<05:27,  5.29s/it]Loading train:  80%|████████  | 250/311 [29:42<05:32,  5.44s/it]Loading train:  81%|████████  | 251/311 [29:49<05:40,  5.67s/it]Loading train:  81%|████████  | 252/311 [29:54<05:38,  5.73s/it]Loading train:  81%|████████▏ | 253/311 [30:00<05:31,  5.72s/it]Loading train:  82%|████████▏ | 254/311 [30:06<05:36,  5.91s/it]Loading train:  82%|████████▏ | 255/311 [30:12<05:29,  5.88s/it]Loading train:  82%|████████▏ | 256/311 [30:18<05:24,  5.90s/it]Loading train:  83%|████████▎ | 257/311 [30:25<05:29,  6.10s/it]Loading train:  83%|████████▎ | 258/311 [30:30<05:17,  5.99s/it]Loading train:  83%|████████▎ | 259/311 [30:36<05:08,  5.94s/it]Loading train:  84%|████████▎ | 260/311 [30:42<05:05,  5.99s/it]Loading train:  84%|████████▍ | 261/311 [30:48<04:56,  5.93s/it]Loading train:  84%|████████▍ | 262/311 [30:54<04:51,  5.96s/it]Loading train:  85%|████████▍ | 263/311 [31:00<04:48,  6.00s/it]Loading train:  85%|████████▍ | 264/311 [31:06<04:42,  6.01s/it]Loading train:  85%|████████▌ | 265/311 [31:12<04:33,  5.94s/it]Loading train:  86%|████████▌ | 266/311 [31:18<04:27,  5.94s/it]Loading train:  86%|████████▌ | 267/311 [31:24<04:17,  5.86s/it]Loading train:  86%|████████▌ | 268/311 [31:30<04:12,  5.88s/it]Loading train:  86%|████████▋ | 269/311 [31:35<04:05,  5.84s/it]Loading train:  87%|████████▋ | 270/311 [31:41<03:55,  5.75s/it]Loading train:  87%|████████▋ | 271/311 [31:47<03:50,  5.75s/it]Loading train:  87%|████████▋ | 272/311 [31:53<03:45,  5.77s/it]Loading train:  88%|████████▊ | 273/311 [31:58<03:38,  5.74s/it]Loading train:  88%|████████▊ | 274/311 [32:04<03:38,  5.90s/it]Loading train:  88%|████████▊ | 275/311 [32:10<03:32,  5.91s/it]Loading train:  89%|████████▊ | 276/311 [32:16<03:24,  5.84s/it]Loading train:  89%|████████▉ | 277/311 [32:22<03:18,  5.85s/it]Loading train:  89%|████████▉ | 278/311 [32:28<03:11,  5.82s/it]Loading train:  90%|████████▉ | 279/311 [32:33<03:05,  5.80s/it]Loading train:  90%|█████████ | 280/311 [32:39<03:00,  5.82s/it]Loading train:  90%|█████████ | 281/311 [32:45<02:52,  5.76s/it]Loading train:  91%|█████████ | 282/311 [32:51<02:46,  5.75s/it]Loading train:  91%|█████████ | 283/311 [32:56<02:38,  5.67s/it]Loading train:  91%|█████████▏| 284/311 [33:01<02:29,  5.54s/it]Loading train:  92%|█████████▏| 285/311 [33:07<02:21,  5.46s/it]Loading train:  92%|█████████▏| 286/311 [33:12<02:15,  5.40s/it]Loading train:  92%|█████████▏| 287/311 [33:17<02:07,  5.31s/it]Loading train:  93%|█████████▎| 288/311 [33:22<02:00,  5.23s/it]Loading train:  93%|█████████▎| 289/311 [33:28<01:57,  5.34s/it]Loading train:  93%|█████████▎| 290/311 [33:33<01:51,  5.31s/it]Loading train:  94%|█████████▎| 291/311 [33:38<01:45,  5.28s/it]Loading train:  94%|█████████▍| 292/311 [33:44<01:41,  5.32s/it]Loading train:  94%|█████████▍| 293/311 [33:49<01:36,  5.37s/it]Loading train:  95%|█████████▍| 294/311 [33:54<01:31,  5.38s/it]Loading train:  95%|█████████▍| 295/311 [34:00<01:26,  5.39s/it]Loading train:  95%|█████████▌| 296/311 [34:05<01:21,  5.40s/it]Loading train:  95%|█████████▌| 297/311 [34:10<01:14,  5.35s/it]Loading train:  96%|█████████▌| 298/311 [34:16<01:10,  5.42s/it]Loading train:  96%|█████████▌| 299/311 [34:21<01:04,  5.38s/it]Loading train:  96%|█████████▋| 300/311 [34:27<00:59,  5.37s/it]Loading train:  97%|█████████▋| 301/311 [34:32<00:54,  5.44s/it]Loading train:  97%|█████████▋| 302/311 [34:38<00:48,  5.43s/it]Loading train:  97%|█████████▋| 303/311 [34:43<00:43,  5.42s/it]Loading train:  98%|█████████▊| 304/311 [34:48<00:37,  5.35s/it]Loading train:  98%|█████████▊| 305/311 [34:54<00:32,  5.42s/it]Loading train:  98%|█████████▊| 306/311 [34:59<00:26,  5.30s/it]Loading train:  99%|█████████▊| 307/311 [35:04<00:21,  5.38s/it]Loading train:  99%|█████████▉| 308/311 [35:10<00:16,  5.37s/it]Loading train:  99%|█████████▉| 309/311 [35:15<00:10,  5.22s/it]Loading train: 100%|█████████▉| 310/311 [35:20<00:05,  5.15s/it]Loading train: 100%|██████████| 311/311 [35:25<00:00,  5.20s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 18/311 [00:00<00:01, 176.28it/s]concatenating: train:  13%|█▎        | 39/311 [00:00<00:01, 181.74it/s]concatenating: train:  20%|█▉        | 62/311 [00:00<00:01, 193.11it/s]concatenating: train:  27%|██▋       | 84/311 [00:00<00:01, 199.25it/s]concatenating: train:  36%|███▌      | 111/311 [00:00<00:00, 208.15it/s]concatenating: train:  42%|████▏     | 131/311 [00:00<00:00, 194.32it/s]concatenating: train:  48%|████▊     | 149/311 [00:00<00:00, 179.68it/s]concatenating: train:  57%|█████▋    | 176/311 [00:00<00:00, 199.46it/s]concatenating: train:  66%|██████▌   | 205/311 [00:00<00:00, 211.82it/s]concatenating: train:  75%|███████▌  | 234/311 [00:01<00:00, 215.81it/s]concatenating: train:  84%|████████▍ | 261/311 [00:01<00:00, 221.49it/s]concatenating: train:  92%|█████████▏| 285/311 [00:01<00:00, 216.88it/s]concatenating: train:  99%|█████████▊| 307/311 [00:01<00:00, 214.80it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 209.13it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 12.00s/it]Loading test:  50%|█████     | 2/4 [00:22<00:23, 11.65s/it]Loading test:  75%|███████▌  | 3/4 [00:35<00:11, 11.82s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.82s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 51.29it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 12:27:04.063271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 12:27:04.063369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 12:27:04.063384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 12:27:04.063394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 12:27:04.063822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 40, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [5.87995836e-02 2.85625934e-02 1.22042724e-01 1.04920441e-02
 3.15682606e-02 5.46103058e-03 7.22892131e-02 1.13259646e-01
 7.87837639e-02 1.27868129e-02 2.92912776e-01 1.72791632e-01
 2.49918858e-04]
Train on 12355 samples, validate on 158 samples
Epoch 1/300
 - 19s - loss: 38413.1631 - acc: 0.8465 - mDice: 0.0707 - val_loss: 40610.3573 - val_acc: 0.8740 - val_mDice: 0.1274

Epoch 00001: val_mDice improved from -inf to 0.12744, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 17146.1880 - acc: 0.8480 - mDice: 0.1483 - val_loss: 28042.5072 - val_acc: 0.8509 - val_mDice: 0.2088

Epoch 00002: val_mDice improved from 0.12744 to 0.20878, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 14083.1405 - acc: 0.8620 - mDice: 0.1986 - val_loss: 23326.6886 - val_acc: 0.8844 - val_mDice: 0.2756

Epoch 00003: val_mDice improved from 0.20878 to 0.27562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 11808.6767 - acc: 0.8741 - mDice: 0.2481 - val_loss: 21287.2062 - val_acc: 0.8912 - val_mDice: 0.3132

Epoch 00004: val_mDice improved from 0.27562 to 0.31323, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 10522.3137 - acc: 0.8814 - mDice: 0.2854 - val_loss: 16248.5180 - val_acc: 0.8956 - val_mDice: 0.3365

Epoch 00005: val_mDice improved from 0.31323 to 0.33646, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 9112.4546 - acc: 0.8880 - mDice: 0.3258 - val_loss: 6049.1653 - val_acc: 0.9022 - val_mDice: 0.4128

Epoch 00006: val_mDice improved from 0.33646 to 0.41284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 9s - loss: 7934.4207 - acc: 0.8926 - mDice: 0.3651 - val_loss: 5184.9243 - val_acc: 0.9062 - val_mDice: 0.4605

Epoch 00007: val_mDice improved from 0.41284 to 0.46052, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 7277.7691 - acc: 0.8971 - mDice: 0.3945 - val_loss: 4983.7121 - val_acc: 0.9098 - val_mDice: 0.4758

Epoch 00008: val_mDice improved from 0.46052 to 0.47584, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 6755.7863 - acc: 0.9006 - mDice: 0.4199 - val_loss: 4669.1983 - val_acc: 0.9138 - val_mDice: 0.4994

Epoch 00009: val_mDice improved from 0.47584 to 0.49943, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 6293.0732 - acc: 0.9038 - mDice: 0.4447 - val_loss: 4441.1229 - val_acc: 0.9158 - val_mDice: 0.5167

Epoch 00010: val_mDice improved from 0.49943 to 0.51669, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 5877.6649 - acc: 0.9074 - mDice: 0.4684 - val_loss: 4149.8066 - val_acc: 0.9193 - val_mDice: 0.5400

Epoch 00011: val_mDice improved from 0.51669 to 0.54005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 5499.8272 - acc: 0.9102 - mDice: 0.4907 - val_loss: 4207.6313 - val_acc: 0.9216 - val_mDice: 0.5414

Epoch 00012: val_mDice improved from 0.54005 to 0.54140, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 9s - loss: 5192.6230 - acc: 0.9125 - mDice: 0.5098 - val_loss: 4058.0899 - val_acc: 0.9232 - val_mDice: 0.5537

Epoch 00013: val_mDice improved from 0.54140 to 0.55370, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 10s - loss: 4958.0231 - acc: 0.9147 - mDice: 0.5252 - val_loss: 4298.3755 - val_acc: 0.9231 - val_mDice: 0.5410

Epoch 00014: val_mDice did not improve from 0.55370
Epoch 15/300
 - 9s - loss: 4718.2369 - acc: 0.9165 - mDice: 0.5408 - val_loss: 3745.7831 - val_acc: 0.9270 - val_mDice: 0.5759

Epoch 00015: val_mDice improved from 0.55370 to 0.57585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 9s - loss: 4561.2427 - acc: 0.9180 - mDice: 0.5520 - val_loss: 3682.5331 - val_acc: 0.9268 - val_mDice: 0.5800

Epoch 00016: val_mDice improved from 0.57585 to 0.57998, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 4414.5859 - acc: 0.9196 - mDice: 0.5625 - val_loss: 3805.5677 - val_acc: 0.9270 - val_mDice: 0.5739

Epoch 00017: val_mDice did not improve from 0.57998
Epoch 18/300
 - 9s - loss: 4286.1239 - acc: 0.9207 - mDice: 0.5717 - val_loss: 3475.7924 - val_acc: 0.9304 - val_mDice: 0.5981

Epoch 00018: val_mDice improved from 0.57998 to 0.59807, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 9s - loss: 4169.2819 - acc: 0.9216 - mDice: 0.5802 - val_loss: 3404.8136 - val_acc: 0.9315 - val_mDice: 0.6033

Epoch 00019: val_mDice improved from 0.59807 to 0.60333, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 10s - loss: 4057.3521 - acc: 0.9228 - mDice: 0.5885 - val_loss: 3517.5239 - val_acc: 0.9311 - val_mDice: 0.5960

Epoch 00020: val_mDice did not improve from 0.60333
Epoch 21/300
 - 9s - loss: 3978.4043 - acc: 0.9236 - mDice: 0.5946 - val_loss: 3321.6951 - val_acc: 0.9325 - val_mDice: 0.6108

Epoch 00021: val_mDice improved from 0.60333 to 0.61082, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 9s - loss: 3861.0889 - acc: 0.9248 - mDice: 0.6038 - val_loss: 3213.9240 - val_acc: 0.9341 - val_mDice: 0.6187

Epoch 00022: val_mDice improved from 0.61082 to 0.61874, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 10s - loss: 3798.4539 - acc: 0.9254 - mDice: 0.6084 - val_loss: 3604.3823 - val_acc: 0.9334 - val_mDice: 0.5954

Epoch 00023: val_mDice did not improve from 0.61874
Epoch 24/300
 - 9s - loss: 3725.4724 - acc: 0.9263 - mDice: 0.6143 - val_loss: 3113.3136 - val_acc: 0.9363 - val_mDice: 0.6292

Epoch 00024: val_mDice improved from 0.61874 to 0.62918, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 9s - loss: 3679.2901 - acc: 0.9268 - mDice: 0.6180 - val_loss: 3258.4850 - val_acc: 0.9366 - val_mDice: 0.6189

Epoch 00025: val_mDice did not improve from 0.62918
Epoch 26/300
 - 10s - loss: 3603.3278 - acc: 0.9279 - mDice: 0.6243 - val_loss: 3166.3387 - val_acc: 0.9361 - val_mDice: 0.6259

Epoch 00026: val_mDice did not improve from 0.62918
Epoch 27/300
 - 9s - loss: 3525.4209 - acc: 0.9285 - mDice: 0.6303 - val_loss: 3206.0304 - val_acc: 0.9368 - val_mDice: 0.6256

Epoch 00027: val_mDice did not improve from 0.62918
Epoch 28/300
 - 9s - loss: 3488.9787 - acc: 0.9291 - mDice: 0.6336 - val_loss: 3316.1795 - val_acc: 0.9355 - val_mDice: 0.6172

Epoch 00028: val_mDice did not improve from 0.62918
Epoch 29/300
 - 10s - loss: 3418.6000 - acc: 0.9298 - mDice: 0.6391 - val_loss: 3056.0614 - val_acc: 0.9396 - val_mDice: 0.6374

Epoch 00029: val_mDice improved from 0.62918 to 0.63741, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 9s - loss: 3388.1474 - acc: 0.9303 - mDice: 0.6417 - val_loss: 3184.2776 - val_acc: 0.9363 - val_mDice: 0.6279

Epoch 00030: val_mDice did not improve from 0.63741
Epoch 31/300
 - 9s - loss: 3332.2462 - acc: 0.9311 - mDice: 0.6464 - val_loss: 3167.7748 - val_acc: 0.9374 - val_mDice: 0.6318

Epoch 00031: val_mDice did not improve from 0.63741
Epoch 32/300
 - 10s - loss: 3290.5124 - acc: 0.9315 - mDice: 0.6498 - val_loss: 3229.2507 - val_acc: 0.9360 - val_mDice: 0.6278

Epoch 00032: val_mDice did not improve from 0.63741
Epoch 33/300
 - 9s - loss: 3243.3754 - acc: 0.9318 - mDice: 0.6536 - val_loss: 3133.2858 - val_acc: 0.9373 - val_mDice: 0.6316

Epoch 00033: val_mDice did not improve from 0.63741
Epoch 34/300
 - 9s - loss: 3219.7481 - acc: 0.9324 - mDice: 0.6558 - val_loss: 3016.6911 - val_acc: 0.9416 - val_mDice: 0.6428

Epoch 00034: val_mDice improved from 0.63741 to 0.64280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 9s - loss: 3157.3262 - acc: 0.9330 - mDice: 0.6609 - val_loss: 3017.5662 - val_acc: 0.9389 - val_mDice: 0.6415

Epoch 00035: val_mDice did not improve from 0.64280
Epoch 36/300
 - 10s - loss: 3141.1552 - acc: 0.9333 - mDice: 0.6624 - val_loss: 3885.2664 - val_acc: 0.9386 - val_mDice: 0.6059

Epoch 00036: val_mDice did not improve from 0.64280
Epoch 37/300
 - 9s - loss: 3115.2848 - acc: 0.9336 - mDice: 0.6646 - val_loss: 3198.9579 - val_acc: 0.9389 - val_mDice: 0.6300

Epoch 00037: val_mDice did not improve from 0.64280
Epoch 38/300
 - 9s - loss: 3061.0283 - acc: 0.9343 - mDice: 0.6692 - val_loss: 3013.6151 - val_acc: 0.9401 - val_mDice: 0.6439

Epoch 00038: val_mDice improved from 0.64280 to 0.64386, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 10s - loss: 3045.4800 - acc: 0.9346 - mDice: 0.6708 - val_loss: 3007.2649 - val_acc: 0.9401 - val_mDice: 0.6433

Epoch 00039: val_mDice did not improve from 0.64386
Epoch 40/300
 - 9s - loss: 3013.1699 - acc: 0.9350 - mDice: 0.6733 - val_loss: 3106.7638 - val_acc: 0.9399 - val_mDice: 0.6360

Epoch 00040: val_mDice did not improve from 0.64386
Epoch 41/300
 - 9s - loss: 2989.7963 - acc: 0.9353 - mDice: 0.6756 - val_loss: 2888.6785 - val_acc: 0.9420 - val_mDice: 0.6520

Epoch 00041: val_mDice improved from 0.64386 to 0.65204, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 42/300
 - 10s - loss: 2950.0465 - acc: 0.9355 - mDice: 0.6788 - val_loss: 2986.1887 - val_acc: 0.9406 - val_mDice: 0.6436

Epoch 00042: val_mDice did not improve from 0.65204
Epoch 43/300
 - 9s - loss: 2940.1173 - acc: 0.9359 - mDice: 0.6799 - val_loss: 3008.0862 - val_acc: 0.9416 - val_mDice: 0.6445

Epoch 00043: val_mDice did not improve from 0.65204
Epoch 44/300
 - 9s - loss: 2895.3964 - acc: 0.9364 - mDice: 0.6839 - val_loss: 3036.1132 - val_acc: 0.9418 - val_mDice: 0.6482

Epoch 00044: val_mDice did not improve from 0.65204
Epoch 45/300
 - 10s - loss: 2895.7019 - acc: 0.9366 - mDice: 0.6839 - val_loss: 2708.8554 - val_acc: 0.9450 - val_mDice: 0.6660

Epoch 00045: val_mDice improved from 0.65204 to 0.66601, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 9s - loss: 2858.4931 - acc: 0.9369 - mDice: 0.6869 - val_loss: 2837.6286 - val_acc: 0.9432 - val_mDice: 0.6582

Epoch 00046: val_mDice did not improve from 0.66601
Epoch 47/300
 - 9s - loss: 2824.6959 - acc: 0.9372 - mDice: 0.6899 - val_loss: 2859.3293 - val_acc: 0.9428 - val_mDice: 0.6557

Epoch 00047: val_mDice did not improve from 0.66601
Epoch 48/300
 - 10s - loss: 2823.3592 - acc: 0.9374 - mDice: 0.6902 - val_loss: 2769.7058 - val_acc: 0.9452 - val_mDice: 0.6588

Epoch 00048: val_mDice did not improve from 0.66601
Epoch 49/300
 - 10s - loss: 2788.0196 - acc: 0.9378 - mDice: 0.6933 - val_loss: 2679.3886 - val_acc: 0.9426 - val_mDice: 0.6678

Epoch 00049: val_mDice improved from 0.66601 to 0.66778, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 50/300
 - 9s - loss: 2784.7295 - acc: 0.9378 - mDice: 0.6936 - val_loss: 2596.3442 - val_acc: 0.9442 - val_mDice: 0.6732

Epoch 00050: val_mDice improved from 0.66778 to 0.67317, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 10s - loss: 2757.0484 - acc: 0.9382 - mDice: 0.6959 - val_loss: 3005.7682 - val_acc: 0.9412 - val_mDice: 0.6432

Epoch 00051: val_mDice did not improve from 0.67317
Epoch 52/300
 - 10s - loss: 2748.7513 - acc: 0.9384 - mDice: 0.6969 - val_loss: 2681.7939 - val_acc: 0.9440 - val_mDice: 0.6704

Epoch 00052: val_mDice did not improve from 0.67317
Epoch 53/300
 - 9s - loss: 2729.9861 - acc: 0.9386 - mDice: 0.6984 - val_loss: 2518.3778 - val_acc: 0.9464 - val_mDice: 0.6803

Epoch 00053: val_mDice improved from 0.67317 to 0.68034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 54/300
 - 9s - loss: 2719.8745 - acc: 0.9389 - mDice: 0.6995 - val_loss: 2950.3320 - val_acc: 0.9431 - val_mDice: 0.6503

Epoch 00054: val_mDice did not improve from 0.68034
Epoch 55/300
 - 10s - loss: 2683.1317 - acc: 0.9391 - mDice: 0.7027 - val_loss: 2790.1420 - val_acc: 0.9424 - val_mDice: 0.6613

Epoch 00055: val_mDice did not improve from 0.68034
Epoch 56/300
 - 9s - loss: 2683.3681 - acc: 0.9393 - mDice: 0.7029 - val_loss: 3176.1922 - val_acc: 0.9400 - val_mDice: 0.6340

Epoch 00056: val_mDice did not improve from 0.68034
Epoch 57/300
 - 9s - loss: 2663.4726 - acc: 0.9395 - mDice: 0.7046 - val_loss: 2750.8686 - val_acc: 0.9474 - val_mDice: 0.6662

Epoch 00057: val_mDice did not improve from 0.68034
Epoch 58/300
 - 10s - loss: 2629.3096 - acc: 0.9398 - mDice: 0.7076 - val_loss: 2860.9919 - val_acc: 0.9440 - val_mDice: 0.6572

Epoch 00058: val_mDice did not improve from 0.68034
Epoch 59/300
 - 9s - loss: 2616.8912 - acc: 0.9399 - mDice: 0.7087 - val_loss: 2955.4830 - val_acc: 0.9451 - val_mDice: 0.6520

Epoch 00059: val_mDice did not improve from 0.68034
Epoch 60/300
 - 9s - loss: 2613.8949 - acc: 0.9401 - mDice: 0.7090 - val_loss: 2921.6788 - val_acc: 0.9435 - val_mDice: 0.6522

Epoch 00060: val_mDice did not improve from 0.68034
Epoch 61/300
 - 10s - loss: 2604.4577 - acc: 0.9402 - mDice: 0.7098 - val_loss: 2649.1053 - val_acc: 0.9452 - val_mDice: 0.6719

Epoch 00061: val_mDice did not improve from 0.68034
Epoch 62/300
 - 9s - loss: 2583.5933 - acc: 0.9404 - mDice: 0.7117 - val_loss: 2979.6409 - val_acc: 0.9425 - val_mDice: 0.6462

Epoch 00062: val_mDice did not improve from 0.68034
Epoch 63/300
 - 9s - loss: 2553.9215 - acc: 0.9408 - mDice: 0.7144 - val_loss: 2577.3390 - val_acc: 0.9471 - val_mDice: 0.6767

Epoch 00063: val_mDice did not improve from 0.68034
Epoch 64/300
 - 10s - loss: 2557.5493 - acc: 0.9406 - mDice: 0.7141 - val_loss: 2604.1401 - val_acc: 0.9482 - val_mDice: 0.6762

Epoch 00064: val_mDice did not improve from 0.68034
Epoch 65/300
 - 10s - loss: 2537.6523 - acc: 0.9409 - mDice: 0.7160 - val_loss: 2993.6983 - val_acc: 0.9451 - val_mDice: 0.6467

Epoch 00065: val_mDice did not improve from 0.68034
Epoch 66/300
 - 9s - loss: 2533.9751 - acc: 0.9409 - mDice: 0.7163 - val_loss: 2675.5224 - val_acc: 0.9464 - val_mDice: 0.6685

Epoch 00066: val_mDice did not improve from 0.68034
Epoch 67/300
 - 9s - loss: 2509.1711 - acc: 0.9412 - mDice: 0.7186 - val_loss: 3013.9183 - val_acc: 0.9443 - val_mDice: 0.6431

Epoch 00067: val_mDice did not improve from 0.68034
Epoch 68/300
 - 10s - loss: 2498.5354 - acc: 0.9415 - mDice: 0.7195 - val_loss: 2617.0387 - val_acc: 0.9462 - val_mDice: 0.6731

Epoch 00068: val_mDice did not improve from 0.68034
Epoch 69/300
 - 9s - loss: 2493.7836 - acc: 0.9414 - mDice: 0.7200 - val_loss: 2953.3305 - val_acc: 0.9440 - val_mDice: 0.6500

Epoch 00069: val_mDice did not improve from 0.68034
Epoch 70/300
 - 9s - loss: 2483.4023 - acc: 0.9415 - mDice: 0.7210 - val_loss: 2868.9057 - val_acc: 0.9457 - val_mDice: 0.6555

Epoch 00070: val_mDice did not improve from 0.68034
Epoch 71/300
 - 10s - loss: 2460.3891 - acc: 0.9418 - mDice: 0.7231 - val_loss: 2631.3761 - val_acc: 0.9477 - val_mDice: 0.6734

Epoch 00071: val_mDice did not improve from 0.68034
Epoch 72/300
 - 9s - loss: 2448.6482 - acc: 0.9420 - mDice: 0.7242 - val_loss: 2646.2102 - val_acc: 0.9480 - val_mDice: 0.6728

Epoch 00072: val_mDice did not improve from 0.68034
Epoch 73/300
 - 9s - loss: 2432.3787 - acc: 0.9420 - mDice: 0.7257 - val_loss: 2807.9324 - val_acc: 0.9454 - val_mDice: 0.6585

Epoch 00073: val_mDice did not improve from 0.68034
Epoch 74/300
 - 10s - loss: 2410.8239 - acc: 0.9423 - mDice: 0.7276 - val_loss: 2869.2240 - val_acc: 0.9453 - val_mDice: 0.6527

Epoch 00074: val_mDice did not improve from 0.68034
Epoch 75/300
 - 9s - loss: 2418.4953 - acc: 0.9422 - mDice: 0.7269 - val_loss: 2771.5863 - val_acc: 0.9468 - val_mDice: 0.6677

Epoch 00075: val_mDice did not improve from 0.68034
Epoch 76/300
 - 9s - loss: 2397.3431 - acc: 0.9425 - mDice: 0.7289 - val_loss: 3378.1596 - val_acc: 0.9432 - val_mDice: 0.6239

Epoch 00076: val_mDice did not improve from 0.68034
Epoch 77/300
 - 9s - loss: 2400.2679 - acc: 0.9425 - mDice: 0.7287 - val_loss: 3160.1155 - val_acc: 0.9431 - val_mDice: 0.6337

Epoch 00077: val_mDice did not improve from 0.68034
Epoch 78/300
 - 10s - loss: 2377.2728 - acc: 0.9429 - mDice: 0.7309 - val_loss: 2792.0096 - val_acc: 0.9459 - val_mDice: 0.6622

Epoch 00078: val_mDice did not improve from 0.68034
Epoch 79/300
 - 9s - loss: 2376.3264 - acc: 0.9427 - mDice: 0.7309 - val_loss: 2773.8266 - val_acc: 0.9469 - val_mDice: 0.6651

Epoch 00079: val_mDice did not improve from 0.68034
Epoch 80/300
 - 9s - loss: 2372.1193 - acc: 0.9429 - mDice: 0.7315 - val_loss: 2637.5080 - val_acc: 0.9456 - val_mDice: 0.6728

Epoch 00080: val_mDice did not improve from 0.68034
Epoch 81/300
 - 10s - loss: 2353.3251 - acc: 0.9430 - mDice: 0.7331 - val_loss: 3015.1216 - val_acc: 0.9437 - val_mDice: 0.6473

Epoch 00081: val_mDice did not improve from 0.68034
Epoch 82/300
 - 9s - loss: 2342.7042 - acc: 0.9432 - mDice: 0.7342 - val_loss: 3818.6100 - val_acc: 0.9431 - val_mDice: 0.6095

Epoch 00082: val_mDice did not improve from 0.68034
Epoch 83/300
 - 9s - loss: 2341.7141 - acc: 0.9432 - mDice: 0.7343 - val_loss: 2560.1816 - val_acc: 0.9483 - val_mDice: 0.6806

Epoch 00083: val_mDice improved from 0.68034 to 0.68056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 84/300
 - 10s - loss: 2338.8494 - acc: 0.9434 - mDice: 0.7346 - val_loss: 3077.5072 - val_acc: 0.9427 - val_mDice: 0.6341

Epoch 00084: val_mDice did not improve from 0.68056
Epoch 85/300
 - 9s - loss: 2336.9781 - acc: 0.9433 - mDice: 0.7348 - val_loss: 2787.6152 - val_acc: 0.9442 - val_mDice: 0.6608

Epoch 00085: val_mDice did not improve from 0.68056
Epoch 86/300
 - 9s - loss: 2314.5215 - acc: 0.9435 - mDice: 0.7368 - val_loss: 2677.3642 - val_acc: 0.9475 - val_mDice: 0.6700

Epoch 00086: val_mDice did not improve from 0.68056
Epoch 87/300
 - 10s - loss: 2308.4024 - acc: 0.9438 - mDice: 0.7376 - val_loss: 2622.3268 - val_acc: 0.9479 - val_mDice: 0.6760

Epoch 00087: val_mDice did not improve from 0.68056
Epoch 88/300
 - 9s - loss: 2318.5722 - acc: 0.9436 - mDice: 0.7364 - val_loss: 3020.8827 - val_acc: 0.9466 - val_mDice: 0.6483

Epoch 00088: val_mDice did not improve from 0.68056
Epoch 89/300
 - 9s - loss: 2288.1476 - acc: 0.9438 - mDice: 0.7393 - val_loss: 2843.0200 - val_acc: 0.9458 - val_mDice: 0.6559

Epoch 00089: val_mDice did not improve from 0.68056
Epoch 90/300
 - 9s - loss: 2280.6664 - acc: 0.9440 - mDice: 0.7401 - val_loss: 2875.9362 - val_acc: 0.9459 - val_mDice: 0.6566

Epoch 00090: val_mDice did not improve from 0.68056
Epoch 91/300
 - 10s - loss: 2281.5676 - acc: 0.9441 - mDice: 0.7400 - val_loss: 3003.8940 - val_acc: 0.9484 - val_mDice: 0.6508

Epoch 00091: val_mDice did not improve from 0.68056
Epoch 92/300
 - 9s - loss: 2268.0311 - acc: 0.9441 - mDice: 0.7412 - val_loss: 2660.3948 - val_acc: 0.9493 - val_mDice: 0.6732

Epoch 00092: val_mDice did not improve from 0.68056
Epoch 93/300
 - 9s - loss: 2277.1551 - acc: 0.9441 - mDice: 0.7406 - val_loss: 2756.3452 - val_acc: 0.9460 - val_mDice: 0.6648

Epoch 00093: val_mDice did not improve from 0.68056
Epoch 94/300
 - 10s - loss: 2249.7380 - acc: 0.9443 - mDice: 0.7431 - val_loss: 2629.3314 - val_acc: 0.9473 - val_mDice: 0.6744

Epoch 00094: val_mDice did not improve from 0.68056
Epoch 95/300
 - 9s - loss: 2242.8631 - acc: 0.9443 - mDice: 0.7436 - val_loss: 2519.5084 - val_acc: 0.9491 - val_mDice: 0.6846

Epoch 00095: val_mDice improved from 0.68056 to 0.68460, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 96/300
 - 9s - loss: 2247.6330 - acc: 0.9443 - mDice: 0.7432 - val_loss: 2474.9505 - val_acc: 0.9493 - val_mDice: 0.6896

Epoch 00096: val_mDice improved from 0.68460 to 0.68956, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 10s - loss: 2228.9183 - acc: 0.9446 - mDice: 0.7450 - val_loss: 2950.2331 - val_acc: 0.9468 - val_mDice: 0.6496

Epoch 00097: val_mDice did not improve from 0.68956
Epoch 98/300
 - 9s - loss: 2227.6921 - acc: 0.9445 - mDice: 0.7451 - val_loss: 2534.0546 - val_acc: 0.9498 - val_mDice: 0.6824

Epoch 00098: val_mDice did not improve from 0.68956
Epoch 99/300
 - 9s - loss: 2217.4148 - acc: 0.9447 - mDice: 0.7462 - val_loss: 2594.7761 - val_acc: 0.9486 - val_mDice: 0.6787

Epoch 00099: val_mDice did not improve from 0.68956
Epoch 100/300
 - 10s - loss: 2222.4957 - acc: 0.9446 - mDice: 0.7456 - val_loss: 2585.2779 - val_acc: 0.9468 - val_mDice: 0.6781

Epoch 00100: val_mDice did not improve from 0.68956
Epoch 101/300
 - 9s - loss: 2210.8383 - acc: 0.9448 - mDice: 0.7468 - val_loss: 2564.5019 - val_acc: 0.9476 - val_mDice: 0.6797

Epoch 00101: val_mDice did not improve from 0.68956
Epoch 102/300
 - 9s - loss: 2200.4326 - acc: 0.9449 - mDice: 0.7478 - val_loss: 2634.1514 - val_acc: 0.9484 - val_mDice: 0.6748

Epoch 00102: val_mDice did not improve from 0.68956
Epoch 103/300
 - 10s - loss: 2193.3310 - acc: 0.9449 - mDice: 0.7484 - val_loss: 3036.7003 - val_acc: 0.9471 - val_mDice: 0.6490

Epoch 00103: val_mDice did not improve from 0.68956
Epoch 104/300
 - 9s - loss: 2188.0577 - acc: 0.9450 - mDice: 0.7490 - val_loss: 2455.2135 - val_acc: 0.9495 - val_mDice: 0.6893

Epoch 00104: val_mDice did not improve from 0.68956
Epoch 105/300
 - 9s - loss: 2194.8376 - acc: 0.9450 - mDice: 0.7484 - val_loss: 2398.3302 - val_acc: 0.9508 - val_mDice: 0.6944

Epoch 00105: val_mDice improved from 0.68956 to 0.69441, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 106/300
 - 9s - loss: 2191.5920 - acc: 0.9450 - mDice: 0.7487 - val_loss: 2739.8450 - val_acc: 0.9477 - val_mDice: 0.6664

Epoch 00106: val_mDice did not improve from 0.69441
Epoch 107/300
 - 9s - loss: 2178.6746 - acc: 0.9452 - mDice: 0.7500 - val_loss: 2467.9283 - val_acc: 0.9514 - val_mDice: 0.6888

Epoch 00107: val_mDice did not improve from 0.69441
Epoch 108/300
 - 9s - loss: 2164.4998 - acc: 0.9453 - mDice: 0.7513 - val_loss: 2503.5731 - val_acc: 0.9498 - val_mDice: 0.6865

Epoch 00108: val_mDice did not improve from 0.69441
Epoch 109/300
 - 9s - loss: 2154.2678 - acc: 0.9454 - mDice: 0.7523 - val_loss: 2503.5548 - val_acc: 0.9494 - val_mDice: 0.6870

Epoch 00109: val_mDice did not improve from 0.69441
Epoch 110/300
 - 10s - loss: 2148.0975 - acc: 0.9454 - mDice: 0.7529 - val_loss: 2513.6611 - val_acc: 0.9511 - val_mDice: 0.6825

Epoch 00110: val_mDice did not improve from 0.69441
Epoch 111/300
 - 9s - loss: 2143.3741 - acc: 0.9455 - mDice: 0.7534 - val_loss: 2474.9649 - val_acc: 0.9507 - val_mDice: 0.6889

Epoch 00111: val_mDice did not improve from 0.69441
Epoch 112/300
 - 9s - loss: 2143.5986 - acc: 0.9455 - mDice: 0.7534 - val_loss: 2730.7299 - val_acc: 0.9504 - val_mDice: 0.6678

Epoch 00112: val_mDice did not improve from 0.69441
Epoch 113/300
 - 10s - loss: 2133.5735 - acc: 0.9457 - mDice: 0.7544 - val_loss: 2824.8292 - val_acc: 0.9481 - val_mDice: 0.6611

Epoch 00113: val_mDice did not improve from 0.69441
Epoch 114/300
 - 9s - loss: 2138.8605 - acc: 0.9455 - mDice: 0.7538 - val_loss: 2451.9002 - val_acc: 0.9520 - val_mDice: 0.6901

Epoch 00114: val_mDice did not improve from 0.69441
Epoch 115/300
 - 9s - loss: 2137.8528 - acc: 0.9457 - mDice: 0.7540 - val_loss: 2528.0228 - val_acc: 0.9492 - val_mDice: 0.6821

Epoch 00115: val_mDice did not improve from 0.69441
Epoch 116/300
 - 10s - loss: 2132.9056 - acc: 0.9457 - mDice: 0.7545 - val_loss: 2618.9200 - val_acc: 0.9510 - val_mDice: 0.6772

Epoch 00116: val_mDice did not improve from 0.69441
Epoch 117/300
 - 9s - loss: 2135.1630 - acc: 0.9457 - mDice: 0.7542 - val_loss: 3068.0860 - val_acc: 0.9459 - val_mDice: 0.6405

Epoch 00117: val_mDice did not improve from 0.69441
Epoch 118/300
 - 9s - loss: 2111.9659 - acc: 0.9459 - mDice: 0.7565 - val_loss: 2589.9561 - val_acc: 0.9488 - val_mDice: 0.6784

Epoch 00118: val_mDice did not improve from 0.69441
Epoch 119/300
 - 9s - loss: 2124.9751 - acc: 0.9457 - mDice: 0.7552 - val_loss: 2617.0069 - val_acc: 0.9480 - val_mDice: 0.6770

Epoch 00119: val_mDice did not improve from 0.69441
Epoch 120/300
 - 10s - loss: 2114.8588 - acc: 0.9459 - mDice: 0.7562 - val_loss: 2599.7115 - val_acc: 0.9493 - val_mDice: 0.6805

Epoch 00120: val_mDice did not improve from 0.69441
Epoch 121/300
 - 9s - loss: 2101.2722 - acc: 0.9460 - mDice: 0.7575 - val_loss: 2478.8444 - val_acc: 0.9509 - val_mDice: 0.6888

Epoch 00121: val_mDice did not improve from 0.69441
Epoch 122/300
 - 9s - loss: 2097.6911 - acc: 0.9459 - mDice: 0.7579 - val_loss: 2446.1084 - val_acc: 0.9505 - val_mDice: 0.6918

Epoch 00122: val_mDice did not improve from 0.69441
Epoch 123/300
 - 10s - loss: 2097.0693 - acc: 0.9461 - mDice: 0.7580 - val_loss: 2839.7843 - val_acc: 0.9475 - val_mDice: 0.6578

Epoch 00123: val_mDice did not improve from 0.69441
Epoch 124/300
 - 9s - loss: 2091.6934 - acc: 0.9461 - mDice: 0.7585 - val_loss: 2619.9578 - val_acc: 0.9502 - val_mDice: 0.6764

Epoch 00124: val_mDice did not improve from 0.69441
Epoch 125/300
 - 9s - loss: 2096.7069 - acc: 0.9460 - mDice: 0.7580 - val_loss: 2561.8982 - val_acc: 0.9509 - val_mDice: 0.6786

Epoch 00125: val_mDice did not improve from 0.69441
Epoch 126/300
 - 10s - loss: 2079.1967 - acc: 0.9463 - mDice: 0.7597 - val_loss: 2460.5982 - val_acc: 0.9519 - val_mDice: 0.6912

Epoch 00126: val_mDice did not improve from 0.69441
Epoch 127/300
 - 9s - loss: 2083.3330 - acc: 0.9463 - mDice: 0.7593 - val_loss: 2906.8007 - val_acc: 0.9452 - val_mDice: 0.6524

Epoch 00127: val_mDice did not improve from 0.69441
Epoch 128/300
 - 9s - loss: 2083.9770 - acc: 0.9461 - mDice: 0.7591 - val_loss: 2568.7219 - val_acc: 0.9497 - val_mDice: 0.6804

Epoch 00128: val_mDice did not improve from 0.69441
Epoch 129/300
 - 10s - loss: 2067.7115 - acc: 0.9463 - mDice: 0.7608 - val_loss: 2575.0409 - val_acc: 0.9499 - val_mDice: 0.6801

Epoch 00129: val_mDice did not improve from 0.69441
Epoch 130/300
 - 9s - loss: 2069.3878 - acc: 0.9463 - mDice: 0.7606 - val_loss: 2365.8933 - val_acc: 0.9515 - val_mDice: 0.6990

Epoch 00130: val_mDice improved from 0.69441 to 0.69899, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 131/300
 - 9s - loss: 2066.6062 - acc: 0.9464 - mDice: 0.7609 - val_loss: 2568.7023 - val_acc: 0.9495 - val_mDice: 0.6808

Epoch 00131: val_mDice did not improve from 0.69899
Epoch 132/300
 - 10s - loss: 2056.8921 - acc: 0.9464 - mDice: 0.7619 - val_loss: 2558.8777 - val_acc: 0.9497 - val_mDice: 0.6810

Epoch 00132: val_mDice did not improve from 0.69899
Epoch 133/300
 - 9s - loss: 2059.6126 - acc: 0.9463 - mDice: 0.7616 - val_loss: 2639.4122 - val_acc: 0.9479 - val_mDice: 0.6746

Epoch 00133: val_mDice did not improve from 0.69899
Epoch 134/300
 - 9s - loss: 2042.2673 - acc: 0.9466 - mDice: 0.7633 - val_loss: 2391.7363 - val_acc: 0.9518 - val_mDice: 0.6962

Epoch 00134: val_mDice did not improve from 0.69899
Epoch 135/300
 - 9s - loss: 2055.6033 - acc: 0.9465 - mDice: 0.7620 - val_loss: 2709.1156 - val_acc: 0.9482 - val_mDice: 0.6683

Epoch 00135: val_mDice did not improve from 0.69899
Epoch 136/300
 - 10s - loss: 2046.6432 - acc: 0.9466 - mDice: 0.7631 - val_loss: 2463.7835 - val_acc: 0.9512 - val_mDice: 0.6879

Epoch 00136: val_mDice did not improve from 0.69899
Epoch 137/300
 - 9s - loss: 2045.9472 - acc: 0.9467 - mDice: 0.7631 - val_loss: 2593.4367 - val_acc: 0.9495 - val_mDice: 0.6783

Epoch 00137: val_mDice did not improve from 0.69899
Epoch 138/300
 - 9s - loss: 2049.9520 - acc: 0.9466 - mDice: 0.7626 - val_loss: 2533.4586 - val_acc: 0.9508 - val_mDice: 0.6827

Epoch 00138: val_mDice did not improve from 0.69899
Epoch 139/300
 - 10s - loss: 2036.9402 - acc: 0.9466 - mDice: 0.7638 - val_loss: 2517.8370 - val_acc: 0.9515 - val_mDice: 0.6855

Epoch 00139: val_mDice did not improve from 0.69899
Epoch 140/300
 - 9s - loss: 2026.0487 - acc: 0.9469 - mDice: 0.7650 - val_loss: 2551.3931 - val_acc: 0.9494 - val_mDice: 0.6840

Epoch 00140: val_mDice did not improve from 0.69899
Epoch 141/300
 - 9s - loss: 2037.1239 - acc: 0.9467 - mDice: 0.7639 - val_loss: 2656.5259 - val_acc: 0.9492 - val_mDice: 0.6731

Epoch 00141: val_mDice did not improve from 0.69899
Epoch 142/300
 - 9s - loss: 2028.6270 - acc: 0.9468 - mDice: 0.7647 - val_loss: 2737.7213 - val_acc: 0.9506 - val_mDice: 0.6666

Epoch 00142: val_mDice did not improve from 0.69899
Epoch 143/300
 - 9s - loss: 2017.5071 - acc: 0.9469 - mDice: 0.7658 - val_loss: 2608.0414 - val_acc: 0.9498 - val_mDice: 0.6760

Epoch 00143: val_mDice did not improve from 0.69899
Epoch 144/300
 - 9s - loss: 2024.4416 - acc: 0.9469 - mDice: 0.7652 - val_loss: 2583.3997 - val_acc: 0.9504 - val_mDice: 0.6781

Epoch 00144: val_mDice did not improve from 0.69899
Epoch 145/300
 - 9s - loss: 2007.1258 - acc: 0.9470 - mDice: 0.7668 - val_loss: 2609.8660 - val_acc: 0.9497 - val_mDice: 0.6775

Epoch 00145: val_mDice did not improve from 0.69899
Epoch 146/300
 - 10s - loss: 2010.3991 - acc: 0.9470 - mDice: 0.7665 - val_loss: 2493.6238 - val_acc: 0.9502 - val_mDice: 0.6873

Epoch 00146: val_mDice did not improve from 0.69899
Epoch 147/300
 - 9s - loss: 2021.0455 - acc: 0.9469 - mDice: 0.7655 - val_loss: 2482.2768 - val_acc: 0.9519 - val_mDice: 0.6885

Epoch 00147: val_mDice did not improve from 0.69899
Epoch 148/300
 - 9s - loss: 2019.6516 - acc: 0.9469 - mDice: 0.7656 - val_loss: 2456.9125 - val_acc: 0.9513 - val_mDice: 0.6901

Epoch 00148: val_mDice did not improve from 0.69899
Epoch 149/300
 - 10s - loss: 2011.1593 - acc: 0.9470 - mDice: 0.7664 - val_loss: 2448.7856 - val_acc: 0.9526 - val_mDice: 0.6903

Epoch 00149: val_mDice did not improve from 0.69899
Epoch 150/300
 - 9s - loss: 2005.1506 - acc: 0.9471 - mDice: 0.7671 - val_loss: 2395.9258 - val_acc: 0.9525 - val_mDice: 0.6952

Epoch 00150: val_mDice did not improve from 0.69899
Epoch 151/300
 - 9s - loss: 1999.9418 - acc: 0.9472 - mDice: 0.7676 - val_loss: 2360.3748 - val_acc: 0.9518 - val_mDice: 0.6998

Epoch 00151: val_mDice improved from 0.69899 to 0.69981, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 152/300
 - 10s - loss: 2007.6171 - acc: 0.9470 - mDice: 0.7668 - val_loss: 2410.1086 - val_acc: 0.9514 - val_mDice: 0.6971

Epoch 00152: val_mDice did not improve from 0.69981
Epoch 153/300
 - 9s - loss: 1992.1326 - acc: 0.9472 - mDice: 0.7684 - val_loss: 2481.6029 - val_acc: 0.9512 - val_mDice: 0.6888

Epoch 00153: val_mDice did not improve from 0.69981
Epoch 154/300
 - 9s - loss: 1997.6853 - acc: 0.9471 - mDice: 0.7678 - val_loss: 2785.2116 - val_acc: 0.9482 - val_mDice: 0.6632

Epoch 00154: val_mDice did not improve from 0.69981
Epoch 155/300
 - 9s - loss: 1984.7609 - acc: 0.9473 - mDice: 0.7691 - val_loss: 2597.9528 - val_acc: 0.9518 - val_mDice: 0.6789

Epoch 00155: val_mDice did not improve from 0.69981
Epoch 156/300
 - 10s - loss: 2002.1521 - acc: 0.9472 - mDice: 0.7674 - val_loss: 2602.5901 - val_acc: 0.9524 - val_mDice: 0.6785

Epoch 00156: val_mDice did not improve from 0.69981
Epoch 157/300
 - 9s - loss: 1988.4633 - acc: 0.9473 - mDice: 0.7688 - val_loss: 2989.9382 - val_acc: 0.9472 - val_mDice: 0.6466

Epoch 00157: val_mDice did not improve from 0.69981
Epoch 158/300
 - 9s - loss: 1992.4182 - acc: 0.9472 - mDice: 0.7683 - val_loss: 2582.6157 - val_acc: 0.9509 - val_mDice: 0.6796

Epoch 00158: val_mDice did not improve from 0.69981
Epoch 159/300
 - 10s - loss: 1980.1379 - acc: 0.9472 - mDice: 0.7694 - val_loss: 2639.3162 - val_acc: 0.9477 - val_mDice: 0.6732

Epoch 00159: val_mDice did not improve from 0.69981
Epoch 160/300
 - 9s - loss: 1982.5244 - acc: 0.9474 - mDice: 0.7694 - val_loss: 2574.7306 - val_acc: 0.9506 - val_mDice: 0.6816

Epoch 00160: val_mDice did not improve from 0.69981
Epoch 161/300
 - 9s - loss: 1972.7554 - acc: 0.9473 - mDice: 0.7703 - val_loss: 2521.0691 - val_acc: 0.9481 - val_mDice: 0.6849

Epoch 00161: val_mDice did not improve from 0.69981
Epoch 162/300
 - 10s - loss: 1958.1732 - acc: 0.9475 - mDice: 0.7718 - val_loss: 2482.3990 - val_acc: 0.9503 - val_mDice: 0.6887

Epoch 00162: val_mDice did not improve from 0.69981
Epoch 163/300
 - 9s - loss: 1968.8943 - acc: 0.9474 - mDice: 0.7706 - val_loss: 2469.1858 - val_acc: 0.9510 - val_mDice: 0.6896

Epoch 00163: val_mDice did not improve from 0.69981
Epoch 164/300
 - 9s - loss: 1975.4457 - acc: 0.9474 - mDice: 0.7701 - val_loss: 2853.7253 - val_acc: 0.9434 - val_mDice: 0.6544

Epoch 00164: val_mDice did not improve from 0.69981
Epoch 165/300
 - 10s - loss: 1965.5513 - acc: 0.9474 - mDice: 0.7710 - val_loss: 2596.6449 - val_acc: 0.9516 - val_mDice: 0.6792

Epoch 00165: val_mDice did not improve from 0.69981
Epoch 166/300
 - 9s - loss: 1960.3018 - acc: 0.9475 - mDice: 0.7715 - val_loss: 2408.6635 - val_acc: 0.9522 - val_mDice: 0.6961

Epoch 00166: val_mDice did not improve from 0.69981
Epoch 167/300
 - 9s - loss: 1971.8985 - acc: 0.9474 - mDice: 0.7704 - val_loss: 2514.7149 - val_acc: 0.9497 - val_mDice: 0.6847

Epoch 00167: val_mDice did not improve from 0.69981
Epoch 168/300
 - 10s - loss: 1962.3775 - acc: 0.9474 - mDice: 0.7713 - val_loss: 2361.4698 - val_acc: 0.9516 - val_mDice: 0.6974

Epoch 00168: val_mDice did not improve from 0.69981
Epoch 169/300
 - 10s - loss: 1956.3044 - acc: 0.9475 - mDice: 0.7720 - val_loss: 2698.8611 - val_acc: 0.9494 - val_mDice: 0.6719

Epoch 00169: val_mDice did not improve from 0.69981
Epoch 170/300
 - 9s - loss: 1948.8829 - acc: 0.9477 - mDice: 0.7726 - val_loss: 2434.5014 - val_acc: 0.9517 - val_mDice: 0.6923

Epoch 00170: val_mDice did not improve from 0.69981
Epoch 171/300
 - 9s - loss: 1950.5021 - acc: 0.9476 - mDice: 0.7726 - val_loss: 2430.5582 - val_acc: 0.9518 - val_mDice: 0.6925

Epoch 00171: val_mDice did not improve from 0.69981
Epoch 172/300
 - 10s - loss: 1959.1332 - acc: 0.9477 - mDice: 0.7716 - val_loss: 2419.3159 - val_acc: 0.9515 - val_mDice: 0.6948

Epoch 00172: val_mDice did not improve from 0.69981
Epoch 173/300
 - 9s - loss: 1944.4829 - acc: 0.9477 - mDice: 0.7731 - val_loss: 2800.2006 - val_acc: 0.9493 - val_mDice: 0.6632

Epoch 00173: val_mDice did not improve from 0.69981
Epoch 174/300
 - 9s - loss: 1948.4185 - acc: 0.9477 - mDice: 0.7728 - val_loss: 2606.9068 - val_acc: 0.9472 - val_mDice: 0.6777

Epoch 00174: val_mDice did not improve from 0.69981
Epoch 175/300
 - 10s - loss: 1942.3741 - acc: 0.9477 - mDice: 0.7733 - val_loss: 2666.9942 - val_acc: 0.9483 - val_mDice: 0.6713

Epoch 00175: val_mDice did not improve from 0.69981
Epoch 176/300
 - 9s - loss: 1944.1776 - acc: 0.9477 - mDice: 0.7732 - val_loss: 2662.2286 - val_acc: 0.9496 - val_mDice: 0.6718

Epoch 00176: val_mDice did not improve from 0.69981
Epoch 177/300
 - 9s - loss: 1939.9647 - acc: 0.9477 - mDice: 0.7736 - val_loss: 2589.5265 - val_acc: 0.9506 - val_mDice: 0.6784

Epoch 00177: val_mDice did not improve from 0.69981
Epoch 178/300
 - 9s - loss: 1948.9062 - acc: 0.9477 - mDice: 0.7727 - val_loss: 2549.2938 - val_acc: 0.9503 - val_mDice: 0.6833

Epoch 00178: val_mDice did not improve from 0.69981
Epoch 179/300
 - 10s - loss: 1934.9580 - acc: 0.9478 - mDice: 0.7741 - val_loss: 2856.8196 - val_acc: 0.9467 - val_mDice: 0.6539

Epoch 00179: val_mDice did not improve from 0.69981
Epoch 180/300
 - 9s - loss: 1934.1045 - acc: 0.9478 - mDice: 0.7742 - val_loss: 2403.4753 - val_acc: 0.9529 - val_mDice: 0.6960

Epoch 00180: val_mDice did not improve from 0.69981
Epoch 181/300
 - 9s - loss: 1929.8150 - acc: 0.9477 - mDice: 0.7746 - val_loss: 2463.2153 - val_acc: 0.9523 - val_mDice: 0.6892

Epoch 00181: val_mDice did not improve from 0.69981
Restoring model weights from the end of the best epoch
Epoch 00181: early stopping
{'val_loss': [40610.3573477057, 28042.507169699365, 23326.688587816454, 21287.206203026108, 16248.517998417721, 6049.165348101265, 5184.924310225475, 4983.712062401108, 4669.198279272152, 4441.122929440269, 4149.806581907635, 4207.631276577334, 4058.0898931962024, 4298.375482100475, 3745.7830671479433, 3682.533101142207, 3805.5676702185524, 3475.7924402937106, 3404.8135970876187, 3517.523918055281, 3321.6951178055774, 3213.9240042770966, 3604.382288679292, 3113.313595542425, 3258.484951357298, 3166.3386802190466, 3206.0303816010683, 3316.179506712322, 3056.0613689181173, 3184.2775940714005, 3167.774837445609, 3229.2507478738135, 3133.2858222285404, 3016.6910941208466, 3017.566199194027, 3885.26643622676, 3198.9579398239716, 3013.6150767652293, 3007.264850857892, 3106.763755315467, 2888.6784915199764, 2986.188739245451, 3008.0862156348894, 3036.1132240778284, 2708.8553605864317, 2837.6286327506923, 2859.3292869857596, 2769.7058259988135, 2679.388644061511, 2596.344191925435, 3005.7681838409812, 2681.7938587816457, 2518.377759716179, 2950.3320003461236, 2790.142043487935, 3176.192245290249, 2750.868596716772, 2860.9919449045688, 2955.4830430429192, 2921.678771200059, 2649.1052647844144, 2979.6409077704707, 2577.338958353936, 2604.140067185028, 2993.69833489913, 2675.522406855716, 3013.9183117830303, 2617.03866693038, 2953.3304675138447, 2868.9056999109966, 2631.3761449886274, 2646.210150996341, 2807.932437945016, 2869.223960393592, 2771.586272807061, 3378.1596432456486, 3160.115495512757, 2792.00956784019, 2773.8265921677216, 2637.5079762905457, 3015.1216021187697, 3818.6099621736553, 2560.181649896163, 3077.5071975128562, 2787.6151849287976, 2677.3641867335837, 2622.326840943928, 3020.8826672517803, 2843.0199978985365, 2875.9362020371836, 3003.8939626186707, 2660.3948001137264, 2756.3451653975476, 2629.331423988825, 2519.5084336679192, 2474.9505259839793, 2950.2331342093553, 2534.0545731556567, 2594.7760797814476, 2585.277886113034, 2564.50192067593, 2634.151441356804, 3036.7003220183938, 2455.21347161788, 2398.3301909241495, 2739.8450139685524, 2467.9283277294303, 2503.573098484474, 2503.554761669304, 2513.661078730716, 2474.9648561115505, 2730.7298862119264, 2824.8291726414163, 2451.9001897498024, 2528.022756069521, 2618.919977501978, 3068.0860333020173, 2589.9560763202135, 2617.006877657733, 2599.7115385803995, 2478.8444159785404, 2446.1083551720726, 2839.7842507664163, 2619.9577605814875, 2561.8982242632514, 2460.598153802413, 2906.800716351859, 2568.7219191925437, 2575.0408904643, 2365.8933136372625, 2568.702264327037, 2558.8776809112937, 2639.4121804539163, 2391.736346667326, 2709.1156237638447, 2463.7834627175635, 2593.4366872280457, 2533.4585718082476, 2517.8370005933543, 2551.3931096716774, 2656.5258835418313, 2737.7212624851663, 2608.0414096494264, 2583.3996736550635, 2609.8659652516812, 2493.62382565269, 2482.276773573477, 2456.9124616791933, 2448.785625988924, 2395.9258059731014, 2360.3748145767404, 2410.1086178550236, 2481.6028820955303, 2785.2116312920293, 2597.9528128708466, 2602.5900987069817, 2989.9382169699365, 2582.615685571598, 2639.316227007516, 2574.7306356309336, 2521.069110339201, 2482.399007676523, 2469.1857709281053, 2853.725341796875, 2596.6448897349683, 2408.6635077754154, 2514.7149333712423, 2361.469782189478, 2698.8611318853837, 2434.5013520446005, 2430.5581734572784, 2419.31588551968, 2800.2005939725077, 2606.90681090536, 2666.9941977971716, 2662.2286021558543, 2589.526455263548, 2549.2937676152096, 2856.8196387954904, 2403.475276898734, 2463.215276404272], 'val_acc': [0.8740430217754992, 0.8508535178401803, 0.8844419348089001, 0.8911559838282911, 0.8955696285525455, 0.9021726009211962, 0.9061571887776821, 0.9098086010051679, 0.9137719137759148, 0.9157786693754075, 0.919274900532976, 0.9216467624978174, 0.9232168899306769, 0.9230693095847021, 0.9270341418966462, 0.9268379015258595, 0.9269671945632258, 0.9304040911831434, 0.9315390783020213, 0.9310674441011646, 0.9324838662449317, 0.9341422160969505, 0.9333921520015861, 0.9363193859027911, 0.9365597812435295, 0.9360804995404014, 0.9367666991451119, 0.9355145436298998, 0.9395539383345013, 0.9362996009331715, 0.93741024294986, 0.9360409703435777, 0.9372596099406858, 0.941613927672181, 0.9389316665975354, 0.9385847788822802, 0.9388890726656853, 0.9400651213489001, 0.9400970860372616, 0.9398962319651737, 0.9419516641882402, 0.9405595818652382, 0.941583484033995, 0.9417782259892814, 0.9449868934063972, 0.9431611971010135, 0.9428447530239443, 0.9452136241936986, 0.9425876397120801, 0.9441927309277691, 0.941184890421131, 0.9440360182448279, 0.9464444306832326, 0.9431003513215463, 0.9423822330523141, 0.9400453356247914, 0.9474272637427608, 0.9439888649348971, 0.9451497234875643, 0.9435004856013045, 0.9452455511576012, 0.942494840561589, 0.9470955933196635, 0.948181918150262, 0.9450614640984354, 0.9463653141939188, 0.9442961812019348, 0.9462192443352712, 0.9440481760833836, 0.9456746012349672, 0.9477269951301285, 0.9480069521107252, 0.945370315750943, 0.945317073713375, 0.9468430522121961, 0.9431536122213436, 0.9430760175366945, 0.9458997898463961, 0.9468765002262743, 0.9455863410913492, 0.943667830545691, 0.9430851423287694, 0.94825646168069, 0.9427078026759473, 0.9442323008670083, 0.9475413696675361, 0.9479110935066319, 0.9465965628623962, 0.9458221762995177, 0.9458906401561785, 0.9483979434906682, 0.9492940427381781, 0.9460001716130897, 0.947305570674848, 0.9491267128835751, 0.9493381743189655, 0.9468384769898427, 0.9498022093048578, 0.9485957267918165, 0.9467897913123988, 0.9475900613808934, 0.9484420788439014, 0.9471047301835651, 0.9495390087743348, 0.950830694995349, 0.9476509109328065, 0.9514316712753682, 0.949823532677904, 0.9493686006039004, 0.9510999789720849, 0.950742474085168, 0.9503773179235337, 0.9480541031571883, 0.9519915505300595, 0.9492453698870502, 0.9510117610798606, 0.9458952289593371, 0.948760034162787, 0.9480206121372271, 0.9493199247348157, 0.9509280723861501, 0.95048687201512, 0.9475078982642934, 0.9502084330667423, 0.9508580693715736, 0.9519093783595894, 0.945187730125234, 0.949672870243652, 0.9499406678767144, 0.9514986125728752, 0.9495055328441572, 0.9496652891364279, 0.9478882400295402, 0.9518044160891183, 0.9482473285892342, 0.9512247579007209, 0.9494690472566629, 0.9507652694665933, 0.9515320522875725, 0.9494066676007041, 0.949193667007398, 0.9505918214592752, 0.9497900326040727, 0.9504366607605657, 0.9497428958929037, 0.9501673639575138, 0.9518652905391741, 0.9512856066981449, 0.9525651177273521, 0.9525012328654905, 0.9517542176608798, 0.9513571209545377, 0.951200389409367, 0.9481590842898888, 0.9517739724509323, 0.9523947088024284, 0.947240139864668, 0.9508778505687472, 0.9477391491962385, 0.9506283342083798, 0.9481210338918469, 0.9502738751942599, 0.9509721851047082, 0.9433529007283947, 0.9515503486500511, 0.9521619277664378, 0.9496881297872036, 0.9516279486161244, 0.9493853261199179, 0.9516918349869644, 0.9517633326445953, 0.9515275087537645, 0.9493168826344647, 0.9472279541100128, 0.9483035999008372, 0.9495557425897333, 0.9506253026708772, 0.9502768969234032, 0.9467030688177182, 0.9529272053815141, 0.9523125411588934], 'val_mDice': [0.12744452474237997, 0.20877737221838552, 0.2756170962430254, 0.3132320604746855, 0.33645634786992135, 0.41283718619165544, 0.460517401936688, 0.47584150184558915, 0.4994308812708794, 0.5166931763479982, 0.5400486158419259, 0.5414043046251128, 0.5536978810648375, 0.5409697369684147, 0.5758527705941019, 0.5799795449534549, 0.5738893437989151, 0.59806889295578, 0.6033251572258865, 0.5959771818752531, 0.6108240885070607, 0.6187370940099789, 0.5954103002065345, 0.6291769727875914, 0.6188908196702788, 0.6258582540705234, 0.625599867180933, 0.6172122102749499, 0.6374105343335792, 0.6279320731947694, 0.6318377603458453, 0.6278369223015218, 0.631627389901801, 0.64279827739619, 0.6415345631068265, 0.6059425737284407, 0.6300241260588924, 0.6438625334184381, 0.643256460564046, 0.6360183531724954, 0.6520368871809561, 0.6436497486090358, 0.644453569303585, 0.6481710491301138, 0.6660070630568492, 0.6581546302083172, 0.6556877214697343, 0.6587712598752372, 0.6677840193615684, 0.6731651674343061, 0.6432438372056696, 0.6703583062449588, 0.6803392760361298, 0.6503320298617399, 0.6612503392786919, 0.6339821928664099, 0.666154924827286, 0.6571733076361161, 0.6520452001426793, 0.6522306731984585, 0.6719208623789534, 0.6461570534525038, 0.6767213201221032, 0.6761653000795389, 0.6467497122438648, 0.6685281946689268, 0.6430947441089002, 0.6730638169035127, 0.6499883034561253, 0.655501975288874, 0.6733700127541264, 0.6728466749191284, 0.6584624104861971, 0.6527022349683544, 0.6677302657803402, 0.6238953124118757, 0.633665759352189, 0.6621548088291024, 0.6651042073587828, 0.6728471909897237, 0.6472520813157286, 0.6095044763782357, 0.6805587267573876, 0.6341209985032866, 0.6608229951013492, 0.6699589438076261, 0.6759583308726926, 0.6482840761353698, 0.6559228210509578, 0.6566042967989475, 0.6507633630233475, 0.6732075802887543, 0.6647923618932313, 0.6744218687467938, 0.6845985258681865, 0.6895600346070302, 0.6495794940598404, 0.6823590360110319, 0.6786835774590697, 0.6781017538867419, 0.679709108569954, 0.6748244558708577, 0.6489689003063154, 0.6893084615091735, 0.6944059646582301, 0.6664275791071639, 0.6887750384173815, 0.6865049842037733, 0.6870074475867839, 0.6825003427795217, 0.6888899765437162, 0.6678275405606137, 0.661068367807171, 0.6900753084617325, 0.6821123520030251, 0.6771513751790493, 0.6405381567870514, 0.6784063192862498, 0.677014752279354, 0.680452853818483, 0.6887629288661329, 0.6917851220203352, 0.6577704978894584, 0.676395988917049, 0.678649513027336, 0.6911725771578052, 0.6524305871770352, 0.680418273316154, 0.6801266051545928, 0.69898684568043, 0.6808394865144657, 0.6809763727308829, 0.6746053989929489, 0.6962366647358182, 0.6683029396624505, 0.6878934917570669, 0.6783001211625111, 0.6826852861839005, 0.6854787506634676, 0.6839746825302704, 0.6730555220495297, 0.66656648584559, 0.6759637096260167, 0.6781293508372729, 0.6775448216667658, 0.6873368673686739, 0.6884561550768116, 0.6900604933123046, 0.6902557068233248, 0.6952327912366842, 0.6998134534570235, 0.6971020442021044, 0.688840727262859, 0.6631800758687756, 0.6789110846157316, 0.6785120149201984, 0.6465937185891067, 0.6796019077301025, 0.6731843042977249, 0.681612945810149, 0.6848960224586197, 0.6887436003624638, 0.6896040665952465, 0.6543688925006722, 0.6792238000073011, 0.6960846532749224, 0.6847480626045903, 0.697390503521207, 0.67194810698304, 0.6922999929778183, 0.6924557617948025, 0.6948015916196606, 0.6631652818450445, 0.6776751370369634, 0.671310145643693, 0.6717883718164661, 0.6784331096878534, 0.6833074515378927, 0.653946024707601, 0.6959615289410458, 0.6892087701000745], 'loss': [38413.16305076386, 17146.188016143515, 14083.140468497066, 11808.676697938272, 10522.313708945645, 9112.45461454434, 7934.420713281882, 7277.769078537599, 6755.786252857364, 6293.073219067748, 5877.66490577812, 5499.827244176984, 5192.622999548671, 4958.023134176763, 4718.236924100819, 4561.242669556702, 4414.585852529973, 4286.123903293834, 4169.281909110526, 4057.35210443093, 3978.4042720756083, 3861.0888752892934, 3798.453948122439, 3725.4723889896236, 3679.2901266013887, 3603.3278074492237, 3525.4209497159236, 3488.9787102162427, 3418.5999868988074, 3388.147382933039, 3332.2461704700304, 3290.51241827069, 3243.375374065725, 3219.7481138629983, 3157.3261821998462, 3141.1552001261507, 3115.28478070224, 3061.028250558036, 3045.4800270540613, 3013.169867089093, 2989.7962778879532, 2950.046549545035, 2940.1173360987455, 2895.3964239079573, 2895.7019357160248, 2858.493091837977, 2824.6959081794125, 2823.359249422204, 2788.019566324837, 2784.729496139594, 2757.0483701760736, 2748.7513226671576, 2729.9860826999443, 2719.8744922052842, 2683.13167498846, 2683.3681342735895, 2663.472623694623, 2629.309576388845, 2616.8911722662574, 2613.894852802272, 2604.457701821599, 2583.5932530735436, 2553.9215045899623, 2557.5493470349807, 2537.6523057604936, 2533.9751394990485, 2509.1710982158666, 2498.535403157091, 2493.7836388433957, 2483.402262979073, 2460.389111199682, 2448.648241525524, 2432.3787357171313, 2410.8238931962323, 2418.4953022937166, 2397.3431280885616, 2400.267865936267, 2377.2728407337618, 2376.3263721967796, 2372.1193280036705, 2353.3250690924883, 2342.7041688963063, 2341.7141234314136, 2338.849373484372, 2336.9781201685646, 2314.521547213299, 2308.4024489745107, 2318.5722167672343, 2288.147627073664, 2280.666425358376, 2281.5676483932366, 2268.031091224612, 2277.155065853747, 2249.7379760989193, 2242.863138529995, 2247.6329708801786, 2228.9183239444747, 2227.692076525192, 2217.4148241179714, 2222.4956719627367, 2210.838328862856, 2200.4325725782355, 2193.3310282578695, 2188.057715298241, 2194.8375617613538, 2191.592032222215, 2178.6745518028665, 2164.4997864387046, 2154.267836838973, 2148.097474305459, 2143.37409971292, 2143.5986436313583, 2133.573474768249, 2138.860457626831, 2137.85275366122, 2132.9056381170008, 2135.163017319263, 2111.965853213685, 2124.975099039483, 2114.8587596589186, 2101.2722304316003, 2097.6911152276566, 2097.069300813262, 2091.6933763196043, 2096.706866151261, 2079.19674715963, 2083.333010578966, 2083.9770075552187, 2067.7114594728537, 2069.387791002583, 2066.606229083541, 2056.892072800343, 2059.6125727876965, 2042.267330674496, 2055.603298062209, 2046.643202457096, 2045.9472408256083, 2049.95195187021, 2036.9402042699217, 2026.0486772043992, 2037.1239470632777, 2028.6269526309882, 2017.5070710871105, 2024.4416429804483, 2007.1257828110772, 2010.3990511120403, 2021.0455354870403, 2019.6516091050719, 2011.1593442922274, 2005.1506384707134, 1999.9418347558237, 2007.617086326386, 1992.1325665315314, 1997.6852962134194, 1984.760901703906, 2002.152063645317, 1988.4633143883107, 1992.418228106188, 1980.1378505310033, 1982.5244296732724, 1972.7554262995673, 1958.1732166372103, 1968.8942778219534, 1975.4457377947472, 1965.5512568845484, 1960.3017710026147, 1971.898465411666, 1962.3774681816888, 1956.304388919276, 1948.8828739550663, 1950.5021316608597, 1959.13320983368, 1944.4829201352882, 1948.4184809414205, 1942.3741022817812, 1944.1775599394382, 1939.9647432680026, 1948.9061720449401, 1934.9579786658046, 1934.1044712908015, 1929.815003602334], 'acc': [0.846506066189175, 0.8479688827058459, 0.8620241559357452, 0.874140705091661, 0.8814308285134276, 0.8879558631689719, 0.8926314096226956, 0.8970754814746167, 0.9006152710466914, 0.9038329803475673, 0.9073645246506509, 0.910224508607209, 0.9125326647299208, 0.9146758542037695, 0.9165030911787952, 0.9180467270106644, 0.9196187115690092, 0.9206687973511456, 0.9216066969401052, 0.9228058163090208, 0.9235995241815096, 0.9248167195574855, 0.9253643982953651, 0.926270486926415, 0.9267802069371454, 0.9278891084889852, 0.9284870842602126, 0.9290996528453356, 0.9298380066247567, 0.9303467126087542, 0.9310718379923806, 0.93148546183172, 0.9318272736283846, 0.9323844488986056, 0.9330150511331377, 0.9333206558459107, 0.9336367631817288, 0.9342636105889784, 0.9346023896405302, 0.9349900390493007, 0.9352850940776518, 0.9355388868921249, 0.9359376677276151, 0.9364250682713483, 0.936553835024577, 0.9368526638157211, 0.937185331304659, 0.9373779279024965, 0.9378232665748936, 0.9378480398186977, 0.9382482963455491, 0.9383602086130495, 0.9386162556698814, 0.9388852605015003, 0.9391052384986321, 0.9392756943710416, 0.939544563445906, 0.9397893857492796, 0.9399400747338561, 0.9400802379385849, 0.940175204926394, 0.9404256294150914, 0.9407975779328448, 0.9406334840542196, 0.9409463803375457, 0.9409276260773888, 0.9411990041194392, 0.9414560617536053, 0.9413577528532484, 0.9414952267571916, 0.9418117675594065, 0.9419758429608331, 0.9420085689983885, 0.942271542544309, 0.9421933842351783, 0.9425287579341921, 0.9424992595448373, 0.9429323847165526, 0.9426618979219384, 0.9429188393620237, 0.9430203236630454, 0.9432245420328956, 0.9432454161053484, 0.9433772156519332, 0.943273549087614, 0.9434702351044084, 0.9437726271485375, 0.9436132006923085, 0.9437688736238252, 0.9439576959764364, 0.9440669083537384, 0.9441047864180255, 0.944094242836386, 0.9443095712370353, 0.9443321952159855, 0.9443132428686805, 0.9445706929141623, 0.9444943658015545, 0.9446618463384242, 0.9445938076967172, 0.9448175155552039, 0.944921767214733, 0.944866878404544, 0.945026267230969, 0.9450131887272272, 0.9449920401260564, 0.9452159837738602, 0.9452790024790962, 0.9453558004225666, 0.9453953343429627, 0.9454552623387147, 0.9454796219923776, 0.9456544953866894, 0.9455212012373547, 0.945677239467431, 0.9456709956698262, 0.9456652392746706, 0.9458738296488334, 0.9457157824455317, 0.9458870166759653, 0.9460202541393773, 0.9459184208219228, 0.9460806695858219, 0.9461085294866697, 0.9459724543742061, 0.9462810348325874, 0.946262683428429, 0.9461226396500847, 0.9462855874358378, 0.9462957982108063, 0.9463532954418239, 0.9463876552641609, 0.9463441319332485, 0.9465911470652109, 0.946521183948486, 0.946615839284328, 0.9466857678347008, 0.9466403357319773, 0.9466198284536275, 0.9468676040935786, 0.9466960977224723, 0.9467595619066965, 0.9469369285891096, 0.9468610095910243, 0.9470036449532719, 0.9469527463254924, 0.9469128432953131, 0.9469383930156512, 0.9469914268453514, 0.9471123516438993, 0.9472113061124909, 0.9470141331756805, 0.9471837340796443, 0.947107328595733, 0.947343373313118, 0.9471738307353506, 0.9472726710119599, 0.9472499840754529, 0.9472158967797354, 0.947410789736366, 0.9473064876384264, 0.9474885403410427, 0.9473578336749275, 0.947356625902947, 0.9474389822750331, 0.947470038490033, 0.9473834378861166, 0.9474382654272656, 0.9475157966453601, 0.9476587455893084, 0.9475860168990795, 0.9476681775720628, 0.9476944299083835, 0.9477100512943785, 0.9476895844439465, 0.9476567601829539, 0.9476522269252822, 0.9476780272456423, 0.9477782071191547, 0.9477770810231464, 0.9477414511225571], 'mDice': [0.07066890128780019, 0.14828366352353006, 0.19857959885290402, 0.24812170687063365, 0.28536825980169483, 0.32575545398776995, 0.36505619167847364, 0.3945214450479953, 0.4199320542238252, 0.44468069400974536, 0.4684321465930298, 0.4907355797237734, 0.5097888970317169, 0.5251564498567137, 0.5408287945183508, 0.5520115015671737, 0.5624579633840517, 0.571682697749244, 0.58019735725338, 0.5884569120619375, 0.5946322023410249, 0.6038073063716866, 0.6083851445304966, 0.6142855962487379, 0.6179748546107487, 0.6242507518133814, 0.6302532884380876, 0.6335508756336535, 0.6390642403880867, 0.6416811601732579, 0.646369283520611, 0.6498429662589842, 0.6535515619018983, 0.6558193279055631, 0.6608921186203225, 0.662424244049926, 0.6646235504405116, 0.6692072585834178, 0.6707518184681934, 0.6732941489140546, 0.675602884680479, 0.6787699674701266, 0.6798607100122421, 0.6838778618712601, 0.6838668147738961, 0.6869318010545559, 0.6898868623314383, 0.6902135004644112, 0.6932600011520663, 0.6936155077852444, 0.6959069276907723, 0.6969179436534293, 0.6984386856331125, 0.6995371473988556, 0.7027095752127109, 0.7029002849894562, 0.7045777796830595, 0.7075983941530901, 0.7087162842107948, 0.7090457909409211, 0.709823397285588, 0.7117427395259451, 0.7144034924848705, 0.7140785994581826, 0.7159883946071796, 0.7162889435628029, 0.7185875245888964, 0.7194628242006769, 0.7199774461446721, 0.7209926123852577, 0.7231464516725775, 0.7242139950786608, 0.7256548561002021, 0.7276114958686319, 0.7269166177798263, 0.7289191490722928, 0.7286818781539719, 0.7308953982622988, 0.7309055094388949, 0.7314854664920265, 0.7330591367208634, 0.7341633371282135, 0.7343093083484701, 0.7346086243732117, 0.7348395016259965, 0.7368419118518049, 0.7375621476765829, 0.7364058975553956, 0.7393495421426974, 0.7401190132614284, 0.740040610889248, 0.7412489117856259, 0.7405707672123772, 0.7430546071692451, 0.7436464456641592, 0.7431588953007382, 0.7450438287758914, 0.7450976290957545, 0.7461892571925924, 0.745625704611327, 0.7468391592229536, 0.7478110049717439, 0.7484383114384814, 0.7489933130085975, 0.7483775408728216, 0.7486818445592407, 0.7499531375064101, 0.7513389800879117, 0.7523007791373277, 0.7529404406748239, 0.7534208757488509, 0.7533983239178135, 0.7543502380760128, 0.7537938617637214, 0.7539647710270266, 0.7544997943793651, 0.7542312374147796, 0.7564593582247877, 0.7552170179383275, 0.7562045363557817, 0.7575265095331368, 0.7578923240310024, 0.7579972646536494, 0.758540316879484, 0.7579678563828509, 0.7596995619230066, 0.7593007149458992, 0.7591489145312894, 0.7608154582523807, 0.7606442606627628, 0.7609198503000251, 0.7618599329241756, 0.761602462230545, 0.7633206535572468, 0.7620192162906627, 0.7630771890385148, 0.7630668102319981, 0.7625829359144877, 0.7638064554373487, 0.7649775777013618, 0.7639374587276309, 0.7646606601427943, 0.7658278149470102, 0.7652099751017442, 0.7667965623638688, 0.7664741993143412, 0.7654769657981005, 0.7655995912466972, 0.7664191220656719, 0.7670957421735441, 0.7675740825941765, 0.766800319699805, 0.7683834705648033, 0.7677999319503395, 0.7690795440752948, 0.7673765279801931, 0.7687699174359953, 0.7683077149427839, 0.7694313082797283, 0.7693971528402952, 0.7703198654745234, 0.7717714492052202, 0.7706029799388807, 0.7700522673945348, 0.77104068998864, 0.7714985571183545, 0.7703856919661846, 0.7712949997787291, 0.7719569906007419, 0.7726242501983658, 0.772576401900396, 0.7716415282059951, 0.7731215358504107, 0.7727651320358656, 0.7733482856443661, 0.7731715046602046, 0.7735678253266456, 0.772743010028853, 0.7740588295754032, 0.7741725810719424, 0.7745861994597846]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:44, 14.70s/it]predicting test subjects:  50%|█████     | 2/4 [00:27<00:28, 14.15s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:41<00:14, 14.10s/it]predicting test subjects: 100%|██████████| 4/4 [00:55<00:00, 13.95s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:20<1:48:17, 20.96s/it]predicting train subjects:   1%|          | 2/311 [00:30<1:30:16, 17.53s/it]predicting train subjects:   1%|          | 3/311 [00:42<1:21:35, 15.89s/it]predicting train subjects:   1%|▏         | 4/311 [00:54<1:15:18, 14.72s/it]predicting train subjects:   2%|▏         | 5/311 [01:05<1:09:14, 13.58s/it]predicting train subjects:   2%|▏         | 6/311 [01:15<1:04:16, 12.64s/it]predicting train subjects:   2%|▏         | 7/311 [01:28<1:04:35, 12.75s/it]predicting train subjects:   3%|▎         | 8/311 [01:43<1:07:06, 13.29s/it]predicting train subjects:   3%|▎         | 9/311 [01:56<1:07:14, 13.36s/it]predicting train subjects:   3%|▎         | 10/311 [02:08<1:04:02, 12.77s/it]predicting train subjects:   4%|▎         | 11/311 [02:22<1:05:57, 13.19s/it]predicting train subjects:   4%|▍         | 12/311 [02:33<1:03:02, 12.65s/it]predicting train subjects:   4%|▍         | 13/311 [02:45<1:01:42, 12.42s/it]predicting train subjects:   5%|▍         | 14/311 [03:00<1:05:06, 13.15s/it]predicting train subjects:   5%|▍         | 15/311 [03:21<1:16:03, 15.42s/it]predicting train subjects:   5%|▌         | 16/311 [03:42<1:23:43, 17.03s/it]predicting train subjects:   5%|▌         | 17/311 [04:02<1:28:46, 18.12s/it]predicting train subjects:   6%|▌         | 18/311 [04:23<1:31:45, 18.79s/it]predicting train subjects:   6%|▌         | 19/311 [04:44<1:34:39, 19.45s/it]predicting train subjects:   6%|▋         | 20/311 [05:04<1:35:57, 19.79s/it]predicting train subjects:   7%|▋         | 21/311 [05:25<1:37:23, 20.15s/it]predicting train subjects:   7%|▋         | 22/311 [05:46<1:37:39, 20.27s/it]predicting train subjects:   7%|▋         | 23/311 [06:06<1:37:46, 20.37s/it]predicting train subjects:   8%|▊         | 24/311 [06:28<1:39:06, 20.72s/it]predicting train subjects:   8%|▊         | 25/311 [06:49<1:39:53, 20.96s/it]predicting train subjects:   8%|▊         | 26/311 [07:10<1:39:22, 20.92s/it]predicting train subjects:   9%|▊         | 27/311 [07:31<1:38:31, 20.82s/it]predicting train subjects:   9%|▉         | 28/311 [07:52<1:38:31, 20.89s/it]predicting train subjects:   9%|▉         | 29/311 [08:12<1:37:29, 20.74s/it]predicting train subjects:  10%|▉         | 30/311 [08:33<1:37:08, 20.74s/it]predicting train subjects:  10%|▉         | 31/311 [08:54<1:36:52, 20.76s/it]predicting train subjects:  10%|█         | 32/311 [09:15<1:36:23, 20.73s/it]predicting train subjects:  11%|█         | 33/311 [09:24<1:20:48, 17.44s/it]predicting train subjects:  11%|█         | 34/311 [09:34<1:10:10, 15.20s/it]predicting train subjects:  11%|█▏        | 35/311 [09:45<1:03:06, 13.72s/it]predicting train subjects:  12%|█▏        | 36/311 [09:54<56:57, 12.43s/it]  predicting train subjects:  12%|█▏        | 37/311 [10:04<53:05, 11.62s/it]predicting train subjects:  12%|█▏        | 38/311 [10:13<50:07, 11.02s/it]predicting train subjects:  13%|█▎        | 39/311 [10:23<47:33, 10.49s/it]predicting train subjects:  13%|█▎        | 40/311 [10:32<46:25, 10.28s/it]predicting train subjects:  13%|█▎        | 41/311 [10:42<45:12, 10.05s/it]predicting train subjects:  14%|█▎        | 42/311 [10:52<44:38,  9.96s/it]predicting train subjects:  14%|█▍        | 43/311 [11:02<44:28,  9.96s/it]predicting train subjects:  14%|█▍        | 44/311 [11:11<43:32,  9.78s/it]predicting train subjects:  14%|█▍        | 45/311 [11:21<43:19,  9.77s/it]predicting train subjects:  15%|█▍        | 46/311 [11:31<43:24,  9.83s/it]predicting train subjects:  15%|█▌        | 47/311 [11:41<43:29,  9.89s/it]predicting train subjects:  15%|█▌        | 48/311 [11:50<42:46,  9.76s/it]predicting train subjects:  16%|█▌        | 49/311 [12:00<42:40,  9.77s/it]predicting train subjects:  16%|█▌        | 50/311 [12:09<41:58,  9.65s/it]predicting train subjects:  16%|█▋        | 51/311 [12:22<46:11, 10.66s/it]predicting train subjects:  17%|█▋        | 52/311 [12:35<48:15, 11.18s/it]predicting train subjects:  17%|█▋        | 53/311 [12:47<49:37, 11.54s/it]predicting train subjects:  17%|█▋        | 54/311 [13:00<50:40, 11.83s/it]predicting train subjects:  18%|█▊        | 55/311 [13:12<51:16, 12.02s/it]predicting train subjects:  18%|█▊        | 56/311 [13:24<51:32, 12.13s/it]predicting train subjects:  18%|█▊        | 57/311 [13:37<51:35, 12.19s/it]predicting train subjects:  19%|█▊        | 58/311 [13:49<51:25, 12.19s/it]predicting train subjects:  19%|█▉        | 59/311 [14:01<51:27, 12.25s/it]predicting train subjects:  19%|█▉        | 60/311 [14:14<51:12, 12.24s/it]predicting train subjects:  20%|█▉        | 61/311 [14:26<51:17, 12.31s/it]predicting train subjects:  20%|█▉        | 62/311 [14:39<52:02, 12.54s/it]predicting train subjects:  20%|██        | 63/311 [14:52<51:52, 12.55s/it]predicting train subjects:  21%|██        | 64/311 [15:04<51:24, 12.49s/it]predicting train subjects:  21%|██        | 65/311 [15:16<51:08, 12.47s/it]predicting train subjects:  21%|██        | 66/311 [15:29<50:31, 12.37s/it]predicting train subjects:  22%|██▏       | 67/311 [15:40<49:31, 12.18s/it]predicting train subjects:  22%|██▏       | 68/311 [15:53<49:20, 12.18s/it]predicting train subjects:  22%|██▏       | 69/311 [16:05<49:35, 12.29s/it]predicting train subjects:  23%|██▎       | 70/311 [16:17<49:09, 12.24s/it]predicting train subjects:  23%|██▎       | 71/311 [16:29<48:21, 12.09s/it]predicting train subjects:  23%|██▎       | 72/311 [16:41<47:59, 12.05s/it]predicting train subjects:  23%|██▎       | 73/311 [16:53<47:58, 12.09s/it]predicting train subjects:  24%|██▍       | 74/311 [17:05<47:54, 12.13s/it]predicting train subjects:  24%|██▍       | 75/311 [17:17<47:44, 12.14s/it]predicting train subjects:  24%|██▍       | 76/311 [17:30<47:26, 12.11s/it]predicting train subjects:  25%|██▍       | 77/311 [17:42<47:38, 12.22s/it]predicting train subjects:  25%|██▌       | 78/311 [17:54<47:39, 12.27s/it]predicting train subjects:  25%|██▌       | 79/311 [18:07<47:26, 12.27s/it]predicting train subjects:  26%|██▌       | 80/311 [18:18<46:45, 12.14s/it]predicting train subjects:  26%|██▌       | 81/311 [18:31<46:51, 12.23s/it]predicting train subjects:  26%|██▋       | 82/311 [18:43<46:59, 12.31s/it]predicting train subjects:  27%|██▋       | 83/311 [18:55<46:12, 12.16s/it]predicting train subjects:  27%|██▋       | 84/311 [19:07<45:32, 12.04s/it]predicting train subjects:  27%|██▋       | 85/311 [19:18<44:24, 11.79s/it]predicting train subjects:  28%|██▊       | 86/311 [19:29<43:34, 11.62s/it]predicting train subjects:  28%|██▊       | 87/311 [19:40<42:21, 11.35s/it]predicting train subjects:  28%|██▊       | 88/311 [19:51<41:57, 11.29s/it]predicting train subjects:  29%|██▊       | 89/311 [20:02<41:38, 11.25s/it]predicting train subjects:  29%|██▉       | 90/311 [20:13<40:46, 11.07s/it]predicting train subjects:  29%|██▉       | 91/311 [20:24<40:19, 11.00s/it]predicting train subjects:  30%|██▉       | 92/311 [20:35<40:13, 11.02s/it]predicting train subjects:  30%|██▉       | 93/311 [20:46<39:46, 10.95s/it]predicting train subjects:  30%|███       | 94/311 [20:57<39:51, 11.02s/it]predicting train subjects:  31%|███       | 95/311 [21:08<39:52, 11.07s/it]predicting train subjects:  31%|███       | 96/311 [21:19<39:19, 10.97s/it]predicting train subjects:  31%|███       | 97/311 [21:30<39:16, 11.01s/it]predicting train subjects:  32%|███▏      | 98/311 [21:41<39:20, 11.08s/it]predicting train subjects:  32%|███▏      | 99/311 [21:52<38:53, 11.01s/it]predicting train subjects:  32%|███▏      | 100/311 [22:03<38:14, 10.87s/it]predicting train subjects:  32%|███▏      | 101/311 [22:14<38:14, 10.93s/it]predicting train subjects:  33%|███▎      | 102/311 [22:25<38:23, 11.02s/it]predicting train subjects:  33%|███▎      | 103/311 [22:36<38:07, 11.00s/it]predicting train subjects:  33%|███▎      | 104/311 [22:47<37:54, 10.99s/it]predicting train subjects:  34%|███▍      | 105/311 [22:58<37:52, 11.03s/it]predicting train subjects:  34%|███▍      | 106/311 [23:09<37:48, 11.06s/it]predicting train subjects:  34%|███▍      | 107/311 [23:20<37:49, 11.12s/it]predicting train subjects:  35%|███▍      | 108/311 [23:31<37:29, 11.08s/it]predicting train subjects:  35%|███▌      | 109/311 [23:42<36:52, 10.95s/it]predicting train subjects:  35%|███▌      | 110/311 [23:53<36:58, 11.04s/it]predicting train subjects:  36%|███▌      | 111/311 [24:04<36:59, 11.10s/it]predicting train subjects:  36%|███▌      | 112/311 [24:16<36:57, 11.15s/it]predicting train subjects:  36%|███▋      | 113/311 [24:27<36:45, 11.14s/it]predicting train subjects:  37%|███▋      | 114/311 [24:48<45:57, 14.00s/it]predicting train subjects:  37%|███▋      | 115/311 [25:08<52:17, 16.01s/it]predicting train subjects:  37%|███▋      | 116/311 [25:29<56:13, 17.30s/it]predicting train subjects:  38%|███▊      | 117/311 [25:49<58:54, 18.22s/it]predicting train subjects:  38%|███▊      | 118/311 [26:09<1:00:43, 18.88s/it]predicting train subjects:  38%|███▊      | 119/311 [26:30<1:01:43, 19.29s/it]predicting train subjects:  39%|███▊      | 120/311 [26:50<1:02:35, 19.66s/it]predicting train subjects:  39%|███▉      | 121/311 [27:11<1:03:20, 20.00s/it]predicting train subjects:  39%|███▉      | 122/311 [27:31<1:03:13, 20.07s/it]predicting train subjects:  40%|███▉      | 123/311 [27:51<1:03:07, 20.15s/it]predicting train subjects:  40%|███▉      | 124/311 [28:13<1:03:38, 20.42s/it]predicting train subjects:  40%|████      | 125/311 [28:34<1:04:04, 20.67s/it]predicting train subjects:  41%|████      | 126/311 [28:55<1:03:56, 20.74s/it]predicting train subjects:  41%|████      | 127/311 [29:16<1:04:02, 20.88s/it]predicting train subjects:  41%|████      | 128/311 [29:37<1:03:53, 20.95s/it]predicting train subjects:  41%|████▏     | 129/311 [29:58<1:03:59, 21.10s/it]predicting train subjects:  42%|████▏     | 130/311 [30:19<1:03:23, 21.01s/it]predicting train subjects:  42%|████▏     | 131/311 [30:40<1:03:10, 21.06s/it]predicting train subjects:  42%|████▏     | 132/311 [30:50<52:44, 17.68s/it]  predicting train subjects:  43%|████▎     | 133/311 [31:00<45:41, 15.40s/it]predicting train subjects:  43%|████▎     | 134/311 [31:10<40:14, 13.64s/it]predicting train subjects:  43%|████▎     | 135/311 [31:19<36:29, 12.44s/it]predicting train subjects:  44%|████▎     | 136/311 [31:30<34:12, 11.73s/it]predicting train subjects:  44%|████▍     | 137/311 [31:39<32:03, 11.06s/it]predicting train subjects:  44%|████▍     | 138/311 [31:49<30:43, 10.65s/it]predicting train subjects:  45%|████▍     | 139/311 [31:59<30:00, 10.47s/it]predicting train subjects:  45%|████▌     | 140/311 [32:08<29:01, 10.18s/it]predicting train subjects:  45%|████▌     | 141/311 [32:18<28:32, 10.07s/it]predicting train subjects:  46%|████▌     | 142/311 [32:28<28:19, 10.06s/it]predicting train subjects:  46%|████▌     | 143/311 [32:38<28:16, 10.10s/it]predicting train subjects:  46%|████▋     | 144/311 [32:48<27:46,  9.98s/it]predicting train subjects:  47%|████▋     | 145/311 [32:58<27:31,  9.95s/it]predicting train subjects:  47%|████▋     | 146/311 [33:08<27:21,  9.95s/it]predicting train subjects:  47%|████▋     | 147/311 [33:17<26:34,  9.72s/it]predicting train subjects:  48%|████▊     | 148/311 [33:27<26:30,  9.76s/it]predicting train subjects:  48%|████▊     | 149/311 [33:37<26:58,  9.99s/it]predicting train subjects:  48%|████▊     | 150/311 [33:50<28:39, 10.68s/it]predicting train subjects:  49%|████▊     | 151/311 [34:02<29:44, 11.15s/it]predicting train subjects:  49%|████▉     | 152/311 [34:14<30:30, 11.51s/it]predicting train subjects:  49%|████▉     | 153/311 [34:27<31:04, 11.80s/it]predicting train subjects:  50%|████▉     | 154/311 [34:39<31:32, 12.06s/it]predicting train subjects:  50%|████▉     | 155/311 [34:52<31:42, 12.19s/it]predicting train subjects:  50%|█████     | 156/311 [35:05<31:58, 12.38s/it]predicting train subjects:  50%|█████     | 157/311 [35:17<31:50, 12.41s/it]predicting train subjects:  51%|█████     | 158/311 [35:29<31:21, 12.30s/it]predicting train subjects:  51%|█████     | 159/311 [35:41<31:04, 12.26s/it]predicting train subjects:  51%|█████▏    | 160/311 [35:55<31:43, 12.60s/it]predicting train subjects:  52%|█████▏    | 161/311 [36:07<31:28, 12.59s/it]predicting train subjects:  52%|█████▏    | 162/311 [36:20<31:12, 12.56s/it]predicting train subjects:  52%|█████▏    | 163/311 [36:33<31:32, 12.79s/it]predicting train subjects:  53%|█████▎    | 164/311 [36:45<30:50, 12.59s/it]predicting train subjects:  53%|█████▎    | 165/311 [36:58<30:19, 12.46s/it]predicting train subjects:  53%|█████▎    | 166/311 [37:09<29:37, 12.26s/it]predicting train subjects:  54%|█████▎    | 167/311 [37:21<29:15, 12.19s/it]predicting train subjects:  54%|█████▍    | 168/311 [37:34<29:02, 12.18s/it]predicting train subjects:  54%|█████▍    | 169/311 [37:46<28:47, 12.16s/it]predicting train subjects:  55%|█████▍    | 170/311 [37:58<28:32, 12.15s/it]predicting train subjects:  55%|█████▍    | 171/311 [38:09<28:03, 12.03s/it]predicting train subjects:  55%|█████▌    | 172/311 [38:21<27:39, 11.94s/it]predicting train subjects:  56%|█████▌    | 173/311 [38:33<27:29, 11.95s/it]predicting train subjects:  56%|█████▌    | 174/311 [38:45<27:20, 11.97s/it]predicting train subjects:  56%|█████▋    | 175/311 [38:57<27:19, 12.05s/it]predicting train subjects:  57%|█████▋    | 176/311 [39:09<26:55, 11.97s/it]predicting train subjects:  57%|█████▋    | 177/311 [39:21<26:28, 11.85s/it]predicting train subjects:  57%|█████▋    | 178/311 [39:32<26:06, 11.78s/it]predicting train subjects:  58%|█████▊    | 179/311 [39:44<26:05, 11.86s/it]predicting train subjects:  58%|█████▊    | 180/311 [39:56<25:54, 11.87s/it]predicting train subjects:  58%|█████▊    | 181/311 [40:08<25:37, 11.83s/it]predicting train subjects:  59%|█████▊    | 182/311 [40:20<25:28, 11.85s/it]predicting train subjects:  59%|█████▉    | 183/311 [40:32<25:32, 11.97s/it]predicting train subjects:  59%|█████▉    | 184/311 [40:43<24:51, 11.74s/it]predicting train subjects:  59%|█████▉    | 185/311 [40:54<24:07, 11.49s/it]predicting train subjects:  60%|█████▉    | 186/311 [41:05<23:26, 11.25s/it]predicting train subjects:  60%|██████    | 187/311 [41:16<23:10, 11.21s/it]predicting train subjects:  60%|██████    | 188/311 [41:27<22:56, 11.20s/it]predicting train subjects:  61%|██████    | 189/311 [41:38<22:33, 11.09s/it]predicting train subjects:  61%|██████    | 190/311 [41:49<22:15, 11.03s/it]predicting train subjects:  61%|██████▏   | 191/311 [42:00<22:08, 11.07s/it]predicting train subjects:  62%|██████▏   | 192/311 [42:11<21:53, 11.04s/it]predicting train subjects:  62%|██████▏   | 193/311 [42:22<21:36, 10.99s/it]predicting train subjects:  62%|██████▏   | 194/311 [42:33<21:14, 10.90s/it]predicting train subjects:  63%|██████▎   | 195/311 [42:44<21:14, 10.99s/it]predicting train subjects:  63%|██████▎   | 196/311 [42:55<21:08, 11.03s/it]predicting train subjects:  63%|██████▎   | 197/311 [43:06<20:52, 10.98s/it]predicting train subjects:  64%|██████▎   | 198/311 [43:17<20:31, 10.90s/it]predicting train subjects:  64%|██████▍   | 199/311 [43:28<20:38, 11.06s/it]predicting train subjects:  64%|██████▍   | 200/311 [43:39<20:32, 11.10s/it]predicting train subjects:  65%|██████▍   | 201/311 [43:50<20:22, 11.11s/it]predicting train subjects:  65%|██████▍   | 202/311 [44:01<20:00, 11.02s/it]predicting train subjects:  65%|██████▌   | 203/311 [44:12<19:52, 11.04s/it]predicting train subjects:  66%|██████▌   | 204/311 [44:24<19:46, 11.09s/it]predicting train subjects:  66%|██████▌   | 205/311 [44:35<19:46, 11.19s/it]predicting train subjects:  66%|██████▌   | 206/311 [44:46<19:27, 11.12s/it]predicting train subjects:  67%|██████▋   | 207/311 [44:57<19:08, 11.04s/it]predicting train subjects:  67%|██████▋   | 208/311 [45:08<19:01, 11.08s/it]predicting train subjects:  67%|██████▋   | 209/311 [45:19<18:51, 11.09s/it]predicting train subjects:  68%|██████▊   | 210/311 [45:30<18:44, 11.14s/it]predicting train subjects:  68%|██████▊   | 211/311 [45:41<18:25, 11.05s/it]predicting train subjects:  68%|██████▊   | 212/311 [45:52<18:09, 11.01s/it]predicting train subjects:  68%|██████▊   | 213/311 [46:13<22:55, 14.04s/it]predicting train subjects:  69%|██████▉   | 214/311 [46:34<26:01, 16.10s/it]predicting train subjects:  69%|██████▉   | 215/311 [46:55<27:55, 17.45s/it]predicting train subjects:  69%|██████▉   | 216/311 [47:16<29:16, 18.49s/it]predicting train subjects:  70%|██████▉   | 217/311 [47:36<29:49, 19.04s/it]predicting train subjects:  70%|███████   | 218/311 [47:57<30:33, 19.71s/it]predicting train subjects:  70%|███████   | 219/311 [48:18<30:45, 20.06s/it]predicting train subjects:  71%|███████   | 220/311 [48:39<30:59, 20.43s/it]predicting train subjects:  71%|███████   | 221/311 [49:00<30:39, 20.44s/it]predicting train subjects:  71%|███████▏  | 222/311 [49:21<30:37, 20.65s/it]predicting train subjects:  72%|███████▏  | 223/311 [49:42<30:14, 20.62s/it]predicting train subjects:  72%|███████▏  | 224/311 [50:03<30:08, 20.79s/it]predicting train subjects:  72%|███████▏  | 225/311 [50:23<29:44, 20.75s/it]predicting train subjects:  73%|███████▎  | 226/311 [50:44<29:18, 20.69s/it]predicting train subjects:  73%|███████▎  | 227/311 [51:05<29:09, 20.83s/it]predicting train subjects:  73%|███████▎  | 228/311 [51:25<28:39, 20.71s/it]predicting train subjects:  74%|███████▎  | 229/311 [51:47<28:29, 20.85s/it]predicting train subjects:  74%|███████▍  | 230/311 [52:08<28:09, 20.86s/it]predicting train subjects:  74%|███████▍  | 231/311 [52:17<23:20, 17.51s/it]predicting train subjects:  75%|███████▍  | 232/311 [52:27<20:08, 15.30s/it]predicting train subjects:  75%|███████▍  | 233/311 [52:38<17:54, 13.78s/it]predicting train subjects:  75%|███████▌  | 234/311 [52:47<16:05, 12.54s/it]predicting train subjects:  76%|███████▌  | 235/311 [52:58<15:01, 11.86s/it]predicting train subjects:  76%|███████▌  | 236/311 [53:08<14:16, 11.42s/it]predicting train subjects:  76%|███████▌  | 237/311 [53:18<13:24, 10.87s/it]predicting train subjects:  77%|███████▋  | 238/311 [53:28<13:06, 10.78s/it]predicting train subjects:  77%|███████▋  | 239/311 [53:38<12:47, 10.67s/it]predicting train subjects:  77%|███████▋  | 240/311 [53:48<12:21, 10.45s/it]predicting train subjects:  77%|███████▋  | 241/311 [53:59<12:11, 10.45s/it]predicting train subjects:  78%|███████▊  | 242/311 [54:09<11:52, 10.33s/it]predicting train subjects:  78%|███████▊  | 243/311 [54:19<11:31, 10.16s/it]predicting train subjects:  78%|███████▊  | 244/311 [54:29<11:20, 10.15s/it]predicting train subjects:  79%|███████▉  | 245/311 [54:39<11:01, 10.02s/it]predicting train subjects:  79%|███████▉  | 246/311 [54:49<10:54, 10.07s/it]predicting train subjects:  79%|███████▉  | 247/311 [54:59<10:47, 10.11s/it]predicting train subjects:  80%|███████▉  | 248/311 [55:09<10:31, 10.03s/it]predicting train subjects:  80%|████████  | 249/311 [55:22<11:18, 10.95s/it]predicting train subjects:  80%|████████  | 250/311 [55:35<11:51, 11.67s/it]predicting train subjects:  81%|████████  | 251/311 [55:48<12:03, 12.06s/it]predicting train subjects:  81%|████████  | 252/311 [56:01<12:01, 12.23s/it]predicting train subjects:  81%|████████▏ | 253/311 [56:13<11:56, 12.35s/it]predicting train subjects:  82%|████████▏ | 254/311 [56:26<11:55, 12.54s/it]predicting train subjects:  82%|████████▏ | 255/311 [56:39<11:49, 12.66s/it]predicting train subjects:  82%|████████▏ | 256/311 [56:52<11:37, 12.68s/it]predicting train subjects:  83%|████████▎ | 257/311 [57:05<11:25, 12.69s/it]predicting train subjects:  83%|████████▎ | 258/311 [57:17<11:07, 12.60s/it]predicting train subjects:  83%|████████▎ | 259/311 [57:30<11:02, 12.74s/it]predicting train subjects:  84%|████████▎ | 260/311 [57:43<10:53, 12.81s/it]predicting train subjects:  84%|████████▍ | 261/311 [57:56<10:42, 12.86s/it]predicting train subjects:  84%|████████▍ | 262/311 [58:09<10:27, 12.81s/it]predicting train subjects:  85%|████████▍ | 263/311 [58:22<10:12, 12.76s/it]predicting train subjects:  85%|████████▍ | 264/311 [58:34<09:54, 12.66s/it]predicting train subjects:  85%|████████▌ | 265/311 [58:46<09:39, 12.61s/it]predicting train subjects:  86%|████████▌ | 266/311 [58:59<09:26, 12.59s/it]predicting train subjects:  86%|████████▌ | 267/311 [59:11<09:07, 12.44s/it]predicting train subjects:  86%|████████▌ | 268/311 [59:23<08:44, 12.20s/it]predicting train subjects:  86%|████████▋ | 269/311 [59:35<08:29, 12.14s/it]predicting train subjects:  87%|████████▋ | 270/311 [59:47<08:22, 12.26s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:00:00<08:12, 12.30s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:00:12<08:02, 12.38s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:00:24<07:41, 12.14s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:00:36<07:29, 12.15s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:00:48<07:20, 12.23s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:01:01<07:07, 12.22s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:01:13<06:54, 12.20s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:01:25<06:40, 12.15s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:01:37<06:29, 12.17s/it]predicting train subjects:  90%|█████████ | 280/311 [1:01:49<06:17, 12.19s/it]predicting train subjects:  90%|█████████ | 281/311 [1:02:01<06:04, 12.16s/it]predicting train subjects:  91%|█████████ | 282/311 [1:02:14<05:53, 12.18s/it]predicting train subjects:  91%|█████████ | 283/311 [1:02:24<05:30, 11.79s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:02:35<05:11, 11.54s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:02:46<04:55, 11.38s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:02:57<04:41, 11.28s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:03:08<04:27, 11.16s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:03:20<04:16, 11.17s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:03:31<04:07, 11.25s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:03:42<03:53, 11.10s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:03:52<03:39, 10.95s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:04:03<03:28, 10.97s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:04:14<03:18, 11.00s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:04:25<03:06, 10.98s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:04:36<02:54, 10.91s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:04:47<02:44, 11.00s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:04:58<02:34, 11.02s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:05:09<02:22, 10.98s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:05:20<02:11, 10.98s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:05:31<02:01, 11.04s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:05:42<01:50, 11.01s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:05:53<01:38, 10.90s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:06:04<01:28, 11.01s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:06:16<01:17, 11.09s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:06:26<01:05, 10.97s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:06:37<00:54, 10.96s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:06:49<00:44, 11.10s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:07:00<00:33, 11.10s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:07:11<00:22, 11.02s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:07:22<00:11, 11.10s/it]predicting train subjects: 100%|██████████| 311/311 [1:07:34<00:00, 11.54s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:30:29, 17.51s/it]Loading train:   1%|          | 2/311 [00:26<1:16:31, 14.86s/it]Loading train:   1%|          | 3/311 [00:36<1:09:59, 13.63s/it]Loading train:   1%|▏         | 4/311 [00:48<1:07:07, 13.12s/it]Loading train:   2%|▏         | 5/311 [01:00<1:03:55, 12.53s/it]Loading train:   2%|▏         | 6/311 [01:11<1:02:01, 12.20s/it]Loading train:   2%|▏         | 7/311 [01:24<1:03:05, 12.45s/it]Loading train:   3%|▎         | 8/311 [01:39<1:06:19, 13.14s/it]Loading train:   3%|▎         | 9/311 [01:52<1:06:15, 13.16s/it]Loading train:   3%|▎         | 10/311 [02:04<1:03:52, 12.73s/it]Loading train:   4%|▎         | 11/311 [02:18<1:06:27, 13.29s/it]Loading train:   4%|▍         | 12/311 [02:31<1:05:04, 13.06s/it]Loading train:   4%|▍         | 13/311 [02:42<1:02:04, 12.50s/it]Loading train:   5%|▍         | 14/311 [02:57<1:05:34, 13.25s/it]Loading train:   5%|▍         | 15/311 [03:08<1:02:20, 12.64s/it]Loading train:   5%|▌         | 16/311 [03:20<1:00:21, 12.28s/it]Loading train:   5%|▌         | 17/311 [03:31<58:06, 11.86s/it]  Loading train:   6%|▌         | 18/311 [03:41<56:13, 11.51s/it]Loading train:   6%|▌         | 19/311 [03:53<55:53, 11.48s/it]Loading train:   6%|▋         | 20/311 [04:04<55:30, 11.45s/it]Loading train:   7%|▋         | 21/311 [04:16<55:48, 11.55s/it]Loading train:   7%|▋         | 22/311 [04:29<57:19, 11.90s/it]Loading train:   7%|▋         | 23/311 [04:40<56:48, 11.83s/it]Loading train:   8%|▊         | 24/311 [04:51<55:19, 11.57s/it]Loading train:   8%|▊         | 25/311 [05:02<54:29, 11.43s/it]Loading train:   8%|▊         | 26/311 [05:14<54:34, 11.49s/it]Loading train:   9%|▊         | 27/311 [05:26<54:59, 11.62s/it]Loading train:   9%|▉         | 28/311 [05:37<54:53, 11.64s/it]Loading train:   9%|▉         | 29/311 [05:49<54:57, 11.70s/it]Loading train:  10%|▉         | 30/311 [06:01<54:51, 11.71s/it]Loading train:  10%|▉         | 31/311 [06:13<54:38, 11.71s/it]Loading train:  10%|█         | 32/311 [06:25<54:45, 11.77s/it]Loading train:  11%|█         | 33/311 [06:31<47:03, 10.16s/it]Loading train:  11%|█         | 34/311 [06:37<41:14,  8.93s/it]Loading train:  11%|█▏        | 35/311 [06:43<37:10,  8.08s/it]Loading train:  12%|█▏        | 36/311 [06:49<34:24,  7.51s/it]Loading train:  12%|█▏        | 37/311 [06:56<33:12,  7.27s/it]Loading train:  12%|█▏        | 38/311 [07:04<33:15,  7.31s/it]Loading train:  13%|█▎        | 39/311 [07:10<32:38,  7.20s/it]Loading train:  13%|█▎        | 40/311 [07:18<32:48,  7.26s/it]Loading train:  13%|█▎        | 41/311 [07:24<31:17,  6.95s/it]Loading train:  14%|█▎        | 42/311 [07:31<31:14,  6.97s/it]Loading train:  14%|█▍        | 43/311 [07:38<31:05,  6.96s/it]Loading train:  14%|█▍        | 44/311 [07:46<31:37,  7.11s/it]Loading train:  14%|█▍        | 45/311 [07:52<31:03,  7.01s/it]Loading train:  15%|█▍        | 46/311 [07:59<30:59,  7.02s/it]Loading train:  15%|█▌        | 47/311 [08:06<30:34,  6.95s/it]Loading train:  15%|█▌        | 48/311 [08:14<31:18,  7.14s/it]Loading train:  16%|█▌        | 49/311 [08:20<30:28,  6.98s/it]Loading train:  16%|█▌        | 50/311 [08:27<30:18,  6.97s/it]Loading train:  16%|█▋        | 51/311 [08:35<31:33,  7.28s/it]Loading train:  17%|█▋        | 52/311 [08:44<32:58,  7.64s/it]Loading train:  17%|█▋        | 53/311 [08:52<33:33,  7.80s/it]Loading train:  17%|█▋        | 54/311 [09:00<34:14,  7.99s/it]Loading train:  18%|█▊        | 55/311 [09:10<36:04,  8.46s/it]Loading train:  18%|█▊        | 56/311 [09:16<33:30,  7.89s/it]Loading train:  18%|█▊        | 57/311 [09:24<32:37,  7.71s/it]Loading train:  19%|█▊        | 58/311 [09:30<30:40,  7.27s/it]Loading train:  19%|█▉        | 59/311 [09:36<29:13,  6.96s/it]Loading train:  19%|█▉        | 60/311 [09:42<28:10,  6.73s/it]Loading train:  20%|█▉        | 61/311 [09:49<27:33,  6.62s/it]Loading train:  20%|█▉        | 62/311 [09:55<27:01,  6.51s/it]Loading train:  20%|██        | 63/311 [10:01<26:17,  6.36s/it]Loading train:  21%|██        | 64/311 [10:07<25:56,  6.30s/it]Loading train:  21%|██        | 65/311 [10:13<25:26,  6.21s/it]Loading train:  21%|██        | 66/311 [10:19<25:20,  6.20s/it]Loading train:  22%|██▏       | 67/311 [10:25<24:54,  6.13s/it]Loading train:  22%|██▏       | 68/311 [10:31<24:30,  6.05s/it]Loading train:  22%|██▏       | 69/311 [10:37<24:27,  6.07s/it]Loading train:  23%|██▎       | 70/311 [10:44<24:33,  6.11s/it]Loading train:  23%|██▎       | 71/311 [10:49<23:54,  5.98s/it]Loading train:  23%|██▎       | 72/311 [10:55<23:39,  5.94s/it]Loading train:  23%|██▎       | 73/311 [11:01<23:28,  5.92s/it]Loading train:  24%|██▍       | 74/311 [11:07<23:18,  5.90s/it]Loading train:  24%|██▍       | 75/311 [11:12<22:59,  5.85s/it]Loading train:  24%|██▍       | 76/311 [11:18<22:53,  5.84s/it]Loading train:  25%|██▍       | 77/311 [11:24<22:30,  5.77s/it]Loading train:  25%|██▌       | 78/311 [11:30<22:10,  5.71s/it]Loading train:  25%|██▌       | 79/311 [11:35<22:11,  5.74s/it]Loading train:  26%|██▌       | 80/311 [11:41<22:03,  5.73s/it]Loading train:  26%|██▌       | 81/311 [11:47<21:53,  5.71s/it]Loading train:  26%|██▋       | 82/311 [11:53<21:57,  5.75s/it]Loading train:  27%|██▋       | 83/311 [11:58<21:38,  5.70s/it]Loading train:  27%|██▋       | 84/311 [12:04<21:43,  5.74s/it]Loading train:  27%|██▋       | 85/311 [12:09<21:18,  5.66s/it]Loading train:  28%|██▊       | 86/311 [12:15<20:53,  5.57s/it]Loading train:  28%|██▊       | 87/311 [12:20<20:39,  5.53s/it]Loading train:  28%|██▊       | 88/311 [12:26<20:25,  5.50s/it]Loading train:  29%|██▊       | 89/311 [12:31<20:01,  5.41s/it]Loading train:  29%|██▉       | 90/311 [12:36<19:43,  5.35s/it]Loading train:  29%|██▉       | 91/311 [12:41<19:37,  5.35s/it]Loading train:  30%|██▉       | 92/311 [12:47<19:25,  5.32s/it]Loading train:  30%|██▉       | 93/311 [12:52<19:23,  5.34s/it]Loading train:  30%|███       | 94/311 [12:57<19:20,  5.35s/it]Loading train:  31%|███       | 95/311 [13:03<19:09,  5.32s/it]Loading train:  31%|███       | 96/311 [13:08<19:17,  5.38s/it]Loading train:  31%|███       | 97/311 [13:14<19:12,  5.39s/it]Loading train:  32%|███▏      | 98/311 [13:19<19:20,  5.45s/it]Loading train:  32%|███▏      | 99/311 [13:25<19:23,  5.49s/it]Loading train:  32%|███▏      | 100/311 [13:31<19:35,  5.57s/it]Loading train:  32%|███▏      | 101/311 [13:36<19:37,  5.60s/it]Loading train:  33%|███▎      | 102/311 [13:43<20:32,  5.90s/it]Loading train:  33%|███▎      | 103/311 [13:49<20:40,  5.96s/it]Loading train:  33%|███▎      | 104/311 [13:54<19:57,  5.78s/it]Loading train:  34%|███▍      | 105/311 [14:01<20:21,  5.93s/it]Loading train:  34%|███▍      | 106/311 [14:07<20:18,  5.94s/it]Loading train:  34%|███▍      | 107/311 [14:12<19:54,  5.86s/it]Loading train:  35%|███▍      | 108/311 [14:18<19:59,  5.91s/it]Loading train:  35%|███▌      | 109/311 [14:24<19:46,  5.87s/it]Loading train:  35%|███▌      | 110/311 [14:30<19:51,  5.93s/it]Loading train:  36%|███▌      | 111/311 [14:36<19:53,  5.97s/it]Loading train:  36%|███▌      | 112/311 [14:42<19:51,  5.99s/it]Loading train:  36%|███▋      | 113/311 [14:48<19:23,  5.88s/it]Loading train:  37%|███▋      | 114/311 [14:58<23:38,  7.20s/it]Loading train:  37%|███▋      | 115/311 [15:08<26:36,  8.14s/it]Loading train:  37%|███▋      | 116/311 [15:18<28:17,  8.71s/it]Loading train:  38%|███▊      | 117/311 [15:30<30:34,  9.46s/it]Loading train:  38%|███▊      | 118/311 [15:41<31:48,  9.89s/it]Loading train:  38%|███▊      | 119/311 [15:51<31:51,  9.96s/it]Loading train:  39%|███▊      | 120/311 [16:01<31:40,  9.95s/it]Loading train:  39%|███▉      | 121/311 [16:11<32:23, 10.23s/it]Loading train:  39%|███▉      | 122/311 [16:22<32:12, 10.22s/it]Loading train:  40%|███▉      | 123/311 [16:32<32:27, 10.36s/it]Loading train:  40%|███▉      | 124/311 [16:42<31:58, 10.26s/it]Loading train:  40%|████      | 125/311 [16:53<31:44, 10.24s/it]Loading train:  41%|████      | 126/311 [17:03<31:26, 10.20s/it]Loading train:  41%|████      | 127/311 [17:13<31:38, 10.32s/it]Loading train:  41%|████      | 128/311 [17:24<31:35, 10.36s/it]Loading train:  41%|████▏     | 129/311 [17:34<31:44, 10.46s/it]Loading train:  42%|████▏     | 130/311 [17:45<31:22, 10.40s/it]Loading train:  42%|████▏     | 131/311 [17:55<31:17, 10.43s/it]Loading train:  42%|████▏     | 132/311 [18:01<26:55,  9.02s/it]Loading train:  43%|████▎     | 133/311 [18:07<23:51,  8.04s/it]Loading train:  43%|████▎     | 134/311 [18:12<21:40,  7.35s/it]Loading train:  43%|████▎     | 135/311 [18:18<20:05,  6.85s/it]Loading train:  44%|████▎     | 136/311 [18:23<18:28,  6.34s/it]Loading train:  44%|████▍     | 137/311 [18:28<17:13,  5.94s/it]Loading train:  44%|████▍     | 138/311 [18:34<16:39,  5.78s/it]Loading train:  45%|████▍     | 139/311 [18:39<16:02,  5.59s/it]Loading train:  45%|████▌     | 140/311 [18:44<15:25,  5.41s/it]Loading train:  45%|████▌     | 141/311 [18:49<15:09,  5.35s/it]Loading train:  46%|████▌     | 142/311 [18:54<14:48,  5.26s/it]Loading train:  46%|████▌     | 143/311 [18:59<14:22,  5.13s/it]Loading train:  46%|████▋     | 144/311 [19:04<14:01,  5.04s/it]Loading train:  47%|████▋     | 145/311 [19:09<13:58,  5.05s/it]Loading train:  47%|████▋     | 146/311 [19:14<13:41,  4.98s/it]Loading train:  47%|████▋     | 147/311 [19:19<13:35,  4.97s/it]Loading train:  48%|████▊     | 148/311 [19:23<13:24,  4.93s/it]Loading train:  48%|████▊     | 149/311 [19:28<13:27,  4.98s/it]Loading train:  48%|████▊     | 150/311 [19:34<13:55,  5.19s/it]Loading train:  49%|████▊     | 151/311 [19:40<14:21,  5.39s/it]Loading train:  49%|████▉     | 152/311 [19:46<14:56,  5.64s/it]Loading train:  49%|████▉     | 153/311 [19:52<15:05,  5.73s/it]Loading train:  50%|████▉     | 154/311 [19:58<15:00,  5.73s/it]Loading train:  50%|████▉     | 155/311 [20:04<15:04,  5.80s/it]Loading train:  50%|█████     | 156/311 [20:10<15:15,  5.90s/it]Loading train:  50%|█████     | 157/311 [20:16<15:03,  5.87s/it]Loading train:  51%|█████     | 158/311 [20:22<15:10,  5.95s/it]Loading train:  51%|█████     | 159/311 [20:28<15:08,  5.98s/it]Loading train:  51%|█████▏    | 160/311 [20:34<14:53,  5.92s/it]Loading train:  52%|█████▏    | 161/311 [20:40<14:48,  5.93s/it]Loading train:  52%|█████▏    | 162/311 [20:46<14:43,  5.93s/it]Loading train:  52%|█████▏    | 163/311 [20:51<14:28,  5.87s/it]Loading train:  53%|█████▎    | 164/311 [20:57<14:26,  5.90s/it]Loading train:  53%|█████▎    | 165/311 [21:03<14:22,  5.91s/it]Loading train:  53%|█████▎    | 166/311 [21:09<14:13,  5.89s/it]Loading train:  54%|█████▎    | 167/311 [21:15<14:02,  5.85s/it]Loading train:  54%|█████▍    | 168/311 [21:21<13:59,  5.87s/it]Loading train:  54%|█████▍    | 169/311 [21:27<13:50,  5.85s/it]Loading train:  55%|█████▍    | 170/311 [21:32<13:39,  5.81s/it]Loading train:  55%|█████▍    | 171/311 [21:38<13:39,  5.86s/it]Loading train:  55%|█████▌    | 172/311 [21:44<13:34,  5.86s/it]Loading train:  56%|█████▌    | 173/311 [21:50<13:23,  5.82s/it]Loading train:  56%|█████▌    | 174/311 [21:56<13:17,  5.82s/it]Loading train:  56%|█████▋    | 175/311 [22:02<13:15,  5.85s/it]Loading train:  57%|█████▋    | 176/311 [22:08<13:11,  5.87s/it]Loading train:  57%|█████▋    | 177/311 [22:14<13:14,  5.93s/it]Loading train:  57%|█████▋    | 178/311 [22:20<13:14,  5.97s/it]Loading train:  58%|█████▊    | 179/311 [22:25<12:56,  5.88s/it]Loading train:  58%|█████▊    | 180/311 [22:31<12:38,  5.79s/it]Loading train:  58%|█████▊    | 181/311 [22:37<12:42,  5.86s/it]Loading train:  59%|█████▊    | 182/311 [22:43<12:28,  5.80s/it]Loading train:  59%|█████▉    | 183/311 [22:49<12:28,  5.85s/it]Loading train:  59%|█████▉    | 184/311 [22:54<12:12,  5.77s/it]Loading train:  59%|█████▉    | 185/311 [23:00<11:54,  5.67s/it]Loading train:  60%|█████▉    | 186/311 [23:05<11:45,  5.65s/it]Loading train:  60%|██████    | 187/311 [23:11<11:37,  5.63s/it]Loading train:  60%|██████    | 188/311 [23:16<11:26,  5.58s/it]Loading train:  61%|██████    | 189/311 [23:21<10:56,  5.38s/it]Loading train:  61%|██████    | 190/311 [23:26<10:39,  5.28s/it]Loading train:  61%|██████▏   | 191/311 [23:32<10:38,  5.32s/it]Loading train:  62%|██████▏   | 192/311 [23:37<10:23,  5.24s/it]Loading train:  62%|██████▏   | 193/311 [23:42<10:08,  5.16s/it]Loading train:  62%|██████▏   | 194/311 [23:47<10:00,  5.13s/it]Loading train:  63%|██████▎   | 195/311 [23:52<09:53,  5.12s/it]Loading train:  63%|██████▎   | 196/311 [23:57<09:42,  5.07s/it]Loading train:  63%|██████▎   | 197/311 [24:02<09:31,  5.02s/it]Loading train:  64%|██████▎   | 198/311 [24:07<09:27,  5.02s/it]Loading train:  64%|██████▍   | 199/311 [24:12<09:21,  5.01s/it]Loading train:  64%|██████▍   | 200/311 [24:17<09:15,  5.01s/it]Loading train:  65%|██████▍   | 201/311 [24:22<09:13,  5.04s/it]Loading train:  65%|██████▍   | 202/311 [24:27<09:10,  5.05s/it]Loading train:  65%|██████▌   | 203/311 [24:32<09:03,  5.03s/it]Loading train:  66%|██████▌   | 204/311 [24:37<08:55,  5.01s/it]Loading train:  66%|██████▌   | 205/311 [24:42<08:59,  5.09s/it]Loading train:  66%|██████▌   | 206/311 [24:47<08:40,  4.96s/it]Loading train:  67%|██████▋   | 207/311 [24:52<08:41,  5.02s/it]Loading train:  67%|██████▋   | 208/311 [24:57<08:47,  5.12s/it]Loading train:  67%|██████▋   | 209/311 [25:02<08:39,  5.09s/it]Loading train:  68%|██████▊   | 210/311 [25:07<08:32,  5.08s/it]Loading train:  68%|██████▊   | 211/311 [25:13<08:33,  5.13s/it]Loading train:  68%|██████▊   | 212/311 [25:18<08:31,  5.16s/it]Loading train:  68%|██████▊   | 213/311 [25:27<10:19,  6.32s/it]Loading train:  69%|██████▉   | 214/311 [25:36<11:32,  7.13s/it]Loading train:  69%|██████▉   | 215/311 [25:45<12:20,  7.71s/it]Loading train:  69%|██████▉   | 216/311 [25:54<12:43,  8.04s/it]Loading train:  70%|██████▉   | 217/311 [26:03<13:08,  8.38s/it]Loading train:  70%|███████   | 218/311 [26:12<13:14,  8.54s/it]Loading train:  70%|███████   | 219/311 [26:21<13:24,  8.74s/it]Loading train:  71%|███████   | 220/311 [26:30<13:16,  8.75s/it]Loading train:  71%|███████   | 221/311 [26:39<13:08,  8.76s/it]Loading train:  71%|███████▏  | 222/311 [26:48<13:11,  8.89s/it]Loading train:  72%|███████▏  | 223/311 [26:57<13:03,  8.91s/it]Loading train:  72%|███████▏  | 224/311 [27:06<12:59,  8.96s/it]Loading train:  72%|███████▏  | 225/311 [27:14<12:39,  8.83s/it]Loading train:  73%|███████▎  | 226/311 [27:24<12:40,  8.94s/it]Loading train:  73%|███████▎  | 227/311 [27:33<12:35,  8.99s/it]Loading train:  73%|███████▎  | 228/311 [27:42<12:27,  9.01s/it]Loading train:  74%|███████▎  | 229/311 [27:51<12:25,  9.09s/it]Loading train:  74%|███████▍  | 230/311 [28:00<12:12,  9.05s/it]Loading train:  74%|███████▍  | 231/311 [28:05<10:19,  7.75s/it]Loading train:  75%|███████▍  | 232/311 [28:09<08:57,  6.80s/it]Loading train:  75%|███████▍  | 233/311 [28:14<07:56,  6.11s/it]Loading train:  75%|███████▌  | 234/311 [28:18<07:15,  5.66s/it]Loading train:  76%|███████▌  | 235/311 [28:23<06:46,  5.35s/it]Loading train:  76%|███████▌  | 236/311 [28:27<06:21,  5.09s/it]Loading train:  76%|███████▌  | 237/311 [28:32<05:57,  4.83s/it]Loading train:  77%|███████▋  | 238/311 [28:36<05:45,  4.73s/it]Loading train:  77%|███████▋  | 239/311 [28:41<05:36,  4.68s/it]Loading train:  77%|███████▋  | 240/311 [28:45<05:25,  4.59s/it]Loading train:  77%|███████▋  | 241/311 [28:49<05:14,  4.49s/it]Loading train:  78%|███████▊  | 242/311 [28:54<05:13,  4.54s/it]Loading train:  78%|███████▊  | 243/311 [28:59<05:08,  4.54s/it]Loading train:  78%|███████▊  | 244/311 [29:03<04:59,  4.47s/it]Loading train:  79%|███████▉  | 245/311 [29:07<04:51,  4.42s/it]Loading train:  79%|███████▉  | 246/311 [29:12<04:49,  4.45s/it]Loading train:  79%|███████▉  | 247/311 [29:16<04:44,  4.45s/it]Loading train:  80%|███████▉  | 248/311 [29:21<04:43,  4.50s/it]Loading train:  80%|████████  | 249/311 [29:26<04:58,  4.81s/it]Loading train:  80%|████████  | 250/311 [29:32<05:09,  5.08s/it]Loading train:  81%|████████  | 251/311 [29:38<05:17,  5.30s/it]Loading train:  81%|████████  | 252/311 [29:43<05:15,  5.35s/it]Loading train:  81%|████████▏ | 253/311 [29:49<05:18,  5.49s/it]Loading train:  82%|████████▏ | 254/311 [29:55<05:12,  5.48s/it]Loading train:  82%|████████▏ | 255/311 [30:00<05:08,  5.51s/it]Loading train:  82%|████████▏ | 256/311 [30:06<05:09,  5.63s/it]Loading train:  83%|████████▎ | 257/311 [30:12<05:03,  5.62s/it]Loading train:  83%|████████▎ | 258/311 [30:17<04:54,  5.56s/it]Loading train:  83%|████████▎ | 259/311 [30:23<04:53,  5.65s/it]Loading train:  84%|████████▎ | 260/311 [30:28<04:46,  5.61s/it]Loading train:  84%|████████▍ | 261/311 [30:34<04:41,  5.64s/it]Loading train:  84%|████████▍ | 262/311 [30:40<04:38,  5.68s/it]Loading train:  85%|████████▍ | 263/311 [30:46<04:31,  5.67s/it]Loading train:  85%|████████▍ | 264/311 [30:51<04:19,  5.51s/it]Loading train:  85%|████████▌ | 265/311 [30:56<04:16,  5.57s/it]Loading train:  86%|████████▌ | 266/311 [31:02<04:08,  5.52s/it]Loading train:  86%|████████▌ | 267/311 [31:07<03:56,  5.39s/it]Loading train:  86%|████████▌ | 268/311 [31:13<03:55,  5.47s/it]Loading train:  86%|████████▋ | 269/311 [31:18<03:49,  5.47s/it]Loading train:  87%|████████▋ | 270/311 [31:23<03:41,  5.41s/it]Loading train:  87%|████████▋ | 271/311 [31:29<03:38,  5.47s/it]Loading train:  87%|████████▋ | 272/311 [31:34<03:34,  5.50s/it]Loading train:  88%|████████▊ | 273/311 [31:40<03:26,  5.42s/it]Loading train:  88%|████████▊ | 274/311 [31:45<03:23,  5.49s/it]Loading train:  88%|████████▊ | 275/311 [31:51<03:18,  5.50s/it]Loading train:  89%|████████▊ | 276/311 [31:56<03:07,  5.36s/it]Loading train:  89%|████████▉ | 277/311 [32:01<03:01,  5.35s/it]Loading train:  89%|████████▉ | 278/311 [32:07<02:59,  5.42s/it]Loading train:  90%|████████▉ | 279/311 [32:12<02:52,  5.38s/it]Loading train:  90%|█████████ | 280/311 [32:17<02:44,  5.31s/it]Loading train:  90%|█████████ | 281/311 [32:23<02:45,  5.51s/it]Loading train:  91%|█████████ | 282/311 [32:28<02:36,  5.40s/it]Loading train:  91%|█████████ | 283/311 [32:33<02:25,  5.20s/it]Loading train:  91%|█████████▏| 284/311 [32:38<02:20,  5.21s/it]Loading train:  92%|█████████▏| 285/311 [32:43<02:14,  5.16s/it]Loading train:  92%|█████████▏| 286/311 [32:48<02:04,  4.98s/it]Loading train:  92%|█████████▏| 287/311 [32:53<02:00,  5.02s/it]Loading train:  93%|█████████▎| 288/311 [32:58<01:55,  5.02s/it]Loading train:  93%|█████████▎| 289/311 [33:03<01:49,  4.96s/it]Loading train:  93%|█████████▎| 290/311 [33:08<01:45,  5.02s/it]Loading train:  94%|█████████▎| 291/311 [33:13<01:41,  5.08s/it]Loading train:  94%|█████████▍| 292/311 [33:18<01:34,  4.98s/it]Loading train:  94%|█████████▍| 293/311 [33:23<01:29,  4.97s/it]Loading train:  95%|█████████▍| 294/311 [33:28<01:25,  5.05s/it]Loading train:  95%|█████████▍| 295/311 [33:33<01:19,  4.96s/it]Loading train:  95%|█████████▌| 296/311 [33:38<01:13,  4.92s/it]Loading train:  95%|█████████▌| 297/311 [33:43<01:09,  4.95s/it]Loading train:  96%|█████████▌| 298/311 [33:48<01:04,  4.95s/it]Loading train:  96%|█████████▌| 299/311 [33:53<00:59,  4.97s/it]Loading train:  96%|█████████▋| 300/311 [33:58<00:54,  4.99s/it]Loading train:  97%|█████████▋| 301/311 [34:03<00:49,  4.92s/it]Loading train:  97%|█████████▋| 302/311 [34:07<00:43,  4.84s/it]Loading train:  97%|█████████▋| 303/311 [34:12<00:39,  4.91s/it]Loading train:  98%|█████████▊| 304/311 [34:18<00:35,  5.01s/it]Loading train:  98%|█████████▊| 305/311 [34:22<00:29,  4.98s/it]Loading train:  98%|█████████▊| 306/311 [34:28<00:25,  5.03s/it]Loading train:  99%|█████████▊| 307/311 [34:33<00:20,  5.14s/it]Loading train:  99%|█████████▉| 308/311 [34:38<00:15,  5.11s/it]Loading train:  99%|█████████▉| 309/311 [34:43<00:10,  5.04s/it]Loading train: 100%|█████████▉| 310/311 [34:48<00:05,  5.03s/it]Loading train: 100%|██████████| 311/311 [34:53<00:00,  4.98s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 22/311 [00:00<00:01, 217.23it/s]concatenating: train:  14%|█▍        | 44/311 [00:00<00:01, 217.03it/s]concatenating: train:  18%|█▊        | 57/311 [00:00<00:01, 180.19it/s]concatenating: train:  26%|██▋       | 82/311 [00:00<00:01, 195.09it/s]concatenating: train:  34%|███▍      | 105/311 [00:00<00:01, 204.12it/s]concatenating: train:  42%|████▏     | 130/311 [00:00<00:00, 213.97it/s]concatenating: train:  48%|████▊     | 150/311 [00:00<00:00, 192.40it/s]concatenating: train:  57%|█████▋    | 178/311 [00:00<00:00, 212.32it/s]concatenating: train:  65%|██████▍   | 201/311 [00:00<00:00, 214.83it/s]concatenating: train:  73%|███████▎  | 228/311 [00:01<00:00, 226.76it/s]concatenating: train:  81%|████████  | 251/311 [00:01<00:00, 225.18it/s]concatenating: train:  88%|████████▊ | 274/311 [00:01<00:00, 226.48it/s]concatenating: train:  98%|█████████▊| 304/311 [00:01<00:00, 243.60it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 225.89it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:12<00:36, 12.14s/it]Loading test:  50%|█████     | 2/4 [00:23<00:23, 11.82s/it]Loading test:  75%|███████▌  | 3/4 [00:35<00:11, 11.86s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.85s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 75.74it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   2019-07-07 14:40:41.705769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 14:40:41.705876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 14:40:41.705904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 14:40:41.705916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 14:40:41.733027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [5.86066190e-02 2.84688586e-02 1.21642213e-01 1.04576120e-02
 3.14646619e-02 5.44310893e-03 7.20519791e-02 1.12887958e-01
 7.85252165e-02 1.27448500e-02 2.91951514e-01 1.75516909e-01
 2.38500254e-04]
Train on 12832 samples, validate on 168 samples
Epoch 1/300
 - 21s - loss: 10742.7608 - acc: 0.8540 - mDice: 0.2010 - val_loss: 8955.4724 - val_acc: 0.8971 - val_mDice: 0.3065

Epoch 00001: val_mDice improved from -inf to 0.30655, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 4801.3338 - acc: 0.8958 - mDice: 0.4005 - val_loss: 4308.3741 - val_acc: 0.9135 - val_mDice: 0.4253

Epoch 00002: val_mDice improved from 0.30655 to 0.42531, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 3646.7141 - acc: 0.9109 - mDice: 0.4915 - val_loss: 2848.8421 - val_acc: 0.9247 - val_mDice: 0.5324

Epoch 00003: val_mDice improved from 0.42531 to 0.53235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 3111.8797 - acc: 0.9192 - mDice: 0.5414 - val_loss: 2536.6556 - val_acc: 0.9266 - val_mDice: 0.5700

Epoch 00004: val_mDice improved from 0.53235 to 0.56995, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 12s - loss: 2772.3188 - acc: 0.9246 - mDice: 0.5765 - val_loss: 2324.3065 - val_acc: 0.9283 - val_mDice: 0.5956

Epoch 00005: val_mDice improved from 0.56995 to 0.59556, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 2531.4382 - acc: 0.9286 - mDice: 0.6033 - val_loss: 2255.6791 - val_acc: 0.9277 - val_mDice: 0.6018

Epoch 00006: val_mDice improved from 0.59556 to 0.60177, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 11s - loss: 2370.5198 - acc: 0.9312 - mDice: 0.6219 - val_loss: 2052.4361 - val_acc: 0.9343 - val_mDice: 0.6297

Epoch 00007: val_mDice improved from 0.60177 to 0.62968, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 12s - loss: 2241.2373 - acc: 0.9333 - mDice: 0.6377 - val_loss: 2161.4573 - val_acc: 0.9325 - val_mDice: 0.6133

Epoch 00008: val_mDice did not improve from 0.62968
Epoch 9/300
 - 11s - loss: 2125.5608 - acc: 0.9352 - mDice: 0.6516 - val_loss: 2172.7367 - val_acc: 0.9260 - val_mDice: 0.6098

Epoch 00009: val_mDice did not improve from 0.62968
Epoch 10/300
 - 11s - loss: 2053.2458 - acc: 0.9364 - mDice: 0.6612 - val_loss: 1820.6524 - val_acc: 0.9405 - val_mDice: 0.6603

Epoch 00010: val_mDice improved from 0.62968 to 0.66033, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 12s - loss: 1972.5656 - acc: 0.9379 - mDice: 0.6715 - val_loss: 1792.9113 - val_acc: 0.9436 - val_mDice: 0.6640

Epoch 00011: val_mDice improved from 0.66033 to 0.66401, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 1912.2243 - acc: 0.9391 - mDice: 0.6796 - val_loss: 1862.7540 - val_acc: 0.9426 - val_mDice: 0.6565

Epoch 00012: val_mDice did not improve from 0.66401
Epoch 13/300
 - 12s - loss: 1867.9190 - acc: 0.9400 - mDice: 0.6855 - val_loss: 1814.2103 - val_acc: 0.9402 - val_mDice: 0.6611

Epoch 00013: val_mDice did not improve from 0.66401
Epoch 14/300
 - 11s - loss: 1811.9841 - acc: 0.9411 - mDice: 0.6931 - val_loss: 1880.2757 - val_acc: 0.9417 - val_mDice: 0.6539

Epoch 00014: val_mDice did not improve from 0.66401
Epoch 15/300
 - 11s - loss: 1787.4211 - acc: 0.9417 - mDice: 0.6966 - val_loss: 1797.6026 - val_acc: 0.9447 - val_mDice: 0.6656

Epoch 00015: val_mDice improved from 0.66401 to 0.66561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 12s - loss: 1732.8615 - acc: 0.9428 - mDice: 0.7041 - val_loss: 1824.1526 - val_acc: 0.9408 - val_mDice: 0.6619

Epoch 00016: val_mDice did not improve from 0.66561
Epoch 17/300
 - 11s - loss: 1697.5068 - acc: 0.9433 - mDice: 0.7089 - val_loss: 1784.8077 - val_acc: 0.9435 - val_mDice: 0.6676

Epoch 00017: val_mDice improved from 0.66561 to 0.66759, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 11s - loss: 1672.1949 - acc: 0.9439 - mDice: 0.7125 - val_loss: 1711.6737 - val_acc: 0.9484 - val_mDice: 0.6783

Epoch 00018: val_mDice improved from 0.66759 to 0.67832, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 12s - loss: 1638.0553 - acc: 0.9447 - mDice: 0.7174 - val_loss: 1711.9333 - val_acc: 0.9460 - val_mDice: 0.6785

Epoch 00019: val_mDice improved from 0.67832 to 0.67845, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 11s - loss: 1606.3068 - acc: 0.9452 - mDice: 0.7219 - val_loss: 1736.9276 - val_acc: 0.9512 - val_mDice: 0.6749

Epoch 00020: val_mDice did not improve from 0.67845
Epoch 21/300
 - 12s - loss: 1580.8427 - acc: 0.9457 - mDice: 0.7256 - val_loss: 1722.4696 - val_acc: 0.9484 - val_mDice: 0.6733

Epoch 00021: val_mDice did not improve from 0.67845
Epoch 22/300
 - 11s - loss: 1557.8014 - acc: 0.9462 - mDice: 0.7289 - val_loss: 1673.8846 - val_acc: 0.9517 - val_mDice: 0.6836

Epoch 00022: val_mDice improved from 0.67845 to 0.68360, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 11s - loss: 1541.9867 - acc: 0.9465 - mDice: 0.7313 - val_loss: 1640.4545 - val_acc: 0.9520 - val_mDice: 0.6890

Epoch 00023: val_mDice improved from 0.68360 to 0.68899, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 12s - loss: 1507.9910 - acc: 0.9471 - mDice: 0.7361 - val_loss: 1629.4789 - val_acc: 0.9530 - val_mDice: 0.6917

Epoch 00024: val_mDice improved from 0.68899 to 0.69165, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 11s - loss: 1493.4664 - acc: 0.9475 - mDice: 0.7383 - val_loss: 1772.9328 - val_acc: 0.9450 - val_mDice: 0.6710

Epoch 00025: val_mDice did not improve from 0.69165
Epoch 26/300
 - 12s - loss: 1474.6624 - acc: 0.9478 - mDice: 0.7410 - val_loss: 1703.8299 - val_acc: 0.9515 - val_mDice: 0.6817

Epoch 00026: val_mDice did not improve from 0.69165
Epoch 27/300
 - 12s - loss: 1456.0965 - acc: 0.9482 - mDice: 0.7438 - val_loss: 1595.9014 - val_acc: 0.9538 - val_mDice: 0.6978

Epoch 00027: val_mDice improved from 0.69165 to 0.69781, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 12s - loss: 1437.3597 - acc: 0.9485 - mDice: 0.7467 - val_loss: 1752.9238 - val_acc: 0.9531 - val_mDice: 0.6749

Epoch 00028: val_mDice did not improve from 0.69781
Epoch 29/300
 - 12s - loss: 1420.0591 - acc: 0.9488 - mDice: 0.7491 - val_loss: 1672.0159 - val_acc: 0.9504 - val_mDice: 0.6841

Epoch 00029: val_mDice did not improve from 0.69781
Epoch 30/300
 - 11s - loss: 1395.5356 - acc: 0.9492 - mDice: 0.7527 - val_loss: 1701.2602 - val_acc: 0.9497 - val_mDice: 0.6791

Epoch 00030: val_mDice did not improve from 0.69781
Epoch 31/300
 - 12s - loss: 1388.7163 - acc: 0.9495 - mDice: 0.7540 - val_loss: 1637.9665 - val_acc: 0.9544 - val_mDice: 0.6923

Epoch 00031: val_mDice did not improve from 0.69781
Epoch 32/300
 - 12s - loss: 1373.0523 - acc: 0.9497 - mDice: 0.7563 - val_loss: 1596.1825 - val_acc: 0.9546 - val_mDice: 0.6976

Epoch 00032: val_mDice did not improve from 0.69781
Epoch 33/300
 - 12s - loss: 1357.3497 - acc: 0.9500 - mDice: 0.7586 - val_loss: 1706.3968 - val_acc: 0.9534 - val_mDice: 0.6825

Epoch 00033: val_mDice did not improve from 0.69781
Epoch 34/300
 - 12s - loss: 1346.0881 - acc: 0.9502 - mDice: 0.7603 - val_loss: 1619.9271 - val_acc: 0.9512 - val_mDice: 0.6923

Epoch 00034: val_mDice did not improve from 0.69781
Epoch 35/300
 - 11s - loss: 1333.6314 - acc: 0.9505 - mDice: 0.7629 - val_loss: 1646.3132 - val_acc: 0.9507 - val_mDice: 0.6894

Epoch 00035: val_mDice did not improve from 0.69781
Epoch 36/300
 - 12s - loss: 1323.4617 - acc: 0.9507 - mDice: 0.7638 - val_loss: 1696.7786 - val_acc: 0.9530 - val_mDice: 0.6833

Epoch 00036: val_mDice did not improve from 0.69781
Epoch 37/300
 - 11s - loss: 1310.4510 - acc: 0.9509 - mDice: 0.7657 - val_loss: 1751.3047 - val_acc: 0.9540 - val_mDice: 0.6762

Epoch 00037: val_mDice did not improve from 0.69781
Epoch 38/300
 - 12s - loss: 1294.7279 - acc: 0.9511 - mDice: 0.7682 - val_loss: 1627.6162 - val_acc: 0.9496 - val_mDice: 0.6933

Epoch 00038: val_mDice did not improve from 0.69781
Epoch 39/300
 - 12s - loss: 1286.9875 - acc: 0.9513 - mDice: 0.7694 - val_loss: 1655.5127 - val_acc: 0.9536 - val_mDice: 0.6893

Epoch 00039: val_mDice did not improve from 0.69781
Epoch 40/300
 - 12s - loss: 1280.0091 - acc: 0.9515 - mDice: 0.7705 - val_loss: 1630.0425 - val_acc: 0.9520 - val_mDice: 0.6932

Epoch 00040: val_mDice did not improve from 0.69781
Epoch 41/300
 - 12s - loss: 1267.9461 - acc: 0.9516 - mDice: 0.7722 - val_loss: 1652.2985 - val_acc: 0.9532 - val_mDice: 0.6888

Epoch 00041: val_mDice did not improve from 0.69781
Epoch 42/300
 - 11s - loss: 1254.7695 - acc: 0.9519 - mDice: 0.7743 - val_loss: 1631.9387 - val_acc: 0.9530 - val_mDice: 0.6928

Epoch 00042: val_mDice did not improve from 0.69781
Epoch 43/300
 - 12s - loss: 1243.6065 - acc: 0.9521 - mDice: 0.7761 - val_loss: 1717.7797 - val_acc: 0.9534 - val_mDice: 0.6808

Epoch 00043: val_mDice did not improve from 0.69781
Epoch 44/300
 - 11s - loss: 1239.2516 - acc: 0.9522 - mDice: 0.7768 - val_loss: 1647.4586 - val_acc: 0.9545 - val_mDice: 0.6906

Epoch 00044: val_mDice did not improve from 0.69781
Epoch 45/300
 - 12s - loss: 1230.5747 - acc: 0.9523 - mDice: 0.7781 - val_loss: 1654.0555 - val_acc: 0.9513 - val_mDice: 0.6893

Epoch 00045: val_mDice did not improve from 0.69781
Epoch 46/300
 - 12s - loss: 1220.5808 - acc: 0.9525 - mDice: 0.7796 - val_loss: 1773.7372 - val_acc: 0.9453 - val_mDice: 0.6694

Epoch 00046: val_mDice did not improve from 0.69781
Epoch 47/300
 - 11s - loss: 1216.7535 - acc: 0.9527 - mDice: 0.7803 - val_loss: 1592.1089 - val_acc: 0.9542 - val_mDice: 0.6989

Epoch 00047: val_mDice improved from 0.69781 to 0.69889, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 12s - loss: 1198.1332 - acc: 0.9529 - mDice: 0.7832 - val_loss: 1672.2922 - val_acc: 0.9560 - val_mDice: 0.6874

Epoch 00048: val_mDice did not improve from 0.69889
Epoch 49/300
 - 11s - loss: 1197.0935 - acc: 0.9529 - mDice: 0.7833 - val_loss: 1650.1322 - val_acc: 0.9532 - val_mDice: 0.6907

Epoch 00049: val_mDice did not improve from 0.69889
Epoch 50/300
 - 12s - loss: 1194.9374 - acc: 0.9530 - mDice: 0.7838 - val_loss: 1648.8271 - val_acc: 0.9553 - val_mDice: 0.6906

Epoch 00050: val_mDice did not improve from 0.69889
Epoch 51/300
 - 12s - loss: 1181.3626 - acc: 0.9532 - mDice: 0.7857 - val_loss: 1644.3679 - val_acc: 0.9549 - val_mDice: 0.6904

Epoch 00051: val_mDice did not improve from 0.69889
Epoch 52/300
 - 11s - loss: 1170.4472 - acc: 0.9534 - mDice: 0.7876 - val_loss: 1649.9967 - val_acc: 0.9549 - val_mDice: 0.6934

Epoch 00052: val_mDice did not improve from 0.69889
Epoch 53/300
 - 12s - loss: 1165.1618 - acc: 0.9535 - mDice: 0.7884 - val_loss: 1713.6153 - val_acc: 0.9552 - val_mDice: 0.6824

Epoch 00053: val_mDice did not improve from 0.69889
Epoch 54/300
 - 11s - loss: 1158.0646 - acc: 0.9535 - mDice: 0.7895 - val_loss: 1600.2527 - val_acc: 0.9563 - val_mDice: 0.6980

Epoch 00054: val_mDice did not improve from 0.69889
Epoch 55/300
 - 12s - loss: 1149.3208 - acc: 0.9537 - mDice: 0.7909 - val_loss: 1548.4486 - val_acc: 0.9554 - val_mDice: 0.7059

Epoch 00055: val_mDice improved from 0.69889 to 0.70587, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 11s - loss: 1144.8830 - acc: 0.9538 - mDice: 0.7916 - val_loss: 1709.0290 - val_acc: 0.9564 - val_mDice: 0.6834

Epoch 00056: val_mDice did not improve from 0.70587
Epoch 57/300
 - 12s - loss: 1134.0599 - acc: 0.9540 - mDice: 0.7933 - val_loss: 1604.6453 - val_acc: 0.9553 - val_mDice: 0.6979

Epoch 00057: val_mDice did not improve from 0.70587
Epoch 58/300
 - 12s - loss: 1128.8661 - acc: 0.9540 - mDice: 0.7941 - val_loss: 1662.3492 - val_acc: 0.9528 - val_mDice: 0.6893

Epoch 00058: val_mDice did not improve from 0.70587
Epoch 59/300
 - 12s - loss: 1125.6379 - acc: 0.9541 - mDice: 0.7947 - val_loss: 1708.3369 - val_acc: 0.9522 - val_mDice: 0.6811

Epoch 00059: val_mDice did not improve from 0.70587
Epoch 60/300
 - 12s - loss: 1121.2387 - acc: 0.9542 - mDice: 0.7954 - val_loss: 1673.5994 - val_acc: 0.9538 - val_mDice: 0.6886

Epoch 00060: val_mDice did not improve from 0.70587
Epoch 61/300
 - 11s - loss: 1116.2191 - acc: 0.9542 - mDice: 0.7962 - val_loss: 1674.3357 - val_acc: 0.9546 - val_mDice: 0.6873

Epoch 00061: val_mDice did not improve from 0.70587
Epoch 62/300
 - 13s - loss: 1106.7267 - acc: 0.9546 - mDice: 0.7977 - val_loss: 1775.0423 - val_acc: 0.9484 - val_mDice: 0.6720

Epoch 00062: val_mDice did not improve from 0.70587
Epoch 63/300
 - 12s - loss: 1105.5569 - acc: 0.9545 - mDice: 0.7978 - val_loss: 1732.6457 - val_acc: 0.9476 - val_mDice: 0.6788

Epoch 00063: val_mDice did not improve from 0.70587
Epoch 64/300
 - 11s - loss: 1098.1208 - acc: 0.9547 - mDice: 0.7991 - val_loss: 1845.8646 - val_acc: 0.9447 - val_mDice: 0.6579

Epoch 00064: val_mDice did not improve from 0.70587
Epoch 65/300
 - 13s - loss: 1084.1007 - acc: 0.9549 - mDice: 0.8014 - val_loss: 1805.2466 - val_acc: 0.9525 - val_mDice: 0.6703

Epoch 00065: val_mDice did not improve from 0.70587
Epoch 66/300
 - 11s - loss: 1092.6540 - acc: 0.9547 - mDice: 0.8000 - val_loss: 1665.4839 - val_acc: 0.9547 - val_mDice: 0.6905

Epoch 00066: val_mDice did not improve from 0.70587
Epoch 67/300
 - 12s - loss: 1078.7063 - acc: 0.9549 - mDice: 0.8022 - val_loss: 1650.9091 - val_acc: 0.9555 - val_mDice: 0.6901

Epoch 00067: val_mDice did not improve from 0.70587
Epoch 68/300
 - 12s - loss: 1076.4947 - acc: 0.9550 - mDice: 0.8026 - val_loss: 1754.8898 - val_acc: 0.9509 - val_mDice: 0.6778

Epoch 00068: val_mDice did not improve from 0.70587
Epoch 69/300
 - 11s - loss: 1069.7570 - acc: 0.9550 - mDice: 0.8037 - val_loss: 1727.3093 - val_acc: 0.9566 - val_mDice: 0.6806

Epoch 00069: val_mDice did not improve from 0.70587
Epoch 70/300
 - 12s - loss: 1063.7263 - acc: 0.9551 - mDice: 0.8046 - val_loss: 1638.1139 - val_acc: 0.9546 - val_mDice: 0.6937

Epoch 00070: val_mDice did not improve from 0.70587
Epoch 71/300
 - 11s - loss: 1059.7630 - acc: 0.9552 - mDice: 0.8053 - val_loss: 1759.3722 - val_acc: 0.9517 - val_mDice: 0.6796

Epoch 00071: val_mDice did not improve from 0.70587
Epoch 72/300
 - 12s - loss: 1062.1613 - acc: 0.9551 - mDice: 0.8049 - val_loss: 1623.6496 - val_acc: 0.9565 - val_mDice: 0.6961

Epoch 00072: val_mDice did not improve from 0.70587
Epoch 73/300
 - 12s - loss: 1046.8097 - acc: 0.9555 - mDice: 0.8074 - val_loss: 1763.2764 - val_acc: 0.9519 - val_mDice: 0.6769

Epoch 00073: val_mDice did not improve from 0.70587
Epoch 74/300
 - 11s - loss: 1046.1508 - acc: 0.9555 - mDice: 0.8075 - val_loss: 1643.5563 - val_acc: 0.9524 - val_mDice: 0.6910

Epoch 00074: val_mDice did not improve from 0.70587
Epoch 75/300
 - 13s - loss: 1045.5289 - acc: 0.9556 - mDice: 0.8076 - val_loss: 1793.4021 - val_acc: 0.9534 - val_mDice: 0.6742

Epoch 00075: val_mDice did not improve from 0.70587
Epoch 76/300
 - 11s - loss: 1033.2498 - acc: 0.9557 - mDice: 0.8096 - val_loss: 1662.1125 - val_acc: 0.9566 - val_mDice: 0.6903

Epoch 00076: val_mDice did not improve from 0.70587
Epoch 77/300
 - 12s - loss: 1029.8178 - acc: 0.9558 - mDice: 0.8102 - val_loss: 1648.7044 - val_acc: 0.9527 - val_mDice: 0.6901

Epoch 00077: val_mDice did not improve from 0.70587
Epoch 78/300
 - 12s - loss: 1031.7474 - acc: 0.9557 - mDice: 0.8099 - val_loss: 1685.4276 - val_acc: 0.9552 - val_mDice: 0.6873

Epoch 00078: val_mDice did not improve from 0.70587
Epoch 79/300
 - 11s - loss: 1025.6755 - acc: 0.9558 - mDice: 0.8109 - val_loss: 1714.5741 - val_acc: 0.9542 - val_mDice: 0.6841

Epoch 00079: val_mDice did not improve from 0.70587
Epoch 80/300
 - 12s - loss: 1024.4081 - acc: 0.9558 - mDice: 0.8111 - val_loss: 1674.4805 - val_acc: 0.9550 - val_mDice: 0.6886

Epoch 00080: val_mDice did not improve from 0.70587
Epoch 81/300
 - 12s - loss: 1019.1856 - acc: 0.9560 - mDice: 0.8119 - val_loss: 1626.9453 - val_acc: 0.9550 - val_mDice: 0.6951

Epoch 00081: val_mDice did not improve from 0.70587
Epoch 82/300
 - 12s - loss: 1014.5527 - acc: 0.9560 - mDice: 0.8127 - val_loss: 1658.6763 - val_acc: 0.9575 - val_mDice: 0.6902

Epoch 00082: val_mDice did not improve from 0.70587
Epoch 83/300
 - 12s - loss: 1013.7386 - acc: 0.9560 - mDice: 0.8129 - val_loss: 1577.2133 - val_acc: 0.9563 - val_mDice: 0.7018

Epoch 00083: val_mDice did not improve from 0.70587
Epoch 84/300
 - 12s - loss: 1012.7580 - acc: 0.9560 - mDice: 0.8130 - val_loss: 1767.5778 - val_acc: 0.9561 - val_mDice: 0.6748

Epoch 00084: val_mDice did not improve from 0.70587
Epoch 85/300
 - 13s - loss: 1003.6411 - acc: 0.9562 - mDice: 0.8145 - val_loss: 1610.8454 - val_acc: 0.9571 - val_mDice: 0.6979

Epoch 00085: val_mDice did not improve from 0.70587
Restoring model weights from the end of the best epoch
Epoch 00085: early stopping
{'val_loss': [8955.472423735118, 4308.374104817708, 2848.842110770089, 2536.6555902390255, 2324.3065476190477, 2255.6790713355654, 2052.4360555013022, 2161.4573364257812, 2172.7366710844494, 1820.6524222237724, 1792.9112897600446, 1862.7540399460565, 1814.2103097098213, 1880.2756958007812, 1797.6026407877605, 1824.152611142113, 1784.80766078404, 1711.6737089611236, 1711.9332798549108, 1736.9275570824034, 1722.4695521763392, 1673.8845592680432, 1640.4545375279017, 1629.4789196196057, 1772.932829357329, 1703.8299182710193, 1595.901375906808, 1752.9237583705358, 1672.015869140625, 1701.260221935454, 1637.9665352957588, 1596.1824922107514, 1706.396760486421, 1619.9271065848213, 1646.3132033575148, 1696.778564453125, 1751.3046816871279, 1627.6162051246279, 1655.512663341704, 1630.0425356910341, 1652.2985229492188, 1631.9386596679688, 1717.7796514601935, 1647.4585774739583, 1654.0555216471355, 1773.7372349330358, 1592.1089274088542, 1672.2921578543526, 1650.1322428385417, 1648.8270670572917, 1644.3678937639509, 1649.9967273530506, 1713.615266345796, 1600.252673921131, 1548.4486316499256, 1709.0289539155506, 1604.6453421456474, 1662.34916469029, 1708.336890811012, 1673.599350702195, 1674.3356875465029, 1775.0423031761534, 1732.6457141694568, 1845.8645775204614, 1805.2465762183779, 1665.48390125093, 1650.9090954008557, 1754.8897617885045, 1727.3092767624628, 1638.1138945079986, 1759.3721545991443, 1623.6495739164807, 1763.2764282226562, 1643.5563412620909, 1793.402108328683, 1662.112534295945, 1648.7044067382812, 1685.4276384626116, 1714.5741141183037, 1674.4804745628721, 1626.9453125, 1658.6763160342261, 1577.2133033389136, 1767.5777529761904, 1610.8453543526787], 'val_acc': [0.89707531389736, 0.9134787008875892, 0.9247424290293739, 0.9266011218229929, 0.9283167265710377, 0.9276971831208184, 0.9342648230847859, 0.932474801937739, 0.925960103670756, 0.9404919374556768, 0.9435897299221584, 0.94256382612955, 0.940179990870612, 0.941683848698934, 0.9446986658232552, 0.940821050178437, 0.9435425287201291, 0.9484360842477708, 0.9460036087603796, 0.951217688265301, 0.9484460949897766, 0.9516626752558208, 0.9520447041307177, 0.9529647713615781, 0.944957645166488, 0.9515267014503479, 0.9537688805943444, 0.9530792335669199, 0.9503519918237414, 0.9496766201087407, 0.9544256471452259, 0.9545515662147885, 0.9533739941460746, 0.9511547145389375, 0.950701138802937, 0.9529890829608554, 0.9539691961946941, 0.9496494389715648, 0.9535671273867289, 0.9519774459657215, 0.9532208655561719, 0.953047731092998, 0.9534054512069339, 0.9545172424543471, 0.951329258226213, 0.9453496961366563, 0.9542253329640343, 0.9560310798031944, 0.9532237095492226, 0.9552770242804572, 0.9549150083746228, 0.9548978209495544, 0.9552226307846251, 0.9563329702331906, 0.9553599939459846, 0.9563587620144799, 0.9552841725803557, 0.9528345252786364, 0.9522493041697002, 0.9537731934161413, 0.9545858999093374, 0.9484274884064993, 0.9476261933644613, 0.9446514561062768, 0.9524739654291243, 0.9546631546247573, 0.9554858988239652, 0.9509400782131013, 0.956583382118316, 0.9545844665595463, 0.9516669682094029, 0.9565433207012358, 0.9518658547174363, 0.9524396246387845, 0.9533696784859612, 0.9565690826802027, 0.9526814222335815, 0.9552011830466134, 0.9542210343338194, 0.9550280528409141, 0.9550480700674511, 0.9575234836056119, 0.9563487072785696, 0.9561369660354796, 0.9571113969598498], 'val_mDice': [0.3065478170201892, 0.4253060207480476, 0.532354671330679, 0.5699538162776402, 0.5955641127768017, 0.6017705485934303, 0.6296788780462175, 0.613310843706131, 0.609760263136455, 0.6603341996669769, 0.6640140698069618, 0.6565113195351192, 0.6610963855470929, 0.6539206036499569, 0.665610154469808, 0.6618636931691851, 0.6675919393698374, 0.6783163845539093, 0.6784538882119315, 0.6748719158626738, 0.673277660494759, 0.6836002071698507, 0.6889905943757012, 0.6916533084142775, 0.6710215665045238, 0.6816561945847103, 0.6978080528123038, 0.6748634860629127, 0.6840757954688299, 0.679077760094688, 0.6922808729466938, 0.6976112169878823, 0.6825470796653202, 0.6922671227228074, 0.6893828724111829, 0.683341037659418, 0.6761503020922343, 0.6932875897203173, 0.6892591970307487, 0.6931995167618706, 0.6888295298530942, 0.6928065248898098, 0.6808358161222368, 0.6905915254638308, 0.6893292963504791, 0.669422237646012, 0.6988944141637712, 0.6874481581506275, 0.690712686095919, 0.6906397740046183, 0.6903993714423406, 0.6933507365839822, 0.6823542302563077, 0.6980370496000562, 0.7058691410791307, 0.6834417581558228, 0.6978895224276043, 0.6892685123852321, 0.6810781090032487, 0.6886442715213412, 0.6873223228113992, 0.6720470998968396, 0.6787571736744472, 0.6578973886512575, 0.6703445911407471, 0.6904576477550325, 0.6901141149657113, 0.6777714576039996, 0.6806231779711587, 0.6936664879322052, 0.6796331221149081, 0.6961444715658823, 0.6769191367285592, 0.6909634854112353, 0.6741725021884555, 0.690299989212127, 0.6900999333177295, 0.687344335374378, 0.6841470216001783, 0.6885823422954196, 0.6951295676685515, 0.6902305086453756, 0.7018203706968398, 0.6748079983961015, 0.697932759920756], 'loss': [10742.760845688514, 4801.333751802135, 3646.7141315717054, 3111.8797191134713, 2772.318829771884, 2531.438205785585, 2370.5197970040717, 2241.2373483710157, 2125.560814950234, 2053.2457624326025, 1972.5655755782664, 1912.2243266498062, 1867.9190289885028, 1811.9840526247856, 1787.4210849676347, 1732.8615342518337, 1697.5067630682206, 1672.1948660757773, 1638.0553023797318, 1606.3067792478641, 1580.8426622500147, 1557.8014095239805, 1541.9867219235236, 1507.9909985321121, 1493.4663792560225, 1474.6624479602995, 1456.0964575027883, 1437.359682877462, 1420.0590560418411, 1395.5355625295283, 1388.7162546362365, 1373.0522989858118, 1357.349657624737, 1346.0881150547702, 1333.631383767449, 1323.4617292827502, 1310.4509828334437, 1294.7279187818417, 1286.9875277474039, 1280.0090970921694, 1267.9461436664078, 1254.7694930078978, 1243.606536751079, 1239.2516397300205, 1230.5746740022503, 1220.580786764473, 1216.7535212034002, 1198.1331593425493, 1197.0935094743002, 1194.937419976974, 1181.362591027619, 1170.4471790951088, 1165.1617994046865, 1158.0645960096706, 1149.3207577446155, 1144.883048155064, 1134.0598976725057, 1128.866078098516, 1125.6378716447407, 1121.2386646032928, 1116.2191443502754, 1106.7266515413128, 1105.5568909490496, 1098.1207699097897, 1084.1006791074376, 1092.6539953902475, 1078.70626176563, 1076.494684690252, 1069.7569722582277, 1063.7263168373013, 1059.7630175355068, 1062.1612605144853, 1046.8096623028305, 1046.1507906259742, 1045.528865557359, 1033.24981573395, 1029.817750811874, 1031.7474113140916, 1025.6754781290183, 1024.4081407770552, 1019.1856197062276, 1014.5527009084041, 1013.7386173809556, 1012.7579683032714, 1003.6411107127506], 'acc': [0.854013854428717, 0.8958337909339966, 0.9109447864337158, 0.9192003080449497, 0.9245840482358029, 0.9285657726729897, 0.9311855984782043, 0.9333164237829813, 0.9352150912816982, 0.9364400006217553, 0.937942886107283, 0.9390762726453474, 0.9400083210105611, 0.9410626268817897, 0.9417451527016121, 0.9427998135066092, 0.9433360145127684, 0.9439245756724826, 0.9446823730172956, 0.9451865574851298, 0.9457340731547955, 0.9461808024053264, 0.9465175688712674, 0.9470665477903704, 0.9475412271229406, 0.9478210634795805, 0.9482466275443757, 0.9484982709783568, 0.9487778435918756, 0.949242127692313, 0.9494943713160822, 0.9497025889946041, 0.9499891706349843, 0.9501719861256511, 0.9505404515791118, 0.9507236448569488, 0.9508905030433971, 0.9511497131644044, 0.9512710111434025, 0.9514714579406819, 0.9515935220474614, 0.9519035576882208, 0.9520622822003174, 0.9522108368185392, 0.9523259730559037, 0.9525031162764961, 0.9526721239461566, 0.952906534503077, 0.9528716712855638, 0.9529511550083719, 0.9532164538887671, 0.9533531285469371, 0.9534811762874561, 0.9535317934696513, 0.9536718604273332, 0.9538338473275713, 0.954003868276193, 0.954012467918402, 0.9541304300253528, 0.9541772436211234, 0.9542379954880907, 0.9545764298436054, 0.9544734912471581, 0.9546574510801166, 0.9548697358838043, 0.9547386040674184, 0.9549457206764721, 0.954958438780391, 0.9550049694584789, 0.9550645804204548, 0.9552152703267678, 0.955132881918007, 0.9555065888642076, 0.9555043205433058, 0.9555856604268426, 0.9557159709885827, 0.9557628436315981, 0.9557337323366258, 0.9558291173635278, 0.9557936188586038, 0.9559524414359483, 0.9560226154817905, 0.9560204624869579, 0.9559627438238136, 0.9561714519214749], 'mDice': [0.20103963174882747, 0.4005141644517977, 0.4914515696354489, 0.5413657333097999, 0.5764833305802132, 0.6032955993775121, 0.621926761810619, 0.6377288645082281, 0.6516138618612229, 0.6612498709499984, 0.6714691032569604, 0.6795591197146145, 0.6854627430253195, 0.6930571464900661, 0.696550789579489, 0.7041050756810014, 0.7088529505857506, 0.7124838652716313, 0.7173689742783953, 0.7218939923214496, 0.7255743319294102, 0.7289027969847593, 0.7312685059490347, 0.7361060437604674, 0.7383151695763975, 0.741004766650182, 0.7438238005982968, 0.7466700188351094, 0.7491492795342222, 0.7527487116524406, 0.7539822335849676, 0.7562622883150405, 0.7586452680409995, 0.7602743135203149, 0.762866734250674, 0.7637666061223296, 0.7657425576388984, 0.7681608156224439, 0.769394314218489, 0.7705025838832011, 0.7722166835927309, 0.7743033732559318, 0.7760740805630969, 0.7767778619417823, 0.778082387814498, 0.7796244471707844, 0.7802888089024516, 0.7832305057164737, 0.7833159610703402, 0.7837676205428461, 0.7857430997000371, 0.7875791881744404, 0.7884012964040858, 0.7895445931990842, 0.7908513337522374, 0.7915727959346592, 0.7933465192963061, 0.794123749873436, 0.7946932533584034, 0.7953621696987354, 0.7962064662962186, 0.7977007255701353, 0.7978498546262631, 0.7990733567541675, 0.8013657319947074, 0.7999987623786688, 0.8021880727159115, 0.802597976199112, 0.8036796677476747, 0.8046384866063732, 0.805292597639739, 0.804927996603628, 0.8073531567047064, 0.8075426218850059, 0.8075816685942343, 0.8095946344837286, 0.8102478410797821, 0.809915729535934, 0.8108504591440024, 0.8111009477937311, 0.8118778391000339, 0.8126903228517482, 0.812860582107469, 0.8129902006013138, 0.8145028576812244]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:16<00:49, 16.42s/it]predicting test subjects:  50%|█████     | 2/4 [00:34<00:33, 16.96s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:53<00:17, 17.55s/it]predicting test subjects: 100%|██████████| 4/4 [01:12<00:00, 17.89s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:28<2:24:45, 28.02s/it]predicting train subjects:   1%|          | 2/311 [00:40<2:00:25, 23.38s/it]predicting train subjects:   1%|          | 3/311 [00:56<1:48:21, 21.11s/it]predicting train subjects:   1%|▏         | 4/311 [01:11<1:38:23, 19.23s/it]predicting train subjects:   2%|▏         | 5/311 [01:25<1:29:58, 17.64s/it]predicting train subjects:   2%|▏         | 6/311 [01:39<1:25:05, 16.74s/it]predicting train subjects:   2%|▏         | 7/311 [01:55<1:22:43, 16.33s/it]predicting train subjects:   3%|▎         | 8/311 [02:15<1:28:16, 17.48s/it]predicting train subjects:   3%|▎         | 9/311 [02:32<1:26:51, 17.26s/it]predicting train subjects:   3%|▎         | 10/311 [02:46<1:22:18, 16.41s/it]predicting train subjects:   4%|▎         | 11/311 [03:05<1:25:39, 17.13s/it]predicting train subjects:   4%|▍         | 12/311 [03:19<1:20:44, 16.20s/it]predicting train subjects:   4%|▍         | 13/311 [03:32<1:16:07, 15.33s/it]predicting train subjects:   5%|▍         | 14/311 [03:51<1:20:54, 16.34s/it]predicting train subjects:   5%|▍         | 15/311 [04:18<1:36:33, 19.57s/it]predicting train subjects:   5%|▌         | 16/311 [04:43<1:43:58, 21.15s/it]predicting train subjects:   5%|▌         | 17/311 [05:09<1:50:54, 22.64s/it]predicting train subjects:   6%|▌         | 18/311 [05:36<1:57:08, 23.99s/it]predicting train subjects:   6%|▌         | 19/311 [06:04<2:01:54, 25.05s/it]predicting train subjects:   6%|▋         | 20/311 [06:30<2:04:03, 25.58s/it]predicting train subjects:   7%|▋         | 21/311 [06:55<2:02:24, 25.33s/it]predicting train subjects:   7%|▋         | 22/311 [07:17<1:57:05, 24.31s/it]predicting train subjects:   7%|▋         | 23/311 [07:39<1:53:27, 23.64s/it]predicting train subjects:   8%|▊         | 24/311 [08:02<1:52:02, 23.42s/it]predicting train subjects:   8%|▊         | 25/311 [08:25<1:51:15, 23.34s/it]predicting train subjects:   8%|▊         | 26/311 [08:48<1:50:06, 23.18s/it]predicting train subjects:   9%|▊         | 27/311 [09:10<1:47:40, 22.75s/it]predicting train subjects:   9%|▉         | 28/311 [09:32<1:47:09, 22.72s/it]predicting train subjects:   9%|▉         | 29/311 [09:54<1:45:12, 22.38s/it]predicting train subjects:  10%|▉         | 30/311 [10:16<1:45:00, 22.42s/it]predicting train subjects:  10%|▉         | 31/311 [10:39<1:44:15, 22.34s/it]predicting train subjects:  10%|█         | 32/311 [11:00<1:42:50, 22.12s/it]predicting train subjects:  11%|█         | 33/311 [11:11<1:26:17, 18.63s/it]predicting train subjects:  11%|█         | 34/311 [11:21<1:14:49, 16.21s/it]predicting train subjects:  11%|█▏        | 35/311 [11:31<1:05:50, 14.31s/it]predicting train subjects:  12%|█▏        | 36/311 [11:41<1:00:01, 13.10s/it]predicting train subjects:  12%|█▏        | 37/311 [11:52<56:14, 12.32s/it]  predicting train subjects:  12%|█▏        | 38/311 [12:02<53:37, 11.78s/it]predicting train subjects:  13%|█▎        | 39/311 [12:12<50:55, 11.23s/it]predicting train subjects:  13%|█▎        | 40/311 [12:23<49:27, 10.95s/it]predicting train subjects:  13%|█▎        | 41/311 [12:33<48:42, 10.82s/it]predicting train subjects:  14%|█▎        | 42/311 [12:43<47:25, 10.58s/it]predicting train subjects:  14%|█▍        | 43/311 [12:54<46:48, 10.48s/it]predicting train subjects:  14%|█▍        | 44/311 [13:04<46:36, 10.47s/it]predicting train subjects:  14%|█▍        | 45/311 [13:14<45:48, 10.33s/it]predicting train subjects:  15%|█▍        | 46/311 [13:25<45:56, 10.40s/it]predicting train subjects:  15%|█▌        | 47/311 [13:35<45:58, 10.45s/it]predicting train subjects:  15%|█▌        | 48/311 [13:46<46:00, 10.49s/it]predicting train subjects:  16%|█▌        | 49/311 [13:56<45:17, 10.37s/it]predicting train subjects:  16%|█▌        | 50/311 [14:06<45:13, 10.40s/it]predicting train subjects:  16%|█▋        | 51/311 [14:19<48:43, 11.25s/it]predicting train subjects:  17%|█▋        | 52/311 [14:33<51:08, 11.85s/it]predicting train subjects:  17%|█▋        | 53/311 [14:46<52:44, 12.26s/it]predicting train subjects:  17%|█▋        | 54/311 [14:59<53:52, 12.58s/it]predicting train subjects:  18%|█▊        | 55/311 [15:12<53:56, 12.64s/it]predicting train subjects:  18%|█▊        | 56/311 [15:25<54:18, 12.78s/it]predicting train subjects:  18%|█▊        | 57/311 [15:38<54:37, 12.90s/it]predicting train subjects:  19%|█▊        | 58/311 [15:52<54:59, 13.04s/it]predicting train subjects:  19%|█▉        | 59/311 [16:05<55:07, 13.12s/it]predicting train subjects:  19%|█▉        | 60/311 [16:18<54:53, 13.12s/it]predicting train subjects:  20%|█▉        | 61/311 [16:31<54:50, 13.16s/it]predicting train subjects:  20%|█▉        | 62/311 [16:45<55:43, 13.43s/it]predicting train subjects:  20%|██        | 63/311 [16:59<55:14, 13.36s/it]predicting train subjects:  21%|██        | 64/311 [17:12<54:55, 13.34s/it]predicting train subjects:  21%|██        | 65/311 [17:25<54:31, 13.30s/it]predicting train subjects:  21%|██        | 66/311 [17:38<54:09, 13.26s/it]predicting train subjects:  22%|██▏       | 67/311 [17:51<53:13, 13.09s/it]predicting train subjects:  22%|██▏       | 68/311 [18:03<52:11, 12.89s/it]predicting train subjects:  22%|██▏       | 69/311 [18:16<51:30, 12.77s/it]predicting train subjects:  23%|██▎       | 70/311 [18:29<51:07, 12.73s/it]predicting train subjects:  23%|██▎       | 71/311 [18:42<51:17, 12.82s/it]predicting train subjects:  23%|██▎       | 72/311 [18:55<51:38, 12.97s/it]predicting train subjects:  23%|██▎       | 73/311 [19:08<51:13, 12.92s/it]predicting train subjects:  24%|██▍       | 74/311 [19:21<50:58, 12.91s/it]predicting train subjects:  24%|██▍       | 75/311 [19:33<50:23, 12.81s/it]predicting train subjects:  24%|██▍       | 76/311 [19:46<49:48, 12.72s/it]predicting train subjects:  25%|██▍       | 77/311 [19:58<49:40, 12.74s/it]predicting train subjects:  25%|██▌       | 78/311 [20:11<49:31, 12.75s/it]predicting train subjects:  25%|██▌       | 79/311 [20:24<49:19, 12.76s/it]predicting train subjects:  26%|██▌       | 80/311 [20:37<49:21, 12.82s/it]predicting train subjects:  26%|██▌       | 81/311 [20:50<49:12, 12.84s/it]predicting train subjects:  26%|██▋       | 82/311 [21:03<49:29, 12.97s/it]predicting train subjects:  27%|██▋       | 83/311 [21:17<49:46, 13.10s/it]predicting train subjects:  27%|██▋       | 84/311 [21:30<49:28, 13.08s/it]predicting train subjects:  27%|██▋       | 85/311 [21:41<47:21, 12.57s/it]predicting train subjects:  28%|██▊       | 86/311 [21:52<45:51, 12.23s/it]predicting train subjects:  28%|██▊       | 87/311 [22:04<44:59, 12.05s/it]predicting train subjects:  28%|██▊       | 88/311 [22:16<44:27, 11.96s/it]predicting train subjects:  29%|██▊       | 89/311 [22:28<44:13, 11.95s/it]predicting train subjects:  29%|██▉       | 90/311 [22:40<43:59, 11.95s/it]predicting train subjects:  29%|██▉       | 91/311 [22:51<43:21, 11.83s/it]predicting train subjects:  30%|██▉       | 92/311 [23:03<43:22, 11.88s/it]predicting train subjects:  30%|██▉       | 93/311 [23:15<43:07, 11.87s/it]predicting train subjects:  30%|███       | 94/311 [23:27<42:50, 11.84s/it]predicting train subjects:  31%|███       | 95/311 [23:39<42:31, 11.81s/it]predicting train subjects:  31%|███       | 96/311 [23:50<42:14, 11.79s/it]predicting train subjects:  31%|███       | 97/311 [24:02<41:57, 11.76s/it]predicting train subjects:  32%|███▏      | 98/311 [24:14<41:36, 11.72s/it]predicting train subjects:  32%|███▏      | 99/311 [24:26<41:38, 11.78s/it]predicting train subjects:  32%|███▏      | 100/311 [24:37<41:31, 11.81s/it]predicting train subjects:  32%|███▏      | 101/311 [24:49<41:05, 11.74s/it]predicting train subjects:  33%|███▎      | 102/311 [25:01<40:41, 11.68s/it]predicting train subjects:  33%|███▎      | 103/311 [25:12<40:42, 11.74s/it]predicting train subjects:  33%|███▎      | 104/311 [25:24<40:46, 11.82s/it]predicting train subjects:  34%|███▍      | 105/311 [25:36<40:40, 11.85s/it]predicting train subjects:  34%|███▍      | 106/311 [25:48<40:08, 11.75s/it]predicting train subjects:  34%|███▍      | 107/311 [25:59<39:43, 11.69s/it]predicting train subjects:  35%|███▍      | 108/311 [26:11<39:31, 11.68s/it]predicting train subjects:  35%|███▌      | 109/311 [26:23<39:37, 11.77s/it]predicting train subjects:  35%|███▌      | 110/311 [26:35<39:26, 11.78s/it]predicting train subjects:  36%|███▌      | 111/311 [26:46<39:01, 11.71s/it]predicting train subjects:  36%|███▌      | 112/311 [26:58<38:48, 11.70s/it]predicting train subjects:  36%|███▋      | 113/311 [27:10<39:01, 11.82s/it]predicting train subjects:  37%|███▋      | 114/311 [27:33<49:18, 15.02s/it]predicting train subjects:  37%|███▋      | 115/311 [27:55<56:12, 17.21s/it]predicting train subjects:  37%|███▋      | 116/311 [28:17<1:01:01, 18.78s/it]predicting train subjects:  38%|███▊      | 117/311 [28:40<1:04:52, 20.07s/it]predicting train subjects:  38%|███▊      | 118/311 [29:03<1:06:29, 20.67s/it]predicting train subjects:  38%|███▊      | 119/311 [29:26<1:08:36, 21.44s/it]predicting train subjects:  39%|███▊      | 120/311 [29:49<1:09:29, 21.83s/it]predicting train subjects:  39%|███▉      | 121/311 [30:11<1:09:38, 21.99s/it]predicting train subjects:  39%|███▉      | 122/311 [30:33<1:09:30, 22.06s/it]predicting train subjects:  40%|███▉      | 123/311 [30:56<1:10:02, 22.35s/it]predicting train subjects:  40%|███▉      | 124/311 [31:18<1:09:37, 22.34s/it]predicting train subjects:  40%|████      | 125/311 [31:41<1:09:49, 22.52s/it]predicting train subjects:  41%|████      | 126/311 [32:04<1:09:41, 22.60s/it]predicting train subjects:  41%|████      | 127/311 [32:27<1:09:29, 22.66s/it]predicting train subjects:  41%|████      | 128/311 [32:50<1:09:37, 22.83s/it]predicting train subjects:  41%|████▏     | 129/311 [33:12<1:08:23, 22.55s/it]predicting train subjects:  42%|████▏     | 130/311 [33:34<1:07:48, 22.48s/it]predicting train subjects:  42%|████▏     | 131/311 [33:56<1:06:47, 22.27s/it]predicting train subjects:  42%|████▏     | 132/311 [34:07<56:01, 18.78s/it]  predicting train subjects:  43%|████▎     | 133/311 [34:17<48:12, 16.25s/it]predicting train subjects:  43%|████▎     | 134/311 [34:29<43:36, 14.78s/it]predicting train subjects:  43%|████▎     | 135/311 [34:40<40:05, 13.67s/it]predicting train subjects:  44%|████▎     | 136/311 [34:50<37:20, 12.80s/it]predicting train subjects:  44%|████▍     | 137/311 [35:02<35:42, 12.32s/it]predicting train subjects:  44%|████▍     | 138/311 [35:13<34:40, 12.03s/it]predicting train subjects:  45%|████▍     | 139/311 [35:23<33:07, 11.56s/it]predicting train subjects:  45%|████▌     | 140/311 [35:34<32:07, 11.27s/it]predicting train subjects:  45%|████▌     | 141/311 [35:45<31:47, 11.22s/it]predicting train subjects:  46%|████▌     | 142/311 [35:56<31:07, 11.05s/it]predicting train subjects:  46%|████▌     | 143/311 [36:07<30:56, 11.05s/it]predicting train subjects:  46%|████▋     | 144/311 [36:18<30:47, 11.06s/it]predicting train subjects:  47%|████▋     | 145/311 [36:29<30:24, 10.99s/it]predicting train subjects:  47%|████▋     | 146/311 [36:40<30:22, 11.04s/it]predicting train subjects:  47%|████▋     | 147/311 [36:51<30:17, 11.08s/it]predicting train subjects:  48%|████▊     | 148/311 [37:02<30:15, 11.14s/it]predicting train subjects:  48%|████▊     | 149/311 [37:13<29:52, 11.06s/it]predicting train subjects:  48%|████▊     | 150/311 [37:27<32:12, 12.00s/it]predicting train subjects:  49%|████▊     | 151/311 [37:42<33:46, 12.67s/it]predicting train subjects:  49%|████▉     | 152/311 [37:56<34:35, 13.06s/it]predicting train subjects:  49%|████▉     | 153/311 [38:09<35:01, 13.30s/it]predicting train subjects:  50%|████▉     | 154/311 [38:23<35:08, 13.43s/it]predicting train subjects:  50%|████▉     | 155/311 [38:37<35:32, 13.67s/it]predicting train subjects:  50%|█████     | 156/311 [38:51<35:31, 13.75s/it]predicting train subjects:  50%|█████     | 157/311 [39:05<35:20, 13.77s/it]predicting train subjects:  51%|█████     | 158/311 [39:19<35:05, 13.76s/it]predicting train subjects:  51%|█████     | 159/311 [39:33<35:01, 13.83s/it]predicting train subjects:  51%|█████▏    | 160/311 [39:47<35:07, 13.96s/it]predicting train subjects:  52%|█████▏    | 161/311 [40:05<37:42, 15.09s/it]predicting train subjects:  52%|█████▏    | 162/311 [40:23<39:40, 15.98s/it]predicting train subjects:  52%|█████▏    | 163/311 [40:41<41:10, 16.69s/it]predicting train subjects:  53%|█████▎    | 164/311 [40:59<41:42, 17.03s/it]predicting train subjects:  53%|█████▎    | 165/311 [41:17<42:21, 17.41s/it]predicting train subjects:  53%|█████▎    | 166/311 [41:35<41:54, 17.34s/it]predicting train subjects:  54%|█████▎    | 167/311 [41:50<39:55, 16.64s/it]predicting train subjects:  54%|█████▍    | 168/311 [42:06<39:09, 16.43s/it]predicting train subjects:  54%|█████▍    | 169/311 [42:22<38:39, 16.34s/it]predicting train subjects:  55%|█████▍    | 170/311 [42:36<37:10, 15.82s/it]predicting train subjects:  55%|█████▍    | 171/311 [42:51<36:18, 15.56s/it]predicting train subjects:  55%|█████▌    | 172/311 [43:07<36:10, 15.62s/it]predicting train subjects:  56%|█████▌    | 173/311 [43:23<36:02, 15.67s/it]predicting train subjects:  56%|█████▌    | 174/311 [43:39<36:27, 15.96s/it]predicting train subjects:  56%|█████▋    | 175/311 [43:56<36:47, 16.23s/it]predicting train subjects:  57%|█████▋    | 176/311 [44:14<37:14, 16.55s/it]predicting train subjects:  57%|█████▋    | 177/311 [44:32<38:12, 17.11s/it]predicting train subjects:  57%|█████▋    | 178/311 [44:50<38:16, 17.26s/it]predicting train subjects:  58%|█████▊    | 179/311 [45:07<38:05, 17.32s/it]predicting train subjects:  58%|█████▊    | 180/311 [45:25<37:59, 17.40s/it]predicting train subjects:  58%|█████▊    | 181/311 [45:42<37:48, 17.45s/it]predicting train subjects:  59%|█████▊    | 182/311 [45:59<37:02, 17.23s/it]predicting train subjects:  59%|█████▉    | 183/311 [46:16<36:30, 17.11s/it]predicting train subjects:  59%|█████▉    | 184/311 [46:32<35:29, 16.77s/it]predicting train subjects:  59%|█████▉    | 185/311 [46:48<34:37, 16.49s/it]predicting train subjects:  60%|█████▉    | 186/311 [47:03<33:52, 16.26s/it]predicting train subjects:  60%|██████    | 187/311 [47:20<34:11, 16.54s/it]predicting train subjects:  60%|██████    | 188/311 [47:35<32:56, 16.07s/it]predicting train subjects:  61%|██████    | 189/311 [47:51<32:19, 15.90s/it]predicting train subjects:  61%|██████    | 190/311 [48:04<30:12, 14.98s/it]predicting train subjects:  61%|██████▏   | 191/311 [48:16<28:18, 14.15s/it]predicting train subjects:  62%|██████▏   | 192/311 [48:27<26:24, 13.31s/it]predicting train subjects:  62%|██████▏   | 193/311 [48:39<25:17, 12.86s/it]predicting train subjects:  62%|██████▏   | 194/311 [48:51<24:38, 12.63s/it]predicting train subjects:  63%|██████▎   | 195/311 [49:03<23:48, 12.32s/it]predicting train subjects:  63%|██████▎   | 196/311 [49:14<23:06, 12.05s/it]predicting train subjects:  63%|██████▎   | 197/311 [49:26<22:54, 12.05s/it]predicting train subjects:  64%|██████▎   | 198/311 [49:38<22:39, 12.03s/it]predicting train subjects:  64%|██████▍   | 199/311 [49:50<22:19, 11.96s/it]predicting train subjects:  64%|██████▍   | 200/311 [50:01<21:44, 11.76s/it]predicting train subjects:  65%|██████▍   | 201/311 [50:13<21:43, 11.85s/it]predicting train subjects:  65%|██████▍   | 202/311 [50:25<21:32, 11.86s/it]predicting train subjects:  65%|██████▌   | 203/311 [50:37<21:23, 11.88s/it]predicting train subjects:  66%|██████▌   | 204/311 [50:49<21:01, 11.79s/it]predicting train subjects:  66%|██████▌   | 205/311 [51:01<20:46, 11.76s/it]predicting train subjects:  66%|██████▌   | 206/311 [51:13<20:42, 11.83s/it]predicting train subjects:  67%|██████▋   | 207/311 [51:24<20:34, 11.87s/it]predicting train subjects:  67%|██████▋   | 208/311 [51:36<20:04, 11.69s/it]predicting train subjects:  67%|██████▋   | 209/311 [51:48<20:01, 11.78s/it]predicting train subjects:  68%|██████▊   | 210/311 [52:00<20:00, 11.89s/it]predicting train subjects:  68%|██████▊   | 211/311 [52:12<19:47, 11.88s/it]predicting train subjects:  68%|██████▊   | 212/311 [52:23<19:18, 11.71s/it]predicting train subjects:  68%|██████▊   | 213/311 [52:46<24:37, 15.07s/it]predicting train subjects:  69%|██████▉   | 214/311 [53:08<27:48, 17.20s/it]predicting train subjects:  69%|██████▉   | 215/311 [53:30<29:56, 18.72s/it]predicting train subjects:  69%|██████▉   | 216/311 [53:52<31:14, 19.73s/it]predicting train subjects:  70%|██████▉   | 217/311 [54:16<32:33, 20.78s/it]predicting train subjects:  70%|███████   | 218/311 [54:37<32:37, 21.05s/it]predicting train subjects:  70%|███████   | 219/311 [55:00<33:10, 21.64s/it]predicting train subjects:  71%|███████   | 220/311 [55:22<32:58, 21.74s/it]predicting train subjects:  71%|███████   | 221/311 [55:45<32:51, 21.91s/it]predicting train subjects:  71%|███████▏  | 222/311 [56:07<32:31, 21.93s/it]predicting train subjects:  72%|███████▏  | 223/311 [56:29<32:32, 22.19s/it]predicting train subjects:  72%|███████▏  | 224/311 [56:51<31:58, 22.05s/it]predicting train subjects:  72%|███████▏  | 225/311 [57:13<31:42, 22.13s/it]predicting train subjects:  73%|███████▎  | 226/311 [57:36<31:25, 22.18s/it]predicting train subjects:  73%|███████▎  | 227/311 [57:58<31:14, 22.32s/it]predicting train subjects:  73%|███████▎  | 228/311 [58:21<31:00, 22.42s/it]predicting train subjects:  74%|███████▎  | 229/311 [58:44<30:39, 22.43s/it]predicting train subjects:  74%|███████▍  | 230/311 [59:06<30:14, 22.40s/it]predicting train subjects:  74%|███████▍  | 231/311 [59:16<25:08, 18.86s/it]predicting train subjects:  75%|███████▍  | 232/311 [59:27<21:28, 16.31s/it]predicting train subjects:  75%|███████▍  | 233/311 [59:37<18:48, 14.47s/it]predicting train subjects:  75%|███████▌  | 234/311 [59:48<17:09, 13.37s/it]predicting train subjects:  76%|███████▌  | 235/311 [59:59<16:01, 12.65s/it]predicting train subjects:  76%|███████▌  | 236/311 [1:00:09<14:53, 11.91s/it]predicting train subjects:  76%|███████▌  | 237/311 [1:00:19<14:10, 11.49s/it]predicting train subjects:  77%|███████▋  | 238/311 [1:00:30<13:37, 11.20s/it]predicting train subjects:  77%|███████▋  | 239/311 [1:00:40<13:09, 10.96s/it]predicting train subjects:  77%|███████▋  | 240/311 [1:00:51<12:49, 10.84s/it]predicting train subjects:  77%|███████▋  | 241/311 [1:01:02<12:33, 10.77s/it]predicting train subjects:  78%|███████▊  | 242/311 [1:01:12<12:13, 10.63s/it]predicting train subjects:  78%|███████▊  | 243/311 [1:01:22<11:56, 10.53s/it]predicting train subjects:  78%|███████▊  | 244/311 [1:01:33<11:50, 10.61s/it]predicting train subjects:  79%|███████▉  | 245/311 [1:01:43<11:34, 10.52s/it]predicting train subjects:  79%|███████▉  | 246/311 [1:01:53<11:16, 10.40s/it]predicting train subjects:  79%|███████▉  | 247/311 [1:02:04<11:10, 10.48s/it]predicting train subjects:  80%|███████▉  | 248/311 [1:02:15<11:10, 10.65s/it]predicting train subjects:  80%|████████  | 249/311 [1:02:28<11:45, 11.38s/it]predicting train subjects:  80%|████████  | 250/311 [1:02:41<12:01, 11.83s/it]predicting train subjects:  81%|████████  | 251/311 [1:02:54<12:15, 12.26s/it]predicting train subjects:  81%|████████  | 252/311 [1:03:08<12:24, 12.62s/it]predicting train subjects:  81%|████████▏ | 253/311 [1:03:21<12:23, 12.82s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:03:35<12:23, 13.04s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:03:48<12:23, 13.27s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:04:02<12:09, 13.27s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:04:15<11:52, 13.20s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:04:28<11:37, 13.16s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:04:41<11:24, 13.16s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:04:54<11:12, 13.19s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:05:08<11:00, 13.22s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:05:21<10:53, 13.34s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:05:34<10:38, 13.31s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:05:48<10:24, 13.29s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:06:00<10:03, 13.11s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:06:13<09:44, 13.00s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:06:26<09:30, 12.96s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:06:39<09:14, 12.90s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:06:52<09:05, 13.00s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:07:05<08:52, 13.00s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:07:18<08:39, 13.00s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:07:31<08:25, 12.97s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:07:43<08:06, 12.79s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:07:56<07:51, 12.73s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:08:09<07:39, 12.77s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:08:22<07:31, 12.91s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:08:35<07:19, 12.93s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:08:48<07:10, 13.03s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:09:01<06:59, 13.12s/it]predicting train subjects:  90%|█████████ | 280/311 [1:09:15<06:46, 13.11s/it]predicting train subjects:  90%|█████████ | 281/311 [1:09:28<06:32, 13.10s/it]predicting train subjects:  91%|█████████ | 282/311 [1:09:41<06:25, 13.28s/it]predicting train subjects:  91%|█████████ | 283/311 [1:09:53<06:01, 12.93s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:10:06<05:42, 12.70s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:10:17<05:22, 12.40s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:10:30<05:11, 12.48s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:10:42<04:57, 12.39s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:10:54<04:42, 12.28s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:11:06<04:27, 12.18s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:11:18<04:11, 11.98s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:11:29<03:57, 11.90s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:11:42<03:47, 11.97s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:11:54<03:35, 11.99s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:12:05<03:21, 11.85s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:12:17<03:09, 11.84s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:12:29<02:59, 11.94s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:12:41<02:47, 11.98s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:12:53<02:34, 11.88s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:13:04<02:21, 11.82s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:13:16<02:10, 11.87s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:13:29<01:59, 11.94s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:13:41<01:47, 11.95s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:13:52<01:35, 11.90s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:14:04<01:22, 11.79s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:14:16<01:11, 11.91s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:14:28<01:00, 12.02s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:14:41<00:48, 12.08s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:14:53<00:36, 12.22s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:15:05<00:24, 12.10s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:15:17<00:12, 12.13s/it]predicting train subjects: 100%|██████████| 311/311 [1:15:29<00:00, 12.12s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:28:50, 17.20s/it]Loading train:   1%|          | 2/311 [00:25<1:15:24, 14.64s/it]Loading train:   1%|          | 3/311 [00:36<1:09:19, 13.51s/it]Loading train:   1%|▏         | 4/311 [00:46<1:04:03, 12.52s/it]Loading train:   2%|▏         | 5/311 [00:56<59:04, 11.58s/it]  Loading train:   2%|▏         | 6/311 [01:06<55:57, 11.01s/it]Loading train:   2%|▏         | 7/311 [01:16<55:34, 10.97s/it]Loading train:   3%|▎         | 8/311 [01:28<56:55, 11.27s/it]Loading train:   3%|▎         | 9/311 [01:39<56:28, 11.22s/it]Loading train:   3%|▎         | 10/311 [01:49<53:40, 10.70s/it]Loading train:   4%|▎         | 11/311 [02:02<56:26, 11.29s/it]Loading train:   4%|▍         | 12/311 [02:12<54:11, 10.87s/it]Loading train:   4%|▍         | 13/311 [02:21<52:28, 10.56s/it]Loading train:   5%|▍         | 14/311 [02:34<54:51, 11.08s/it]Loading train:   5%|▍         | 15/311 [02:43<52:01, 10.54s/it]Loading train:   5%|▌         | 16/311 [02:52<50:03, 10.18s/it]Loading train:   5%|▌         | 17/311 [03:01<48:12,  9.84s/it]Loading train:   6%|▌         | 18/311 [03:11<47:20,  9.69s/it]Loading train:   6%|▌         | 19/311 [03:20<46:39,  9.59s/it]Loading train:   6%|▋         | 20/311 [03:29<45:33,  9.39s/it]Loading train:   7%|▋         | 21/311 [03:38<45:24,  9.39s/it]Loading train:   7%|▋         | 22/311 [03:48<45:11,  9.38s/it]Loading train:   7%|▋         | 23/311 [03:57<44:53,  9.35s/it]Loading train:   8%|▊         | 24/311 [04:06<44:36,  9.33s/it]Loading train:   8%|▊         | 25/311 [04:16<44:48,  9.40s/it]Loading train:   8%|▊         | 26/311 [04:25<44:22,  9.34s/it]Loading train:   9%|▊         | 27/311 [04:34<44:06,  9.32s/it]Loading train:   9%|▉         | 28/311 [04:44<44:13,  9.38s/it]Loading train:   9%|▉         | 29/311 [04:53<44:04,  9.38s/it]Loading train:  10%|▉         | 30/311 [05:02<43:35,  9.31s/it]Loading train:  10%|▉         | 31/311 [05:12<43:29,  9.32s/it]Loading train:  10%|█         | 32/311 [05:21<43:31,  9.36s/it]Loading train:  11%|█         | 33/311 [05:26<37:20,  8.06s/it]Loading train:  11%|█         | 34/311 [05:31<32:31,  7.05s/it]Loading train:  11%|█▏        | 35/311 [05:35<28:49,  6.27s/it]Loading train:  12%|█▏        | 36/311 [05:40<26:19,  5.74s/it]Loading train:  12%|█▏        | 37/311 [05:45<25:09,  5.51s/it]Loading train:  12%|█▏        | 38/311 [05:49<23:55,  5.26s/it]Loading train:  13%|█▎        | 39/311 [05:54<23:04,  5.09s/it]Loading train:  13%|█▎        | 40/311 [05:59<22:35,  5.00s/it]Loading train:  13%|█▎        | 41/311 [06:04<21:57,  4.88s/it]Loading train:  14%|█▎        | 42/311 [06:08<21:34,  4.81s/it]Loading train:  14%|█▍        | 43/311 [06:13<21:06,  4.73s/it]Loading train:  14%|█▍        | 44/311 [06:17<20:53,  4.69s/it]Loading train:  14%|█▍        | 45/311 [06:22<20:52,  4.71s/it]Loading train:  15%|█▍        | 46/311 [06:27<20:47,  4.71s/it]Loading train:  15%|█▌        | 47/311 [06:31<20:32,  4.67s/it]Loading train:  15%|█▌        | 48/311 [06:36<20:17,  4.63s/it]Loading train:  16%|█▌        | 49/311 [06:41<20:23,  4.67s/it]Loading train:  16%|█▌        | 50/311 [06:45<20:20,  4.68s/it]Loading train:  16%|█▋        | 51/311 [06:51<21:33,  4.98s/it]Loading train:  17%|█▋        | 52/311 [06:57<22:37,  5.24s/it]Loading train:  17%|█▋        | 53/311 [07:03<23:02,  5.36s/it]Loading train:  17%|█▋        | 54/311 [07:08<23:17,  5.44s/it]Loading train:  18%|█▊        | 55/311 [07:14<23:22,  5.48s/it]Loading train:  18%|█▊        | 56/311 [07:19<23:22,  5.50s/it]Loading train:  18%|█▊        | 57/311 [07:25<23:40,  5.59s/it]Loading train:  19%|█▊        | 58/311 [07:31<23:59,  5.69s/it]Loading train:  19%|█▉        | 59/311 [07:37<24:02,  5.72s/it]Loading train:  19%|█▉        | 60/311 [07:43<24:03,  5.75s/it]Loading train:  20%|█▉        | 61/311 [07:48<23:35,  5.66s/it]Loading train:  20%|█▉        | 62/311 [07:54<23:20,  5.63s/it]Loading train:  20%|██        | 63/311 [07:59<23:29,  5.68s/it]Loading train:  21%|██        | 64/311 [08:05<23:46,  5.78s/it]Loading train:  21%|██        | 65/311 [08:11<23:47,  5.80s/it]Loading train:  21%|██        | 66/311 [08:17<23:33,  5.77s/it]Loading train:  22%|██▏       | 67/311 [08:23<23:20,  5.74s/it]Loading train:  22%|██▏       | 68/311 [08:28<23:21,  5.77s/it]Loading train:  22%|██▏       | 69/311 [08:34<22:42,  5.63s/it]Loading train:  23%|██▎       | 70/311 [08:40<22:45,  5.67s/it]Loading train:  23%|██▎       | 71/311 [08:45<22:38,  5.66s/it]Loading train:  23%|██▎       | 72/311 [08:51<22:35,  5.67s/it]Loading train:  23%|██▎       | 73/311 [08:56<22:19,  5.63s/it]Loading train:  24%|██▍       | 74/311 [09:02<22:03,  5.58s/it]Loading train:  24%|██▍       | 75/311 [09:08<22:04,  5.61s/it]Loading train:  24%|██▍       | 76/311 [09:13<22:12,  5.67s/it]Loading train:  25%|██▍       | 77/311 [09:19<21:59,  5.64s/it]Loading train:  25%|██▌       | 78/311 [09:24<21:43,  5.60s/it]Loading train:  25%|██▌       | 79/311 [09:30<21:40,  5.60s/it]Loading train:  26%|██▌       | 80/311 [09:35<21:16,  5.53s/it]Loading train:  26%|██▌       | 81/311 [09:41<20:57,  5.47s/it]Loading train:  26%|██▋       | 82/311 [09:46<20:49,  5.46s/it]Loading train:  27%|██▋       | 83/311 [09:51<20:31,  5.40s/it]Loading train:  27%|██▋       | 84/311 [09:57<20:26,  5.40s/it]Loading train:  27%|██▋       | 85/311 [10:02<20:12,  5.37s/it]Loading train:  28%|██▊       | 86/311 [10:07<19:58,  5.33s/it]Loading train:  28%|██▊       | 87/311 [10:12<19:36,  5.25s/it]Loading train:  28%|██▊       | 88/311 [10:17<19:09,  5.15s/it]Loading train:  29%|██▊       | 89/311 [10:23<19:02,  5.15s/it]Loading train:  29%|██▉       | 90/311 [10:28<18:59,  5.16s/it]Loading train:  29%|██▉       | 91/311 [10:33<19:00,  5.19s/it]Loading train:  30%|██▉       | 92/311 [10:38<18:57,  5.19s/it]Loading train:  30%|██▉       | 93/311 [10:43<18:32,  5.10s/it]Loading train:  30%|███       | 94/311 [10:48<18:22,  5.08s/it]Loading train:  31%|███       | 95/311 [10:53<18:19,  5.09s/it]Loading train:  31%|███       | 96/311 [10:58<18:18,  5.11s/it]Loading train:  31%|███       | 97/311 [11:03<18:14,  5.12s/it]Loading train:  32%|███▏      | 98/311 [11:08<18:02,  5.08s/it]Loading train:  32%|███▏      | 99/311 [11:13<17:53,  5.06s/it]Loading train:  32%|███▏      | 100/311 [11:18<17:43,  5.04s/it]Loading train:  32%|███▏      | 101/311 [11:24<17:45,  5.08s/it]Loading train:  33%|███▎      | 102/311 [11:29<17:53,  5.14s/it]Loading train:  33%|███▎      | 103/311 [11:34<18:00,  5.19s/it]Loading train:  33%|███▎      | 104/311 [11:40<18:13,  5.28s/it]Loading train:  34%|███▍      | 105/311 [11:45<17:51,  5.20s/it]Loading train:  34%|███▍      | 106/311 [11:50<17:46,  5.20s/it]Loading train:  34%|███▍      | 107/311 [11:55<17:39,  5.19s/it]Loading train:  35%|███▍      | 108/311 [12:00<17:20,  5.13s/it]Loading train:  35%|███▌      | 109/311 [12:06<17:35,  5.22s/it]Loading train:  35%|███▌      | 110/311 [12:11<17:27,  5.21s/it]Loading train:  36%|███▌      | 111/311 [12:16<17:30,  5.25s/it]Loading train:  36%|███▌      | 112/311 [12:22<17:45,  5.35s/it]Loading train:  36%|███▋      | 113/311 [12:27<17:32,  5.31s/it]Loading train:  37%|███▋      | 114/311 [12:36<21:25,  6.52s/it]Loading train:  37%|███▋      | 115/311 [12:45<23:55,  7.32s/it]Loading train:  37%|███▋      | 116/311 [12:54<25:27,  7.84s/it]Loading train:  38%|███▊      | 117/311 [13:04<26:41,  8.25s/it]Loading train:  38%|███▊      | 118/311 [13:13<27:28,  8.54s/it]Loading train:  38%|███▊      | 119/311 [13:22<28:06,  8.79s/it]Loading train:  39%|███▊      | 120/311 [13:31<28:12,  8.86s/it]Loading train:  39%|███▉      | 121/311 [13:41<28:28,  8.99s/it]Loading train:  39%|███▉      | 122/311 [13:50<28:24,  9.02s/it]Loading train:  40%|███▉      | 123/311 [13:59<28:32,  9.11s/it]Loading train:  40%|███▉      | 124/311 [14:08<28:34,  9.17s/it]Loading train:  40%|████      | 125/311 [14:18<28:58,  9.34s/it]Loading train:  41%|████      | 126/311 [14:27<28:34,  9.27s/it]Loading train:  41%|████      | 127/311 [14:37<28:39,  9.35s/it]Loading train:  41%|████      | 128/311 [14:46<28:18,  9.28s/it]Loading train:  41%|████▏     | 129/311 [14:55<28:01,  9.24s/it]Loading train:  42%|████▏     | 130/311 [15:04<27:59,  9.28s/it]Loading train:  42%|████▏     | 131/311 [15:13<27:30,  9.17s/it]Loading train:  42%|████▏     | 132/311 [15:18<23:43,  7.95s/it]Loading train:  43%|████▎     | 133/311 [15:23<20:36,  6.95s/it]Loading train:  43%|████▎     | 134/311 [15:28<18:28,  6.26s/it]Loading train:  43%|████▎     | 135/311 [15:32<16:56,  5.78s/it]Loading train:  44%|████▎     | 136/311 [15:37<15:46,  5.41s/it]Loading train:  44%|████▍     | 137/311 [15:41<14:55,  5.15s/it]Loading train:  44%|████▍     | 138/311 [15:46<14:30,  5.03s/it]Loading train:  45%|████▍     | 139/311 [15:51<14:05,  4.91s/it]Loading train:  45%|████▌     | 140/311 [15:55<13:47,  4.84s/it]Loading train:  45%|████▌     | 141/311 [16:00<13:30,  4.77s/it]Loading train:  46%|████▌     | 142/311 [16:05<13:24,  4.76s/it]Loading train:  46%|████▌     | 143/311 [16:09<13:18,  4.76s/it]Loading train:  46%|████▋     | 144/311 [16:14<13:13,  4.75s/it]Loading train:  47%|████▋     | 145/311 [16:19<13:09,  4.76s/it]Loading train:  47%|████▋     | 146/311 [16:24<13:03,  4.75s/it]Loading train:  47%|████▋     | 147/311 [16:29<13:02,  4.77s/it]Loading train:  48%|████▊     | 148/311 [16:33<12:55,  4.76s/it]Loading train:  48%|████▊     | 149/311 [16:38<12:49,  4.75s/it]Loading train:  48%|████▊     | 150/311 [16:44<13:40,  5.09s/it]Loading train:  49%|████▊     | 151/311 [16:50<14:02,  5.27s/it]Loading train:  49%|████▉     | 152/311 [16:55<14:26,  5.45s/it]Loading train:  49%|████▉     | 153/311 [17:01<14:44,  5.60s/it]Loading train:  50%|████▉     | 154/311 [17:07<14:51,  5.68s/it]Loading train:  50%|████▉     | 155/311 [17:13<14:51,  5.72s/it]Loading train:  50%|█████     | 156/311 [17:19<14:44,  5.71s/it]Loading train:  50%|█████     | 157/311 [17:24<14:34,  5.68s/it]Loading train:  51%|█████     | 158/311 [17:30<14:34,  5.71s/it]Loading train:  51%|█████     | 159/311 [17:36<14:30,  5.73s/it]Loading train:  51%|█████▏    | 160/311 [17:42<14:28,  5.75s/it]Loading train:  52%|█████▏    | 161/311 [17:48<14:26,  5.78s/it]Loading train:  52%|█████▏    | 162/311 [17:53<14:14,  5.73s/it]Loading train:  52%|█████▏    | 163/311 [17:59<14:12,  5.76s/it]Loading train:  53%|█████▎    | 164/311 [18:05<14:17,  5.84s/it]Loading train:  53%|█████▎    | 165/311 [18:11<14:06,  5.80s/it]Loading train:  53%|█████▎    | 166/311 [18:16<13:57,  5.78s/it]Loading train:  54%|█████▎    | 167/311 [18:22<13:42,  5.71s/it]Loading train:  54%|█████▍    | 168/311 [18:28<13:46,  5.78s/it]Loading train:  54%|█████▍    | 169/311 [18:34<13:48,  5.83s/it]Loading train:  55%|█████▍    | 170/311 [18:39<13:30,  5.75s/it]Loading train:  55%|█████▍    | 171/311 [18:45<13:24,  5.74s/it]Loading train:  55%|█████▌    | 172/311 [18:51<13:26,  5.80s/it]Loading train:  56%|█████▌    | 173/311 [18:57<13:15,  5.76s/it]Loading train:  56%|█████▌    | 174/311 [19:03<13:15,  5.81s/it]Loading train:  56%|█████▋    | 175/311 [19:08<13:08,  5.80s/it]Loading train:  57%|█████▋    | 176/311 [19:14<12:58,  5.76s/it]Loading train:  57%|█████▋    | 177/311 [19:20<13:02,  5.84s/it]Loading train:  57%|█████▋    | 178/311 [19:26<12:51,  5.80s/it]Loading train:  58%|█████▊    | 179/311 [19:32<12:43,  5.78s/it]Loading train:  58%|█████▊    | 180/311 [19:37<12:40,  5.80s/it]Loading train:  58%|█████▊    | 181/311 [19:43<12:30,  5.77s/it]Loading train:  59%|█████▊    | 182/311 [19:49<12:14,  5.69s/it]Loading train:  59%|█████▉    | 183/311 [19:55<12:15,  5.75s/it]Loading train:  59%|█████▉    | 184/311 [20:00<11:54,  5.63s/it]Loading train:  59%|█████▉    | 185/311 [20:05<11:43,  5.58s/it]Loading train:  60%|█████▉    | 186/311 [20:11<11:25,  5.49s/it]Loading train:  60%|██████    | 187/311 [20:16<11:09,  5.40s/it]Loading train:  60%|██████    | 188/311 [20:21<11:03,  5.40s/it]Loading train:  61%|██████    | 189/311 [20:27<11:01,  5.42s/it]Loading train:  61%|██████    | 190/311 [20:32<10:52,  5.39s/it]Loading train:  61%|██████▏   | 191/311 [20:38<10:53,  5.45s/it]Loading train:  62%|██████▏   | 192/311 [20:43<10:50,  5.46s/it]Loading train:  62%|██████▏   | 193/311 [20:48<10:40,  5.42s/it]Loading train:  62%|██████▏   | 194/311 [20:54<10:33,  5.42s/it]Loading train:  63%|██████▎   | 195/311 [21:00<10:42,  5.54s/it]Loading train:  63%|██████▎   | 196/311 [21:05<10:29,  5.47s/it]Loading train:  63%|██████▎   | 197/311 [21:10<10:16,  5.41s/it]Loading train:  64%|██████▎   | 198/311 [21:16<10:13,  5.43s/it]Loading train:  64%|██████▍   | 199/311 [21:21<10:02,  5.38s/it]Loading train:  64%|██████▍   | 200/311 [21:27<10:02,  5.42s/it]Loading train:  65%|██████▍   | 201/311 [21:32<09:54,  5.40s/it]Loading train:  65%|██████▍   | 202/311 [21:37<09:53,  5.44s/it]Loading train:  65%|██████▌   | 203/311 [21:43<09:42,  5.40s/it]Loading train:  66%|██████▌   | 204/311 [21:48<09:38,  5.40s/it]Loading train:  66%|██████▌   | 205/311 [21:53<09:24,  5.32s/it]Loading train:  66%|██████▌   | 206/311 [21:59<09:22,  5.35s/it]Loading train:  67%|██████▋   | 207/311 [22:04<09:11,  5.30s/it]Loading train:  67%|██████▋   | 208/311 [22:09<09:06,  5.31s/it]Loading train:  67%|██████▋   | 209/311 [22:15<09:03,  5.33s/it]Loading train:  68%|██████▊   | 210/311 [22:20<08:54,  5.29s/it]Loading train:  68%|██████▊   | 211/311 [22:25<08:52,  5.33s/it]Loading train:  68%|██████▊   | 212/311 [22:31<08:51,  5.37s/it]Loading train:  68%|██████▊   | 213/311 [22:42<11:29,  7.03s/it]Loading train:  69%|██████▉   | 214/311 [22:54<13:52,  8.58s/it]Loading train:  69%|██████▉   | 215/311 [23:07<15:45,  9.85s/it]Loading train:  69%|██████▉   | 216/311 [23:18<16:33, 10.46s/it]Loading train:  70%|██████▉   | 217/311 [23:31<17:12, 10.99s/it]Loading train:  70%|███████   | 218/311 [23:42<17:16, 11.15s/it]Loading train:  70%|███████   | 219/311 [23:54<17:24, 11.35s/it]Loading train:  71%|███████   | 220/311 [24:06<17:16, 11.39s/it]Loading train:  71%|███████   | 221/311 [24:17<17:06, 11.40s/it]Loading train:  71%|███████▏  | 222/311 [24:29<17:13, 11.62s/it]Loading train:  72%|███████▏  | 223/311 [24:41<17:14, 11.76s/it]Loading train:  72%|███████▏  | 224/311 [24:53<17:08, 11.82s/it]Loading train:  72%|███████▏  | 225/311 [25:05<16:52, 11.77s/it]Loading train:  73%|███████▎  | 226/311 [25:16<16:27, 11.62s/it]Loading train:  73%|███████▎  | 227/311 [25:28<16:24, 11.72s/it]Loading train:  73%|███████▎  | 228/311 [25:39<16:05, 11.63s/it]Loading train:  74%|███████▎  | 229/311 [25:51<15:56, 11.66s/it]Loading train:  74%|███████▍  | 230/311 [26:03<15:55, 11.80s/it]Loading train:  74%|███████▍  | 231/311 [26:09<13:21, 10.02s/it]Loading train:  75%|███████▍  | 232/311 [26:16<11:54,  9.04s/it]Loading train:  75%|███████▍  | 233/311 [26:22<10:28,  8.06s/it]Loading train:  75%|███████▌  | 234/311 [26:28<09:37,  7.50s/it]Loading train:  76%|███████▌  | 235/311 [26:34<08:57,  7.07s/it]Loading train:  76%|███████▌  | 236/311 [26:40<08:27,  6.77s/it]Loading train:  76%|███████▌  | 237/311 [26:46<08:10,  6.63s/it]Loading train:  77%|███████▋  | 238/311 [26:52<07:54,  6.50s/it]Loading train:  77%|███████▋  | 239/311 [26:59<07:44,  6.45s/it]Loading train:  77%|███████▋  | 240/311 [27:05<07:23,  6.24s/it]Loading train:  77%|███████▋  | 241/311 [27:11<07:17,  6.25s/it]Loading train:  78%|███████▊  | 242/311 [27:17<07:08,  6.21s/it]Loading train:  78%|███████▊  | 243/311 [27:24<07:10,  6.34s/it]Loading train:  78%|███████▊  | 244/311 [27:30<07:03,  6.32s/it]Loading train:  79%|███████▉  | 245/311 [27:37<07:03,  6.42s/it]Loading train:  79%|███████▉  | 246/311 [27:43<06:48,  6.29s/it]Loading train:  79%|███████▉  | 247/311 [27:49<06:45,  6.33s/it]Loading train:  80%|███████▉  | 248/311 [27:55<06:33,  6.25s/it]Loading train:  80%|████████  | 249/311 [28:03<06:53,  6.67s/it]Loading train:  80%|████████  | 250/311 [28:10<06:53,  6.77s/it]Loading train:  81%|████████  | 251/311 [28:17<07:01,  7.02s/it]Loading train:  81%|████████  | 252/311 [28:24<06:51,  6.98s/it]Loading train:  81%|████████▏ | 253/311 [28:32<06:59,  7.24s/it]Loading train:  82%|████████▏ | 254/311 [28:39<06:55,  7.28s/it]Loading train:  82%|████████▏ | 255/311 [28:47<06:51,  7.35s/it]Loading train:  82%|████████▏ | 256/311 [28:54<06:46,  7.40s/it]Loading train:  83%|████████▎ | 257/311 [29:02<06:40,  7.42s/it]Loading train:  83%|████████▎ | 258/311 [29:09<06:34,  7.45s/it]Loading train:  83%|████████▎ | 259/311 [29:17<06:24,  7.39s/it]Loading train:  84%|████████▎ | 260/311 [29:24<06:18,  7.43s/it]Loading train:  84%|████████▍ | 261/311 [29:32<06:10,  7.40s/it]Loading train:  84%|████████▍ | 262/311 [29:40<06:13,  7.63s/it]Loading train:  85%|████████▍ | 263/311 [29:47<06:02,  7.55s/it]Loading train:  85%|████████▍ | 264/311 [29:55<05:57,  7.62s/it]Loading train:  85%|████████▌ | 265/311 [30:02<05:46,  7.54s/it]Loading train:  86%|████████▌ | 266/311 [30:10<05:39,  7.55s/it]Loading train:  86%|████████▌ | 267/311 [30:17<05:28,  7.48s/it]Loading train:  86%|████████▌ | 268/311 [30:24<05:14,  7.32s/it]Loading train:  86%|████████▋ | 269/311 [30:31<05:06,  7.30s/it]Loading train:  87%|████████▋ | 270/311 [30:39<05:04,  7.42s/it]Loading train:  87%|████████▋ | 271/311 [30:46<04:49,  7.24s/it]Loading train:  87%|████████▋ | 272/311 [30:53<04:40,  7.18s/it]Loading train:  88%|████████▊ | 273/311 [30:59<04:23,  6.92s/it]Loading train:  88%|████████▊ | 274/311 [31:05<04:01,  6.52s/it]Loading train:  88%|████████▊ | 275/311 [31:10<03:45,  6.27s/it]Loading train:  89%|████████▊ | 276/311 [31:16<03:32,  6.06s/it]Loading train:  89%|████████▉ | 277/311 [31:22<03:23,  5.98s/it]Loading train:  89%|████████▉ | 278/311 [31:27<03:14,  5.88s/it]Loading train:  90%|████████▉ | 279/311 [31:33<03:04,  5.75s/it]Loading train:  90%|█████████ | 280/311 [31:39<02:58,  5.77s/it]Loading train:  90%|█████████ | 281/311 [31:44<02:53,  5.78s/it]Loading train:  91%|█████████ | 282/311 [31:50<02:49,  5.83s/it]Loading train:  91%|█████████ | 283/311 [31:56<02:41,  5.75s/it]Loading train:  91%|█████████▏| 284/311 [32:01<02:32,  5.64s/it]Loading train:  92%|█████████▏| 285/311 [32:07<02:25,  5.60s/it]Loading train:  92%|█████████▏| 286/311 [32:13<02:22,  5.68s/it]Loading train:  92%|█████████▏| 287/311 [32:18<02:15,  5.64s/it]Loading train:  93%|█████████▎| 288/311 [32:24<02:10,  5.67s/it]Loading train:  93%|█████████▎| 289/311 [32:30<02:05,  5.71s/it]Loading train:  93%|█████████▎| 290/311 [32:35<01:59,  5.67s/it]Loading train:  94%|█████████▎| 291/311 [32:41<01:53,  5.69s/it]Loading train:  94%|█████████▍| 292/311 [32:47<01:46,  5.61s/it]Loading train:  94%|█████████▍| 293/311 [32:52<01:40,  5.57s/it]Loading train:  95%|█████████▍| 294/311 [32:57<01:33,  5.48s/it]Loading train:  95%|█████████▍| 295/311 [33:03<01:28,  5.50s/it]Loading train:  95%|█████████▌| 296/311 [33:09<01:23,  5.56s/it]Loading train:  95%|█████████▌| 297/311 [33:14<01:16,  5.50s/it]Loading train:  96%|█████████▌| 298/311 [33:20<01:11,  5.53s/it]Loading train:  96%|█████████▌| 299/311 [33:25<01:07,  5.58s/it]Loading train:  96%|█████████▋| 300/311 [33:31<01:01,  5.61s/it]Loading train:  97%|█████████▋| 301/311 [33:37<00:56,  5.69s/it]Loading train:  97%|█████████▋| 302/311 [33:42<00:51,  5.68s/it]Loading train:  97%|█████████▋| 303/311 [33:48<00:45,  5.68s/it]Loading train:  98%|█████████▊| 304/311 [33:54<00:39,  5.63s/it]Loading train:  98%|█████████▊| 305/311 [34:00<00:34,  5.74s/it]Loading train:  98%|█████████▊| 306/311 [34:05<00:28,  5.68s/it]Loading train:  99%|█████████▊| 307/311 [34:11<00:22,  5.67s/it]Loading train:  99%|█████████▉| 308/311 [34:17<00:17,  5.74s/it]Loading train:  99%|█████████▉| 309/311 [34:22<00:11,  5.72s/it]Loading train: 100%|█████████▉| 310/311 [34:28<00:05,  5.64s/it]Loading train: 100%|██████████| 311/311 [34:34<00:00,  5.71s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/311 [00:00<00:06, 44.90it/s]concatenating: train:   3%|▎         | 10/311 [00:00<00:06, 44.29it/s]concatenating: train:   5%|▍         | 15/311 [00:00<00:06, 44.45it/s]concatenating: train:   7%|▋         | 21/311 [00:00<00:06, 45.56it/s]concatenating: train:   8%|▊         | 25/311 [00:00<00:06, 43.74it/s]concatenating: train:   9%|▉         | 29/311 [00:00<00:06, 42.15it/s]concatenating: train:  11%|█         | 34/311 [00:00<00:06, 43.20it/s]concatenating: train:  13%|█▎        | 39/311 [00:00<00:06, 44.08it/s]concatenating: train:  14%|█▍        | 44/311 [00:01<00:07, 36.82it/s]concatenating: train:  16%|█▌        | 49/311 [00:01<00:06, 37.80it/s]concatenating: train:  17%|█▋        | 54/311 [00:01<00:06, 39.25it/s]concatenating: train:  19%|█▉        | 60/311 [00:01<00:05, 42.67it/s]concatenating: train:  21%|██        | 65/311 [00:01<00:05, 43.25it/s]concatenating: train:  23%|██▎       | 70/311 [00:01<00:05, 44.68it/s]concatenating: train:  24%|██▍       | 75/311 [00:01<00:05, 45.07it/s]concatenating: train:  27%|██▋       | 83/311 [00:01<00:04, 50.68it/s]concatenating: train:  29%|██▊       | 89/311 [00:01<00:04, 52.59it/s]concatenating: train:  31%|███       | 97/311 [00:02<00:03, 57.55it/s]concatenating: train:  33%|███▎      | 104/311 [00:02<00:03, 59.62it/s]concatenating: train:  36%|███▌      | 112/311 [00:02<00:03, 63.86it/s]concatenating: train:  39%|███▉      | 121/311 [00:02<00:02, 65.68it/s]concatenating: train:  42%|████▏     | 130/311 [00:02<00:02, 70.79it/s]concatenating: train:  45%|████▌     | 140/311 [00:02<00:02, 77.06it/s]concatenating: train:  48%|████▊     | 149/311 [00:02<00:02, 78.72it/s]concatenating: train:  51%|█████     | 158/311 [00:02<00:02, 72.24it/s]concatenating: train:  53%|█████▎    | 166/311 [00:03<00:02, 62.04it/s]concatenating: train:  56%|█████▌    | 173/311 [00:03<00:02, 59.40it/s]concatenating: train:  58%|█████▊    | 180/311 [00:03<00:02, 60.54it/s]concatenating: train:  60%|██████    | 187/311 [00:03<00:02, 61.11it/s]concatenating: train:  62%|██████▏   | 194/311 [00:03<00:01, 61.52it/s]concatenating: train:  65%|██████▍   | 201/311 [00:03<00:01, 60.53it/s]concatenating: train:  67%|██████▋   | 208/311 [00:03<00:01, 61.11it/s]concatenating: train:  70%|███████   | 218/311 [00:03<00:01, 68.61it/s]concatenating: train:  73%|███████▎  | 226/311 [00:03<00:01, 71.58it/s]concatenating: train:  77%|███████▋  | 239/311 [00:04<00:00, 82.11it/s]concatenating: train:  81%|████████  | 251/311 [00:04<00:00, 89.89it/s]concatenating: train:  85%|████████▍ | 263/311 [00:04<00:00, 93.62it/s]concatenating: train:  88%|████████▊ | 273/311 [00:04<00:00, 95.37it/s]concatenating: train:  91%|█████████ | 283/311 [00:04<00:00, 92.55it/s]concatenating: train:  94%|█████████▍| 293/311 [00:04<00:00, 88.52it/s]concatenating: train:  97%|█████████▋| 303/311 [00:04<00:00, 88.75it/s]concatenating: train: 100%|██████████| 311/311 [00:04<00:00, 63.58it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:12<00:37, 12.54s/it]Loading test:  50%|█████     | 2/4 [00:23<00:24, 12.08s/it]Loading test:  75%|███████▌  | 3/4 [00:36<00:12, 12.26s/it]Loading test: 100%|██████████| 4/4 [00:48<00:00, 12.21s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 39.59it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 16:50:31.801381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 16:50:31.801492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 16:50:31.801509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 16:50:31.801520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 16:50:31.801932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 26, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [5.88176395e-02 2.85713643e-02 1.22080201e-01 1.04952659e-02
 3.15779544e-02 5.46270752e-03 7.23535399e-02 1.13294426e-01
 7.88079565e-02 1.27907394e-02 2.93002722e-01 1.72516551e-01
 2.28932584e-04]
Train on 20529 samples, validate on 262 samples
Epoch 1/300
 - 24s - loss: 13081.2405 - acc: 0.8667 - mDice: 0.1979 - val_loss: 5763.8436 - val_acc: 0.8654 - val_mDice: 0.3344

Epoch 00001: val_mDice improved from -inf to 0.33442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 5354.9381 - acc: 0.8985 - mDice: 0.3733 - val_loss: 4086.5296 - val_acc: 0.8859 - val_mDice: 0.4335

Epoch 00002: val_mDice improved from 0.33442 to 0.43348, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 4033.6326 - acc: 0.9126 - mDice: 0.4627 - val_loss: 2902.9668 - val_acc: 0.9162 - val_mDice: 0.5351

Epoch 00003: val_mDice improved from 0.43348 to 0.53507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 3371.7175 - acc: 0.9213 - mDice: 0.5200 - val_loss: 2516.6574 - val_acc: 0.9273 - val_mDice: 0.5748

Epoch 00004: val_mDice improved from 0.53507 to 0.57484, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 2930.9028 - acc: 0.9272 - mDice: 0.5624 - val_loss: 2389.5735 - val_acc: 0.9267 - val_mDice: 0.5920

Epoch 00005: val_mDice improved from 0.57484 to 0.59203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 14s - loss: 2655.9580 - acc: 0.9310 - mDice: 0.5911 - val_loss: 2187.7077 - val_acc: 0.9343 - val_mDice: 0.6190

Epoch 00006: val_mDice improved from 0.59203 to 0.61903, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 2455.9281 - acc: 0.9340 - mDice: 0.6132 - val_loss: 2067.3275 - val_acc: 0.9402 - val_mDice: 0.6336

Epoch 00007: val_mDice improved from 0.61903 to 0.63362, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 2310.7606 - acc: 0.9362 - mDice: 0.6305 - val_loss: 2023.7573 - val_acc: 0.9409 - val_mDice: 0.6450

Epoch 00008: val_mDice improved from 0.63362 to 0.64503, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 2188.7119 - acc: 0.9381 - mDice: 0.6453 - val_loss: 1960.6365 - val_acc: 0.9423 - val_mDice: 0.6517

Epoch 00009: val_mDice improved from 0.64503 to 0.65168, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 14s - loss: 2089.9855 - acc: 0.9397 - mDice: 0.6575 - val_loss: 1897.6588 - val_acc: 0.9453 - val_mDice: 0.6602

Epoch 00010: val_mDice improved from 0.65168 to 0.66025, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 14s - loss: 2017.9713 - acc: 0.9410 - mDice: 0.6670 - val_loss: 1919.7385 - val_acc: 0.9447 - val_mDice: 0.6571

Epoch 00011: val_mDice did not improve from 0.66025
Epoch 12/300
 - 13s - loss: 1941.1152 - acc: 0.9423 - mDice: 0.6768 - val_loss: 1813.0220 - val_acc: 0.9479 - val_mDice: 0.6746

Epoch 00012: val_mDice improved from 0.66025 to 0.67455, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 14s - loss: 1887.0173 - acc: 0.9433 - mDice: 0.6842 - val_loss: 1781.9196 - val_acc: 0.9493 - val_mDice: 0.6785

Epoch 00013: val_mDice improved from 0.67455 to 0.67847, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 13s - loss: 1825.7170 - acc: 0.9443 - mDice: 0.6923 - val_loss: 1733.4212 - val_acc: 0.9494 - val_mDice: 0.6835

Epoch 00014: val_mDice improved from 0.67847 to 0.68351, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 14s - loss: 1770.1294 - acc: 0.9451 - mDice: 0.7001 - val_loss: 1719.0596 - val_acc: 0.9492 - val_mDice: 0.6848

Epoch 00015: val_mDice improved from 0.68351 to 0.68480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 13s - loss: 1731.2047 - acc: 0.9459 - mDice: 0.7053 - val_loss: 1747.5207 - val_acc: 0.9494 - val_mDice: 0.6805

Epoch 00016: val_mDice did not improve from 0.68480
Epoch 17/300
 - 14s - loss: 1679.4389 - acc: 0.9466 - mDice: 0.7123 - val_loss: 1730.7412 - val_acc: 0.9519 - val_mDice: 0.6853

Epoch 00017: val_mDice improved from 0.68480 to 0.68532, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 13s - loss: 1645.1039 - acc: 0.9473 - mDice: 0.7171 - val_loss: 1713.8059 - val_acc: 0.9519 - val_mDice: 0.6871

Epoch 00018: val_mDice improved from 0.68532 to 0.68712, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 14s - loss: 1605.4703 - acc: 0.9480 - mDice: 0.7227 - val_loss: 1691.3816 - val_acc: 0.9527 - val_mDice: 0.6917

Epoch 00019: val_mDice improved from 0.68712 to 0.69171, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 14s - loss: 1584.1165 - acc: 0.9484 - mDice: 0.7259 - val_loss: 1769.6671 - val_acc: 0.9509 - val_mDice: 0.6799

Epoch 00020: val_mDice did not improve from 0.69171
Epoch 21/300
 - 14s - loss: 1550.3823 - acc: 0.9490 - mDice: 0.7307 - val_loss: 1648.7801 - val_acc: 0.9546 - val_mDice: 0.6969

Epoch 00021: val_mDice improved from 0.69171 to 0.69690, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 14s - loss: 1525.8549 - acc: 0.9495 - mDice: 0.7343 - val_loss: 1637.5937 - val_acc: 0.9539 - val_mDice: 0.6991

Epoch 00022: val_mDice improved from 0.69690 to 0.69911, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 13s - loss: 1490.9433 - acc: 0.9500 - mDice: 0.7391 - val_loss: 1702.9352 - val_acc: 0.9531 - val_mDice: 0.6896

Epoch 00023: val_mDice did not improve from 0.69911
Epoch 24/300
 - 14s - loss: 1475.5634 - acc: 0.9503 - mDice: 0.7417 - val_loss: 1629.1583 - val_acc: 0.9544 - val_mDice: 0.7015

Epoch 00024: val_mDice improved from 0.69911 to 0.70150, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 13s - loss: 1447.9756 - acc: 0.9508 - mDice: 0.7456 - val_loss: 1762.1554 - val_acc: 0.9520 - val_mDice: 0.6812

Epoch 00025: val_mDice did not improve from 0.70150
Epoch 26/300
 - 14s - loss: 1428.6082 - acc: 0.9512 - mDice: 0.7484 - val_loss: 1681.3020 - val_acc: 0.9530 - val_mDice: 0.6918

Epoch 00026: val_mDice did not improve from 0.70150
Epoch 27/300
 - 13s - loss: 1407.2761 - acc: 0.9516 - mDice: 0.7517 - val_loss: 1638.2119 - val_acc: 0.9547 - val_mDice: 0.6997

Epoch 00027: val_mDice did not improve from 0.70150
Epoch 28/300
 - 14s - loss: 1388.6545 - acc: 0.9519 - mDice: 0.7545 - val_loss: 1619.3489 - val_acc: 0.9564 - val_mDice: 0.7029

Epoch 00028: val_mDice improved from 0.70150 to 0.70286, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 13s - loss: 1373.2213 - acc: 0.9522 - mDice: 0.7569 - val_loss: 1641.1675 - val_acc: 0.9547 - val_mDice: 0.6992

Epoch 00029: val_mDice did not improve from 0.70286
Epoch 30/300
 - 14s - loss: 1363.2066 - acc: 0.9525 - mDice: 0.7586 - val_loss: 1681.9515 - val_acc: 0.9553 - val_mDice: 0.6957

Epoch 00030: val_mDice did not improve from 0.70286
Epoch 31/300
 - 14s - loss: 1339.6332 - acc: 0.9529 - mDice: 0.7620 - val_loss: 1635.5942 - val_acc: 0.9550 - val_mDice: 0.7002

Epoch 00031: val_mDice did not improve from 0.70286
Epoch 32/300
 - 13s - loss: 1325.5811 - acc: 0.9531 - mDice: 0.7640 - val_loss: 1679.9814 - val_acc: 0.9557 - val_mDice: 0.6933

Epoch 00032: val_mDice did not improve from 0.70286
Epoch 33/300
 - 14s - loss: 1314.1458 - acc: 0.9534 - mDice: 0.7657 - val_loss: 1600.1640 - val_acc: 0.9584 - val_mDice: 0.7062

Epoch 00033: val_mDice improved from 0.70286 to 0.70623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 13s - loss: 1295.4880 - acc: 0.9536 - mDice: 0.7686 - val_loss: 1710.4159 - val_acc: 0.9545 - val_mDice: 0.6901

Epoch 00034: val_mDice did not improve from 0.70623
Epoch 35/300
 - 14s - loss: 1283.3716 - acc: 0.9539 - mDice: 0.7706 - val_loss: 1606.4361 - val_acc: 0.9571 - val_mDice: 0.7055

Epoch 00035: val_mDice did not improve from 0.70623
Epoch 36/300
 - 13s - loss: 1265.8975 - acc: 0.9541 - mDice: 0.7731 - val_loss: 1633.3935 - val_acc: 0.9576 - val_mDice: 0.7020

Epoch 00036: val_mDice did not improve from 0.70623
Epoch 37/300
 - 14s - loss: 1255.4234 - acc: 0.9544 - mDice: 0.7748 - val_loss: 1644.6012 - val_acc: 0.9580 - val_mDice: 0.6986

Epoch 00037: val_mDice did not improve from 0.70623
Epoch 38/300
 - 13s - loss: 1289.6418 - acc: 0.9544 - mDice: 0.7745 - val_loss: 1631.6191 - val_acc: 0.9588 - val_mDice: 0.7026

Epoch 00038: val_mDice did not improve from 0.70623
Epoch 39/300
 - 14s - loss: 1229.5157 - acc: 0.9547 - mDice: 0.7788 - val_loss: 1597.2660 - val_acc: 0.9575 - val_mDice: 0.7066

Epoch 00039: val_mDice improved from 0.70623 to 0.70663, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 40/300
 - 13s - loss: 1222.9036 - acc: 0.9549 - mDice: 0.7799 - val_loss: 1739.0019 - val_acc: 0.9542 - val_mDice: 0.6858

Epoch 00040: val_mDice did not improve from 0.70663
Epoch 41/300
 - 14s - loss: 1216.0971 - acc: 0.9551 - mDice: 0.7811 - val_loss: 1714.2821 - val_acc: 0.9541 - val_mDice: 0.6881

Epoch 00041: val_mDice did not improve from 0.70663
Epoch 42/300
 - 14s - loss: 1212.5068 - acc: 0.9552 - mDice: 0.7815 - val_loss: 1635.1437 - val_acc: 0.9585 - val_mDice: 0.6997

Epoch 00042: val_mDice did not improve from 0.70663
Epoch 43/300
 - 14s - loss: 1193.6267 - acc: 0.9554 - mDice: 0.7844 - val_loss: 1684.1881 - val_acc: 0.9577 - val_mDice: 0.6926

Epoch 00043: val_mDice did not improve from 0.70663
Epoch 44/300
 - 14s - loss: 1232.5824 - acc: 0.9554 - mDice: 0.7833 - val_loss: 1637.4167 - val_acc: 0.9570 - val_mDice: 0.7011

Epoch 00044: val_mDice did not improve from 0.70663
Epoch 45/300
 - 14s - loss: 1181.1343 - acc: 0.9557 - mDice: 0.7864 - val_loss: 1756.9654 - val_acc: 0.9566 - val_mDice: 0.6861

Epoch 00045: val_mDice did not improve from 0.70663
Epoch 46/300
 - 14s - loss: 1169.3208 - acc: 0.9559 - mDice: 0.7883 - val_loss: 1584.2257 - val_acc: 0.9586 - val_mDice: 0.7073

Epoch 00046: val_mDice improved from 0.70663 to 0.70727, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 13s - loss: 1163.3546 - acc: 0.9561 - mDice: 0.7892 - val_loss: 1711.0201 - val_acc: 0.9537 - val_mDice: 0.6864

Epoch 00047: val_mDice did not improve from 0.70727
Epoch 48/300
 - 14s - loss: 1156.7536 - acc: 0.9562 - mDice: 0.7902 - val_loss: 1650.5911 - val_acc: 0.9566 - val_mDice: 0.6997

Epoch 00048: val_mDice did not improve from 0.70727
Epoch 49/300
 - 13s - loss: 1144.5564 - acc: 0.9563 - mDice: 0.7921 - val_loss: 1606.4979 - val_acc: 0.9578 - val_mDice: 0.7041

Epoch 00049: val_mDice did not improve from 0.70727
Epoch 50/300
 - 14s - loss: 1132.0379 - acc: 0.9565 - mDice: 0.7941 - val_loss: 1589.7610 - val_acc: 0.9566 - val_mDice: 0.7054

Epoch 00050: val_mDice did not improve from 0.70727
Epoch 51/300
 - 13s - loss: 1136.4300 - acc: 0.9565 - mDice: 0.7935 - val_loss: 1923.1727 - val_acc: 0.9466 - val_mDice: 0.6572

Epoch 00051: val_mDice did not improve from 0.70727
Epoch 52/300
 - 14s - loss: 1115.6559 - acc: 0.9568 - mDice: 0.7968 - val_loss: 1622.5629 - val_acc: 0.9595 - val_mDice: 0.7028

Epoch 00052: val_mDice did not improve from 0.70727
Epoch 53/300
 - 14s - loss: 1116.8992 - acc: 0.9567 - mDice: 0.7965 - val_loss: 1686.6385 - val_acc: 0.9559 - val_mDice: 0.6924

Epoch 00053: val_mDice did not improve from 0.70727
Epoch 54/300
 - 14s - loss: 1108.3395 - acc: 0.9569 - mDice: 0.7979 - val_loss: 1595.3451 - val_acc: 0.9586 - val_mDice: 0.7058

Epoch 00054: val_mDice did not improve from 0.70727
Epoch 55/300
 - 14s - loss: 1112.3232 - acc: 0.9570 - mDice: 0.7973 - val_loss: 1690.7807 - val_acc: 0.9572 - val_mDice: 0.6920

Epoch 00055: val_mDice did not improve from 0.70727
Epoch 56/300
 - 13s - loss: 1097.9938 - acc: 0.9571 - mDice: 0.7996 - val_loss: 1607.6292 - val_acc: 0.9591 - val_mDice: 0.7048

Epoch 00056: val_mDice did not improve from 0.70727
Epoch 57/300
 - 14s - loss: 1097.2018 - acc: 0.9572 - mDice: 0.7997 - val_loss: 1680.3411 - val_acc: 0.9548 - val_mDice: 0.6924

Epoch 00057: val_mDice did not improve from 0.70727
Epoch 58/300
 - 13s - loss: 1087.0501 - acc: 0.9573 - mDice: 0.8013 - val_loss: 1659.3740 - val_acc: 0.9584 - val_mDice: 0.6971

Epoch 00058: val_mDice did not improve from 0.70727
Epoch 59/300
 - 14s - loss: 1101.4299 - acc: 0.9570 - mDice: 0.7996 - val_loss: 4387.8920 - val_acc: 0.9404 - val_mDice: 0.5265

Epoch 00059: val_mDice did not improve from 0.70727
Epoch 60/300
 - 13s - loss: 1103.1201 - acc: 0.9570 - mDice: 0.7988 - val_loss: 1606.9398 - val_acc: 0.9571 - val_mDice: 0.7053

Epoch 00060: val_mDice did not improve from 0.70727
Epoch 61/300
 - 14s - loss: 1073.7339 - acc: 0.9574 - mDice: 0.8035 - val_loss: 1589.3186 - val_acc: 0.9591 - val_mDice: 0.7067

Epoch 00061: val_mDice did not improve from 0.70727
Epoch 62/300
 - 13s - loss: 1063.9044 - acc: 0.9577 - mDice: 0.8050 - val_loss: 1634.8861 - val_acc: 0.9580 - val_mDice: 0.7009

Epoch 00062: val_mDice did not improve from 0.70727
Epoch 63/300
 - 14s - loss: 1063.4773 - acc: 0.9577 - mDice: 0.8051 - val_loss: 1591.0524 - val_acc: 0.9600 - val_mDice: 0.7080

Epoch 00063: val_mDice improved from 0.70727 to 0.70799, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 64/300
 - 14s - loss: 1062.0630 - acc: 0.9577 - mDice: 0.8054 - val_loss: 1612.1834 - val_acc: 0.9584 - val_mDice: 0.7035

Epoch 00064: val_mDice did not improve from 0.70799
Epoch 65/300
 - 14s - loss: 1049.3009 - acc: 0.9578 - mDice: 0.8074 - val_loss: 1593.7038 - val_acc: 0.9584 - val_mDice: 0.7066

Epoch 00065: val_mDice did not improve from 0.70799
Epoch 66/300
 - 14s - loss: 1049.8856 - acc: 0.9578 - mDice: 0.8073 - val_loss: 1641.5747 - val_acc: 0.9573 - val_mDice: 0.6994

Epoch 00066: val_mDice did not improve from 0.70799
Epoch 67/300
 - 13s - loss: 1040.2020 - acc: 0.9579 - mDice: 0.8088 - val_loss: 1607.2991 - val_acc: 0.9598 - val_mDice: 0.7049

Epoch 00067: val_mDice did not improve from 0.70799
Epoch 68/300
 - 14s - loss: 1039.2494 - acc: 0.9580 - mDice: 0.8091 - val_loss: 1771.4112 - val_acc: 0.9510 - val_mDice: 0.6792

Epoch 00068: val_mDice did not improve from 0.70799
Epoch 69/300
 - 13s - loss: 1032.7788 - acc: 0.9582 - mDice: 0.8101 - val_loss: 1625.0071 - val_acc: 0.9602 - val_mDice: 0.7024

Epoch 00069: val_mDice did not improve from 0.70799
Epoch 70/300
 - 14s - loss: 1035.7715 - acc: 0.9581 - mDice: 0.8097 - val_loss: 1678.2759 - val_acc: 0.9555 - val_mDice: 0.6946

Epoch 00070: val_mDice did not improve from 0.70799
Epoch 71/300
 - 13s - loss: 1027.6829 - acc: 0.9583 - mDice: 0.8110 - val_loss: 1593.4908 - val_acc: 0.9588 - val_mDice: 0.7072

Epoch 00071: val_mDice did not improve from 0.70799
Epoch 72/300
 - 14s - loss: 1021.9483 - acc: 0.9583 - mDice: 0.8121 - val_loss: 1670.0053 - val_acc: 0.9577 - val_mDice: 0.6942

Epoch 00072: val_mDice did not improve from 0.70799
Epoch 73/300
 - 13s - loss: 1339.8743 - acc: 0.9520 - mDice: 0.7634 - val_loss: 1598.6811 - val_acc: 0.9580 - val_mDice: 0.7060

Epoch 00073: val_mDice did not improve from 0.70799
Epoch 74/300
 - 14s - loss: 1106.8474 - acc: 0.9566 - mDice: 0.7981 - val_loss: 1616.1609 - val_acc: 0.9588 - val_mDice: 0.7038

Epoch 00074: val_mDice did not improve from 0.70799
Epoch 75/300
 - 14s - loss: 1062.6421 - acc: 0.9574 - mDice: 0.8052 - val_loss: 1615.1940 - val_acc: 0.9580 - val_mDice: 0.7039

Epoch 00075: val_mDice did not improve from 0.70799
Epoch 76/300
 - 13s - loss: 1046.1089 - acc: 0.9578 - mDice: 0.8080 - val_loss: 1600.7623 - val_acc: 0.9582 - val_mDice: 0.7059

Epoch 00076: val_mDice did not improve from 0.70799
Epoch 77/300
 - 14s - loss: 1030.8213 - acc: 0.9580 - mDice: 0.8104 - val_loss: 1625.3858 - val_acc: 0.9581 - val_mDice: 0.7006

Epoch 00077: val_mDice did not improve from 0.70799
Epoch 78/300
 - 13s - loss: 1024.5970 - acc: 0.9582 - mDice: 0.8114 - val_loss: 1598.5321 - val_acc: 0.9584 - val_mDice: 0.7068

Epoch 00078: val_mDice did not improve from 0.70799
Epoch 79/300
 - 14s - loss: 1020.4029 - acc: 0.9583 - mDice: 0.8128 - val_loss: 1691.7955 - val_acc: 0.9566 - val_mDice: 0.6932

Epoch 00079: val_mDice did not improve from 0.70799
Epoch 80/300
 - 13s - loss: 1115.6953 - acc: 0.9566 - mDice: 0.7972 - val_loss: 1659.1455 - val_acc: 0.9584 - val_mDice: 0.6986

Epoch 00080: val_mDice did not improve from 0.70799
Epoch 81/300
 - 14s - loss: 1028.5725 - acc: 0.9581 - mDice: 0.8108 - val_loss: 1596.8156 - val_acc: 0.9556 - val_mDice: 0.7065

Epoch 00081: val_mDice did not improve from 0.70799
Epoch 82/300
 - 13s - loss: 1011.5954 - acc: 0.9583 - mDice: 0.8136 - val_loss: 1637.1568 - val_acc: 0.9567 - val_mDice: 0.7002

Epoch 00082: val_mDice did not improve from 0.70799
Epoch 83/300
 - 14s - loss: 1007.1727 - acc: 0.9585 - mDice: 0.8143 - val_loss: 1614.7216 - val_acc: 0.9580 - val_mDice: 0.7032

Epoch 00083: val_mDice did not improve from 0.70799
Epoch 84/300
 - 13s - loss: 997.3493 - acc: 0.9586 - mDice: 0.8159 - val_loss: 1619.3315 - val_acc: 0.9587 - val_mDice: 0.7046

Epoch 00084: val_mDice did not improve from 0.70799
Epoch 85/300
 - 14s - loss: 991.2029 - acc: 0.9588 - mDice: 0.8169 - val_loss: 1592.2951 - val_acc: 0.9581 - val_mDice: 0.7063

Epoch 00085: val_mDice did not improve from 0.70799
Epoch 86/300
 - 13s - loss: 992.4024 - acc: 0.9587 - mDice: 0.8168 - val_loss: 1563.1098 - val_acc: 0.9589 - val_mDice: 0.7114

Epoch 00086: val_mDice improved from 0.70799 to 0.71141, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 87/300
 - 14s - loss: 991.3403 - acc: 0.9587 - mDice: 0.8169 - val_loss: 1709.5849 - val_acc: 0.9559 - val_mDice: 0.6891

Epoch 00087: val_mDice did not improve from 0.71141
Epoch 88/300
 - 14s - loss: 982.7172 - acc: 0.9587 - mDice: 0.8183 - val_loss: 1576.9286 - val_acc: 0.9593 - val_mDice: 0.7090

Epoch 00088: val_mDice did not improve from 0.71141
Epoch 89/300
 - 14s - loss: 984.7758 - acc: 0.9589 - mDice: 0.8180 - val_loss: 1688.7350 - val_acc: 0.9546 - val_mDice: 0.6921

Epoch 00089: val_mDice did not improve from 0.71141
Epoch 90/300
 - 14s - loss: 987.3607 - acc: 0.9587 - mDice: 0.8175 - val_loss: 1667.5846 - val_acc: 0.9566 - val_mDice: 0.6948

Epoch 00090: val_mDice did not improve from 0.71141
Epoch 91/300
 - 13s - loss: 982.1434 - acc: 0.9589 - mDice: 0.8184 - val_loss: 1588.1732 - val_acc: 0.9594 - val_mDice: 0.7086

Epoch 00091: val_mDice did not improve from 0.71141
Epoch 92/300
 - 14s - loss: 988.2452 - acc: 0.9587 - mDice: 0.8174 - val_loss: 1671.1887 - val_acc: 0.9585 - val_mDice: 0.6971

Epoch 00092: val_mDice did not improve from 0.71141
Epoch 93/300
 - 13s - loss: 981.7078 - acc: 0.9589 - mDice: 0.8185 - val_loss: 1620.2385 - val_acc: 0.9593 - val_mDice: 0.7039

Epoch 00093: val_mDice did not improve from 0.71141
Epoch 94/300
 - 14s - loss: 977.3088 - acc: 0.9589 - mDice: 0.8192 - val_loss: 1647.6723 - val_acc: 0.9576 - val_mDice: 0.6985

Epoch 00094: val_mDice did not improve from 0.71141
Epoch 95/300
 - 13s - loss: 974.7871 - acc: 0.9590 - mDice: 0.8197 - val_loss: 1608.8587 - val_acc: 0.9590 - val_mDice: 0.7048

Epoch 00095: val_mDice did not improve from 0.71141
Epoch 96/300
 - 14s - loss: 982.2713 - acc: 0.9590 - mDice: 0.8187 - val_loss: 1623.4717 - val_acc: 0.9584 - val_mDice: 0.7030

Epoch 00096: val_mDice did not improve from 0.71141
Epoch 97/300
 - 13s - loss: 979.8414 - acc: 0.9589 - mDice: 0.8188 - val_loss: 1691.1914 - val_acc: 0.9561 - val_mDice: 0.6935

Epoch 00097: val_mDice did not improve from 0.71141
Epoch 98/300
 - 14s - loss: 971.8526 - acc: 0.9591 - mDice: 0.8201 - val_loss: 1750.5351 - val_acc: 0.9526 - val_mDice: 0.6826

Epoch 00098: val_mDice did not improve from 0.71141
Epoch 99/300
 - 14s - loss: 973.0534 - acc: 0.9590 - mDice: 0.8199 - val_loss: 1732.9780 - val_acc: 0.9532 - val_mDice: 0.6853

Epoch 00099: val_mDice did not improve from 0.71141
Epoch 100/300
 - 14s - loss: 979.1048 - acc: 0.9590 - mDice: 0.8191 - val_loss: 1793.2994 - val_acc: 0.9513 - val_mDice: 0.6767

Epoch 00100: val_mDice did not improve from 0.71141
Epoch 101/300
 - 14s - loss: 970.0246 - acc: 0.9591 - mDice: 0.8205 - val_loss: 1635.7151 - val_acc: 0.9572 - val_mDice: 0.7007

Epoch 00101: val_mDice did not improve from 0.71141
Epoch 102/300
 - 14s - loss: 966.0267 - acc: 0.9592 - mDice: 0.8211 - val_loss: 1629.7496 - val_acc: 0.9578 - val_mDice: 0.7028

Epoch 00102: val_mDice did not improve from 0.71141
Epoch 103/300
 - 14s - loss: 960.9594 - acc: 0.9592 - mDice: 0.8218 - val_loss: 1640.4071 - val_acc: 0.9574 - val_mDice: 0.6994

Epoch 00103: val_mDice did not improve from 0.71141
Epoch 104/300
 - 13s - loss: 963.7301 - acc: 0.9592 - mDice: 0.8215 - val_loss: 1622.6012 - val_acc: 0.9593 - val_mDice: 0.7035

Epoch 00104: val_mDice did not improve from 0.71141
Epoch 105/300
 - 15s - loss: 953.0353 - acc: 0.9594 - mDice: 0.8232 - val_loss: 1637.4266 - val_acc: 0.9581 - val_mDice: 0.7003

Epoch 00105: val_mDice did not improve from 0.71141
Epoch 106/300
 - 13s - loss: 954.8675 - acc: 0.9593 - mDice: 0.8229 - val_loss: 1667.7357 - val_acc: 0.9569 - val_mDice: 0.6957

Epoch 00106: val_mDice did not improve from 0.71141
Epoch 107/300
 - 14s - loss: 956.4548 - acc: 0.9594 - mDice: 0.8227 - val_loss: 1687.6319 - val_acc: 0.9590 - val_mDice: 0.6951

Epoch 00107: val_mDice did not improve from 0.71141
Epoch 108/300
 - 13s - loss: 953.4559 - acc: 0.9594 - mDice: 0.8232 - val_loss: 1637.4474 - val_acc: 0.9592 - val_mDice: 0.7018

Epoch 00108: val_mDice did not improve from 0.71141
Epoch 109/300
 - 14s - loss: 952.5050 - acc: 0.9594 - mDice: 0.8234 - val_loss: 1683.5654 - val_acc: 0.9582 - val_mDice: 0.6954

Epoch 00109: val_mDice did not improve from 0.71141
Epoch 110/300
 - 14s - loss: 953.2454 - acc: 0.9595 - mDice: 0.8235 - val_loss: 1759.6622 - val_acc: 0.9545 - val_mDice: 0.6831

Epoch 00110: val_mDice did not improve from 0.71141
Epoch 111/300
 - 14s - loss: 949.2244 - acc: 0.9595 - mDice: 0.8239 - val_loss: 1653.5583 - val_acc: 0.9583 - val_mDice: 0.6994

Epoch 00111: val_mDice did not improve from 0.71141
Epoch 112/300
 - 14s - loss: 943.9194 - acc: 0.9596 - mDice: 0.8247 - val_loss: 1619.3247 - val_acc: 0.9590 - val_mDice: 0.7045

Epoch 00112: val_mDice did not improve from 0.71141
Epoch 113/300
 - 13s - loss: 942.5777 - acc: 0.9596 - mDice: 0.8250 - val_loss: 1609.5864 - val_acc: 0.9586 - val_mDice: 0.7048

Epoch 00113: val_mDice did not improve from 0.71141
Epoch 114/300
 - 14s - loss: 941.9532 - acc: 0.9596 - mDice: 0.8251 - val_loss: 2134.5495 - val_acc: 0.9540 - val_mDice: 0.6444

Epoch 00114: val_mDice did not improve from 0.71141
Epoch 115/300
 - 13s - loss: 939.8842 - acc: 0.9597 - mDice: 0.8255 - val_loss: 1623.3176 - val_acc: 0.9596 - val_mDice: 0.7018

Epoch 00115: val_mDice did not improve from 0.71141
Epoch 116/300
 - 14s - loss: 939.6439 - acc: 0.9596 - mDice: 0.8255 - val_loss: 1654.5485 - val_acc: 0.9574 - val_mDice: 0.6979

Epoch 00116: val_mDice did not improve from 0.71141
Restoring model weights from the end of the best epoch
Epoch 00116: early stopping
{'val_loss': [5763.843561769442, 4086.5296211533873, 2902.9667577379532, 2516.657401747376, 2389.5735254651718, 2187.7077142846492, 2067.3274540791986, 2023.7573354007634, 1960.6364867232228, 1897.6587529073236, 1919.7384508438693, 1813.021999679449, 1781.9196106422949, 1733.4212441480797, 1719.0596075858778, 1747.5206951112239, 1730.7412202558444, 1713.8058504293892, 1691.3815899332062, 1769.6671282353293, 1648.780143912512, 1637.5937267041388, 1702.9352412333014, 1629.1583130814647, 1762.1553740756203, 1681.3019991576216, 1638.2118767891222, 1619.3488657711116, 1641.167499105439, 1681.9515194492485, 1635.5942410767534, 1679.981384743261, 1600.1639609300453, 1710.4159187142175, 1606.4360910663167, 1633.3935313916388, 1644.6012419489505, 1631.61913223849, 1597.2660079839575, 1739.0018785782443, 1714.282128719883, 1635.1437158948593, 1684.1881066242247, 1637.4167089098282, 1756.9654326693703, 1584.225732235508, 1711.020125760377, 1650.5911278178673, 1606.4978698264551, 1589.7609574412572, 1923.172735083194, 1622.562900688812, 1686.6384957582895, 1595.3450694775763, 1690.7807319000476, 1607.6292389148973, 1680.3411380680463, 1659.3739563454199, 4387.892026479008, 1606.9397857898973, 1589.3186268114862, 1634.886097216424, 1591.052400778268, 1612.1834139059517, 1593.7038453080272, 1641.5746977129056, 1607.2991281756917, 1771.4112381097925, 1625.0070670324428, 1678.2758500193822, 1593.490774838979, 1670.005291887822, 1598.6810945700142, 1616.1609464456108, 1615.1939986134303, 1600.7623141922113, 1625.3857999612358, 1598.5320513776242, 1691.7954930895157, 1659.1455096761688, 1596.8155713263359, 1637.1567541224356, 1614.7216125954199, 1619.3314903201037, 1592.2950635138359, 1563.1098208827827, 1709.584871481393, 1576.9286019128697, 1688.734952737357, 1667.5846236134303, 1588.173176772722, 1671.1886787705748, 1620.238542163645, 1647.6722878026599, 1608.8586984881917, 1623.4717281428912, 1691.1913503399333, 1750.5350779759065, 1732.977991934041, 1793.2993667253102, 1635.7151037318106, 1629.7496086295325, 1640.407078400823, 1622.601201880069, 1637.4266180373331, 1667.735685159232, 1687.6318825292224, 1637.4474026046637, 1683.5653570044133, 1759.6621568985568, 1653.5583160633348, 1619.3246697578722, 1609.5864052808922, 2134.549539114683, 1623.3175896797472, 1654.5484703005725], 'val_acc': [0.8654001437070715, 0.8859224797205161, 0.9161942719503213, 0.9272889490345962, 0.9266862195866709, 0.9343282994423204, 0.9401847378898213, 0.9409031972630333, 0.9422949830084356, 0.9453015655051661, 0.9446833060897943, 0.9479256117616901, 0.9492976215049511, 0.9493681879443977, 0.94918470118792, 0.9493554766851527, 0.9519061423440016, 0.9519075482856226, 0.9526641478065316, 0.9509251267855404, 0.9545555910991348, 0.9539190066679744, 0.9530664204641153, 0.954446918636788, 0.9519851890229086, 0.9530268930296861, 0.954739100605477, 0.9563948207229148, 0.9547023905142573, 0.9553079286604437, 0.954971995972495, 0.9556523611527363, 0.9584020408055255, 0.9544666573291517, 0.9571048389864332, 0.9576228761490975, 0.958011017045902, 0.9587803210010966, 0.9575367451624106, 0.9541504883584175, 0.9540841420188205, 0.9585107200928317, 0.9577386165393218, 0.9569904740530116, 0.956567017176679, 0.9585855266520085, 0.9536536203995916, 0.9566023040363807, 0.957758373431577, 0.9565585574120966, 0.9466368665221994, 0.9594988126791161, 0.9558880897878691, 0.9586250522664486, 0.9571895230817431, 0.9590626286186335, 0.9548209646275936, 0.9584118987767751, 0.9403583530251306, 0.9570624873838351, 0.9590979095633704, 0.9580392678275363, 0.9599561168037298, 0.9584062727353045, 0.9584048636087025, 0.9573236130576097, 0.9597641716476615, 0.9510352402242995, 0.9602073835962601, 0.9554745090826777, 0.9588000724333843, 0.957725902550093, 0.9580223287334879, 0.9587633723521051, 0.9580110370657826, 0.958241103714659, 0.9581451247666628, 0.9583850798716071, 0.9565656303449441, 0.9583511989535266, 0.9555676483925972, 0.9567166562298782, 0.9580110352457935, 0.9586547071697148, 0.9580943029345447, 0.9588791236622642, 0.9559092558067264, 0.9593435275645656, 0.9546007473050183, 0.9565514922142029, 0.9594169372820672, 0.9585177943906711, 0.9593477590393474, 0.9576186128245056, 0.9589892343710397, 0.9583737950288612, 0.9561478199849602, 0.9526387293830173, 0.9531850054973864, 0.9513203547201083, 0.9571824510588901, 0.9578402433686584, 0.9573603117738971, 0.9592545865146258, 0.9581310275856775, 0.9569410768174033, 0.9589807623215304, 0.9591515523786763, 0.9582467552359778, 0.9544779599167919, 0.9583060404726567, 0.9589567694045206, 0.9585855312019814, 0.9539853370826663, 0.9595693741135924, 0.9574238253003768], 'val_mDice': [0.33441733995466744, 0.4334812949176963, 0.5350652742021866, 0.5748390678231042, 0.5920337929980446, 0.6190345446572049, 0.6336170871749179, 0.6450297295592213, 0.6516829383282261, 0.6602466957259724, 0.6571158821346196, 0.674550177031801, 0.6784696474330116, 0.6835096200913874, 0.6848025599508795, 0.6804568257950644, 0.6853210562058077, 0.6871225251496293, 0.6917141666849151, 0.6799318995184571, 0.6968980995753339, 0.6991050065928743, 0.6896280541674782, 0.7015017343841436, 0.6811749125254973, 0.6918304853766929, 0.6997326348574107, 0.7028616735043417, 0.6991919597596613, 0.6956528270517597, 0.7001852579699218, 0.6933168018137226, 0.7062306868211004, 0.6901215669762997, 0.705478791972153, 0.7020376342853517, 0.6986305932052262, 0.7025976481328484, 0.706633020903318, 0.6857874161414518, 0.6880688307849505, 0.6996549195005693, 0.692648844409535, 0.7011025752730042, 0.6860587742492443, 0.7072745256751548, 0.6863849640802573, 0.6997489132953965, 0.7040584606068735, 0.7053554690521182, 0.6571579648338202, 0.7027795847135646, 0.6924072340244555, 0.7058165592091684, 0.6919950237710968, 0.7048061135161015, 0.6923902817354858, 0.6970833994960057, 0.5264559683908943, 0.7053258127838601, 0.7067338569473675, 0.7009379172143135, 0.7079946630783663, 0.7035277927194843, 0.706617642904966, 0.6994093256142303, 0.7048853353689645, 0.6792433425670362, 0.702418168082492, 0.694582927773017, 0.7072482946264835, 0.6942051471644686, 0.7060482188035514, 0.7037718778348151, 0.7039245894847025, 0.7058567836994433, 0.7006040998087585, 0.7068415943902867, 0.6932147522919051, 0.6986247910798051, 0.7064956308321189, 0.7002357972487239, 0.7032105786199788, 0.7045740039294003, 0.706282907314883, 0.7114121445262706, 0.689142202602998, 0.7090047506885674, 0.6920576914576174, 0.6947868780325387, 0.708577227956466, 0.6971348000846747, 0.703903345661309, 0.6985101185682165, 0.7048100119328681, 0.7029818014334176, 0.6935448628345519, 0.6825991914472507, 0.6853170731595455, 0.6766941065096673, 0.7007164727640516, 0.7027528222280605, 0.6993925607841434, 0.703472079211519, 0.700347657422073, 0.6957114056776498, 0.6950533849592427, 0.7017882980463159, 0.6953761081659157, 0.6830932989375282, 0.6994421582185585, 0.7045484317168025, 0.7048173514941266, 0.6444231194394235, 0.7017545572674001, 0.69791150866574], 'loss': [13081.24053317344, 5354.93811833736, 4033.63259355953, 3371.717502399069, 2930.902780542778, 2655.958017692174, 2455.9280887588707, 2310.760562117586, 2188.7119117523866, 2089.98553349656, 2017.971251858675, 1941.1152243050465, 1887.0173426450701, 1825.7169557763084, 1770.1293759670962, 1731.2047197749887, 1679.4389477810212, 1645.1039457015029, 1605.4702867144379, 1584.1164583634213, 1550.382328847896, 1525.8548678797133, 1490.9432822641902, 1475.5634092050066, 1447.9755901741944, 1428.608225073455, 1407.2760563300887, 1388.654515565728, 1373.2213019245094, 1363.2065588006078, 1339.6332190710255, 1325.5810941021361, 1314.1458481275727, 1295.488020118001, 1283.371589889203, 1265.8975252178154, 1255.423412405688, 1289.6418482897384, 1229.5156937712113, 1222.9035561001476, 1216.0971163509475, 1212.5067774919303, 1193.6267225863935, 1232.5824282594754, 1181.1342996213293, 1169.3208035670623, 1163.3545627663677, 1156.753561907838, 1144.5564309457952, 1132.037850630011, 1136.4300060042729, 1115.6559028259423, 1116.8991834495657, 1108.3395011798168, 1112.3231719594603, 1097.9938153167448, 1097.201792697887, 1087.0500598821807, 1101.4299346494213, 1103.1200600828067, 1073.7338554623518, 1063.9044305285834, 1063.4773300819782, 1062.0629902568874, 1049.3009344414338, 1049.8856338440771, 1040.2020406009938, 1039.2494357005614, 1032.7787507472638, 1035.7715387280716, 1027.6828901718372, 1021.9483156711048, 1339.874312240316, 1106.8473699059534, 1062.642108161135, 1046.1089180346105, 1030.8213112895362, 1024.5969670320012, 1020.4029390635275, 1115.695329042433, 1028.5725495087909, 1011.5954077575377, 1007.172701293642, 997.3492857643955, 991.2028774239362, 992.4023546791848, 991.3403457180025, 982.7171715801379, 984.7757643683341, 987.3607150812784, 982.14340227651, 988.245234191618, 981.7077597354656, 977.3087627762645, 974.7871019213911, 982.2713108459469, 979.8413539665163, 971.8526475218746, 973.0533670056284, 979.1048240083721, 970.0245581175396, 966.0267012441575, 960.9594005819035, 963.7300632834881, 953.0352998962358, 954.8675484500037, 956.4547580955171, 953.4559209075591, 952.5049676400396, 953.2454384151498, 949.2243504758131, 943.9194485544839, 942.5777093014998, 941.9532107581258, 939.8841629648958, 939.6438616070154], 'acc': [0.8667243277952833, 0.8984847270052829, 0.9126285412086363, 0.9212878716950689, 0.9271595445945855, 0.931044903623883, 0.9339738865237571, 0.9361556049236175, 0.9380737476675456, 0.939703587808288, 0.9410325450348815, 0.9422573053869921, 0.9433385636647496, 0.9443432218501557, 0.9451184614907052, 0.9458793110793817, 0.9466272621375679, 0.9472888114652235, 0.9479599652151444, 0.9483881171665176, 0.9490211707297556, 0.9495339914782547, 0.9500400425019804, 0.9502979238949968, 0.9508433867327754, 0.9511777585785797, 0.9516219435958067, 0.9519431271597869, 0.952238548588222, 0.9524826857349052, 0.9528975783254291, 0.9531044218339157, 0.9533578169474187, 0.9536193355535403, 0.9538781163933924, 0.9541100736245984, 0.9543725083258597, 0.9544368382290908, 0.9547282622557213, 0.9549159373674491, 0.9550928599539802, 0.9552157911847156, 0.955437623706573, 0.9554103670155545, 0.9556874687797439, 0.9558932679918588, 0.9560870348556489, 0.9561686214808859, 0.9563011204228375, 0.9564706036273256, 0.9565372730644002, 0.9568345507235678, 0.9567380117611679, 0.9569116368598739, 0.9570217072118815, 0.9570709563328291, 0.9571942325527747, 0.9572852792269047, 0.9570054383492516, 0.9570320284606432, 0.9574467417320347, 0.9576629546557454, 0.9576866605660554, 0.957724130254115, 0.9578224203718859, 0.9578103510163612, 0.9579147633751797, 0.9579633842767014, 0.9581711839071013, 0.9581363081897226, 0.9582514923961066, 0.9583102913489094, 0.9520324635240883, 0.9565973193508783, 0.95742674810608, 0.9578119351428461, 0.9579972888323665, 0.9581783171304917, 0.9583184893233806, 0.9566020915375757, 0.958143475627207, 0.9583068707118317, 0.9584850884022764, 0.9586201631800454, 0.9587723479836989, 0.9587188113350696, 0.9587449486758869, 0.9587406467065128, 0.958860333352937, 0.9587493995886421, 0.9588578852305741, 0.958734286157217, 0.9588553254652769, 0.9589330581852439, 0.9590184839285496, 0.9589774976332274, 0.9589119827389061, 0.9591194188474615, 0.9590001992303877, 0.9590037848116842, 0.9590790521280352, 0.9591950471451502, 0.9592343333042849, 0.9592282485175664, 0.9593864889864717, 0.9593300836527248, 0.9593973679911626, 0.9594057810231641, 0.9594043024365904, 0.959457195004321, 0.9594929001550713, 0.9595945382194876, 0.9596266748843745, 0.9596484190037168, 0.9596985004556656, 0.9596063925726472], 'mDice': [0.19791117237357392, 0.373251794505743, 0.46265036570903323, 0.5200314332891982, 0.5623577810122374, 0.5910587289944342, 0.6131628667090557, 0.6304662055514909, 0.6452509351385001, 0.6574970851122673, 0.6670306427537207, 0.6767723810609465, 0.6841730713855914, 0.6922955128585516, 0.7001497976017728, 0.7053151046302409, 0.7122507551118352, 0.7171174334541346, 0.7227338298743673, 0.7258861829501816, 0.7306866363657044, 0.7342986369296749, 0.7391386078065889, 0.7417245803942456, 0.7456494076658813, 0.7484208469041528, 0.7517319590635763, 0.7545430189136221, 0.7568740117706101, 0.7586419672257333, 0.7620380267960346, 0.7640158609307058, 0.7657380286603984, 0.7686099148167109, 0.7706116659502249, 0.7730980486968296, 0.7747513628736487, 0.7744944155073948, 0.7787788476787881, 0.7798871534056169, 0.7810965717126277, 0.7815483591224279, 0.7844338611438286, 0.7833334710758377, 0.7864109861606269, 0.7882784393772216, 0.7892350242375875, 0.7901858192335887, 0.7921479349913544, 0.7940708516059729, 0.7935053098625072, 0.7967679277363647, 0.7965213039474287, 0.7979431989433483, 0.7972816072139083, 0.7996016935242083, 0.7997244203994798, 0.8013344021098776, 0.7995760037132627, 0.7987982693124522, 0.8034569564178768, 0.8050193045431863, 0.8051376331914586, 0.805415764357391, 0.8074027103986131, 0.8073258903506345, 0.8088348036305033, 0.8090573439230392, 0.8101293890252894, 0.8096731454678382, 0.810959857666543, 0.8121285093783566, 0.7634480916331298, 0.7981491636977901, 0.8052070884757084, 0.8079510256535556, 0.8104018116317854, 0.8114389334380455, 0.8128054327992423, 0.7971619366031631, 0.8107964563221095, 0.8135554654586971, 0.8142802886023571, 0.8158670075307071, 0.8168509245394987, 0.8167644966664274, 0.8168733807672532, 0.818292585709073, 0.817986244453632, 0.8175338360539622, 0.8184456260334737, 0.8174324865998293, 0.8185487021031339, 0.8192261888806776, 0.819652612561565, 0.8187296098099338, 0.8187516859952911, 0.8201489711598696, 0.819913028570313, 0.8191089185668917, 0.8204667077845422, 0.8210738588049569, 0.8218250633755211, 0.821528908335824, 0.8232377821973264, 0.8229395908006093, 0.8226537770172538, 0.8231500048709163, 0.8234374972818029, 0.8235474884251635, 0.8239439013546781, 0.824749332758436, 0.8250086761565011, 0.8251108496610348, 0.825484686479908, 0.8254777077048142]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:44, 14.94s/it]predicting test subjects:  50%|█████     | 2/4 [00:28<00:28, 14.40s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:42<00:14, 14.51s/it]predicting test subjects: 100%|██████████| 4/4 [00:56<00:00, 14.24s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:20<1:47:59, 20.90s/it]predicting train subjects:   1%|          | 2/311 [00:30<1:30:24, 17.55s/it]predicting train subjects:   1%|          | 3/311 [00:43<1:22:37, 16.10s/it]predicting train subjects:   1%|▏         | 4/311 [00:55<1:16:32, 14.96s/it]predicting train subjects:   2%|▏         | 5/311 [01:06<1:10:40, 13.86s/it]predicting train subjects:   2%|▏         | 6/311 [01:17<1:06:08, 13.01s/it]predicting train subjects:   2%|▏         | 7/311 [01:30<1:05:28, 12.92s/it]predicting train subjects:   3%|▎         | 8/311 [01:45<1:08:46, 13.62s/it]predicting train subjects:   3%|▎         | 9/311 [01:59<1:08:40, 13.65s/it]predicting train subjects:   3%|▎         | 10/311 [02:11<1:05:52, 13.13s/it]predicting train subjects:   4%|▎         | 11/311 [02:26<1:08:44, 13.75s/it]predicting train subjects:   4%|▍         | 12/311 [02:38<1:05:56, 13.23s/it]predicting train subjects:   4%|▍         | 13/311 [02:50<1:03:32, 12.79s/it]predicting train subjects:   5%|▍         | 14/311 [03:05<1:06:59, 13.53s/it]predicting train subjects:   5%|▍         | 15/311 [03:27<1:18:21, 15.88s/it]predicting train subjects:   5%|▌         | 16/311 [03:48<1:26:44, 17.64s/it]predicting train subjects:   5%|▌         | 17/311 [04:10<1:32:19, 18.84s/it]predicting train subjects:   6%|▌         | 18/311 [04:33<1:37:17, 19.92s/it]predicting train subjects:   6%|▌         | 19/311 [04:54<1:39:05, 20.36s/it]predicting train subjects:   6%|▋         | 20/311 [05:16<1:40:45, 20.78s/it]predicting train subjects:   7%|▋         | 21/311 [05:37<1:41:09, 20.93s/it]predicting train subjects:   7%|▋         | 22/311 [05:58<1:40:45, 20.92s/it]predicting train subjects:   7%|▋         | 23/311 [06:20<1:41:50, 21.22s/it]predicting train subjects:   8%|▊         | 24/311 [06:42<1:43:02, 21.54s/it]predicting train subjects:   8%|▊         | 25/311 [07:04<1:43:06, 21.63s/it]predicting train subjects:   8%|▊         | 26/311 [07:26<1:43:06, 21.71s/it]predicting train subjects:   9%|▊         | 27/311 [07:48<1:43:41, 21.91s/it]predicting train subjects:   9%|▉         | 28/311 [08:10<1:43:04, 21.85s/it]predicting train subjects:   9%|▉         | 29/311 [08:31<1:42:19, 21.77s/it]predicting train subjects:  10%|▉         | 30/311 [08:54<1:42:33, 21.90s/it]predicting train subjects:  10%|▉         | 31/311 [09:16<1:42:19, 21.93s/it]predicting train subjects:  10%|█         | 32/311 [09:38<1:41:54, 21.92s/it]predicting train subjects:  11%|█         | 33/311 [09:48<1:26:04, 18.58s/it]predicting train subjects:  11%|█         | 34/311 [09:58<1:14:03, 16.04s/it]predicting train subjects:  11%|█▏        | 35/311 [10:09<1:06:00, 14.35s/it]predicting train subjects:  12%|█▏        | 36/311 [10:19<1:00:26, 13.19s/it]predicting train subjects:  12%|█▏        | 37/311 [10:29<55:34, 12.17s/it]  predicting train subjects:  12%|█▏        | 38/311 [10:40<52:58, 11.64s/it]predicting train subjects:  13%|█▎        | 39/311 [10:50<50:39, 11.17s/it]predicting train subjects:  13%|█▎        | 40/311 [11:00<49:21, 10.93s/it]predicting train subjects:  13%|█▎        | 41/311 [11:11<48:41, 10.82s/it]predicting train subjects:  14%|█▎        | 42/311 [11:20<47:22, 10.57s/it]predicting train subjects:  14%|█▍        | 43/311 [11:31<47:07, 10.55s/it]predicting train subjects:  14%|█▍        | 44/311 [11:41<46:10, 10.38s/it]predicting train subjects:  14%|█▍        | 45/311 [11:51<45:49, 10.34s/it]predicting train subjects:  15%|█▍        | 46/311 [12:02<46:01, 10.42s/it]predicting train subjects:  15%|█▌        | 47/311 [12:12<45:07, 10.26s/it]predicting train subjects:  15%|█▌        | 48/311 [12:22<45:21, 10.35s/it]predicting train subjects:  16%|█▌        | 49/311 [12:33<45:11, 10.35s/it]predicting train subjects:  16%|█▌        | 50/311 [12:43<44:50, 10.31s/it]predicting train subjects:  16%|█▋        | 51/311 [12:57<49:05, 11.33s/it]predicting train subjects:  17%|█▋        | 52/311 [13:10<51:41, 11.97s/it]predicting train subjects:  17%|█▋        | 53/311 [13:23<52:27, 12.20s/it]predicting train subjects:  17%|█▋        | 54/311 [13:35<52:26, 12.24s/it]predicting train subjects:  18%|█▊        | 55/311 [13:48<52:44, 12.36s/it]predicting train subjects:  18%|█▊        | 56/311 [14:01<53:27, 12.58s/it]predicting train subjects:  18%|█▊        | 57/311 [14:14<53:37, 12.67s/it]predicting train subjects:  19%|█▊        | 58/311 [14:28<56:03, 13.29s/it]predicting train subjects:  19%|█▉        | 59/311 [14:43<57:39, 13.73s/it]predicting train subjects:  19%|█▉        | 60/311 [14:58<59:22, 14.19s/it]predicting train subjects:  20%|█▉        | 61/311 [15:13<59:29, 14.28s/it]predicting train subjects:  20%|█▉        | 62/311 [15:27<59:20, 14.30s/it]predicting train subjects:  20%|██        | 63/311 [15:41<58:21, 14.12s/it]predicting train subjects:  21%|██        | 64/311 [15:56<59:24, 14.43s/it]predicting train subjects:  21%|██        | 65/311 [16:11<59:48, 14.59s/it]predicting train subjects:  21%|██        | 66/311 [16:26<59:52, 14.66s/it]predicting train subjects:  22%|██▏       | 67/311 [16:40<58:20, 14.35s/it]predicting train subjects:  22%|██▏       | 68/311 [16:54<58:39, 14.48s/it]predicting train subjects:  22%|██▏       | 69/311 [17:09<59:06, 14.65s/it]predicting train subjects:  23%|██▎       | 70/311 [17:24<58:55, 14.67s/it]predicting train subjects:  23%|██▎       | 71/311 [17:39<58:54, 14.73s/it]predicting train subjects:  23%|██▎       | 72/311 [17:53<57:47, 14.51s/it]predicting train subjects:  23%|██▎       | 73/311 [18:08<57:38, 14.53s/it]predicting train subjects:  24%|██▍       | 74/311 [18:23<58:35, 14.83s/it]predicting train subjects:  24%|██▍       | 75/311 [18:39<59:01, 15.01s/it]predicting train subjects:  24%|██▍       | 76/311 [18:53<58:01, 14.81s/it]predicting train subjects:  25%|██▍       | 77/311 [19:08<58:23, 14.97s/it]predicting train subjects:  25%|██▌       | 78/311 [19:23<57:52, 14.90s/it]predicting train subjects:  25%|██▌       | 79/311 [19:36<55:52, 14.45s/it]predicting train subjects:  26%|██▌       | 80/311 [19:50<54:57, 14.27s/it]predicting train subjects:  26%|██▌       | 81/311 [20:04<53:52, 14.05s/it]predicting train subjects:  26%|██▋       | 82/311 [20:17<52:33, 13.77s/it]predicting train subjects:  27%|██▋       | 83/311 [20:30<51:55, 13.67s/it]predicting train subjects:  27%|██▋       | 84/311 [20:45<52:47, 13.96s/it]predicting train subjects:  27%|██▋       | 85/311 [20:58<52:02, 13.82s/it]predicting train subjects:  28%|██▊       | 86/311 [21:12<51:05, 13.62s/it]predicting train subjects:  28%|██▊       | 87/311 [21:25<50:10, 13.44s/it]predicting train subjects:  28%|██▊       | 88/311 [21:38<49:22, 13.28s/it]predicting train subjects:  29%|██▊       | 89/311 [21:49<46:56, 12.69s/it]predicting train subjects:  29%|██▉       | 90/311 [21:59<44:15, 12.02s/it]predicting train subjects:  29%|██▉       | 91/311 [22:10<42:56, 11.71s/it]predicting train subjects:  30%|██▉       | 92/311 [22:21<42:09, 11.55s/it]predicting train subjects:  30%|██▉       | 93/311 [22:32<41:23, 11.39s/it]predicting train subjects:  30%|███       | 94/311 [22:43<40:32, 11.21s/it]predicting train subjects:  31%|███       | 95/311 [22:55<40:26, 11.23s/it]predicting train subjects:  31%|███       | 96/311 [23:06<40:12, 11.22s/it]predicting train subjects:  31%|███       | 97/311 [23:16<39:26, 11.06s/it]predicting train subjects:  32%|███▏      | 98/311 [23:28<39:31, 11.13s/it]predicting train subjects:  32%|███▏      | 99/311 [23:39<39:22, 11.15s/it]predicting train subjects:  32%|███▏      | 100/311 [23:51<39:51, 11.33s/it]predicting train subjects:  32%|███▏      | 101/311 [24:01<39:08, 11.18s/it]predicting train subjects:  33%|███▎      | 102/311 [24:13<38:56, 11.18s/it]predicting train subjects:  33%|███▎      | 103/311 [24:24<38:58, 11.24s/it]predicting train subjects:  33%|███▎      | 104/311 [24:35<38:54, 11.28s/it]predicting train subjects:  34%|███▍      | 105/311 [24:47<38:47, 11.30s/it]predicting train subjects:  34%|███▍      | 106/311 [24:58<38:27, 11.26s/it]predicting train subjects:  34%|███▍      | 107/311 [25:09<38:06, 11.21s/it]predicting train subjects:  35%|███▍      | 108/311 [25:21<38:16, 11.31s/it]predicting train subjects:  35%|███▌      | 109/311 [25:32<38:01, 11.29s/it]predicting train subjects:  35%|███▌      | 110/311 [25:43<37:33, 11.21s/it]predicting train subjects:  36%|███▌      | 111/311 [25:54<37:17, 11.19s/it]predicting train subjects:  36%|███▌      | 112/311 [26:06<37:32, 11.32s/it]predicting train subjects:  36%|███▋      | 113/311 [26:17<37:24, 11.34s/it]predicting train subjects:  37%|███▋      | 114/311 [26:38<46:24, 14.13s/it]predicting train subjects:  37%|███▋      | 115/311 [26:59<53:19, 16.32s/it]predicting train subjects:  37%|███▋      | 116/311 [27:20<57:40, 17.75s/it]predicting train subjects:  38%|███▊      | 117/311 [27:42<1:00:58, 18.86s/it]predicting train subjects:  38%|███▊      | 118/311 [28:03<1:02:55, 19.56s/it]predicting train subjects:  38%|███▊      | 119/311 [28:24<1:04:12, 20.06s/it]predicting train subjects:  39%|███▊      | 120/311 [28:45<1:04:51, 20.38s/it]predicting train subjects:  39%|███▉      | 121/311 [29:06<1:05:19, 20.63s/it]predicting train subjects:  39%|███▉      | 122/311 [29:27<1:05:21, 20.75s/it]predicting train subjects:  40%|███▉      | 123/311 [29:49<1:05:31, 20.91s/it]predicting train subjects:  40%|███▉      | 124/311 [30:09<1:05:03, 20.88s/it]predicting train subjects:  40%|████      | 125/311 [30:32<1:05:56, 21.27s/it]predicting train subjects:  41%|████      | 126/311 [30:52<1:05:05, 21.11s/it]predicting train subjects:  41%|████      | 127/311 [31:14<1:04:56, 21.18s/it]predicting train subjects:  41%|████      | 128/311 [31:34<1:04:04, 21.01s/it]predicting train subjects:  41%|████▏     | 129/311 [31:55<1:03:10, 20.83s/it]predicting train subjects:  42%|████▏     | 130/311 [32:15<1:02:35, 20.75s/it]predicting train subjects:  42%|████▏     | 131/311 [32:37<1:03:15, 21.09s/it]predicting train subjects:  42%|████▏     | 132/311 [32:47<52:29, 17.59s/it]  predicting train subjects:  43%|████▎     | 133/311 [32:57<45:31, 15.34s/it]predicting train subjects:  43%|████▎     | 134/311 [33:07<40:32, 13.74s/it]predicting train subjects:  43%|████▎     | 135/311 [33:16<36:46, 12.54s/it]predicting train subjects:  44%|████▎     | 136/311 [33:28<35:18, 12.11s/it]predicting train subjects:  44%|████▍     | 137/311 [33:37<33:12, 11.45s/it]predicting train subjects:  44%|████▍     | 138/311 [33:47<31:30, 10.93s/it]predicting train subjects:  45%|████▍     | 139/311 [33:57<30:37, 10.68s/it]predicting train subjects:  45%|████▌     | 140/311 [34:07<29:40, 10.41s/it]predicting train subjects:  45%|████▌     | 141/311 [34:18<29:31, 10.42s/it]predicting train subjects:  46%|████▌     | 142/311 [34:28<29:10, 10.36s/it]predicting train subjects:  46%|████▌     | 143/311 [34:38<28:48, 10.29s/it]predicting train subjects:  46%|████▋     | 144/311 [34:48<28:09, 10.12s/it]predicting train subjects:  47%|████▋     | 145/311 [34:58<27:55, 10.09s/it]predicting train subjects:  47%|████▋     | 146/311 [35:08<27:41, 10.07s/it]predicting train subjects:  47%|████▋     | 147/311 [35:17<27:09,  9.94s/it]predicting train subjects:  48%|████▊     | 148/311 [35:27<26:55,  9.91s/it]predicting train subjects:  48%|████▊     | 149/311 [35:37<26:47,  9.92s/it]predicting train subjects:  48%|████▊     | 150/311 [35:49<28:37, 10.67s/it]predicting train subjects:  49%|████▊     | 151/311 [36:02<29:53, 11.21s/it]predicting train subjects:  49%|████▉     | 152/311 [36:14<30:43, 11.59s/it]predicting train subjects:  49%|████▉     | 153/311 [36:27<31:17, 11.89s/it]predicting train subjects:  50%|████▉     | 154/311 [36:40<31:38, 12.09s/it]predicting train subjects:  50%|████▉     | 155/311 [36:52<32:02, 12.32s/it]predicting train subjects:  50%|█████     | 156/311 [37:05<32:24, 12.55s/it]predicting train subjects:  50%|█████     | 157/311 [37:19<32:37, 12.71s/it]predicting train subjects:  51%|█████     | 158/311 [37:31<32:33, 12.77s/it]predicting train subjects:  51%|█████     | 159/311 [37:44<32:25, 12.80s/it]predicting train subjects:  51%|█████▏    | 160/311 [37:57<32:06, 12.76s/it]predicting train subjects:  52%|█████▏    | 161/311 [38:10<32:04, 12.83s/it]predicting train subjects:  52%|█████▏    | 162/311 [38:23<31:50, 12.83s/it]predicting train subjects:  52%|█████▏    | 163/311 [38:36<31:40, 12.84s/it]predicting train subjects:  53%|█████▎    | 164/311 [38:48<31:24, 12.82s/it]predicting train subjects:  53%|█████▎    | 165/311 [39:01<30:51, 12.68s/it]predicting train subjects:  53%|█████▎    | 166/311 [39:13<30:23, 12.57s/it]predicting train subjects:  54%|█████▎    | 167/311 [39:26<30:16, 12.62s/it]predicting train subjects:  54%|█████▍    | 168/311 [39:38<29:57, 12.57s/it]predicting train subjects:  54%|█████▍    | 169/311 [39:50<29:22, 12.41s/it]predicting train subjects:  55%|█████▍    | 170/311 [40:02<28:49, 12.27s/it]predicting train subjects:  55%|█████▍    | 171/311 [40:15<28:55, 12.39s/it]predicting train subjects:  55%|█████▌    | 172/311 [40:28<29:06, 12.56s/it]predicting train subjects:  56%|█████▌    | 173/311 [40:41<29:05, 12.65s/it]predicting train subjects:  56%|█████▌    | 174/311 [40:53<28:53, 12.66s/it]predicting train subjects:  56%|█████▋    | 175/311 [41:06<28:15, 12.47s/it]predicting train subjects:  57%|█████▋    | 176/311 [41:18<27:53, 12.40s/it]predicting train subjects:  57%|█████▋    | 177/311 [41:30<27:55, 12.51s/it]predicting train subjects:  57%|█████▋    | 178/311 [41:43<27:43, 12.51s/it]predicting train subjects:  58%|█████▊    | 179/311 [41:55<27:22, 12.44s/it]predicting train subjects:  58%|█████▊    | 180/311 [42:07<26:50, 12.30s/it]predicting train subjects:  58%|█████▊    | 181/311 [42:20<26:37, 12.29s/it]predicting train subjects:  59%|█████▊    | 182/311 [42:32<26:42, 12.42s/it]predicting train subjects:  59%|█████▉    | 183/311 [42:45<26:49, 12.58s/it]predicting train subjects:  59%|█████▉    | 184/311 [42:57<25:53, 12.24s/it]predicting train subjects:  59%|█████▉    | 185/311 [43:07<24:47, 11.81s/it]predicting train subjects:  60%|█████▉    | 186/311 [43:19<24:16, 11.66s/it]predicting train subjects:  60%|██████    | 187/311 [43:30<24:04, 11.65s/it]predicting train subjects:  60%|██████    | 188/311 [43:42<23:37, 11.52s/it]predicting train subjects:  61%|██████    | 189/311 [43:53<23:08, 11.38s/it]predicting train subjects:  61%|██████    | 190/311 [44:04<22:54, 11.36s/it]predicting train subjects:  61%|██████▏   | 191/311 [44:16<22:51, 11.43s/it]predicting train subjects:  62%|██████▏   | 192/311 [44:27<22:43, 11.46s/it]predicting train subjects:  62%|██████▏   | 193/311 [44:38<22:26, 11.41s/it]predicting train subjects:  62%|██████▏   | 194/311 [44:50<22:16, 11.42s/it]predicting train subjects:  63%|██████▎   | 195/311 [45:01<22:02, 11.40s/it]predicting train subjects:  63%|██████▎   | 196/311 [45:13<21:57, 11.45s/it]predicting train subjects:  63%|██████▎   | 197/311 [45:24<21:39, 11.40s/it]predicting train subjects:  64%|██████▎   | 198/311 [45:35<21:16, 11.30s/it]predicting train subjects:  64%|██████▍   | 199/311 [45:47<21:18, 11.42s/it]predicting train subjects:  64%|██████▍   | 200/311 [45:58<21:15, 11.49s/it]predicting train subjects:  65%|██████▍   | 201/311 [46:10<20:58, 11.44s/it]predicting train subjects:  65%|██████▍   | 202/311 [46:21<20:30, 11.29s/it]predicting train subjects:  65%|██████▌   | 203/311 [46:32<20:28, 11.37s/it]predicting train subjects:  66%|██████▌   | 204/311 [46:44<20:15, 11.36s/it]predicting train subjects:  66%|██████▌   | 205/311 [46:55<19:58, 11.31s/it]predicting train subjects:  66%|██████▌   | 206/311 [47:06<19:44, 11.28s/it]predicting train subjects:  67%|██████▋   | 207/311 [47:18<19:46, 11.41s/it]predicting train subjects:  67%|██████▋   | 208/311 [47:29<19:43, 11.49s/it]predicting train subjects:  67%|██████▋   | 209/311 [47:40<19:19, 11.37s/it]predicting train subjects:  68%|██████▊   | 210/311 [47:52<19:11, 11.40s/it]predicting train subjects:  68%|██████▊   | 211/311 [48:04<19:11, 11.51s/it]predicting train subjects:  68%|██████▊   | 212/311 [48:15<19:01, 11.53s/it]predicting train subjects:  68%|██████▊   | 213/311 [48:36<23:33, 14.42s/it]predicting train subjects:  69%|██████▉   | 214/311 [48:59<27:08, 16.79s/it]predicting train subjects:  69%|██████▉   | 215/311 [49:22<30:02, 18.78s/it]predicting train subjects:  69%|██████▉   | 216/311 [49:50<33:53, 21.41s/it]predicting train subjects:  70%|██████▉   | 217/311 [50:16<35:38, 22.76s/it]predicting train subjects:  70%|███████   | 218/311 [50:43<37:24, 24.13s/it]predicting train subjects:  70%|███████   | 219/311 [51:09<37:49, 24.66s/it]predicting train subjects:  71%|███████   | 220/311 [51:35<38:15, 25.23s/it]predicting train subjects:  71%|███████   | 221/311 [52:01<37:56, 25.30s/it]predicting train subjects:  71%|███████▏  | 222/311 [52:29<38:41, 26.08s/it]predicting train subjects:  72%|███████▏  | 223/311 [52:53<37:36, 25.64s/it]predicting train subjects:  72%|███████▏  | 224/311 [53:20<37:21, 25.77s/it]predicting train subjects:  72%|███████▏  | 225/311 [53:46<37:13, 25.97s/it]predicting train subjects:  73%|███████▎  | 226/311 [54:10<35:59, 25.40s/it]predicting train subjects:  73%|███████▎  | 227/311 [54:37<36:07, 25.80s/it]predicting train subjects:  73%|███████▎  | 228/311 [55:03<35:58, 26.00s/it]predicting train subjects:  74%|███████▎  | 229/311 [55:30<35:54, 26.28s/it]predicting train subjects:  74%|███████▍  | 230/311 [55:52<33:33, 24.86s/it]predicting train subjects:  74%|███████▍  | 231/311 [56:02<27:15, 20.45s/it]predicting train subjects:  75%|███████▍  | 232/311 [56:12<22:41, 17.23s/it]predicting train subjects:  75%|███████▍  | 233/311 [56:21<19:27, 14.97s/it]predicting train subjects:  75%|███████▌  | 234/311 [56:31<17:18, 13.48s/it]predicting train subjects:  76%|███████▌  | 235/311 [56:41<15:34, 12.30s/it]predicting train subjects:  76%|███████▌  | 236/311 [56:51<14:28, 11.57s/it]predicting train subjects:  76%|███████▌  | 237/311 [57:01<13:45, 11.15s/it]predicting train subjects:  77%|███████▋  | 238/311 [57:10<12:59, 10.68s/it]predicting train subjects:  77%|███████▋  | 239/311 [57:20<12:30, 10.42s/it]predicting train subjects:  77%|███████▋  | 240/311 [57:30<12:13, 10.32s/it]predicting train subjects:  77%|███████▋  | 241/311 [57:40<11:49, 10.13s/it]predicting train subjects:  78%|███████▊  | 242/311 [57:50<11:33, 10.04s/it]predicting train subjects:  78%|███████▊  | 243/311 [58:00<11:24, 10.07s/it]predicting train subjects:  78%|███████▊  | 244/311 [58:10<11:06,  9.95s/it]predicting train subjects:  79%|███████▉  | 245/311 [58:20<11:01, 10.03s/it]predicting train subjects:  79%|███████▉  | 246/311 [58:30<10:51, 10.02s/it]predicting train subjects:  79%|███████▉  | 247/311 [58:40<10:41, 10.02s/it]predicting train subjects:  80%|███████▉  | 248/311 [58:50<10:26,  9.94s/it]predicting train subjects:  80%|████████  | 249/311 [59:03<11:12, 10.85s/it]predicting train subjects:  80%|████████  | 250/311 [59:16<11:41, 11.50s/it]predicting train subjects:  81%|████████  | 251/311 [59:28<11:53, 11.88s/it]predicting train subjects:  81%|████████  | 252/311 [59:41<11:51, 12.07s/it]predicting train subjects:  81%|████████▏ | 253/311 [59:53<11:41, 12.09s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:00:06<11:42, 12.33s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:00:19<11:40, 12.51s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:00:32<11:31, 12.57s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:00:44<11:23, 12.66s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:00:57<11:11, 12.66s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:01:10<10:55, 12.60s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:01:22<10:38, 12.53s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:01:34<10:25, 12.50s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:01:48<10:21, 12.68s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:02:00<10:08, 12.68s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:02:13<09:54, 12.65s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:02:25<09:35, 12.52s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:02:37<09:20, 12.47s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:02:50<09:07, 12.45s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:03:02<08:52, 12.38s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:03:14<08:36, 12.30s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:03:26<08:23, 12.28s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:03:38<08:06, 12.15s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:03:50<07:51, 12.10s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:04:02<07:42, 12.16s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:04:15<07:36, 12.34s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:04:28<07:24, 12.35s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:04:40<07:09, 12.28s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:04:52<06:53, 12.16s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:05:03<06:38, 12.09s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:05:16<06:30, 12.20s/it]predicting train subjects:  90%|█████████ | 280/311 [1:05:29<06:21, 12.32s/it]predicting train subjects:  90%|█████████ | 281/311 [1:05:41<06:09, 12.33s/it]predicting train subjects:  91%|█████████ | 282/311 [1:05:53<05:55, 12.25s/it]predicting train subjects:  91%|█████████ | 283/311 [1:06:04<05:30, 11.80s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:06:15<05:15, 11.67s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:06:27<05:08, 11.87s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:06:39<04:53, 11.75s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:06:50<04:35, 11.47s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:07:01<04:20, 11.33s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:07:12<04:09, 11.34s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:07:23<03:58, 11.37s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:07:34<03:44, 11.21s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:07:46<03:36, 11.38s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:07:57<03:22, 11.26s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:08:08<03:10, 11.22s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:08:19<02:59, 11.19s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:08:30<02:46, 11.10s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:08:41<02:35, 11.12s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:08:52<02:24, 11.08s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:09:03<02:10, 10.89s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:09:14<02:02, 11.12s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:09:26<01:51, 11.18s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:09:37<01:40, 11.18s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:09:48<01:29, 11.13s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:10:00<01:18, 11.27s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:10:11<01:07, 11.32s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:10:22<00:56, 11.35s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:10:34<00:45, 11.28s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:10:45<00:33, 11.19s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:10:56<00:22, 11.21s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:11:07<00:11, 11.32s/it]predicting train subjects: 100%|██████████| 311/311 [1:11:18<00:00, 11.23s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:16<1:23:25, 16.15s/it]Loading train:   1%|          | 2/311 [00:24<1:11:18, 13.85s/it]Loading train:   1%|          | 3/311 [00:35<1:05:50, 12.83s/it]Loading train:   1%|▏         | 4/311 [00:45<1:01:29, 12.02s/it]Loading train:   2%|▏         | 5/311 [00:54<57:13, 11.22s/it]  Loading train:   2%|▏         | 6/311 [01:03<54:12, 10.66s/it]Loading train:   2%|▏         | 7/311 [01:14<54:24, 10.74s/it]Loading train:   3%|▎         | 8/311 [01:27<56:48, 11.25s/it]Loading train:   3%|▎         | 9/311 [01:38<57:10, 11.36s/it]Loading train:   3%|▎         | 10/311 [01:48<54:28, 10.86s/it]Loading train:   4%|▎         | 11/311 [02:00<56:29, 11.30s/it]Loading train:   4%|▍         | 12/311 [02:10<53:47, 10.80s/it]Loading train:   4%|▍         | 13/311 [02:20<51:38, 10.40s/it]Loading train:   5%|▍         | 14/311 [02:32<54:23, 10.99s/it]Loading train:   5%|▍         | 15/311 [02:41<52:08, 10.57s/it]Loading train:   5%|▌         | 16/311 [02:50<49:37, 10.09s/it]Loading train:   5%|▌         | 17/311 [03:00<48:23,  9.88s/it]Loading train:   6%|▌         | 18/311 [03:09<46:54,  9.61s/it]Loading train:   6%|▌         | 19/311 [03:18<46:39,  9.59s/it]Loading train:   6%|▋         | 20/311 [03:27<45:38,  9.41s/it]Loading train:   7%|▋         | 21/311 [03:37<45:15,  9.36s/it]Loading train:   7%|▋         | 22/311 [03:46<45:06,  9.37s/it]Loading train:   7%|▋         | 23/311 [03:55<44:29,  9.27s/it]Loading train:   8%|▊         | 24/311 [04:04<44:20,  9.27s/it]Loading train:   8%|▊         | 25/311 [04:13<43:55,  9.22s/it]Loading train:   8%|▊         | 26/311 [04:23<44:10,  9.30s/it]Loading train:   9%|▊         | 27/311 [04:32<44:01,  9.30s/it]Loading train:   9%|▉         | 28/311 [04:41<43:40,  9.26s/it]Loading train:   9%|▉         | 29/311 [04:51<43:45,  9.31s/it]Loading train:  10%|▉         | 30/311 [05:00<43:18,  9.25s/it]Loading train:  10%|▉         | 31/311 [05:09<43:17,  9.28s/it]Loading train:  10%|█         | 32/311 [05:19<43:27,  9.34s/it]Loading train:  11%|█         | 33/311 [05:23<36:43,  7.93s/it]Loading train:  11%|█         | 34/311 [05:28<31:43,  6.87s/it]Loading train:  11%|█▏        | 35/311 [05:32<28:17,  6.15s/it]Loading train:  12%|█▏        | 36/311 [05:37<26:06,  5.70s/it]Loading train:  12%|█▏        | 37/311 [05:42<24:47,  5.43s/it]Loading train:  12%|█▏        | 38/311 [05:46<23:25,  5.15s/it]Loading train:  13%|█▎        | 39/311 [05:51<22:37,  4.99s/it]Loading train:  13%|█▎        | 40/311 [05:55<21:41,  4.80s/it]Loading train:  13%|█▎        | 41/311 [06:00<21:26,  4.76s/it]Loading train:  14%|█▎        | 42/311 [06:04<21:09,  4.72s/it]Loading train:  14%|█▍        | 43/311 [06:09<20:45,  4.65s/it]Loading train:  14%|█▍        | 44/311 [06:13<20:28,  4.60s/it]Loading train:  14%|█▍        | 45/311 [06:18<20:05,  4.53s/it]Loading train:  15%|█▍        | 46/311 [06:22<20:15,  4.59s/it]Loading train:  15%|█▌        | 47/311 [06:27<19:58,  4.54s/it]Loading train:  15%|█▌        | 48/311 [06:31<19:57,  4.55s/it]Loading train:  16%|█▌        | 49/311 [06:36<19:29,  4.46s/it]Loading train:  16%|█▌        | 50/311 [06:40<19:37,  4.51s/it]Loading train:  16%|█▋        | 51/311 [06:46<21:10,  4.89s/it]Loading train:  17%|█▋        | 52/311 [06:52<21:48,  5.05s/it]Loading train:  17%|█▋        | 53/311 [06:57<22:08,  5.15s/it]Loading train:  17%|█▋        | 54/311 [07:03<22:51,  5.34s/it]Loading train:  18%|█▊        | 55/311 [07:08<23:02,  5.40s/it]Loading train:  18%|█▊        | 56/311 [07:14<23:06,  5.44s/it]Loading train:  18%|█▊        | 57/311 [07:19<23:15,  5.49s/it]Loading train:  19%|█▊        | 58/311 [07:25<23:20,  5.53s/it]Loading train:  19%|█▉        | 59/311 [07:31<23:12,  5.53s/it]Loading train:  19%|█▉        | 60/311 [07:36<23:23,  5.59s/it]Loading train:  20%|█▉        | 61/311 [07:42<23:23,  5.61s/it]Loading train:  20%|█▉        | 62/311 [07:48<23:21,  5.63s/it]Loading train:  20%|██        | 63/311 [07:53<23:22,  5.66s/it]Loading train:  21%|██        | 64/311 [07:59<23:18,  5.66s/it]Loading train:  21%|██        | 65/311 [08:05<23:18,  5.69s/it]Loading train:  21%|██        | 66/311 [08:10<23:09,  5.67s/it]Loading train:  22%|██▏       | 67/311 [08:16<23:01,  5.66s/it]Loading train:  22%|██▏       | 68/311 [08:22<22:47,  5.63s/it]Loading train:  22%|██▏       | 69/311 [08:27<22:20,  5.54s/it]Loading train:  23%|██▎       | 70/311 [08:33<22:24,  5.58s/it]Loading train:  23%|██▎       | 71/311 [08:38<22:27,  5.61s/it]Loading train:  23%|██▎       | 72/311 [08:44<22:17,  5.60s/it]Loading train:  23%|██▎       | 73/311 [08:49<22:10,  5.59s/it]Loading train:  24%|██▍       | 74/311 [08:55<22:19,  5.65s/it]Loading train:  24%|██▍       | 75/311 [09:01<22:18,  5.67s/it]Loading train:  24%|██▍       | 76/311 [09:07<22:20,  5.70s/it]Loading train:  25%|██▍       | 77/311 [09:12<22:18,  5.72s/it]Loading train:  25%|██▌       | 78/311 [09:18<21:51,  5.63s/it]Loading train:  25%|██▌       | 79/311 [09:23<21:21,  5.52s/it]Loading train:  26%|██▌       | 80/311 [09:29<21:15,  5.52s/it]Loading train:  26%|██▌       | 81/311 [09:34<21:20,  5.57s/it]Loading train:  26%|██▋       | 82/311 [09:40<21:09,  5.54s/it]Loading train:  27%|██▋       | 83/311 [09:45<20:51,  5.49s/it]Loading train:  27%|██▋       | 84/311 [09:51<20:49,  5.51s/it]Loading train:  27%|██▋       | 85/311 [09:56<20:15,  5.38s/it]Loading train:  28%|██▊       | 86/311 [10:01<19:49,  5.28s/it]Loading train:  28%|██▊       | 87/311 [10:06<19:22,  5.19s/it]Loading train:  28%|██▊       | 88/311 [10:11<19:14,  5.18s/it]Loading train:  29%|██▊       | 89/311 [10:16<18:54,  5.11s/it]Loading train:  29%|██▉       | 90/311 [10:21<18:35,  5.05s/it]Loading train:  29%|██▉       | 91/311 [10:26<18:34,  5.06s/it]Loading train:  30%|██▉       | 92/311 [10:31<18:21,  5.03s/it]Loading train:  30%|██▉       | 93/311 [10:36<18:05,  4.98s/it]Loading train:  30%|███       | 94/311 [10:41<17:53,  4.95s/it]Loading train:  31%|███       | 95/311 [10:46<18:03,  5.01s/it]Loading train:  31%|███       | 96/311 [10:51<17:49,  4.98s/it]Loading train:  31%|███       | 97/311 [10:56<17:50,  5.00s/it]Loading train:  32%|███▏      | 98/311 [11:01<17:55,  5.05s/it]Loading train:  32%|███▏      | 99/311 [11:06<18:03,  5.11s/it]Loading train:  32%|███▏      | 100/311 [11:11<17:54,  5.09s/it]Loading train:  32%|███▏      | 101/311 [11:16<17:36,  5.03s/it]Loading train:  33%|███▎      | 102/311 [11:21<17:32,  5.03s/it]Loading train:  33%|███▎      | 103/311 [11:26<17:34,  5.07s/it]Loading train:  33%|███▎      | 104/311 [11:31<17:19,  5.02s/it]Loading train:  34%|███▍      | 105/311 [11:36<17:27,  5.09s/it]Loading train:  34%|███▍      | 106/311 [11:41<17:07,  5.01s/it]Loading train:  34%|███▍      | 107/311 [11:47<17:14,  5.07s/it]Loading train:  35%|███▍      | 108/311 [11:51<16:59,  5.02s/it]Loading train:  35%|███▌      | 109/311 [11:56<16:53,  5.02s/it]Loading train:  35%|███▌      | 110/311 [12:01<16:37,  4.96s/it]Loading train:  36%|███▌      | 111/311 [12:06<16:39,  5.00s/it]Loading train:  36%|███▌      | 112/311 [12:11<16:27,  4.96s/it]Loading train:  36%|███▋      | 113/311 [12:16<16:19,  4.95s/it]Loading train:  37%|███▋      | 114/311 [12:26<20:41,  6.30s/it]Loading train:  37%|███▋      | 115/311 [12:35<23:14,  7.11s/it]Loading train:  37%|███▋      | 116/311 [12:44<25:00,  7.70s/it]Loading train:  38%|███▊      | 117/311 [12:53<26:29,  8.19s/it]Loading train:  38%|███▊      | 118/311 [13:02<27:13,  8.46s/it]Loading train:  38%|███▊      | 119/311 [13:11<27:32,  8.60s/it]Loading train:  39%|███▊      | 120/311 [13:20<27:44,  8.71s/it]Loading train:  39%|███▉      | 121/311 [13:29<27:47,  8.78s/it]Loading train:  39%|███▉      | 122/311 [13:38<27:50,  8.84s/it]Loading train:  40%|███▉      | 123/311 [13:47<27:52,  8.90s/it]Loading train:  40%|███▉      | 124/311 [13:57<28:27,  9.13s/it]Loading train:  40%|████      | 125/311 [14:05<27:54,  9.00s/it]Loading train:  41%|████      | 126/311 [14:15<27:55,  9.06s/it]Loading train:  41%|████      | 127/311 [14:24<27:46,  9.06s/it]Loading train:  41%|████      | 128/311 [14:33<27:47,  9.11s/it]Loading train:  41%|████▏     | 129/311 [14:42<27:51,  9.18s/it]Loading train:  42%|████▏     | 130/311 [14:51<27:27,  9.10s/it]Loading train:  42%|████▏     | 131/311 [15:01<27:35,  9.20s/it]Loading train:  42%|████▏     | 132/311 [15:05<23:21,  7.83s/it]Loading train:  43%|████▎     | 133/311 [15:10<20:15,  6.83s/it]Loading train:  43%|████▎     | 134/311 [15:14<18:09,  6.16s/it]Loading train:  43%|████▎     | 135/311 [15:19<16:42,  5.69s/it]Loading train:  44%|████▎     | 136/311 [15:23<15:21,  5.27s/it]Loading train:  44%|████▍     | 137/311 [15:28<14:34,  5.03s/it]Loading train:  44%|████▍     | 138/311 [15:32<14:04,  4.88s/it]Loading train:  45%|████▍     | 139/311 [15:37<13:39,  4.77s/it]Loading train:  45%|████▌     | 140/311 [15:41<13:04,  4.59s/it]Loading train:  45%|████▌     | 141/311 [15:45<12:51,  4.54s/it]Loading train:  46%|████▌     | 142/311 [15:50<12:46,  4.53s/it]Loading train:  46%|████▌     | 143/311 [15:54<12:44,  4.55s/it]Loading train:  46%|████▋     | 144/311 [15:59<12:47,  4.60s/it]Loading train:  47%|████▋     | 145/311 [16:03<12:36,  4.56s/it]Loading train:  47%|████▋     | 146/311 [16:08<12:28,  4.54s/it]Loading train:  47%|████▋     | 147/311 [16:13<12:32,  4.59s/it]Loading train:  48%|████▊     | 148/311 [16:17<12:21,  4.55s/it]Loading train:  48%|████▊     | 149/311 [16:22<12:17,  4.55s/it]Loading train:  48%|████▊     | 150/311 [16:27<13:00,  4.85s/it]Loading train:  49%|████▊     | 151/311 [16:33<13:35,  5.10s/it]Loading train:  49%|████▉     | 152/311 [16:38<13:49,  5.21s/it]Loading train:  49%|████▉     | 153/311 [16:44<13:49,  5.25s/it]Loading train:  50%|████▉     | 154/311 [16:49<13:57,  5.33s/it]Loading train:  50%|████▉     | 155/311 [16:55<14:17,  5.50s/it]Loading train:  50%|█████     | 156/311 [17:01<14:16,  5.53s/it]Loading train:  50%|█████     | 157/311 [17:06<14:15,  5.55s/it]Loading train:  51%|█████     | 158/311 [17:12<14:20,  5.62s/it]Loading train:  51%|█████     | 159/311 [17:17<13:59,  5.52s/it]Loading train:  51%|█████▏    | 160/311 [17:23<13:43,  5.46s/it]Loading train:  52%|█████▏    | 161/311 [17:29<14:03,  5.62s/it]Loading train:  52%|█████▏    | 162/311 [17:34<14:00,  5.64s/it]Loading train:  52%|█████▏    | 163/311 [17:40<13:53,  5.63s/it]Loading train:  53%|█████▎    | 164/311 [17:46<13:58,  5.71s/it]Loading train:  53%|█████▎    | 165/311 [17:51<13:45,  5.65s/it]Loading train:  53%|█████▎    | 166/311 [17:57<13:24,  5.55s/it]Loading train:  54%|█████▎    | 167/311 [18:02<13:22,  5.57s/it]Loading train:  54%|█████▍    | 168/311 [18:08<12:59,  5.45s/it]Loading train:  54%|█████▍    | 169/311 [18:13<12:52,  5.44s/it]Loading train:  55%|█████▍    | 170/311 [18:18<12:46,  5.43s/it]Loading train:  55%|█████▍    | 171/311 [18:24<12:39,  5.43s/it]Loading train:  55%|█████▌    | 172/311 [18:29<12:18,  5.32s/it]Loading train:  56%|█████▌    | 173/311 [18:34<12:21,  5.37s/it]Loading train:  56%|█████▌    | 174/311 [18:40<12:21,  5.41s/it]Loading train:  56%|█████▋    | 175/311 [18:45<12:19,  5.44s/it]Loading train:  57%|█████▋    | 176/311 [18:51<12:08,  5.40s/it]Loading train:  57%|█████▋    | 177/311 [18:56<11:59,  5.37s/it]Loading train:  57%|█████▋    | 178/311 [19:01<11:45,  5.31s/it]Loading train:  58%|█████▊    | 179/311 [19:06<11:36,  5.28s/it]Loading train:  58%|█████▊    | 180/311 [19:12<11:47,  5.40s/it]Loading train:  58%|█████▊    | 181/311 [19:17<11:39,  5.38s/it]Loading train:  59%|█████▊    | 182/311 [19:22<11:20,  5.28s/it]Loading train:  59%|█████▉    | 183/311 [19:28<11:25,  5.36s/it]Loading train:  59%|█████▉    | 184/311 [19:33<11:01,  5.21s/it]Loading train:  59%|█████▉    | 185/311 [19:38<10:42,  5.10s/it]Loading train:  60%|█████▉    | 186/311 [19:42<10:24,  5.00s/it]Loading train:  60%|██████    | 187/311 [19:47<10:22,  5.02s/it]Loading train:  60%|██████    | 188/311 [19:53<10:19,  5.03s/it]Loading train:  61%|██████    | 189/311 [19:57<10:04,  4.96s/it]Loading train:  61%|██████    | 190/311 [20:02<10:06,  5.01s/it]Loading train:  61%|██████▏   | 191/311 [20:07<10:02,  5.02s/it]Loading train:  62%|██████▏   | 192/311 [20:14<10:54,  5.50s/it]Loading train:  62%|██████▏   | 193/311 [20:21<11:30,  5.85s/it]Loading train:  62%|██████▏   | 194/311 [20:27<11:43,  6.01s/it]Loading train:  63%|██████▎   | 195/311 [20:34<12:19,  6.38s/it]Loading train:  63%|██████▎   | 196/311 [20:41<12:16,  6.41s/it]Loading train:  63%|██████▎   | 197/311 [20:48<12:23,  6.52s/it]Loading train:  64%|██████▎   | 198/311 [20:54<12:03,  6.41s/it]Loading train:  64%|██████▍   | 199/311 [21:00<11:58,  6.42s/it]Loading train:  64%|██████▍   | 200/311 [21:06<11:38,  6.30s/it]Loading train:  65%|██████▍   | 201/311 [21:12<11:27,  6.25s/it]Loading train:  65%|██████▍   | 202/311 [21:19<11:21,  6.25s/it]Loading train:  65%|██████▌   | 203/311 [21:25<11:05,  6.16s/it]Loading train:  66%|██████▌   | 204/311 [21:31<10:55,  6.13s/it]Loading train:  66%|██████▌   | 205/311 [21:37<10:41,  6.05s/it]Loading train:  66%|██████▌   | 206/311 [21:43<10:42,  6.12s/it]Loading train:  67%|██████▋   | 207/311 [21:50<10:54,  6.30s/it]Loading train:  67%|██████▋   | 208/311 [21:56<11:03,  6.44s/it]Loading train:  67%|██████▋   | 209/311 [22:02<10:44,  6.32s/it]Loading train:  68%|██████▊   | 210/311 [22:09<10:49,  6.43s/it]Loading train:  68%|██████▊   | 211/311 [22:16<10:47,  6.48s/it]Loading train:  68%|██████▊   | 212/311 [22:23<10:54,  6.61s/it]Loading train:  68%|██████▊   | 213/311 [22:34<13:02,  7.98s/it]Loading train:  69%|██████▉   | 214/311 [22:44<13:58,  8.65s/it]Loading train:  69%|██████▉   | 215/311 [22:55<14:49,  9.26s/it]Loading train:  69%|██████▉   | 216/311 [23:06<15:30,  9.80s/it]Loading train:  70%|██████▉   | 217/311 [23:17<15:58, 10.19s/it]Loading train:  70%|███████   | 218/311 [23:28<16:15, 10.48s/it]Loading train:  70%|███████   | 219/311 [23:39<16:16, 10.62s/it]Loading train:  71%|███████   | 220/311 [23:51<16:38, 10.97s/it]Loading train:  71%|███████   | 221/311 [24:02<16:30, 11.00s/it]Loading train:  71%|███████▏  | 222/311 [24:13<16:20, 11.02s/it]Loading train:  72%|███████▏  | 223/311 [24:24<16:04, 10.96s/it]Loading train:  72%|███████▏  | 224/311 [24:34<15:47, 10.89s/it]Loading train:  72%|███████▏  | 225/311 [24:46<15:46, 11.01s/it]Loading train:  73%|███████▎  | 226/311 [24:56<15:25, 10.89s/it]Loading train:  73%|███████▎  | 227/311 [25:07<15:09, 10.83s/it]Loading train:  73%|███████▎  | 228/311 [25:18<15:01, 10.87s/it]Loading train:  74%|███████▎  | 229/311 [25:29<14:52, 10.88s/it]Loading train:  74%|███████▍  | 230/311 [25:40<14:53, 11.03s/it]Loading train:  74%|███████▍  | 231/311 [25:46<12:48,  9.61s/it]Loading train:  75%|███████▍  | 232/311 [25:52<11:04,  8.41s/it]Loading train:  75%|███████▍  | 233/311 [25:58<10:01,  7.71s/it]Loading train:  75%|███████▌  | 234/311 [26:03<08:57,  6.98s/it]Loading train:  76%|███████▌  | 235/311 [26:10<08:35,  6.79s/it]Loading train:  76%|███████▌  | 236/311 [26:15<08:04,  6.46s/it]Loading train:  76%|███████▌  | 237/311 [26:21<07:40,  6.22s/it]Loading train:  77%|███████▋  | 238/311 [26:27<07:19,  6.03s/it]Loading train:  77%|███████▋  | 239/311 [26:32<07:02,  5.87s/it]Loading train:  77%|███████▋  | 240/311 [26:38<06:49,  5.77s/it]Loading train:  77%|███████▋  | 241/311 [26:43<06:37,  5.68s/it]Loading train:  78%|███████▊  | 242/311 [26:48<06:21,  5.53s/it]Loading train:  78%|███████▊  | 243/311 [26:54<06:17,  5.56s/it]Loading train:  78%|███████▊  | 244/311 [26:59<06:08,  5.50s/it]Loading train:  79%|███████▉  | 245/311 [27:05<06:04,  5.52s/it]Loading train:  79%|███████▉  | 246/311 [27:11<06:04,  5.61s/it]Loading train:  79%|███████▉  | 247/311 [27:16<05:53,  5.52s/it]Loading train:  80%|███████▉  | 248/311 [27:22<06:00,  5.72s/it]Loading train:  80%|████████  | 249/311 [27:29<06:11,  5.98s/it]Loading train:  80%|████████  | 250/311 [27:36<06:28,  6.37s/it]Loading train:  81%|████████  | 251/311 [27:43<06:26,  6.44s/it]Loading train:  81%|████████  | 252/311 [27:48<06:00,  6.11s/it]Loading train:  81%|████████▏ | 253/311 [27:54<05:53,  6.09s/it]Loading train:  82%|████████▏ | 254/311 [27:59<05:34,  5.87s/it]Loading train:  82%|████████▏ | 255/311 [28:05<05:16,  5.64s/it]Loading train:  82%|████████▏ | 256/311 [28:10<05:06,  5.57s/it]Loading train:  83%|████████▎ | 257/311 [28:15<04:58,  5.52s/it]Loading train:  83%|████████▎ | 258/311 [28:21<04:46,  5.41s/it]Loading train:  83%|████████▎ | 259/311 [28:26<04:38,  5.36s/it]Loading train:  84%|████████▎ | 260/311 [28:31<04:36,  5.42s/it]Loading train:  84%|████████▍ | 261/311 [28:37<04:32,  5.44s/it]Loading train:  84%|████████▍ | 262/311 [28:43<04:31,  5.53s/it]Loading train:  85%|████████▍ | 263/311 [28:48<04:24,  5.51s/it]Loading train:  85%|████████▍ | 264/311 [28:54<04:19,  5.53s/it]Loading train:  85%|████████▌ | 265/311 [28:59<04:14,  5.52s/it]Loading train:  86%|████████▌ | 266/311 [29:04<04:05,  5.45s/it]Loading train:  86%|████████▌ | 267/311 [29:09<03:54,  5.33s/it]Loading train:  86%|████████▌ | 268/311 [29:15<03:53,  5.43s/it]Loading train:  86%|████████▋ | 269/311 [29:21<03:50,  5.48s/it]Loading train:  87%|████████▋ | 270/311 [29:26<03:40,  5.38s/it]Loading train:  87%|████████▋ | 271/311 [29:31<03:35,  5.40s/it]Loading train:  87%|████████▋ | 272/311 [29:37<03:32,  5.44s/it]Loading train:  88%|████████▊ | 273/311 [29:42<03:22,  5.34s/it]Loading train:  88%|████████▊ | 274/311 [29:47<03:18,  5.36s/it]Loading train:  88%|████████▊ | 275/311 [29:53<03:14,  5.39s/it]Loading train:  89%|████████▊ | 276/311 [29:58<03:05,  5.31s/it]Loading train:  89%|████████▉ | 277/311 [30:03<02:57,  5.22s/it]Loading train:  89%|████████▉ | 278/311 [30:08<02:53,  5.25s/it]Loading train:  90%|████████▉ | 279/311 [30:13<02:46,  5.19s/it]Loading train:  90%|█████████ | 280/311 [30:18<02:40,  5.18s/it]Loading train:  90%|█████████ | 281/311 [30:24<02:34,  5.14s/it]Loading train:  91%|█████████ | 282/311 [30:29<02:27,  5.10s/it]Loading train:  91%|█████████ | 283/311 [30:33<02:18,  4.95s/it]Loading train:  91%|█████████▏| 284/311 [30:38<02:13,  4.95s/it]Loading train:  92%|█████████▏| 285/311 [30:43<02:06,  4.86s/it]Loading train:  92%|█████████▏| 286/311 [30:47<01:58,  4.75s/it]Loading train:  92%|█████████▏| 287/311 [30:52<01:52,  4.71s/it]Loading train:  93%|█████████▎| 288/311 [30:56<01:47,  4.67s/it]Loading train:  93%|█████████▎| 289/311 [31:01<01:42,  4.67s/it]Loading train:  93%|█████████▎| 290/311 [31:06<01:37,  4.66s/it]Loading train:  94%|█████████▎| 291/311 [31:10<01:33,  4.68s/it]Loading train:  94%|█████████▍| 292/311 [31:15<01:28,  4.67s/it]Loading train:  94%|█████████▍| 293/311 [31:20<01:22,  4.60s/it]Loading train:  95%|█████████▍| 294/311 [31:24<01:18,  4.63s/it]Loading train:  95%|█████████▍| 295/311 [31:29<01:15,  4.72s/it]Loading train:  95%|█████████▌| 296/311 [31:34<01:10,  4.69s/it]Loading train:  95%|█████████▌| 297/311 [31:39<01:05,  4.70s/it]Loading train:  96%|█████████▌| 298/311 [31:44<01:02,  4.85s/it]Loading train:  96%|█████████▌| 299/311 [31:48<00:57,  4.79s/it]Loading train:  96%|█████████▋| 300/311 [31:53<00:53,  4.86s/it]Loading train:  97%|█████████▋| 301/311 [31:58<00:48,  4.87s/it]Loading train:  97%|█████████▋| 302/311 [32:03<00:44,  4.96s/it]Loading train:  97%|█████████▋| 303/311 [32:08<00:39,  4.92s/it]Loading train:  98%|█████████▊| 304/311 [32:13<00:34,  4.91s/it]Loading train:  98%|█████████▊| 305/311 [32:18<00:29,  4.92s/it]Loading train:  98%|█████████▊| 306/311 [32:23<00:24,  4.81s/it]Loading train:  99%|█████████▊| 307/311 [32:28<00:19,  4.83s/it]Loading train:  99%|█████████▉| 308/311 [32:33<00:14,  4.92s/it]Loading train:  99%|█████████▉| 309/311 [32:38<00:09,  4.92s/it]Loading train: 100%|█████████▉| 310/311 [32:43<00:04,  4.95s/it]Loading train: 100%|██████████| 311/311 [32:48<00:00,  5.03s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   5%|▌         | 16/311 [00:00<00:01, 153.72it/s]concatenating: train:  12%|█▏        | 38/311 [00:00<00:01, 168.20it/s]concatenating: train:  19%|█▉        | 60/311 [00:00<00:01, 180.95it/s]concatenating: train:  27%|██▋       | 83/311 [00:00<00:01, 191.78it/s]concatenating: train:  33%|███▎      | 104/311 [00:00<00:01, 194.48it/s]concatenating: train:  41%|████      | 126/311 [00:00<00:00, 198.60it/s]concatenating: train:  49%|████▉     | 153/311 [00:00<00:00, 208.82it/s]concatenating: train:  57%|█████▋    | 177/311 [00:00<00:00, 216.39it/s]concatenating: train:  65%|██████▍   | 202/311 [00:00<00:00, 224.75it/s]concatenating: train:  74%|███████▎  | 229/311 [00:01<00:00, 227.88it/s]concatenating: train:  82%|████████▏ | 254/311 [00:01<00:00, 234.08it/s]concatenating: train:  89%|████████▉ | 278/311 [00:01<00:00, 234.74it/s]concatenating: train:  98%|█████████▊| 305/311 [00:01<00:00, 232.52it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 224.03it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:34, 11.45s/it]Loading test:  50%|█████     | 2/4 [00:22<00:22, 11.20s/it]Loading test:  75%|███████▌  | 3/4 [00:33<00:11, 11.41s/it]Loading test: 100%|██████████| 4/4 [00:45<00:00, 11.30s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 154.14it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 19:03:58.991404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 19:03:58.991523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 19:03:58.991539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 19:03:58.991548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 19:03:58.991991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 40, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [5.87995836e-02 2.85625934e-02 1.22042724e-01 1.04920441e-02
 3.15682606e-02 5.46103058e-03 7.22892131e-02 1.13259646e-01
 7.87837639e-02 1.27868129e-02 2.92912776e-01 1.72791632e-01
 2.49918858e-04]
Train on 12355 samples, validate on 158 samples
Epoch 1/300
 - 19s - loss: 38039.5624 - acc: 0.8367 - mDice: 0.0729 - val_loss: 14343.2429 - val_acc: 0.8552 - val_mDice: 0.1718

Epoch 00001: val_mDice improved from -inf to 0.17176, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 13356.3733 - acc: 0.8588 - mDice: 0.2042 - val_loss: 8313.3647 - val_acc: 0.8654 - val_mDice: 0.2999

Epoch 00002: val_mDice improved from 0.17176 to 0.29991, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 9846.0734 - acc: 0.8778 - mDice: 0.2937 - val_loss: 7268.7685 - val_acc: 0.8768 - val_mDice: 0.3524

Epoch 00003: val_mDice improved from 0.29991 to 0.35244, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 8239.7245 - acc: 0.8889 - mDice: 0.3578 - val_loss: 6601.4406 - val_acc: 0.8849 - val_mDice: 0.3960

Epoch 00004: val_mDice improved from 0.35244 to 0.39597, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 10s - loss: 7257.8286 - acc: 0.8978 - mDice: 0.4053 - val_loss: 6041.6465 - val_acc: 0.8980 - val_mDice: 0.4250

Epoch 00005: val_mDice improved from 0.39597 to 0.42498, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 6704.3010 - acc: 0.9044 - mDice: 0.4392 - val_loss: 5395.5410 - val_acc: 0.9075 - val_mDice: 0.4614

Epoch 00006: val_mDice improved from 0.42498 to 0.46139, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 6136.8916 - acc: 0.9084 - mDice: 0.4658 - val_loss: 4977.6152 - val_acc: 0.9124 - val_mDice: 0.4984

Epoch 00007: val_mDice improved from 0.46139 to 0.49844, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 5703.0272 - acc: 0.9125 - mDice: 0.4907 - val_loss: 4825.8010 - val_acc: 0.9175 - val_mDice: 0.5088

Epoch 00008: val_mDice improved from 0.49844 to 0.50880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 5442.2910 - acc: 0.9146 - mDice: 0.5059 - val_loss: 4562.5598 - val_acc: 0.9187 - val_mDice: 0.5231

Epoch 00009: val_mDice improved from 0.50880 to 0.52314, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 10s - loss: 5190.2789 - acc: 0.9168 - mDice: 0.5220 - val_loss: 4320.6792 - val_acc: 0.9218 - val_mDice: 0.5456

Epoch 00010: val_mDice improved from 0.52314 to 0.54562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 4877.8682 - acc: 0.9186 - mDice: 0.5394 - val_loss: 4127.7080 - val_acc: 0.9237 - val_mDice: 0.5564

Epoch 00011: val_mDice improved from 0.54562 to 0.55645, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 4695.5867 - acc: 0.9202 - mDice: 0.5515 - val_loss: 3920.2271 - val_acc: 0.9249 - val_mDice: 0.5684

Epoch 00012: val_mDice improved from 0.55645 to 0.56835, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 4496.9463 - acc: 0.9217 - mDice: 0.5638 - val_loss: 3698.9734 - val_acc: 0.9275 - val_mDice: 0.5842

Epoch 00013: val_mDice improved from 0.56835 to 0.58416, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 10s - loss: 4319.5283 - acc: 0.9227 - mDice: 0.5745 - val_loss: 3603.1142 - val_acc: 0.9275 - val_mDice: 0.5889

Epoch 00014: val_mDice improved from 0.58416 to 0.58895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 10s - loss: 4112.0631 - acc: 0.9240 - mDice: 0.5873 - val_loss: 3394.4066 - val_acc: 0.9291 - val_mDice: 0.6049

Epoch 00015: val_mDice improved from 0.58895 to 0.60489, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 10s - loss: 3919.9133 - acc: 0.9253 - mDice: 0.6002 - val_loss: 3264.4298 - val_acc: 0.9326 - val_mDice: 0.6143

Epoch 00016: val_mDice improved from 0.60489 to 0.61427, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 3778.4254 - acc: 0.9267 - mDice: 0.6106 - val_loss: 3308.4248 - val_acc: 0.9321 - val_mDice: 0.6134

Epoch 00017: val_mDice did not improve from 0.61427
Epoch 18/300
 - 11s - loss: 3682.2562 - acc: 0.9276 - mDice: 0.6178 - val_loss: 3201.0286 - val_acc: 0.9332 - val_mDice: 0.6215

Epoch 00018: val_mDice improved from 0.61427 to 0.62145, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 10s - loss: 3555.4154 - acc: 0.9289 - mDice: 0.6276 - val_loss: 3225.4167 - val_acc: 0.9332 - val_mDice: 0.6187

Epoch 00019: val_mDice did not improve from 0.62145
Epoch 20/300
 - 10s - loss: 3467.1463 - acc: 0.9297 - mDice: 0.6347 - val_loss: 3372.0650 - val_acc: 0.9317 - val_mDice: 0.6104

Epoch 00020: val_mDice did not improve from 0.62145
Epoch 21/300
 - 11s - loss: 3393.5484 - acc: 0.9304 - mDice: 0.6409 - val_loss: 3166.6144 - val_acc: 0.9343 - val_mDice: 0.6263

Epoch 00021: val_mDice improved from 0.62145 to 0.62628, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 10s - loss: 3336.5009 - acc: 0.9314 - mDice: 0.6457 - val_loss: 2997.6912 - val_acc: 0.9363 - val_mDice: 0.6398

Epoch 00022: val_mDice improved from 0.62628 to 0.63984, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 10s - loss: 3240.2986 - acc: 0.9325 - mDice: 0.6536 - val_loss: 3003.2606 - val_acc: 0.9350 - val_mDice: 0.6386

Epoch 00023: val_mDice did not improve from 0.63984
Epoch 24/300
 - 11s - loss: 3190.4966 - acc: 0.9331 - mDice: 0.6580 - val_loss: 2968.8476 - val_acc: 0.9375 - val_mDice: 0.6411

Epoch 00024: val_mDice improved from 0.63984 to 0.64112, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 10s - loss: 3146.9784 - acc: 0.9338 - mDice: 0.6619 - val_loss: 2953.1281 - val_acc: 0.9365 - val_mDice: 0.6422

Epoch 00025: val_mDice improved from 0.64112 to 0.64224, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 10s - loss: 3083.1900 - acc: 0.9343 - mDice: 0.6670 - val_loss: 2963.4441 - val_acc: 0.9366 - val_mDice: 0.6438

Epoch 00026: val_mDice improved from 0.64224 to 0.64383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 11s - loss: 3022.3289 - acc: 0.9351 - mDice: 0.6724 - val_loss: 2899.4625 - val_acc: 0.9378 - val_mDice: 0.6475

Epoch 00027: val_mDice improved from 0.64383 to 0.64749, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 10s - loss: 2970.8625 - acc: 0.9357 - mDice: 0.6767 - val_loss: 3008.7126 - val_acc: 0.9394 - val_mDice: 0.6447

Epoch 00028: val_mDice did not improve from 0.64749
Epoch 29/300
 - 10s - loss: 2940.3409 - acc: 0.9363 - mDice: 0.6796 - val_loss: 2770.1243 - val_acc: 0.9420 - val_mDice: 0.6598

Epoch 00029: val_mDice improved from 0.64749 to 0.65984, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 11s - loss: 2880.3315 - acc: 0.9369 - mDice: 0.6849 - val_loss: 2731.6702 - val_acc: 0.9412 - val_mDice: 0.6612

Epoch 00030: val_mDice improved from 0.65984 to 0.66118, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 10s - loss: 2840.2787 - acc: 0.9375 - mDice: 0.6884 - val_loss: 2750.8320 - val_acc: 0.9424 - val_mDice: 0.6624

Epoch 00031: val_mDice improved from 0.66118 to 0.66238, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 10s - loss: 2816.2860 - acc: 0.9378 - mDice: 0.6905 - val_loss: 2871.5844 - val_acc: 0.9436 - val_mDice: 0.6541

Epoch 00032: val_mDice did not improve from 0.66238
Epoch 33/300
 - 11s - loss: 2771.5062 - acc: 0.9382 - mDice: 0.6944 - val_loss: 2822.7166 - val_acc: 0.9408 - val_mDice: 0.6575

Epoch 00033: val_mDice did not improve from 0.66238
Epoch 34/300
 - 10s - loss: 2737.1022 - acc: 0.9387 - mDice: 0.6975 - val_loss: 2655.1214 - val_acc: 0.9443 - val_mDice: 0.6688

Epoch 00034: val_mDice improved from 0.66238 to 0.66882, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 10s - loss: 2693.2257 - acc: 0.9392 - mDice: 0.7016 - val_loss: 2654.5120 - val_acc: 0.9435 - val_mDice: 0.6704

Epoch 00035: val_mDice improved from 0.66882 to 0.67042, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 11s - loss: 2669.1493 - acc: 0.9397 - mDice: 0.7038 - val_loss: 2839.7778 - val_acc: 0.9425 - val_mDice: 0.6577

Epoch 00036: val_mDice did not improve from 0.67042
Epoch 37/300
 - 10s - loss: 2620.8086 - acc: 0.9401 - mDice: 0.7081 - val_loss: 2625.4600 - val_acc: 0.9443 - val_mDice: 0.6692

Epoch 00037: val_mDice did not improve from 0.67042
Epoch 38/300
 - 10s - loss: 2591.1325 - acc: 0.9404 - mDice: 0.7110 - val_loss: 2799.7256 - val_acc: 0.9429 - val_mDice: 0.6585

Epoch 00038: val_mDice did not improve from 0.67042
Epoch 39/300
 - 11s - loss: 2564.1180 - acc: 0.9409 - mDice: 0.7133 - val_loss: 2743.5441 - val_acc: 0.9441 - val_mDice: 0.6625

Epoch 00039: val_mDice did not improve from 0.67042
Epoch 40/300
 - 10s - loss: 2535.5682 - acc: 0.9412 - mDice: 0.7160 - val_loss: 2526.8291 - val_acc: 0.9473 - val_mDice: 0.6811

Epoch 00040: val_mDice improved from 0.67042 to 0.68114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 10s - loss: 2493.2198 - acc: 0.9416 - mDice: 0.7199 - val_loss: 2512.0900 - val_acc: 0.9457 - val_mDice: 0.6827

Epoch 00041: val_mDice improved from 0.68114 to 0.68268, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 42/300
 - 11s - loss: 2478.7310 - acc: 0.9418 - mDice: 0.7213 - val_loss: 2774.1915 - val_acc: 0.9434 - val_mDice: 0.6646

Epoch 00042: val_mDice did not improve from 0.68268
Epoch 43/300
 - 10s - loss: 2440.5290 - acc: 0.9424 - mDice: 0.7248 - val_loss: 2686.9662 - val_acc: 0.9470 - val_mDice: 0.6685

Epoch 00043: val_mDice did not improve from 0.68268
Epoch 44/300
 - 10s - loss: 2426.8705 - acc: 0.9425 - mDice: 0.7262 - val_loss: 2721.0609 - val_acc: 0.9430 - val_mDice: 0.6668

Epoch 00044: val_mDice did not improve from 0.68268
Epoch 45/300
 - 11s - loss: 2402.7742 - acc: 0.9428 - mDice: 0.7284 - val_loss: 2421.0888 - val_acc: 0.9474 - val_mDice: 0.6926

Epoch 00045: val_mDice improved from 0.68268 to 0.69255, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 10s - loss: 2363.4819 - acc: 0.9432 - mDice: 0.7321 - val_loss: 2717.6931 - val_acc: 0.9430 - val_mDice: 0.6679

Epoch 00046: val_mDice did not improve from 0.69255
Epoch 47/300
 - 10s - loss: 2339.9024 - acc: 0.9437 - mDice: 0.7343 - val_loss: 2595.9878 - val_acc: 0.9456 - val_mDice: 0.6791

Epoch 00047: val_mDice did not improve from 0.69255
Epoch 48/300
 - 11s - loss: 2325.8853 - acc: 0.9439 - mDice: 0.7357 - val_loss: 2581.7359 - val_acc: 0.9443 - val_mDice: 0.6813

Epoch 00048: val_mDice did not improve from 0.69255
Epoch 49/300
 - 10s - loss: 2303.6183 - acc: 0.9441 - mDice: 0.7378 - val_loss: 2600.9391 - val_acc: 0.9476 - val_mDice: 0.6748

Epoch 00049: val_mDice did not improve from 0.69255
Epoch 50/300
 - 10s - loss: 2285.6042 - acc: 0.9445 - mDice: 0.7395 - val_loss: 2723.8335 - val_acc: 0.9429 - val_mDice: 0.6691

Epoch 00050: val_mDice did not improve from 0.69255
Epoch 51/300
 - 11s - loss: 2246.7832 - acc: 0.9449 - mDice: 0.7432 - val_loss: 2531.6406 - val_acc: 0.9504 - val_mDice: 0.6855

Epoch 00051: val_mDice did not improve from 0.69255
Epoch 52/300
 - 10s - loss: 2248.6750 - acc: 0.9450 - mDice: 0.7430 - val_loss: 2567.6909 - val_acc: 0.9494 - val_mDice: 0.6769

Epoch 00052: val_mDice did not improve from 0.69255
Epoch 53/300
 - 10s - loss: 2228.7866 - acc: 0.9454 - mDice: 0.7451 - val_loss: 2900.8701 - val_acc: 0.9440 - val_mDice: 0.6504

Epoch 00053: val_mDice did not improve from 0.69255
Epoch 54/300
 - 11s - loss: 2199.6198 - acc: 0.9456 - mDice: 0.7478 - val_loss: 2409.6065 - val_acc: 0.9497 - val_mDice: 0.6966

Epoch 00054: val_mDice improved from 0.69255 to 0.69662, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 55/300
 - 10s - loss: 2190.6358 - acc: 0.9459 - mDice: 0.7488 - val_loss: 2660.0926 - val_acc: 0.9484 - val_mDice: 0.6730

Epoch 00055: val_mDice did not improve from 0.69662
Epoch 56/300
 - 10s - loss: 2175.6730 - acc: 0.9462 - mDice: 0.7501 - val_loss: 2748.0354 - val_acc: 0.9451 - val_mDice: 0.6676

Epoch 00056: val_mDice did not improve from 0.69662
Epoch 57/300
 - 10s - loss: 2149.2889 - acc: 0.9464 - mDice: 0.7526 - val_loss: 2585.6011 - val_acc: 0.9483 - val_mDice: 0.6774

Epoch 00057: val_mDice did not improve from 0.69662
Epoch 58/300
 - 10s - loss: 2131.9455 - acc: 0.9466 - mDice: 0.7544 - val_loss: 2420.3353 - val_acc: 0.9509 - val_mDice: 0.6947

Epoch 00058: val_mDice did not improve from 0.69662
Epoch 59/300
 - 10s - loss: 2119.5396 - acc: 0.9470 - mDice: 0.7556 - val_loss: 2659.1991 - val_acc: 0.9459 - val_mDice: 0.6708

Epoch 00059: val_mDice did not improve from 0.69662
Epoch 60/300
 - 10s - loss: 2103.1696 - acc: 0.9471 - mDice: 0.7572 - val_loss: 2525.1086 - val_acc: 0.9486 - val_mDice: 0.6833

Epoch 00060: val_mDice did not improve from 0.69662
Epoch 61/300
 - 10s - loss: 2083.4872 - acc: 0.9474 - mDice: 0.7592 - val_loss: 2488.3701 - val_acc: 0.9508 - val_mDice: 0.6893

Epoch 00061: val_mDice did not improve from 0.69662
Epoch 62/300
 - 10s - loss: 2061.2573 - acc: 0.9477 - mDice: 0.7614 - val_loss: 2804.7723 - val_acc: 0.9479 - val_mDice: 0.6619

Epoch 00062: val_mDice did not improve from 0.69662
Epoch 63/300
 - 11s - loss: 2060.9922 - acc: 0.9477 - mDice: 0.7614 - val_loss: 2669.1360 - val_acc: 0.9497 - val_mDice: 0.6718

Epoch 00063: val_mDice did not improve from 0.69662
Epoch 64/300
 - 10s - loss: 2042.6950 - acc: 0.9480 - mDice: 0.7632 - val_loss: 2441.5993 - val_acc: 0.9515 - val_mDice: 0.6943

Epoch 00064: val_mDice did not improve from 0.69662
Epoch 65/300
 - 10s - loss: 2029.8249 - acc: 0.9482 - mDice: 0.7645 - val_loss: 2765.1715 - val_acc: 0.9467 - val_mDice: 0.6631

Epoch 00065: val_mDice did not improve from 0.69662
Epoch 66/300
 - 10s - loss: 2016.7996 - acc: 0.9483 - mDice: 0.7659 - val_loss: 2466.7648 - val_acc: 0.9510 - val_mDice: 0.6894

Epoch 00066: val_mDice did not improve from 0.69662
Epoch 67/300
 - 10s - loss: 2006.7235 - acc: 0.9485 - mDice: 0.7667 - val_loss: 2455.9222 - val_acc: 0.9506 - val_mDice: 0.6894

Epoch 00067: val_mDice did not improve from 0.69662
Epoch 68/300
 - 10s - loss: 1994.5731 - acc: 0.9487 - mDice: 0.7680 - val_loss: 2578.5255 - val_acc: 0.9480 - val_mDice: 0.6797

Epoch 00068: val_mDice did not improve from 0.69662
Epoch 69/300
 - 10s - loss: 1976.8844 - acc: 0.9489 - mDice: 0.7699 - val_loss: 2427.4095 - val_acc: 0.9513 - val_mDice: 0.6953

Epoch 00069: val_mDice did not improve from 0.69662
Epoch 70/300
 - 10s - loss: 1969.6438 - acc: 0.9490 - mDice: 0.7706 - val_loss: 2571.7905 - val_acc: 0.9508 - val_mDice: 0.6820

Epoch 00070: val_mDice did not improve from 0.69662
Epoch 71/300
 - 10s - loss: 1961.4423 - acc: 0.9493 - mDice: 0.7714 - val_loss: 2777.9799 - val_acc: 0.9508 - val_mDice: 0.6668

Epoch 00071: val_mDice did not improve from 0.69662
Epoch 72/300
 - 10s - loss: 1948.4007 - acc: 0.9495 - mDice: 0.7727 - val_loss: 2852.0750 - val_acc: 0.9474 - val_mDice: 0.6559

Epoch 00072: val_mDice did not improve from 0.69662
Epoch 73/300
 - 10s - loss: 1928.8590 - acc: 0.9497 - mDice: 0.7747 - val_loss: 2508.8339 - val_acc: 0.9520 - val_mDice: 0.6885

Epoch 00073: val_mDice did not improve from 0.69662
Epoch 74/300
 - 10s - loss: 1925.3380 - acc: 0.9496 - mDice: 0.7750 - val_loss: 2715.2170 - val_acc: 0.9493 - val_mDice: 0.6702

Epoch 00074: val_mDice did not improve from 0.69662
Epoch 75/300
 - 11s - loss: 1911.1151 - acc: 0.9499 - mDice: 0.7764 - val_loss: 2493.5163 - val_acc: 0.9508 - val_mDice: 0.6891

Epoch 00075: val_mDice did not improve from 0.69662
Epoch 76/300
 - 10s - loss: 1908.4115 - acc: 0.9500 - mDice: 0.7767 - val_loss: 2544.4856 - val_acc: 0.9491 - val_mDice: 0.6856

Epoch 00076: val_mDice did not improve from 0.69662
Epoch 77/300
 - 10s - loss: 1891.2750 - acc: 0.9501 - mDice: 0.7784 - val_loss: 2399.1906 - val_acc: 0.9525 - val_mDice: 0.6963

Epoch 00077: val_mDice did not improve from 0.69662
Epoch 78/300
 - 10s - loss: 1880.5658 - acc: 0.9505 - mDice: 0.7795 - val_loss: 2480.7919 - val_acc: 0.9523 - val_mDice: 0.6914

Epoch 00078: val_mDice did not improve from 0.69662
Epoch 79/300
 - 10s - loss: 1875.9915 - acc: 0.9504 - mDice: 0.7800 - val_loss: 2423.1827 - val_acc: 0.9513 - val_mDice: 0.6931

Epoch 00079: val_mDice did not improve from 0.69662
Epoch 80/300
 - 10s - loss: 1868.7990 - acc: 0.9506 - mDice: 0.7808 - val_loss: 2446.6915 - val_acc: 0.9512 - val_mDice: 0.6927

Epoch 00080: val_mDice did not improve from 0.69662
Epoch 81/300
 - 10s - loss: 1858.3168 - acc: 0.9506 - mDice: 0.7818 - val_loss: 2350.8728 - val_acc: 0.9539 - val_mDice: 0.7009

Epoch 00081: val_mDice improved from 0.69662 to 0.70092, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 82/300
 - 10s - loss: 1850.2522 - acc: 0.9507 - mDice: 0.7826 - val_loss: 2682.0574 - val_acc: 0.9496 - val_mDice: 0.6727

Epoch 00082: val_mDice did not improve from 0.70092
Epoch 83/300
 - 10s - loss: 1846.5453 - acc: 0.9509 - mDice: 0.7831 - val_loss: 2500.5028 - val_acc: 0.9498 - val_mDice: 0.6879

Epoch 00083: val_mDice did not improve from 0.70092
Epoch 84/300
 - 10s - loss: 1836.1163 - acc: 0.9509 - mDice: 0.7841 - val_loss: 2480.4042 - val_acc: 0.9527 - val_mDice: 0.6911

Epoch 00084: val_mDice did not improve from 0.70092
Epoch 85/300
 - 10s - loss: 1823.1975 - acc: 0.9511 - mDice: 0.7854 - val_loss: 2529.2921 - val_acc: 0.9522 - val_mDice: 0.6866

Epoch 00085: val_mDice did not improve from 0.70092
Epoch 86/300
 - 10s - loss: 1823.6547 - acc: 0.9511 - mDice: 0.7854 - val_loss: 2906.7942 - val_acc: 0.9450 - val_mDice: 0.6568

Epoch 00086: val_mDice did not improve from 0.70092
Epoch 87/300
 - 10s - loss: 1808.8200 - acc: 0.9513 - mDice: 0.7869 - val_loss: 2564.3740 - val_acc: 0.9515 - val_mDice: 0.6807

Epoch 00087: val_mDice did not improve from 0.70092
Epoch 88/300
 - 11s - loss: 1809.6424 - acc: 0.9515 - mDice: 0.7869 - val_loss: 2357.8996 - val_acc: 0.9544 - val_mDice: 0.7015

Epoch 00088: val_mDice improved from 0.70092 to 0.70150, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 89/300
 - 10s - loss: 1811.5311 - acc: 0.9514 - mDice: 0.7867 - val_loss: 2721.1345 - val_acc: 0.9486 - val_mDice: 0.6688

Epoch 00089: val_mDice did not improve from 0.70150
Epoch 90/300
 - 10s - loss: 1785.2645 - acc: 0.9517 - mDice: 0.7893 - val_loss: 2380.8082 - val_acc: 0.9537 - val_mDice: 0.6974

Epoch 00090: val_mDice did not improve from 0.70150
Epoch 91/300
 - 11s - loss: 1782.5697 - acc: 0.9516 - mDice: 0.7896 - val_loss: 2700.2414 - val_acc: 0.9464 - val_mDice: 0.6708

Epoch 00091: val_mDice did not improve from 0.70150
Epoch 92/300
 - 10s - loss: 1776.4774 - acc: 0.9517 - mDice: 0.7902 - val_loss: 2363.4926 - val_acc: 0.9534 - val_mDice: 0.6997

Epoch 00092: val_mDice did not improve from 0.70150
Epoch 93/300
 - 10s - loss: 1762.7047 - acc: 0.9519 - mDice: 0.7917 - val_loss: 2468.2377 - val_acc: 0.9512 - val_mDice: 0.6910

Epoch 00093: val_mDice did not improve from 0.70150
Epoch 94/300
 - 11s - loss: 1757.1112 - acc: 0.9520 - mDice: 0.7923 - val_loss: 2483.6402 - val_acc: 0.9520 - val_mDice: 0.6880

Epoch 00094: val_mDice did not improve from 0.70150
Epoch 95/300
 - 10s - loss: 1751.5158 - acc: 0.9520 - mDice: 0.7929 - val_loss: 2460.5873 - val_acc: 0.9512 - val_mDice: 0.6860

Epoch 00095: val_mDice did not improve from 0.70150
Epoch 96/300
 - 10s - loss: 1747.5185 - acc: 0.9521 - mDice: 0.7933 - val_loss: 2510.4553 - val_acc: 0.9523 - val_mDice: 0.6893

Epoch 00096: val_mDice did not improve from 0.70150
Epoch 97/300
 - 11s - loss: 1742.1754 - acc: 0.9521 - mDice: 0.7938 - val_loss: 2409.5362 - val_acc: 0.9523 - val_mDice: 0.6961

Epoch 00097: val_mDice did not improve from 0.70150
Epoch 98/300
 - 10s - loss: 1731.6212 - acc: 0.9523 - mDice: 0.7949 - val_loss: 2651.5915 - val_acc: 0.9496 - val_mDice: 0.6743

Epoch 00098: val_mDice did not improve from 0.70150
Epoch 99/300
 - 10s - loss: 1721.8559 - acc: 0.9524 - mDice: 0.7959 - val_loss: 2523.1498 - val_acc: 0.9521 - val_mDice: 0.6850

Epoch 00099: val_mDice did not improve from 0.70150
Epoch 100/300
 - 11s - loss: 1725.8029 - acc: 0.9524 - mDice: 0.7956 - val_loss: 2538.3918 - val_acc: 0.9517 - val_mDice: 0.6841

Epoch 00100: val_mDice did not improve from 0.70150
Epoch 101/300
 - 10s - loss: 1719.8200 - acc: 0.9525 - mDice: 0.7961 - val_loss: 2505.2751 - val_acc: 0.9524 - val_mDice: 0.6875

Epoch 00101: val_mDice did not improve from 0.70150
Epoch 102/300
 - 10s - loss: 1707.2227 - acc: 0.9526 - mDice: 0.7974 - val_loss: 2410.2785 - val_acc: 0.9540 - val_mDice: 0.6964

Epoch 00102: val_mDice did not improve from 0.70150
Epoch 103/300
 - 11s - loss: 1711.8293 - acc: 0.9525 - mDice: 0.7970 - val_loss: 2605.6897 - val_acc: 0.9519 - val_mDice: 0.6788

Epoch 00103: val_mDice did not improve from 0.70150
Epoch 104/300
 - 10s - loss: 1702.1180 - acc: 0.9526 - mDice: 0.7979 - val_loss: 2498.5318 - val_acc: 0.9515 - val_mDice: 0.6897

Epoch 00104: val_mDice did not improve from 0.70150
Epoch 105/300
 - 10s - loss: 1706.1124 - acc: 0.9527 - mDice: 0.7975 - val_loss: 2493.8393 - val_acc: 0.9537 - val_mDice: 0.6882

Epoch 00105: val_mDice did not improve from 0.70150
Epoch 106/300
 - 11s - loss: 1686.6089 - acc: 0.9528 - mDice: 0.7996 - val_loss: 2578.4014 - val_acc: 0.9510 - val_mDice: 0.6828

Epoch 00106: val_mDice did not improve from 0.70150
Epoch 107/300
 - 10s - loss: 1680.8191 - acc: 0.9530 - mDice: 0.8002 - val_loss: 3103.9039 - val_acc: 0.9480 - val_mDice: 0.6413

Epoch 00107: val_mDice did not improve from 0.70150
Epoch 108/300
 - 10s - loss: 1677.8280 - acc: 0.9530 - mDice: 0.8005 - val_loss: 2787.6019 - val_acc: 0.9481 - val_mDice: 0.6639

Epoch 00108: val_mDice did not improve from 0.70150
Epoch 109/300
 - 11s - loss: 1680.4749 - acc: 0.9530 - mDice: 0.8002 - val_loss: 2342.9858 - val_acc: 0.9542 - val_mDice: 0.7014

Epoch 00109: val_mDice did not improve from 0.70150
Epoch 110/300
 - 10s - loss: 1677.5198 - acc: 0.9531 - mDice: 0.8005 - val_loss: 2486.7253 - val_acc: 0.9541 - val_mDice: 0.6897

Epoch 00110: val_mDice did not improve from 0.70150
Epoch 111/300
 - 10s - loss: 1667.0016 - acc: 0.9532 - mDice: 0.8017 - val_loss: 2550.8995 - val_acc: 0.9529 - val_mDice: 0.6832

Epoch 00111: val_mDice did not improve from 0.70150
Epoch 112/300
 - 11s - loss: 1663.9078 - acc: 0.9532 - mDice: 0.8020 - val_loss: 2389.4396 - val_acc: 0.9540 - val_mDice: 0.6969

Epoch 00112: val_mDice did not improve from 0.70150
Epoch 113/300
 - 10s - loss: 1661.0690 - acc: 0.9533 - mDice: 0.8023 - val_loss: 2725.6282 - val_acc: 0.9510 - val_mDice: 0.6719

Epoch 00113: val_mDice did not improve from 0.70150
Epoch 114/300
 - 10s - loss: 1658.1405 - acc: 0.9533 - mDice: 0.8026 - val_loss: 2435.6389 - val_acc: 0.9546 - val_mDice: 0.6904

Epoch 00114: val_mDice did not improve from 0.70150
Epoch 115/300
 - 11s - loss: 1645.3647 - acc: 0.9534 - mDice: 0.8039 - val_loss: 3146.9432 - val_acc: 0.9515 - val_mDice: 0.6546

Epoch 00115: val_mDice did not improve from 0.70150
Epoch 116/300
 - 10s - loss: 1649.7309 - acc: 0.9534 - mDice: 0.8034 - val_loss: 2699.6896 - val_acc: 0.9514 - val_mDice: 0.6674

Epoch 00116: val_mDice did not improve from 0.70150
Epoch 117/300
 - 10s - loss: 1636.7105 - acc: 0.9536 - mDice: 0.8048 - val_loss: 2528.7010 - val_acc: 0.9516 - val_mDice: 0.6829

Epoch 00117: val_mDice did not improve from 0.70150
Epoch 118/300
 - 11s - loss: 1641.9354 - acc: 0.9536 - mDice: 0.8043 - val_loss: 2389.2138 - val_acc: 0.9554 - val_mDice: 0.6988

Epoch 00118: val_mDice did not improve from 0.70150
Restoring model weights from the end of the best epoch
Epoch 00118: early stopping
{'val_loss': [14343.242879746835, 8313.364653382121, 7268.768505241297, 6601.440621291535, 6041.646453471123, 5395.540975449961, 4977.615197290348, 4825.800979034811, 4562.559761916535, 4320.6792084899125, 4127.7080078125, 3920.2271125890034, 3698.9733933074563, 3603.114216092267, 3394.4065837618673, 3264.4298420193827, 3308.424795416337, 3201.0285629079312, 3225.41670169106, 3372.0650171207476, 3166.614367521262, 2997.691152838212, 3003.26064947587, 2968.847558902789, 2953.1281429242486, 2963.4441443334654, 2899.4625058717365, 3008.712564589102, 2770.124321659909, 2731.6702092810524, 2750.831975623022, 2871.5843923061707, 2822.716640810423, 2655.1214275118673, 2654.5120494214793, 2839.777776404272, 2625.4599825702135, 2799.725558124011, 2743.544055021262, 2526.8291139240505, 2512.0899797270567, 2774.1914927808543, 2686.9662467859966, 2721.0609022695808, 2421.0887713854827, 2717.693147683445, 2595.9877867879745, 2581.7358707476264, 2600.9390791880933, 2723.833533178402, 2531.640583279767, 2567.690853070609, 2900.8700507441654, 2409.606454583663, 2660.0925911046284, 2748.0353509444226, 2585.601064947587, 2420.3352946993673, 2659.1990951344937, 2525.10856377324, 2488.37008473843, 2804.772323415249, 2669.136023412777, 2441.599337420886, 2765.171487156349, 2466.764776688588, 2455.9222273041933, 2578.525464794304, 2427.4095289013053, 2571.7905134370058, 2777.979906299446, 2852.0750284315664, 2508.8339411095726, 2715.216976117484, 2493.5162616198577, 2544.4855709800236, 2399.1906429242486, 2480.791922653778, 2423.1826697240904, 2446.6914742385284, 2350.8727532881726, 2682.0573946795885, 2500.502801436412, 2480.4041670787183, 2529.2921096222312, 2906.7942018146755, 2564.3739755364913, 2357.899635025218, 2721.1345431170885, 2380.8082290842563, 2700.2414149030856, 2363.492647967761, 2468.237677079213, 2483.6402047072784, 2460.5873158128957, 2510.455262003066, 2409.5362471568433, 2651.591515649723, 2523.1497849090188, 2538.3917560818827, 2505.275058408327, 2410.2785350944423, 2605.689669452136, 2498.5317815466774, 2493.8393261100673, 2578.4013718230813, 3103.9039260284812, 2787.601871538766, 2342.985795033129, 2486.7253217093553, 2550.899542313588, 2389.439627731903, 2725.6281985512264, 2435.638852662678, 3146.9432450306567, 2699.6895705597312, 2528.7009709998024, 2389.2138270124606], 'val_acc': [0.8552260889282709, 0.8654181112216998, 0.8768302677552912, 0.884874009633366, 0.8980358507059798, 0.9074762810634661, 0.9123661125762553, 0.9175130694727355, 0.91870436110074, 0.9218141413942168, 0.9236855122107493, 0.9248782833920249, 0.9274722956403901, 0.927502756631827, 0.9291382514977757, 0.9326390397699573, 0.9320518042467818, 0.9331928650035134, 0.9331700137898892, 0.9316972999633113, 0.934300452848024, 0.9362965701501581, 0.9349546477764468, 0.9374650150914735, 0.9365278188186356, 0.9366373510300359, 0.9378149222724045, 0.9394443548178371, 0.9420307663422597, 0.9411970414692843, 0.9424187752264964, 0.9436100381839124, 0.9407756207864496, 0.9443159827703163, 0.9434654908844188, 0.9425054796134369, 0.9443083729925035, 0.9428721228732339, 0.9441029602968241, 0.9472781796998615, 0.9456502621686911, 0.9434365705598758, 0.9469708332532569, 0.9430364272262477, 0.9473709750779068, 0.9430227702177023, 0.9455574562277975, 0.9443235797218129, 0.9476402877252313, 0.9429406161549725, 0.9503666645363916, 0.9493640457527547, 0.9439675709869289, 0.9497337379033053, 0.948429896861692, 0.9451116564907606, 0.9483203488060191, 0.9508945957014833, 0.9458632672889323, 0.9486002793794945, 0.9508200438716744, 0.9479126243651668, 0.9496866011921363, 0.9515077147302748, 0.9466696109952806, 0.9510087114346178, 0.9505766185024117, 0.9479552069796792, 0.951320577271377, 0.9507591701761077, 0.9508337446405918, 0.9474272810960118, 0.9519824031033094, 0.9492940570734725, 0.9508352581458756, 0.9491023504281346, 0.9524601396126083, 0.952309545082382, 0.9512779999382889, 0.9511502038074445, 0.9539237361920031, 0.9496333463282525, 0.949785482279862, 0.9526807439478138, 0.9521512728703173, 0.9450234476524063, 0.9515183862251572, 0.9544014975994448, 0.9485713922524754, 0.953663594360593, 0.9464261690272561, 0.953394288503671, 0.9512004037446613, 0.9520189090620114, 0.9511851811710792, 0.9522578052327603, 0.9523323464997208, 0.949570937247216, 0.9520523880101457, 0.9516872695729702, 0.9524342576159707, 0.9540211309360552, 0.9519108933738515, 0.9515077486822877, 0.9537457552137254, 0.9509509153003934, 0.9480008611196205, 0.9480571573293661, 0.9542326127426534, 0.9540865534468542, 0.9529363196107405, 0.9540348075613191, 0.9509813091422938, 0.9545703364323966, 0.9515457515475116, 0.951411892341662, 0.9516111997109425, 0.9554208215278915], 'val_mDice': [0.17176300287246704, 0.299908346767667, 0.3524371566651743, 0.3959710699847982, 0.42497636245775827, 0.4613914580284795, 0.4984365814848791, 0.5087959223155734, 0.5231402493730376, 0.5456170371816128, 0.5564477594592904, 0.5683546262451366, 0.584155551240414, 0.5889452122434785, 0.6048942615714255, 0.6142687065691887, 0.6133990710294699, 0.6214532399479347, 0.6186552440063863, 0.6104225591768192, 0.6262796807892715, 0.6398393632490423, 0.6386133726639084, 0.6411166251460209, 0.6422436448592174, 0.6438262507885317, 0.6474869990650611, 0.6446700888344005, 0.6598386870154852, 0.661181347279609, 0.6623816203467453, 0.6541494085818906, 0.6574999078919616, 0.6688227132905887, 0.6704172205321396, 0.6577195457265347, 0.6692097647280633, 0.6585310750369784, 0.6625001558774635, 0.6811364081841481, 0.6826764903491056, 0.6645526606825334, 0.6684625707095182, 0.6667798259590245, 0.6925502381747282, 0.6679056437709664, 0.6791120314899879, 0.6813406235055078, 0.674816863446296, 0.6690844938724856, 0.6854865664168249, 0.6768632478351835, 0.6503611870958835, 0.6966196947459933, 0.6729509566403642, 0.6676071565362471, 0.677398482455483, 0.6947383035587359, 0.670840405210664, 0.683267796341377, 0.6892614983305146, 0.6618904961815363, 0.671800222577928, 0.6942888785012161, 0.6631428410735312, 0.6894466695906241, 0.6894301281699652, 0.6797187260434597, 0.6953479866438275, 0.6820084882687919, 0.6668441484246073, 0.6559341300891924, 0.6885276406626158, 0.6701865860178501, 0.6890694959254204, 0.6856168274638019, 0.6962619838835318, 0.6914061232458187, 0.6930765637868568, 0.692700293999684, 0.7009168395513221, 0.6726905635640591, 0.6879026150401635, 0.6911255226859564, 0.6866074211989777, 0.656826536866683, 0.6806734166567838, 0.7014963475963737, 0.6687503192998185, 0.6973749716070634, 0.6707707560515102, 0.6996977148176748, 0.6910133422175541, 0.6879860645608057, 0.6860410171219066, 0.6892504812795904, 0.6961467764045619, 0.6743362870397447, 0.6850035522557512, 0.6841313401355019, 0.6874749909473371, 0.6963795966739896, 0.6787936076333251, 0.6896901462651506, 0.6881550769262677, 0.6827739612965644, 0.641328587562223, 0.663906749290756, 0.7014208217210407, 0.6896658094623421, 0.6831823164903665, 0.6968999414504329, 0.6719040659409535, 0.6904331724854964, 0.6545914652981336, 0.6673978559578522, 0.6829063273683379, 0.6987962405892867], 'loss': [38039.56238578448, 13356.373314036575, 9846.073351858116, 8239.724503854082, 7257.828592038743, 6704.3010224265545, 6136.891616876866, 5703.02718951952, 5442.290950316642, 5190.278924192508, 4877.868236385825, 4695.58668602666, 4496.946336784039, 4319.528262019109, 4112.0630865895955, 3919.913315158969, 3778.4253646992615, 3682.2561799886494, 3555.4154426207288, 3467.146280348132, 3393.548432520361, 3336.5009156508468, 3240.2986247403473, 3190.496624417461, 3146.978356553205, 3083.1899583014533, 3022.3288921015023, 2970.862547988305, 2940.3408841388227, 2880.3314980630785, 2840.2787355294067, 2816.286001800574, 2771.5062281053974, 2737.1022160775938, 2693.225651147056, 2669.149281370934, 2620.8085868832363, 2591.1324938623975, 2564.1180118080674, 2535.5681820741697, 2493.219789894811, 2478.730978619565, 2440.528964009858, 2426.870491747237, 2402.774201686833, 2363.481878017424, 2339.9024097499746, 2325.885337344841, 2303.618309795977, 2285.604230311852, 2246.783196208835, 2248.6749736889324, 2228.786638186558, 2199.619813913664, 2190.6358041859794, 2175.673037162728, 2149.2889227934666, 2131.9455269505165, 2119.5396258216406, 2103.1696112403883, 2083.4871936336503, 2061.2573121154614, 2060.992209434123, 2042.6949647651034, 2029.8249086868614, 2016.7996096516465, 2006.7235420131335, 1994.5731021351585, 1976.8843794559864, 1969.6438255047615, 1961.442322296056, 1948.4007320365458, 1928.8590156064251, 1925.3379793989182, 1911.1150780202695, 1908.411518783909, 1891.2750074694582, 1880.5658398654866, 1875.9914784448824, 1868.7989617551882, 1858.3167692004597, 1850.2522074422677, 1846.5452907042, 1836.1163484456808, 1823.1974585366027, 1823.6546685447677, 1808.8199685442935, 1809.642385287499, 1811.531109379545, 1785.2644878095675, 1782.5696967390084, 1776.477443792327, 1762.7046688609353, 1757.1112262597696, 1751.5158392776125, 1747.5185340378073, 1742.1753934013464, 1731.621221205041, 1721.855903258067, 1725.8028758105745, 1719.8200017418856, 1707.2226557559882, 1711.8292944741027, 1702.1180281598574, 1706.1124356500247, 1686.6088847674034, 1680.8190888575048, 1677.8280310142575, 1680.4749249991305, 1677.51977099392, 1667.0016176415957, 1663.9077639485215, 1661.0689827437732, 1658.1404941609783, 1645.364680834793, 1649.7309046165994, 1636.7105268774028, 1641.9354067238562], 'acc': [0.836686077001171, 0.8587564778009535, 0.8777952104481257, 0.8889079675265334, 0.8978181692425995, 0.9043682661195459, 0.9084171567161958, 0.9125059907950644, 0.914587621310615, 0.9167786730730018, 0.9185953003730141, 0.9202143931282719, 0.9216690144525371, 0.922738383531281, 0.9239635366941936, 0.9253251374081435, 0.9267014291353044, 0.9275909961355403, 0.9289126745943403, 0.9297408196714811, 0.9304488650076498, 0.9314328135869031, 0.932460679114468, 0.9330989871851011, 0.9338099836868972, 0.9343402152696345, 0.9350775548052277, 0.9356726500631971, 0.9362571601055258, 0.9369002138492503, 0.9374808753274897, 0.9378357014160126, 0.9382270914926456, 0.9387182295684243, 0.939195300152021, 0.9397144581276798, 0.9400581156421123, 0.940427750409349, 0.9408505584054127, 0.9412071945116328, 0.9415836981654119, 0.9418041400946089, 0.9423714129850479, 0.9424845518635526, 0.9428481335391018, 0.9432387627217993, 0.9437168844553778, 0.9438684293009019, 0.9441311512095684, 0.9445341941510459, 0.9449392560762415, 0.9449660285722384, 0.9453670670271209, 0.9456149431579464, 0.945899372036184, 0.9462066321226326, 0.9463961384451761, 0.9466264832362333, 0.9469980018334754, 0.9471180506294818, 0.9473660424478331, 0.947659815795409, 0.9477284969418988, 0.9479551274541996, 0.9481723369591055, 0.9483482228363637, 0.9485387804294974, 0.9486658700513049, 0.9488812322222911, 0.9490110859220591, 0.9492524426893298, 0.949462649794254, 0.9496660121584267, 0.9496342959745555, 0.9498812581112104, 0.950034203123149, 0.9501414111344644, 0.9504586291525442, 0.9503898892697898, 0.9505564766536112, 0.9506106214067899, 0.95073893862859, 0.9509256806319564, 0.9508822151689287, 0.9510977334794801, 0.9510865456080543, 0.951300974463413, 0.9514648371840816, 0.9513686069926961, 0.9516618933720128, 0.9516390687248959, 0.9517029835019021, 0.9518643575417084, 0.95196338960971, 0.9520292113976457, 0.9520566839286067, 0.952088885633437, 0.9522896955390538, 0.9524200518861661, 0.9524168636527731, 0.9524851533769355, 0.9526153200071189, 0.9524961265172615, 0.9526091879169645, 0.9526560247209765, 0.9528370213286687, 0.953038477333197, 0.9530351877164281, 0.9529846192660577, 0.953111321035545, 0.9532487438497925, 0.9532460180770429, 0.9533117426546515, 0.9533045851523362, 0.9534325097939689, 0.953418132024755, 0.9536257302746605, 0.9535755919377749], 'mDice': [0.07291555966094938, 0.20420923150053685, 0.29368486092284546, 0.35777103145901173, 0.4052541154760525, 0.4391749733158183, 0.46580145287639163, 0.49074111369301654, 0.5059416757475167, 0.5220243479500218, 0.5393735955765931, 0.551532479444046, 0.5638450081171849, 0.5745279178210281, 0.587261638724336, 0.6002289215498537, 0.6105960434817534, 0.6178218302626399, 0.6276261002271584, 0.6347366659229268, 0.6408688474019884, 0.6456660392891295, 0.6536023571200816, 0.6580189584913837, 0.6618764361163857, 0.6669720212538104, 0.6723651610516865, 0.6766965140074865, 0.6796321762278706, 0.6848583537429415, 0.6884170639182045, 0.6904609206715657, 0.6944206664312325, 0.6975406323401661, 0.7016116404330764, 0.7038133225668688, 0.7080842369917866, 0.7110214568207207, 0.7133385578373191, 0.7160427540432147, 0.7199327012683061, 0.7212922445968403, 0.724815768975567, 0.7261645629887444, 0.7284294926218058, 0.7320702806362398, 0.7343325889192579, 0.7357130972106946, 0.7377884477943797, 0.7394692573601396, 0.7432460562269102, 0.7430176247184164, 0.7451447440949783, 0.7477749334033903, 0.748750216707147, 0.7501431742162176, 0.7526465442826129, 0.754439757353668, 0.7556254814048375, 0.7572222449720654, 0.7592036683566172, 0.7613889294228348, 0.7613772066051494, 0.7632259826146847, 0.7644563316816456, 0.7658674444857033, 0.7667469916098613, 0.7680228480150323, 0.7698525725372019, 0.7705726682633246, 0.7713864210500065, 0.7726740848916785, 0.7747060390485534, 0.7749720554224444, 0.7764309315438311, 0.7767179582052413, 0.7784211128552111, 0.7795494406727922, 0.7800257370231702, 0.7807615460870914, 0.7817950699311044, 0.7826019326524183, 0.783056483028486, 0.7841184964454014, 0.7853556568204801, 0.7854048889786162, 0.7868615434942627, 0.7869218951147705, 0.7867215594652933, 0.7893369248018531, 0.7896269110955965, 0.7901799940522601, 0.7916787177722303, 0.7922912588586503, 0.7928504854115046, 0.7932858288601699, 0.7938212373873234, 0.7948573459888074, 0.7958954181665353, 0.795556313134745, 0.7960792452350217, 0.797428677362838, 0.796950299215915, 0.7979369361310872, 0.7975302450042271, 0.7996105371048363, 0.800200518617163, 0.8005010513871462, 0.8001975684646458, 0.8004931805829488, 0.8016570783105277, 0.8020029514967696, 0.8023369367766217, 0.8026157741071916, 0.8039493999805396, 0.8034407711376405, 0.8048112991607802, 0.8042964288359564]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:43, 14.37s/it]predicting test subjects:  50%|█████     | 2/4 [00:27<00:27, 13.93s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:40<00:13, 13.84s/it]predicting test subjects: 100%|██████████| 4/4 [00:54<00:00, 13.65s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:20<1:46:18, 20.58s/it]predicting train subjects:   1%|          | 2/311 [00:30<1:29:30, 17.38s/it]predicting train subjects:   1%|          | 3/311 [00:42<1:21:31, 15.88s/it]predicting train subjects:   1%|▏         | 4/311 [00:54<1:15:23, 14.73s/it]predicting train subjects:   2%|▏         | 5/311 [01:05<1:09:03, 13.54s/it]predicting train subjects:   2%|▏         | 6/311 [01:16<1:05:05, 12.81s/it]predicting train subjects:   2%|▏         | 7/311 [01:29<1:04:33, 12.74s/it]predicting train subjects:   3%|▎         | 8/311 [01:44<1:07:41, 13.40s/it]predicting train subjects:   3%|▎         | 9/311 [01:57<1:07:51, 13.48s/it]predicting train subjects:   3%|▎         | 10/311 [02:08<1:03:50, 12.72s/it]predicting train subjects:   4%|▎         | 11/311 [02:23<1:06:34, 13.32s/it]predicting train subjects:   4%|▍         | 12/311 [02:34<1:02:50, 12.61s/it]predicting train subjects:   4%|▍         | 13/311 [02:45<1:00:19, 12.15s/it]predicting train subjects:   5%|▍         | 14/311 [03:00<1:03:34, 12.84s/it]predicting train subjects:   5%|▍         | 15/311 [03:21<1:15:51, 15.38s/it]predicting train subjects:   5%|▌         | 16/311 [03:41<1:23:08, 16.91s/it]predicting train subjects:   5%|▌         | 17/311 [04:02<1:28:41, 18.10s/it]predicting train subjects:   6%|▌         | 18/311 [04:24<1:33:05, 19.06s/it]predicting train subjects:   6%|▌         | 19/311 [04:44<1:34:39, 19.45s/it]predicting train subjects:   6%|▋         | 20/311 [05:05<1:36:52, 19.97s/it]predicting train subjects:   7%|▋         | 21/311 [05:27<1:38:47, 20.44s/it]predicting train subjects:   7%|▋         | 22/311 [05:48<1:39:05, 20.57s/it]predicting train subjects:   7%|▋         | 23/311 [06:09<1:39:54, 20.81s/it]predicting train subjects:   8%|▊         | 24/311 [06:29<1:38:06, 20.51s/it]predicting train subjects:   8%|▊         | 25/311 [06:49<1:37:36, 20.48s/it]predicting train subjects:   8%|▊         | 26/311 [07:10<1:37:39, 20.56s/it]predicting train subjects:   9%|▊         | 27/311 [07:31<1:38:42, 20.85s/it]predicting train subjects:   9%|▉         | 28/311 [07:52<1:38:35, 20.90s/it]predicting train subjects:   9%|▉         | 29/311 [08:14<1:38:30, 20.96s/it]predicting train subjects:  10%|▉         | 30/311 [08:35<1:38:31, 21.04s/it]predicting train subjects:  10%|▉         | 31/311 [08:56<1:38:28, 21.10s/it]predicting train subjects:  10%|█         | 32/311 [09:17<1:37:24, 20.95s/it]predicting train subjects:  11%|█         | 33/311 [09:27<1:22:05, 17.72s/it]predicting train subjects:  11%|█         | 34/311 [09:36<1:10:29, 15.27s/it]predicting train subjects:  11%|█▏        | 35/311 [09:46<1:02:58, 13.69s/it]predicting train subjects:  12%|█▏        | 36/311 [09:56<57:38, 12.58s/it]  predicting train subjects:  12%|█▏        | 37/311 [10:06<53:44, 11.77s/it]predicting train subjects:  12%|█▏        | 38/311 [10:16<50:48, 11.17s/it]predicting train subjects:  13%|█▎        | 39/311 [10:26<49:03, 10.82s/it]predicting train subjects:  13%|█▎        | 40/311 [10:36<47:27, 10.51s/it]predicting train subjects:  13%|█▎        | 41/311 [10:46<46:22, 10.31s/it]predicting train subjects:  14%|█▎        | 42/311 [10:56<45:44, 10.20s/it]predicting train subjects:  14%|█▍        | 43/311 [11:06<45:19, 10.15s/it]predicting train subjects:  14%|█▍        | 44/311 [11:15<44:05,  9.91s/it]predicting train subjects:  14%|█▍        | 45/311 [11:25<43:43,  9.86s/it]predicting train subjects:  15%|█▍        | 46/311 [11:34<43:27,  9.84s/it]predicting train subjects:  15%|█▌        | 47/311 [11:44<43:09,  9.81s/it]predicting train subjects:  15%|█▌        | 48/311 [11:54<43:30,  9.93s/it]predicting train subjects:  16%|█▌        | 49/311 [12:04<43:06,  9.87s/it]predicting train subjects:  16%|█▌        | 50/311 [12:14<42:52,  9.86s/it]predicting train subjects:  16%|█▋        | 51/311 [12:26<46:03, 10.63s/it]predicting train subjects:  17%|█▋        | 52/311 [12:39<47:50, 11.08s/it]predicting train subjects:  17%|█▋        | 53/311 [12:52<50:27, 11.73s/it]predicting train subjects:  17%|█▋        | 54/311 [13:05<52:45, 12.32s/it]predicting train subjects:  18%|█▊        | 55/311 [13:20<55:56, 13.11s/it]predicting train subjects:  18%|█▊        | 56/311 [13:34<56:09, 13.21s/it]predicting train subjects:  18%|█▊        | 57/311 [13:48<57:05, 13.49s/it]predicting train subjects:  19%|█▊        | 58/311 [14:02<57:36, 13.66s/it]predicting train subjects:  19%|█▉        | 59/311 [14:17<58:53, 14.02s/it]predicting train subjects:  19%|█▉        | 60/311 [14:31<58:46, 14.05s/it]predicting train subjects:  20%|█▉        | 61/311 [14:44<57:14, 13.74s/it]predicting train subjects:  20%|█▉        | 62/311 [14:58<56:58, 13.73s/it]predicting train subjects:  20%|██        | 63/311 [15:11<55:43, 13.48s/it]predicting train subjects:  21%|██        | 64/311 [15:24<55:43, 13.54s/it]predicting train subjects:  21%|██        | 65/311 [15:39<56:26, 13.77s/it]predicting train subjects:  21%|██        | 66/311 [15:52<55:41, 13.64s/it]predicting train subjects:  22%|██▏       | 67/311 [16:06<55:30, 13.65s/it]predicting train subjects:  22%|██▏       | 68/311 [16:20<55:47, 13.77s/it]predicting train subjects:  22%|██▏       | 69/311 [16:33<54:59, 13.63s/it]predicting train subjects:  23%|██▎       | 70/311 [16:47<54:36, 13.59s/it]predicting train subjects:  23%|██▎       | 71/311 [17:00<53:43, 13.43s/it]predicting train subjects:  23%|██▎       | 72/311 [17:14<54:34, 13.70s/it]predicting train subjects:  23%|██▎       | 73/311 [17:28<54:34, 13.76s/it]predicting train subjects:  24%|██▍       | 74/311 [17:40<52:45, 13.36s/it]predicting train subjects:  24%|██▍       | 75/311 [17:53<51:28, 13.09s/it]predicting train subjects:  24%|██▍       | 76/311 [18:05<50:34, 12.91s/it]predicting train subjects:  25%|██▍       | 77/311 [18:18<49:42, 12.75s/it]predicting train subjects:  25%|██▌       | 78/311 [18:30<48:43, 12.55s/it]predicting train subjects:  25%|██▌       | 79/311 [18:43<49:56, 12.92s/it]predicting train subjects:  26%|██▌       | 80/311 [18:58<51:24, 13.35s/it]predicting train subjects:  26%|██▌       | 81/311 [19:12<52:44, 13.76s/it]predicting train subjects:  26%|██▋       | 82/311 [19:26<51:48, 13.58s/it]predicting train subjects:  27%|██▋       | 83/311 [19:39<51:48, 13.63s/it]predicting train subjects:  27%|██▋       | 84/311 [19:52<50:22, 13.31s/it]predicting train subjects:  27%|██▋       | 85/311 [20:03<48:04, 12.77s/it]predicting train subjects:  28%|██▊       | 86/311 [20:14<45:45, 12.20s/it]predicting train subjects:  28%|██▊       | 87/311 [20:25<44:02, 11.80s/it]predicting train subjects:  28%|██▊       | 88/311 [20:36<42:21, 11.40s/it]predicting train subjects:  29%|██▊       | 89/311 [20:47<41:39, 11.26s/it]predicting train subjects:  29%|██▉       | 90/311 [20:58<41:22, 11.23s/it]predicting train subjects:  29%|██▉       | 91/311 [21:09<40:57, 11.17s/it]predicting train subjects:  30%|██▉       | 92/311 [21:20<40:24, 11.07s/it]predicting train subjects:  30%|██▉       | 93/311 [21:30<39:47, 10.95s/it]predicting train subjects:  30%|███       | 94/311 [21:41<39:50, 11.02s/it]predicting train subjects:  31%|███       | 95/311 [21:53<39:45, 11.05s/it]predicting train subjects:  31%|███       | 96/311 [22:03<39:22, 10.99s/it]predicting train subjects:  31%|███       | 97/311 [22:14<38:49, 10.89s/it]predicting train subjects:  32%|███▏      | 98/311 [22:25<38:50, 10.94s/it]predicting train subjects:  32%|███▏      | 99/311 [22:36<38:47, 10.98s/it]predicting train subjects:  32%|███▏      | 100/311 [22:47<37:53, 10.77s/it]predicting train subjects:  32%|███▏      | 101/311 [22:57<37:40, 10.76s/it]predicting train subjects:  33%|███▎      | 102/311 [23:09<38:00, 10.91s/it]predicting train subjects:  33%|███▎      | 103/311 [23:19<37:40, 10.87s/it]predicting train subjects:  33%|███▎      | 104/311 [23:30<37:43, 10.93s/it]predicting train subjects:  34%|███▍      | 105/311 [23:41<37:39, 10.97s/it]predicting train subjects:  34%|███▍      | 106/311 [23:53<37:43, 11.04s/it]predicting train subjects:  34%|███▍      | 107/311 [24:04<37:24, 11.00s/it]predicting train subjects:  35%|███▍      | 108/311 [24:14<37:02, 10.95s/it]predicting train subjects:  35%|███▌      | 109/311 [24:26<37:11, 11.05s/it]predicting train subjects:  35%|███▌      | 110/311 [24:37<37:08, 11.09s/it]predicting train subjects:  36%|███▌      | 111/311 [24:48<36:58, 11.09s/it]predicting train subjects:  36%|███▌      | 112/311 [24:59<36:15, 10.93s/it]predicting train subjects:  36%|███▋      | 113/311 [25:10<36:20, 11.01s/it]predicting train subjects:  37%|███▋      | 114/311 [25:31<46:09, 14.06s/it]predicting train subjects:  37%|███▋      | 115/311 [25:51<52:13, 15.99s/it]predicting train subjects:  37%|███▋      | 116/311 [26:13<57:10, 17.59s/it]predicting train subjects:  38%|███▊      | 117/311 [26:34<1:00:03, 18.57s/it]predicting train subjects:  38%|███▊      | 118/311 [26:55<1:02:08, 19.32s/it]predicting train subjects:  38%|███▊      | 119/311 [27:16<1:03:39, 19.89s/it]predicting train subjects:  39%|███▊      | 120/311 [27:37<1:04:59, 20.42s/it]predicting train subjects:  39%|███▉      | 121/311 [27:58<1:05:11, 20.59s/it]predicting train subjects:  39%|███▉      | 122/311 [28:19<1:04:42, 20.54s/it]predicting train subjects:  40%|███▉      | 123/311 [28:40<1:04:24, 20.56s/it]predicting train subjects:  40%|███▉      | 124/311 [29:00<1:04:05, 20.56s/it]predicting train subjects:  40%|████      | 125/311 [29:22<1:04:40, 20.86s/it]predicting train subjects:  41%|████      | 126/311 [29:43<1:04:29, 20.92s/it]predicting train subjects:  41%|████      | 127/311 [30:03<1:03:55, 20.84s/it]predicting train subjects:  41%|████      | 128/311 [30:25<1:04:01, 20.99s/it]predicting train subjects:  41%|████▏     | 129/311 [30:46<1:03:50, 21.05s/it]predicting train subjects:  42%|████▏     | 130/311 [31:07<1:03:09, 20.94s/it]predicting train subjects:  42%|████▏     | 131/311 [31:28<1:03:18, 21.10s/it]predicting train subjects:  42%|████▏     | 132/311 [31:38<52:50, 17.71s/it]  predicting train subjects:  43%|████▎     | 133/311 [31:47<45:10, 15.22s/it]predicting train subjects:  43%|████▎     | 134/311 [31:57<40:14, 13.64s/it]predicting train subjects:  43%|████▎     | 135/311 [32:07<36:49, 12.55s/it]predicting train subjects:  44%|████▎     | 136/311 [32:16<33:39, 11.54s/it]predicting train subjects:  44%|████▍     | 137/311 [32:26<32:02, 11.05s/it]predicting train subjects:  44%|████▍     | 138/311 [32:36<30:56, 10.73s/it]predicting train subjects:  45%|████▍     | 139/311 [32:46<29:39, 10.35s/it]predicting train subjects:  45%|████▌     | 140/311 [32:55<28:55, 10.15s/it]predicting train subjects:  45%|████▌     | 141/311 [33:05<28:35, 10.09s/it]predicting train subjects:  46%|████▌     | 142/311 [33:15<27:55,  9.92s/it]predicting train subjects:  46%|████▌     | 143/311 [33:24<27:29,  9.82s/it]predicting train subjects:  46%|████▋     | 144/311 [33:34<27:16,  9.80s/it]predicting train subjects:  47%|████▋     | 145/311 [33:43<26:38,  9.63s/it]predicting train subjects:  47%|████▋     | 146/311 [33:54<26:53,  9.78s/it]predicting train subjects:  47%|████▋     | 147/311 [34:03<26:41,  9.77s/it]predicting train subjects:  48%|████▊     | 148/311 [34:13<26:14,  9.66s/it]predicting train subjects:  48%|████▊     | 149/311 [34:23<26:33,  9.84s/it]predicting train subjects:  48%|████▊     | 150/311 [34:35<28:31, 10.63s/it]predicting train subjects:  49%|████▊     | 151/311 [34:48<30:03, 11.27s/it]predicting train subjects:  49%|████▉     | 152/311 [35:00<30:38, 11.56s/it]predicting train subjects:  49%|████▉     | 153/311 [35:13<31:00, 11.77s/it]predicting train subjects:  50%|████▉     | 154/311 [35:25<31:22, 11.99s/it]predicting train subjects:  50%|████▉     | 155/311 [35:38<31:30, 12.12s/it]predicting train subjects:  50%|█████     | 156/311 [35:50<31:43, 12.28s/it]predicting train subjects:  50%|█████     | 157/311 [36:03<31:40, 12.34s/it]predicting train subjects:  51%|█████     | 158/311 [36:15<31:34, 12.38s/it]predicting train subjects:  51%|█████     | 159/311 [36:27<31:12, 12.32s/it]predicting train subjects:  51%|█████▏    | 160/311 [36:40<30:52, 12.27s/it]predicting train subjects:  52%|█████▏    | 161/311 [36:52<30:47, 12.32s/it]predicting train subjects:  52%|█████▏    | 162/311 [37:05<30:45, 12.39s/it]predicting train subjects:  52%|█████▏    | 163/311 [37:18<31:10, 12.64s/it]predicting train subjects:  53%|█████▎    | 164/311 [37:30<30:52, 12.60s/it]predicting train subjects:  53%|█████▎    | 165/311 [37:43<30:43, 12.63s/it]predicting train subjects:  53%|█████▎    | 166/311 [37:55<30:05, 12.45s/it]predicting train subjects:  54%|█████▎    | 167/311 [38:07<29:16, 12.20s/it]predicting train subjects:  54%|█████▍    | 168/311 [38:18<28:48, 12.09s/it]predicting train subjects:  54%|█████▍    | 169/311 [38:31<28:37, 12.09s/it]predicting train subjects:  55%|█████▍    | 170/311 [38:43<28:59, 12.34s/it]predicting train subjects:  55%|█████▍    | 171/311 [38:55<28:24, 12.18s/it]predicting train subjects:  55%|█████▌    | 172/311 [39:07<28:03, 12.11s/it]predicting train subjects:  56%|█████▌    | 173/311 [39:19<27:48, 12.09s/it]predicting train subjects:  56%|█████▌    | 174/311 [39:31<27:39, 12.11s/it]predicting train subjects:  56%|█████▋    | 175/311 [39:43<27:21, 12.07s/it]predicting train subjects:  57%|█████▋    | 176/311 [39:56<27:12, 12.09s/it]predicting train subjects:  57%|█████▋    | 177/311 [40:07<26:29, 11.86s/it]predicting train subjects:  57%|█████▋    | 178/311 [40:18<26:00, 11.74s/it]predicting train subjects:  58%|█████▊    | 179/311 [40:30<25:52, 11.76s/it]predicting train subjects:  58%|█████▊    | 180/311 [40:42<25:48, 11.82s/it]predicting train subjects:  58%|█████▊    | 181/311 [40:54<25:20, 11.70s/it]predicting train subjects:  59%|█████▊    | 182/311 [41:05<25:13, 11.74s/it]predicting train subjects:  59%|█████▉    | 183/311 [41:17<25:02, 11.74s/it]predicting train subjects:  59%|█████▉    | 184/311 [41:28<24:00, 11.34s/it]predicting train subjects:  59%|█████▉    | 185/311 [41:38<23:22, 11.13s/it]predicting train subjects:  60%|█████▉    | 186/311 [41:49<23:10, 11.12s/it]predicting train subjects:  60%|██████    | 187/311 [42:00<22:48, 11.04s/it]predicting train subjects:  60%|██████    | 188/311 [42:11<22:26, 10.95s/it]predicting train subjects:  61%|██████    | 189/311 [42:22<22:08, 10.89s/it]predicting train subjects:  61%|██████    | 190/311 [42:32<21:56, 10.88s/it]predicting train subjects:  61%|██████▏   | 191/311 [42:43<21:33, 10.78s/it]predicting train subjects:  62%|██████▏   | 192/311 [42:53<21:11, 10.69s/it]predicting train subjects:  62%|██████▏   | 193/311 [43:04<21:11, 10.77s/it]predicting train subjects:  62%|██████▏   | 194/311 [43:15<21:09, 10.85s/it]predicting train subjects:  63%|██████▎   | 195/311 [43:26<20:50, 10.78s/it]predicting train subjects:  63%|██████▎   | 196/311 [43:37<20:48, 10.86s/it]predicting train subjects:  63%|██████▎   | 197/311 [43:48<20:42, 10.90s/it]predicting train subjects:  64%|██████▎   | 198/311 [43:59<20:20, 10.80s/it]predicting train subjects:  64%|██████▍   | 199/311 [44:09<20:04, 10.75s/it]predicting train subjects:  64%|██████▍   | 200/311 [44:21<20:11, 10.92s/it]predicting train subjects:  65%|██████▍   | 201/311 [44:32<20:11, 11.02s/it]predicting train subjects:  65%|██████▍   | 202/311 [44:42<19:43, 10.86s/it]predicting train subjects:  65%|██████▌   | 203/311 [44:53<19:40, 10.93s/it]predicting train subjects:  66%|██████▌   | 204/311 [45:04<19:30, 10.94s/it]predicting train subjects:  66%|██████▌   | 205/311 [45:16<19:37, 11.11s/it]predicting train subjects:  66%|██████▌   | 206/311 [45:27<19:20, 11.05s/it]predicting train subjects:  67%|██████▋   | 207/311 [45:38<19:10, 11.06s/it]predicting train subjects:  67%|██████▋   | 208/311 [45:49<19:03, 11.10s/it]predicting train subjects:  67%|██████▋   | 209/311 [46:00<18:49, 11.08s/it]predicting train subjects:  68%|██████▊   | 210/311 [46:11<18:27, 10.97s/it]predicting train subjects:  68%|██████▊   | 211/311 [46:22<18:15, 10.95s/it]predicting train subjects:  68%|██████▊   | 212/311 [46:33<18:11, 11.03s/it]predicting train subjects:  68%|██████▊   | 213/311 [46:54<22:49, 13.98s/it]predicting train subjects:  69%|██████▉   | 214/311 [47:15<25:57, 16.06s/it]predicting train subjects:  69%|██████▉   | 215/311 [47:35<27:48, 17.38s/it]predicting train subjects:  69%|██████▉   | 216/311 [47:56<28:57, 18.29s/it]predicting train subjects:  70%|██████▉   | 217/311 [48:16<29:38, 18.92s/it]predicting train subjects:  70%|███████   | 218/311 [48:36<29:47, 19.22s/it]predicting train subjects:  70%|███████   | 219/311 [48:57<30:06, 19.63s/it]predicting train subjects:  71%|███████   | 220/311 [49:17<30:13, 19.92s/it]predicting train subjects:  71%|███████   | 221/311 [49:37<29:57, 19.98s/it]predicting train subjects:  71%|███████▏  | 222/311 [49:58<29:45, 20.06s/it]predicting train subjects:  72%|███████▏  | 223/311 [50:18<29:42, 20.25s/it]predicting train subjects:  72%|███████▏  | 224/311 [50:38<29:20, 20.23s/it]predicting train subjects:  72%|███████▏  | 225/311 [50:59<29:11, 20.37s/it]predicting train subjects:  73%|███████▎  | 226/311 [51:20<28:58, 20.45s/it]predicting train subjects:  73%|███████▎  | 227/311 [51:41<28:53, 20.64s/it]predicting train subjects:  73%|███████▎  | 228/311 [52:02<28:43, 20.76s/it]predicting train subjects:  74%|███████▎  | 229/311 [52:24<28:47, 21.07s/it]predicting train subjects:  74%|███████▍  | 230/311 [52:45<28:23, 21.03s/it]predicting train subjects:  74%|███████▍  | 231/311 [52:55<23:46, 17.83s/it]predicting train subjects:  75%|███████▍  | 232/311 [53:05<20:12, 15.35s/it]predicting train subjects:  75%|███████▍  | 233/311 [53:15<17:59, 13.84s/it]predicting train subjects:  75%|███████▌  | 234/311 [53:25<16:27, 12.83s/it]predicting train subjects:  76%|███████▌  | 235/311 [53:35<15:05, 11.91s/it]predicting train subjects:  76%|███████▌  | 236/311 [53:45<14:18, 11.44s/it]predicting train subjects:  76%|███████▌  | 237/311 [53:55<13:32, 10.98s/it]predicting train subjects:  77%|███████▋  | 238/311 [54:05<12:53, 10.59s/it]predicting train subjects:  77%|███████▋  | 239/311 [54:15<12:33, 10.47s/it]predicting train subjects:  77%|███████▋  | 240/311 [54:25<12:05, 10.21s/it]predicting train subjects:  77%|███████▋  | 241/311 [54:35<11:55, 10.22s/it]predicting train subjects:  78%|███████▊  | 242/311 [54:45<11:39, 10.13s/it]predicting train subjects:  78%|███████▊  | 243/311 [54:55<11:24, 10.07s/it]predicting train subjects:  78%|███████▊  | 244/311 [55:05<11:21, 10.17s/it]predicting train subjects:  79%|███████▉  | 245/311 [55:15<11:11, 10.18s/it]predicting train subjects:  79%|███████▉  | 246/311 [55:25<10:50, 10.00s/it]predicting train subjects:  79%|███████▉  | 247/311 [55:35<10:45, 10.09s/it]predicting train subjects:  80%|███████▉  | 248/311 [55:45<10:29, 10.00s/it]predicting train subjects:  80%|████████  | 249/311 [55:58<11:06, 10.74s/it]predicting train subjects:  80%|████████  | 250/311 [56:10<11:26, 11.26s/it]predicting train subjects:  81%|████████  | 251/311 [56:23<11:42, 11.71s/it]predicting train subjects:  81%|████████  | 252/311 [56:35<11:44, 11.94s/it]predicting train subjects:  81%|████████▏ | 253/311 [56:48<11:45, 12.16s/it]predicting train subjects:  82%|████████▏ | 254/311 [57:01<11:40, 12.30s/it]predicting train subjects:  82%|████████▏ | 255/311 [57:13<11:36, 12.43s/it]predicting train subjects:  82%|████████▏ | 256/311 [57:28<11:57, 13.04s/it]predicting train subjects:  83%|████████▎ | 257/311 [57:44<12:31, 13.91s/it]predicting train subjects:  83%|████████▎ | 258/311 [57:58<12:19, 13.95s/it]predicting train subjects:  83%|████████▎ | 259/311 [58:11<11:49, 13.64s/it]predicting train subjects:  84%|████████▎ | 260/311 [58:23<11:19, 13.33s/it]predicting train subjects:  84%|████████▍ | 261/311 [58:36<10:58, 13.18s/it]predicting train subjects:  84%|████████▍ | 262/311 [58:49<10:42, 13.11s/it]predicting train subjects:  85%|████████▍ | 263/311 [59:02<10:26, 13.04s/it]predicting train subjects:  85%|████████▍ | 264/311 [59:15<10:13, 13.05s/it]predicting train subjects:  85%|████████▌ | 265/311 [59:27<09:45, 12.74s/it]predicting train subjects:  86%|████████▌ | 266/311 [59:39<09:26, 12.60s/it]predicting train subjects:  86%|████████▌ | 267/311 [59:51<09:08, 12.45s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:00:04<08:56, 12.49s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:00:16<08:38, 12.36s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:00:28<08:20, 12.20s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:00:40<08:05, 12.15s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:00:52<07:53, 12.14s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:01:05<07:45, 12.24s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:01:16<07:28, 12.11s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:01:28<07:15, 12.08s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:01:40<07:01, 12.04s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:01:52<06:49, 12.03s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:02:04<06:35, 11.99s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:02:16<06:22, 11.95s/it]predicting train subjects:  90%|█████████ | 280/311 [1:02:29<06:17, 12.16s/it]predicting train subjects:  90%|█████████ | 281/311 [1:02:41<06:04, 12.16s/it]predicting train subjects:  91%|█████████ | 282/311 [1:02:53<05:48, 12.01s/it]predicting train subjects:  91%|█████████ | 283/311 [1:03:03<05:25, 11.62s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:03:14<05:08, 11.44s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:03:25<04:49, 11.13s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:03:37<04:44, 11.39s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:03:50<04:45, 11.88s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:04:04<04:47, 12.49s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:04:17<04:42, 12.84s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:04:31<04:34, 13.08s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:04:45<04:24, 13.25s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:04:58<04:12, 13.31s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:05:11<03:58, 13.27s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:05:25<03:47, 13.35s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:05:38<03:34, 13.42s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:05:53<03:24, 13.66s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:06:06<03:08, 13.47s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:06:19<02:55, 13.54s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:06:33<02:42, 13.56s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:06:46<02:29, 13.57s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:07:00<02:15, 13.59s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:07:15<02:05, 13.90s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:07:28<01:49, 13.70s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:07:42<01:36, 13.78s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:07:55<01:21, 13.55s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:08:08<01:07, 13.48s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:08:22<00:54, 13.61s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:08:36<00:41, 13.74s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:08:49<00:26, 13.43s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:09:02<00:13, 13.38s/it]predicting train subjects: 100%|██████████| 311/311 [1:09:16<00:00, 13.54s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:18<1:34:55, 18.37s/it]Loading train:   1%|          | 2/311 [00:28<1:21:21, 15.80s/it]Loading train:   1%|          | 3/311 [00:38<1:12:54, 14.20s/it]Loading train:   1%|▏         | 4/311 [00:48<1:06:10, 12.93s/it]Loading train:   2%|▏         | 5/311 [00:57<1:00:08, 11.79s/it]Loading train:   2%|▏         | 6/311 [01:07<56:12, 11.06s/it]  Loading train:   2%|▏         | 7/311 [01:17<55:19, 10.92s/it]Loading train:   3%|▎         | 8/311 [01:30<58:07, 11.51s/it]Loading train:   3%|▎         | 9/311 [01:41<57:39, 11.46s/it]Loading train:   3%|▎         | 10/311 [01:51<54:51, 10.94s/it]Loading train:   4%|▎         | 11/311 [02:04<57:31, 11.51s/it]Loading train:   4%|▍         | 12/311 [02:14<54:41, 10.98s/it]Loading train:   4%|▍         | 13/311 [02:23<52:33, 10.58s/it]Loading train:   5%|▍         | 14/311 [02:36<54:53, 11.09s/it]Loading train:   5%|▍         | 15/311 [02:45<52:13, 10.59s/it]Loading train:   5%|▌         | 16/311 [02:54<50:17, 10.23s/it]Loading train:   5%|▌         | 17/311 [03:03<48:06,  9.82s/it]Loading train:   6%|▌         | 18/311 [03:12<46:39,  9.56s/it]Loading train:   6%|▌         | 19/311 [03:21<45:15,  9.30s/it]Loading train:   6%|▋         | 20/311 [03:30<44:55,  9.26s/it]Loading train:   7%|▋         | 21/311 [03:39<44:01,  9.11s/it]Loading train:   7%|▋         | 22/311 [03:48<44:08,  9.17s/it]Loading train:   7%|▋         | 23/311 [03:57<43:46,  9.12s/it]Loading train:   8%|▊         | 24/311 [04:07<44:08,  9.23s/it]Loading train:   8%|▊         | 25/311 [04:16<43:44,  9.18s/it]Loading train:   8%|▊         | 26/311 [04:25<43:43,  9.21s/it]Loading train:   9%|▊         | 27/311 [04:34<43:14,  9.14s/it]Loading train:   9%|▉         | 28/311 [04:43<42:52,  9.09s/it]Loading train:   9%|▉         | 29/311 [04:52<42:44,  9.09s/it]Loading train:  10%|▉         | 30/311 [05:01<42:37,  9.10s/it]Loading train:  10%|▉         | 31/311 [05:10<42:30,  9.11s/it]Loading train:  10%|█         | 32/311 [05:19<42:22,  9.11s/it]Loading train:  11%|█         | 33/311 [05:24<35:52,  7.74s/it]Loading train:  11%|█         | 34/311 [05:29<31:33,  6.83s/it]Loading train:  11%|█▏        | 35/311 [05:33<28:25,  6.18s/it]Loading train:  12%|█▏        | 36/311 [05:38<26:00,  5.67s/it]Loading train:  12%|█▏        | 37/311 [05:42<24:30,  5.37s/it]Loading train:  12%|█▏        | 38/311 [05:47<23:02,  5.07s/it]Loading train:  13%|█▎        | 39/311 [05:51<22:06,  4.88s/it]Loading train:  13%|█▎        | 40/311 [05:56<21:22,  4.73s/it]Loading train:  13%|█▎        | 41/311 [06:00<20:47,  4.62s/it]Loading train:  14%|█▎        | 42/311 [06:05<20:50,  4.65s/it]Loading train:  14%|█▍        | 43/311 [06:09<20:21,  4.56s/it]Loading train:  14%|█▍        | 44/311 [06:14<20:21,  4.58s/it]Loading train:  14%|█▍        | 45/311 [06:18<20:23,  4.60s/it]Loading train:  15%|█▍        | 46/311 [06:23<20:42,  4.69s/it]Loading train:  15%|█▌        | 47/311 [06:28<20:23,  4.63s/it]Loading train:  15%|█▌        | 48/311 [06:32<20:16,  4.63s/it]Loading train:  16%|█▌        | 49/311 [06:37<20:15,  4.64s/it]Loading train:  16%|█▌        | 50/311 [06:42<20:12,  4.64s/it]Loading train:  16%|█▋        | 51/311 [06:48<21:39,  5.00s/it]Loading train:  17%|█▋        | 52/311 [06:53<22:48,  5.29s/it]Loading train:  17%|█▋        | 53/311 [07:00<23:45,  5.53s/it]Loading train:  17%|█▋        | 54/311 [07:05<23:59,  5.60s/it]Loading train:  18%|█▊        | 55/311 [07:11<23:56,  5.61s/it]Loading train:  18%|█▊        | 56/311 [07:16<23:42,  5.58s/it]Loading train:  18%|█▊        | 57/311 [07:22<23:49,  5.63s/it]Loading train:  19%|█▊        | 58/311 [07:28<23:31,  5.58s/it]Loading train:  19%|█▉        | 59/311 [07:33<23:20,  5.56s/it]Loading train:  19%|█▉        | 60/311 [07:39<23:33,  5.63s/it]Loading train:  20%|█▉        | 61/311 [07:45<23:30,  5.64s/it]Loading train:  20%|█▉        | 62/311 [07:50<23:08,  5.58s/it]Loading train:  20%|██        | 63/311 [07:56<23:13,  5.62s/it]Loading train:  21%|██        | 64/311 [08:01<22:58,  5.58s/it]Loading train:  21%|██        | 65/311 [08:07<22:40,  5.53s/it]Loading train:  21%|██        | 66/311 [08:12<22:35,  5.53s/it]Loading train:  22%|██▏       | 67/311 [08:18<22:48,  5.61s/it]Loading train:  22%|██▏       | 68/311 [08:23<22:12,  5.48s/it]Loading train:  22%|██▏       | 69/311 [08:28<21:43,  5.39s/it]Loading train:  23%|██▎       | 70/311 [08:34<21:46,  5.42s/it]Loading train:  23%|██▎       | 71/311 [08:39<21:35,  5.40s/it]Loading train:  23%|██▎       | 72/311 [08:45<21:36,  5.42s/it]Loading train:  23%|██▎       | 73/311 [08:50<21:27,  5.41s/it]Loading train:  24%|██▍       | 74/311 [08:56<21:31,  5.45s/it]Loading train:  24%|██▍       | 75/311 [09:01<21:32,  5.48s/it]Loading train:  24%|██▍       | 76/311 [09:07<21:27,  5.48s/it]Loading train:  25%|██▍       | 77/311 [09:12<21:22,  5.48s/it]Loading train:  25%|██▌       | 78/311 [09:18<21:14,  5.47s/it]Loading train:  25%|██▌       | 79/311 [09:23<21:14,  5.49s/it]Loading train:  26%|██▌       | 80/311 [09:29<21:01,  5.46s/it]Loading train:  26%|██▌       | 81/311 [09:34<20:45,  5.42s/it]Loading train:  26%|██▋       | 82/311 [09:39<20:30,  5.37s/it]Loading train:  27%|██▋       | 83/311 [09:44<20:17,  5.34s/it]Loading train:  27%|██▋       | 84/311 [09:50<20:03,  5.30s/it]Loading train:  27%|██▋       | 85/311 [09:55<19:56,  5.30s/it]Loading train:  28%|██▊       | 86/311 [10:00<19:31,  5.20s/it]Loading train:  28%|██▊       | 87/311 [10:05<19:04,  5.11s/it]Loading train:  28%|██▊       | 88/311 [10:10<18:37,  5.01s/it]Loading train:  29%|██▊       | 89/311 [10:14<18:25,  4.98s/it]Loading train:  29%|██▉       | 90/311 [10:19<18:21,  4.98s/it]Loading train:  29%|██▉       | 91/311 [10:24<18:13,  4.97s/it]Loading train:  30%|██▉       | 92/311 [10:29<17:53,  4.90s/it]Loading train:  30%|██▉       | 93/311 [10:34<17:45,  4.89s/it]Loading train:  30%|███       | 94/311 [10:39<17:31,  4.84s/it]Loading train:  31%|███       | 95/311 [10:43<17:22,  4.83s/it]Loading train:  31%|███       | 96/311 [10:48<17:04,  4.77s/it]Loading train:  31%|███       | 97/311 [10:53<17:19,  4.86s/it]Loading train:  32%|███▏      | 98/311 [10:58<17:25,  4.91s/it]Loading train:  32%|███▏      | 99/311 [11:03<17:00,  4.81s/it]Loading train:  32%|███▏      | 100/311 [11:07<16:44,  4.76s/it]Loading train:  32%|███▏      | 101/311 [11:12<16:49,  4.81s/it]Loading train:  33%|███▎      | 102/311 [11:17<16:49,  4.83s/it]Loading train:  33%|███▎      | 103/311 [11:22<16:55,  4.88s/it]Loading train:  33%|███▎      | 104/311 [11:27<17:00,  4.93s/it]Loading train:  34%|███▍      | 105/311 [11:32<17:01,  4.96s/it]Loading train:  34%|███▍      | 106/311 [11:37<17:00,  4.98s/it]Loading train:  34%|███▍      | 107/311 [11:42<17:02,  5.01s/it]Loading train:  35%|███▍      | 108/311 [11:47<16:55,  5.00s/it]Loading train:  35%|███▌      | 109/311 [11:53<17:07,  5.09s/it]Loading train:  35%|███▌      | 110/311 [11:58<17:07,  5.11s/it]Loading train:  36%|███▌      | 111/311 [12:03<16:50,  5.05s/it]Loading train:  36%|███▌      | 112/311 [12:08<16:41,  5.03s/it]Loading train:  36%|███▋      | 113/311 [12:13<16:46,  5.08s/it]Loading train:  37%|███▋      | 114/311 [12:23<21:12,  6.46s/it]Loading train:  37%|███▋      | 115/311 [12:32<24:01,  7.36s/it]Loading train:  37%|███▋      | 116/311 [12:41<25:34,  7.87s/it]Loading train:  38%|███▊      | 117/311 [12:50<26:46,  8.28s/it]Loading train:  38%|███▊      | 118/311 [12:59<27:14,  8.47s/it]Loading train:  38%|███▊      | 119/311 [13:08<27:41,  8.65s/it]Loading train:  39%|███▊      | 120/311 [13:17<27:47,  8.73s/it]Loading train:  39%|███▉      | 121/311 [13:26<28:02,  8.85s/it]Loading train:  39%|███▉      | 122/311 [13:35<27:49,  8.83s/it]Loading train:  40%|███▉      | 123/311 [13:44<27:58,  8.93s/it]Loading train:  40%|███▉      | 124/311 [13:54<28:18,  9.08s/it]Loading train:  40%|████      | 125/311 [14:03<28:00,  9.03s/it]Loading train:  41%|████      | 126/311 [14:11<27:22,  8.88s/it]Loading train:  41%|████      | 127/311 [14:20<27:27,  8.95s/it]Loading train:  41%|████      | 128/311 [14:29<27:11,  8.91s/it]Loading train:  41%|████▏     | 129/311 [14:38<26:50,  8.85s/it]Loading train:  42%|████▏     | 130/311 [14:47<26:36,  8.82s/it]Loading train:  42%|████▏     | 131/311 [14:56<26:53,  8.96s/it]Loading train:  42%|████▏     | 132/311 [15:00<22:38,  7.59s/it]Loading train:  43%|████▎     | 133/311 [15:05<19:41,  6.63s/it]Loading train:  43%|████▎     | 134/311 [15:10<18:10,  6.16s/it]Loading train:  43%|████▎     | 135/311 [15:15<16:59,  5.79s/it]Loading train:  44%|████▎     | 136/311 [15:20<16:18,  5.59s/it]Loading train:  44%|████▍     | 137/311 [15:24<15:23,  5.30s/it]Loading train:  44%|████▍     | 138/311 [15:29<14:43,  5.11s/it]Loading train:  45%|████▍     | 139/311 [15:34<14:15,  4.98s/it]Loading train:  45%|████▌     | 140/311 [15:38<13:35,  4.77s/it]Loading train:  45%|████▌     | 141/311 [15:43<13:19,  4.71s/it]Loading train:  46%|████▌     | 142/311 [15:47<13:11,  4.68s/it]Loading train:  46%|████▌     | 143/311 [15:52<12:51,  4.59s/it]Loading train:  46%|████▋     | 144/311 [15:56<12:40,  4.56s/it]Loading train:  47%|████▋     | 145/311 [16:01<12:36,  4.56s/it]Loading train:  47%|████▋     | 146/311 [16:05<12:33,  4.57s/it]Loading train:  47%|████▋     | 147/311 [16:10<12:28,  4.56s/it]Loading train:  48%|████▊     | 148/311 [16:14<12:14,  4.50s/it]Loading train:  48%|████▊     | 149/311 [16:19<12:01,  4.45s/it]Loading train:  48%|████▊     | 150/311 [16:24<13:02,  4.86s/it]Loading train:  49%|████▊     | 151/311 [16:30<13:48,  5.18s/it]Loading train:  49%|████▉     | 152/311 [16:36<14:10,  5.35s/it]Loading train:  49%|████▉     | 153/311 [16:42<14:25,  5.48s/it]Loading train:  50%|████▉     | 154/311 [16:47<14:12,  5.43s/it]Loading train:  50%|████▉     | 155/311 [16:52<13:46,  5.30s/it]Loading train:  50%|█████     | 156/311 [16:58<13:55,  5.39s/it]Loading train:  50%|█████     | 157/311 [17:03<14:01,  5.46s/it]Loading train:  51%|█████     | 158/311 [17:09<13:51,  5.44s/it]Loading train:  51%|█████     | 159/311 [17:14<13:53,  5.48s/it]Loading train:  51%|█████▏    | 160/311 [17:20<13:56,  5.54s/it]Loading train:  52%|█████▏    | 161/311 [17:26<13:51,  5.54s/it]Loading train:  52%|█████▏    | 162/311 [17:31<13:48,  5.56s/it]Loading train:  52%|█████▏    | 163/311 [17:37<13:47,  5.59s/it]Loading train:  53%|█████▎    | 164/311 [17:42<13:30,  5.52s/it]Loading train:  53%|█████▎    | 165/311 [17:48<13:24,  5.51s/it]Loading train:  53%|█████▎    | 166/311 [17:53<13:14,  5.48s/it]Loading train:  54%|█████▎    | 167/311 [17:58<12:51,  5.36s/it]Loading train:  54%|█████▍    | 168/311 [18:03<12:31,  5.26s/it]Loading train:  54%|█████▍    | 169/311 [18:08<12:27,  5.26s/it]Loading train:  55%|█████▍    | 170/311 [18:14<12:26,  5.29s/it]Loading train:  55%|█████▍    | 171/311 [18:19<12:18,  5.28s/it]Loading train:  55%|█████▌    | 172/311 [18:24<12:19,  5.32s/it]Loading train:  56%|█████▌    | 173/311 [18:30<12:23,  5.39s/it]Loading train:  56%|█████▌    | 174/311 [18:36<12:24,  5.43s/it]Loading train:  56%|█████▋    | 175/311 [18:41<12:17,  5.43s/it]Loading train:  57%|█████▋    | 176/311 [18:46<12:18,  5.47s/it]Loading train:  57%|█████▋    | 177/311 [18:52<12:12,  5.47s/it]Loading train:  57%|█████▋    | 178/311 [18:58<12:28,  5.63s/it]Loading train:  58%|█████▊    | 179/311 [19:04<12:28,  5.67s/it]Loading train:  58%|█████▊    | 180/311 [19:09<12:13,  5.60s/it]Loading train:  58%|█████▊    | 181/311 [19:14<11:57,  5.52s/it]Loading train:  59%|█████▊    | 182/311 [19:20<11:47,  5.49s/it]Loading train:  59%|█████▉    | 183/311 [19:25<11:43,  5.49s/it]Loading train:  59%|█████▉    | 184/311 [19:30<11:14,  5.31s/it]Loading train:  59%|█████▉    | 185/311 [19:35<10:50,  5.17s/it]Loading train:  60%|█████▉    | 186/311 [19:40<10:47,  5.18s/it]Loading train:  60%|██████    | 187/311 [19:45<10:39,  5.16s/it]Loading train:  60%|██████    | 188/311 [19:50<10:25,  5.09s/it]Loading train:  61%|██████    | 189/311 [19:56<10:24,  5.12s/it]Loading train:  61%|██████    | 190/311 [20:01<10:17,  5.10s/it]Loading train:  61%|██████▏   | 191/311 [20:05<10:01,  5.01s/it]Loading train:  62%|██████▏   | 192/311 [20:10<09:53,  4.99s/it]Loading train:  62%|██████▏   | 193/311 [20:16<09:59,  5.08s/it]Loading train:  62%|██████▏   | 194/311 [20:21<09:52,  5.06s/it]Loading train:  63%|██████▎   | 195/311 [20:26<09:44,  5.04s/it]Loading train:  63%|██████▎   | 196/311 [20:31<09:41,  5.06s/it]Loading train:  63%|██████▎   | 197/311 [20:36<09:33,  5.03s/it]Loading train:  64%|██████▎   | 198/311 [20:41<09:23,  4.99s/it]Loading train:  64%|██████▍   | 199/311 [20:46<09:16,  4.97s/it]Loading train:  64%|██████▍   | 200/311 [20:51<09:11,  4.97s/it]Loading train:  65%|██████▍   | 201/311 [20:56<09:07,  4.98s/it]Loading train:  65%|██████▍   | 202/311 [21:01<09:13,  5.08s/it]Loading train:  65%|██████▌   | 203/311 [21:06<09:13,  5.12s/it]Loading train:  66%|██████▌   | 204/311 [21:11<09:14,  5.18s/it]Loading train:  66%|██████▌   | 205/311 [21:16<09:02,  5.12s/it]Loading train:  66%|██████▌   | 206/311 [21:22<09:05,  5.19s/it]Loading train:  67%|██████▋   | 207/311 [21:27<08:59,  5.19s/it]Loading train:  67%|██████▋   | 208/311 [21:32<08:53,  5.18s/it]Loading train:  67%|██████▋   | 209/311 [21:37<08:54,  5.24s/it]Loading train:  68%|██████▊   | 210/311 [21:42<08:36,  5.11s/it]Loading train:  68%|██████▊   | 211/311 [21:47<08:16,  4.96s/it]Loading train:  68%|██████▊   | 212/311 [21:52<08:09,  4.95s/it]Loading train:  68%|██████▊   | 213/311 [22:01<10:11,  6.24s/it]Loading train:  69%|██████▉   | 214/311 [22:10<11:29,  7.11s/it]Loading train:  69%|██████▉   | 215/311 [22:19<12:14,  7.65s/it]Loading train:  69%|██████▉   | 216/311 [22:28<12:51,  8.12s/it]Loading train:  70%|██████▉   | 217/311 [22:37<13:00,  8.30s/it]Loading train:  70%|███████   | 218/311 [22:46<13:13,  8.53s/it]Loading train:  70%|███████   | 219/311 [22:55<13:13,  8.63s/it]Loading train:  71%|███████   | 220/311 [23:04<13:22,  8.82s/it]Loading train:  71%|███████   | 221/311 [23:13<13:15,  8.84s/it]Loading train:  71%|███████▏  | 222/311 [23:22<13:05,  8.83s/it]Loading train:  72%|███████▏  | 223/311 [23:30<12:49,  8.74s/it]Loading train:  72%|███████▏  | 224/311 [23:39<12:45,  8.80s/it]Loading train:  72%|███████▏  | 225/311 [23:48<12:38,  8.82s/it]Loading train:  73%|███████▎  | 226/311 [23:57<12:27,  8.80s/it]Loading train:  73%|███████▎  | 227/311 [24:06<12:26,  8.89s/it]Loading train:  73%|███████▎  | 228/311 [24:15<12:17,  8.88s/it]Loading train:  74%|███████▎  | 229/311 [24:24<12:21,  9.05s/it]Loading train:  74%|███████▍  | 230/311 [24:33<12:13,  9.05s/it]Loading train:  74%|███████▍  | 231/311 [24:38<10:20,  7.76s/it]Loading train:  75%|███████▍  | 232/311 [24:43<08:59,  6.83s/it]Loading train:  75%|███████▍  | 233/311 [24:47<07:59,  6.15s/it]Loading train:  75%|███████▌  | 234/311 [24:52<07:21,  5.73s/it]Loading train:  76%|███████▌  | 235/311 [24:57<06:48,  5.38s/it]Loading train:  76%|███████▌  | 236/311 [25:01<06:22,  5.10s/it]Loading train:  76%|███████▌  | 237/311 [25:06<06:13,  5.05s/it]Loading train:  77%|███████▋  | 238/311 [25:11<06:01,  4.95s/it]Loading train:  77%|███████▋  | 239/311 [25:15<05:46,  4.81s/it]Loading train:  77%|███████▋  | 240/311 [25:20<05:33,  4.70s/it]Loading train:  77%|███████▋  | 241/311 [25:24<05:29,  4.71s/it]Loading train:  78%|███████▊  | 242/311 [25:29<05:24,  4.71s/it]Loading train:  78%|███████▊  | 243/311 [25:34<05:19,  4.69s/it]Loading train:  78%|███████▊  | 244/311 [25:39<05:16,  4.72s/it]Loading train:  79%|███████▉  | 245/311 [25:43<05:11,  4.72s/it]Loading train:  79%|███████▉  | 246/311 [25:48<05:04,  4.69s/it]Loading train:  79%|███████▉  | 247/311 [25:53<04:59,  4.68s/it]Loading train:  80%|███████▉  | 248/311 [25:57<04:54,  4.68s/it]Loading train:  80%|████████  | 249/311 [26:03<05:03,  4.89s/it]Loading train:  80%|████████  | 250/311 [26:08<05:10,  5.09s/it]Loading train:  81%|████████  | 251/311 [26:14<05:15,  5.26s/it]Loading train:  81%|████████  | 252/311 [26:20<05:22,  5.46s/it]Loading train:  81%|████████▏ | 253/311 [26:25<05:18,  5.49s/it]Loading train:  82%|████████▏ | 254/311 [26:31<05:18,  5.58s/it]Loading train:  82%|████████▏ | 255/311 [26:37<05:17,  5.66s/it]Loading train:  82%|████████▏ | 256/311 [26:43<05:09,  5.62s/it]Loading train:  83%|████████▎ | 257/311 [26:49<05:10,  5.76s/it]Loading train:  83%|████████▎ | 258/311 [26:54<04:57,  5.61s/it]Loading train:  83%|████████▎ | 259/311 [27:00<04:52,  5.63s/it]Loading train:  84%|████████▎ | 260/311 [27:05<04:51,  5.72s/it]Loading train:  84%|████████▍ | 261/311 [27:11<04:41,  5.62s/it]Loading train:  84%|████████▍ | 262/311 [27:17<04:37,  5.65s/it]Loading train:  85%|████████▍ | 263/311 [27:22<04:33,  5.70s/it]Loading train:  85%|████████▍ | 264/311 [27:28<04:22,  5.59s/it]Loading train:  85%|████████▌ | 265/311 [27:33<04:17,  5.60s/it]Loading train:  86%|████████▌ | 266/311 [27:39<04:19,  5.76s/it]Loading train:  86%|████████▌ | 267/311 [27:45<04:14,  5.79s/it]Loading train:  86%|████████▌ | 268/311 [27:51<04:10,  5.82s/it]Loading train:  86%|████████▋ | 269/311 [27:57<04:01,  5.75s/it]Loading train:  87%|████████▋ | 270/311 [28:02<03:49,  5.60s/it]Loading train:  87%|████████▋ | 271/311 [28:08<03:44,  5.62s/it]Loading train:  87%|████████▋ | 272/311 [28:13<03:35,  5.54s/it]Loading train:  88%|████████▊ | 273/311 [28:19<03:29,  5.51s/it]Loading train:  88%|████████▊ | 274/311 [28:24<03:25,  5.57s/it]Loading train:  88%|████████▊ | 275/311 [28:30<03:19,  5.53s/it]Loading train:  89%|████████▊ | 276/311 [28:35<03:12,  5.51s/it]Loading train:  89%|████████▉ | 277/311 [28:41<03:07,  5.51s/it]Loading train:  89%|████████▉ | 278/311 [28:46<02:58,  5.42s/it]Loading train:  90%|████████▉ | 279/311 [28:51<02:50,  5.34s/it]Loading train:  90%|█████████ | 280/311 [28:57<02:48,  5.45s/it]Loading train:  90%|█████████ | 281/311 [29:02<02:43,  5.44s/it]Loading train:  91%|█████████ | 282/311 [29:07<02:35,  5.37s/it]Loading train:  91%|█████████ | 283/311 [29:12<02:28,  5.29s/it]Loading train:  91%|█████████▏| 284/311 [29:18<02:21,  5.25s/it]Loading train:  92%|█████████▏| 285/311 [29:22<02:13,  5.14s/it]Loading train:  92%|█████████▏| 286/311 [29:27<02:07,  5.10s/it]Loading train:  92%|█████████▏| 287/311 [29:33<02:03,  5.13s/it]Loading train:  93%|█████████▎| 288/311 [29:38<01:56,  5.06s/it]Loading train:  93%|█████████▎| 289/311 [29:43<01:51,  5.05s/it]Loading train:  93%|█████████▎| 290/311 [29:48<01:47,  5.10s/it]Loading train:  94%|█████████▎| 291/311 [29:53<01:41,  5.09s/it]Loading train:  94%|█████████▍| 292/311 [29:58<01:34,  5.00s/it]Loading train:  94%|█████████▍| 293/311 [30:03<01:30,  5.05s/it]Loading train:  95%|█████████▍| 294/311 [30:08<01:26,  5.10s/it]Loading train:  95%|█████████▍| 295/311 [30:13<01:20,  5.05s/it]Loading train:  95%|█████████▌| 296/311 [30:18<01:16,  5.10s/it]Loading train:  95%|█████████▌| 297/311 [30:23<01:12,  5.16s/it]Loading train:  96%|█████████▌| 298/311 [30:29<01:06,  5.13s/it]Loading train:  96%|█████████▌| 299/311 [30:34<01:01,  5.16s/it]Loading train:  96%|█████████▋| 300/311 [30:39<00:56,  5.10s/it]Loading train:  97%|█████████▋| 301/311 [30:43<00:49,  4.97s/it]Loading train:  97%|█████████▋| 302/311 [30:48<00:44,  4.98s/it]Loading train:  97%|█████████▋| 303/311 [30:54<00:40,  5.06s/it]Loading train:  98%|█████████▊| 304/311 [30:59<00:35,  5.01s/it]Loading train:  98%|█████████▊| 305/311 [31:04<00:30,  5.05s/it]Loading train:  98%|█████████▊| 306/311 [31:09<00:25,  5.12s/it]Loading train:  99%|█████████▊| 307/311 [31:14<00:20,  5.16s/it]Loading train:  99%|█████████▉| 308/311 [31:19<00:15,  5.10s/it]Loading train:  99%|█████████▉| 309/311 [31:24<00:10,  5.14s/it]Loading train: 100%|█████████▉| 310/311 [31:30<00:05,  5.15s/it]Loading train: 100%|██████████| 311/311 [31:35<00:00,  5.20s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/311 [00:00<00:04, 63.37it/s]concatenating: train:   5%|▍         | 14/311 [00:00<00:04, 63.10it/s]concatenating: train:   6%|▌         | 19/311 [00:00<00:04, 58.50it/s]concatenating: train:   7%|▋         | 23/311 [00:00<00:05, 49.10it/s]concatenating: train:   9%|▊         | 27/311 [00:00<00:06, 45.34it/s]concatenating: train:  11%|█         | 34/311 [00:00<00:05, 48.99it/s]concatenating: train:  13%|█▎        | 40/311 [00:00<00:05, 49.78it/s]concatenating: train:  16%|█▌        | 49/311 [00:00<00:04, 56.98it/s]concatenating: train:  18%|█▊        | 56/311 [00:00<00:04, 58.63it/s]concatenating: train:  22%|██▏       | 68/311 [00:01<00:03, 69.18it/s]concatenating: train:  30%|███       | 94/311 [00:01<00:02, 88.67it/s]concatenating: train:  41%|████      | 127/311 [00:01<00:01, 113.39it/s]concatenating: train:  47%|████▋     | 146/311 [00:01<00:01, 106.95it/s]concatenating: train:  52%|█████▏    | 163/311 [00:01<00:01, 103.53it/s]concatenating: train:  57%|█████▋    | 178/311 [00:01<00:01, 107.28it/s]concatenating: train:  62%|██████▏   | 192/311 [00:01<00:01, 113.10it/s]concatenating: train:  66%|██████▌   | 206/311 [00:02<00:00, 116.47it/s]concatenating: train:  71%|███████   | 220/311 [00:02<00:00, 118.91it/s]concatenating: train:  75%|███████▍  | 233/311 [00:02<00:00, 120.66it/s]concatenating: train:  79%|███████▉  | 246/311 [00:02<00:00, 120.70it/s]concatenating: train:  83%|████████▎ | 259/311 [00:02<00:00, 119.14it/s]concatenating: train:  87%|████████▋ | 272/311 [00:02<00:00, 119.52it/s]concatenating: train:  92%|█████████▏| 285/311 [00:02<00:00, 113.48it/s]concatenating: train:  95%|█████████▌| 297/311 [00:02<00:00, 102.51it/s]concatenating: train:  99%|█████████▉| 308/311 [00:03<00:00, 81.41it/s] concatenating: train: 100%|██████████| 311/311 [00:03<00:00, 100.11it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 11.93s/it]Loading test:  50%|█████     | 2/4 [00:23<00:23, 11.71s/it]Loading test:  75%|███████▌  | 3/4 [00:35<00:11, 11.77s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.66s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 46.69it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 40)   160         conv2d_7[0][0]                   2019-07-07 21:07:55.538908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 21:07:55.539009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 21:07:55.539026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 21:07:55.539037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 21:07:55.598583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [5.86066190e-02 2.84688586e-02 1.21642213e-01 1.04576120e-02
 3.14646619e-02 5.44310893e-03 7.20519791e-02 1.12887958e-01
 7.85252165e-02 1.27448500e-02 2.91951514e-01 1.75516909e-01
 2.38500254e-04]
Train on 12832 samples, validate on 168 samples
Epoch 1/300
 - 23s - loss: 15254.6004 - acc: 0.8693 - mDice: 0.1572 - val_loss: 8293.6316 - val_acc: 0.9073 - val_mDice: 0.2914

Epoch 00001: val_mDice improved from -inf to 0.29145, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 13s - loss: 5894.7875 - acc: 0.8988 - mDice: 0.3506 - val_loss: 4201.0891 - val_acc: 0.9109 - val_mDice: 0.4212

Epoch 00002: val_mDice improved from 0.29145 to 0.42120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 4354.5981 - acc: 0.9070 - mDice: 0.4427 - val_loss: 3203.3208 - val_acc: 0.9086 - val_mDice: 0.4995

Epoch 00003: val_mDice improved from 0.42120 to 0.49954, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 3508.4881 - acc: 0.9136 - mDice: 0.5086 - val_loss: 2870.3019 - val_acc: 0.9160 - val_mDice: 0.5391

Epoch 00004: val_mDice improved from 0.49954 to 0.53913, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 13s - loss: 3041.7127 - acc: 0.9195 - mDice: 0.5534 - val_loss: 2561.6460 - val_acc: 0.9267 - val_mDice: 0.5757

Epoch 00005: val_mDice improved from 0.53913 to 0.57571, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 13s - loss: 2763.0068 - acc: 0.9244 - mDice: 0.5830 - val_loss: 2506.0021 - val_acc: 0.9279 - val_mDice: 0.5864

Epoch 00006: val_mDice improved from 0.57571 to 0.58639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 13s - loss: 2532.3444 - acc: 0.9280 - mDice: 0.6073 - val_loss: 2147.8598 - val_acc: 0.9348 - val_mDice: 0.6200

Epoch 00007: val_mDice improved from 0.58639 to 0.61999, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 13s - loss: 2294.4345 - acc: 0.9311 - mDice: 0.6323 - val_loss: 2048.0113 - val_acc: 0.9369 - val_mDice: 0.6311

Epoch 00008: val_mDice improved from 0.61999 to 0.63111, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 13s - loss: 2145.7014 - acc: 0.9336 - mDice: 0.6494 - val_loss: 1986.2879 - val_acc: 0.9375 - val_mDice: 0.6389

Epoch 00009: val_mDice improved from 0.63111 to 0.63887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 14s - loss: 2033.5865 - acc: 0.9356 - mDice: 0.6634 - val_loss: 1865.7609 - val_acc: 0.9415 - val_mDice: 0.6560

Epoch 00010: val_mDice improved from 0.63887 to 0.65601, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 13s - loss: 1936.1940 - acc: 0.9377 - mDice: 0.6760 - val_loss: 1828.5160 - val_acc: 0.9439 - val_mDice: 0.6614

Epoch 00011: val_mDice improved from 0.65601 to 0.66136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 14s - loss: 1865.5488 - acc: 0.9391 - mDice: 0.6854 - val_loss: 1822.2324 - val_acc: 0.9435 - val_mDice: 0.6625

Epoch 00012: val_mDice improved from 0.66136 to 0.66253, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 12s - loss: 1806.7650 - acc: 0.9405 - mDice: 0.6935 - val_loss: 1826.7922 - val_acc: 0.9439 - val_mDice: 0.6633

Epoch 00013: val_mDice improved from 0.66253 to 0.66334, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 13s - loss: 1758.2901 - acc: 0.9415 - mDice: 0.7001 - val_loss: 1760.2409 - val_acc: 0.9460 - val_mDice: 0.6719

Epoch 00014: val_mDice improved from 0.66334 to 0.67192, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 12s - loss: 1711.7762 - acc: 0.9423 - mDice: 0.7067 - val_loss: 1771.1969 - val_acc: 0.9437 - val_mDice: 0.6682

Epoch 00015: val_mDice did not improve from 0.67192
Epoch 16/300
 - 13s - loss: 1667.8579 - acc: 0.9433 - mDice: 0.7128 - val_loss: 1724.0721 - val_acc: 0.9468 - val_mDice: 0.6778

Epoch 00016: val_mDice improved from 0.67192 to 0.67783, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 13s - loss: 1632.3953 - acc: 0.9440 - mDice: 0.7179 - val_loss: 1709.2819 - val_acc: 0.9489 - val_mDice: 0.6794

Epoch 00017: val_mDice improved from 0.67783 to 0.67938, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 14s - loss: 1597.4274 - acc: 0.9448 - mDice: 0.7230 - val_loss: 1707.8355 - val_acc: 0.9467 - val_mDice: 0.6797

Epoch 00018: val_mDice improved from 0.67938 to 0.67973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 14s - loss: 1562.4147 - acc: 0.9454 - mDice: 0.7280 - val_loss: 1698.6762 - val_acc: 0.9482 - val_mDice: 0.6816

Epoch 00019: val_mDice improved from 0.67973 to 0.68157, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 16s - loss: 1535.1524 - acc: 0.9459 - mDice: 0.7319 - val_loss: 1665.6740 - val_acc: 0.9483 - val_mDice: 0.6874

Epoch 00020: val_mDice improved from 0.68157 to 0.68742, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 13s - loss: 1505.0960 - acc: 0.9466 - mDice: 0.7364 - val_loss: 1707.8760 - val_acc: 0.9467 - val_mDice: 0.6771

Epoch 00021: val_mDice did not improve from 0.68742
Epoch 22/300
 - 14s - loss: 1471.9184 - acc: 0.9471 - mDice: 0.7412 - val_loss: 1670.0643 - val_acc: 0.9514 - val_mDice: 0.6865

Epoch 00022: val_mDice did not improve from 0.68742
Epoch 23/300
 - 13s - loss: 1447.2166 - acc: 0.9477 - mDice: 0.7449 - val_loss: 1709.3213 - val_acc: 0.9468 - val_mDice: 0.6792

Epoch 00023: val_mDice did not improve from 0.68742
Epoch 24/300
 - 14s - loss: 1423.9117 - acc: 0.9482 - mDice: 0.7484 - val_loss: 1668.3928 - val_acc: 0.9502 - val_mDice: 0.6855

Epoch 00024: val_mDice did not improve from 0.68742
Epoch 25/300
 - 14s - loss: 1404.4624 - acc: 0.9486 - mDice: 0.7514 - val_loss: 1640.4876 - val_acc: 0.9510 - val_mDice: 0.6907

Epoch 00025: val_mDice improved from 0.68742 to 0.69067, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 13s - loss: 1377.0511 - acc: 0.9490 - mDice: 0.7554 - val_loss: 1641.8688 - val_acc: 0.9510 - val_mDice: 0.6908

Epoch 00026: val_mDice improved from 0.69067 to 0.69082, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 27/300
 - 13s - loss: 1356.0373 - acc: 0.9493 - mDice: 0.7587 - val_loss: 1635.7527 - val_acc: 0.9512 - val_mDice: 0.6907

Epoch 00027: val_mDice did not improve from 0.69082
Epoch 28/300
 - 13s - loss: 1339.4087 - acc: 0.9498 - mDice: 0.7612 - val_loss: 1651.4547 - val_acc: 0.9505 - val_mDice: 0.6893

Epoch 00028: val_mDice did not improve from 0.69082
Epoch 29/300
 - 13s - loss: 1318.9929 - acc: 0.9502 - mDice: 0.7644 - val_loss: 1704.1135 - val_acc: 0.9530 - val_mDice: 0.6820

Epoch 00029: val_mDice did not improve from 0.69082
Epoch 30/300
 - 14s - loss: 1297.5301 - acc: 0.9505 - mDice: 0.7676 - val_loss: 1658.7960 - val_acc: 0.9531 - val_mDice: 0.6894

Epoch 00030: val_mDice did not improve from 0.69082
Epoch 31/300
 - 14s - loss: 1282.8305 - acc: 0.9509 - mDice: 0.7700 - val_loss: 1696.9367 - val_acc: 0.9538 - val_mDice: 0.6822

Epoch 00031: val_mDice did not improve from 0.69082
Epoch 32/300
 - 16s - loss: 1271.4440 - acc: 0.9510 - mDice: 0.7717 - val_loss: 1612.5410 - val_acc: 0.9530 - val_mDice: 0.6951

Epoch 00032: val_mDice improved from 0.69082 to 0.69505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 15s - loss: 1253.3933 - acc: 0.9514 - mDice: 0.7745 - val_loss: 1624.6213 - val_acc: 0.9528 - val_mDice: 0.6940

Epoch 00033: val_mDice did not improve from 0.69505
Epoch 34/300
 - 13s - loss: 1241.9297 - acc: 0.9515 - mDice: 0.7763 - val_loss: 1693.8908 - val_acc: 0.9536 - val_mDice: 0.6856

Epoch 00034: val_mDice did not improve from 0.69505
Epoch 35/300
 - 14s - loss: 1230.1301 - acc: 0.9517 - mDice: 0.7781 - val_loss: 1732.4482 - val_acc: 0.9534 - val_mDice: 0.6766

Epoch 00035: val_mDice did not improve from 0.69505
Epoch 36/300
 - 13s - loss: 1216.0177 - acc: 0.9522 - mDice: 0.7804 - val_loss: 1769.4255 - val_acc: 0.9545 - val_mDice: 0.6728

Epoch 00036: val_mDice did not improve from 0.69505
Epoch 37/300
 - 14s - loss: 1200.2470 - acc: 0.9523 - mDice: 0.7828 - val_loss: 1701.3906 - val_acc: 0.9530 - val_mDice: 0.6827

Epoch 00037: val_mDice did not improve from 0.69505
Epoch 38/300
 - 13s - loss: 1185.3157 - acc: 0.9527 - mDice: 0.7852 - val_loss: 1640.8424 - val_acc: 0.9556 - val_mDice: 0.6919

Epoch 00038: val_mDice did not improve from 0.69505
Epoch 39/300
 - 15s - loss: 1176.3641 - acc: 0.9529 - mDice: 0.7866 - val_loss: 1748.6506 - val_acc: 0.9532 - val_mDice: 0.6760

Epoch 00039: val_mDice did not improve from 0.69505
Epoch 40/300
 - 13s - loss: 1157.3148 - acc: 0.9531 - mDice: 0.7896 - val_loss: 1663.8314 - val_acc: 0.9520 - val_mDice: 0.6880

Epoch 00040: val_mDice did not improve from 0.69505
Epoch 41/300
 - 14s - loss: 1148.0663 - acc: 0.9532 - mDice: 0.7910 - val_loss: 1658.7651 - val_acc: 0.9562 - val_mDice: 0.6900

Epoch 00041: val_mDice did not improve from 0.69505
Epoch 42/300
 - 14s - loss: 1134.1680 - acc: 0.9534 - mDice: 0.7933 - val_loss: 1685.2632 - val_acc: 0.9548 - val_mDice: 0.6862

Epoch 00042: val_mDice did not improve from 0.69505
Epoch 43/300
 - 14s - loss: 1129.5999 - acc: 0.9537 - mDice: 0.7940 - val_loss: 1726.8742 - val_acc: 0.9552 - val_mDice: 0.6781

Epoch 00043: val_mDice did not improve from 0.69505
Epoch 44/300
 - 14s - loss: 1120.8645 - acc: 0.9539 - mDice: 0.7955 - val_loss: 1597.0725 - val_acc: 0.9577 - val_mDice: 0.6983

Epoch 00044: val_mDice improved from 0.69505 to 0.69826, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 13s - loss: 1107.8069 - acc: 0.9540 - mDice: 0.7975 - val_loss: 1659.9713 - val_acc: 0.9532 - val_mDice: 0.6877

Epoch 00045: val_mDice did not improve from 0.69826
Epoch 46/300
 - 14s - loss: 1101.7954 - acc: 0.9542 - mDice: 0.7985 - val_loss: 1573.0013 - val_acc: 0.9574 - val_mDice: 0.7006

Epoch 00046: val_mDice improved from 0.69826 to 0.70058, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 47/300
 - 13s - loss: 1090.9792 - acc: 0.9543 - mDice: 0.8003 - val_loss: 1613.9354 - val_acc: 0.9559 - val_mDice: 0.6965

Epoch 00047: val_mDice did not improve from 0.70058
Epoch 48/300
 - 14s - loss: 1078.9369 - acc: 0.9546 - mDice: 0.8022 - val_loss: 1630.1535 - val_acc: 0.9554 - val_mDice: 0.6934

Epoch 00048: val_mDice did not improve from 0.70058
Epoch 49/300
 - 12s - loss: 1074.0283 - acc: 0.9546 - mDice: 0.8030 - val_loss: 1686.0579 - val_acc: 0.9553 - val_mDice: 0.6857

Epoch 00049: val_mDice did not improve from 0.70058
Epoch 50/300
 - 13s - loss: 1060.4538 - acc: 0.9549 - mDice: 0.8052 - val_loss: 1618.2453 - val_acc: 0.9577 - val_mDice: 0.6961

Epoch 00050: val_mDice did not improve from 0.70058
Epoch 51/300
 - 12s - loss: 1055.0097 - acc: 0.9549 - mDice: 0.8060 - val_loss: 1731.3869 - val_acc: 0.9577 - val_mDice: 0.6789

Epoch 00051: val_mDice did not improve from 0.70058
Epoch 52/300
 - 13s - loss: 1051.4401 - acc: 0.9551 - mDice: 0.8067 - val_loss: 1624.2002 - val_acc: 0.9571 - val_mDice: 0.6941

Epoch 00052: val_mDice did not improve from 0.70058
Epoch 53/300
 - 13s - loss: 1038.0656 - acc: 0.9552 - mDice: 0.8089 - val_loss: 1717.8687 - val_acc: 0.9559 - val_mDice: 0.6807

Epoch 00053: val_mDice did not improve from 0.70058
Epoch 54/300
 - 12s - loss: 1030.7913 - acc: 0.9554 - mDice: 0.8101 - val_loss: 1636.5952 - val_acc: 0.9563 - val_mDice: 0.6909

Epoch 00054: val_mDice did not improve from 0.70058
Epoch 55/300
 - 13s - loss: 1023.1741 - acc: 0.9556 - mDice: 0.8113 - val_loss: 1699.1556 - val_acc: 0.9568 - val_mDice: 0.6866

Epoch 00055: val_mDice did not improve from 0.70058
Epoch 56/300
 - 12s - loss: 1015.3242 - acc: 0.9558 - mDice: 0.8126 - val_loss: 1637.0285 - val_acc: 0.9547 - val_mDice: 0.6904

Epoch 00056: val_mDice did not improve from 0.70058
Epoch 57/300
 - 13s - loss: 1006.9638 - acc: 0.9559 - mDice: 0.8140 - val_loss: 1688.9988 - val_acc: 0.9566 - val_mDice: 0.6825

Epoch 00057: val_mDice did not improve from 0.70058
Epoch 58/300
 - 13s - loss: 998.6281 - acc: 0.9560 - mDice: 0.8153 - val_loss: 1583.5584 - val_acc: 0.9582 - val_mDice: 0.6998

Epoch 00058: val_mDice did not improve from 0.70058
Epoch 59/300
 - 12s - loss: 991.8081 - acc: 0.9561 - mDice: 0.8164 - val_loss: 1615.1017 - val_acc: 0.9562 - val_mDice: 0.6933

Epoch 00059: val_mDice did not improve from 0.70058
Epoch 60/300
 - 13s - loss: 989.0858 - acc: 0.9562 - mDice: 0.8169 - val_loss: 1654.9687 - val_acc: 0.9565 - val_mDice: 0.6881

Epoch 00060: val_mDice did not improve from 0.70058
Epoch 61/300
 - 12s - loss: 986.8486 - acc: 0.9562 - mDice: 0.8173 - val_loss: 1617.5129 - val_acc: 0.9581 - val_mDice: 0.6944

Epoch 00061: val_mDice did not improve from 0.70058
Epoch 62/300
 - 13s - loss: 979.3356 - acc: 0.9563 - mDice: 0.8186 - val_loss: 1585.4193 - val_acc: 0.9568 - val_mDice: 0.6985

Epoch 00062: val_mDice did not improve from 0.70058
Epoch 63/300
 - 12s - loss: 970.6655 - acc: 0.9565 - mDice: 0.8200 - val_loss: 1620.2981 - val_acc: 0.9584 - val_mDice: 0.6949

Epoch 00063: val_mDice did not improve from 0.70058
Epoch 64/300
 - 13s - loss: 960.8599 - acc: 0.9566 - mDice: 0.8216 - val_loss: 1661.6387 - val_acc: 0.9578 - val_mDice: 0.6884

Epoch 00064: val_mDice did not improve from 0.70058
Epoch 65/300
 - 13s - loss: 956.6545 - acc: 0.9567 - mDice: 0.8223 - val_loss: 1640.8630 - val_acc: 0.9564 - val_mDice: 0.6901

Epoch 00065: val_mDice did not improve from 0.70058
Epoch 66/300
 - 12s - loss: 953.3803 - acc: 0.9568 - mDice: 0.8229 - val_loss: 1609.4537 - val_acc: 0.9584 - val_mDice: 0.6969

Epoch 00066: val_mDice did not improve from 0.70058
Epoch 67/300
 - 13s - loss: 945.5318 - acc: 0.9570 - mDice: 0.8242 - val_loss: 1643.8299 - val_acc: 0.9568 - val_mDice: 0.6894

Epoch 00067: val_mDice did not improve from 0.70058
Epoch 68/300
 - 12s - loss: 941.3698 - acc: 0.9570 - mDice: 0.8249 - val_loss: 1673.2814 - val_acc: 0.9575 - val_mDice: 0.6873

Epoch 00068: val_mDice did not improve from 0.70058
Epoch 69/300
 - 13s - loss: 930.4285 - acc: 0.9572 - mDice: 0.8266 - val_loss: 1636.0244 - val_acc: 0.9576 - val_mDice: 0.6924

Epoch 00069: val_mDice did not improve from 0.70058
Epoch 70/300
 - 13s - loss: 929.0901 - acc: 0.9572 - mDice: 0.8269 - val_loss: 1698.2453 - val_acc: 0.9565 - val_mDice: 0.6822

Epoch 00070: val_mDice did not improve from 0.70058
Epoch 71/300
 - 12s - loss: 928.6618 - acc: 0.9571 - mDice: 0.8270 - val_loss: 1646.9756 - val_acc: 0.9563 - val_mDice: 0.6911

Epoch 00071: val_mDice did not improve from 0.70058
Epoch 72/300
 - 13s - loss: 915.7517 - acc: 0.9574 - mDice: 0.8292 - val_loss: 1706.1825 - val_acc: 0.9578 - val_mDice: 0.6840

Epoch 00072: val_mDice did not improve from 0.70058
Epoch 73/300
 - 12s - loss: 920.5360 - acc: 0.9574 - mDice: 0.8284 - val_loss: 1628.6004 - val_acc: 0.9580 - val_mDice: 0.6926

Epoch 00073: val_mDice did not improve from 0.70058
Epoch 74/300
 - 13s - loss: 908.3934 - acc: 0.9575 - mDice: 0.8304 - val_loss: 1633.8502 - val_acc: 0.9567 - val_mDice: 0.6919

Epoch 00074: val_mDice did not improve from 0.70058
Epoch 75/300
 - 13s - loss: 906.8401 - acc: 0.9576 - mDice: 0.8306 - val_loss: 1775.7812 - val_acc: 0.9556 - val_mDice: 0.6727

Epoch 00075: val_mDice did not improve from 0.70058
Epoch 76/300
 - 12s - loss: 904.5096 - acc: 0.9576 - mDice: 0.8311 - val_loss: 1632.0312 - val_acc: 0.9586 - val_mDice: 0.6922

Epoch 00076: val_mDice did not improve from 0.70058
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [8293.631568545386, 4201.0890880766365, 3203.320824032738, 2870.3019205729165, 2561.645999000186, 2506.0021449497767, 2147.859837123326, 2048.01131766183, 1986.287865048363, 1865.7609194800966, 1828.5159534272693, 1822.232430594308, 1826.7921549479167, 1760.2409173874628, 1771.1969342912946, 1724.0721144903273, 1709.2818748837426, 1707.8354753766741, 1698.6762172154017, 1665.6740025111608, 1707.8760143461682, 1670.0643397739955, 1709.321254185268, 1668.392799014137, 1640.4876156761534, 1641.8687511625744, 1635.7526913597471, 1651.4546508789062, 1704.1135428292412, 1658.7960146949404, 1696.936723981585, 1612.5409691220239, 1624.6212681361608, 1693.8907819475446, 1732.448218936012, 1769.4254906063989, 1701.3905552455358, 1640.8424391973585, 1748.650649297805, 1663.8313569568452, 1658.765133812314, 1685.2632242838542, 1726.8742123558409, 1597.0724603562128, 1659.9712524414062, 1573.0013078962054, 1613.9353666759673, 1630.1535179501489, 1686.057884579613, 1618.245329357329, 1731.3868669782366, 1624.200160435268, 1717.868675595238, 1636.595206124442, 1699.1555931454614, 1637.0285121372767, 1688.9988490513392, 1583.5584455217634, 1615.1016816638764, 1654.968715122768, 1617.5128638857886, 1585.4193434942335, 1620.298075358073, 1661.638695126488, 1640.8629644484747, 1609.4537237258185, 1643.8299095517114, 1673.2813749767486, 1636.0244198753721, 1698.2452857607886, 1646.9755917503721, 1706.1824573335193, 1628.6004173642114, 1633.8502400716145, 1775.7811628069196, 1632.031238374256], 'val_acc': [0.9072587433315459, 0.9109489449432918, 0.9085808864661625, 0.9159669805140722, 0.9267428162552062, 0.927946130434672, 0.9347842151210422, 0.9368547002474467, 0.937527175460543, 0.9415192902088165, 0.9438830883730025, 0.9435138972032637, 0.9439002261275337, 0.9460422354085105, 0.9437385513668969, 0.9467662714776539, 0.9488782087961832, 0.9466746747493744, 0.9481957001345498, 0.9483172978673663, 0.9466603526047298, 0.9513965036187854, 0.946813471260525, 0.9501974469139463, 0.9510359338351658, 0.9509586720239549, 0.9511733097689492, 0.9505322603952318, 0.9530119526953924, 0.9531164254461016, 0.9537674671127683, 0.9530105392138163, 0.9528073455606189, 0.9536286620866685, 0.9533596379416329, 0.954544430687314, 0.9529962113925389, 0.9555917878945669, 0.9532308862322852, 0.9519889014107841, 0.9562399926639739, 0.9548091349147615, 0.955198313508715, 0.9577123409225827, 0.9531650614170801, 0.9574347564152309, 0.9558837115764618, 0.9553542733192444, 0.9552741618383498, 0.9577123238926842, 0.9577066160383678, 0.9571085373560587, 0.9558607950097039, 0.9562843214897883, 0.9567894282795134, 0.9547490136963981, 0.956557632911773, 0.9582260165895734, 0.9561755969410851, 0.9565361582097553, 0.9580671787261963, 0.9567708358878181, 0.958434922354562, 0.9578139384587606, 0.9564045454774585, 0.9584234598137084, 0.9567922822066716, 0.9574548006057739, 0.9575892857142857, 0.9564674837248666, 0.9562700163750422, 0.9578182427656083, 0.9580085220791045, 0.9567422199816931, 0.955603247597104, 0.9585808841955095], 'val_mDice': [0.2914453964857828, 0.4212020706562769, 0.4995401586805071, 0.5391264586221605, 0.575706300281343, 0.5863921798410869, 0.6199935064429328, 0.6311060942354656, 0.6388727838084811, 0.6560069947015672, 0.6613649285974956, 0.6625283445630755, 0.6633448359512147, 0.6719237849825904, 0.6682034305163792, 0.6778277854124705, 0.6793776069368634, 0.6797297511781965, 0.68157401964778, 0.6874166343893323, 0.6771087561334882, 0.6865119962465196, 0.6791809598604838, 0.6854956192629678, 0.6906726984750657, 0.6908244036492848, 0.6906713985261463, 0.6893387380100432, 0.6820251090185983, 0.6894353954564958, 0.6821508123761132, 0.6950524747371674, 0.6939872588430133, 0.6855728881699699, 0.6766116193362645, 0.672819265297481, 0.6827111627374377, 0.6918546968982333, 0.6759940612883795, 0.6880179331416175, 0.6900485824970972, 0.6862293850807917, 0.6780711582728794, 0.6982589562733968, 0.6876960496107737, 0.7005839958077386, 0.69651679339863, 0.6933518307549613, 0.685670758996691, 0.6961410130773272, 0.6789271292232332, 0.6940830945968628, 0.6806832310699281, 0.6908946789446331, 0.6866476166815985, 0.6904258245513553, 0.6825287711052668, 0.6997787115119752, 0.6932922871339888, 0.6881314189661116, 0.6944331626097361, 0.6984918259439015, 0.6948728022121248, 0.688350111246109, 0.6900941147690728, 0.6968691419987452, 0.6893691193489802, 0.6873446972597212, 0.6923577657767704, 0.6822043302513304, 0.6910529094082969, 0.6840466658274332, 0.6925982378778004, 0.6918815062159583, 0.6726850555056617, 0.6921896622294471], 'loss': [15254.600375891327, 5894.787524596712, 4354.598142780866, 3508.488062528006, 3041.7126699243104, 2763.0067519190306, 2532.3444384339446, 2294.434527656384, 2145.701393717245, 2033.5865071360904, 1936.19402996263, 1865.548782538892, 1806.7650216499767, 1758.2900757444768, 1711.77619024643, 1667.8579054378215, 1632.3953370738802, 1597.427446817222, 1562.4146542442113, 1535.1523863300124, 1505.0960226082743, 1471.9184398698687, 1447.2165832519531, 1423.9116876464234, 1404.4624005172616, 1377.0511321640965, 1356.0372893602175, 1339.4086619541235, 1318.9929247164073, 1297.5300914735865, 1282.8304579204455, 1271.4440201452546, 1253.3932774798234, 1241.9297304985826, 1230.1301052635745, 1216.017730142113, 1200.2469712635525, 1185.3156528235077, 1176.3640828881776, 1157.3147923191289, 1148.0663226501008, 1134.1679511319967, 1129.5999440980374, 1120.8644571280538, 1107.8069265846004, 1101.7954337293668, 1090.979209272047, 1078.9369285754728, 1074.028290517907, 1060.4537500776257, 1055.0096971507085, 1051.4400942034258, 1038.0655664648498, 1030.7913101272393, 1023.1741331675998, 1015.3241754279767, 1006.9638290976051, 998.6280709739932, 991.8080649245112, 989.085773344349, 986.8486371694361, 979.3356379178397, 970.6655314723749, 960.8598718999924, 956.6544762513881, 953.3803370183246, 945.5317762950413, 941.369788438602, 930.4284796964498, 929.090102179092, 928.6617559685077, 915.7517328619065, 920.535999250531, 908.3933692989207, 906.8400648882858, 904.509609726599], 'acc': [0.8693120732271761, 0.8988081929726791, 0.9070028706158783, 0.9136135208227688, 0.9194852417320979, 0.9244067595152189, 0.9280153350379698, 0.931142582578998, 0.9335811076839071, 0.9356357654245417, 0.9376849347256365, 0.939118942213326, 0.940473860970459, 0.9414697526547677, 0.942306961780623, 0.9433185739670311, 0.9439830790062498, 0.9447704924646756, 0.9453985035939704, 0.9459460760812807, 0.9465650392143506, 0.9471375291186972, 0.9476854934582389, 0.9481952405555587, 0.9485729988153438, 0.9489569702090468, 0.9492932504363488, 0.9497529822134615, 0.9501765620455778, 0.950544237012875, 0.9508643491830017, 0.9509850691381535, 0.951398192089692, 0.9515283670545813, 0.9517157001053901, 0.9521854741503473, 0.9523102725273058, 0.9526557345825835, 0.9528774589374476, 0.9530525751913574, 0.9532287287667505, 0.9534153078410988, 0.9537192931459134, 0.9538816519992013, 0.9540010781545294, 0.9542094462010035, 0.9542893785751074, 0.9545739573470672, 0.9545510087784687, 0.9548575610962889, 0.9549125430924339, 0.955123457974032, 0.9552308221224538, 0.9553858933603377, 0.9555870490775739, 0.95576336656574, 0.9558643940789742, 0.9560166227995903, 0.9560588274401917, 0.9561612800767, 0.9561968702925113, 0.9562757390358502, 0.9565096784410928, 0.956628131097243, 0.9566878118085445, 0.9567890277229937, 0.9569683267997388, 0.9569936507472077, 0.9571897510132588, 0.9572226129044916, 0.9571237717371927, 0.957421762316007, 0.9573900490033062, 0.9574750953927599, 0.9575940528118105, 0.9576302249718486], 'mDice': [0.157160208663297, 0.350556094041489, 0.44273109915213393, 0.5086437174748453, 0.553385054344251, 0.58295788582498, 0.6072901222028042, 0.6322520981517219, 0.6493980915394805, 0.6633823986659918, 0.6759836932927593, 0.6853924232193657, 0.6935151840311631, 0.7000500317152004, 0.7067252990796679, 0.7128295790859291, 0.7179208028123266, 0.7229950149680611, 0.7280307192903505, 0.7319011077507773, 0.7364020092305994, 0.7412116710941987, 0.7449392193087616, 0.7484099644600899, 0.7513880241950254, 0.7553996477935677, 0.7586539170316925, 0.7611926724191318, 0.7643624938968708, 0.7676451326234085, 0.7699612477919705, 0.7716848299539, 0.7745426425761416, 0.7762670707041188, 0.778057261502505, 0.7803617272888336, 0.7828283797104163, 0.7851624311763152, 0.7866127363910105, 0.7895968211559287, 0.7909917827147498, 0.7932809767245949, 0.7940408033585905, 0.795511768680261, 0.79750631968874, 0.7985223471523818, 0.8002631912504943, 0.802209834821355, 0.8029737817007407, 0.8051746901579926, 0.8060278450870454, 0.80666421565629, 0.8088889997684747, 0.8100648166569986, 0.8112968073930229, 0.8126125169959746, 0.8139885426905387, 0.8152894039180808, 0.8163957388843979, 0.8169416363659939, 0.8172563697000097, 0.8185602768215158, 0.8199536891054928, 0.8215736202393982, 0.8222869393459876, 0.8228604946090396, 0.8242155082356603, 0.8248725598701218, 0.826628539404667, 0.8269174207847314, 0.8269989235219812, 0.8291629265594364, 0.8283578005812114, 0.8304226693332641, 0.8306400656997415, 0.8310785947966755]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:15<00:47, 15.87s/it]predicting test subjects:  50%|█████     | 2/4 [00:29<00:30, 15.23s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:44<00:15, 15.19s/it]predicting test subjects: 100%|██████████| 4/4 [00:59<00:00, 15.06s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:21<1:53:21, 21.94s/it]predicting train subjects:   1%|          | 2/311 [00:32<1:36:09, 18.67s/it]predicting train subjects:   1%|          | 3/311 [00:46<1:28:40, 17.27s/it]predicting train subjects:   1%|▏         | 4/311 [01:00<1:22:20, 16.09s/it]predicting train subjects:   2%|▏         | 5/311 [01:12<1:15:48, 14.87s/it]predicting train subjects:   2%|▏         | 6/311 [01:23<1:10:36, 13.89s/it]predicting train subjects:   2%|▏         | 7/311 [01:37<1:10:08, 13.84s/it]predicting train subjects:   3%|▎         | 8/311 [01:53<1:12:31, 14.36s/it]predicting train subjects:   3%|▎         | 9/311 [02:07<1:11:46, 14.26s/it]predicting train subjects:   3%|▎         | 10/311 [02:19<1:07:46, 13.51s/it]predicting train subjects:   4%|▎         | 11/311 [02:34<1:10:22, 14.07s/it]predicting train subjects:   4%|▍         | 12/311 [02:46<1:07:13, 13.49s/it]predicting train subjects:   4%|▍         | 13/311 [02:59<1:05:31, 13.19s/it]predicting train subjects:   5%|▍         | 14/311 [03:14<1:08:58, 13.93s/it]predicting train subjects:   5%|▍         | 15/311 [03:36<1:20:21, 16.29s/it]predicting train subjects:   5%|▌         | 16/311 [03:58<1:29:10, 18.14s/it]predicting train subjects:   5%|▌         | 17/311 [04:20<1:33:50, 19.15s/it]predicting train subjects:   6%|▌         | 18/311 [04:44<1:41:00, 20.68s/it]predicting train subjects:   6%|▌         | 19/311 [05:14<1:53:12, 23.26s/it]predicting train subjects:   6%|▋         | 20/311 [05:41<1:59:04, 24.55s/it]predicting train subjects:   7%|▋         | 21/311 [06:08<2:01:52, 25.21s/it]predicting train subjects:   7%|▋         | 22/311 [06:35<2:04:41, 25.89s/it]predicting train subjects:   7%|▋         | 23/311 [07:04<2:08:08, 26.69s/it]predicting train subjects:   8%|▊         | 24/311 [07:32<2:09:04, 26.98s/it]predicting train subjects:   8%|▊         | 25/311 [08:00<2:10:10, 27.31s/it]predicting train subjects:   8%|▊         | 26/311 [08:27<2:09:26, 27.25s/it]predicting train subjects:   9%|▊         | 27/311 [08:53<2:07:52, 27.01s/it]predicting train subjects:   9%|▉         | 28/311 [09:15<2:00:42, 25.59s/it]predicting train subjects:   9%|▉         | 29/311 [09:37<1:54:57, 24.46s/it]predicting train subjects:  10%|▉         | 30/311 [09:59<1:50:11, 23.53s/it]predicting train subjects:  10%|▉         | 31/311 [10:20<1:47:17, 22.99s/it]predicting train subjects:  10%|█         | 32/311 [10:42<1:45:24, 22.67s/it]predicting train subjects:  11%|█         | 33/311 [10:53<1:28:01, 19.00s/it]predicting train subjects:  11%|█         | 34/311 [11:03<1:15:15, 16.30s/it]predicting train subjects:  11%|█▏        | 35/311 [11:13<1:07:05, 14.58s/it]predicting train subjects:  12%|█▏        | 36/311 [11:24<1:01:14, 13.36s/it]predicting train subjects:  12%|█▏        | 37/311 [11:34<56:37, 12.40s/it]  predicting train subjects:  12%|█▏        | 38/311 [11:44<53:43, 11.81s/it]predicting train subjects:  13%|█▎        | 39/311 [11:55<51:58, 11.47s/it]predicting train subjects:  13%|█▎        | 40/311 [12:05<50:13, 11.12s/it]predicting train subjects:  13%|█▎        | 41/311 [12:16<48:58, 10.88s/it]predicting train subjects:  14%|█▎        | 42/311 [12:26<48:23, 10.79s/it]predicting train subjects:  14%|█▍        | 43/311 [12:37<48:16, 10.81s/it]predicting train subjects:  14%|█▍        | 44/311 [12:47<46:44, 10.51s/it]predicting train subjects:  14%|█▍        | 45/311 [12:57<46:37, 10.52s/it]predicting train subjects:  15%|█▍        | 46/311 [13:08<46:18, 10.48s/it]predicting train subjects:  15%|█▌        | 47/311 [13:18<45:35, 10.36s/it]predicting train subjects:  15%|█▌        | 48/311 [13:29<45:52, 10.47s/it]predicting train subjects:  16%|█▌        | 49/311 [13:39<45:54, 10.51s/it]predicting train subjects:  16%|█▌        | 50/311 [13:49<45:18, 10.42s/it]predicting train subjects:  16%|█▋        | 51/311 [14:02<48:14, 11.13s/it]predicting train subjects:  17%|█▋        | 52/311 [14:15<50:44, 11.75s/it]predicting train subjects:  17%|█▋        | 53/311 [14:29<52:26, 12.20s/it]predicting train subjects:  17%|█▋        | 54/311 [14:42<53:35, 12.51s/it]predicting train subjects:  18%|█▊        | 55/311 [14:55<54:11, 12.70s/it]predicting train subjects:  18%|█▊        | 56/311 [15:08<54:45, 12.88s/it]predicting train subjects:  18%|█▊        | 57/311 [15:21<54:42, 12.92s/it]predicting train subjects:  19%|█▊        | 58/311 [15:35<54:42, 12.97s/it]predicting train subjects:  19%|█▉        | 59/311 [15:48<55:45, 13.27s/it]predicting train subjects:  19%|█▉        | 60/311 [16:02<55:52, 13.36s/it]predicting train subjects:  20%|█▉        | 61/311 [16:15<55:21, 13.29s/it]predicting train subjects:  20%|█▉        | 62/311 [16:28<54:56, 13.24s/it]predicting train subjects:  20%|██        | 63/311 [16:42<54:45, 13.25s/it]predicting train subjects:  21%|██        | 64/311 [16:55<54:40, 13.28s/it]predicting train subjects:  21%|██        | 65/311 [17:10<56:13, 13.71s/it]predicting train subjects:  21%|██        | 66/311 [17:23<55:52, 13.68s/it]predicting train subjects:  22%|██▏       | 67/311 [17:36<54:47, 13.48s/it]predicting train subjects:  22%|██▏       | 68/311 [17:49<53:35, 13.23s/it]predicting train subjects:  22%|██▏       | 69/311 [18:02<52:55, 13.12s/it]predicting train subjects:  23%|██▎       | 70/311 [18:15<52:22, 13.04s/it]predicting train subjects:  23%|██▎       | 71/311 [18:28<52:03, 13.01s/it]predicting train subjects:  23%|██▎       | 72/311 [18:41<52:09, 13.09s/it]predicting train subjects:  23%|██▎       | 73/311 [18:54<52:18, 13.19s/it]predicting train subjects:  24%|██▍       | 74/311 [19:07<51:27, 13.03s/it]predicting train subjects:  24%|██▍       | 75/311 [19:19<50:31, 12.84s/it]predicting train subjects:  24%|██▍       | 76/311 [19:33<50:42, 12.95s/it]predicting train subjects:  25%|██▍       | 77/311 [19:46<50:50, 13.04s/it]predicting train subjects:  25%|██▌       | 78/311 [19:58<50:00, 12.88s/it]predicting train subjects:  25%|██▌       | 79/311 [20:11<49:55, 12.91s/it]predicting train subjects:  26%|██▌       | 80/311 [20:24<49:35, 12.88s/it]predicting train subjects:  26%|██▌       | 81/311 [20:37<49:26, 12.90s/it]predicting train subjects:  26%|██▋       | 82/311 [20:50<49:18, 12.92s/it]predicting train subjects:  27%|██▋       | 83/311 [21:03<49:16, 12.97s/it]predicting train subjects:  27%|██▋       | 84/311 [21:16<49:32, 13.09s/it]predicting train subjects:  27%|██▋       | 85/311 [21:28<47:54, 12.72s/it]predicting train subjects:  28%|██▊       | 86/311 [21:40<46:37, 12.43s/it]predicting train subjects:  28%|██▊       | 87/311 [21:52<45:53, 12.29s/it]predicting train subjects:  28%|██▊       | 88/311 [22:04<45:47, 12.32s/it]predicting train subjects:  29%|██▊       | 89/311 [22:18<46:30, 12.57s/it]predicting train subjects:  29%|██▉       | 90/311 [22:29<45:36, 12.38s/it]predicting train subjects:  29%|██▉       | 91/311 [22:41<44:57, 12.26s/it]predicting train subjects:  30%|██▉       | 92/311 [22:53<44:21, 12.15s/it]predicting train subjects:  30%|██▉       | 93/311 [23:05<43:44, 12.04s/it]predicting train subjects:  30%|███       | 94/311 [23:17<43:26, 12.01s/it]predicting train subjects:  31%|███       | 95/311 [23:29<43:11, 12.00s/it]predicting train subjects:  31%|███       | 96/311 [23:41<42:51, 11.96s/it]predicting train subjects:  31%|███       | 97/311 [23:53<42:15, 11.85s/it]predicting train subjects:  32%|███▏      | 98/311 [24:04<41:43, 11.75s/it]predicting train subjects:  32%|███▏      | 99/311 [24:15<41:06, 11.63s/it]predicting train subjects:  32%|███▏      | 100/311 [24:27<40:20, 11.47s/it]predicting train subjects:  32%|███▏      | 101/311 [24:38<40:31, 11.58s/it]predicting train subjects:  33%|███▎      | 102/311 [24:50<40:55, 11.75s/it]predicting train subjects:  33%|███▎      | 103/311 [25:02<40:10, 11.59s/it]predicting train subjects:  33%|███▎      | 104/311 [25:14<40:25, 11.72s/it]predicting train subjects:  34%|███▍      | 105/311 [25:26<40:50, 11.90s/it]predicting train subjects:  34%|███▍      | 106/311 [25:38<41:00, 12.00s/it]predicting train subjects:  34%|███▍      | 107/311 [25:50<40:51, 12.02s/it]predicting train subjects:  35%|███▍      | 108/311 [26:02<40:38, 12.01s/it]predicting train subjects:  35%|███▌      | 109/311 [26:14<40:18, 11.97s/it]predicting train subjects:  35%|███▌      | 110/311 [26:25<39:25, 11.77s/it]predicting train subjects:  36%|███▌      | 111/311 [26:40<42:01, 12.61s/it]predicting train subjects:  36%|███▌      | 112/311 [26:55<43:49, 13.21s/it]predicting train subjects:  36%|███▋      | 113/311 [27:09<45:00, 13.64s/it]predicting train subjects:  37%|███▋      | 114/311 [27:36<57:18, 17.46s/it]predicting train subjects:  37%|███▋      | 115/311 [28:02<1:05:57, 20.19s/it]predicting train subjects:  37%|███▋      | 116/311 [28:30<1:13:04, 22.48s/it]predicting train subjects:  38%|███▊      | 117/311 [28:53<1:12:38, 22.46s/it]predicting train subjects:  38%|███▊      | 118/311 [29:15<1:11:54, 22.35s/it]predicting train subjects:  38%|███▊      | 119/311 [29:38<1:12:19, 22.60s/it]predicting train subjects:  39%|███▊      | 120/311 [30:01<1:12:06, 22.65s/it]predicting train subjects:  39%|███▉      | 121/311 [30:23<1:11:19, 22.53s/it]predicting train subjects:  39%|███▉      | 122/311 [30:46<1:11:35, 22.72s/it]predicting train subjects:  40%|███▉      | 123/311 [31:08<1:10:47, 22.59s/it]predicting train subjects:  40%|███▉      | 124/311 [31:31<1:10:39, 22.67s/it]predicting train subjects:  40%|████      | 125/311 [31:53<1:09:50, 22.53s/it]predicting train subjects:  41%|████      | 126/311 [32:16<1:09:34, 22.56s/it]predicting train subjects:  41%|████      | 127/311 [32:38<1:08:41, 22.40s/it]predicting train subjects:  41%|████      | 128/311 [33:01<1:09:02, 22.63s/it]predicting train subjects:  41%|████▏     | 129/311 [33:25<1:09:24, 22.88s/it]predicting train subjects:  42%|████▏     | 130/311 [33:48<1:09:47, 23.14s/it]predicting train subjects:  42%|████▏     | 131/311 [34:11<1:09:01, 23.01s/it]predicting train subjects:  42%|████▏     | 132/311 [34:22<58:05, 19.47s/it]  predicting train subjects:  43%|████▎     | 133/311 [34:34<50:47, 17.12s/it]predicting train subjects:  43%|████▎     | 134/311 [34:45<45:13, 15.33s/it]predicting train subjects:  43%|████▎     | 135/311 [34:56<40:46, 13.90s/it]predicting train subjects:  44%|████▎     | 136/311 [35:07<38:10, 13.09s/it]predicting train subjects:  44%|████▍     | 137/311 [35:18<35:51, 12.36s/it]predicting train subjects:  44%|████▍     | 138/311 [35:28<33:56, 11.77s/it]predicting train subjects:  45%|████▍     | 139/311 [35:38<32:39, 11.39s/it]predicting train subjects:  45%|████▌     | 140/311 [35:49<32:06, 11.27s/it]predicting train subjects:  45%|████▌     | 141/311 [36:00<31:28, 11.11s/it]predicting train subjects:  46%|████▌     | 142/311 [36:11<30:58, 11.00s/it]predicting train subjects:  46%|████▌     | 143/311 [36:24<32:23, 11.57s/it]predicting train subjects:  46%|████▋     | 144/311 [36:37<33:58, 12.20s/it]predicting train subjects:  47%|████▋     | 145/311 [36:51<34:31, 12.48s/it]predicting train subjects:  47%|████▋     | 146/311 [37:04<35:18, 12.84s/it]predicting train subjects:  47%|████▋     | 147/311 [37:18<35:49, 13.11s/it]predicting train subjects:  48%|████▊     | 148/311 [37:31<35:33, 13.09s/it]predicting train subjects:  48%|████▊     | 149/311 [37:44<35:26, 13.13s/it]predicting train subjects:  48%|████▊     | 150/311 [38:02<38:34, 14.37s/it]predicting train subjects:  49%|████▊     | 151/311 [38:15<37:35, 14.09s/it]predicting train subjects:  49%|████▉     | 152/311 [38:28<36:54, 13.93s/it]predicting train subjects:  49%|████▉     | 153/311 [38:41<35:50, 13.61s/it]predicting train subjects:  50%|████▉     | 154/311 [38:55<35:31, 13.58s/it]predicting train subjects:  50%|████▉     | 155/311 [39:08<35:08, 13.52s/it]predicting train subjects:  50%|█████     | 156/311 [39:22<34:50, 13.49s/it]predicting train subjects:  50%|█████     | 157/311 [39:37<36:06, 14.07s/it]predicting train subjects:  51%|█████     | 158/311 [39:53<37:15, 14.61s/it]predicting train subjects:  51%|█████     | 159/311 [40:09<37:52, 14.95s/it]predicting train subjects:  51%|█████▏    | 160/311 [40:25<38:43, 15.39s/it]predicting train subjects:  52%|█████▏    | 161/311 [40:41<38:59, 15.60s/it]predicting train subjects:  52%|█████▏    | 162/311 [40:58<39:47, 16.02s/it]predicting train subjects:  52%|█████▏    | 163/311 [41:14<39:24, 15.97s/it]predicting train subjects:  53%|█████▎    | 164/311 [41:30<39:11, 16.00s/it]predicting train subjects:  53%|█████▎    | 165/311 [41:47<39:20, 16.17s/it]predicting train subjects:  53%|█████▎    | 166/311 [42:03<39:11, 16.22s/it]predicting train subjects:  54%|█████▎    | 167/311 [42:18<38:00, 15.84s/it]predicting train subjects:  54%|█████▍    | 168/311 [42:33<37:16, 15.64s/it]predicting train subjects:  54%|█████▍    | 169/311 [42:50<37:39, 15.91s/it]predicting train subjects:  55%|█████▍    | 170/311 [43:06<37:38, 16.02s/it]predicting train subjects:  55%|█████▍    | 171/311 [43:21<36:54, 15.82s/it]predicting train subjects:  55%|█████▌    | 172/311 [43:36<35:34, 15.35s/it]predicting train subjects:  56%|█████▌    | 173/311 [43:52<35:43, 15.53s/it]predicting train subjects:  56%|█████▌    | 174/311 [44:07<35:35, 15.59s/it]predicting train subjects:  56%|█████▋    | 175/311 [44:23<35:41, 15.75s/it]predicting train subjects:  57%|█████▋    | 176/311 [44:39<35:06, 15.60s/it]predicting train subjects:  57%|█████▋    | 177/311 [44:55<35:21, 15.83s/it]predicting train subjects:  57%|█████▋    | 178/311 [45:11<35:22, 15.96s/it]predicting train subjects:  58%|█████▊    | 179/311 [45:27<34:51, 15.84s/it]predicting train subjects:  58%|█████▊    | 180/311 [45:43<34:39, 15.87s/it]predicting train subjects:  58%|█████▊    | 181/311 [45:58<34:15, 15.81s/it]predicting train subjects:  59%|█████▊    | 182/311 [46:14<34:03, 15.84s/it]predicting train subjects:  59%|█████▉    | 183/311 [46:31<34:01, 15.95s/it]predicting train subjects:  59%|█████▉    | 184/311 [46:45<32:34, 15.39s/it]predicting train subjects:  59%|█████▉    | 185/311 [46:59<31:33, 15.03s/it]predicting train subjects:  60%|█████▉    | 186/311 [47:13<30:40, 14.72s/it]predicting train subjects:  60%|██████    | 187/311 [47:26<29:24, 14.23s/it]predicting train subjects:  60%|██████    | 188/311 [47:39<28:35, 13.95s/it]predicting train subjects:  61%|██████    | 189/311 [47:54<28:53, 14.21s/it]predicting train subjects:  61%|██████    | 190/311 [48:09<28:58, 14.37s/it]predicting train subjects:  61%|██████▏   | 191/311 [48:24<28:57, 14.48s/it]predicting train subjects:  62%|██████▏   | 192/311 [48:38<28:55, 14.58s/it]predicting train subjects:  62%|██████▏   | 193/311 [48:53<29:00, 14.75s/it]predicting train subjects:  62%|██████▏   | 194/311 [49:08<28:37, 14.68s/it]predicting train subjects:  63%|██████▎   | 195/311 [49:23<28:39, 14.82s/it]predicting train subjects:  63%|██████▎   | 196/311 [49:38<28:23, 14.82s/it]predicting train subjects:  63%|██████▎   | 197/311 [49:52<27:54, 14.69s/it]predicting train subjects:  64%|██████▎   | 198/311 [50:07<27:21, 14.53s/it]predicting train subjects:  64%|██████▍   | 199/311 [50:21<27:10, 14.56s/it]predicting train subjects:  64%|██████▍   | 200/311 [50:36<26:52, 14.53s/it]predicting train subjects:  65%|██████▍   | 201/311 [50:50<26:36, 14.52s/it]predicting train subjects:  65%|██████▍   | 202/311 [51:04<26:00, 14.32s/it]predicting train subjects:  65%|██████▌   | 203/311 [51:19<25:55, 14.40s/it]predicting train subjects:  66%|██████▌   | 204/311 [51:33<25:42, 14.42s/it]predicting train subjects:  66%|██████▌   | 205/311 [51:48<25:42, 14.55s/it]predicting train subjects:  66%|██████▌   | 206/311 [52:00<24:23, 13.94s/it]predicting train subjects:  67%|██████▋   | 207/311 [52:12<22:59, 13.27s/it]predicting train subjects:  67%|██████▋   | 208/311 [52:24<22:01, 12.83s/it]predicting train subjects:  67%|██████▋   | 209/311 [52:36<21:24, 12.59s/it]predicting train subjects:  68%|██████▊   | 210/311 [52:48<20:45, 12.34s/it]predicting train subjects:  68%|██████▊   | 211/311 [52:59<20:07, 12.07s/it]predicting train subjects:  68%|██████▊   | 212/311 [53:10<19:33, 11.86s/it]predicting train subjects:  68%|██████▊   | 213/311 [53:34<25:10, 15.42s/it]predicting train subjects:  69%|██████▉   | 214/311 [53:57<28:17, 17.50s/it]predicting train subjects:  69%|██████▉   | 215/311 [54:20<30:44, 19.21s/it]predicting train subjects:  69%|██████▉   | 216/311 [54:43<32:10, 20.33s/it]predicting train subjects:  70%|██████▉   | 217/311 [55:07<33:39, 21.49s/it]predicting train subjects:  70%|███████   | 218/311 [55:33<35:20, 22.80s/it]predicting train subjects:  70%|███████   | 219/311 [56:00<37:07, 24.22s/it]predicting train subjects:  71%|███████   | 220/311 [56:29<38:35, 25.44s/it]predicting train subjects:  71%|███████   | 221/311 [56:57<39:29, 26.33s/it]predicting train subjects:  71%|███████▏  | 222/311 [57:26<40:15, 27.14s/it]predicting train subjects:  72%|███████▏  | 223/311 [57:54<40:24, 27.55s/it]predicting train subjects:  72%|███████▏  | 224/311 [58:24<40:38, 28.03s/it]predicting train subjects:  72%|███████▏  | 225/311 [58:53<40:35, 28.32s/it]predicting train subjects:  73%|███████▎  | 226/311 [59:23<40:48, 28.81s/it]predicting train subjects:  73%|███████▎  | 227/311 [59:53<41:03, 29.32s/it]predicting train subjects:  73%|███████▎  | 228/311 [1:00:24<41:02, 29.67s/it]predicting train subjects:  74%|███████▎  | 229/311 [1:00:56<41:33, 30.41s/it]predicting train subjects:  74%|███████▍  | 230/311 [1:01:29<42:22, 31.38s/it]predicting train subjects:  74%|███████▍  | 231/311 [1:01:43<34:53, 26.17s/it]predicting train subjects:  75%|███████▍  | 232/311 [1:01:58<29:49, 22.66s/it]predicting train subjects:  75%|███████▍  | 233/311 [1:02:12<26:09, 20.13s/it]predicting train subjects:  75%|███████▌  | 234/311 [1:02:26<23:32, 18.34s/it]predicting train subjects:  76%|███████▌  | 235/311 [1:02:41<21:46, 17.19s/it]predicting train subjects:  76%|███████▌  | 236/311 [1:02:55<20:22, 16.29s/it]predicting train subjects:  76%|███████▌  | 237/311 [1:03:10<19:28, 15.79s/it]predicting train subjects:  77%|███████▋  | 238/311 [1:03:25<18:56, 15.57s/it]predicting train subjects:  77%|███████▋  | 239/311 [1:03:40<18:32, 15.45s/it]predicting train subjects:  77%|███████▋  | 240/311 [1:03:54<17:42, 14.96s/it]predicting train subjects:  77%|███████▋  | 241/311 [1:04:09<17:38, 15.13s/it]predicting train subjects:  78%|███████▊  | 242/311 [1:04:23<16:57, 14.75s/it]predicting train subjects:  78%|███████▊  | 243/311 [1:04:37<16:23, 14.46s/it]predicting train subjects:  78%|███████▊  | 244/311 [1:04:51<15:58, 14.31s/it]predicting train subjects:  79%|███████▉  | 245/311 [1:05:06<16:05, 14.62s/it]predicting train subjects:  79%|███████▉  | 246/311 [1:05:21<15:53, 14.67s/it]predicting train subjects:  79%|███████▉  | 247/311 [1:05:36<15:38, 14.67s/it]predicting train subjects:  80%|███████▉  | 248/311 [1:05:50<15:22, 14.65s/it]predicting train subjects:  80%|████████  | 249/311 [1:06:08<16:13, 15.70s/it]predicting train subjects:  80%|████████  | 250/311 [1:06:27<16:58, 16.69s/it]predicting train subjects:  81%|████████  | 251/311 [1:06:47<17:28, 17.47s/it]predicting train subjects:  81%|████████  | 252/311 [1:07:07<18:10, 18.49s/it]predicting train subjects:  81%|████████▏ | 253/311 [1:07:28<18:24, 19.05s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:07:50<19:00, 20.00s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:08:11<19:03, 20.43s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:08:32<18:45, 20.46s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:08:52<18:20, 20.38s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:09:12<17:53, 20.25s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:09:32<17:25, 20.11s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:09:51<16:50, 19.81s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:10:09<16:03, 19.27s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:10:26<15:07, 18.52s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:10:44<14:43, 18.40s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:11:00<13:54, 17.76s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:11:15<13:02, 17.02s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:11:30<12:15, 16.35s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:11:44<11:28, 15.65s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:11:58<10:49, 15.11s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:12:12<10:19, 14.74s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:12:26<09:50, 14.41s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:12:39<09:26, 14.17s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:12:53<09:08, 14.06s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:13:08<09:08, 14.43s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:13:26<09:27, 15.35s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:13:43<09:30, 15.84s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:14:02<09:48, 16.81s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:14:19<09:33, 16.86s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:14:36<09:18, 16.94s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:14:53<09:04, 17.02s/it]predicting train subjects:  90%|█████████ | 280/311 [1:15:11<08:52, 17.16s/it]predicting train subjects:  90%|█████████ | 281/311 [1:15:29<08:48, 17.62s/it]predicting train subjects:  91%|█████████ | 282/311 [1:15:48<08:43, 18.06s/it]predicting train subjects:  91%|█████████ | 283/311 [1:16:05<08:10, 17.53s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:16:21<07:42, 17.12s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:16:37<07:14, 16.73s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:16:53<06:53, 16.53s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:17:09<06:36, 16.50s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:17:26<06:18, 16.47s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:17:42<05:59, 16.35s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:17:59<05:50, 16.69s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:18:16<05:37, 16.86s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:18:29<04:54, 15.53s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:18:41<04:20, 14.47s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:18:53<03:53, 13.75s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:19:05<03:34, 13.38s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:19:17<03:13, 12.91s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:19:29<02:56, 12.62s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:19:41<02:39, 12.27s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:19:52<02:24, 12.05s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:20:05<02:14, 12.20s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:20:17<02:02, 12.25s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:20:29<01:50, 12.23s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:20:41<01:37, 12.14s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:20:53<01:24, 12.02s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:21:05<01:11, 11.98s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:21:17<01:00, 12.02s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:21:29<00:48, 12.16s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:21:42<00:36, 12.25s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:21:54<00:24, 12.08s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:22:05<00:12, 12.01s/it]predicting train subjects: 100%|██████████| 311/311 [1:22:18<00:00, 12.14s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:29:19, 17.29s/it]Loading train:   1%|          | 2/311 [00:26<1:15:48, 14.72s/it]Loading train:   1%|          | 3/311 [00:36<1:09:28, 13.53s/it]Loading train:   1%|▏         | 4/311 [00:47<1:04:22, 12.58s/it]Loading train:   2%|▏         | 5/311 [00:56<59:36, 11.69s/it]  Loading train:   2%|▏         | 6/311 [01:06<56:51, 11.19s/it]Loading train:   2%|▏         | 7/311 [01:17<56:29, 11.15s/it]Loading train:   3%|▎         | 8/311 [01:32<1:01:27, 12.17s/it]Loading train:   3%|▎         | 9/311 [01:46<1:03:53, 12.69s/it]Loading train:   3%|▎         | 10/311 [01:57<1:01:25, 12.24s/it]Loading train:   4%|▎         | 11/311 [02:11<1:04:22, 12.87s/it]Loading train:   4%|▍         | 12/311 [02:23<1:02:43, 12.59s/it]Loading train:   4%|▍         | 13/311 [02:35<1:01:16, 12.34s/it]Loading train:   5%|▍         | 14/311 [02:49<1:03:29, 12.83s/it]Loading train:   5%|▍         | 15/311 [03:00<1:01:11, 12.40s/it]Loading train:   5%|▌         | 16/311 [03:12<1:00:13, 12.25s/it]Loading train:   5%|▌         | 17/311 [03:25<1:00:07, 12.27s/it]Loading train:   6%|▌         | 18/311 [03:36<58:46, 12.03s/it]  Loading train:   6%|▌         | 19/311 [03:48<58:11, 11.96s/it]Loading train:   6%|▋         | 20/311 [03:59<56:36, 11.67s/it]Loading train:   7%|▋         | 21/311 [04:10<55:16, 11.44s/it]Loading train:   7%|▋         | 22/311 [04:21<54:52, 11.39s/it]Loading train:   7%|▋         | 23/311 [04:32<54:37, 11.38s/it]Loading train:   8%|▊         | 24/311 [04:44<54:51, 11.47s/it]Loading train:   8%|▊         | 25/311 [04:56<54:50, 11.51s/it]Loading train:   8%|▊         | 26/311 [05:07<54:53, 11.55s/it]Loading train:   9%|▊         | 27/311 [05:19<55:01, 11.62s/it]Loading train:   9%|▉         | 28/311 [05:31<54:57, 11.65s/it]Loading train:   9%|▉         | 29/311 [05:42<54:25, 11.58s/it]Loading train:  10%|▉         | 30/311 [05:53<53:04, 11.33s/it]Loading train:  10%|▉         | 31/311 [06:04<52:38, 11.28s/it]Loading train:  10%|█         | 32/311 [06:16<52:48, 11.36s/it]Loading train:  11%|█         | 33/311 [06:22<45:31,  9.82s/it]Loading train:  11%|█         | 34/311 [06:28<39:44,  8.61s/it]Loading train:  11%|█▏        | 35/311 [06:34<36:16,  7.88s/it]Loading train:  12%|█▏        | 36/311 [06:40<33:17,  7.27s/it]Loading train:  12%|█▏        | 37/311 [06:46<31:51,  6.98s/it]Loading train:  12%|█▏        | 38/311 [06:52<30:57,  6.80s/it]Loading train:  13%|█▎        | 39/311 [06:59<30:00,  6.62s/it]Loading train:  13%|█▎        | 40/311 [07:05<29:17,  6.48s/it]Loading train:  13%|█▎        | 41/311 [07:11<28:46,  6.39s/it]Loading train:  14%|█▎        | 42/311 [07:17<28:30,  6.36s/it]Loading train:  14%|█▍        | 43/311 [07:23<28:10,  6.31s/it]Loading train:  14%|█▍        | 44/311 [07:30<27:54,  6.27s/it]Loading train:  14%|█▍        | 45/311 [07:36<27:37,  6.23s/it]Loading train:  15%|█▍        | 46/311 [07:42<27:51,  6.31s/it]Loading train:  15%|█▌        | 47/311 [07:48<27:41,  6.29s/it]Loading train:  15%|█▌        | 48/311 [07:54<27:06,  6.18s/it]Loading train:  16%|█▌        | 49/311 [08:00<26:30,  6.07s/it]Loading train:  16%|█▌        | 50/311 [08:06<26:36,  6.12s/it]Loading train:  16%|█▋        | 51/311 [08:14<28:18,  6.53s/it]Loading train:  17%|█▋        | 52/311 [08:21<29:13,  6.77s/it]Loading train:  17%|█▋        | 53/311 [08:28<29:38,  6.89s/it]Loading train:  17%|█▋        | 54/311 [08:35<29:35,  6.91s/it]Loading train:  18%|█▊        | 55/311 [08:42<29:37,  6.94s/it]Loading train:  18%|█▊        | 56/311 [08:49<29:26,  6.93s/it]Loading train:  18%|█▊        | 57/311 [08:55<27:58,  6.61s/it]Loading train:  19%|█▊        | 58/311 [09:01<27:10,  6.44s/it]Loading train:  19%|█▉        | 59/311 [09:07<26:09,  6.23s/it]Loading train:  19%|█▉        | 60/311 [09:13<25:29,  6.09s/it]Loading train:  20%|█▉        | 61/311 [09:18<24:38,  5.91s/it]Loading train:  20%|█▉        | 62/311 [09:24<23:51,  5.75s/it]Loading train:  20%|██        | 63/311 [09:30<23:59,  5.81s/it]Loading train:  21%|██        | 64/311 [09:35<23:55,  5.81s/it]Loading train:  21%|██        | 65/311 [09:41<23:20,  5.69s/it]Loading train:  21%|██        | 66/311 [09:47<23:23,  5.73s/it]Loading train:  22%|██▏       | 67/311 [09:52<23:06,  5.68s/it]Loading train:  22%|██▏       | 68/311 [09:58<22:56,  5.66s/it]Loading train:  22%|██▏       | 69/311 [10:03<22:46,  5.65s/it]Loading train:  23%|██▎       | 70/311 [10:09<22:30,  5.60s/it]Loading train:  23%|██▎       | 71/311 [10:14<22:03,  5.51s/it]Loading train:  23%|██▎       | 72/311 [10:20<21:56,  5.51s/it]Loading train:  23%|██▎       | 73/311 [10:25<21:53,  5.52s/it]Loading train:  24%|██▍       | 74/311 [10:31<21:53,  5.54s/it]Loading train:  24%|██▍       | 75/311 [10:36<21:43,  5.52s/it]Loading train:  24%|██▍       | 76/311 [10:42<21:35,  5.51s/it]Loading train:  25%|██▍       | 77/311 [10:48<21:42,  5.57s/it]Loading train:  25%|██▌       | 78/311 [10:53<21:37,  5.57s/it]Loading train:  25%|██▌       | 79/311 [10:59<21:22,  5.53s/it]Loading train:  26%|██▌       | 80/311 [11:04<21:07,  5.49s/it]Loading train:  26%|██▌       | 81/311 [11:10<21:10,  5.52s/it]Loading train:  26%|██▋       | 82/311 [11:15<20:38,  5.41s/it]Loading train:  27%|██▋       | 83/311 [11:20<20:32,  5.41s/it]Loading train:  27%|██▋       | 84/311 [11:26<20:41,  5.47s/it]Loading train:  27%|██▋       | 85/311 [11:31<20:05,  5.34s/it]Loading train:  28%|██▊       | 86/311 [11:36<19:37,  5.23s/it]Loading train:  28%|██▊       | 87/311 [11:41<19:12,  5.14s/it]Loading train:  28%|██▊       | 88/311 [11:46<19:09,  5.15s/it]Loading train:  29%|██▊       | 89/311 [11:51<18:55,  5.11s/it]Loading train:  29%|██▉       | 90/311 [11:56<18:48,  5.11s/it]Loading train:  29%|██▉       | 91/311 [12:01<18:40,  5.09s/it]Loading train:  30%|██▉       | 92/311 [12:06<18:18,  5.02s/it]Loading train:  30%|██▉       | 93/311 [12:11<18:18,  5.04s/it]Loading train:  30%|███       | 94/311 [12:16<18:09,  5.02s/it]Loading train:  31%|███       | 95/311 [12:21<18:07,  5.03s/it]Loading train:  31%|███       | 96/311 [12:26<17:56,  5.01s/it]Loading train:  31%|███       | 97/311 [12:31<17:48,  4.99s/it]Loading train:  32%|███▏      | 98/311 [12:36<17:39,  4.98s/it]Loading train:  32%|███▏      | 99/311 [12:41<17:51,  5.05s/it]Loading train:  32%|███▏      | 100/311 [12:46<17:50,  5.07s/it]Loading train:  32%|███▏      | 101/311 [12:51<17:37,  5.04s/it]Loading train:  33%|███▎      | 102/311 [12:56<17:37,  5.06s/it]Loading train:  33%|███▎      | 103/311 [13:01<17:45,  5.12s/it]Loading train:  33%|███▎      | 104/311 [13:07<17:38,  5.11s/it]Loading train:  34%|███▍      | 105/311 [13:12<17:42,  5.16s/it]Loading train:  34%|███▍      | 106/311 [13:17<17:30,  5.12s/it]Loading train:  34%|███▍      | 107/311 [13:22<17:21,  5.11s/it]Loading train:  35%|███▍      | 108/311 [13:27<17:03,  5.04s/it]Loading train:  35%|███▌      | 109/311 [13:32<16:51,  5.01s/it]Loading train:  35%|███▌      | 110/311 [13:37<16:31,  4.93s/it]Loading train:  36%|███▌      | 111/311 [13:42<16:40,  5.00s/it]Loading train:  36%|███▌      | 112/311 [13:47<16:35,  5.00s/it]Loading train:  36%|███▋      | 113/311 [13:52<16:41,  5.06s/it]Loading train:  37%|███▋      | 114/311 [14:01<20:33,  6.26s/it]Loading train:  37%|███▋      | 115/311 [14:10<23:24,  7.16s/it]Loading train:  37%|███▋      | 116/311 [14:20<25:23,  7.81s/it]Loading train:  38%|███▊      | 117/311 [14:29<26:24,  8.17s/it]Loading train:  38%|███▊      | 118/311 [14:38<27:13,  8.47s/it]Loading train:  38%|███▊      | 119/311 [14:47<27:35,  8.62s/it]Loading train:  39%|███▊      | 120/311 [14:55<27:31,  8.65s/it]Loading train:  39%|███▉      | 121/311 [15:04<27:25,  8.66s/it]Loading train:  39%|███▉      | 122/311 [15:13<27:44,  8.80s/it]Loading train:  40%|███▉      | 123/311 [15:22<27:56,  8.92s/it]Loading train:  40%|███▉      | 124/311 [15:31<27:54,  8.95s/it]Loading train:  40%|████      | 125/311 [15:40<27:49,  8.97s/it]Loading train:  41%|████      | 126/311 [15:50<28:00,  9.08s/it]Loading train:  41%|████      | 127/311 [15:59<28:15,  9.21s/it]Loading train:  41%|████      | 128/311 [16:09<28:19,  9.29s/it]Loading train:  41%|████▏     | 129/311 [16:18<28:02,  9.24s/it]Loading train:  42%|████▏     | 130/311 [16:27<28:04,  9.31s/it]Loading train:  42%|████▏     | 131/311 [16:37<27:47,  9.27s/it]Loading train:  42%|████▏     | 132/311 [16:41<23:33,  7.90s/it]Loading train:  43%|████▎     | 133/311 [16:46<20:29,  6.91s/it]Loading train:  43%|████▎     | 134/311 [16:50<18:19,  6.21s/it]Loading train:  43%|████▎     | 135/311 [16:55<16:46,  5.72s/it]Loading train:  44%|████▎     | 136/311 [17:00<15:48,  5.42s/it]Loading train:  44%|████▍     | 137/311 [17:04<14:43,  5.08s/it]Loading train:  44%|████▍     | 138/311 [17:09<14:09,  4.91s/it]Loading train:  45%|████▍     | 139/311 [17:13<13:54,  4.85s/it]Loading train:  45%|████▌     | 140/311 [17:18<13:41,  4.81s/it]Loading train:  45%|████▌     | 141/311 [17:22<13:21,  4.72s/it]Loading train:  46%|████▌     | 142/311 [17:27<13:03,  4.63s/it]Loading train:  46%|████▌     | 143/311 [17:32<12:57,  4.63s/it]Loading train:  46%|████▋     | 144/311 [17:36<12:53,  4.63s/it]Loading train:  47%|████▋     | 145/311 [17:41<13:00,  4.70s/it]Loading train:  47%|████▋     | 146/311 [17:46<12:50,  4.67s/it]Loading train:  47%|████▋     | 147/311 [17:50<12:49,  4.69s/it]Loading train:  48%|████▊     | 148/311 [17:55<12:48,  4.71s/it]Loading train:  48%|████▊     | 149/311 [18:00<12:35,  4.66s/it]Loading train:  48%|████▊     | 150/311 [18:05<13:10,  4.91s/it]Loading train:  49%|████▊     | 151/311 [18:11<13:59,  5.25s/it]Loading train:  49%|████▉     | 152/311 [18:17<14:03,  5.31s/it]Loading train:  49%|████▉     | 153/311 [18:22<14:20,  5.45s/it]Loading train:  50%|████▉     | 154/311 [18:28<14:38,  5.59s/it]Loading train:  50%|████▉     | 155/311 [18:34<14:32,  5.59s/it]Loading train:  50%|█████     | 156/311 [18:39<14:10,  5.48s/it]Loading train:  50%|█████     | 157/311 [18:45<14:11,  5.53s/it]Loading train:  51%|█████     | 158/311 [18:50<14:09,  5.55s/it]Loading train:  51%|█████     | 159/311 [18:56<14:12,  5.61s/it]Loading train:  51%|█████▏    | 160/311 [19:02<14:26,  5.74s/it]Loading train:  52%|█████▏    | 161/311 [19:08<14:05,  5.64s/it]Loading train:  52%|█████▏    | 162/311 [19:13<13:58,  5.63s/it]Loading train:  52%|█████▏    | 163/311 [19:19<14:00,  5.68s/it]Loading train:  53%|█████▎    | 164/311 [19:25<14:03,  5.74s/it]Loading train:  53%|█████▎    | 165/311 [19:31<13:55,  5.72s/it]Loading train:  53%|█████▎    | 166/311 [19:36<13:37,  5.64s/it]Loading train:  54%|█████▎    | 167/311 [19:41<13:26,  5.60s/it]Loading train:  54%|█████▍    | 168/311 [19:47<13:15,  5.56s/it]Loading train:  54%|█████▍    | 169/311 [19:52<13:05,  5.53s/it]Loading train:  55%|█████▍    | 170/311 [19:58<13:02,  5.55s/it]Loading train:  55%|█████▍    | 171/311 [20:04<12:59,  5.57s/it]Loading train:  55%|█████▌    | 172/311 [20:09<12:54,  5.57s/it]Loading train:  56%|█████▌    | 173/311 [20:15<12:49,  5.58s/it]Loading train:  56%|█████▌    | 174/311 [20:20<12:48,  5.61s/it]Loading train:  56%|█████▋    | 175/311 [20:26<12:43,  5.61s/it]Loading train:  57%|█████▋    | 176/311 [20:32<12:33,  5.58s/it]Loading train:  57%|█████▋    | 177/311 [20:37<12:23,  5.55s/it]Loading train:  57%|█████▋    | 178/311 [20:43<12:16,  5.54s/it]Loading train:  58%|█████▊    | 179/311 [20:48<12:04,  5.49s/it]Loading train:  58%|█████▊    | 180/311 [20:54<12:05,  5.54s/it]Loading train:  58%|█████▊    | 181/311 [20:59<11:59,  5.54s/it]Loading train:  59%|█████▊    | 182/311 [21:05<11:55,  5.55s/it]Loading train:  59%|█████▉    | 183/311 [21:10<11:54,  5.58s/it]Loading train:  59%|█████▉    | 184/311 [21:15<11:24,  5.39s/it]Loading train:  59%|█████▉    | 185/311 [21:20<11:09,  5.31s/it]Loading train:  60%|█████▉    | 186/311 [21:26<11:07,  5.34s/it]Loading train:  60%|██████    | 187/311 [21:31<10:55,  5.29s/it]Loading train:  60%|██████    | 188/311 [21:36<10:44,  5.24s/it]Loading train:  61%|██████    | 189/311 [21:41<10:39,  5.24s/it]Loading train:  61%|██████    | 190/311 [21:47<10:30,  5.21s/it]Loading train:  61%|██████▏   | 191/311 [21:52<10:20,  5.17s/it]Loading train:  62%|██████▏   | 192/311 [21:57<10:20,  5.21s/it]Loading train:  62%|██████▏   | 193/311 [22:02<10:22,  5.28s/it]Loading train:  62%|██████▏   | 194/311 [22:08<10:14,  5.25s/it]Loading train:  63%|██████▎   | 195/311 [22:13<10:04,  5.21s/it]Loading train:  63%|██████▎   | 196/311 [22:18<10:02,  5.24s/it]Loading train:  63%|██████▎   | 197/311 [22:23<09:51,  5.18s/it]Loading train:  64%|██████▎   | 198/311 [22:28<09:50,  5.22s/it]Loading train:  64%|██████▍   | 199/311 [22:33<09:38,  5.17s/it]Loading train:  64%|██████▍   | 200/311 [22:38<09:28,  5.12s/it]Loading train:  65%|██████▍   | 201/311 [22:44<09:29,  5.17s/it]Loading train:  65%|██████▍   | 202/311 [22:49<09:26,  5.20s/it]Loading train:  65%|██████▌   | 203/311 [22:54<09:23,  5.21s/it]Loading train:  66%|██████▌   | 204/311 [23:00<09:24,  5.27s/it]Loading train:  66%|██████▌   | 205/311 [23:05<09:18,  5.27s/it]Loading train:  66%|██████▌   | 206/311 [23:10<09:10,  5.24s/it]Loading train:  67%|██████▋   | 207/311 [23:15<09:08,  5.27s/it]Loading train:  67%|██████▋   | 208/311 [23:21<08:59,  5.23s/it]Loading train:  67%|██████▋   | 209/311 [23:26<08:54,  5.24s/it]Loading train:  68%|██████▊   | 210/311 [23:31<08:51,  5.26s/it]Loading train:  68%|██████▊   | 211/311 [23:36<08:47,  5.27s/it]Loading train:  68%|██████▊   | 212/311 [23:42<08:40,  5.25s/it]Loading train:  68%|██████▊   | 213/311 [23:51<10:36,  6.50s/it]Loading train:  69%|██████▉   | 214/311 [24:01<11:59,  7.42s/it]Loading train:  69%|██████▉   | 215/311 [24:10<12:45,  7.97s/it]Loading train:  69%|██████▉   | 216/311 [24:19<13:20,  8.42s/it]Loading train:  70%|██████▉   | 217/311 [24:29<13:34,  8.67s/it]Loading train:  70%|███████   | 218/311 [24:38<13:40,  8.83s/it]Loading train:  70%|███████   | 219/311 [24:47<13:47,  8.99s/it]Loading train:  71%|███████   | 220/311 [24:57<13:49,  9.11s/it]Loading train:  71%|███████   | 221/311 [25:06<13:39,  9.10s/it]Loading train:  71%|███████▏  | 222/311 [25:15<13:37,  9.19s/it]Loading train:  72%|███████▏  | 223/311 [25:24<13:28,  9.19s/it]Loading train:  72%|███████▏  | 224/311 [25:34<13:24,  9.24s/it]Loading train:  72%|███████▏  | 225/311 [25:43<13:15,  9.24s/it]Loading train:  73%|███████▎  | 226/311 [25:52<12:59,  9.18s/it]Loading train:  73%|███████▎  | 227/311 [26:01<12:56,  9.24s/it]Loading train:  73%|███████▎  | 228/311 [26:11<12:57,  9.37s/it]Loading train:  74%|███████▎  | 229/311 [26:20<12:47,  9.36s/it]Loading train:  74%|███████▍  | 230/311 [26:30<12:37,  9.35s/it]Loading train:  74%|███████▍  | 231/311 [26:34<10:40,  8.00s/it]Loading train:  75%|███████▍  | 232/311 [26:39<09:14,  7.02s/it]Loading train:  75%|███████▍  | 233/311 [26:44<08:14,  6.33s/it]Loading train:  75%|███████▌  | 234/311 [26:49<07:37,  5.94s/it]Loading train:  76%|███████▌  | 235/311 [26:53<06:59,  5.52s/it]Loading train:  76%|███████▌  | 236/311 [26:58<06:30,  5.20s/it]Loading train:  76%|███████▌  | 237/311 [27:03<06:17,  5.10s/it]Loading train:  77%|███████▋  | 238/311 [27:07<06:00,  4.94s/it]Loading train:  77%|███████▋  | 239/311 [27:12<05:51,  4.88s/it]Loading train:  77%|███████▋  | 240/311 [27:17<05:44,  4.85s/it]Loading train:  77%|███████▋  | 241/311 [27:22<05:36,  4.81s/it]Loading train:  78%|███████▊  | 242/311 [27:26<05:28,  4.76s/it]Loading train:  78%|███████▊  | 243/311 [27:31<05:25,  4.79s/it]Loading train:  78%|███████▊  | 244/311 [27:36<05:18,  4.75s/it]Loading train:  79%|███████▉  | 245/311 [27:40<05:09,  4.69s/it]Loading train:  79%|███████▉  | 246/311 [27:45<05:06,  4.72s/it]Loading train:  79%|███████▉  | 247/311 [27:50<05:01,  4.70s/it]Loading train:  80%|███████▉  | 248/311 [27:54<04:51,  4.63s/it]Loading train:  80%|████████  | 249/311 [28:00<05:06,  4.94s/it]Loading train:  80%|████████  | 250/311 [28:06<05:19,  5.23s/it]Loading train:  81%|████████  | 251/311 [28:11<05:20,  5.34s/it]Loading train:  81%|████████  | 252/311 [28:17<05:21,  5.45s/it]Loading train:  81%|████████▏ | 253/311 [28:23<05:27,  5.64s/it]Loading train:  82%|████████▏ | 254/311 [28:29<05:20,  5.63s/it]Loading train:  82%|████████▏ | 255/311 [28:34<05:15,  5.63s/it]Loading train:  82%|████████▏ | 256/311 [28:40<05:12,  5.69s/it]Loading train:  83%|████████▎ | 257/311 [28:46<05:10,  5.75s/it]Loading train:  83%|████████▎ | 258/311 [28:52<05:06,  5.79s/it]Loading train:  83%|████████▎ | 259/311 [28:58<05:07,  5.91s/it]Loading train:  84%|████████▎ | 260/311 [29:04<04:57,  5.83s/it]Loading train:  84%|████████▍ | 261/311 [29:10<04:50,  5.81s/it]Loading train:  84%|████████▍ | 262/311 [29:15<04:42,  5.77s/it]Loading train:  85%|████████▍ | 263/311 [29:21<04:34,  5.73s/it]Loading train:  85%|████████▍ | 264/311 [29:27<04:29,  5.73s/it]Loading train:  85%|████████▌ | 265/311 [29:32<04:19,  5.64s/it]Loading train:  86%|████████▌ | 266/311 [29:38<04:12,  5.61s/it]Loading train:  86%|████████▌ | 267/311 [29:43<04:06,  5.59s/it]Loading train:  86%|████████▌ | 268/311 [29:49<04:01,  5.62s/it]Loading train:  86%|████████▋ | 269/311 [29:54<03:50,  5.48s/it]Loading train:  87%|████████▋ | 270/311 [30:00<03:46,  5.53s/it]Loading train:  87%|████████▋ | 271/311 [30:05<03:41,  5.54s/it]Loading train:  87%|████████▋ | 272/311 [30:11<03:37,  5.57s/it]Loading train:  88%|████████▊ | 273/311 [30:17<03:33,  5.63s/it]Loading train:  88%|████████▊ | 274/311 [30:23<03:32,  5.74s/it]Loading train:  88%|████████▊ | 275/311 [30:28<03:26,  5.74s/it]Loading train:  89%|████████▊ | 276/311 [30:34<03:22,  5.77s/it]Loading train:  89%|████████▉ | 277/311 [30:40<03:12,  5.66s/it]Loading train:  89%|████████▉ | 278/311 [30:45<03:07,  5.67s/it]Loading train:  90%|████████▉ | 279/311 [30:51<03:03,  5.74s/it]Loading train:  90%|█████████ | 280/311 [30:57<02:56,  5.70s/it]Loading train:  90%|█████████ | 281/311 [31:02<02:50,  5.69s/it]Loading train:  91%|█████████ | 282/311 [31:08<02:45,  5.69s/it]Loading train:  91%|█████████ | 283/311 [31:13<02:35,  5.54s/it]Loading train:  91%|█████████▏| 284/311 [31:19<02:27,  5.45s/it]Loading train:  92%|█████████▏| 285/311 [31:24<02:19,  5.36s/it]Loading train:  92%|█████████▏| 286/311 [31:29<02:10,  5.22s/it]Loading train:  92%|█████████▏| 287/311 [31:34<02:05,  5.22s/it]Loading train:  93%|█████████▎| 288/311 [31:39<02:01,  5.29s/it]Loading train:  93%|█████████▎| 289/311 [31:44<01:55,  5.23s/it]Loading train:  93%|█████████▎| 290/311 [31:50<01:49,  5.22s/it]Loading train:  94%|█████████▎| 291/311 [31:55<01:43,  5.15s/it]Loading train:  94%|█████████▍| 292/311 [32:00<01:37,  5.12s/it]Loading train:  94%|█████████▍| 293/311 [32:05<01:33,  5.20s/it]Loading train:  95%|█████████▍| 294/311 [32:10<01:28,  5.20s/it]Loading train:  95%|█████████▍| 295/311 [32:15<01:22,  5.14s/it]Loading train:  95%|█████████▌| 296/311 [32:20<01:16,  5.11s/it]Loading train:  95%|█████████▌| 297/311 [32:26<01:12,  5.20s/it]Loading train:  96%|█████████▌| 298/311 [32:31<01:07,  5.16s/it]Loading train:  96%|█████████▌| 299/311 [32:36<01:02,  5.19s/it]Loading train:  96%|█████████▋| 300/311 [32:41<00:58,  5.29s/it]Loading train:  97%|█████████▋| 301/311 [32:47<00:52,  5.25s/it]Loading train:  97%|█████████▋| 302/311 [32:52<00:47,  5.28s/it]Loading train:  97%|█████████▋| 303/311 [32:57<00:42,  5.29s/it]Loading train:  98%|█████████▊| 304/311 [33:02<00:36,  5.26s/it]Loading train:  98%|█████████▊| 305/311 [33:08<00:31,  5.19s/it]Loading train:  98%|█████████▊| 306/311 [33:13<00:26,  5.25s/it]Loading train:  99%|█████████▊| 307/311 [33:18<00:20,  5.23s/it]Loading train:  99%|█████████▉| 308/311 [33:23<00:15,  5.19s/it]Loading train:  99%|█████████▉| 309/311 [33:29<00:10,  5.24s/it]Loading train: 100%|█████████▉| 310/311 [33:34<00:05,  5.21s/it]Loading train: 100%|██████████| 311/311 [33:39<00:00,  5.24s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/311 [00:00<00:04, 64.21it/s]concatenating: train:   6%|▌         | 18/311 [00:00<00:04, 72.71it/s]concatenating: train:  10%|█         | 32/311 [00:00<00:03, 84.53it/s]concatenating: train:  18%|█▊        | 56/311 [00:00<00:02, 104.82it/s]concatenating: train:  24%|██▍       | 74/311 [00:00<00:01, 119.83it/s]concatenating: train:  30%|███       | 94/311 [00:00<00:01, 135.80it/s]concatenating: train:  37%|███▋      | 115/311 [00:00<00:01, 148.07it/s]concatenating: train:  46%|████▌     | 142/311 [00:00<00:00, 170.74it/s]concatenating: train:  52%|█████▏    | 163/311 [00:00<00:00, 179.97it/s]concatenating: train:  59%|█████▉    | 183/311 [00:01<00:00, 185.38it/s]concatenating: train:  68%|██████▊   | 212/311 [00:01<00:00, 199.42it/s]concatenating: train:  75%|███████▌  | 234/311 [00:01<00:00, 203.25it/s]concatenating: train:  82%|████████▏ | 256/311 [00:01<00:00, 190.72it/s]concatenating: train:  89%|████████▉ | 278/311 [00:01<00:00, 198.62it/s]concatenating: train:  96%|█████████▌| 299/311 [00:01<00:00, 196.01it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 189.97it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:34, 11.53s/it]Loading test:  50%|█████     | 2/4 [00:22<00:22, 11.38s/it]Loading test:  75%|███████▌  | 3/4 [00:34<00:11, 11.68s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.71s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 60.79it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 23:23:29.846271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 23:23:29.846409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 23:23:29.846426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 23:23:29.846435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 23:23:29.846870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 26, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [5.88176395e-02 2.85713643e-02 1.22080201e-01 1.04952659e-02
 3.15779544e-02 5.46270752e-03 7.23535399e-02 1.13294426e-01
 7.88079565e-02 1.27907394e-02 2.93002722e-01 1.72516551e-01
 2.28932584e-04]
Train on 20529 samples, validate on 262 samples
Epoch 1/300
 - 23s - loss: 11147.2571 - acc: 0.8699 - mDice: 0.2263 - val_loss: 5193.6344 - val_acc: 0.9014 - val_mDice: 0.3672

Epoch 00001: val_mDice improved from -inf to 0.36718, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 4581.3440 - acc: 0.9040 - mDice: 0.4210 - val_loss: 3338.2360 - val_acc: 0.9109 - val_mDice: 0.4922

Epoch 00002: val_mDice improved from 0.36718 to 0.49223, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 3459.8020 - acc: 0.9169 - mDice: 0.5095 - val_loss: 2665.7345 - val_acc: 0.9200 - val_mDice: 0.5578

Epoch 00003: val_mDice improved from 0.49223 to 0.55782, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 16s - loss: 2909.1822 - acc: 0.9251 - mDice: 0.5628 - val_loss: 2352.0978 - val_acc: 0.9297 - val_mDice: 0.5955

Epoch 00004: val_mDice improved from 0.55782 to 0.59551, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 2573.1561 - acc: 0.9304 - mDice: 0.5995 - val_loss: 2110.4898 - val_acc: 0.9346 - val_mDice: 0.6279

Epoch 00005: val_mDice improved from 0.59551 to 0.62794, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 2394.6577 - acc: 0.9338 - mDice: 0.6220 - val_loss: 2018.2771 - val_acc: 0.9402 - val_mDice: 0.6404

Epoch 00006: val_mDice improved from 0.62794 to 0.64045, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 2191.6984 - acc: 0.9371 - mDice: 0.6447 - val_loss: 1970.7972 - val_acc: 0.9403 - val_mDice: 0.6473

Epoch 00007: val_mDice improved from 0.64045 to 0.64732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 16s - loss: 2054.9939 - acc: 0.9393 - mDice: 0.6617 - val_loss: 1919.9592 - val_acc: 0.9413 - val_mDice: 0.6552

Epoch 00008: val_mDice improved from 0.64732 to 0.65515, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 1952.3686 - acc: 0.9410 - mDice: 0.6750 - val_loss: 1821.4117 - val_acc: 0.9446 - val_mDice: 0.6690

Epoch 00009: val_mDice improved from 0.65515 to 0.66900, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 16s - loss: 1867.4036 - acc: 0.9427 - mDice: 0.6865 - val_loss: 1773.3735 - val_acc: 0.9461 - val_mDice: 0.6758

Epoch 00010: val_mDice improved from 0.66900 to 0.67578, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 14s - loss: 1799.5002 - acc: 0.9439 - mDice: 0.6956 - val_loss: 1788.4051 - val_acc: 0.9469 - val_mDice: 0.6738

Epoch 00011: val_mDice did not improve from 0.67578
Epoch 12/300
 - 15s - loss: 1738.5867 - acc: 0.9450 - mDice: 0.7042 - val_loss: 1828.9320 - val_acc: 0.9463 - val_mDice: 0.6681

Epoch 00012: val_mDice did not improve from 0.67578
Epoch 13/300
 - 14s - loss: 1668.2861 - acc: 0.9461 - mDice: 0.7136 - val_loss: 1727.1559 - val_acc: 0.9482 - val_mDice: 0.6837

Epoch 00013: val_mDice improved from 0.67578 to 0.68370, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 16s - loss: 1628.7940 - acc: 0.9471 - mDice: 0.7193 - val_loss: 1743.1242 - val_acc: 0.9481 - val_mDice: 0.6805

Epoch 00014: val_mDice did not improve from 0.68370
Epoch 15/300
 - 14s - loss: 1577.0567 - acc: 0.9479 - mDice: 0.7265 - val_loss: 1761.0869 - val_acc: 0.9481 - val_mDice: 0.6771

Epoch 00015: val_mDice did not improve from 0.68370
Epoch 16/300
 - 16s - loss: 1536.2115 - acc: 0.9487 - mDice: 0.7324 - val_loss: 1703.3660 - val_acc: 0.9498 - val_mDice: 0.6868

Epoch 00016: val_mDice improved from 0.68370 to 0.68681, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 14s - loss: 1505.3875 - acc: 0.9494 - mDice: 0.7375 - val_loss: 1700.7141 - val_acc: 0.9513 - val_mDice: 0.6869

Epoch 00017: val_mDice improved from 0.68681 to 0.68692, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 15s - loss: 1494.0395 - acc: 0.9502 - mDice: 0.7430 - val_loss: 1762.7410 - val_acc: 0.9486 - val_mDice: 0.6788

Epoch 00018: val_mDice did not improve from 0.68692
Epoch 19/300
 - 14s - loss: 1435.0319 - acc: 0.9508 - mDice: 0.7473 - val_loss: 1737.3901 - val_acc: 0.9503 - val_mDice: 0.6821

Epoch 00019: val_mDice did not improve from 0.68692
Epoch 20/300
 - 16s - loss: 1407.6076 - acc: 0.9512 - mDice: 0.7516 - val_loss: 1665.7902 - val_acc: 0.9526 - val_mDice: 0.6924

Epoch 00020: val_mDice improved from 0.68692 to 0.69240, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 14s - loss: 1372.8954 - acc: 0.9519 - mDice: 0.7565 - val_loss: 1641.5446 - val_acc: 0.9542 - val_mDice: 0.6970

Epoch 00021: val_mDice improved from 0.69240 to 0.69703, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 16s - loss: 1355.6842 - acc: 0.9522 - mDice: 0.7592 - val_loss: 1730.1555 - val_acc: 0.9510 - val_mDice: 0.6834

Epoch 00022: val_mDice did not improve from 0.69703
Epoch 23/300
 - 14s - loss: 1333.9350 - acc: 0.9528 - mDice: 0.7627 - val_loss: 1646.3570 - val_acc: 0.9536 - val_mDice: 0.6966

Epoch 00023: val_mDice did not improve from 0.69703
Epoch 24/300
 - 15s - loss: 1303.3869 - acc: 0.9533 - mDice: 0.7672 - val_loss: 1633.0422 - val_acc: 0.9551 - val_mDice: 0.6984

Epoch 00024: val_mDice improved from 0.69703 to 0.69838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 14s - loss: 1285.4414 - acc: 0.9538 - mDice: 0.7701 - val_loss: 1666.8953 - val_acc: 0.9558 - val_mDice: 0.6937

Epoch 00025: val_mDice did not improve from 0.69838
Epoch 26/300
 - 16s - loss: 1263.6847 - acc: 0.9541 - mDice: 0.7734 - val_loss: 1623.2552 - val_acc: 0.9553 - val_mDice: 0.6992

Epoch 00026: val_mDice improved from 0.69838 to 0.69917, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 14s - loss: 1248.6357 - acc: 0.9545 - mDice: 0.7757 - val_loss: 1675.5103 - val_acc: 0.9561 - val_mDice: 0.6930

Epoch 00027: val_mDice did not improve from 0.69917
Epoch 28/300
 - 16s - loss: 1227.6074 - acc: 0.9549 - mDice: 0.7790 - val_loss: 1640.7813 - val_acc: 0.9558 - val_mDice: 0.6971

Epoch 00028: val_mDice did not improve from 0.69917
Epoch 29/300
 - 14s - loss: 1207.0433 - acc: 0.9553 - mDice: 0.7822 - val_loss: 1622.2567 - val_acc: 0.9568 - val_mDice: 0.7002

Epoch 00029: val_mDice improved from 0.69917 to 0.70022, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 16s - loss: 1198.5581 - acc: 0.9554 - mDice: 0.7836 - val_loss: 1632.8160 - val_acc: 0.9580 - val_mDice: 0.6998

Epoch 00030: val_mDice did not improve from 0.70022
Epoch 31/300
 - 14s - loss: 1176.4453 - acc: 0.9559 - mDice: 0.7870 - val_loss: 1582.8898 - val_acc: 0.9548 - val_mDice: 0.7063

Epoch 00031: val_mDice improved from 0.70022 to 0.70626, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 16s - loss: 1161.8527 - acc: 0.9562 - mDice: 0.7893 - val_loss: 1610.2029 - val_acc: 0.9553 - val_mDice: 0.7023

Epoch 00032: val_mDice did not improve from 0.70626
Epoch 33/300
 - 14s - loss: 1154.1732 - acc: 0.9564 - mDice: 0.7906 - val_loss: 1684.2650 - val_acc: 0.9553 - val_mDice: 0.6917

Epoch 00033: val_mDice did not improve from 0.70626
Epoch 34/300
 - 15s - loss: 1136.7478 - acc: 0.9568 - mDice: 0.7933 - val_loss: 1678.6310 - val_acc: 0.9546 - val_mDice: 0.6921

Epoch 00034: val_mDice did not improve from 0.70626
Epoch 35/300
 - 14s - loss: 1129.0641 - acc: 0.9569 - mDice: 0.7946 - val_loss: 1638.0176 - val_acc: 0.9578 - val_mDice: 0.6975

Epoch 00035: val_mDice did not improve from 0.70626
Epoch 36/300
 - 16s - loss: 1109.0698 - acc: 0.9572 - mDice: 0.7977 - val_loss: 1706.6771 - val_acc: 0.9556 - val_mDice: 0.6879

Epoch 00036: val_mDice did not improve from 0.70626
Epoch 37/300
 - 14s - loss: 1096.2195 - acc: 0.9575 - mDice: 0.7998 - val_loss: 1632.6539 - val_acc: 0.9550 - val_mDice: 0.6983

Epoch 00037: val_mDice did not improve from 0.70626
Epoch 38/300
 - 15s - loss: 1091.4839 - acc: 0.9576 - mDice: 0.8006 - val_loss: 1626.6972 - val_acc: 0.9566 - val_mDice: 0.7007

Epoch 00038: val_mDice did not improve from 0.70626
Epoch 39/300
 - 14s - loss: 1090.6340 - acc: 0.9577 - mDice: 0.8010 - val_loss: 1622.5260 - val_acc: 0.9571 - val_mDice: 0.7011

Epoch 00039: val_mDice did not improve from 0.70626
Epoch 40/300
 - 15s - loss: 1067.4093 - acc: 0.9580 - mDice: 0.8044 - val_loss: 1633.1688 - val_acc: 0.9596 - val_mDice: 0.6993

Epoch 00040: val_mDice did not improve from 0.70626
Epoch 41/300
 - 14s - loss: 1060.4249 - acc: 0.9582 - mDice: 0.8056 - val_loss: 1609.4080 - val_acc: 0.9565 - val_mDice: 0.7016

Epoch 00041: val_mDice did not improve from 0.70626
Epoch 42/300
 - 15s - loss: 1057.0093 - acc: 0.9582 - mDice: 0.8062 - val_loss: 1588.8852 - val_acc: 0.9587 - val_mDice: 0.7067

Epoch 00042: val_mDice improved from 0.70626 to 0.70672, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 14s - loss: 1038.6842 - acc: 0.9585 - mDice: 0.8091 - val_loss: 1592.8287 - val_acc: 0.9589 - val_mDice: 0.7054

Epoch 00043: val_mDice did not improve from 0.70672
Epoch 44/300
 - 15s - loss: 1029.2382 - acc: 0.9587 - mDice: 0.8106 - val_loss: 1612.6224 - val_acc: 0.9597 - val_mDice: 0.7037

Epoch 00044: val_mDice did not improve from 0.70672
Epoch 45/300
 - 14s - loss: 1021.8641 - acc: 0.9589 - mDice: 0.8121 - val_loss: 1630.9409 - val_acc: 0.9594 - val_mDice: 0.7007

Epoch 00045: val_mDice did not improve from 0.70672
Epoch 46/300
 - 15s - loss: 1013.3085 - acc: 0.9589 - mDice: 0.8132 - val_loss: 1684.4758 - val_acc: 0.9593 - val_mDice: 0.6938

Epoch 00046: val_mDice did not improve from 0.70672
Epoch 47/300
 - 14s - loss: 1009.6483 - acc: 0.9590 - mDice: 0.8139 - val_loss: 1611.3881 - val_acc: 0.9584 - val_mDice: 0.7035

Epoch 00047: val_mDice did not improve from 0.70672
Epoch 48/300
 - 15s - loss: 997.6882 - acc: 0.9593 - mDice: 0.8161 - val_loss: 1667.6084 - val_acc: 0.9577 - val_mDice: 0.6970

Epoch 00048: val_mDice did not improve from 0.70672
Epoch 49/300
 - 14s - loss: 999.1922 - acc: 0.9592 - mDice: 0.8156 - val_loss: 1672.7416 - val_acc: 0.9585 - val_mDice: 0.6944

Epoch 00049: val_mDice did not improve from 0.70672
Epoch 50/300
 - 15s - loss: 983.0062 - acc: 0.9595 - mDice: 0.8183 - val_loss: 1651.9711 - val_acc: 0.9605 - val_mDice: 0.6991

Epoch 00050: val_mDice did not improve from 0.70672
Epoch 51/300
 - 14s - loss: 976.4012 - acc: 0.9597 - mDice: 0.8193 - val_loss: 1615.3497 - val_acc: 0.9590 - val_mDice: 0.7028

Epoch 00051: val_mDice did not improve from 0.70672
Epoch 52/300
 - 15s - loss: 968.5690 - acc: 0.9598 - mDice: 0.8206 - val_loss: 1685.1892 - val_acc: 0.9567 - val_mDice: 0.6928

Epoch 00052: val_mDice did not improve from 0.70672
Epoch 53/300
 - 14s - loss: 961.5241 - acc: 0.9599 - mDice: 0.8218 - val_loss: 1798.2641 - val_acc: 0.9578 - val_mDice: 0.6791

Epoch 00053: val_mDice did not improve from 0.70672
Epoch 54/300
 - 15s - loss: 952.9175 - acc: 0.9600 - mDice: 0.8232 - val_loss: 1740.3155 - val_acc: 0.9582 - val_mDice: 0.6846

Epoch 00054: val_mDice did not improve from 0.70672
Epoch 55/300
 - 15s - loss: 945.1575 - acc: 0.9601 - mDice: 0.8245 - val_loss: 1619.5330 - val_acc: 0.9597 - val_mDice: 0.7024

Epoch 00055: val_mDice did not improve from 0.70672
Epoch 56/300
 - 15s - loss: 940.7337 - acc: 0.9602 - mDice: 0.8252 - val_loss: 1592.6392 - val_acc: 0.9595 - val_mDice: 0.7076

Epoch 00056: val_mDice improved from 0.70672 to 0.70762, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 57/300
 - 15s - loss: 934.8140 - acc: 0.9603 - mDice: 0.8263 - val_loss: 1660.0732 - val_acc: 0.9594 - val_mDice: 0.6971

Epoch 00057: val_mDice did not improve from 0.70762
Epoch 58/300
 - 15s - loss: 929.7101 - acc: 0.9603 - mDice: 0.8271 - val_loss: 1721.3351 - val_acc: 0.9588 - val_mDice: 0.6882

Epoch 00058: val_mDice did not improve from 0.70762
Epoch 59/300
 - 15s - loss: 931.2564 - acc: 0.9604 - mDice: 0.8269 - val_loss: 1587.8566 - val_acc: 0.9590 - val_mDice: 0.7079

Epoch 00059: val_mDice improved from 0.70762 to 0.70794, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 60/300
 - 15s - loss: 919.1646 - acc: 0.9606 - mDice: 0.8288 - val_loss: 1629.8858 - val_acc: 0.9592 - val_mDice: 0.7018

Epoch 00060: val_mDice did not improve from 0.70794
Epoch 61/300
 - 15s - loss: 915.1318 - acc: 0.9606 - mDice: 0.8295 - val_loss: 1614.2360 - val_acc: 0.9611 - val_mDice: 0.7033

Epoch 00061: val_mDice did not improve from 0.70794
Epoch 62/300
 - 15s - loss: 909.3775 - acc: 0.9607 - mDice: 0.8305 - val_loss: 1593.1338 - val_acc: 0.9580 - val_mDice: 0.7054

Epoch 00062: val_mDice did not improve from 0.70794
Epoch 63/300
 - 15s - loss: 908.0503 - acc: 0.9607 - mDice: 0.8307 - val_loss: 1714.4024 - val_acc: 0.9568 - val_mDice: 0.6885

Epoch 00063: val_mDice did not improve from 0.70794
Epoch 64/300
 - 15s - loss: 903.1085 - acc: 0.9608 - mDice: 0.8316 - val_loss: 1629.0395 - val_acc: 0.9592 - val_mDice: 0.7003

Epoch 00064: val_mDice did not improve from 0.70794
Epoch 65/300
 - 15s - loss: 899.9317 - acc: 0.9609 - mDice: 0.8321 - val_loss: 1559.2038 - val_acc: 0.9615 - val_mDice: 0.7116

Epoch 00065: val_mDice improved from 0.70794 to 0.71161, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 66/300
 - 15s - loss: 889.8149 - acc: 0.9610 - mDice: 0.8338 - val_loss: 1642.0118 - val_acc: 0.9612 - val_mDice: 0.7006

Epoch 00066: val_mDice did not improve from 0.71161
Epoch 67/300
 - 15s - loss: 879.6211 - acc: 0.9612 - mDice: 0.8354 - val_loss: 1569.7140 - val_acc: 0.9604 - val_mDice: 0.7096

Epoch 00067: val_mDice did not improve from 0.71161
Epoch 68/300
 - 14s - loss: 883.6272 - acc: 0.9612 - mDice: 0.8348 - val_loss: 1641.3492 - val_acc: 0.9603 - val_mDice: 0.6996

Epoch 00068: val_mDice did not improve from 0.71161
Epoch 69/300
 - 15s - loss: 880.2699 - acc: 0.9612 - mDice: 0.8354 - val_loss: 1607.9995 - val_acc: 0.9587 - val_mDice: 0.7051

Epoch 00069: val_mDice did not improve from 0.71161
Epoch 70/300
 - 15s - loss: 873.4935 - acc: 0.9613 - mDice: 0.8365 - val_loss: 1555.7131 - val_acc: 0.9597 - val_mDice: 0.7114

Epoch 00070: val_mDice did not improve from 0.71161
Epoch 71/300
 - 15s - loss: 866.1669 - acc: 0.9614 - mDice: 0.8378 - val_loss: 1582.5949 - val_acc: 0.9602 - val_mDice: 0.7068

Epoch 00071: val_mDice did not improve from 0.71161
Epoch 72/300
 - 15s - loss: 863.9953 - acc: 0.9614 - mDice: 0.8382 - val_loss: 1588.4103 - val_acc: 0.9606 - val_mDice: 0.7075

Epoch 00072: val_mDice did not improve from 0.71161
Epoch 73/300
 - 15s - loss: 865.0115 - acc: 0.9615 - mDice: 0.8382 - val_loss: 1611.9494 - val_acc: 0.9590 - val_mDice: 0.7018

Epoch 00073: val_mDice did not improve from 0.71161
Epoch 74/300
 - 15s - loss: 906.2379 - acc: 0.9604 - mDice: 0.8311 - val_loss: 1621.4077 - val_acc: 0.9584 - val_mDice: 0.7002

Epoch 00074: val_mDice did not improve from 0.71161
Epoch 75/300
 - 15s - loss: 858.3892 - acc: 0.9615 - mDice: 0.8391 - val_loss: 1618.7625 - val_acc: 0.9597 - val_mDice: 0.7037

Epoch 00075: val_mDice did not improve from 0.71161
Epoch 76/300
 - 16s - loss: 853.9122 - acc: 0.9616 - mDice: 0.8399 - val_loss: 1623.9332 - val_acc: 0.9599 - val_mDice: 0.7032

Epoch 00076: val_mDice did not improve from 0.71161
Epoch 77/300
 - 15s - loss: 853.1594 - acc: 0.9616 - mDice: 0.8401 - val_loss: 1600.1840 - val_acc: 0.9597 - val_mDice: 0.7063

Epoch 00077: val_mDice did not improve from 0.71161
Epoch 78/300
 - 16s - loss: 846.9474 - acc: 0.9617 - mDice: 0.8410 - val_loss: 1626.3700 - val_acc: 0.9574 - val_mDice: 0.7003

Epoch 00078: val_mDice did not improve from 0.71161
Epoch 79/300
 - 15s - loss: 844.1280 - acc: 0.9618 - mDice: 0.8415 - val_loss: 1588.5986 - val_acc: 0.9610 - val_mDice: 0.7073

Epoch 00079: val_mDice did not improve from 0.71161
Epoch 80/300
 - 15s - loss: 839.4806 - acc: 0.9618 - mDice: 0.8423 - val_loss: 1595.5751 - val_acc: 0.9589 - val_mDice: 0.7061

Epoch 00080: val_mDice did not improve from 0.71161
Epoch 81/300
 - 16s - loss: 837.7652 - acc: 0.9619 - mDice: 0.8426 - val_loss: 1571.8738 - val_acc: 0.9604 - val_mDice: 0.7094

Epoch 00081: val_mDice did not improve from 0.71161
Epoch 82/300
 - 15s - loss: 830.9429 - acc: 0.9619 - mDice: 0.8438 - val_loss: 1612.8390 - val_acc: 0.9597 - val_mDice: 0.7051

Epoch 00082: val_mDice did not improve from 0.71161
Epoch 83/300
 - 16s - loss: 828.4386 - acc: 0.9620 - mDice: 0.8442 - val_loss: 1586.0897 - val_acc: 0.9603 - val_mDice: 0.7089

Epoch 00083: val_mDice did not improve from 0.71161
Epoch 84/300
 - 15s - loss: 830.5262 - acc: 0.9619 - mDice: 0.8438 - val_loss: 1705.5930 - val_acc: 0.9593 - val_mDice: 0.6912

Epoch 00084: val_mDice did not improve from 0.71161
Epoch 85/300
 - 15s - loss: 825.5246 - acc: 0.9621 - mDice: 0.8448 - val_loss: 1624.7173 - val_acc: 0.9591 - val_mDice: 0.7031

Epoch 00085: val_mDice did not improve from 0.71161
Epoch 86/300
 - 16s - loss: 826.5593 - acc: 0.9620 - mDice: 0.8445 - val_loss: 1624.6174 - val_acc: 0.9602 - val_mDice: 0.7021

Epoch 00086: val_mDice did not improve from 0.71161
Epoch 87/300
 - 15s - loss: 819.2386 - acc: 0.9622 - mDice: 0.8458 - val_loss: 1624.3361 - val_acc: 0.9588 - val_mDice: 0.7003

Epoch 00087: val_mDice did not improve from 0.71161
Epoch 88/300
 - 16s - loss: 816.6204 - acc: 0.9623 - mDice: 0.8463 - val_loss: 1657.3939 - val_acc: 0.9599 - val_mDice: 0.6986

Epoch 00088: val_mDice did not improve from 0.71161
Epoch 89/300
 - 15s - loss: 813.9270 - acc: 0.9622 - mDice: 0.8467 - val_loss: 1598.0452 - val_acc: 0.9604 - val_mDice: 0.7057

Epoch 00089: val_mDice did not improve from 0.71161
Epoch 90/300
 - 16s - loss: 813.8005 - acc: 0.9622 - mDice: 0.8471 - val_loss: 1737.6307 - val_acc: 0.9580 - val_mDice: 0.6875

Epoch 00090: val_mDice did not improve from 0.71161
Epoch 91/300
 - 16s - loss: 834.8924 - acc: 0.9620 - mDice: 0.8432 - val_loss: 1563.3979 - val_acc: 0.9598 - val_mDice: 0.7109

Epoch 00091: val_mDice did not improve from 0.71161
Epoch 92/300
 - 15s - loss: 809.8496 - acc: 0.9624 - mDice: 0.8474 - val_loss: 1550.6090 - val_acc: 0.9606 - val_mDice: 0.7137

Epoch 00092: val_mDice improved from 0.71161 to 0.71371, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 93/300
 - 16s - loss: 809.4166 - acc: 0.9623 - mDice: 0.8475 - val_loss: 1634.3575 - val_acc: 0.9596 - val_mDice: 0.6989

Epoch 00093: val_mDice did not improve from 0.71371
Epoch 94/300
 - 15s - loss: 808.8108 - acc: 0.9623 - mDice: 0.8477 - val_loss: 1623.1456 - val_acc: 0.9611 - val_mDice: 0.7047

Epoch 00094: val_mDice did not improve from 0.71371
Epoch 95/300
 - 15s - loss: 798.2249 - acc: 0.9625 - mDice: 0.8494 - val_loss: 1585.5995 - val_acc: 0.9603 - val_mDice: 0.7091

Epoch 00095: val_mDice did not improve from 0.71371
Epoch 96/300
 - 16s - loss: 802.2599 - acc: 0.9624 - mDice: 0.8488 - val_loss: 1623.2512 - val_acc: 0.9596 - val_mDice: 0.7022

Epoch 00096: val_mDice did not improve from 0.71371
Epoch 97/300
 - 15s - loss: 798.9125 - acc: 0.9625 - mDice: 0.8493 - val_loss: 1615.2262 - val_acc: 0.9599 - val_mDice: 0.7035

Epoch 00097: val_mDice did not improve from 0.71371
Epoch 98/300
 - 16s - loss: 798.9992 - acc: 0.9625 - mDice: 0.8493 - val_loss: 1623.7806 - val_acc: 0.9602 - val_mDice: 0.7028

Epoch 00098: val_mDice did not improve from 0.71371
Epoch 99/300
 - 15s - loss: 792.0602 - acc: 0.9626 - mDice: 0.8505 - val_loss: 1628.3680 - val_acc: 0.9612 - val_mDice: 0.7022

Epoch 00099: val_mDice did not improve from 0.71371
Epoch 100/300
 - 16s - loss: 789.1242 - acc: 0.9626 - mDice: 0.8510 - val_loss: 1724.2541 - val_acc: 0.9597 - val_mDice: 0.6907

Epoch 00100: val_mDice did not improve from 0.71371
Epoch 101/300
 - 15s - loss: 785.8316 - acc: 0.9627 - mDice: 0.8516 - val_loss: 1613.2710 - val_acc: 0.9606 - val_mDice: 0.7034

Epoch 00101: val_mDice did not improve from 0.71371
Epoch 102/300
 - 15s - loss: 786.8198 - acc: 0.9627 - mDice: 0.8514 - val_loss: 1607.9840 - val_acc: 0.9606 - val_mDice: 0.7070

Epoch 00102: val_mDice did not improve from 0.71371
Epoch 103/300
 - 16s - loss: 783.4736 - acc: 0.9628 - mDice: 0.8520 - val_loss: 1549.2810 - val_acc: 0.9600 - val_mDice: 0.7117

Epoch 00103: val_mDice did not improve from 0.71371
Epoch 104/300
 - 15s - loss: 787.1825 - acc: 0.9626 - mDice: 0.8513 - val_loss: 1540.6752 - val_acc: 0.9612 - val_mDice: 0.7133

Epoch 00104: val_mDice did not improve from 0.71371
Epoch 105/300
 - 16s - loss: 777.2689 - acc: 0.9628 - mDice: 0.8530 - val_loss: 1602.9307 - val_acc: 0.9583 - val_mDice: 0.7055

Epoch 00105: val_mDice did not improve from 0.71371
Epoch 106/300
 - 15s - loss: 782.1459 - acc: 0.9627 - mDice: 0.8522 - val_loss: 1593.9327 - val_acc: 0.9611 - val_mDice: 0.7056

Epoch 00106: val_mDice did not improve from 0.71371
Epoch 107/300
 - 15s - loss: 776.6589 - acc: 0.9628 - mDice: 0.8532 - val_loss: 1664.3238 - val_acc: 0.9598 - val_mDice: 0.6962

Epoch 00107: val_mDice did not improve from 0.71371
Epoch 108/300
 - 16s - loss: 773.7702 - acc: 0.9628 - mDice: 0.8537 - val_loss: 1663.6044 - val_acc: 0.9583 - val_mDice: 0.6951

Epoch 00108: val_mDice did not improve from 0.71371
Epoch 109/300
 - 15s - loss: 776.7641 - acc: 0.9628 - mDice: 0.8531 - val_loss: 1621.2342 - val_acc: 0.9611 - val_mDice: 0.7025

Epoch 00109: val_mDice did not improve from 0.71371
Epoch 110/300
 - 16s - loss: 772.4832 - acc: 0.9629 - mDice: 0.8538 - val_loss: 1620.4679 - val_acc: 0.9601 - val_mDice: 0.7025

Epoch 00110: val_mDice did not improve from 0.71371
Epoch 111/300
 - 15s - loss: 770.2867 - acc: 0.9629 - mDice: 0.8542 - val_loss: 1720.1201 - val_acc: 0.9604 - val_mDice: 0.6900

Epoch 00111: val_mDice did not improve from 0.71371
Epoch 112/300
 - 15s - loss: 766.7235 - acc: 0.9630 - mDice: 0.8549 - val_loss: 1592.9177 - val_acc: 0.9615 - val_mDice: 0.7061

Epoch 00112: val_mDice did not improve from 0.71371
Epoch 113/300
 - 15s - loss: 764.5715 - acc: 0.9630 - mDice: 0.8553 - val_loss: 1603.4895 - val_acc: 0.9596 - val_mDice: 0.7047

Epoch 00113: val_mDice did not improve from 0.71371
Epoch 114/300
 - 15s - loss: 768.6066 - acc: 0.9629 - mDice: 0.8545 - val_loss: 1575.1507 - val_acc: 0.9600 - val_mDice: 0.7086

Epoch 00114: val_mDice did not improve from 0.71371
Epoch 115/300
 - 16s - loss: 766.1984 - acc: 0.9630 - mDice: 0.8549 - val_loss: 1591.9955 - val_acc: 0.9608 - val_mDice: 0.7068

Epoch 00115: val_mDice did not improve from 0.71371
Epoch 116/300
 - 15s - loss: 764.4356 - acc: 0.9630 - mDice: 0.8553 - val_loss: 1599.7275 - val_acc: 0.9615 - val_mDice: 0.7070

Epoch 00116: val_mDice did not improve from 0.71371
Epoch 117/300
 - 16s - loss: 755.8678 - acc: 0.9631 - mDice: 0.8568 - val_loss: 1633.6680 - val_acc: 0.9617 - val_mDice: 0.7014

Epoch 00117: val_mDice did not improve from 0.71371
Epoch 118/300
 - 15s - loss: 759.3130 - acc: 0.9631 - mDice: 0.8562 - val_loss: 1658.7015 - val_acc: 0.9598 - val_mDice: 0.6997

Epoch 00118: val_mDice did not improve from 0.71371
Epoch 119/300
 - 15s - loss: 762.1606 - acc: 0.9631 - mDice: 0.8557 - val_loss: 1677.0808 - val_acc: 0.9619 - val_mDice: 0.6972

Epoch 00119: val_mDice did not improve from 0.71371
Epoch 120/300
 - 16s - loss: 747.4225 - acc: 0.9631 - mDice: 0.8582 - val_loss: 1603.6146 - val_acc: 0.9614 - val_mDice: 0.7055

Epoch 00120: val_mDice did not improve from 0.71371
Epoch 121/300
 - 16s - loss: 755.9939 - acc: 0.9631 - mDice: 0.8568 - val_loss: 1603.2616 - val_acc: 0.9620 - val_mDice: 0.7056

Epoch 00121: val_mDice did not improve from 0.71371
Epoch 122/300
 - 17s - loss: 756.1303 - acc: 0.9631 - mDice: 0.8567 - val_loss: 1720.5999 - val_acc: 0.9598 - val_mDice: 0.6909

Epoch 00122: val_mDice did not improve from 0.71371
Restoring model weights from the end of the best epoch
Epoch 00122: early stopping
{'val_loss': [5193.6344227099235, 3338.2360075739502, 2665.7344681834447, 2352.0977885704915, 2110.489783367128, 2018.2770958820372, 1970.7971955510495, 1919.959209878936, 1821.4117291865457, 1773.3734503593153, 1788.4051019799617, 1828.9319835400763, 1727.155882857228, 1743.1242452140982, 1761.0868656071088, 1703.3660366844585, 1700.714057281727, 1762.7409910245706, 1737.3900668311665, 1665.7901816331703, 1641.5445603232347, 1730.155534351145, 1646.3570202543535, 1633.0421580540315, 1666.8953475369751, 1623.2551959088742, 1675.5103219301645, 1640.781329205928, 1622.256706412512, 1632.816007424857, 1582.8897993946803, 1610.2028929732228, 1684.2649811023973, 1678.6310308325383, 1638.0176014208612, 1706.6770848863907, 1632.6539455734137, 1626.6971566003697, 1622.5259991128937, 1633.1688353560353, 1609.4079552570372, 1588.8852278148854, 1592.8287167148735, 1612.6224262732585, 1630.9408751043654, 1684.4758151687738, 1611.3880615234375, 1667.608444097388, 1672.741647036021, 1651.971061881262, 1615.3497006947757, 1685.1892304165672, 1798.2641089053554, 1740.3154716200502, 1619.5329785528984, 1592.639205816138, 1660.0732477785066, 1721.3350867351503, 1587.8566465887404, 1629.8858353709447, 1614.2359796189169, 1593.1337611074666, 1714.402379159709, 1629.0394808936665, 1559.2038201484972, 1642.0118454794847, 1569.7139790076335, 1641.3491742083133, 1607.9994781727098, 1555.7130509005249, 1582.5949446117604, 1588.4102559562857, 1611.9494079123926, 1621.4077437306178, 1618.762549014492, 1623.9332107660425, 1600.1840140073355, 1626.3699643666507, 1588.5985908799498, 1595.5750546054985, 1571.8738035245706, 1612.8390069626669, 1586.0896657696208, 1705.5930063961116, 1624.71726838323, 1624.617413003936, 1624.336067024988, 1657.3938649883708, 1598.0452331077051, 1737.630736372853, 1563.3978634899809, 1550.609041403268, 1634.3574936262523, 1623.145605655117, 1585.5994751908397, 1623.2512495899928, 1615.2262084029103, 1623.7805902612117, 1628.3679646499284, 1724.2540702528627, 1613.2709923664122, 1607.984041403268, 1549.2810002683684, 1540.6752435815242, 1602.9307106542224, 1593.9327075754413, 1664.3238152656847, 1663.6043570715053, 1621.2341877012761, 1620.4679057579915, 1720.1200743231154, 1592.9177124955272, 1603.4895420220062, 1575.150670175334, 1591.9955309219943, 1599.7275241531488, 1633.6680106825502, 1658.7015343585997, 1677.0807928420206, 1603.614589545563, 1603.2616414077409, 1720.5998516519562], 'val_acc': [0.90144795861863, 0.9109461794372733, 0.9199899093795368, 0.9297224219518764, 0.9345964652891378, 0.9402228416377352, 0.9402581266774476, 0.9412815102184092, 0.9445548708202275, 0.9460764795769262, 0.9468627367310851, 0.946320679806571, 0.9482319018312992, 0.9481415653046761, 0.9481288645103687, 0.949770467881938, 0.9512723593311455, 0.9485988994591109, 0.9502588715262086, 0.9525540248128294, 0.9541772977086423, 0.9510338115328141, 0.9535703472508729, 0.9551272683471214, 0.9558499769400094, 0.9552571364031494, 0.9561449894468292, 0.9557765817824211, 0.9568013517001203, 0.9579672777015744, 0.9547786025600579, 0.9553008843924253, 0.9553403977219385, 0.9546106389460672, 0.9577654336245005, 0.9556283759706803, 0.9549607147697274, 0.9565543218423392, 0.9571019947983836, 0.9596328808151129, 0.9565035104751587, 0.9586956250758571, 0.958920048393366, 0.9597048877759744, 0.9594197514402958, 0.9592687219153834, 0.9584231990894289, 0.9577498886421436, 0.9585304879050218, 0.960451587010886, 0.9589539411413761, 0.9566587933147227, 0.957762583066489, 0.9581959397738217, 0.9597373427325533, 0.9595185436365259, 0.9594381055759109, 0.9587690220534346, 0.9589722961869859, 0.9592052024739389, 0.96105853837865, 0.957989864221966, 0.9568479434224485, 0.9591543806418208, 0.9614594128295666, 0.9611728782872208, 0.9603527688798104, 0.960338644853985, 0.9587351320354083, 0.9596568782820957, 0.9601720894566019, 0.9606449513034966, 0.9589779399733507, 0.9583625211060502, 0.9596766397243238, 0.9598728422900192, 0.9597091201607507, 0.9574111208660911, 0.9609752443000561, 0.9588918167216177, 0.9603584076612051, 0.9597034727344076, 0.9602581967834298, 0.9593068406782077, 0.959056974367331, 0.9602497379288418, 0.9588198616304471, 0.9598587219041722, 0.960385229751354, 0.9580124448273928, 0.9597500471668389, 0.9606407066337935, 0.9596046586983077, 0.9611234783216287, 0.9602765418190993, 0.9596470039309436, 0.9598827125461957, 0.9601975046951352, 0.9611898255712203, 0.9597006485662387, 0.9606181396782854, 0.9606421234953495, 0.9600041235676249, 0.9612208604812622, 0.9582707472429931, 0.9610655912916168, 0.959834736267119, 0.958262278833462, 0.9611418047024094, 0.9600549308398297, 0.9604050039335061, 0.9614721286387844, 0.9596258388220809, 0.9600224667833052, 0.9607790385493795, 0.961537049471877, 0.9616598659799299, 0.959844604248309, 0.9619407480909624, 0.9614170685069252, 0.9619986073661396, 0.9598036895271476], 'val_mDice': [0.36718479686110983, 0.4922293711254615, 0.5578182471617488, 0.5955117795303577, 0.6279425994130491, 0.6404493801466381, 0.6473233099202164, 0.6551520260235736, 0.6689950782834119, 0.6757774980923602, 0.6737737196092387, 0.6681399290798274, 0.6836997488982804, 0.680494739809109, 0.6771436310906447, 0.6868124012728684, 0.6869154831835331, 0.6787583473074528, 0.6821146316200722, 0.6924044494410507, 0.6970266717990846, 0.6834358058812964, 0.6966351297975496, 0.698382108266117, 0.6937483321619398, 0.6991693354744948, 0.6930444222370177, 0.6970580702519599, 0.7002197176445532, 0.6998427573961156, 0.7062587346739442, 0.7023467107583549, 0.6916670289658408, 0.6920687465267327, 0.6975383913244, 0.6879188259139316, 0.6983360816504209, 0.7006860771251999, 0.7010590493224049, 0.6992599627443852, 0.7016085522775432, 0.7067232332156814, 0.705407194508851, 0.7036687699893048, 0.7007389514500858, 0.6938488315079958, 0.7034576398725728, 0.6969567883105678, 0.6944071473056124, 0.6990671567334473, 0.7027867163410624, 0.6928400124302347, 0.6791104678889267, 0.6846275848286753, 0.7024128314192969, 0.7076177692595329, 0.6970553598331131, 0.6882157057296229, 0.7079428293322789, 0.701788061447726, 0.7032628295985797, 0.7054026681958264, 0.6884637638812757, 0.700299694792915, 0.7116137033200446, 0.7005548518122607, 0.7096389677688366, 0.6996343681830486, 0.7051112779224192, 0.7114358134852111, 0.7068371153969801, 0.7075296749595468, 0.7018145081651119, 0.7001638840173037, 0.7036806062887643, 0.7032125992629364, 0.7063293502530978, 0.7002650617643167, 0.7073021476505367, 0.706053237423642, 0.7094211651168707, 0.7050522092644494, 0.7088739953878271, 0.6911801077027357, 0.7031143330435716, 0.702104325057896, 0.7003006662121256, 0.698556748510317, 0.7057448457215578, 0.6875120410482392, 0.7109438417522052, 0.713713796539161, 0.6989317732002899, 0.7046993961771026, 0.7091493470068196, 0.7021744087452196, 0.7035422743731783, 0.70284702031667, 0.7021947635039119, 0.6906817409828419, 0.703415181345612, 0.7070029946683928, 0.7117004822228701, 0.7132561598115295, 0.7054670625970564, 0.7055762942510707, 0.6962319776302076, 0.6950984961203946, 0.7024961214029152, 0.7025153045435898, 0.6900308864717265, 0.7061481375730675, 0.7046652559105676, 0.7085889086468529, 0.7068048906690292, 0.7070034487556865, 0.7014374364423388, 0.6996810190550243, 0.6971803089134566, 0.7055083822658044, 0.7055766163891508, 0.6909189688340398], 'loss': [11147.257084799438, 4581.344045486387, 3459.8020433002885, 2909.182197359338, 2573.156116156137, 2394.6576878597234, 2191.6983945628126, 2054.993880937937, 1952.3686023804883, 1867.4036483931886, 1799.500239136866, 1738.5867491852227, 1668.2861481240618, 1628.7939721805749, 1577.0566925802514, 1536.2115292606504, 1505.3874559883275, 1494.0395337244672, 1435.0318760317912, 1407.6075772472163, 1372.8953523897405, 1355.6842494178395, 1333.9350429937956, 1303.386945686673, 1285.4414309922947, 1263.6847158942362, 1248.6356561855785, 1227.6073547271114, 1207.0432946395001, 1198.5580561224103, 1176.4453073460986, 1161.8527085332457, 1154.173205750145, 1136.7478499207439, 1129.0640550541211, 1109.0697572135712, 1096.2195103022968, 1091.4838891656268, 1090.6339756970608, 1067.409341188801, 1060.4248967932344, 1057.0093355276854, 1038.6842120383033, 1029.2381907675883, 1021.864091841115, 1013.3084721241688, 1009.6483416392165, 997.688222664099, 999.1921572330558, 983.0061649982356, 976.4011822268051, 968.5690015976529, 961.5241397194475, 952.9174660000673, 945.1575234611184, 940.733650797312, 934.8139902081699, 929.7101074022524, 931.2563865238324, 919.1646171085578, 915.131831390858, 909.3774715135378, 908.0502769495859, 903.108509661875, 899.9316720389735, 889.8149323426973, 879.6210970709737, 883.6272261375818, 880.2699465842932, 873.4934921565676, 866.1668660900981, 863.9953408834734, 865.0115070817787, 906.237871586931, 858.3892259008264, 853.912174905512, 853.1593506507514, 846.9473549746533, 844.1280359764978, 839.4805580461372, 837.7651830681858, 830.9429400938916, 828.4386491683996, 830.5262014495048, 825.5245712074385, 826.5592708911902, 819.2386421583801, 816.6203744975548, 813.9269703875225, 813.800544316215, 834.8924067529447, 809.849553987283, 809.4166296201196, 808.8108465847023, 798.2249423709974, 802.2598837261988, 798.912535813892, 798.9992423081015, 792.0601639640541, 789.124185795059, 785.8316400537152, 786.8198053751229, 783.4735666160095, 787.1825204288346, 777.2688996844914, 782.1458866681119, 776.6588991454947, 773.7701534970109, 776.7640982380775, 772.4832322015075, 770.2866957725486, 766.7235487297266, 764.5714980786993, 768.606556305715, 766.1983747811665, 764.4355941906995, 755.8677843788746, 759.3129827111119, 762.1605909497026, 747.4224557586243, 755.9939128543672, 756.1302704284064], 'acc': [0.869892092932565, 0.9039990596766827, 0.9169395526528933, 0.925093210558204, 0.9303915140614762, 0.9338201857227526, 0.9370753937192874, 0.9393096968181018, 0.9410173402207008, 0.9426634465964633, 0.9438964215277975, 0.9450282250698464, 0.9461072120154802, 0.9470625309311436, 0.9479323301657216, 0.948741494601791, 0.9494264290623021, 0.9501774228840356, 0.9507787864963928, 0.9512307939285994, 0.951871717116692, 0.9522350548251964, 0.9528030916424941, 0.9532871074309287, 0.9537645877699652, 0.9541360664352578, 0.9545499895887093, 0.9549397005480411, 0.9552636748369696, 0.9554456219333338, 0.9559347208839193, 0.9561549146191992, 0.9563884153200709, 0.9567557382911126, 0.9568671936403266, 0.9572135431308115, 0.9574831696032572, 0.9576164408679875, 0.9577005875314447, 0.9579860995780812, 0.9581848014213413, 0.9582437994772915, 0.958511876069284, 0.9586617203345051, 0.9588622974985916, 0.9589015315758851, 0.9590131336879995, 0.9592531241294708, 0.9592417593682653, 0.959544943871248, 0.9596750463923277, 0.9597975077338281, 0.9598564504183438, 0.9599797828110724, 0.9600558727173957, 0.9601752038815905, 0.9603189442583854, 0.9603378765883486, 0.9604273161523915, 0.9605522320967247, 0.9605728942621259, 0.9607137153759417, 0.9606899183790266, 0.9607850171557021, 0.9608891065914265, 0.961047904636248, 0.9611513636575485, 0.9612057991781332, 0.9612164148469542, 0.9613408582337943, 0.961403947783211, 0.9614370178302977, 0.9614913525232482, 0.9604189404847125, 0.9614954076511744, 0.96159609239259, 0.96162918338797, 0.9616646889623127, 0.9617668147227392, 0.961847593237441, 0.9619023042592938, 0.9618657346423088, 0.9619965016612517, 0.961935360236328, 0.9620506527176602, 0.9620450876750822, 0.9622178649413405, 0.962253678439625, 0.9622155954674161, 0.96222627744782, 0.9620251094721814, 0.9623510655828851, 0.9623280062533324, 0.9623439680398239, 0.9624925703920851, 0.9623970029978799, 0.9624527230364492, 0.9625250148792936, 0.9626245463467578, 0.9626183647304372, 0.9627342721857187, 0.9626974324214023, 0.9627702485232307, 0.9626096302009289, 0.9628463938184091, 0.9627076640062426, 0.9627726274073469, 0.9628481456822187, 0.9628368115929147, 0.9628989250738104, 0.9629092128111096, 0.9629996635955774, 0.9629969297170093, 0.9629214978077553, 0.96298952134657, 0.9629615822376792, 0.9630853249295153, 0.9630936834349821, 0.9630529516665038, 0.9631436389997378, 0.963145077966019, 0.9631276410974015], 'mDice': [0.2262781058511207, 0.4210114490127034, 0.5094500226913864, 0.5628147219547753, 0.5994915908389529, 0.621963216297532, 0.6446902418608115, 0.6617074088448933, 0.674990798986407, 0.6865260411971926, 0.6956222744179431, 0.7042067356723754, 0.7135978837677318, 0.719310241270718, 0.7264580806148657, 0.7324317859148131, 0.7374562130755273, 0.7429869095635394, 0.7473376771490761, 0.7515847114401976, 0.756544236259074, 0.7592161816148648, 0.7626821021085081, 0.7672140209236649, 0.7700578161533034, 0.7733565084427527, 0.7757423930721199, 0.7789607971211289, 0.7822062046031143, 0.7835576906665986, 0.787022455209322, 0.7892741698674994, 0.7905905548343587, 0.793291878999891, 0.7946177350893494, 0.7976587333038817, 0.7998179177277691, 0.8005603443072864, 0.800986899232207, 0.804425608775568, 0.805649682714678, 0.8062173143051714, 0.8091110899849185, 0.8106210603188584, 0.8120727136181672, 0.8132294986081824, 0.8138968939875028, 0.8161373581027571, 0.815616833756604, 0.8182616802434658, 0.8193441003893464, 0.8206232019816565, 0.8218008898029117, 0.8231999864301376, 0.8244673705663118, 0.8252470914402024, 0.8262713060521181, 0.8271412694034356, 0.8268840526650679, 0.8288431208076442, 0.829534835181087, 0.8304657378491241, 0.8307157870629044, 0.8315620333227786, 0.8320908617146429, 0.8338011404270493, 0.8354026474538784, 0.8348262986877157, 0.8353953851495148, 0.8365493220542931, 0.8378257578710381, 0.8381597462164525, 0.8381501898634793, 0.8310625094330092, 0.839056533254809, 0.8399386518249742, 0.8400562533540683, 0.8409900938525597, 0.8415137808161127, 0.842323745961858, 0.8426321479457638, 0.8437723693220979, 0.8442051780805114, 0.8438180938048778, 0.8447532545162005, 0.8445455305232209, 0.8458038641314888, 0.8462854613138944, 0.8467235980899563, 0.847059696539674, 0.8432158728368017, 0.8474210275091124, 0.8475189135411298, 0.8476727148503903, 0.84942481942158, 0.8487560019710745, 0.8492880614375609, 0.8493191172895571, 0.850464621299926, 0.850965888444816, 0.8515804817013516, 0.8513849216578527, 0.8519964669536897, 0.8513144339842237, 0.8530145914597915, 0.8522333280482384, 0.8531626888144654, 0.8536561552156249, 0.8531496253571768, 0.8538447032571043, 0.8542485949363552, 0.8549034383074099, 0.855264853612964, 0.8545268934070004, 0.8549420509680288, 0.8553200505858617, 0.8567519686127889, 0.8561935124705506, 0.8557105188194616, 0.8582339691252883, 0.8567887960752455, 0.8567275099953161]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:18<00:54, 18.26s/it]predicting test subjects:  50%|█████     | 2/4 [00:34<00:35, 17.72s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:53<00:18, 18.06s/it]predicting test subjects: 100%|██████████| 4/4 [01:10<00:00, 17.75s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:26<2:16:45, 26.47s/it]predicting train subjects:   1%|          | 2/311 [00:39<1:55:01, 22.33s/it]predicting train subjects:   1%|          | 3/311 [00:54<1:44:20, 20.33s/it]predicting train subjects:   1%|▏         | 4/311 [01:10<1:36:28, 18.86s/it]predicting train subjects:   2%|▏         | 5/311 [01:25<1:30:07, 17.67s/it]predicting train subjects:   2%|▏         | 6/311 [01:39<1:24:20, 16.59s/it]predicting train subjects:   2%|▏         | 7/311 [01:54<1:22:33, 16.29s/it]predicting train subjects:   3%|▎         | 8/311 [02:13<1:25:13, 16.87s/it]predicting train subjects:   3%|▎         | 9/311 [02:31<1:26:39, 17.22s/it]predicting train subjects:   3%|▎         | 10/311 [02:46<1:23:15, 16.59s/it]predicting train subjects:   4%|▎         | 11/311 [03:05<1:27:43, 17.54s/it]predicting train subjects:   4%|▍         | 12/311 [03:21<1:24:34, 16.97s/it]predicting train subjects:   4%|▍         | 13/311 [03:37<1:22:11, 16.55s/it]predicting train subjects:   5%|▍         | 14/311 [03:56<1:25:43, 17.32s/it]predicting train subjects:   5%|▍         | 15/311 [04:21<1:37:18, 19.73s/it]predicting train subjects:   5%|▌         | 16/311 [04:42<1:38:31, 20.04s/it]predicting train subjects:   5%|▌         | 17/311 [05:03<1:39:54, 20.39s/it]predicting train subjects:   6%|▌         | 18/311 [05:25<1:42:04, 20.90s/it]predicting train subjects:   6%|▌         | 19/311 [05:46<1:41:56, 20.95s/it]predicting train subjects:   6%|▋         | 20/311 [06:08<1:42:09, 21.06s/it]predicting train subjects:   7%|▋         | 21/311 [06:29<1:42:37, 21.23s/it]predicting train subjects:   7%|▋         | 22/311 [06:50<1:41:56, 21.17s/it]predicting train subjects:   7%|▋         | 23/311 [07:12<1:41:59, 21.25s/it]predicting train subjects:   8%|▊         | 24/311 [07:33<1:42:19, 21.39s/it]predicting train subjects:   8%|▊         | 25/311 [07:54<1:41:20, 21.26s/it]predicting train subjects:   8%|▊         | 26/311 [08:16<1:41:05, 21.28s/it]predicting train subjects:   9%|▊         | 27/311 [08:37<1:41:07, 21.37s/it]predicting train subjects:   9%|▉         | 28/311 [08:59<1:40:51, 21.38s/it]predicting train subjects:   9%|▉         | 29/311 [09:20<1:40:11, 21.32s/it]predicting train subjects:  10%|▉         | 30/311 [09:42<1:40:28, 21.45s/it]predicting train subjects:  10%|▉         | 31/311 [10:02<1:39:22, 21.29s/it]predicting train subjects:  10%|█         | 32/311 [10:24<1:39:18, 21.36s/it]predicting train subjects:  11%|█         | 33/311 [10:34<1:22:57, 17.91s/it]predicting train subjects:  11%|█         | 34/311 [10:44<1:11:59, 15.60s/it]predicting train subjects:  11%|█▏        | 35/311 [10:54<1:04:05, 13.93s/it]predicting train subjects:  12%|█▏        | 36/311 [11:04<58:16, 12.71s/it]  predicting train subjects:  12%|█▏        | 37/311 [11:14<54:47, 12.00s/it]predicting train subjects:  12%|█▏        | 38/311 [11:24<51:29, 11.32s/it]predicting train subjects:  13%|█▎        | 39/311 [11:34<50:06, 11.05s/it]predicting train subjects:  13%|█▎        | 40/311 [11:45<48:58, 10.84s/it]predicting train subjects:  13%|█▎        | 41/311 [11:55<47:33, 10.57s/it]predicting train subjects:  14%|█▎        | 42/311 [12:05<46:47, 10.44s/it]predicting train subjects:  14%|█▍        | 43/311 [12:15<46:13, 10.35s/it]predicting train subjects:  14%|█▍        | 44/311 [12:25<45:10, 10.15s/it]predicting train subjects:  14%|█▍        | 45/311 [12:35<44:34, 10.06s/it]predicting train subjects:  15%|█▍        | 46/311 [12:45<44:42, 10.12s/it]predicting train subjects:  15%|█▌        | 47/311 [12:55<44:24, 10.09s/it]predicting train subjects:  15%|█▌        | 48/311 [13:05<43:55, 10.02s/it]predicting train subjects:  16%|█▌        | 49/311 [13:15<44:04, 10.09s/it]predicting train subjects:  16%|█▌        | 50/311 [13:25<44:16, 10.18s/it]predicting train subjects:  16%|█▋        | 51/311 [13:38<47:19, 10.92s/it]predicting train subjects:  17%|█▋        | 52/311 [13:51<50:07, 11.61s/it]predicting train subjects:  17%|█▋        | 53/311 [14:05<52:35, 12.23s/it]predicting train subjects:  17%|█▋        | 54/311 [14:17<52:47, 12.33s/it]predicting train subjects:  18%|█▊        | 55/311 [14:30<53:00, 12.42s/it]predicting train subjects:  18%|█▊        | 56/311 [14:43<52:53, 12.45s/it]predicting train subjects:  18%|█▊        | 57/311 [14:56<53:22, 12.61s/it]predicting train subjects:  19%|█▊        | 58/311 [15:09<53:35, 12.71s/it]predicting train subjects:  19%|█▉        | 59/311 [15:22<54:36, 13.00s/it]predicting train subjects:  19%|█▉        | 60/311 [15:35<54:24, 13.01s/it]predicting train subjects:  20%|█▉        | 61/311 [15:48<53:56, 12.95s/it]predicting train subjects:  20%|█▉        | 62/311 [16:01<53:32, 12.90s/it]predicting train subjects:  20%|██        | 63/311 [16:14<54:00, 13.07s/it]predicting train subjects:  21%|██        | 64/311 [16:27<53:13, 12.93s/it]predicting train subjects:  21%|██        | 65/311 [16:40<52:40, 12.85s/it]predicting train subjects:  21%|██        | 66/311 [16:53<53:08, 13.01s/it]predicting train subjects:  22%|██▏       | 67/311 [17:05<52:12, 12.84s/it]predicting train subjects:  22%|██▏       | 68/311 [17:18<51:24, 12.69s/it]predicting train subjects:  22%|██▏       | 69/311 [17:30<51:12, 12.69s/it]predicting train subjects:  23%|██▎       | 70/311 [17:43<50:53, 12.67s/it]predicting train subjects:  23%|██▎       | 71/311 [17:56<50:42, 12.68s/it]predicting train subjects:  23%|██▎       | 72/311 [18:08<50:15, 12.62s/it]predicting train subjects:  23%|██▎       | 73/311 [18:21<49:59, 12.60s/it]predicting train subjects:  24%|██▍       | 74/311 [18:33<49:19, 12.49s/it]predicting train subjects:  24%|██▍       | 75/311 [18:46<49:10, 12.50s/it]predicting train subjects:  24%|██▍       | 76/311 [18:58<48:28, 12.38s/it]predicting train subjects:  25%|██▍       | 77/311 [19:10<48:42, 12.49s/it]predicting train subjects:  25%|██▌       | 78/311 [19:23<48:41, 12.54s/it]predicting train subjects:  25%|██▌       | 79/311 [19:36<48:41, 12.59s/it]predicting train subjects:  26%|██▌       | 80/311 [19:48<48:13, 12.53s/it]predicting train subjects:  26%|██▌       | 81/311 [20:00<47:44, 12.45s/it]predicting train subjects:  26%|██▋       | 82/311 [20:13<47:29, 12.44s/it]predicting train subjects:  27%|██▋       | 83/311 [20:25<47:21, 12.46s/it]predicting train subjects:  27%|██▋       | 84/311 [20:38<47:39, 12.60s/it]predicting train subjects:  27%|██▋       | 85/311 [20:49<45:33, 12.10s/it]predicting train subjects:  28%|██▊       | 86/311 [21:00<44:11, 11.78s/it]predicting train subjects:  28%|██▊       | 87/311 [21:12<43:36, 11.68s/it]predicting train subjects:  28%|██▊       | 88/311 [21:23<43:21, 11.67s/it]predicting train subjects:  29%|██▊       | 89/311 [21:35<43:05, 11.64s/it]predicting train subjects:  29%|██▉       | 90/311 [21:46<42:12, 11.46s/it]predicting train subjects:  29%|██▉       | 91/311 [21:57<41:59, 11.45s/it]predicting train subjects:  30%|██▉       | 92/311 [22:09<41:56, 11.49s/it]predicting train subjects:  30%|██▉       | 93/311 [22:20<41:45, 11.49s/it]predicting train subjects:  30%|███       | 94/311 [22:32<41:20, 11.43s/it]predicting train subjects:  31%|███       | 95/311 [22:43<40:46, 11.33s/it]predicting train subjects:  31%|███       | 96/311 [22:54<40:27, 11.29s/it]predicting train subjects:  31%|███       | 97/311 [23:05<40:11, 11.27s/it]predicting train subjects:  32%|███▏      | 98/311 [23:17<40:24, 11.38s/it]predicting train subjects:  32%|███▏      | 99/311 [23:28<40:14, 11.39s/it]predicting train subjects:  32%|███▏      | 100/311 [23:39<39:35, 11.26s/it]predicting train subjects:  32%|███▏      | 101/311 [23:51<39:29, 11.28s/it]predicting train subjects:  33%|███▎      | 102/311 [24:02<39:52, 11.45s/it]predicting train subjects:  33%|███▎      | 103/311 [24:14<39:37, 11.43s/it]predicting train subjects:  33%|███▎      | 104/311 [24:25<39:13, 11.37s/it]predicting train subjects:  34%|███▍      | 105/311 [24:37<39:15, 11.44s/it]predicting train subjects:  34%|███▍      | 106/311 [24:48<39:32, 11.57s/it]predicting train subjects:  34%|███▍      | 107/311 [25:01<39:52, 11.73s/it]predicting train subjects:  35%|███▍      | 108/311 [25:12<38:59, 11.53s/it]predicting train subjects:  35%|███▌      | 109/311 [25:23<38:14, 11.36s/it]predicting train subjects:  35%|███▌      | 110/311 [25:34<38:08, 11.38s/it]predicting train subjects:  36%|███▌      | 111/311 [25:46<38:16, 11.48s/it]predicting train subjects:  36%|███▌      | 112/311 [25:57<38:08, 11.50s/it]predicting train subjects:  36%|███▋      | 113/311 [26:09<37:48, 11.45s/it]predicting train subjects:  37%|███▋      | 114/311 [26:30<47:36, 14.50s/it]predicting train subjects:  37%|███▋      | 115/311 [26:52<54:13, 16.60s/it]predicting train subjects:  37%|███▋      | 116/311 [27:14<59:35, 18.34s/it]predicting train subjects:  38%|███▊      | 117/311 [27:36<1:02:19, 19.28s/it]predicting train subjects:  38%|███▊      | 118/311 [27:58<1:05:09, 20.26s/it]predicting train subjects:  38%|███▊      | 119/311 [28:24<1:09:56, 21.86s/it]predicting train subjects:  39%|███▊      | 120/311 [28:48<1:12:11, 22.68s/it]predicting train subjects:  39%|███▉      | 121/311 [29:14<1:14:15, 23.45s/it]predicting train subjects:  39%|███▉      | 122/311 [29:39<1:16:07, 24.17s/it]predicting train subjects:  40%|███▉      | 123/311 [30:05<1:16:53, 24.54s/it]predicting train subjects:  40%|███▉      | 124/311 [30:32<1:19:00, 25.35s/it]predicting train subjects:  40%|████      | 125/311 [30:58<1:18:42, 25.39s/it]predicting train subjects:  41%|████      | 126/311 [31:24<1:18:56, 25.60s/it]predicting train subjects:  41%|████      | 127/311 [31:50<1:19:29, 25.92s/it]predicting train subjects:  41%|████      | 128/311 [32:15<1:18:02, 25.59s/it]predicting train subjects:  41%|████▏     | 129/311 [32:41<1:18:13, 25.79s/it]predicting train subjects:  42%|████▏     | 130/311 [33:06<1:16:44, 25.44s/it]predicting train subjects:  42%|████▏     | 131/311 [33:32<1:16:51, 25.62s/it]predicting train subjects:  42%|████▏     | 132/311 [33:45<1:04:58, 21.78s/it]predicting train subjects:  43%|████▎     | 133/311 [33:57<56:16, 18.97s/it]  predicting train subjects:  43%|████▎     | 134/311 [34:10<50:08, 17.00s/it]predicting train subjects:  43%|████▎     | 135/311 [34:21<44:38, 15.22s/it]predicting train subjects:  44%|████▎     | 136/311 [34:30<39:24, 13.51s/it]predicting train subjects:  44%|████▍     | 137/311 [34:40<36:13, 12.49s/it]predicting train subjects:  44%|████▍     | 138/311 [34:51<34:04, 11.82s/it]predicting train subjects:  45%|████▍     | 139/311 [35:00<32:00, 11.17s/it]predicting train subjects:  45%|████▌     | 140/311 [35:10<30:54, 10.85s/it]predicting train subjects:  45%|████▌     | 141/311 [35:21<30:08, 10.64s/it]predicting train subjects:  46%|████▌     | 142/311 [35:30<29:08, 10.35s/it]predicting train subjects:  46%|████▌     | 143/311 [35:40<28:43, 10.26s/it]predicting train subjects:  46%|████▋     | 144/311 [35:50<28:31, 10.25s/it]predicting train subjects:  47%|████▋     | 145/311 [36:00<28:03, 10.14s/it]predicting train subjects:  47%|████▋     | 146/311 [36:10<27:39, 10.06s/it]predicting train subjects:  47%|████▋     | 147/311 [36:21<27:40, 10.12s/it]predicting train subjects:  48%|████▊     | 148/311 [36:31<27:32, 10.14s/it]predicting train subjects:  48%|████▊     | 149/311 [36:40<26:54,  9.97s/it]predicting train subjects:  48%|████▊     | 150/311 [36:53<29:11, 10.88s/it]predicting train subjects:  49%|████▊     | 151/311 [37:06<30:35, 11.47s/it]predicting train subjects:  49%|████▉     | 152/311 [37:19<31:35, 11.92s/it]predicting train subjects:  49%|████▉     | 153/311 [37:32<32:18, 12.27s/it]predicting train subjects:  50%|████▉     | 154/311 [37:45<32:34, 12.45s/it]predicting train subjects:  50%|████▉     | 155/311 [37:58<32:38, 12.55s/it]predicting train subjects:  50%|█████     | 156/311 [38:11<32:35, 12.62s/it]predicting train subjects:  50%|█████     | 157/311 [38:23<32:34, 12.69s/it]predicting train subjects:  51%|█████     | 158/311 [38:36<32:30, 12.75s/it]predicting train subjects:  51%|█████     | 159/311 [38:49<32:18, 12.75s/it]predicting train subjects:  51%|█████▏    | 160/311 [39:02<32:17, 12.83s/it]predicting train subjects:  52%|█████▏    | 161/311 [39:15<32:08, 12.85s/it]predicting train subjects:  52%|█████▏    | 162/311 [39:28<32:01, 12.89s/it]predicting train subjects:  52%|█████▏    | 163/311 [39:41<31:52, 12.92s/it]predicting train subjects:  53%|█████▎    | 164/311 [39:54<31:35, 12.89s/it]predicting train subjects:  53%|█████▎    | 165/311 [40:07<31:13, 12.83s/it]predicting train subjects:  53%|█████▎    | 166/311 [40:19<30:36, 12.67s/it]predicting train subjects:  54%|█████▎    | 167/311 [40:31<30:08, 12.56s/it]predicting train subjects:  54%|█████▍    | 168/311 [40:44<29:58, 12.58s/it]predicting train subjects:  54%|█████▍    | 169/311 [40:56<29:48, 12.60s/it]predicting train subjects:  55%|█████▍    | 170/311 [41:09<29:58, 12.76s/it]predicting train subjects:  55%|█████▍    | 171/311 [41:22<29:27, 12.63s/it]predicting train subjects:  55%|█████▌    | 172/311 [41:34<28:58, 12.51s/it]predicting train subjects:  56%|█████▌    | 173/311 [41:47<28:47, 12.52s/it]predicting train subjects:  56%|█████▌    | 174/311 [41:59<28:26, 12.46s/it]predicting train subjects:  56%|█████▋    | 175/311 [42:11<28:15, 12.46s/it]predicting train subjects:  57%|█████▋    | 176/311 [42:24<28:09, 12.52s/it]predicting train subjects:  57%|█████▋    | 177/311 [42:37<28:00, 12.54s/it]predicting train subjects:  57%|█████▋    | 178/311 [42:49<27:40, 12.49s/it]predicting train subjects:  58%|█████▊    | 179/311 [43:01<27:16, 12.40s/it]predicting train subjects:  58%|█████▊    | 180/311 [43:14<27:02, 12.39s/it]predicting train subjects:  58%|█████▊    | 181/311 [43:26<26:56, 12.44s/it]predicting train subjects:  59%|█████▊    | 182/311 [43:39<26:56, 12.53s/it]predicting train subjects:  59%|█████▉    | 183/311 [43:52<26:57, 12.64s/it]predicting train subjects:  59%|█████▉    | 184/311 [44:03<26:12, 12.38s/it]predicting train subjects:  59%|█████▉    | 185/311 [44:14<25:04, 11.94s/it]predicting train subjects:  60%|█████▉    | 186/311 [44:26<24:34, 11.79s/it]predicting train subjects:  60%|██████    | 187/311 [44:38<24:19, 11.77s/it]predicting train subjects:  60%|██████    | 188/311 [44:49<24:02, 11.73s/it]predicting train subjects:  61%|██████    | 189/311 [45:00<23:31, 11.57s/it]predicting train subjects:  61%|██████    | 190/311 [45:12<23:10, 11.49s/it]predicting train subjects:  61%|██████▏   | 191/311 [45:23<23:07, 11.57s/it]predicting train subjects:  62%|██████▏   | 192/311 [45:35<22:52, 11.53s/it]predicting train subjects:  62%|██████▏   | 193/311 [45:46<22:19, 11.35s/it]predicting train subjects:  62%|██████▏   | 194/311 [45:58<22:26, 11.51s/it]predicting train subjects:  63%|██████▎   | 195/311 [46:10<22:28, 11.62s/it]predicting train subjects:  63%|██████▎   | 196/311 [46:22<22:29, 11.73s/it]predicting train subjects:  63%|██████▎   | 197/311 [46:33<22:10, 11.68s/it]predicting train subjects:  64%|██████▎   | 198/311 [46:46<22:24, 11.89s/it]predicting train subjects:  64%|██████▍   | 199/311 [46:58<22:21, 11.98s/it]predicting train subjects:  64%|██████▍   | 200/311 [47:09<21:59, 11.89s/it]predicting train subjects:  65%|██████▍   | 201/311 [47:21<21:42, 11.84s/it]predicting train subjects:  65%|██████▍   | 202/311 [47:33<21:37, 11.91s/it]predicting train subjects:  65%|██████▌   | 203/311 [47:45<21:21, 11.86s/it]predicting train subjects:  66%|██████▌   | 204/311 [47:57<21:11, 11.88s/it]predicting train subjects:  66%|██████▌   | 205/311 [48:09<21:02, 11.91s/it]predicting train subjects:  66%|██████▌   | 206/311 [48:21<21:02, 12.02s/it]predicting train subjects:  67%|██████▋   | 207/311 [48:33<20:52, 12.04s/it]predicting train subjects:  67%|██████▋   | 208/311 [48:45<20:29, 11.94s/it]predicting train subjects:  67%|██████▋   | 209/311 [48:57<20:10, 11.87s/it]predicting train subjects:  68%|██████▊   | 210/311 [49:09<20:01, 11.90s/it]predicting train subjects:  68%|██████▊   | 211/311 [49:21<19:51, 11.92s/it]predicting train subjects:  68%|██████▊   | 212/311 [49:32<19:28, 11.80s/it]predicting train subjects:  68%|██████▊   | 213/311 [49:55<24:45, 15.16s/it]predicting train subjects:  69%|██████▉   | 214/311 [50:17<27:52, 17.25s/it]predicting train subjects:  69%|██████▉   | 215/311 [50:40<30:21, 18.98s/it]predicting train subjects:  69%|██████▉   | 216/311 [51:03<31:43, 20.04s/it]predicting train subjects:  70%|██████▉   | 217/311 [51:25<32:36, 20.81s/it]predicting train subjects:  70%|███████   | 218/311 [51:48<33:06, 21.36s/it]predicting train subjects:  70%|███████   | 219/311 [52:10<33:11, 21.64s/it]predicting train subjects:  71%|███████   | 220/311 [52:33<33:24, 22.03s/it]predicting train subjects:  71%|███████   | 221/311 [52:55<33:05, 22.06s/it]predicting train subjects:  71%|███████▏  | 222/311 [53:18<33:02, 22.27s/it]predicting train subjects:  72%|███████▏  | 223/311 [53:41<33:06, 22.57s/it]predicting train subjects:  72%|███████▏  | 224/311 [54:04<32:41, 22.54s/it]predicting train subjects:  72%|███████▏  | 225/311 [54:27<32:21, 22.58s/it]predicting train subjects:  73%|███████▎  | 226/311 [54:48<31:37, 22.32s/it]predicting train subjects:  73%|███████▎  | 227/311 [55:11<31:16, 22.33s/it]predicting train subjects:  73%|███████▎  | 228/311 [55:35<31:55, 23.08s/it]predicting train subjects:  74%|███████▎  | 229/311 [56:02<32:53, 24.07s/it]predicting train subjects:  74%|███████▍  | 230/311 [56:29<33:56, 25.14s/it]predicting train subjects:  74%|███████▍  | 231/311 [56:42<28:26, 21.34s/it]predicting train subjects:  75%|███████▍  | 232/311 [56:54<24:17, 18.45s/it]predicting train subjects:  75%|███████▍  | 233/311 [57:06<21:26, 16.49s/it]predicting train subjects:  75%|███████▌  | 234/311 [57:18<19:44, 15.38s/it]predicting train subjects:  76%|███████▌  | 235/311 [57:32<18:49, 14.86s/it]predicting train subjects:  76%|███████▌  | 236/311 [57:44<17:39, 14.12s/it]predicting train subjects:  76%|███████▌  | 237/311 [57:57<16:58, 13.76s/it]predicting train subjects:  77%|███████▋  | 238/311 [58:10<16:17, 13.39s/it]predicting train subjects:  77%|███████▋  | 239/311 [58:22<15:37, 13.02s/it]predicting train subjects:  77%|███████▋  | 240/311 [58:34<15:02, 12.71s/it]predicting train subjects:  77%|███████▋  | 241/311 [58:47<14:53, 12.77s/it]predicting train subjects:  78%|███████▊  | 242/311 [59:00<14:46, 12.84s/it]predicting train subjects:  78%|███████▊  | 243/311 [59:13<14:29, 12.79s/it]predicting train subjects:  78%|███████▊  | 244/311 [59:25<14:18, 12.82s/it]predicting train subjects:  79%|███████▉  | 245/311 [59:38<14:01, 12.76s/it]predicting train subjects:  79%|███████▉  | 246/311 [59:50<13:33, 12.51s/it]predicting train subjects:  79%|███████▉  | 247/311 [1:00:02<13:18, 12.47s/it]predicting train subjects:  80%|███████▉  | 248/311 [1:00:15<13:11, 12.57s/it]predicting train subjects:  80%|████████  | 249/311 [1:00:31<14:06, 13.65s/it]predicting train subjects:  80%|████████  | 250/311 [1:00:46<14:12, 13.98s/it]predicting train subjects:  81%|████████  | 251/311 [1:01:01<14:10, 14.18s/it]predicting train subjects:  81%|████████  | 252/311 [1:01:13<13:29, 13.73s/it]predicting train subjects:  81%|████████▏ | 253/311 [1:01:26<13:02, 13.49s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:01:39<12:38, 13.30s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:01:52<12:11, 13.06s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:02:04<11:50, 12.92s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:02:17<11:34, 12.85s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:02:30<11:20, 12.83s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:02:43<11:09, 12.88s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:02:56<10:59, 12.92s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:03:08<10:37, 12.75s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:03:21<10:25, 12.76s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:03:34<10:15, 12.82s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:03:47<10:05, 12.89s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:04:00<09:52, 12.88s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:04:12<09:30, 12.69s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:04:24<09:10, 12.51s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:04:37<09:01, 12.59s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:04:50<08:49, 12.60s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:05:02<08:32, 12.51s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:05:14<08:17, 12.43s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:05:27<08:08, 12.51s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:05:39<07:57, 12.56s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:05:52<07:44, 12.54s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:06:04<07:31, 12.54s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:06:17<07:19, 12.55s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:06:30<07:06, 12.55s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:06:42<06:54, 12.57s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:06:55<06:42, 12.57s/it]predicting train subjects:  90%|█████████ | 280/311 [1:07:07<06:25, 12.44s/it]predicting train subjects:  90%|█████████ | 281/311 [1:07:19<06:11, 12.38s/it]predicting train subjects:  91%|█████████ | 282/311 [1:07:32<06:02, 12.49s/it]predicting train subjects:  91%|█████████ | 283/311 [1:07:44<05:42, 12.25s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:07:55<05:23, 11.99s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:08:06<05:03, 11.67s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:08:17<04:50, 11.63s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:08:29<04:38, 11.62s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:08:40<04:22, 11.43s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:08:52<04:11, 11.45s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:09:03<04:00, 11.47s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:09:14<03:48, 11.42s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:09:25<03:34, 11.26s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:09:37<03:23, 11.31s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:09:48<03:14, 11.42s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:10:00<03:01, 11.35s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:10:11<02:49, 11.32s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:10:22<02:38, 11.32s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:10:33<02:27, 11.33s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:10:46<02:19, 11.61s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:10:57<02:06, 11.46s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:11:08<01:55, 11.51s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:11:20<01:43, 11.55s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:11:32<01:32, 11.57s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:11:44<01:21, 11.65s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:11:55<01:09, 11.54s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:12:07<00:58, 11.61s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:12:18<00:46, 11.63s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:12:30<00:34, 11.57s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:12:41<00:22, 11.47s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:12:53<00:11, 11.50s/it]predicting train subjects: 100%|██████████| 311/311 [1:13:04<00:00, 11.57s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:28:12, 17.07s/it]Loading train:   1%|          | 2/311 [00:25<1:14:32, 14.47s/it]Loading train:   1%|          | 3/311 [00:35<1:08:11, 13.28s/it]Loading train:   1%|▏         | 4/311 [00:46<1:03:38, 12.44s/it]Loading train:   2%|▏         | 5/311 [00:55<58:50, 11.54s/it]  Loading train:   2%|▏         | 6/311 [01:05<55:35, 10.94s/it]Loading train:   2%|▏         | 7/311 [01:16<55:03, 10.87s/it]Loading train:   3%|▎         | 8/311 [01:28<57:24, 11.37s/it]Loading train:   3%|▎         | 9/311 [01:39<57:02, 11.33s/it]Loading train:   3%|▎         | 10/311 [01:49<54:26, 10.85s/it]Loading train:   4%|▎         | 11/311 [02:01<56:18, 11.26s/it]Loading train:   4%|▍         | 12/311 [02:11<54:01, 10.84s/it]Loading train:   4%|▍         | 13/311 [02:21<52:09, 10.50s/it]Loading train:   5%|▍         | 14/311 [02:33<54:44, 11.06s/it]Loading train:   5%|▍         | 15/311 [02:42<51:35, 10.46s/it]Loading train:   5%|▌         | 16/311 [02:51<49:23, 10.05s/it]Loading train:   5%|▌         | 17/311 [03:01<47:56,  9.78s/it]Loading train:   6%|▌         | 18/311 [03:10<46:39,  9.55s/it]Loading train:   6%|▌         | 19/311 [03:19<45:41,  9.39s/it]Loading train:   6%|▋         | 20/311 [03:28<44:56,  9.27s/it]Loading train:   7%|▋         | 21/311 [03:37<44:58,  9.30s/it]Loading train:   7%|▋         | 22/311 [03:46<44:05,  9.15s/it]Loading train:   7%|▋         | 23/311 [03:55<44:28,  9.27s/it]Loading train:   8%|▊         | 24/311 [04:05<44:11,  9.24s/it]Loading train:   8%|▊         | 25/311 [04:14<44:15,  9.28s/it]Loading train:   8%|▊         | 26/311 [04:23<44:21,  9.34s/it]Loading train:   9%|▊         | 27/311 [04:33<44:57,  9.50s/it]Loading train:   9%|▉         | 28/311 [04:43<45:33,  9.66s/it]Loading train:   9%|▉         | 29/311 [04:53<45:46,  9.74s/it]Loading train:  10%|▉         | 30/311 [05:03<45:58,  9.82s/it]Loading train:  10%|▉         | 31/311 [05:13<45:28,  9.75s/it]Loading train:  10%|█         | 32/311 [05:23<45:25,  9.77s/it]Loading train:  11%|█         | 33/311 [05:28<38:58,  8.41s/it]Loading train:  11%|█         | 34/311 [05:33<34:02,  7.37s/it]Loading train:  11%|█▏        | 35/311 [05:38<30:53,  6.71s/it]Loading train:  12%|█▏        | 36/311 [05:43<28:19,  6.18s/it]Loading train:  12%|█▏        | 37/311 [05:48<26:35,  5.82s/it]Loading train:  12%|█▏        | 38/311 [05:53<25:30,  5.61s/it]Loading train:  13%|█▎        | 39/311 [05:58<25:07,  5.54s/it]Loading train:  13%|█▎        | 40/311 [06:03<24:01,  5.32s/it]Loading train:  13%|█▎        | 41/311 [06:08<23:34,  5.24s/it]Loading train:  14%|█▎        | 42/311 [06:13<23:04,  5.15s/it]Loading train:  14%|█▍        | 43/311 [06:18<22:55,  5.13s/it]Loading train:  14%|█▍        | 44/311 [06:23<22:45,  5.12s/it]Loading train:  14%|█▍        | 45/311 [06:28<22:39,  5.11s/it]Loading train:  15%|█▍        | 46/311 [06:34<22:36,  5.12s/it]Loading train:  15%|█▌        | 47/311 [06:39<22:45,  5.17s/it]Loading train:  15%|█▌        | 48/311 [06:44<22:14,  5.07s/it]Loading train:  16%|█▌        | 49/311 [06:49<22:02,  5.05s/it]Loading train:  16%|█▌        | 50/311 [06:54<22:02,  5.07s/it]Loading train:  16%|█▋        | 51/311 [07:00<23:39,  5.46s/it]Loading train:  17%|█▋        | 52/311 [07:06<24:38,  5.71s/it]Loading train:  17%|█▋        | 53/311 [07:13<25:02,  5.82s/it]Loading train:  17%|█▋        | 54/311 [07:18<25:01,  5.84s/it]Loading train:  18%|█▊        | 55/311 [07:25<25:13,  5.91s/it]Loading train:  18%|█▊        | 56/311 [07:31<25:28,  6.00s/it]Loading train:  18%|█▊        | 57/311 [07:37<25:21,  5.99s/it]Loading train:  19%|█▊        | 58/311 [07:43<25:31,  6.05s/it]Loading train:  19%|█▉        | 59/311 [07:49<25:31,  6.08s/it]Loading train:  19%|█▉        | 60/311 [07:55<25:36,  6.12s/it]Loading train:  20%|█▉        | 61/311 [08:01<25:25,  6.10s/it]Loading train:  20%|█▉        | 62/311 [08:07<25:01,  6.03s/it]Loading train:  20%|██        | 63/311 [08:14<25:16,  6.11s/it]Loading train:  21%|██        | 64/311 [08:20<25:31,  6.20s/it]Loading train:  21%|██        | 65/311 [08:26<25:29,  6.22s/it]Loading train:  21%|██        | 66/311 [08:32<25:12,  6.17s/it]Loading train:  22%|██▏       | 67/311 [08:38<24:57,  6.14s/it]Loading train:  22%|██▏       | 68/311 [08:44<24:50,  6.13s/it]Loading train:  22%|██▏       | 69/311 [08:50<24:33,  6.09s/it]Loading train:  23%|██▎       | 70/311 [08:56<24:06,  6.00s/it]Loading train:  23%|██▎       | 71/311 [09:02<24:07,  6.03s/it]Loading train:  23%|██▎       | 72/311 [09:08<23:32,  5.91s/it]Loading train:  23%|██▎       | 73/311 [09:14<23:22,  5.89s/it]Loading train:  24%|██▍       | 74/311 [09:19<23:04,  5.84s/it]Loading train:  24%|██▍       | 75/311 [09:25<22:59,  5.85s/it]Loading train:  24%|██▍       | 76/311 [09:31<22:53,  5.85s/it]Loading train:  25%|██▍       | 77/311 [09:37<22:43,  5.83s/it]Loading train:  25%|██▌       | 78/311 [09:43<22:33,  5.81s/it]Loading train:  25%|██▌       | 79/311 [09:49<22:53,  5.92s/it]Loading train:  26%|██▌       | 80/311 [09:55<22:41,  5.89s/it]Loading train:  26%|██▌       | 81/311 [10:01<22:26,  5.85s/it]Loading train:  26%|██▋       | 82/311 [10:07<22:30,  5.90s/it]Loading train:  27%|██▋       | 83/311 [10:13<22:38,  5.96s/it]Loading train:  27%|██▋       | 84/311 [10:18<22:16,  5.89s/it]Loading train:  27%|██▋       | 85/311 [10:24<21:34,  5.73s/it]Loading train:  28%|██▊       | 86/311 [10:29<21:04,  5.62s/it]Loading train:  28%|██▊       | 87/311 [10:35<20:54,  5.60s/it]Loading train:  28%|██▊       | 88/311 [10:40<20:38,  5.56s/it]Loading train:  29%|██▊       | 89/311 [10:46<20:29,  5.54s/it]Loading train:  29%|██▉       | 90/311 [10:51<20:18,  5.51s/it]Loading train:  29%|██▉       | 91/311 [10:57<20:10,  5.50s/it]Loading train:  30%|██▉       | 92/311 [11:02<20:04,  5.50s/it]Loading train:  30%|██▉       | 93/311 [11:08<20:02,  5.52s/it]Loading train:  30%|███       | 94/311 [11:13<19:49,  5.48s/it]Loading train:  31%|███       | 95/311 [11:19<20:00,  5.56s/it]Loading train:  31%|███       | 96/311 [11:24<19:36,  5.47s/it]Loading train:  31%|███       | 97/311 [11:29<19:26,  5.45s/it]Loading train:  32%|███▏      | 98/311 [11:35<19:12,  5.41s/it]Loading train:  32%|███▏      | 99/311 [11:41<19:40,  5.57s/it]Loading train:  32%|███▏      | 100/311 [11:46<19:19,  5.50s/it]Loading train:  32%|███▏      | 101/311 [11:51<19:06,  5.46s/it]Loading train:  33%|███▎      | 102/311 [11:57<19:13,  5.52s/it]Loading train:  33%|███▎      | 103/311 [12:02<19:05,  5.50s/it]Loading train:  33%|███▎      | 104/311 [12:08<18:46,  5.44s/it]Loading train:  34%|███▍      | 105/311 [12:13<18:27,  5.37s/it]Loading train:  34%|███▍      | 106/311 [12:19<18:33,  5.43s/it]Loading train:  34%|███▍      | 107/311 [12:24<18:20,  5.40s/it]Loading train:  35%|███▍      | 108/311 [12:30<19:33,  5.78s/it]Loading train:  35%|███▌      | 109/311 [12:38<21:02,  6.25s/it]Loading train:  35%|███▌      | 110/311 [12:45<21:56,  6.55s/it]Loading train:  36%|███▌      | 111/311 [12:52<22:29,  6.75s/it]Loading train:  36%|███▌      | 112/311 [13:00<23:08,  6.98s/it]Loading train:  36%|███▋      | 113/311 [13:07<22:54,  6.94s/it]Loading train:  37%|███▋      | 114/311 [13:19<27:49,  8.48s/it]Loading train:  37%|███▋      | 115/311 [13:32<31:55,  9.77s/it]Loading train:  37%|███▋      | 116/311 [13:44<34:31, 10.62s/it]Loading train:  38%|███▊      | 117/311 [13:55<35:01, 10.83s/it]Loading train:  38%|███▊      | 118/311 [14:07<35:24, 11.01s/it]Loading train:  38%|███▊      | 119/311 [14:18<34:57, 10.93s/it]Loading train:  39%|███▊      | 120/311 [14:29<35:17, 11.08s/it]Loading train:  39%|███▉      | 121/311 [14:40<35:23, 11.18s/it]Loading train:  39%|███▉      | 122/311 [14:52<35:18, 11.21s/it]Loading train:  40%|███▉      | 123/311 [15:03<35:26, 11.31s/it]Loading train:  40%|███▉      | 124/311 [15:14<35:08, 11.28s/it]Loading train:  40%|████      | 125/311 [15:26<35:12, 11.36s/it]Loading train:  41%|████      | 126/311 [15:37<34:41, 11.25s/it]Loading train:  41%|████      | 127/311 [15:48<34:12, 11.15s/it]Loading train:  41%|████      | 128/311 [15:59<33:56, 11.13s/it]Loading train:  41%|████▏     | 129/311 [16:10<33:20, 10.99s/it]Loading train:  42%|████▏     | 130/311 [16:21<33:44, 11.19s/it]Loading train:  42%|████▏     | 131/311 [16:33<34:15, 11.42s/it]Loading train:  42%|████▏     | 132/311 [16:40<29:25,  9.86s/it]Loading train:  43%|████▎     | 133/311 [16:45<25:47,  8.69s/it]Loading train:  43%|████▎     | 134/311 [16:51<22:54,  7.76s/it]Loading train:  43%|████▎     | 135/311 [16:57<21:11,  7.22s/it]Loading train:  44%|████▎     | 136/311 [17:03<19:32,  6.70s/it]Loading train:  44%|████▍     | 137/311 [17:09<19:05,  6.58s/it]Loading train:  44%|████▍     | 138/311 [17:14<18:00,  6.24s/it]Loading train:  45%|████▍     | 139/311 [17:20<17:44,  6.19s/it]Loading train:  45%|████▌     | 140/311 [17:26<17:05,  6.00s/it]Loading train:  45%|████▌     | 141/311 [17:32<17:07,  6.04s/it]Loading train:  46%|████▌     | 142/311 [17:38<16:40,  5.92s/it]Loading train:  46%|████▌     | 143/311 [17:43<16:10,  5.77s/it]Loading train:  46%|████▋     | 144/311 [17:49<16:08,  5.80s/it]Loading train:  47%|████▋     | 145/311 [17:55<16:04,  5.81s/it]Loading train:  47%|████▋     | 146/311 [18:00<15:49,  5.76s/it]Loading train:  47%|████▋     | 147/311 [18:07<16:01,  5.86s/it]Loading train:  48%|████▊     | 148/311 [18:12<15:55,  5.86s/it]Loading train:  48%|████▊     | 149/311 [18:18<15:50,  5.87s/it]Loading train:  48%|████▊     | 150/311 [18:25<16:21,  6.09s/it]Loading train:  49%|████▊     | 151/311 [18:32<16:58,  6.36s/it]Loading train:  49%|████▉     | 152/311 [18:39<17:13,  6.50s/it]Loading train:  49%|████▉     | 153/311 [18:45<17:20,  6.58s/it]Loading train:  50%|████▉     | 154/311 [18:52<17:27,  6.67s/it]Loading train:  50%|████▉     | 155/311 [18:59<17:29,  6.73s/it]Loading train:  50%|█████     | 156/311 [19:05<16:58,  6.57s/it]Loading train:  50%|█████     | 157/311 [19:13<17:26,  6.79s/it]Loading train:  51%|█████     | 158/311 [19:18<16:11,  6.35s/it]Loading train:  51%|█████     | 159/311 [19:24<15:33,  6.14s/it]Loading train:  51%|█████▏    | 160/311 [19:30<15:11,  6.04s/it]Loading train:  52%|█████▏    | 161/311 [19:35<14:40,  5.87s/it]Loading train:  52%|█████▏    | 162/311 [19:41<14:24,  5.80s/it]Loading train:  52%|█████▏    | 163/311 [19:46<14:18,  5.80s/it]Loading train:  53%|█████▎    | 164/311 [19:52<13:39,  5.58s/it]Loading train:  53%|█████▎    | 165/311 [19:57<13:27,  5.53s/it]Loading train:  53%|█████▎    | 166/311 [20:02<13:04,  5.41s/it]Loading train:  54%|█████▎    | 167/311 [20:07<12:42,  5.30s/it]Loading train:  54%|█████▍    | 168/311 [20:12<12:40,  5.32s/it]Loading train:  54%|█████▍    | 169/311 [20:18<12:29,  5.28s/it]Loading train:  55%|█████▍    | 170/311 [20:23<12:32,  5.34s/it]Loading train:  55%|█████▍    | 171/311 [20:28<12:24,  5.32s/it]Loading train:  55%|█████▌    | 172/311 [20:34<12:21,  5.33s/it]Loading train:  56%|█████▌    | 173/311 [20:39<12:20,  5.37s/it]Loading train:  56%|█████▌    | 174/311 [20:45<12:15,  5.37s/it]Loading train:  56%|█████▋    | 175/311 [20:50<12:11,  5.38s/it]Loading train:  57%|█████▋    | 176/311 [20:55<11:57,  5.31s/it]Loading train:  57%|█████▋    | 177/311 [21:00<11:38,  5.21s/it]Loading train:  57%|█████▋    | 178/311 [21:05<11:35,  5.23s/it]Loading train:  58%|█████▊    | 179/311 [21:11<11:38,  5.29s/it]Loading train:  58%|█████▊    | 180/311 [21:16<11:30,  5.27s/it]Loading train:  58%|█████▊    | 181/311 [21:21<11:15,  5.20s/it]Loading train:  59%|█████▊    | 182/311 [21:26<11:05,  5.16s/it]Loading train:  59%|█████▉    | 183/311 [21:32<11:12,  5.25s/it]Loading train:  59%|█████▉    | 184/311 [21:36<10:50,  5.12s/it]Loading train:  59%|█████▉    | 185/311 [21:41<10:42,  5.10s/it]Loading train:  60%|█████▉    | 186/311 [21:47<10:38,  5.11s/it]Loading train:  60%|██████    | 187/311 [21:51<10:25,  5.04s/it]Loading train:  60%|██████    | 188/311 [21:56<10:02,  4.90s/it]Loading train:  61%|██████    | 189/311 [22:01<09:55,  4.88s/it]Loading train:  61%|██████    | 190/311 [22:06<09:57,  4.94s/it]Loading train:  61%|██████▏   | 191/311 [22:11<09:52,  4.94s/it]Loading train:  62%|██████▏   | 192/311 [22:16<09:51,  4.97s/it]Loading train:  62%|██████▏   | 193/311 [22:21<09:55,  5.04s/it]Loading train:  62%|██████▏   | 194/311 [22:26<09:45,  5.01s/it]Loading train:  63%|██████▎   | 195/311 [22:31<09:33,  4.94s/it]Loading train:  63%|██████▎   | 196/311 [22:36<09:29,  4.95s/it]Loading train:  63%|██████▎   | 197/311 [22:41<09:21,  4.92s/it]Loading train:  64%|██████▎   | 198/311 [22:46<09:13,  4.90s/it]Loading train:  64%|██████▍   | 199/311 [22:50<09:08,  4.90s/it]Loading train:  64%|██████▍   | 200/311 [22:55<09:05,  4.91s/it]Loading train:  65%|██████▍   | 201/311 [23:00<08:53,  4.85s/it]Loading train:  65%|██████▍   | 202/311 [23:05<08:44,  4.81s/it]Loading train:  65%|██████▌   | 203/311 [23:10<08:40,  4.82s/it]Loading train:  66%|██████▌   | 204/311 [23:15<08:39,  4.85s/it]Loading train:  66%|██████▌   | 205/311 [23:20<08:36,  4.87s/it]Loading train:  66%|██████▌   | 206/311 [23:25<08:42,  4.97s/it]Loading train:  67%|██████▋   | 207/311 [23:30<08:37,  4.98s/it]Loading train:  67%|██████▋   | 208/311 [23:35<08:27,  4.93s/it]Loading train:  67%|██████▋   | 209/311 [23:40<08:27,  4.97s/it]Loading train:  68%|██████▊   | 210/311 [23:45<08:26,  5.02s/it]Loading train:  68%|██████▊   | 211/311 [23:50<08:19,  4.99s/it]Loading train:  68%|██████▊   | 212/311 [23:55<08:11,  4.96s/it]Loading train:  68%|██████▊   | 213/311 [24:04<10:18,  6.31s/it]Loading train:  69%|██████▉   | 214/311 [24:13<11:26,  7.07s/it]Loading train:  69%|██████▉   | 215/311 [24:22<12:05,  7.55s/it]Loading train:  69%|██████▉   | 216/311 [24:30<12:28,  7.88s/it]Loading train:  70%|██████▉   | 217/311 [24:39<12:43,  8.13s/it]Loading train:  70%|███████   | 218/311 [24:48<12:55,  8.34s/it]Loading train:  70%|███████   | 219/311 [24:57<13:03,  8.51s/it]Loading train:  71%|███████   | 220/311 [25:05<13:04,  8.62s/it]Loading train:  71%|███████   | 221/311 [25:14<13:02,  8.70s/it]Loading train:  71%|███████▏  | 222/311 [25:23<12:59,  8.76s/it]Loading train:  72%|███████▏  | 223/311 [25:32<12:42,  8.66s/it]Loading train:  72%|███████▏  | 224/311 [25:41<12:40,  8.74s/it]Loading train:  72%|███████▏  | 225/311 [25:49<12:25,  8.67s/it]Loading train:  73%|███████▎  | 226/311 [25:58<12:21,  8.73s/it]Loading train:  73%|███████▎  | 227/311 [26:07<12:12,  8.72s/it]Loading train:  73%|███████▎  | 228/311 [26:15<12:02,  8.70s/it]Loading train:  74%|███████▎  | 229/311 [26:24<11:55,  8.72s/it]Loading train:  74%|███████▍  | 230/311 [26:34<12:05,  8.96s/it]Loading train:  74%|███████▍  | 231/311 [26:38<10:10,  7.63s/it]Loading train:  75%|███████▍  | 232/311 [26:43<08:50,  6.71s/it]Loading train:  75%|███████▍  | 233/311 [26:47<07:49,  6.02s/it]Loading train:  75%|███████▌  | 234/311 [26:51<07:04,  5.51s/it]Loading train:  76%|███████▌  | 235/311 [26:56<06:32,  5.17s/it]Loading train:  76%|███████▌  | 236/311 [27:00<06:12,  4.97s/it]Loading train:  76%|███████▌  | 237/311 [27:05<05:56,  4.82s/it]Loading train:  77%|███████▋  | 238/311 [27:09<05:37,  4.62s/it]Loading train:  77%|███████▋  | 239/311 [27:14<05:32,  4.62s/it]Loading train:  77%|███████▋  | 240/311 [27:18<05:27,  4.62s/it]Loading train:  77%|███████▋  | 241/311 [27:23<05:18,  4.55s/it]Loading train:  78%|███████▊  | 242/311 [27:27<05:07,  4.46s/it]Loading train:  78%|███████▊  | 243/311 [27:32<05:09,  4.55s/it]Loading train:  78%|███████▊  | 244/311 [27:36<05:00,  4.49s/it]Loading train:  79%|███████▉  | 245/311 [27:40<04:55,  4.48s/it]Loading train:  79%|███████▉  | 246/311 [27:45<04:48,  4.44s/it]Loading train:  79%|███████▉  | 247/311 [27:50<04:50,  4.53s/it]Loading train:  80%|███████▉  | 248/311 [27:54<04:41,  4.47s/it]Loading train:  80%|████████  | 249/311 [27:59<04:51,  4.70s/it]Loading train:  80%|████████  | 250/311 [28:05<05:02,  4.95s/it]Loading train:  81%|████████  | 251/311 [28:10<05:04,  5.07s/it]Loading train:  81%|████████  | 252/311 [28:15<05:01,  5.11s/it]Loading train:  81%|████████▏ | 253/311 [28:21<05:02,  5.22s/it]Loading train:  82%|████████▏ | 254/311 [28:26<05:07,  5.39s/it]Loading train:  82%|████████▏ | 255/311 [28:32<05:02,  5.41s/it]Loading train:  82%|████████▏ | 256/311 [28:37<05:00,  5.47s/it]Loading train:  83%|████████▎ | 257/311 [28:43<04:54,  5.45s/it]Loading train:  83%|████████▎ | 258/311 [28:48<04:44,  5.37s/it]Loading train:  83%|████████▎ | 259/311 [28:53<04:40,  5.39s/it]Loading train:  84%|████████▎ | 260/311 [28:59<04:40,  5.49s/it]Loading train:  84%|████████▍ | 261/311 [29:05<04:33,  5.47s/it]Loading train:  84%|████████▍ | 262/311 [29:10<04:29,  5.51s/it]Loading train:  85%|████████▍ | 263/311 [29:16<04:21,  5.46s/it]Loading train:  85%|████████▍ | 264/311 [29:21<04:15,  5.44s/it]Loading train:  85%|████████▌ | 265/311 [29:27<04:14,  5.52s/it]Loading train:  86%|████████▌ | 266/311 [29:32<04:09,  5.54s/it]Loading train:  86%|████████▌ | 267/311 [29:37<03:58,  5.41s/it]Loading train:  86%|████████▌ | 268/311 [29:43<03:50,  5.36s/it]Loading train:  86%|████████▋ | 269/311 [29:48<03:49,  5.46s/it]Loading train:  87%|████████▋ | 270/311 [29:53<03:39,  5.36s/it]Loading train:  87%|████████▋ | 271/311 [29:59<03:37,  5.43s/it]Loading train:  87%|████████▋ | 272/311 [30:05<03:37,  5.57s/it]Loading train:  88%|████████▊ | 273/311 [30:10<03:28,  5.50s/it]Loading train:  88%|████████▊ | 274/311 [30:16<03:23,  5.50s/it]Loading train:  88%|████████▊ | 275/311 [30:21<03:17,  5.48s/it]Loading train:  89%|████████▊ | 276/311 [30:27<03:10,  5.45s/it]Loading train:  89%|████████▉ | 277/311 [30:32<03:07,  5.53s/it]Loading train:  89%|████████▉ | 278/311 [30:38<03:04,  5.58s/it]Loading train:  90%|████████▉ | 279/311 [30:43<02:53,  5.43s/it]Loading train:  90%|█████████ | 280/311 [30:48<02:47,  5.40s/it]Loading train:  90%|█████████ | 281/311 [30:54<02:44,  5.50s/it]Loading train:  91%|█████████ | 282/311 [31:00<02:41,  5.56s/it]Loading train:  91%|█████████ | 283/311 [31:05<02:30,  5.39s/it]Loading train:  91%|█████████▏| 284/311 [31:10<02:23,  5.33s/it]Loading train:  92%|█████████▏| 285/311 [31:15<02:14,  5.19s/it]Loading train:  92%|█████████▏| 286/311 [31:20<02:08,  5.16s/it]Loading train:  92%|█████████▏| 287/311 [31:25<02:04,  5.19s/it]Loading train:  93%|█████████▎| 288/311 [31:30<01:57,  5.10s/it]Loading train:  93%|█████████▎| 289/311 [31:35<01:51,  5.06s/it]Loading train:  93%|█████████▎| 290/311 [31:40<01:47,  5.10s/it]Loading train:  94%|█████████▎| 291/311 [31:46<01:42,  5.14s/it]Loading train:  94%|█████████▍| 292/311 [31:51<01:37,  5.14s/it]Loading train:  94%|█████████▍| 293/311 [31:56<01:32,  5.14s/it]Loading train:  95%|█████████▍| 294/311 [32:01<01:29,  5.25s/it]Loading train:  95%|█████████▍| 295/311 [32:06<01:22,  5.19s/it]Loading train:  95%|█████████▌| 296/311 [32:12<01:17,  5.19s/it]Loading train:  95%|█████████▌| 297/311 [32:17<01:12,  5.16s/it]Loading train:  96%|█████████▌| 298/311 [32:22<01:06,  5.14s/it]Loading train:  96%|█████████▌| 299/311 [32:27<01:02,  5.20s/it]Loading train:  96%|█████████▋| 300/311 [32:32<00:57,  5.20s/it]Loading train:  97%|█████████▋| 301/311 [32:37<00:51,  5.16s/it]Loading train:  97%|█████████▋| 302/311 [32:42<00:45,  5.10s/it]Loading train:  97%|█████████▋| 303/311 [32:47<00:40,  5.09s/it]Loading train:  98%|█████████▊| 304/311 [32:53<00:36,  5.15s/it]Loading train:  98%|█████████▊| 305/311 [32:58<00:30,  5.12s/it]Loading train:  98%|█████████▊| 306/311 [33:03<00:25,  5.12s/it]Loading train:  99%|█████████▊| 307/311 [33:08<00:20,  5.17s/it]Loading train:  99%|█████████▉| 308/311 [33:13<00:15,  5.06s/it]Loading train:  99%|█████████▉| 309/311 [33:18<00:10,  5.11s/it]Loading train: 100%|█████████▉| 310/311 [33:23<00:05,  5.16s/it]Loading train: 100%|██████████| 311/311 [33:28<00:00,  5.11s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 14/311 [00:00<00:02, 135.16it/s]concatenating: train:  10%|▉         | 30/311 [00:00<00:02, 139.71it/s]concatenating: train:  15%|█▌        | 47/311 [00:00<00:01, 145.16it/s]concatenating: train:  21%|██        | 64/311 [00:00<00:01, 151.06it/s]concatenating: train:  24%|██▍       | 76/311 [00:00<00:02, 80.28it/s] concatenating: train:  32%|███▏      | 101/311 [00:00<00:02, 100.70it/s]concatenating: train:  41%|████      | 128/311 [00:00<00:01, 122.93it/s]concatenating: train:  50%|█████     | 157/311 [00:01<00:01, 147.88it/s]concatenating: train:  57%|█████▋    | 178/311 [00:01<00:00, 156.25it/s]concatenating: train:  64%|██████▎   | 198/311 [00:01<00:00, 150.59it/s]concatenating: train:  70%|███████   | 219/311 [00:01<00:00, 164.51it/s]concatenating: train:  77%|███████▋  | 239/311 [00:01<00:00, 173.59it/s]concatenating: train:  86%|████████▌ | 266/311 [00:01<00:00, 193.64it/s]concatenating: train:  94%|█████████▍| 293/311 [00:01<00:00, 210.58it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 175.38it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 11.96s/it]Loading test:  50%|█████     | 2/4 [00:23<00:23, 11.72s/it]Loading test:  75%|███████▌  | 3/4 [00:34<00:11, 11.76s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.71s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 65.48it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-08 01:43:39.727225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 01:43:39.727340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 01:43:39.727356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 01:43:39.727366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 01:43:39.727794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 40, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [5.87995836e-02 2.85625934e-02 1.22042724e-01 1.04920441e-02
 3.15682606e-02 5.46103058e-03 7.22892131e-02 1.13259646e-01
 7.87837639e-02 1.27868129e-02 2.92912776e-01 1.72791632e-01
 2.49918858e-04]
Train on 12355 samples, validate on 158 samples
Epoch 1/300
 - 21s - loss: 13738.0234 - acc: 0.8743 - mDice: 0.3073 - val_loss: 5803.5580 - val_acc: 0.9075 - val_mDice: 0.4367

Epoch 00001: val_mDice improved from -inf to 0.43666, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 12s - loss: 4778.5488 - acc: 0.9117 - mDice: 0.5377 - val_loss: 4127.7418 - val_acc: 0.9227 - val_mDice: 0.5482

Epoch 00002: val_mDice improved from 0.43666 to 0.54823, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 3762.7296 - acc: 0.9260 - mDice: 0.6108 - val_loss: 3277.0289 - val_acc: 0.9317 - val_mDice: 0.6088

Epoch 00003: val_mDice improved from 0.54823 to 0.60884, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 12s - loss: 3324.2592 - acc: 0.9321 - mDice: 0.6462 - val_loss: 2877.0623 - val_acc: 0.9366 - val_mDice: 0.6472

Epoch 00004: val_mDice improved from 0.60884 to 0.64720, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 13s - loss: 3044.1386 - acc: 0.9358 - mDice: 0.6698 - val_loss: 2730.1661 - val_acc: 0.9398 - val_mDice: 0.6602

Epoch 00005: val_mDice improved from 0.64720 to 0.66018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 12s - loss: 2858.7923 - acc: 0.9384 - mDice: 0.6864 - val_loss: 2624.4310 - val_acc: 0.9429 - val_mDice: 0.6694

Epoch 00006: val_mDice improved from 0.66018 to 0.66937, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 13s - loss: 2719.7869 - acc: 0.9403 - mDice: 0.6989 - val_loss: 2771.0690 - val_acc: 0.9426 - val_mDice: 0.6582

Epoch 00007: val_mDice did not improve from 0.66937
Epoch 8/300
 - 12s - loss: 2586.6050 - acc: 0.9418 - mDice: 0.7110 - val_loss: 2674.7580 - val_acc: 0.9441 - val_mDice: 0.6694

Epoch 00008: val_mDice improved from 0.66937 to 0.66939, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 13s - loss: 2499.1492 - acc: 0.9429 - mDice: 0.7191 - val_loss: 2579.5116 - val_acc: 0.9456 - val_mDice: 0.6770

Epoch 00009: val_mDice improved from 0.66939 to 0.67703, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 12s - loss: 2420.9165 - acc: 0.9440 - mDice: 0.7264 - val_loss: 2748.8368 - val_acc: 0.9444 - val_mDice: 0.6652

Epoch 00010: val_mDice did not improve from 0.67703
Epoch 11/300
 - 13s - loss: 2357.0452 - acc: 0.9447 - mDice: 0.7324 - val_loss: 2682.4011 - val_acc: 0.9443 - val_mDice: 0.6704

Epoch 00011: val_mDice did not improve from 0.67703
Epoch 12/300
 - 12s - loss: 2272.5094 - acc: 0.9458 - mDice: 0.7404 - val_loss: 2696.9126 - val_acc: 0.9438 - val_mDice: 0.6694

Epoch 00012: val_mDice did not improve from 0.67703
Epoch 13/300
 - 12s - loss: 2223.1827 - acc: 0.9465 - mDice: 0.7452 - val_loss: 2573.5869 - val_acc: 0.9477 - val_mDice: 0.6811

Epoch 00013: val_mDice improved from 0.67703 to 0.68109, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 12s - loss: 2163.3464 - acc: 0.9473 - mDice: 0.7510 - val_loss: 2619.5358 - val_acc: 0.9467 - val_mDice: 0.6769

Epoch 00014: val_mDice did not improve from 0.68109
Epoch 15/300
 - 13s - loss: 2128.1514 - acc: 0.9477 - mDice: 0.7545 - val_loss: 2632.2132 - val_acc: 0.9488 - val_mDice: 0.6753

Epoch 00015: val_mDice did not improve from 0.68109
Epoch 16/300
 - 13s - loss: 2082.0228 - acc: 0.9483 - mDice: 0.7590 - val_loss: 2801.6802 - val_acc: 0.9458 - val_mDice: 0.6615

Epoch 00016: val_mDice did not improve from 0.68109
Epoch 17/300
 - 13s - loss: 2035.4163 - acc: 0.9489 - mDice: 0.7637 - val_loss: 2441.8482 - val_acc: 0.9508 - val_mDice: 0.6891

Epoch 00017: val_mDice improved from 0.68109 to 0.68909, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 13s - loss: 2013.1763 - acc: 0.9493 - mDice: 0.7659 - val_loss: 3170.3934 - val_acc: 0.9423 - val_mDice: 0.6330

Epoch 00018: val_mDice did not improve from 0.68909
Epoch 19/300
 - 14s - loss: 1961.6576 - acc: 0.9497 - mDice: 0.7710 - val_loss: 2898.9981 - val_acc: 0.9435 - val_mDice: 0.6520

Epoch 00019: val_mDice did not improve from 0.68909
Epoch 20/300
 - 12s - loss: 1936.1080 - acc: 0.9502 - mDice: 0.7736 - val_loss: 2820.6776 - val_acc: 0.9450 - val_mDice: 0.6609

Epoch 00020: val_mDice did not improve from 0.68909
Epoch 21/300
 - 14s - loss: 1906.6818 - acc: 0.9506 - mDice: 0.7766 - val_loss: 2732.3670 - val_acc: 0.9465 - val_mDice: 0.6686

Epoch 00021: val_mDice did not improve from 0.68909
Epoch 22/300
 - 13s - loss: 1885.2988 - acc: 0.9509 - mDice: 0.7788 - val_loss: 2599.4180 - val_acc: 0.9480 - val_mDice: 0.6801

Epoch 00022: val_mDice did not improve from 0.68909
Epoch 23/300
 - 14s - loss: 1851.3578 - acc: 0.9512 - mDice: 0.7823 - val_loss: 2567.4916 - val_acc: 0.9513 - val_mDice: 0.6832

Epoch 00023: val_mDice did not improve from 0.68909
Epoch 24/300
 - 13s - loss: 1829.5834 - acc: 0.9515 - mDice: 0.7845 - val_loss: 2403.6430 - val_acc: 0.9529 - val_mDice: 0.6956

Epoch 00024: val_mDice improved from 0.68909 to 0.69557, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 14s - loss: 1811.0211 - acc: 0.9517 - mDice: 0.7864 - val_loss: 2451.6410 - val_acc: 0.9529 - val_mDice: 0.6896

Epoch 00025: val_mDice did not improve from 0.69557
Epoch 26/300
 - 13s - loss: 1782.5184 - acc: 0.9522 - mDice: 0.7893 - val_loss: 2523.2256 - val_acc: 0.9511 - val_mDice: 0.6871

Epoch 00026: val_mDice did not improve from 0.69557
Epoch 27/300
 - 13s - loss: 1759.4066 - acc: 0.9525 - mDice: 0.7917 - val_loss: 2482.5118 - val_acc: 0.9512 - val_mDice: 0.6883

Epoch 00027: val_mDice did not improve from 0.69557
Epoch 28/300
 - 13s - loss: 1736.8732 - acc: 0.9527 - mDice: 0.7941 - val_loss: 2822.8665 - val_acc: 0.9484 - val_mDice: 0.6596

Epoch 00028: val_mDice did not improve from 0.69557
Epoch 29/300
 - 13s - loss: 1724.5919 - acc: 0.9529 - mDice: 0.7953 - val_loss: 2734.0534 - val_acc: 0.9509 - val_mDice: 0.6686

Epoch 00029: val_mDice did not improve from 0.69557
Epoch 30/300
 - 14s - loss: 1708.0003 - acc: 0.9532 - mDice: 0.7972 - val_loss: 2944.1225 - val_acc: 0.9461 - val_mDice: 0.6461

Epoch 00030: val_mDice did not improve from 0.69557
Epoch 31/300
 - 13s - loss: 1686.0812 - acc: 0.9534 - mDice: 0.7994 - val_loss: 2755.3835 - val_acc: 0.9479 - val_mDice: 0.6650

Epoch 00031: val_mDice did not improve from 0.69557
Epoch 32/300
 - 14s - loss: 1662.7631 - acc: 0.9537 - mDice: 0.8018 - val_loss: 2358.8949 - val_acc: 0.9540 - val_mDice: 0.6998

Epoch 00032: val_mDice improved from 0.69557 to 0.69983, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 12s - loss: 1651.2363 - acc: 0.9539 - mDice: 0.8031 - val_loss: 3082.7852 - val_acc: 0.9423 - val_mDice: 0.6378

Epoch 00033: val_mDice did not improve from 0.69983
Epoch 34/300
 - 14s - loss: 1629.7623 - acc: 0.9542 - mDice: 0.8053 - val_loss: 3077.9102 - val_acc: 0.9434 - val_mDice: 0.6404

Epoch 00034: val_mDice did not improve from 0.69983
Epoch 35/300
 - 13s - loss: 1630.0847 - acc: 0.9541 - mDice: 0.8053 - val_loss: 2701.0000 - val_acc: 0.9467 - val_mDice: 0.6693

Epoch 00035: val_mDice did not improve from 0.69983
Epoch 36/300
 - 14s - loss: 1616.2992 - acc: 0.9543 - mDice: 0.8068 - val_loss: 3316.4167 - val_acc: 0.9433 - val_mDice: 0.6236

Epoch 00036: val_mDice did not improve from 0.69983
Epoch 37/300
 - 13s - loss: 1601.8756 - acc: 0.9544 - mDice: 0.8082 - val_loss: 2575.0098 - val_acc: 0.9494 - val_mDice: 0.6807

Epoch 00037: val_mDice did not improve from 0.69983
Epoch 38/300
 - 13s - loss: 1580.4309 - acc: 0.9548 - mDice: 0.8106 - val_loss: 2468.5903 - val_acc: 0.9523 - val_mDice: 0.6881

Epoch 00038: val_mDice did not improve from 0.69983
Epoch 39/300
 - 14s - loss: 1565.7720 - acc: 0.9550 - mDice: 0.8121 - val_loss: 2768.4749 - val_acc: 0.9515 - val_mDice: 0.6599

Epoch 00039: val_mDice did not improve from 0.69983
Epoch 40/300
 - 12s - loss: 1549.9633 - acc: 0.9551 - mDice: 0.8138 - val_loss: 2410.8799 - val_acc: 0.9546 - val_mDice: 0.6944

Epoch 00040: val_mDice did not improve from 0.69983
Epoch 41/300
 - 14s - loss: 1549.1569 - acc: 0.9552 - mDice: 0.8139 - val_loss: 2534.3122 - val_acc: 0.9534 - val_mDice: 0.6842

Epoch 00041: val_mDice did not improve from 0.69983
Epoch 42/300
 - 12s - loss: 1535.7532 - acc: 0.9554 - mDice: 0.8153 - val_loss: 2588.4793 - val_acc: 0.9526 - val_mDice: 0.6754

Epoch 00042: val_mDice did not improve from 0.69983
Epoch 43/300
 - 14s - loss: 1517.0744 - acc: 0.9556 - mDice: 0.8174 - val_loss: 2665.8738 - val_acc: 0.9486 - val_mDice: 0.6722

Epoch 00043: val_mDice did not improve from 0.69983
Epoch 44/300
 - 12s - loss: 1509.6524 - acc: 0.9556 - mDice: 0.8181 - val_loss: 2596.7554 - val_acc: 0.9508 - val_mDice: 0.6778

Epoch 00044: val_mDice did not improve from 0.69983
Epoch 45/300
 - 13s - loss: 1496.5329 - acc: 0.9558 - mDice: 0.8196 - val_loss: 3109.0874 - val_acc: 0.9466 - val_mDice: 0.6343

Epoch 00045: val_mDice did not improve from 0.69983
Epoch 46/300
 - 12s - loss: 1486.7235 - acc: 0.9559 - mDice: 0.8206 - val_loss: 2553.4724 - val_acc: 0.9551 - val_mDice: 0.6835

Epoch 00046: val_mDice did not improve from 0.69983
Epoch 47/300
 - 12s - loss: 1479.6590 - acc: 0.9561 - mDice: 0.8214 - val_loss: 2615.0342 - val_acc: 0.9511 - val_mDice: 0.6757

Epoch 00047: val_mDice did not improve from 0.69983
Epoch 48/300
 - 12s - loss: 1469.7480 - acc: 0.9562 - mDice: 0.8225 - val_loss: 2632.4642 - val_acc: 0.9524 - val_mDice: 0.6753

Epoch 00048: val_mDice did not improve from 0.69983
Epoch 49/300
 - 12s - loss: 1458.9929 - acc: 0.9563 - mDice: 0.8237 - val_loss: 2701.0111 - val_acc: 0.9529 - val_mDice: 0.6706

Epoch 00049: val_mDice did not improve from 0.69983
Epoch 50/300
 - 12s - loss: 1446.5318 - acc: 0.9564 - mDice: 0.8250 - val_loss: 2441.5523 - val_acc: 0.9547 - val_mDice: 0.6926

Epoch 00050: val_mDice did not improve from 0.69983
Epoch 51/300
 - 12s - loss: 1443.7418 - acc: 0.9565 - mDice: 0.8253 - val_loss: 2683.7263 - val_acc: 0.9535 - val_mDice: 0.6664

Epoch 00051: val_mDice did not improve from 0.69983
Epoch 52/300
 - 12s - loss: 1440.0008 - acc: 0.9567 - mDice: 0.8257 - val_loss: 2595.9563 - val_acc: 0.9520 - val_mDice: 0.6791

Epoch 00052: val_mDice did not improve from 0.69983
Epoch 53/300
 - 12s - loss: 1421.9718 - acc: 0.9568 - mDice: 0.8277 - val_loss: 2711.8236 - val_acc: 0.9516 - val_mDice: 0.6680

Epoch 00053: val_mDice did not improve from 0.69983
Epoch 54/300
 - 12s - loss: 1412.8610 - acc: 0.9569 - mDice: 0.8286 - val_loss: 2744.7507 - val_acc: 0.9511 - val_mDice: 0.6674

Epoch 00054: val_mDice did not improve from 0.69983
Epoch 55/300
 - 13s - loss: 1412.7042 - acc: 0.9569 - mDice: 0.8287 - val_loss: 2737.2199 - val_acc: 0.9513 - val_mDice: 0.6647

Epoch 00055: val_mDice did not improve from 0.69983
Epoch 56/300
 - 12s - loss: 1402.6671 - acc: 0.9571 - mDice: 0.8298 - val_loss: 2706.7629 - val_acc: 0.9515 - val_mDice: 0.6692

Epoch 00056: val_mDice did not improve from 0.69983
Epoch 57/300
 - 12s - loss: 1399.7088 - acc: 0.9571 - mDice: 0.8301 - val_loss: 2641.8440 - val_acc: 0.9528 - val_mDice: 0.6676

Epoch 00057: val_mDice did not improve from 0.69983
Epoch 58/300
 - 12s - loss: 1386.9092 - acc: 0.9573 - mDice: 0.8315 - val_loss: 2771.0588 - val_acc: 0.9533 - val_mDice: 0.6643

Epoch 00058: val_mDice did not improve from 0.69983
Epoch 59/300
 - 11s - loss: 1378.2566 - acc: 0.9573 - mDice: 0.8325 - val_loss: 2703.2966 - val_acc: 0.9527 - val_mDice: 0.6692

Epoch 00059: val_mDice did not improve from 0.69983
Epoch 60/300
 - 12s - loss: 1375.8201 - acc: 0.9574 - mDice: 0.8327 - val_loss: 2622.6401 - val_acc: 0.9546 - val_mDice: 0.6761

Epoch 00060: val_mDice did not improve from 0.69983
Epoch 61/300
 - 12s - loss: 1369.2503 - acc: 0.9575 - mDice: 0.8335 - val_loss: 2520.5003 - val_acc: 0.9543 - val_mDice: 0.6859

Epoch 00061: val_mDice did not improve from 0.69983
Epoch 62/300
 - 11s - loss: 1354.7345 - acc: 0.9576 - mDice: 0.8350 - val_loss: 3041.4326 - val_acc: 0.9483 - val_mDice: 0.6440

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:44, 14.85s/it]predicting test subjects:  50%|█████     | 2/4 [00:28<00:28, 14.41s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:42<00:14, 14.27s/it]predicting test subjects: 100%|██████████| 4/4 [00:55<00:00, 14.13s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:21<1:51:09, 21.52s/it]predicting train subjects:   1%|          | 2/311 [00:31<1:33:13, 18.10s/it]predicting train subjects:   1%|          | 3/311 [00:44<1:24:34, 16.48s/it]predicting train subjects:   1%|▏         | 4/311 [00:56<1:17:11, 15.08s/it]predicting train subjects:   2%|▏         | 5/311 [01:07<1:10:57, 13.91s/it]predicting train subjects:   2%|▏         | 6/311 [01:18<1:06:55, 13.16s/it]predicting train subjects:   2%|▏         | 7/311 [01:31<1:05:55, 13.01s/it]predicting train subjects:   3%|▎         | 8/311 [01:46<1:08:11, 13.50s/it]predicting train subjects:   3%|▎         | 9/311 [01:59<1:07:33, 13.42s/it]predicting train subjects:   3%|▎         | 10/311 [02:10<1:04:14, 12.81s/it]predicting train subjects:   4%|▎         | 11/311 [02:25<1:07:01, 13.41s/it]predicting train subjects:   4%|▍         | 12/311 [02:36<1:03:49, 12.81s/it]predicting train subjects:   4%|▍         | 13/311 [02:47<1:00:53, 12.26s/it]predicting train subjects:   5%|▍         | 14/311 [03:02<1:04:52, 13.11s/it]predicting train subjects:   5%|▍         | 15/311 [03:23<1:16:04, 15.42s/it]predicting train subjects:   5%|▌         | 16/311 [03:44<1:24:01, 17.09s/it]predicting train subjects:   5%|▌         | 17/311 [04:05<1:28:56, 18.15s/it]predicting train subjects:   6%|▌         | 18/311 [04:25<1:32:08, 18.87s/it]predicting train subjects:   6%|▌         | 19/311 [04:47<1:36:05, 19.75s/it]predicting train subjects:   6%|▋         | 20/311 [05:09<1:38:17, 20.27s/it]predicting train subjects:   7%|▋         | 21/311 [05:30<1:38:55, 20.47s/it]predicting train subjects:   7%|▋         | 22/311 [05:51<1:39:41, 20.70s/it]predicting train subjects:   7%|▋         | 23/311 [06:13<1:40:51, 21.01s/it]predicting train subjects:   8%|▊         | 24/311 [06:34<1:40:54, 21.10s/it]predicting train subjects:   8%|▊         | 25/311 [06:55<1:40:00, 20.98s/it]predicting train subjects:   8%|▊         | 26/311 [07:15<1:39:13, 20.89s/it]predicting train subjects:   9%|▊         | 27/311 [07:36<1:38:01, 20.71s/it]predicting train subjects:   9%|▉         | 28/311 [07:56<1:37:26, 20.66s/it]predicting train subjects:   9%|▉         | 29/311 [08:17<1:37:26, 20.73s/it]predicting train subjects:  10%|▉         | 30/311 [08:38<1:36:54, 20.69s/it]predicting train subjects:  10%|▉         | 31/311 [08:59<1:37:29, 20.89s/it]predicting train subjects:  10%|█         | 32/311 [09:20<1:36:51, 20.83s/it]predicting train subjects:  11%|█         | 33/311 [09:30<1:21:20, 17.56s/it]predicting train subjects:  11%|█         | 34/311 [09:39<1:09:52, 15.14s/it]predicting train subjects:  11%|█▏        | 35/311 [09:49<1:02:11, 13.52s/it]predicting train subjects:  12%|█▏        | 36/311 [09:59<57:03, 12.45s/it]  predicting train subjects:  12%|█▏        | 37/311 [10:08<52:50, 11.57s/it]predicting train subjects:  12%|█▏        | 38/311 [10:19<50:52, 11.18s/it]predicting train subjects:  13%|█▎        | 39/311 [10:29<49:24, 10.90s/it]predicting train subjects:  13%|█▎        | 40/311 [10:38<47:30, 10.52s/it]predicting train subjects:  13%|█▎        | 41/311 [10:48<46:39, 10.37s/it]predicting train subjects:  14%|█▎        | 42/311 [10:59<46:14, 10.32s/it]predicting train subjects:  14%|█▍        | 43/311 [11:08<44:41, 10.01s/it]predicting train subjects:  14%|█▍        | 44/311 [11:18<44:29, 10.00s/it]predicting train subjects:  14%|█▍        | 45/311 [11:28<44:11,  9.97s/it]predicting train subjects:  15%|█▍        | 46/311 [11:38<43:44,  9.90s/it]predicting train subjects:  15%|█▌        | 47/311 [11:48<43:38,  9.92s/it]predicting train subjects:  15%|█▌        | 48/311 [11:58<43:46,  9.99s/it]predicting train subjects:  16%|█▌        | 49/311 [12:08<43:51, 10.04s/it]predicting train subjects:  16%|█▌        | 50/311 [12:17<42:55,  9.87s/it]predicting train subjects:  16%|█▋        | 51/311 [12:30<46:22, 10.70s/it]predicting train subjects:  17%|█▋        | 52/311 [12:43<48:40, 11.28s/it]predicting train subjects:  17%|█▋        | 53/311 [12:55<50:09, 11.66s/it]predicting train subjects:  17%|█▋        | 54/311 [13:08<51:02, 11.92s/it]predicting train subjects:  18%|█▊        | 55/311 [13:20<51:59, 12.19s/it]predicting train subjects:  18%|█▊        | 56/311 [13:33<52:18, 12.31s/it]predicting train subjects:  18%|█▊        | 57/311 [13:46<52:23, 12.37s/it]predicting train subjects:  19%|█▊        | 58/311 [13:58<52:13, 12.39s/it]predicting train subjects:  19%|█▉        | 59/311 [14:10<52:04, 12.40s/it]predicting train subjects:  19%|█▉        | 60/311 [14:23<52:15, 12.49s/it]predicting train subjects:  20%|█▉        | 61/311 [14:36<52:19, 12.56s/it]predicting train subjects:  20%|█▉        | 62/311 [14:49<52:39, 12.69s/it]predicting train subjects:  20%|██        | 63/311 [15:02<52:51, 12.79s/it]predicting train subjects:  21%|██        | 64/311 [15:15<52:31, 12.76s/it]predicting train subjects:  21%|██        | 65/311 [15:28<52:37, 12.83s/it]predicting train subjects:  21%|██        | 66/311 [15:42<54:49, 13.43s/it]predicting train subjects:  22%|██▏       | 67/311 [15:57<56:08, 13.81s/it]predicting train subjects:  22%|██▏       | 68/311 [16:12<57:17, 14.15s/it]predicting train subjects:  22%|██▏       | 69/311 [16:27<58:04, 14.40s/it]predicting train subjects:  23%|██▎       | 70/311 [16:42<58:21, 14.53s/it]predicting train subjects:  23%|██▎       | 71/311 [16:57<58:32, 14.64s/it]predicting train subjects:  23%|██▎       | 72/311 [17:12<58:31, 14.69s/it]predicting train subjects:  23%|██▎       | 73/311 [17:26<58:29, 14.75s/it]predicting train subjects:  24%|██▍       | 74/311 [17:39<56:16, 14.25s/it]predicting train subjects:  24%|██▍       | 75/311 [17:54<55:50, 14.20s/it]predicting train subjects:  24%|██▍       | 76/311 [18:08<56:22, 14.40s/it]predicting train subjects:  25%|██▍       | 77/311 [18:23<56:53, 14.59s/it]predicting train subjects:  25%|██▌       | 78/311 [18:37<55:58, 14.41s/it]predicting train subjects:  25%|██▌       | 79/311 [18:52<55:53, 14.46s/it]predicting train subjects:  26%|██▌       | 80/311 [19:08<56:58, 14.80s/it]predicting train subjects:  26%|██▌       | 81/311 [19:22<56:25, 14.72s/it]predicting train subjects:  26%|██▋       | 82/311 [19:37<56:37, 14.84s/it]predicting train subjects:  27%|██▋       | 83/311 [19:51<55:14, 14.54s/it]predicting train subjects:  27%|██▋       | 84/311 [20:04<53:15, 14.08s/it]predicting train subjects:  27%|██▋       | 85/311 [20:18<52:27, 13.93s/it]predicting train subjects:  28%|██▊       | 86/311 [20:31<51:35, 13.76s/it]predicting train subjects:  28%|██▊       | 87/311 [20:44<50:44, 13.59s/it]predicting train subjects:  28%|██▊       | 88/311 [20:56<48:47, 13.13s/it]predicting train subjects:  29%|██▊       | 89/311 [21:07<45:56, 12.42s/it]predicting train subjects:  29%|██▉       | 90/311 [21:18<43:46, 11.88s/it]predicting train subjects:  29%|██▉       | 91/311 [21:29<42:31, 11.60s/it]predicting train subjects:  30%|██▉       | 92/311 [21:40<41:57, 11.50s/it]predicting train subjects:  30%|██▉       | 93/311 [21:51<40:58, 11.28s/it]predicting train subjects:  30%|███       | 94/311 [22:02<40:48, 11.28s/it]predicting train subjects:  31%|███       | 95/311 [22:13<40:30, 11.25s/it]predicting train subjects:  31%|███       | 96/311 [22:24<40:10, 11.21s/it]predicting train subjects:  31%|███       | 97/311 [22:35<39:30, 11.08s/it]predicting train subjects:  32%|███▏      | 98/311 [22:46<39:12, 11.04s/it]predicting train subjects:  32%|███▏      | 99/311 [22:57<39:07, 11.07s/it]predicting train subjects:  32%|███▏      | 100/311 [23:08<39:08, 11.13s/it]predicting train subjects:  32%|███▏      | 101/311 [23:20<39:21, 11.24s/it]predicting train subjects:  33%|███▎      | 102/311 [23:31<38:48, 11.14s/it]predicting train subjects:  33%|███▎      | 103/311 [23:42<38:26, 11.09s/it]predicting train subjects:  33%|███▎      | 104/311 [23:53<38:35, 11.19s/it]predicting train subjects:  34%|███▍      | 105/311 [24:05<38:33, 11.23s/it]predicting train subjects:  34%|███▍      | 106/311 [24:16<38:11, 11.18s/it]predicting train subjects:  34%|███▍      | 107/311 [24:26<37:40, 11.08s/it]predicting train subjects:  35%|███▍      | 108/311 [24:37<37:20, 11.04s/it]predicting train subjects:  35%|███▌      | 109/311 [24:49<37:20, 11.09s/it]predicting train subjects:  35%|███▌      | 110/311 [25:00<37:21, 11.15s/it]predicting train subjects:  36%|███▌      | 111/311 [25:11<36:55, 11.08s/it]predicting train subjects:  36%|███▌      | 112/311 [25:22<36:44, 11.08s/it]predicting train subjects:  36%|███▋      | 113/311 [25:33<36:55, 11.19s/it]predicting train subjects:  37%|███▋      | 114/311 [25:54<46:11, 14.07s/it]predicting train subjects:  37%|███▋      | 115/311 [26:15<52:17, 16.01s/it]predicting train subjects:  37%|███▋      | 116/311 [26:35<56:09, 17.28s/it]predicting train subjects:  38%|███▊      | 117/311 [26:56<59:10, 18.30s/it]predicting train subjects:  38%|███▊      | 118/311 [27:17<1:01:44, 19.20s/it]predicting train subjects:  38%|███▊      | 119/311 [27:37<1:02:31, 19.54s/it]predicting train subjects:  39%|███▊      | 120/311 [27:58<1:03:25, 19.93s/it]predicting train subjects:  39%|███▉      | 121/311 [28:18<1:03:37, 20.09s/it]predicting train subjects:  39%|███▉      | 122/311 [28:39<1:03:55, 20.29s/it]predicting train subjects:  40%|███▉      | 123/311 [29:00<1:03:59, 20.42s/it]predicting train subjects:  40%|███▉      | 124/311 [29:20<1:03:44, 20.45s/it]predicting train subjects:  40%|████      | 125/311 [29:41<1:03:24, 20.46s/it]predicting train subjects:  41%|████      | 126/311 [30:02<1:03:54, 20.73s/it]predicting train subjects:  41%|████      | 127/311 [30:24<1:04:03, 20.89s/it]predicting train subjects:  41%|████      | 128/311 [30:45<1:03:46, 20.91s/it]predicting train subjects:  41%|████▏     | 129/311 [31:07<1:04:47, 21.36s/it]predicting train subjects:  42%|████▏     | 130/311 [31:28<1:04:04, 21.24s/it]predicting train subjects:  42%|████▏     | 131/311 [31:49<1:03:48, 21.27s/it]predicting train subjects:  42%|████▏     | 132/311 [32:00<54:07, 18.14s/it]  predicting train subjects:  43%|████▎     | 133/311 [32:10<46:06, 15.54s/it]predicting train subjects:  43%|████▎     | 134/311 [32:20<41:01, 13.91s/it]predicting train subjects:  43%|████▎     | 135/311 [32:30<37:34, 12.81s/it]predicting train subjects:  44%|████▎     | 136/311 [32:40<34:57, 11.98s/it]predicting train subjects:  44%|████▍     | 137/311 [32:50<32:43, 11.29s/it]predicting train subjects:  44%|████▍     | 138/311 [33:00<31:35, 10.96s/it]predicting train subjects:  45%|████▍     | 139/311 [33:11<31:24, 10.96s/it]predicting train subjects:  45%|████▌     | 140/311 [33:20<30:01, 10.54s/it]predicting train subjects:  45%|████▌     | 141/311 [33:30<29:09, 10.29s/it]predicting train subjects:  46%|████▌     | 142/311 [33:41<29:56, 10.63s/it]predicting train subjects:  46%|████▌     | 143/311 [33:52<29:17, 10.46s/it]predicting train subjects:  46%|████▋     | 144/311 [34:01<28:28, 10.23s/it]predicting train subjects:  47%|████▋     | 145/311 [34:11<28:17, 10.23s/it]predicting train subjects:  47%|████▋     | 146/311 [34:21<27:55, 10.16s/it]predicting train subjects:  47%|████▋     | 147/311 [34:31<27:22, 10.01s/it]predicting train subjects:  48%|████▊     | 148/311 [34:41<27:17, 10.04s/it]predicting train subjects:  48%|████▊     | 149/311 [34:51<27:13, 10.09s/it]predicting train subjects:  48%|████▊     | 150/311 [35:04<28:55, 10.78s/it]predicting train subjects:  49%|████▊     | 151/311 [35:16<30:13, 11.34s/it]predicting train subjects:  49%|████▉     | 152/311 [35:29<31:14, 11.79s/it]predicting train subjects:  49%|████▉     | 153/311 [35:42<31:46, 12.07s/it]predicting train subjects:  50%|████▉     | 154/311 [35:55<32:17, 12.34s/it]predicting train subjects:  50%|████▉     | 155/311 [36:08<32:34, 12.53s/it]predicting train subjects:  50%|█████     | 156/311 [36:20<31:53, 12.34s/it]predicting train subjects:  50%|█████     | 157/311 [36:32<31:51, 12.41s/it]predicting train subjects:  51%|█████     | 158/311 [36:45<31:54, 12.51s/it]predicting train subjects:  51%|█████     | 159/311 [36:58<31:55, 12.60s/it]predicting train subjects:  51%|█████▏    | 160/311 [37:11<32:03, 12.74s/it]predicting train subjects:  52%|█████▏    | 161/311 [37:24<32:00, 12.80s/it]predicting train subjects:  52%|█████▏    | 162/311 [37:37<31:42, 12.77s/it]predicting train subjects:  52%|█████▏    | 163/311 [37:49<31:03, 12.59s/it]predicting train subjects:  53%|█████▎    | 164/311 [38:01<30:42, 12.53s/it]predicting train subjects:  53%|█████▎    | 165/311 [38:14<30:32, 12.55s/it]predicting train subjects:  53%|█████▎    | 166/311 [38:26<30:05, 12.45s/it]predicting train subjects:  54%|█████▎    | 167/311 [38:39<29:57, 12.48s/it]predicting train subjects:  54%|█████▍    | 168/311 [38:51<29:50, 12.52s/it]predicting train subjects:  54%|█████▍    | 169/311 [39:03<29:20, 12.40s/it]predicting train subjects:  55%|█████▍    | 170/311 [39:16<28:57, 12.33s/it]predicting train subjects:  55%|█████▍    | 171/311 [39:28<28:48, 12.34s/it]predicting train subjects:  55%|█████▌    | 172/311 [39:40<28:36, 12.35s/it]predicting train subjects:  56%|█████▌    | 173/311 [39:53<28:29, 12.39s/it]predicting train subjects:  56%|█████▌    | 174/311 [40:05<28:19, 12.40s/it]predicting train subjects:  56%|█████▋    | 175/311 [40:17<27:53, 12.31s/it]predicting train subjects:  57%|█████▋    | 176/311 [40:29<27:33, 12.25s/it]predicting train subjects:  57%|█████▋    | 177/311 [40:42<27:16, 12.21s/it]predicting train subjects:  57%|█████▋    | 178/311 [40:54<27:17, 12.31s/it]predicting train subjects:  58%|█████▊    | 179/311 [41:07<27:10, 12.35s/it]predicting train subjects:  58%|█████▊    | 180/311 [41:19<27:04, 12.40s/it]predicting train subjects:  58%|█████▊    | 181/311 [41:31<26:27, 12.21s/it]predicting train subjects:  59%|█████▊    | 182/311 [41:43<26:25, 12.29s/it]predicting train subjects:  59%|█████▉    | 183/311 [41:58<27:58, 13.11s/it]predicting train subjects:  59%|█████▉    | 184/311 [42:12<28:03, 13.26s/it]predicting train subjects:  59%|█████▉    | 185/311 [42:26<28:23, 13.52s/it]predicting train subjects:  60%|█████▉    | 186/311 [42:40<28:21, 13.61s/it]predicting train subjects:  60%|██████    | 187/311 [42:54<28:18, 13.70s/it]predicting train subjects:  60%|██████    | 188/311 [43:07<28:05, 13.70s/it]predicting train subjects:  61%|██████    | 189/311 [43:22<28:07, 13.83s/it]predicting train subjects:  61%|██████    | 190/311 [43:36<28:02, 13.90s/it]predicting train subjects:  61%|██████▏   | 191/311 [43:49<27:44, 13.87s/it]predicting train subjects:  62%|██████▏   | 192/311 [44:03<27:25, 13.83s/it]predicting train subjects:  62%|██████▏   | 193/311 [44:17<27:03, 13.76s/it]predicting train subjects:  62%|██████▏   | 194/311 [44:30<26:41, 13.69s/it]predicting train subjects:  63%|██████▎   | 195/311 [44:44<26:37, 13.77s/it]predicting train subjects:  63%|██████▎   | 196/311 [44:58<26:29, 13.82s/it]predicting train subjects:  63%|██████▎   | 197/311 [45:12<26:06, 13.74s/it]predicting train subjects:  64%|██████▎   | 198/311 [45:26<26:08, 13.88s/it]predicting train subjects:  64%|██████▍   | 199/311 [45:40<25:57, 13.91s/it]predicting train subjects:  64%|██████▍   | 200/311 [45:54<25:35, 13.83s/it]predicting train subjects:  65%|██████▍   | 201/311 [46:08<25:29, 13.91s/it]predicting train subjects:  65%|██████▍   | 202/311 [46:22<25:13, 13.88s/it]predicting train subjects:  65%|██████▌   | 203/311 [46:36<25:09, 13.98s/it]predicting train subjects:  66%|██████▌   | 204/311 [46:50<25:01, 14.04s/it]predicting train subjects:  66%|██████▌   | 205/311 [47:04<24:42, 13.99s/it]predicting train subjects:  66%|██████▌   | 206/311 [47:17<24:01, 13.72s/it]predicting train subjects:  67%|██████▋   | 207/311 [47:29<22:58, 13.25s/it]predicting train subjects:  67%|██████▋   | 208/311 [47:40<21:26, 12.49s/it]predicting train subjects:  67%|██████▋   | 209/311 [47:51<20:34, 12.10s/it]predicting train subjects:  68%|██████▊   | 210/311 [48:02<20:03, 11.92s/it]predicting train subjects:  68%|██████▊   | 211/311 [48:14<19:30, 11.71s/it]predicting train subjects:  68%|██████▊   | 212/311 [48:24<18:52, 11.44s/it]predicting train subjects:  68%|██████▊   | 213/311 [48:46<23:42, 14.51s/it]predicting train subjects:  69%|██████▉   | 214/311 [49:07<26:21, 16.31s/it]predicting train subjects:  69%|██████▉   | 215/311 [49:29<28:51, 18.04s/it]predicting train subjects:  69%|██████▉   | 216/311 [49:49<29:42, 18.76s/it]predicting train subjects:  70%|██████▉   | 217/311 [50:10<30:31, 19.48s/it]predicting train subjects:  70%|███████   | 218/311 [50:31<30:50, 19.90s/it]predicting train subjects:  70%|███████   | 219/311 [50:53<31:14, 20.37s/it]predicting train subjects:  71%|███████   | 220/311 [51:14<31:17, 20.63s/it]predicting train subjects:  71%|███████   | 221/311 [51:35<30:58, 20.65s/it]predicting train subjects:  71%|███████▏  | 222/311 [51:55<30:35, 20.63s/it]predicting train subjects:  72%|███████▏  | 223/311 [52:16<30:21, 20.70s/it]predicting train subjects:  72%|███████▏  | 224/311 [52:37<30:00, 20.69s/it]predicting train subjects:  72%|███████▏  | 225/311 [52:58<29:47, 20.78s/it]predicting train subjects:  73%|███████▎  | 226/311 [53:18<29:26, 20.78s/it]predicting train subjects:  73%|███████▎  | 227/311 [53:40<29:19, 20.95s/it]predicting train subjects:  73%|███████▎  | 228/311 [54:01<28:54, 20.89s/it]predicting train subjects:  74%|███████▎  | 229/311 [54:21<28:31, 20.87s/it]predicting train subjects:  74%|███████▍  | 230/311 [54:43<28:27, 21.08s/it]predicting train subjects:  74%|███████▍  | 231/311 [54:53<23:29, 17.62s/it]predicting train subjects:  75%|███████▍  | 232/311 [55:03<20:20, 15.45s/it]predicting train subjects:  75%|███████▍  | 233/311 [55:13<17:58, 13.82s/it]predicting train subjects:  75%|███████▌  | 234/311 [55:23<16:13, 12.64s/it]predicting train subjects:  76%|███████▌  | 235/311 [55:33<15:09, 11.96s/it]predicting train subjects:  76%|███████▌  | 236/311 [55:43<14:12, 11.37s/it]predicting train subjects:  76%|███████▌  | 237/311 [55:54<13:39, 11.07s/it]predicting train subjects:  77%|███████▋  | 238/311 [56:04<13:13, 10.88s/it]predicting train subjects:  77%|███████▋  | 239/311 [56:14<12:35, 10.50s/it]predicting train subjects:  77%|███████▋  | 240/311 [56:24<12:19, 10.41s/it]predicting train subjects:  77%|███████▋  | 241/311 [56:34<12:01, 10.30s/it]predicting train subjects:  78%|███████▊  | 242/311 [56:44<11:40, 10.15s/it]predicting train subjects:  78%|███████▊  | 243/311 [56:54<11:36, 10.24s/it]predicting train subjects:  78%|███████▊  | 244/311 [57:04<11:17, 10.11s/it]predicting train subjects:  79%|███████▉  | 245/311 [57:14<11:14, 10.22s/it]predicting train subjects:  79%|███████▉  | 246/311 [57:25<11:09, 10.30s/it]predicting train subjects:  79%|███████▉  | 247/311 [57:35<10:52, 10.19s/it]predicting train subjects:  80%|███████▉  | 248/311 [57:45<10:44, 10.23s/it]predicting train subjects:  80%|████████  | 249/311 [57:58<11:25, 11.05s/it]predicting train subjects:  80%|████████  | 250/311 [58:11<11:47, 11.60s/it]predicting train subjects:  81%|████████  | 251/311 [58:24<11:58, 11.98s/it]predicting train subjects:  81%|████████  | 252/311 [58:37<12:05, 12.30s/it]predicting train subjects:  81%|████████▏ | 253/311 [58:50<12:07, 12.54s/it]predicting train subjects:  82%|████████▏ | 254/311 [59:03<12:02, 12.67s/it]predicting train subjects:  82%|████████▏ | 255/311 [59:16<11:56, 12.80s/it]predicting train subjects:  82%|████████▏ | 256/311 [59:29<11:40, 12.74s/it]predicting train subjects:  83%|████████▎ | 257/311 [59:41<11:20, 12.60s/it]predicting train subjects:  83%|████████▎ | 258/311 [59:54<11:08, 12.62s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:00:06<10:53, 12.56s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:00:19<10:40, 12.55s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:00:31<10:27, 12.55s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:00:43<10:11, 12.48s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:00:56<09:59, 12.48s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:01:09<09:50, 12.56s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:01:21<09:35, 12.52s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:01:33<09:22, 12.49s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:01:45<09:00, 12.28s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:01:58<08:48, 12.28s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:02:10<08:35, 12.27s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:02:22<08:25, 12.33s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:02:34<08:05, 12.14s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:02:46<07:49, 12.03s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:02:58<07:35, 12.00s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:03:10<07:28, 12.13s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:03:23<07:20, 12.23s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:03:35<07:11, 12.33s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:03:47<06:55, 12.22s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:03:59<06:40, 12.13s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:04:11<06:31, 12.24s/it]predicting train subjects:  90%|█████████ | 280/311 [1:04:24<06:21, 12.31s/it]predicting train subjects:  90%|█████████ | 281/311 [1:04:36<06:07, 12.24s/it]predicting train subjects:  91%|█████████ | 282/311 [1:04:48<05:54, 12.24s/it]predicting train subjects:  91%|█████████ | 283/311 [1:04:59<05:33, 11.91s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:05:11<05:18, 11.79s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:05:22<05:03, 11.66s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:05:33<04:47, 11.51s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:05:45<04:33, 11.39s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:05:56<04:22, 11.39s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:06:07<04:09, 11.35s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:06:19<04:03, 11.59s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:06:32<03:59, 11.97s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:06:45<03:51, 12.16s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:06:57<03:39, 12.19s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:07:10<03:31, 12.45s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:07:24<03:24, 12.79s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:07:36<03:11, 12.73s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:07:48<02:55, 12.52s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:08:01<02:42, 12.50s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:08:13<02:29, 12.42s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:08:26<02:17, 12.53s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:08:39<02:07, 12.76s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:08:53<01:57, 13.02s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:09:05<01:42, 12.85s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:09:17<01:27, 12.49s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:09:30<01:15, 12.61s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:09:43<01:03, 12.69s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:09:56<00:51, 12.76s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:10:09<00:38, 12.90s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:10:22<00:26, 13.06s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:10:34<00:12, 12.82s/it]predicting train subjects: 100%|██████████| 311/311 [1:10:48<00:00, 12.89s/it]
Epoch 00062: val_mDice did not improve from 0.69983
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
{'val_loss': [5803.557957130142, 4127.741807382318, 3277.028924483287, 2877.0623053055774, 2730.1660635260087, 2624.4310225474683, 2771.06897281695, 2674.758028827136, 2579.5116013152688, 2748.8367873566062, 2682.4010751458663, 2696.9126100178005, 2573.586858435522, 2619.5358484968356, 2632.2132491099683, 2801.680203594739, 2441.84821715536, 3170.393420255637, 2898.998082414458, 2820.6776076691062, 2732.367008257516, 2599.418010470233, 2567.491552425336, 2403.6429675138447, 2451.6410004821005, 2523.2255643047865, 2482.5118485462817, 2822.866547789755, 2734.05342044106, 2944.122479788865, 2755.3834676621836, 2358.8948603762856, 3082.7852180577534, 3077.9102056962024, 2701.0000494462024, 3316.416710962223, 2575.0098088904274, 2468.590308853343, 2768.4749431368673, 2410.8798781769187, 2534.3122265006923, 2588.4793345777293, 2665.873787022844, 2596.7554019976264, 3109.087351352354, 2553.472444558445, 2615.0342229529274, 2632.464193223398, 2701.011079039755, 2441.5523310794106, 2683.7262874554986, 2595.956280285799, 2711.823588310918, 2744.750732421875, 2737.219888807852, 2706.7628776453716, 2641.8440343156644, 2771.0588317098495, 2703.296565961234, 2622.640076456191, 2520.5002688637264, 3041.4326480913764], 'val_acc': [0.9074656291853024, 0.9227361060396025, 0.9317383796353883, 0.9365978142883205, 0.9398232049579862, 0.9429299295703067, 0.9425663261473933, 0.944101446037051, 0.9455696057669724, 0.94439354576642, 0.9442840316627599, 0.9438443380066112, 0.9476509388489059, 0.9467304597927045, 0.9488406679298305, 0.9458267575577844, 0.9508261371262466, 0.9423107203048996, 0.943477676639074, 0.9450493017329445, 0.9464885524556607, 0.9480297565460205, 0.9512703788431385, 0.9528937460500982, 0.952922670147087, 0.9510817346693594, 0.9512475623360163, 0.9484359622001648, 0.9508870062948782, 0.9461416571955138, 0.9479384844816183, 0.9540211294270768, 0.9423031346707404, 0.9434487766857389, 0.9467137508754488, 0.9432814091066771, 0.9494416389284255, 0.9522958352595945, 0.9515442523775222, 0.9546251485619364, 0.9534110064747967, 0.9525803553907177, 0.9486474673959273, 0.9507804746869244, 0.9466376719595511, 0.9551378443271299, 0.9511441120618507, 0.9524433899529373, 0.9529074294657647, 0.9547498814667328, 0.9534688237347181, 0.9519595858416979, 0.951624874827228, 0.9511486820027798, 0.951285607452634, 0.951515335070936, 0.9528465965126134, 0.9532680066325997, 0.9526959574675258, 0.9545931506760513, 0.9542554352856889, 0.9482899059223223], 'val_mDice': [0.43666252833378466, 0.5482252323174779, 0.6088449909717222, 0.6471984914586514, 0.660182566582402, 0.6693672401995598, 0.6581764372089242, 0.6693881968908673, 0.6770279558399056, 0.6651926961126207, 0.6703665580930589, 0.6693519263327876, 0.6810902666442001, 0.6768558794939066, 0.675340057928351, 0.6614878494528276, 0.68909098981302, 0.6330339214469813, 0.6519951292231113, 0.6608906154391132, 0.6686004588875589, 0.6801442564288273, 0.6832101246978664, 0.6955674283112152, 0.6896274829212623, 0.6870637769940533, 0.6882778557041024, 0.6595568174048315, 0.6686214419859874, 0.6461267825923388, 0.6649698698067967, 0.6998287537429906, 0.637760492819774, 0.6404130006138282, 0.6692649805093114, 0.6235809160184257, 0.6807310543482816, 0.6880686305746248, 0.6598737526543533, 0.6943756492832039, 0.684229730050775, 0.675431840027435, 0.672183455545691, 0.6778485458108443, 0.6342802191082435, 0.6835382075249394, 0.6757419154613833, 0.6753168634221524, 0.6705577796018576, 0.692645589007607, 0.6664227330231969, 0.679053869428514, 0.6679613590240479, 0.6673693936082381, 0.6647493582737597, 0.6692116607593585, 0.6676000386853761, 0.6642591289327114, 0.6692102724992777, 0.6760731822327722, 0.6859193089642103, 0.6440126488480387], 'loss': [13738.02344461377, 4778.548775068134, 3762.729566239867, 3324.2591945473746, 3044.138609629515, 2858.792326435875, 2719.786916710403, 2586.605001711257, 2499.149226338021, 2420.9164730305133, 2357.0451865665154, 2272.509416951481, 2223.1826880781914, 2163.3463551711575, 2128.151417823708, 2082.022803485273, 2035.4162779452588, 2013.1763221929064, 1961.6576294785132, 1936.1079688448503, 1906.681809033618, 1885.2987596055652, 1851.3578019182676, 1829.5834381955685, 1811.0210814836873, 1782.5183799555311, 1759.4065565343137, 1736.873196165362, 1724.5919437447042, 1708.0002630612764, 1686.0811966417868, 1662.7630805428912, 1651.2363443532872, 1629.7622564324288, 1630.0846767819203, 1616.2992452191515, 1601.8755815012742, 1580.4308882203482, 1565.772014103839, 1549.9633303448913, 1549.1568898440662, 1535.7531929463812, 1517.074419343486, 1509.6523671414582, 1496.5328612688436, 1486.7235391231648, 1479.6589663238094, 1469.748023532943, 1458.9928924795202, 1446.5317938822766, 1443.7417666019578, 1440.0008376463857, 1421.971829694179, 1412.8610354724176, 1412.7041520505045, 1402.6671427128915, 1399.7087638481385, 1386.9091571605625, 1378.2565656636514, 1375.8201349768644, 1369.2502857364175, 1354.7344650089476], 'acc': [0.8742964732314064, 0.9116710566258633, 0.9260121451510634, 0.9321359895540605, 0.9357994836817286, 0.9383505959831139, 0.9402996482322303, 0.9417818634194529, 0.9428726504901699, 0.943977115295137, 0.9447451762128387, 0.9458108493452948, 0.9464779706292672, 0.9472575929906869, 0.9476657680826407, 0.9483065860853268, 0.9488862181954517, 0.94926055630225, 0.9496856608742019, 0.9502139817795161, 0.9505923877887424, 0.9508835768371592, 0.951234375788875, 0.9515333069765052, 0.9517414122638987, 0.9521977639979845, 0.9524909512613622, 0.9527237477547628, 0.9528827656381577, 0.9531738147567709, 0.9534144533978257, 0.9537387156669835, 0.9538934929850419, 0.9541832761502083, 0.9541448500657168, 0.9543192947938441, 0.9544444390995114, 0.9547841286717133, 0.955037473040233, 0.9551280430578017, 0.9551713333251456, 0.9553765614521933, 0.9556011065979421, 0.955631632787503, 0.9557944678044522, 0.9558853268961055, 0.9560772669262271, 0.9562245707239809, 0.9563150210257051, 0.9564461608446354, 0.9565063986832292, 0.9566598678590411, 0.9568071320731357, 0.9569143603225316, 0.9569391292244352, 0.9571112412424138, 0.9571391227321555, 0.9572671272406352, 0.957349270956085, 0.9573712187805238, 0.9575000571509886, 0.9576147331828677], 'mDice': [0.3073489489414488, 0.5376602688669339, 0.6108031487088607, 0.6461570103947135, 0.6697789960330144, 0.6863766184995551, 0.6989348440795522, 0.7109518116275968, 0.7190674640591065, 0.7263681734684072, 0.7323880868371032, 0.7403943725367491, 0.7452093798686791, 0.7510479251559762, 0.7545454970307314, 0.7590423223703123, 0.7636797569966519, 0.7659362665992283, 0.7709623761188641, 0.7736074544793919, 0.7766485734779022, 0.7787806120829658, 0.782252798771289, 0.7844931051249641, 0.7864005694211808, 0.7893415535813351, 0.7917292569871375, 0.7941452770858388, 0.7953190863832005, 0.7972054297458011, 0.7993899055069538, 0.8018226270393918, 0.8030662603196901, 0.8053179081998244, 0.8053197873502258, 0.8067715300186015, 0.808233596423723, 0.8105564066776135, 0.812066655562311, 0.8137808794533372, 0.813912980520788, 0.8153227820950257, 0.8173817712157808, 0.8181194614080802, 0.81958330128657, 0.8206320448907847, 0.8213996830521109, 0.8224762423180318, 0.8236596162914506, 0.8250107119701884, 0.8252600738993544, 0.8257333720227283, 0.8276689410064926, 0.8286442323910085, 0.8287190617409277, 0.8297660177605976, 0.8301294807092905, 0.8315035234043734, 0.8324778273924793, 0.8327314636814406, 0.8334793234971408, 0.8350427682850342]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SDmkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:18<1:35:43, 18.53s/it]Loading train:   1%|          | 2/311 [00:28<1:22:24, 16.00s/it]Loading train:   1%|          | 3/311 [00:40<1:16:14, 14.85s/it]Loading train:   1%|▏         | 4/311 [00:52<1:10:48, 13.84s/it]Loading train:   2%|▏         | 5/311 [01:03<1:06:07, 12.97s/it]Loading train:   2%|▏         | 6/311 [01:13<1:01:58, 12.19s/it]Loading train:   2%|▏         | 7/311 [01:24<59:09, 11.68s/it]  Loading train:   3%|▎         | 8/311 [01:36<1:00:27, 11.97s/it]Loading train:   3%|▎         | 9/311 [01:48<59:17, 11.78s/it]  Loading train:   3%|▎         | 10/311 [01:57<55:58, 11.16s/it]Loading train:   4%|▎         | 11/311 [02:10<57:39, 11.53s/it]Loading train:   4%|▍         | 12/311 [02:19<54:53, 11.01s/it]Loading train:   4%|▍         | 13/311 [02:29<52:34, 10.59s/it]Loading train:   5%|▍         | 14/311 [02:41<54:30, 11.01s/it]Loading train:   5%|▍         | 15/311 [02:50<51:18, 10.40s/it]Loading train:   5%|▌         | 16/311 [02:59<48:34,  9.88s/it]Loading train:   5%|▌         | 17/311 [03:08<47:00,  9.59s/it]Loading train:   6%|▌         | 18/311 [03:16<45:45,  9.37s/it]Loading train:   6%|▌         | 19/311 [03:26<45:21,  9.32s/it]Loading train:   6%|▋         | 20/311 [03:34<44:19,  9.14s/it]Loading train:   7%|▋         | 21/311 [03:43<44:05,  9.12s/it]Loading train:   7%|▋         | 22/311 [03:52<43:29,  9.03s/it]Loading train:   7%|▋         | 23/311 [04:01<43:13,  9.01s/it]Loading train:   8%|▊         | 24/311 [04:10<42:59,  8.99s/it]Loading train:   8%|▊         | 25/311 [04:19<42:46,  8.97s/it]Loading train:   8%|▊         | 26/311 [04:28<42:48,  9.01s/it]Loading train:   9%|▊         | 27/311 [04:37<42:19,  8.94s/it]Loading train:   9%|▉         | 28/311 [04:46<42:30,  9.01s/it]Loading train:   9%|▉         | 29/311 [04:55<42:23,  9.02s/it]Loading train:  10%|▉         | 30/311 [05:04<42:25,  9.06s/it]Loading train:  10%|▉         | 31/311 [05:14<42:49,  9.18s/it]Loading train:  10%|█         | 32/311 [05:23<42:34,  9.15s/it]Loading train:  11%|█         | 33/311 [05:28<36:21,  7.85s/it]Loading train:  11%|█         | 34/311 [05:32<31:42,  6.87s/it]Loading train:  11%|█▏        | 35/311 [05:37<28:20,  6.16s/it]Loading train:  12%|█▏        | 36/311 [05:41<26:03,  5.68s/it]Loading train:  12%|█▏        | 37/311 [05:46<24:38,  5.40s/it]Loading train:  12%|█▏        | 38/311 [05:51<23:23,  5.14s/it]Loading train:  13%|█▎        | 39/311 [05:55<22:09,  4.89s/it]Loading train:  13%|█▎        | 40/311 [06:00<21:36,  4.78s/it]Loading train:  13%|█▎        | 41/311 [06:04<21:13,  4.72s/it]Loading train:  14%|█▎        | 42/311 [06:09<20:52,  4.66s/it]Loading train:  14%|█▍        | 43/311 [06:13<20:46,  4.65s/it]Loading train:  14%|█▍        | 44/311 [06:18<20:31,  4.61s/it]Loading train:  14%|█▍        | 45/311 [06:22<20:28,  4.62s/it]Loading train:  15%|█▍        | 46/311 [06:27<20:01,  4.53s/it]Loading train:  15%|█▌        | 47/311 [06:31<20:00,  4.55s/it]Loading train:  15%|█▌        | 48/311 [06:36<19:47,  4.52s/it]Loading train:  16%|█▌        | 49/311 [06:40<19:54,  4.56s/it]Loading train:  16%|█▌        | 50/311 [06:45<20:02,  4.61s/it]Loading train:  16%|█▋        | 51/311 [06:51<21:21,  4.93s/it]Loading train:  17%|█▋        | 52/311 [06:56<22:06,  5.12s/it]Loading train:  17%|█▋        | 53/311 [07:02<22:51,  5.32s/it]Loading train:  17%|█▋        | 54/311 [07:08<23:06,  5.40s/it]Loading train:  18%|█▊        | 55/311 [07:13<23:22,  5.48s/it]Loading train:  18%|█▊        | 56/311 [07:19<23:48,  5.60s/it]Loading train:  18%|█▊        | 57/311 [07:25<23:27,  5.54s/it]Loading train:  19%|█▊        | 58/311 [07:30<23:27,  5.56s/it]Loading train:  19%|█▉        | 59/311 [07:36<23:42,  5.65s/it]Loading train:  19%|█▉        | 60/311 [07:42<23:40,  5.66s/it]Loading train:  20%|█▉        | 61/311 [07:47<23:35,  5.66s/it]Loading train:  20%|█▉        | 62/311 [07:53<23:40,  5.71s/it]Loading train:  20%|██        | 63/311 [07:59<23:09,  5.60s/it]Loading train:  21%|██        | 64/311 [08:04<22:53,  5.56s/it]Loading train:  21%|██        | 65/311 [08:10<22:59,  5.61s/it]Loading train:  21%|██        | 66/311 [08:15<22:41,  5.56s/it]Loading train:  22%|██▏       | 67/311 [08:21<22:11,  5.46s/it]Loading train:  22%|██▏       | 68/311 [08:26<22:08,  5.47s/it]Loading train:  22%|██▏       | 69/311 [08:31<21:54,  5.43s/it]Loading train:  23%|██▎       | 70/311 [08:37<21:44,  5.41s/it]Loading train:  23%|██▎       | 71/311 [08:42<21:43,  5.43s/it]Loading train:  23%|██▎       | 72/311 [08:47<21:23,  5.37s/it]Loading train:  23%|██▎       | 73/311 [08:52<20:51,  5.26s/it]Loading train:  24%|██▍       | 74/311 [08:58<20:53,  5.29s/it]Loading train:  24%|██▍       | 75/311 [09:03<20:55,  5.32s/it]Loading train:  24%|██▍       | 76/311 [09:08<20:35,  5.26s/it]Loading train:  25%|██▍       | 77/311 [09:13<20:10,  5.17s/it]Loading train:  25%|██▌       | 78/311 [09:19<20:25,  5.26s/it]Loading train:  25%|██▌       | 79/311 [09:24<20:26,  5.29s/it]Loading train:  26%|██▌       | 80/311 [09:29<20:10,  5.24s/it]Loading train:  26%|██▌       | 81/311 [09:35<20:11,  5.27s/it]Loading train:  26%|██▋       | 82/311 [09:40<20:19,  5.33s/it]Loading train:  27%|██▋       | 83/311 [09:45<20:14,  5.33s/it]Loading train:  27%|██▋       | 84/311 [09:50<19:58,  5.28s/it]Loading train:  27%|██▋       | 85/311 [09:56<19:40,  5.22s/it]Loading train:  28%|██▊       | 86/311 [10:01<19:26,  5.18s/it]Loading train:  28%|██▊       | 87/311 [10:05<18:53,  5.06s/it]Loading train:  28%|██▊       | 88/311 [10:10<18:39,  5.02s/it]Loading train:  29%|██▊       | 89/311 [10:15<18:24,  4.98s/it]Loading train:  29%|██▉       | 90/311 [10:20<18:18,  4.97s/it]Loading train:  29%|██▉       | 91/311 [10:25<18:04,  4.93s/it]Loading train:  30%|██▉       | 92/311 [10:30<17:48,  4.88s/it]Loading train:  30%|██▉       | 93/311 [10:35<18:04,  4.98s/it]Loading train:  30%|███       | 94/311 [10:40<17:49,  4.93s/it]Loading train:  31%|███       | 95/311 [10:45<17:32,  4.87s/it]Loading train:  31%|███       | 96/311 [10:49<17:15,  4.82s/it]Loading train:  31%|███       | 97/311 [10:54<17:16,  4.84s/it]Loading train:  32%|███▏      | 98/311 [10:59<17:20,  4.88s/it]Loading train:  32%|███▏      | 99/311 [11:04<17:08,  4.85s/it]Loading train:  32%|███▏      | 100/311 [11:09<16:49,  4.78s/it]Loading train:  32%|███▏      | 101/311 [11:13<16:52,  4.82s/it]Loading train:  33%|███▎      | 102/311 [11:18<16:56,  4.86s/it]Loading train:  33%|███▎      | 103/311 [11:23<16:37,  4.80s/it]Loading train:  33%|███▎      | 104/311 [11:28<16:25,  4.76s/it]Loading train:  34%|███▍      | 105/311 [11:33<16:26,  4.79s/it]Loading train:  34%|███▍      | 106/311 [11:38<16:35,  4.86s/it]Loading train:  34%|███▍      | 107/311 [11:43<16:36,  4.88s/it]Loading train:  35%|███▍      | 108/311 [11:48<16:41,  4.93s/it]Loading train:  35%|███▌      | 109/311 [11:53<16:36,  4.93s/it]Loading train:  35%|███▌      | 110/311 [11:58<16:46,  5.01s/it]Loading train:  36%|███▌      | 111/311 [12:03<16:37,  4.99s/it]Loading train:  36%|███▌      | 112/311 [12:08<16:38,  5.02s/it]Loading train:  36%|███▋      | 113/311 [12:13<16:44,  5.07s/it]Loading train:  37%|███▋      | 114/311 [12:22<20:25,  6.22s/it]Loading train:  37%|███▋      | 115/311 [12:31<23:12,  7.10s/it]Loading train:  37%|███▋      | 116/311 [12:39<24:26,  7.52s/it]Loading train:  38%|███▊      | 117/311 [12:49<25:52,  8.00s/it]Loading train:  38%|███▊      | 118/311 [12:58<26:37,  8.28s/it]Loading train:  38%|███▊      | 119/311 [13:06<27:02,  8.45s/it]Loading train:  39%|███▊      | 120/311 [13:15<27:23,  8.60s/it]Loading train:  39%|███▉      | 121/311 [13:24<27:23,  8.65s/it]Loading train:  39%|███▉      | 122/311 [13:33<27:42,  8.80s/it]Loading train:  40%|███▉      | 123/311 [13:42<27:50,  8.88s/it]Loading train:  40%|███▉      | 124/311 [13:51<27:52,  8.95s/it]Loading train:  40%|████      | 125/311 [14:01<27:51,  8.99s/it]Loading train:  41%|████      | 126/311 [14:10<28:11,  9.14s/it]Loading train:  41%|████      | 127/311 [14:19<27:58,  9.12s/it]Loading train:  41%|████      | 128/311 [14:28<27:57,  9.16s/it]Loading train:  41%|████▏     | 129/311 [14:37<27:33,  9.08s/it]Loading train:  42%|████▏     | 130/311 [14:46<27:30,  9.12s/it]Loading train:  42%|████▏     | 131/311 [14:55<27:03,  9.02s/it]Loading train:  42%|████▏     | 132/311 [15:00<22:56,  7.69s/it]Loading train:  43%|████▎     | 133/311 [15:04<20:06,  6.78s/it]Loading train:  43%|████▎     | 134/311 [15:09<17:59,  6.10s/it]Loading train:  43%|████▎     | 135/311 [15:13<16:29,  5.62s/it]Loading train:  44%|████▎     | 136/311 [15:18<15:34,  5.34s/it]Loading train:  44%|████▍     | 137/311 [15:23<14:58,  5.16s/it]Loading train:  44%|████▍     | 138/311 [15:27<14:15,  4.94s/it]Loading train:  45%|████▍     | 139/311 [15:32<13:41,  4.78s/it]Loading train:  45%|████▌     | 140/311 [15:36<13:17,  4.66s/it]Loading train:  45%|████▌     | 141/311 [15:41<13:11,  4.66s/it]Loading train:  46%|████▌     | 142/311 [15:45<13:00,  4.62s/it]Loading train:  46%|████▌     | 143/311 [15:50<12:50,  4.58s/it]Loading train:  46%|████▋     | 144/311 [15:54<12:45,  4.58s/it]Loading train:  47%|████▋     | 145/311 [15:59<12:35,  4.55s/it]Loading train:  47%|████▋     | 146/311 [16:03<12:27,  4.53s/it]Loading train:  47%|████▋     | 147/311 [16:08<12:19,  4.51s/it]Loading train:  48%|████▊     | 148/311 [16:13<12:25,  4.57s/it]Loading train:  48%|████▊     | 149/311 [16:17<12:28,  4.62s/it]Loading train:  48%|████▊     | 150/311 [16:23<13:14,  4.94s/it]Loading train:  49%|████▊     | 151/311 [16:29<13:43,  5.15s/it]Loading train:  49%|████▉     | 152/311 [16:34<14:07,  5.33s/it]Loading train:  49%|████▉     | 153/311 [16:40<14:07,  5.36s/it]Loading train:  50%|████▉     | 154/311 [16:45<14:16,  5.45s/it]Loading train:  50%|████▉     | 155/311 [16:51<14:24,  5.54s/it]Loading train:  50%|█████     | 156/311 [16:57<14:19,  5.54s/it]Loading train:  50%|█████     | 157/311 [17:02<14:11,  5.53s/it]Loading train:  51%|█████     | 158/311 [17:08<14:11,  5.57s/it]Loading train:  51%|█████     | 159/311 [17:13<14:07,  5.57s/it]Loading train:  51%|█████▏    | 160/311 [17:19<14:09,  5.62s/it]Loading train:  52%|█████▏    | 161/311 [17:25<13:58,  5.59s/it]Loading train:  52%|█████▏    | 162/311 [17:30<13:52,  5.59s/it]Loading train:  52%|█████▏    | 163/311 [17:36<13:54,  5.64s/it]Loading train:  53%|█████▎    | 164/311 [17:42<13:49,  5.64s/it]Loading train:  53%|█████▎    | 165/311 [17:47<13:31,  5.56s/it]Loading train:  53%|█████▎    | 166/311 [17:52<13:12,  5.46s/it]Loading train:  54%|█████▎    | 167/311 [17:58<13:05,  5.45s/it]Loading train:  54%|█████▍    | 168/311 [18:03<12:46,  5.36s/it]Loading train:  54%|█████▍    | 169/311 [18:08<12:40,  5.35s/it]Loading train:  55%|█████▍    | 170/311 [18:14<12:54,  5.49s/it]Loading train:  55%|█████▍    | 171/311 [18:19<12:42,  5.45s/it]Loading train:  55%|█████▌    | 172/311 [18:25<12:29,  5.39s/it]Loading train:  56%|█████▌    | 173/311 [18:30<12:34,  5.47s/it]Loading train:  56%|█████▌    | 174/311 [18:36<12:30,  5.48s/it]Loading train:  56%|█████▋    | 175/311 [18:41<12:16,  5.42s/it]Loading train:  57%|█████▋    | 176/311 [18:47<12:18,  5.47s/it]Loading train:  57%|█████▋    | 177/311 [18:52<12:10,  5.45s/it]Loading train:  57%|█████▋    | 178/311 [18:58<12:04,  5.45s/it]Loading train:  58%|█████▊    | 179/311 [19:03<12:08,  5.52s/it]Loading train:  58%|█████▊    | 180/311 [19:09<12:05,  5.54s/it]Loading train:  58%|█████▊    | 181/311 [19:14<12:04,  5.57s/it]Loading train:  59%|█████▊    | 182/311 [19:20<12:02,  5.60s/it]Loading train:  59%|█████▉    | 183/311 [19:26<11:53,  5.57s/it]Loading train:  59%|█████▉    | 184/311 [19:31<11:23,  5.38s/it]Loading train:  59%|█████▉    | 185/311 [19:36<11:11,  5.33s/it]Loading train:  60%|█████▉    | 186/311 [19:41<11:00,  5.29s/it]Loading train:  60%|██████    | 187/311 [19:46<10:44,  5.20s/it]Loading train:  60%|██████    | 188/311 [19:51<10:34,  5.16s/it]Loading train:  61%|██████    | 189/311 [19:56<10:31,  5.17s/it]Loading train:  61%|██████    | 190/311 [20:01<10:20,  5.13s/it]Loading train:  61%|██████▏   | 191/311 [20:06<10:08,  5.07s/it]Loading train:  62%|██████▏   | 192/311 [20:12<10:14,  5.16s/it]Loading train:  62%|██████▏   | 193/311 [20:17<10:04,  5.12s/it]Loading train:  62%|██████▏   | 194/311 [20:21<09:51,  5.06s/it]Loading train:  63%|██████▎   | 195/311 [20:27<10:03,  5.20s/it]Loading train:  63%|██████▎   | 196/311 [20:32<09:54,  5.17s/it]Loading train:  63%|██████▎   | 197/311 [20:37<09:45,  5.13s/it]Loading train:  64%|██████▎   | 198/311 [20:42<09:38,  5.12s/it]Loading train:  64%|██████▍   | 199/311 [20:47<09:29,  5.08s/it]Loading train:  64%|██████▍   | 200/311 [20:52<09:23,  5.07s/it]Loading train:  65%|██████▍   | 201/311 [20:58<09:29,  5.18s/it]Loading train:  65%|██████▍   | 202/311 [21:03<09:28,  5.21s/it]Loading train:  65%|██████▌   | 203/311 [21:08<09:15,  5.15s/it]Loading train:  66%|██████▌   | 204/311 [21:13<09:18,  5.22s/it]Loading train:  66%|██████▌   | 205/311 [21:19<09:16,  5.25s/it]Loading train:  66%|██████▌   | 206/311 [21:24<09:03,  5.18s/it]Loading train:  67%|██████▋   | 207/311 [21:29<08:50,  5.10s/it]Loading train:  67%|██████▋   | 208/311 [21:34<08:54,  5.19s/it]Loading train:  67%|██████▋   | 209/311 [21:39<08:50,  5.20s/it]Loading train:  68%|██████▊   | 210/311 [21:44<08:36,  5.12s/it]Loading train:  68%|██████▊   | 211/311 [21:49<08:32,  5.12s/it]Loading train:  68%|██████▊   | 212/311 [21:55<08:30,  5.15s/it]Loading train:  68%|██████▊   | 213/311 [22:04<10:19,  6.32s/it]Loading train:  69%|██████▉   | 214/311 [22:13<11:37,  7.19s/it]Loading train:  69%|██████▉   | 215/311 [22:22<12:34,  7.86s/it]Loading train:  69%|██████▉   | 216/311 [22:31<13:01,  8.22s/it]Loading train:  70%|██████▉   | 217/311 [22:41<13:33,  8.65s/it]Loading train:  70%|███████   | 218/311 [22:50<13:36,  8.78s/it]Loading train:  70%|███████   | 219/311 [22:59<13:45,  8.98s/it]Loading train:  71%|███████   | 220/311 [23:08<13:34,  8.95s/it]Loading train:  71%|███████   | 221/311 [23:18<13:30,  9.00s/it]Loading train:  71%|███████▏  | 222/311 [23:26<13:20,  8.99s/it]Loading train:  72%|███████▏  | 223/311 [23:36<13:15,  9.04s/it]Loading train:  72%|███████▏  | 224/311 [23:45<13:12,  9.10s/it]Loading train:  72%|███████▏  | 225/311 [23:54<13:01,  9.09s/it]Loading train:  73%|███████▎  | 226/311 [24:03<13:01,  9.20s/it]Loading train:  73%|███████▎  | 227/311 [24:12<12:45,  9.11s/it]Loading train:  73%|███████▎  | 228/311 [24:22<12:42,  9.18s/it]Loading train:  74%|███████▎  | 229/311 [24:31<12:37,  9.24s/it]Loading train:  74%|███████▍  | 230/311 [24:40<12:20,  9.15s/it]Loading train:  74%|███████▍  | 231/311 [24:45<10:35,  7.94s/it]Loading train:  75%|███████▍  | 232/311 [24:50<09:12,  6.99s/it]Loading train:  75%|███████▍  | 233/311 [24:54<08:10,  6.28s/it]Loading train:  75%|███████▌  | 234/311 [24:59<07:27,  5.81s/it]Loading train:  76%|███████▌  | 235/311 [25:04<06:59,  5.52s/it]Loading train:  76%|███████▌  | 236/311 [25:09<06:30,  5.21s/it]Loading train:  76%|███████▌  | 237/311 [25:13<06:09,  5.00s/it]Loading train:  77%|███████▋  | 238/311 [25:18<05:59,  4.93s/it]Loading train:  77%|███████▋  | 239/311 [25:22<05:47,  4.82s/it]Loading train:  77%|███████▋  | 240/311 [25:27<05:33,  4.70s/it]Loading train:  77%|███████▋  | 241/311 [25:32<05:30,  4.71s/it]Loading train:  78%|███████▊  | 242/311 [25:36<05:26,  4.74s/it]Loading train:  78%|███████▊  | 243/311 [25:41<05:16,  4.66s/it]Loading train:  78%|███████▊  | 244/311 [25:45<05:08,  4.60s/it]Loading train:  79%|███████▉  | 245/311 [25:50<05:06,  4.65s/it]Loading train:  79%|███████▉  | 246/311 [25:55<04:59,  4.61s/it]Loading train:  79%|███████▉  | 247/311 [25:59<04:53,  4.59s/it]Loading train:  80%|███████▉  | 248/311 [26:04<04:50,  4.61s/it]Loading train:  80%|████████  | 249/311 [26:10<05:13,  5.06s/it]Loading train:  80%|████████  | 250/311 [26:15<05:15,  5.18s/it]Loading train:  81%|████████  | 251/311 [26:21<05:22,  5.38s/it]Loading train:  81%|████████  | 252/311 [26:27<05:25,  5.51s/it]Loading train:  81%|████████▏ | 253/311 [26:33<05:21,  5.54s/it]Loading train:  82%|████████▏ | 254/311 [26:38<05:17,  5.57s/it]Loading train:  82%|████████▏ | 255/311 [26:44<05:14,  5.61s/it]Loading train:  82%|████████▏ | 256/311 [26:49<05:07,  5.59s/it]Loading train:  83%|████████▎ | 257/311 [26:56<05:09,  5.73s/it]Loading train:  83%|████████▎ | 258/311 [27:01<05:06,  5.78s/it]Loading train:  83%|████████▎ | 259/311 [27:07<04:58,  5.74s/it]Loading train:  84%|████████▎ | 260/311 [27:13<04:55,  5.79s/it]Loading train:  84%|████████▍ | 261/311 [27:19<04:49,  5.79s/it]Loading train:  84%|████████▍ | 262/311 [27:24<04:38,  5.68s/it]Loading train:  85%|████████▍ | 263/311 [27:30<04:35,  5.75s/it]Loading train:  85%|████████▍ | 264/311 [27:36<04:27,  5.69s/it]Loading train:  85%|████████▌ | 265/311 [27:41<04:19,  5.65s/it]Loading train:  86%|████████▌ | 266/311 [27:47<04:12,  5.60s/it]Loading train:  86%|████████▌ | 267/311 [27:52<04:03,  5.54s/it]Loading train:  86%|████████▌ | 268/311 [27:58<03:57,  5.52s/it]Loading train:  86%|████████▋ | 269/311 [28:03<03:52,  5.54s/it]Loading train:  87%|████████▋ | 270/311 [28:09<03:46,  5.52s/it]Loading train:  87%|████████▋ | 271/311 [28:14<03:40,  5.50s/it]Loading train:  87%|████████▋ | 272/311 [28:20<03:35,  5.52s/it]Loading train:  88%|████████▊ | 273/311 [28:25<03:31,  5.58s/it]Loading train:  88%|████████▊ | 274/311 [28:31<03:27,  5.60s/it]Loading train:  88%|████████▊ | 275/311 [28:37<03:22,  5.63s/it]Loading train:  89%|████████▊ | 276/311 [28:42<03:14,  5.56s/it]Loading train:  89%|████████▉ | 277/311 [28:48<03:08,  5.54s/it]Loading train:  89%|████████▉ | 278/311 [28:53<03:05,  5.63s/it]Loading train:  90%|████████▉ | 279/311 [28:59<02:58,  5.59s/it]Loading train:  90%|█████████ | 280/311 [29:04<02:51,  5.53s/it]Loading train:  90%|█████████ | 281/311 [29:10<02:47,  5.59s/it]Loading train:  91%|█████████ | 282/311 [29:16<02:41,  5.57s/it]Loading train:  91%|█████████ | 283/311 [29:21<02:31,  5.42s/it]Loading train:  91%|█████████▏| 284/311 [29:26<02:24,  5.37s/it]Loading train:  92%|█████████▏| 285/311 [29:31<02:15,  5.21s/it]Loading train:  92%|█████████▏| 286/311 [29:36<02:11,  5.27s/it]Loading train:  92%|█████████▏| 287/311 [29:42<02:10,  5.42s/it]Loading train:  93%|█████████▎| 288/311 [29:48<02:08,  5.57s/it]Loading train:  93%|█████████▎| 289/311 [29:54<02:03,  5.62s/it]Loading train:  93%|█████████▎| 290/311 [30:00<01:59,  5.71s/it]Loading train:  94%|█████████▎| 291/311 [30:05<01:54,  5.72s/it]Loading train:  94%|█████████▍| 292/311 [30:11<01:46,  5.58s/it]Loading train:  94%|█████████▍| 293/311 [30:16<01:41,  5.62s/it]Loading train:  95%|█████████▍| 294/311 [30:22<01:35,  5.63s/it]Loading train:  95%|█████████▍| 295/311 [30:27<01:29,  5.60s/it]Loading train:  95%|█████████▌| 296/311 [30:33<01:24,  5.65s/it]Loading train:  95%|█████████▌| 297/311 [30:39<01:18,  5.61s/it]Loading train:  96%|█████████▌| 298/311 [30:44<01:12,  5.60s/it]Loading train:  96%|█████████▌| 299/311 [30:50<01:07,  5.65s/it]Loading train:  96%|█████████▋| 300/311 [30:56<01:01,  5.61s/it]Loading train:  97%|█████████▋| 301/311 [31:03<01:03,  6.31s/it]Loading train:  97%|█████████▋| 302/311 [31:11<01:00,  6.77s/it]Loading train:  97%|█████████▋| 303/311 [31:19<00:55,  6.93s/it]Loading train:  98%|█████████▊| 304/311 [31:27<00:50,  7.24s/it]Loading train:  98%|█████████▊| 305/311 [31:34<00:43,  7.30s/it]Loading train:  98%|█████████▊| 306/311 [31:42<00:37,  7.45s/it]Loading train:  99%|█████████▊| 307/311 [31:49<00:28,  7.24s/it]Loading train:  99%|█████████▉| 308/311 [31:57<00:22,  7.45s/it]Loading train:  99%|█████████▉| 309/311 [32:04<00:14,  7.49s/it]Loading train: 100%|█████████▉| 310/311 [32:12<00:07,  7.47s/it]Loading train: 100%|██████████| 311/311 [32:19<00:00,  7.52s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/311 [00:00<00:15, 20.41it/s]concatenating: train:   2%|▏         | 5/311 [00:00<00:15, 19.57it/s]concatenating: train:   3%|▎         | 8/311 [00:00<00:15, 19.62it/s]concatenating: train:   4%|▍         | 13/311 [00:00<00:12, 23.86it/s]concatenating: train:   6%|▋         | 20/311 [00:00<00:09, 29.44it/s]concatenating: train:   9%|▊         | 27/311 [00:00<00:08, 35.39it/s]concatenating: train:  11%|█▏        | 35/311 [00:00<00:06, 42.26it/s]concatenating: train:  13%|█▎        | 41/311 [00:01<00:06, 39.74it/s]concatenating: train:  15%|█▍        | 46/311 [00:01<00:07, 35.80it/s]concatenating: train:  16%|█▋        | 51/311 [00:01<00:07, 33.21it/s]concatenating: train:  18%|█▊        | 55/311 [00:01<00:07, 32.59it/s]concatenating: train:  19%|█▉        | 59/311 [00:01<00:07, 32.18it/s]concatenating: train:  20%|██        | 63/311 [00:01<00:07, 31.89it/s]concatenating: train:  22%|██▏       | 67/311 [00:01<00:07, 32.63it/s]concatenating: train:  23%|██▎       | 71/311 [00:02<00:08, 29.89it/s]concatenating: train:  24%|██▍       | 75/311 [00:02<00:08, 28.72it/s]concatenating: train:  25%|██▌       | 78/311 [00:02<00:08, 28.11it/s]concatenating: train:  27%|██▋       | 83/311 [00:02<00:07, 31.39it/s]concatenating: train:  29%|██▉       | 91/311 [00:02<00:05, 37.73it/s]concatenating: train:  32%|███▏      | 98/311 [00:02<00:04, 42.82it/s]concatenating: train:  33%|███▎      | 103/311 [00:02<00:04, 41.62it/s]concatenating: train:  35%|███▍      | 108/311 [00:03<00:06, 30.18it/s]concatenating: train:  36%|███▌      | 112/311 [00:03<00:07, 27.56it/s]concatenating: train:  38%|███▊      | 119/311 [00:03<00:05, 33.23it/s]concatenating: train:  40%|███▉      | 124/311 [00:03<00:06, 31.15it/s]concatenating: train:  41%|████      | 128/311 [00:03<00:05, 32.08it/s]concatenating: train:  43%|████▎     | 133/311 [00:03<00:05, 35.04it/s]concatenating: train:  44%|████▍     | 138/311 [00:03<00:04, 36.79it/s]concatenating: train:  46%|████▌     | 142/311 [00:03<00:04, 36.46it/s]concatenating: train:  47%|████▋     | 146/311 [00:04<00:04, 36.63it/s]concatenating: train:  48%|████▊     | 150/311 [00:04<00:04, 36.35it/s]concatenating: train:  50%|████▉     | 154/311 [00:04<00:04, 36.56it/s]concatenating: train:  51%|█████     | 159/311 [00:04<00:03, 38.26it/s]concatenating: train:  54%|█████▎    | 167/311 [00:04<00:03, 44.19it/s]concatenating: train:  56%|█████▌    | 174/311 [00:04<00:02, 48.05it/s]concatenating: train:  58%|█████▊    | 180/311 [00:04<00:02, 44.27it/s]concatenating: train:  59%|█████▉    | 185/311 [00:04<00:02, 42.18it/s]concatenating: train:  62%|██████▏   | 194/311 [00:05<00:02, 49.81it/s]concatenating: train:  66%|██████▌   | 206/311 [00:05<00:01, 60.01it/s]concatenating: train:  69%|██████▉   | 215/311 [00:05<00:01, 65.01it/s]concatenating: train:  72%|███████▏  | 223/311 [00:05<00:01, 68.25it/s]concatenating: train:  74%|███████▍  | 231/311 [00:05<00:01, 58.80it/s]concatenating: train:  77%|███████▋  | 238/311 [00:05<00:01, 49.67it/s]concatenating: train:  78%|███████▊  | 244/311 [00:05<00:01, 42.21it/s]concatenating: train:  80%|████████  | 249/311 [00:06<00:01, 42.47it/s]concatenating: train:  82%|████████▏ | 255/311 [00:06<00:01, 44.48it/s]concatenating: train:  84%|████████▎ | 260/311 [00:06<00:01, 44.32it/s]concatenating: train:  86%|████████▌ | 266/311 [00:06<00:00, 46.07it/s]concatenating: train:  87%|████████▋ | 271/311 [00:06<00:01, 34.63it/s]concatenating: train:  89%|████████▊ | 276/311 [00:06<00:01, 30.59it/s]concatenating: train:  90%|█████████ | 280/311 [00:06<00:01, 28.94it/s]concatenating: train:  93%|█████████▎| 288/311 [00:07<00:00, 34.58it/s]concatenating: train:  95%|█████████▍| 294/311 [00:07<00:00, 39.07it/s]concatenating: train:  97%|█████████▋| 302/311 [00:07<00:00, 45.86it/s]concatenating: train: 100%|██████████| 311/311 [00:07<00:00, 42.05it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:15<00:45, 15.14s/it]Loading test:  50%|█████     | 2/4 [00:28<00:29, 14.70s/it]Loading test:  75%|███████▌  | 3/4 [00:44<00:14, 14.88s/it]Loading test: 100%|██████████| 4/4 [00:58<00:00, 14.86s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 31.16it/s] 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________2019-07-08 03:43:14.980282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 03:43:14.980388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 03:43:14.980403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 03:43:14.980413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 03:43:14.980844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [5.86066190e-02 2.84688586e-02 1.21642213e-01 1.04576120e-02
 3.14646619e-02 5.44310893e-03 7.20519791e-02 1.12887958e-01
 7.85252165e-02 1.27448500e-02 2.91951514e-01 1.75516909e-01
 2.38500254e-04]
Train on 12832 samples, validate on 168 samples
Epoch 1/300
 - 31s - loss: 14397.0316 - acc: 0.8561 - mDice: 0.1799 - val_loss: 4625.3939 - val_acc: 0.8771 - val_mDice: 0.3778

Epoch 00001: val_mDice improved from -inf to 0.37775, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 4361.8403 - acc: 0.8944 - mDice: 0.4281 - val_loss: 3170.1563 - val_acc: 0.9135 - val_mDice: 0.5074

Epoch 00002: val_mDice improved from 0.37775 to 0.50738, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 3320.3930 - acc: 0.9115 - mDice: 0.5181 - val_loss: 2675.8866 - val_acc: 0.9256 - val_mDice: 0.5554

Epoch 00003: val_mDice improved from 0.50738 to 0.55540, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 2801.2206 - acc: 0.9216 - mDice: 0.5719 - val_loss: 2320.4339 - val_acc: 0.9318 - val_mDice: 0.5994

Epoch 00004: val_mDice improved from 0.55540 to 0.59941, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 20s - loss: 2451.1759 - acc: 0.9280 - mDice: 0.6110 - val_loss: 2078.7443 - val_acc: 0.9372 - val_mDice: 0.6278

Epoch 00005: val_mDice improved from 0.59941 to 0.62776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 20s - loss: 2208.1366 - acc: 0.9325 - mDice: 0.6404 - val_loss: 1988.4451 - val_acc: 0.9402 - val_mDice: 0.6409

Epoch 00006: val_mDice improved from 0.62776 to 0.64094, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 20s - loss: 2040.6671 - acc: 0.9358 - mDice: 0.6616 - val_loss: 1861.3841 - val_acc: 0.9441 - val_mDice: 0.6568

Epoch 00007: val_mDice improved from 0.64094 to 0.65683, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 19s - loss: 1916.4794 - acc: 0.9384 - mDice: 0.6783 - val_loss: 1835.6305 - val_acc: 0.9443 - val_mDice: 0.6604

Epoch 00008: val_mDice improved from 0.65683 to 0.66036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 20s - loss: 1815.4636 - acc: 0.9404 - mDice: 0.6919 - val_loss: 1839.8682 - val_acc: 0.9448 - val_mDice: 0.6611

Epoch 00009: val_mDice improved from 0.66036 to 0.66114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 19s - loss: 1727.4137 - acc: 0.9422 - mDice: 0.7042 - val_loss: 1775.1284 - val_acc: 0.9464 - val_mDice: 0.6690

Epoch 00010: val_mDice improved from 0.66114 to 0.66898, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 19s - loss: 1659.2728 - acc: 0.9437 - mDice: 0.7137 - val_loss: 1752.3742 - val_acc: 0.9462 - val_mDice: 0.6748

Epoch 00011: val_mDice improved from 0.66898 to 0.67482, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 1655.3330 - acc: 0.9439 - mDice: 0.7146 - val_loss: 1749.6916 - val_acc: 0.9468 - val_mDice: 0.6748

Epoch 00012: val_mDice did not improve from 0.67482
Epoch 13/300
 - 16s - loss: 1554.7668 - acc: 0.9459 - mDice: 0.7288 - val_loss: 1692.5290 - val_acc: 0.9488 - val_mDice: 0.6833

Epoch 00013: val_mDice improved from 0.67482 to 0.68329, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 16s - loss: 1509.4212 - acc: 0.9468 - mDice: 0.7355 - val_loss: 1689.6044 - val_acc: 0.9507 - val_mDice: 0.6842

Epoch 00014: val_mDice improved from 0.68329 to 0.68418, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 1463.7893 - acc: 0.9478 - mDice: 0.7423 - val_loss: 1728.7537 - val_acc: 0.9477 - val_mDice: 0.6791

Epoch 00015: val_mDice did not improve from 0.68418
Epoch 16/300
 - 16s - loss: 1427.0714 - acc: 0.9484 - mDice: 0.7477 - val_loss: 1732.5260 - val_acc: 0.9492 - val_mDice: 0.6782

Epoch 00016: val_mDice did not improve from 0.68418
Epoch 17/300
 - 15s - loss: 1393.5748 - acc: 0.9492 - mDice: 0.7528 - val_loss: 1679.8923 - val_acc: 0.9509 - val_mDice: 0.6864

Epoch 00017: val_mDice improved from 0.68418 to 0.68640, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 16s - loss: 1359.6432 - acc: 0.9498 - mDice: 0.7579 - val_loss: 1759.2031 - val_acc: 0.9490 - val_mDice: 0.6754

Epoch 00018: val_mDice did not improve from 0.68640
Epoch 19/300
 - 15s - loss: 1332.5595 - acc: 0.9504 - mDice: 0.7621 - val_loss: 1710.1553 - val_acc: 0.9509 - val_mDice: 0.6817

Epoch 00019: val_mDice did not improve from 0.68640
Epoch 20/300
 - 16s - loss: 1299.8850 - acc: 0.9509 - mDice: 0.7670 - val_loss: 1726.4639 - val_acc: 0.9529 - val_mDice: 0.6817

Epoch 00020: val_mDice did not improve from 0.68640
Epoch 21/300
 - 15s - loss: 1272.5419 - acc: 0.9515 - mDice: 0.7713 - val_loss: 1717.9021 - val_acc: 0.9501 - val_mDice: 0.6805

Epoch 00021: val_mDice did not improve from 0.68640
Epoch 22/300
 - 16s - loss: 1254.7400 - acc: 0.9519 - mDice: 0.7741 - val_loss: 1632.0549 - val_acc: 0.9527 - val_mDice: 0.6919

Epoch 00022: val_mDice improved from 0.68640 to 0.69195, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 15s - loss: 1224.4503 - acc: 0.9525 - mDice: 0.7788 - val_loss: 1719.0526 - val_acc: 0.9510 - val_mDice: 0.6804

Epoch 00023: val_mDice did not improve from 0.69195
Epoch 24/300
 - 16s - loss: 1202.9185 - acc: 0.9528 - mDice: 0.7822 - val_loss: 1850.3627 - val_acc: 0.9514 - val_mDice: 0.6635

Epoch 00024: val_mDice did not improve from 0.69195
Epoch 25/300
 - 15s - loss: 1180.6879 - acc: 0.9534 - mDice: 0.7857 - val_loss: 1736.3876 - val_acc: 0.9522 - val_mDice: 0.6780

Epoch 00025: val_mDice did not improve from 0.69195
Epoch 26/300
 - 16s - loss: 1160.2038 - acc: 0.9536 - mDice: 0.7890 - val_loss: 1733.4992 - val_acc: 0.9499 - val_mDice: 0.6768

Epoch 00026: val_mDice did not improve from 0.69195
Epoch 27/300
 - 15s - loss: 1143.8093 - acc: 0.9540 - mDice: 0.7915 - val_loss: 1717.3034 - val_acc: 0.9506 - val_mDice: 0.6816

Epoch 00027: val_mDice did not improve from 0.69195
Epoch 28/300
 - 16s - loss: 1124.5252 - acc: 0.9544 - mDice: 0.7946 - val_loss: 1695.7344 - val_acc: 0.9515 - val_mDice: 0.6838

Epoch 00028: val_mDice did not improve from 0.69195
Epoch 29/300
 - 15s - loss: 1111.4033 - acc: 0.9547 - mDice: 0.7968 - val_loss: 1652.8911 - val_acc: 0.9531 - val_mDice: 0.6899

Epoch 00029: val_mDice did not improve from 0.69195
Epoch 30/300
 - 16s - loss: 1093.8850 - acc: 0.9550 - mDice: 0.7996 - val_loss: 1687.1388 - val_acc: 0.9528 - val_mDice: 0.6836

Epoch 00030: val_mDice did not improve from 0.69195
Epoch 31/300
 - 15s - loss: 1077.3889 - acc: 0.9553 - mDice: 0.8023 - val_loss: 1639.0458 - val_acc: 0.9539 - val_mDice: 0.6928

Epoch 00031: val_mDice improved from 0.69195 to 0.69284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 16s - loss: 1065.4913 - acc: 0.9555 - mDice: 0.8041 - val_loss: 1694.4850 - val_acc: 0.9541 - val_mDice: 0.6838

Epoch 00032: val_mDice did not improve from 0.69284
Epoch 33/300
 - 15s - loss: 1047.9989 - acc: 0.9558 - mDice: 0.8070 - val_loss: 1685.5574 - val_acc: 0.9551 - val_mDice: 0.6865

Epoch 00033: val_mDice did not improve from 0.69284
Epoch 34/300
 - 16s - loss: 1033.5608 - acc: 0.9561 - mDice: 0.8094 - val_loss: 1699.4783 - val_acc: 0.9534 - val_mDice: 0.6850

Epoch 00034: val_mDice did not improve from 0.69284
Epoch 35/300
 - 15s - loss: 1020.6289 - acc: 0.9563 - mDice: 0.8115 - val_loss: 1622.6184 - val_acc: 0.9557 - val_mDice: 0.6954

Epoch 00035: val_mDice improved from 0.69284 to 0.69536, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 36/300
 - 16s - loss: 1005.9767 - acc: 0.9567 - mDice: 0.8139 - val_loss: 1724.1748 - val_acc: 0.9536 - val_mDice: 0.6816

Epoch 00036: val_mDice did not improve from 0.69536
Epoch 37/300
 - 15s - loss: 992.0872 - acc: 0.9569 - mDice: 0.8162 - val_loss: 1726.0514 - val_acc: 0.9562 - val_mDice: 0.6821

Epoch 00037: val_mDice did not improve from 0.69536
Epoch 38/300
 - 16s - loss: 980.2105 - acc: 0.9572 - mDice: 0.8182 - val_loss: 1735.0575 - val_acc: 0.9555 - val_mDice: 0.6784

Epoch 00038: val_mDice did not improve from 0.69536
Epoch 39/300
 - 15s - loss: 969.0307 - acc: 0.9573 - mDice: 0.8201 - val_loss: 1711.7661 - val_acc: 0.9568 - val_mDice: 0.6813

Epoch 00039: val_mDice did not improve from 0.69536
Epoch 40/300
 - 16s - loss: 957.7045 - acc: 0.9576 - mDice: 0.8219 - val_loss: 1614.7555 - val_acc: 0.9570 - val_mDice: 0.6948

Epoch 00040: val_mDice did not improve from 0.69536
Epoch 41/300
 - 15s - loss: 946.7752 - acc: 0.9578 - mDice: 0.8237 - val_loss: 1618.4777 - val_acc: 0.9561 - val_mDice: 0.6946

Epoch 00041: val_mDice did not improve from 0.69536
Epoch 42/300
 - 16s - loss: 937.6379 - acc: 0.9580 - mDice: 0.8253 - val_loss: 1727.5471 - val_acc: 0.9551 - val_mDice: 0.6804

Epoch 00042: val_mDice did not improve from 0.69536
Epoch 43/300
 - 15s - loss: 925.7953 - acc: 0.9582 - mDice: 0.8273 - val_loss: 1732.5468 - val_acc: 0.9566 - val_mDice: 0.6786

Epoch 00043: val_mDice did not improve from 0.69536
Epoch 44/300
 - 16s - loss: 914.3728 - acc: 0.9584 - mDice: 0.8292 - val_loss: 1677.9933 - val_acc: 0.9564 - val_mDice: 0.6887

Epoch 00044: val_mDice did not improve from 0.69536
Epoch 45/300
 - 16s - loss: 909.9089 - acc: 0.9585 - mDice: 0.8300 - val_loss: 1708.7211 - val_acc: 0.9539 - val_mDice: 0.6828

Epoch 00045: val_mDice did not improve from 0.69536
Epoch 46/300
 - 16s - loss: 898.4104 - acc: 0.9587 - mDice: 0.8319 - val_loss: 1706.3500 - val_acc: 0.9558 - val_mDice: 0.6831

Epoch 00046: val_mDice did not improve from 0.69536
Epoch 47/300
 - 15s - loss: 891.3700 - acc: 0.9588 - mDice: 0.8331 - val_loss: 1689.2961 - val_acc: 0.9575 - val_mDice: 0.6856

Epoch 00047: val_mDice did not improve from 0.69536
Epoch 48/300
 - 16s - loss: 881.2352 - acc: 0.9589 - mDice: 0.8348 - val_loss: 1736.0037 - val_acc: 0.9568 - val_mDice: 0.6790

Epoch 00048: val_mDice did not improve from 0.69536
Epoch 49/300
 - 16s - loss: 870.7649 - acc: 0.9592 - mDice: 0.8366 - val_loss: 1716.0956 - val_acc: 0.9555 - val_mDice: 0.6845

Epoch 00049: val_mDice did not improve from 0.69536
Epoch 50/300
 - 16s - loss: 861.9886 - acc: 0.9594 - mDice: 0.8381 - val_loss: 1692.7910 - val_acc: 0.9551 - val_mDice: 0.6874

Epoch 00050: val_mDice did not improve from 0.69536
Epoch 51/300
 - 15s - loss: 854.1293 - acc: 0.9595 - mDice: 0.8395 - val_loss: 1729.1090 - val_acc: 0.9556 - val_mDice: 0.6783

Epoch 00051: val_mDice did not improve from 0.69536
Epoch 52/300
 - 16s - loss: 848.3637 - acc: 0.9595 - mDice: 0.8405 - val_loss: 1677.0025 - val_acc: 0.9546 - val_mDice: 0.6895

Epoch 00052: val_mDice did not improve from 0.69536
Epoch 53/300
 - 15s - loss: 838.0364 - acc: 0.9598 - mDice: 0.8422 - val_loss: 1730.7454 - val_acc: 0.9558 - val_mDice: 0.6827

Epoch 00053: val_mDice did not improve from 0.69536
Epoch 54/300
 - 16s - loss: 828.8951 - acc: 0.9599 - mDice: 0.8438 - val_loss: 1733.8596 - val_acc: 0.9573 - val_mDice: 0.6785

Epoch 00054: val_mDice did not improve from 0.69536
Epoch 55/300
 - 15s - loss: 820.4915 - acc: 0.9601 - mDice: 0.8453 - val_loss: 1678.8627 - val_acc: 0.9574 - val_mDice: 0.6880

Epoch 00055: val_mDice did not improve from 0.69536
Epoch 56/300
 - 16s - loss: 816.1763 - acc: 0.9602 - mDice: 0.8460 - val_loss: 1694.6410 - val_acc: 0.9562 - val_mDice: 0.6868

Epoch 00056: val_mDice did not improve from 0.69536
Epoch 57/300
 - 16s - loss: 811.4482 - acc: 0.9603 - mDice: 0.8468 - val_loss: 1684.9496 - val_acc: 0.9552 - val_mDice: 0.6848

Epoch 00057: val_mDice did not improve from 0.69536
Epoch 58/300
 - 16s - loss: 797.2659 - acc: 0.9606 - mDice: 0.8492 - val_loss: 1691.2388 - val_acc: 0.9562 - val_mDice: 0.6846

Epoch 00058: val_mDice did not improve from 0.69536
Epoch 59/300
 - 16s - loss: 794.7034 - acc: 0.9606 - mDice: 0.8497 - val_loss: 1704.8766 - val_acc: 0.9577 - val_mDice: 0.6829

Epoch 00059: val_mDice did not improve from 0.69536
Epoch 60/300
 - 16s - loss: 787.4492 - acc: 0.9607 - mDice: 0.8510 - val_loss: 1683.1086 - val_acc: 0.9570 - val_mDice: 0.6869

Epoch 00060: val_mDice did not improve from 0.69536
Epoch 61/300
 - 16s - loss: 782.6068 - acc: 0.9608 - mDice: 0.8518 - val_loss: 1664.7283 - val_acc: 0.9571 - val_mDice: 0.6892

Epoch 00061: val_mDice did not improve from 0.69536
Epoch 62/300
 - 16s - loss: 778.6087 - acc: 0.9609 - mDice: 0.8525 - val_loss: 1623.8604 - val_acc: 0.9570 - val_mDice: 0.6927

Epoch 00062: val_mDice did not improve from 0.69536
Epoch 63/300
 - 17s - loss: 771.1788 - acc: 0.9610 - mDice: 0.8538 - val_loss: 1694.4098 - val_acc: 0.9567 - val_mDice: 0.6840

Epoch 00063: val_mDice did not improve from 0.69536
Epoch 64/300
 - 16s - loss: 763.7096 - acc: 0.9611 - mDice: 0.8551 - val_loss: 1735.8169 - val_acc: 0.9550 - val_mDice: 0.6806

Epoch 00064: val_mDice did not improve from 0.69536
Epoch 65/300
 - 16s - loss: 758.1365 - acc: 0.9612 - mDice: 0.8560 - val_loss: 1658.3255 - val_acc: 0.9568 - val_mDice: 0.6902

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:16<00:48, 16.17s/it]predicting test subjects:  50%|█████     | 2/4 [00:30<00:31, 15.61s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:45<00:15, 15.46s/it]predicting test subjects: 100%|██████████| 4/4 [01:00<00:00, 15.21s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:22<1:55:56, 22.44s/it]predicting train subjects:   1%|          | 2/311 [00:33<1:37:23, 18.91s/it]predicting train subjects:   1%|          | 3/311 [00:46<1:28:41, 17.28s/it]predicting train subjects:   1%|▏         | 4/311 [00:59<1:21:07, 15.86s/it]predicting train subjects:   2%|▏         | 5/311 [01:10<1:14:34, 14.62s/it]predicting train subjects:   2%|▏         | 6/311 [01:22<1:10:21, 13.84s/it]predicting train subjects:   2%|▏         | 7/311 [01:36<1:09:54, 13.80s/it]predicting train subjects:   3%|▎         | 8/311 [01:52<1:12:53, 14.43s/it]predicting train subjects:   3%|▎         | 9/311 [02:06<1:12:17, 14.36s/it]predicting train subjects:   3%|▎         | 10/311 [02:18<1:08:50, 13.72s/it]predicting train subjects:   4%|▎         | 11/311 [02:34<1:11:28, 14.29s/it]predicting train subjects:   4%|▍         | 12/311 [02:46<1:08:08, 13.67s/it]predicting train subjects:   4%|▍         | 13/311 [02:58<1:05:03, 13.10s/it]predicting train subjects:   5%|▍         | 14/311 [03:14<1:08:47, 13.90s/it]predicting train subjects:   5%|▍         | 15/311 [03:36<1:20:58, 16.41s/it]predicting train subjects:   5%|▌         | 16/311 [03:58<1:29:28, 18.20s/it]predicting train subjects:   5%|▌         | 17/311 [04:21<1:35:41, 19.53s/it]predicting train subjects:   6%|▌         | 18/311 [04:44<1:39:41, 20.42s/it]predicting train subjects:   6%|▌         | 19/311 [05:06<1:42:51, 21.13s/it]predicting train subjects:   6%|▋         | 20/311 [05:29<1:44:46, 21.60s/it]predicting train subjects:   7%|▋         | 21/311 [05:52<1:46:12, 21.97s/it]predicting train subjects:   7%|▋         | 22/311 [06:15<1:47:24, 22.30s/it]predicting train subjects:   7%|▋         | 23/311 [06:37<1:47:00, 22.29s/it]predicting train subjects:   8%|▊         | 24/311 [07:00<1:46:57, 22.36s/it]predicting train subjects:   8%|▊         | 25/311 [07:26<1:51:53, 23.47s/it]predicting train subjects:   8%|▊         | 26/311 [07:53<1:57:17, 24.69s/it]predicting train subjects:   9%|▊         | 27/311 [08:22<2:01:47, 25.73s/it]predicting train subjects:   9%|▉         | 28/311 [08:49<2:04:22, 26.37s/it]predicting train subjects:   9%|▉         | 29/311 [09:17<2:05:28, 26.70s/it]predicting train subjects:  10%|▉         | 30/311 [09:45<2:06:52, 27.09s/it]predicting train subjects:  10%|▉         | 31/311 [10:13<2:08:34, 27.55s/it]predicting train subjects:  10%|█         | 32/311 [10:41<2:08:26, 27.62s/it]predicting train subjects:  11%|█         | 33/311 [10:54<1:46:36, 23.01s/it]predicting train subjects:  11%|█         | 34/311 [11:06<1:31:05, 19.73s/it]predicting train subjects:  11%|█▏        | 35/311 [11:19<1:21:50, 17.79s/it]predicting train subjects:  12%|█▏        | 36/311 [11:32<1:15:23, 16.45s/it]predicting train subjects:  12%|█▏        | 37/311 [11:45<1:10:44, 15.49s/it]predicting train subjects:  12%|█▏        | 38/311 [11:59<1:07:13, 14.77s/it]predicting train subjects:  13%|█▎        | 39/311 [12:12<1:04:56, 14.33s/it]predicting train subjects:  13%|█▎        | 40/311 [12:25<1:02:38, 13.87s/it]predicting train subjects:  13%|█▎        | 41/311 [12:37<1:00:50, 13.52s/it]predicting train subjects:  14%|█▎        | 42/311 [12:48<56:39, 12.64s/it]  predicting train subjects:  14%|█▍        | 43/311 [12:58<52:58, 11.86s/it]predicting train subjects:  14%|█▍        | 44/311 [13:08<50:46, 11.41s/it]predicting train subjects:  14%|█▍        | 45/311 [13:19<49:25, 11.15s/it]predicting train subjects:  15%|█▍        | 46/311 [13:29<48:26, 10.97s/it]predicting train subjects:  15%|█▌        | 47/311 [13:39<47:05, 10.70s/it]predicting train subjects:  15%|█▌        | 48/311 [13:50<46:22, 10.58s/it]predicting train subjects:  16%|█▌        | 49/311 [14:00<46:08, 10.57s/it]predicting train subjects:  16%|█▌        | 50/311 [14:11<45:54, 10.55s/it]predicting train subjects:  16%|█▋        | 51/311 [14:24<48:58, 11.30s/it]predicting train subjects:  17%|█▋        | 52/311 [14:37<51:11, 11.86s/it]predicting train subjects:  17%|█▋        | 53/311 [14:50<52:28, 12.20s/it]predicting train subjects:  17%|█▋        | 54/311 [15:03<53:40, 12.53s/it]predicting train subjects:  18%|█▊        | 55/311 [15:17<54:20, 12.74s/it]predicting train subjects:  18%|█▊        | 56/311 [15:30<54:46, 12.89s/it]predicting train subjects:  18%|█▊        | 57/311 [15:43<55:08, 13.02s/it]predicting train subjects:  19%|█▊        | 58/311 [15:56<55:10, 13.08s/it]predicting train subjects:  19%|█▉        | 59/311 [16:10<55:10, 13.14s/it]predicting train subjects:  19%|█▉        | 60/311 [16:23<55:05, 13.17s/it]predicting train subjects:  20%|█▉        | 61/311 [16:36<55:10, 13.24s/it]predicting train subjects:  20%|█▉        | 62/311 [16:50<55:10, 13.30s/it]predicting train subjects:  20%|██        | 63/311 [17:03<55:01, 13.31s/it]predicting train subjects:  21%|██        | 64/311 [17:16<54:27, 13.23s/it]predicting train subjects:  21%|██        | 65/311 [17:29<54:00, 13.17s/it]predicting train subjects:  21%|██        | 66/311 [17:43<54:15, 13.29s/it]predicting train subjects:  22%|██▏       | 67/311 [17:56<53:54, 13.26s/it]predicting train subjects:  22%|██▏       | 68/311 [18:09<53:26, 13.20s/it]predicting train subjects:  22%|██▏       | 69/311 [18:21<52:21, 12.98s/it]predicting train subjects:  23%|██▎       | 70/311 [18:34<52:00, 12.95s/it]predicting train subjects:  23%|██▎       | 71/311 [18:48<52:30, 13.13s/it]predicting train subjects:  23%|██▎       | 72/311 [19:02<53:03, 13.32s/it]predicting train subjects:  23%|██▎       | 73/311 [19:16<54:09, 13.65s/it]predicting train subjects:  24%|██▍       | 74/311 [19:31<55:29, 14.05s/it]predicting train subjects:  24%|██▍       | 75/311 [19:45<54:57, 13.97s/it]predicting train subjects:  24%|██▍       | 76/311 [19:59<55:14, 14.10s/it]predicting train subjects:  25%|██▍       | 77/311 [20:13<54:10, 13.89s/it]predicting train subjects:  25%|██▌       | 78/311 [20:27<54:29, 14.03s/it]predicting train subjects:  25%|██▌       | 79/311 [20:41<54:24, 14.07s/it]predicting train subjects:  26%|██▌       | 80/311 [20:55<53:39, 13.94s/it]predicting train subjects:  26%|██▌       | 81/311 [21:09<53:41, 14.01s/it]predicting train subjects:  26%|██▋       | 82/311 [21:25<55:47, 14.62s/it]predicting train subjects:  27%|██▋       | 83/311 [21:38<54:13, 14.27s/it]predicting train subjects:  27%|██▋       | 84/311 [21:52<53:32, 14.15s/it]predicting train subjects:  27%|██▋       | 85/311 [22:05<52:12, 13.86s/it]predicting train subjects:  28%|██▊       | 86/311 [22:18<50:49, 13.55s/it]predicting train subjects:  28%|██▊       | 87/311 [22:31<49:55, 13.37s/it]predicting train subjects:  28%|██▊       | 88/311 [22:44<49:11, 13.24s/it]predicting train subjects:  29%|██▊       | 89/311 [22:57<48:42, 13.16s/it]predicting train subjects:  29%|██▉       | 90/311 [23:10<48:26, 13.15s/it]predicting train subjects:  29%|██▉       | 91/311 [23:24<48:46, 13.30s/it]predicting train subjects:  30%|██▉       | 92/311 [23:37<48:21, 13.25s/it]predicting train subjects:  30%|██▉       | 93/311 [23:49<47:07, 12.97s/it]predicting train subjects:  30%|███       | 94/311 [24:03<47:05, 13.02s/it]predicting train subjects:  31%|███       | 95/311 [24:16<47:44, 13.26s/it]predicting train subjects:  31%|███       | 96/311 [24:30<48:03, 13.41s/it]predicting train subjects:  31%|███       | 97/311 [24:43<47:29, 13.32s/it]predicting train subjects:  32%|███▏      | 98/311 [24:57<47:17, 13.32s/it]predicting train subjects:  32%|███▏      | 99/311 [25:10<47:28, 13.44s/it]predicting train subjects:  32%|███▏      | 100/311 [25:24<47:27, 13.49s/it]predicting train subjects:  32%|███▏      | 101/311 [25:38<47:27, 13.56s/it]predicting train subjects:  33%|███▎      | 102/311 [25:51<47:11, 13.55s/it]predicting train subjects:  33%|███▎      | 103/311 [26:04<46:16, 13.35s/it]predicting train subjects:  33%|███▎      | 104/311 [26:17<45:37, 13.23s/it]predicting train subjects:  34%|███▍      | 105/311 [26:31<45:49, 13.35s/it]predicting train subjects:  34%|███▍      | 106/311 [26:44<45:39, 13.37s/it]predicting train subjects:  34%|███▍      | 107/311 [26:57<45:08, 13.28s/it]predicting train subjects:  35%|███▍      | 108/311 [27:10<44:59, 13.30s/it]predicting train subjects:  35%|███▌      | 109/311 [27:24<45:04, 13.39s/it]predicting train subjects:  35%|███▌      | 110/311 [27:37<44:11, 13.19s/it]predicting train subjects:  36%|███▌      | 111/311 [27:50<44:01, 13.21s/it]predicting train subjects:  36%|███▌      | 112/311 [28:03<43:51, 13.22s/it]predicting train subjects:  36%|███▋      | 113/311 [28:15<42:42, 12.94s/it]predicting train subjects:  37%|███▋      | 114/311 [28:38<52:08, 15.88s/it]predicting train subjects:  37%|███▋      | 115/311 [29:01<58:45, 17.99s/it]predicting train subjects:  37%|███▋      | 116/311 [29:24<1:03:05, 19.41s/it]predicting train subjects:  38%|███▊      | 117/311 [29:47<1:06:13, 20.48s/it]predicting train subjects:  38%|███▊      | 118/311 [30:10<1:08:12, 21.21s/it]predicting train subjects:  38%|███▊      | 119/311 [30:33<1:09:38, 21.76s/it]predicting train subjects:  39%|███▊      | 120/311 [30:56<1:10:10, 22.04s/it]predicting train subjects:  39%|███▉      | 121/311 [31:18<1:10:23, 22.23s/it]predicting train subjects:  39%|███▉      | 122/311 [31:41<1:10:11, 22.28s/it]predicting train subjects:  40%|███▉      | 123/311 [32:04<1:10:28, 22.49s/it]predicting train subjects:  40%|███▉      | 124/311 [32:26<1:10:26, 22.60s/it]predicting train subjects:  40%|████      | 125/311 [32:49<1:10:02, 22.59s/it]predicting train subjects:  41%|████      | 126/311 [33:12<1:09:37, 22.58s/it]predicting train subjects:  41%|████      | 127/311 [33:34<1:09:04, 22.52s/it]predicting train subjects:  41%|████      | 128/311 [33:59<1:10:59, 23.28s/it]predicting train subjects:  41%|████▏     | 129/311 [34:25<1:12:50, 24.02s/it]predicting train subjects:  42%|████▏     | 130/311 [34:51<1:14:05, 24.56s/it]predicting train subjects:  42%|████▏     | 131/311 [35:18<1:16:08, 25.38s/it]predicting train subjects:  42%|████▏     | 132/311 [35:30<1:04:07, 21.49s/it]predicting train subjects:  43%|████▎     | 133/311 [35:43<55:51, 18.83s/it]  predicting train subjects:  43%|████▎     | 134/311 [35:56<50:16, 17.04s/it]predicting train subjects:  43%|████▎     | 135/311 [36:08<45:25, 15.49s/it]predicting train subjects:  44%|████▎     | 136/311 [36:18<41:03, 14.07s/it]predicting train subjects:  44%|████▍     | 137/311 [36:31<39:33, 13.64s/it]predicting train subjects:  44%|████▍     | 138/311 [36:43<38:02, 13.19s/it]predicting train subjects:  45%|████▍     | 139/311 [36:55<36:30, 12.74s/it]predicting train subjects:  45%|████▌     | 140/311 [37:07<36:03, 12.65s/it]predicting train subjects:  45%|████▌     | 141/311 [37:19<35:05, 12.39s/it]predicting train subjects:  46%|████▌     | 142/311 [37:32<35:06, 12.46s/it]predicting train subjects:  46%|████▌     | 143/311 [37:44<34:24, 12.29s/it]predicting train subjects:  46%|████▋     | 144/311 [37:56<34:27, 12.38s/it]predicting train subjects:  47%|████▋     | 145/311 [38:09<34:19, 12.41s/it]predicting train subjects:  47%|████▋     | 146/311 [38:20<33:21, 12.13s/it]predicting train subjects:  47%|████▋     | 147/311 [38:33<33:40, 12.32s/it]predicting train subjects:  48%|████▊     | 148/311 [38:46<33:52, 12.47s/it]predicting train subjects:  48%|████▊     | 149/311 [38:58<33:25, 12.38s/it]predicting train subjects:  48%|████▊     | 150/311 [39:14<35:54, 13.38s/it]predicting train subjects:  49%|████▊     | 151/311 [39:30<38:04, 14.28s/it]predicting train subjects:  49%|████▉     | 152/311 [39:46<38:53, 14.68s/it]predicting train subjects:  49%|████▉     | 153/311 [40:01<39:01, 14.82s/it]predicting train subjects:  50%|████▉     | 154/311 [40:14<37:30, 14.33s/it]predicting train subjects:  50%|████▉     | 155/311 [40:27<36:03, 13.87s/it]predicting train subjects:  50%|█████     | 156/311 [40:40<35:33, 13.77s/it]predicting train subjects:  50%|█████     | 157/311 [40:53<34:44, 13.54s/it]predicting train subjects:  51%|█████     | 158/311 [41:07<34:22, 13.48s/it]predicting train subjects:  51%|█████     | 159/311 [41:20<34:04, 13.45s/it]predicting train subjects:  51%|█████▏    | 160/311 [41:33<33:25, 13.28s/it]predicting train subjects:  52%|█████▏    | 161/311 [41:46<33:08, 13.26s/it]predicting train subjects:  52%|█████▏    | 162/311 [42:00<33:09, 13.35s/it]predicting train subjects:  52%|█████▏    | 163/311 [42:13<32:51, 13.32s/it]predicting train subjects:  53%|█████▎    | 164/311 [42:26<32:17, 13.18s/it]predicting train subjects:  53%|█████▎    | 165/311 [42:39<32:01, 13.16s/it]predicting train subjects:  53%|█████▎    | 166/311 [42:52<31:39, 13.10s/it]predicting train subjects:  54%|█████▎    | 167/311 [43:04<31:06, 12.96s/it]predicting train subjects:  54%|█████▍    | 168/311 [43:17<30:52, 12.95s/it]predicting train subjects:  54%|█████▍    | 169/311 [43:31<31:07, 13.15s/it]predicting train subjects:  55%|█████▍    | 170/311 [43:44<30:44, 13.08s/it]predicting train subjects:  55%|█████▍    | 171/311 [43:57<30:30, 13.08s/it]predicting train subjects:  55%|█████▌    | 172/311 [44:10<30:08, 13.01s/it]predicting train subjects:  56%|█████▌    | 173/311 [44:23<29:50, 12.98s/it]predicting train subjects:  56%|█████▌    | 174/311 [44:35<29:24, 12.88s/it]predicting train subjects:  56%|█████▋    | 175/311 [44:49<29:23, 12.97s/it]predicting train subjects:  57%|█████▋    | 176/311 [45:01<28:58, 12.88s/it]predicting train subjects:  57%|█████▋    | 177/311 [45:14<28:42, 12.85s/it]predicting train subjects:  57%|█████▋    | 178/311 [45:27<28:33, 12.88s/it]predicting train subjects:  58%|█████▊    | 179/311 [45:40<28:25, 12.92s/it]predicting train subjects:  58%|█████▊    | 180/311 [45:53<28:33, 13.08s/it]predicting train subjects:  58%|█████▊    | 181/311 [46:07<28:21, 13.09s/it]predicting train subjects:  59%|█████▊    | 182/311 [46:20<28:05, 13.06s/it]predicting train subjects:  59%|█████▉    | 183/311 [46:32<27:44, 13.00s/it]predicting train subjects:  59%|█████▉    | 184/311 [46:44<26:41, 12.61s/it]predicting train subjects:  59%|█████▉    | 185/311 [46:56<26:04, 12.41s/it]predicting train subjects:  60%|█████▉    | 186/311 [47:08<25:33, 12.27s/it]predicting train subjects:  60%|██████    | 187/311 [47:20<25:02, 12.11s/it]predicting train subjects:  60%|██████    | 188/311 [47:31<24:31, 11.97s/it]predicting train subjects:  61%|██████    | 189/311 [47:43<24:01, 11.82s/it]predicting train subjects:  61%|██████    | 190/311 [47:55<23:46, 11.79s/it]predicting train subjects:  61%|██████▏   | 191/311 [48:06<23:40, 11.84s/it]predicting train subjects:  62%|██████▏   | 192/311 [48:18<23:28, 11.84s/it]predicting train subjects:  62%|██████▏   | 193/311 [48:30<23:05, 11.74s/it]predicting train subjects:  62%|██████▏   | 194/311 [48:41<22:41, 11.63s/it]predicting train subjects:  63%|██████▎   | 195/311 [48:53<22:31, 11.65s/it]predicting train subjects:  63%|██████▎   | 196/311 [49:05<22:20, 11.65s/it]predicting train subjects:  63%|██████▎   | 197/311 [49:17<22:39, 11.92s/it]predicting train subjects:  64%|██████▎   | 198/311 [49:29<22:25, 11.91s/it]predicting train subjects:  64%|██████▍   | 199/311 [49:40<21:55, 11.75s/it]predicting train subjects:  64%|██████▍   | 200/311 [49:52<21:34, 11.66s/it]predicting train subjects:  65%|██████▍   | 201/311 [50:04<21:28, 11.72s/it]predicting train subjects:  65%|██████▍   | 202/311 [50:16<21:26, 11.80s/it]predicting train subjects:  65%|██████▌   | 203/311 [50:28<21:19, 11.85s/it]predicting train subjects:  66%|██████▌   | 204/311 [50:40<21:11, 11.88s/it]predicting train subjects:  66%|██████▌   | 205/311 [50:51<20:43, 11.73s/it]predicting train subjects:  66%|██████▌   | 206/311 [51:03<20:26, 11.68s/it]predicting train subjects:  67%|██████▋   | 207/311 [51:14<20:22, 11.76s/it]predicting train subjects:  67%|██████▋   | 208/311 [51:26<20:16, 11.81s/it]predicting train subjects:  67%|██████▋   | 209/311 [51:38<20:07, 11.84s/it]predicting train subjects:  68%|██████▊   | 210/311 [51:50<19:57, 11.86s/it]predicting train subjects:  68%|██████▊   | 211/311 [52:02<19:37, 11.78s/it]predicting train subjects:  68%|██████▊   | 212/311 [52:14<19:42, 11.95s/it]predicting train subjects:  68%|██████▊   | 213/311 [52:37<24:42, 15.13s/it]predicting train subjects:  69%|██████▉   | 214/311 [52:59<27:55, 17.27s/it]predicting train subjects:  69%|██████▉   | 215/311 [53:21<29:49, 18.65s/it]predicting train subjects:  69%|██████▉   | 216/311 [53:43<31:25, 19.84s/it]predicting train subjects:  70%|██████▉   | 217/311 [54:07<32:50, 20.96s/it]predicting train subjects:  70%|███████   | 218/311 [54:30<33:16, 21.47s/it]predicting train subjects:  70%|███████   | 219/311 [54:52<33:19, 21.73s/it]predicting train subjects:  71%|███████   | 220/311 [55:16<33:45, 22.26s/it]predicting train subjects:  71%|███████   | 221/311 [55:38<33:32, 22.37s/it]predicting train subjects:  71%|███████▏  | 222/311 [56:01<33:26, 22.54s/it]predicting train subjects:  72%|███████▏  | 223/311 [56:23<32:49, 22.38s/it]predicting train subjects:  72%|███████▏  | 224/311 [56:46<32:38, 22.51s/it]predicting train subjects:  72%|███████▏  | 225/311 [57:09<32:42, 22.81s/it]predicting train subjects:  73%|███████▎  | 226/311 [57:32<32:07, 22.67s/it]predicting train subjects:  73%|███████▎  | 227/311 [57:55<31:49, 22.73s/it]predicting train subjects:  73%|███████▎  | 228/311 [58:17<31:22, 22.69s/it]predicting train subjects:  74%|███████▎  | 229/311 [58:40<31:02, 22.71s/it]predicting train subjects:  74%|███████▍  | 230/311 [59:03<30:48, 22.82s/it]predicting train subjects:  74%|███████▍  | 231/311 [59:14<25:41, 19.27s/it]predicting train subjects:  75%|███████▍  | 232/311 [59:25<22:04, 16.76s/it]predicting train subjects:  75%|███████▍  | 233/311 [59:35<19:15, 14.82s/it]predicting train subjects:  75%|███████▌  | 234/311 [59:46<17:28, 13.62s/it]predicting train subjects:  76%|███████▌  | 235/311 [59:57<16:19, 12.88s/it]predicting train subjects:  76%|███████▌  | 236/311 [1:00:08<15:17, 12.23s/it]predicting train subjects:  76%|███████▌  | 237/311 [1:00:18<14:24, 11.69s/it]predicting train subjects:  77%|███████▋  | 238/311 [1:00:29<13:53, 11.42s/it]predicting train subjects:  77%|███████▋  | 239/311 [1:00:40<13:30, 11.25s/it]predicting train subjects:  77%|███████▋  | 240/311 [1:00:51<13:06, 11.08s/it]predicting train subjects:  77%|███████▋  | 241/311 [1:01:01<12:48, 10.98s/it]predicting train subjects:  78%|███████▊  | 242/311 [1:01:12<12:38, 10.99s/it]predicting train subjects:  78%|███████▊  | 243/311 [1:01:23<12:28, 11.00s/it]predicting train subjects:  78%|███████▊  | 244/311 [1:01:34<12:15, 10.98s/it]predicting train subjects:  79%|███████▉  | 245/311 [1:01:45<11:57, 10.87s/it]predicting train subjects:  79%|███████▉  | 246/311 [1:01:57<11:58, 11.05s/it]predicting train subjects:  79%|███████▉  | 247/311 [1:02:08<11:56, 11.19s/it]predicting train subjects:  80%|███████▉  | 248/311 [1:02:19<11:35, 11.04s/it]predicting train subjects:  80%|████████  | 249/311 [1:02:32<12:15, 11.86s/it]predicting train subjects:  80%|████████  | 250/311 [1:02:46<12:34, 12.37s/it]predicting train subjects:  81%|████████  | 251/311 [1:03:00<12:45, 12.76s/it]predicting train subjects:  81%|████████  | 252/311 [1:03:14<12:54, 13.13s/it]predicting train subjects:  81%|████████▏ | 253/311 [1:03:27<12:45, 13.20s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:03:41<12:37, 13.28s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:03:54<12:31, 13.41s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:04:08<12:21, 13.48s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:04:22<12:11, 13.54s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:04:36<12:06, 13.70s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:04:50<11:54, 13.75s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:05:04<11:47, 13.88s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:05:20<12:17, 14.74s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:05:37<12:24, 15.20s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:05:53<12:26, 15.55s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:06:10<12:27, 15.91s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:06:26<12:20, 16.09s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:06:42<11:57, 15.95s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:06:58<11:43, 15.98s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:07:15<11:34, 16.16s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:07:31<11:19, 16.17s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:07:47<10:59, 16.09s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:08:02<10:38, 15.97s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:08:19<10:25, 16.05s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:08:35<10:16, 16.23s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:08:51<10:00, 16.22s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:09:08<09:42, 16.18s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:09:24<09:26, 16.19s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:09:40<09:13, 16.28s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:09:57<08:59, 16.35s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:10:13<08:41, 16.29s/it]predicting train subjects:  90%|█████████ | 280/311 [1:10:29<08:27, 16.37s/it]predicting train subjects:  90%|█████████ | 281/311 [1:10:45<08:05, 16.17s/it]predicting train subjects:  91%|█████████ | 282/311 [1:10:58<07:19, 15.16s/it]predicting train subjects:  91%|█████████ | 283/311 [1:11:09<06:30, 13.96s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:11:21<05:58, 13.29s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:11:33<05:35, 12.89s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:11:45<05:15, 12.61s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:11:56<04:55, 12.32s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:12:08<04:38, 12.10s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:12:20<04:22, 11.95s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:12:32<04:10, 11.94s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:12:44<03:59, 11.97s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:12:56<03:47, 11.96s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:13:07<03:33, 11.85s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:13:19<03:21, 11.86s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:13:31<03:10, 11.92s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:13:43<02:59, 11.96s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:13:55<02:47, 11.96s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:14:07<02:34, 11.87s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:14:18<02:21, 11.80s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:14:31<02:12, 12.00s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:14:43<02:01, 12.11s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:14:56<01:49, 12.18s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:15:08<01:36, 12.11s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:15:20<01:25, 12.22s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:15:33<01:13, 12.31s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:15:45<01:01, 12.36s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:15:57<00:49, 12.36s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:16:09<00:36, 12.26s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:16:21<00:24, 12.13s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:16:34<00:12, 12.23s/it]predicting train subjects: 100%|██████████| 311/311 [1:16:46<00:00, 12.21s/it]
Epoch 00065: val_mDice did not improve from 0.69536
Restoring model weights from the end of the best epoch
Epoch 00065: early stopping
{'val_loss': [4625.393949962798, 3170.156296502976, 2675.886648995536, 2320.4339047386534, 2078.7442830403647, 1988.445103236607, 1861.3841320219494, 1835.6305135091145, 1839.868187313988, 1775.128409249442, 1752.3741745721727, 1749.6916126069568, 1692.5289655412946, 1689.6043962751116, 1728.7537260509673, 1732.5259602864583, 1679.892290387835, 1759.203136625744, 1710.1552676246279, 1726.463890438988, 1717.9020937965029, 1632.054908389137, 1719.0525803338915, 1850.36274937221, 1736.3875761486236, 1733.4991571335565, 1717.3033796037946, 1695.7344447544642, 1652.891081310454, 1687.1387532552083, 1639.0457996186756, 1694.4849504743304, 1685.557361421131, 1699.4782540457588, 1622.618405296689, 1724.1748308454241, 1726.0514381045386, 1735.0574951171875, 1711.7660871233259, 1614.7555280412946, 1618.4777163550966, 1727.547116234189, 1732.5468081519716, 1677.9933151971727, 1708.7210548037574, 1706.3500482468378, 1689.2960960751489, 1736.003650483631, 1716.0955694289435, 1692.790992373512, 1729.1090436662946, 1677.0025460379463, 1730.7454223632812, 1733.859575544085, 1678.8627232142858, 1694.6409795851935, 1684.9496285574776, 1691.2387753441221, 1704.8766188848585, 1683.1086135137648, 1664.728315080915, 1623.8604271298364, 1694.4098336356026, 1735.8168538411458, 1658.3255033947173], 'val_acc': [0.8771362631093889, 0.9135058763481322, 0.9255794769241696, 0.9317751157851446, 0.9371708986305055, 0.9401971655232566, 0.944094832454409, 0.9443437925406865, 0.9447687651429858, 0.9464214344819387, 0.9462439942927587, 0.9468091712111518, 0.9488095229580289, 0.950704004083361, 0.9476505049637386, 0.949178682906287, 0.9508742505595797, 0.9490456339858827, 0.9508713980515798, 0.9528531446343377, 0.9500772655010223, 0.9527043189321246, 0.9509529499780565, 0.9513593358652932, 0.9521820843219757, 0.9498726583662487, 0.9505594670772552, 0.9514537638141995, 0.9530835038139707, 0.9528044902143025, 0.9539319816089812, 0.954062207823708, 0.9550924471446446, 0.9534211698032561, 0.9557291680858249, 0.9536014610812777, 0.956184161560876, 0.9554945131142935, 0.9567651251951853, 0.9569811792600722, 0.9560525445711046, 0.9550580694561913, 0.9565748217559996, 0.9564345890567416, 0.9538962244987488, 0.9557778239250183, 0.9574762341522035, 0.9567994517939431, 0.9554644567625863, 0.9550895662534804, 0.9556332727273306, 0.9546316933064234, 0.9558250421569461, 0.9572673610278538, 0.9574333358378637, 0.9561755997794015, 0.9552169044812521, 0.9562457104523977, 0.9577166466485887, 0.9569782827581678, 0.9570655879520235, 0.9570469870453789, 0.9566592474778494, 0.9550452076253437, 0.9568194832120623], 'val_mDice': [0.37775184710820514, 0.5073836161976769, 0.5554010598432451, 0.5994126399358114, 0.6277639695576259, 0.6409402290980021, 0.6568342645963033, 0.6603644007728213, 0.6611382308460417, 0.6689778537977309, 0.6748171888646626, 0.6747939458915165, 0.6832948256106604, 0.6841786560558137, 0.679104969615028, 0.6782016810916719, 0.686397712855112, 0.6754451947552818, 0.6816957820029486, 0.6817489536035628, 0.6804784593128023, 0.6919483556633904, 0.6804052520365942, 0.6634912050905681, 0.6780422017687843, 0.6767730599357968, 0.6815881047930036, 0.6838295601663136, 0.6899349462418329, 0.6836186760947818, 0.692844149612245, 0.6838401712122417, 0.6864755806468782, 0.6850076630001977, 0.6953631142775217, 0.6816476682821909, 0.6821003102120899, 0.678390505768004, 0.6813406263078962, 0.6947950224081675, 0.6945542366731734, 0.6803816670463199, 0.6786326652481443, 0.6886647059803918, 0.6828349630037943, 0.6830638888336363, 0.6855561080433074, 0.6790165503819784, 0.6844997831753322, 0.6874438254606157, 0.6783431995482672, 0.6895158418587276, 0.6827079568590436, 0.6784991636162713, 0.6880303493567875, 0.6868300764333635, 0.6847849488258362, 0.6846107783771697, 0.6829004713467189, 0.6869135044869923, 0.689153926713126, 0.6926794293380919, 0.6839932742572966, 0.6806246978896004, 0.690180051894415], 'loss': [14397.031576789228, 4361.840324725296, 3320.3929821594693, 2801.2206072343556, 2451.1758650401584, 2208.136560454333, 2040.667108321725, 1916.479351091266, 1815.4636405507229, 1727.413652491391, 1659.2728404665825, 1655.333029616206, 1554.7667909465229, 1509.4212300593122, 1463.7892980028566, 1427.0713848770408, 1393.5747952354222, 1359.643225957628, 1332.5594611798142, 1299.8849977792945, 1272.5418514337325, 1254.7399756224672, 1224.4503423067697, 1202.9184567268353, 1180.6878509902003, 1160.2038189514617, 1143.8093347715915, 1124.5252249663013, 1111.4033498978079, 1093.8849568164853, 1077.3888993869696, 1065.491323666085, 1047.9989471625806, 1033.5608435271683, 1020.6289086853179, 1005.9767021692899, 992.0871821377343, 980.2105231534811, 969.0306791081988, 957.7044848967669, 946.7751548748064, 937.6378527520006, 925.7952786300546, 914.3727520112682, 909.9089034120935, 898.4104379477941, 891.3700078835808, 881.2351758200629, 870.7648617180803, 861.9885610261761, 854.129342400225, 848.3637257335787, 838.0363522574788, 828.8950863693124, 820.4915257974753, 816.1762894323639, 811.4482380588751, 797.2658509708699, 794.7033785204043, 787.4492103976205, 782.6067616184454, 778.6087296787938, 771.1787803250357, 763.7096225995375, 758.1365096360965], 'acc': [0.856149759413001, 0.8943674093544335, 0.9114637716006757, 0.9215909286293008, 0.9279838812321499, 0.9325441648798096, 0.9358040253606223, 0.9384281172642387, 0.9404433437825142, 0.9421954784272912, 0.9437179479404281, 0.9439156406240867, 0.945920803674736, 0.9468372344896383, 0.9477588327559747, 0.9484283410923142, 0.9491744071728273, 0.9498331795569667, 0.9504335591769278, 0.9509231918619161, 0.9515415197261551, 0.9518643483296594, 0.9525005097252472, 0.9528106577750156, 0.9533635269562503, 0.9536416805778953, 0.953958684480993, 0.9543877486650486, 0.9546619480164569, 0.9550207661385846, 0.9553046466369284, 0.955502787284423, 0.9558102728013981, 0.956112814365777, 0.9563493610468886, 0.956673839108605, 0.9569032273053231, 0.9571989879680988, 0.9573481995751733, 0.9575625646144077, 0.9578106853730066, 0.9580142354950346, 0.9582154347823743, 0.9584219670503812, 0.9585097508871941, 0.9587370782644672, 0.9588351663843058, 0.9589489690049033, 0.9592216111849668, 0.959403720022437, 0.9594771513469201, 0.959517539773796, 0.9598212453381082, 0.9598795045863958, 0.9600982331389798, 0.9601788611297596, 0.9603293456341561, 0.9605559594278918, 0.96058252273578, 0.9607147790510161, 0.9608272384304061, 0.9609285453311226, 0.9610384152342851, 0.9611373454741112, 0.9612237050794901], 'mDice': [0.17987072958083744, 0.4280556104334067, 0.518090957092897, 0.5719308728106004, 0.6110309763553731, 0.640366954919406, 0.6616212157277098, 0.6782606774546261, 0.6919106816004339, 0.7041515802913473, 0.7137465465470145, 0.7146486707793507, 0.728770637341271, 0.7355140590496788, 0.7422534665116051, 0.7477269428329277, 0.7527704296489606, 0.757936142960986, 0.7620561562868723, 0.767031441788721, 0.7712744364417402, 0.774090988454676, 0.7787711012393161, 0.7821603930761987, 0.7857025111479652, 0.7889694179457025, 0.7915486608657456, 0.7946264383910303, 0.7967641243427769, 0.7996068228212675, 0.8022577963825176, 0.804148880044867, 0.8070156635934872, 0.8093951507436664, 0.8115160421020075, 0.813948017886452, 0.8162012841933386, 0.8181967941714344, 0.820050397790281, 0.8219260279451522, 0.8237423615488328, 0.825304289466871, 0.8272712345506782, 0.829221784845552, 0.8299757317451765, 0.8319368068491134, 0.8330685626947671, 0.8348075404131502, 0.8366135184530011, 0.8381379327348938, 0.839451939127689, 0.8404693025677579, 0.8421869423992914, 0.8437789635282205, 0.8452708571034476, 0.8460070718627916, 0.8468044395570149, 0.8492328286765519, 0.8497218276348495, 0.8509616142979584, 0.851809724236367, 0.8525302164683912, 0.8538098636819538, 0.8550723143237785, 0.8560390134999283]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:31:25, 17.70s/it]Loading train:   1%|          | 2/311 [00:26<1:18:00, 15.15s/it]Loading train:   1%|          | 3/311 [00:37<1:11:20, 13.90s/it]Loading train:   1%|▏         | 4/311 [00:48<1:06:08, 12.93s/it]Loading train:   2%|▏         | 5/311 [00:58<1:00:50, 11.93s/it]Loading train:   2%|▏         | 6/311 [01:08<57:43, 11.36s/it]  Loading train:   2%|▏         | 7/311 [01:19<57:35, 11.37s/it]Loading train:   3%|▎         | 8/311 [01:32<59:26, 11.77s/it]Loading train:   3%|▎         | 9/311 [01:44<59:51, 11.89s/it]Loading train:   3%|▎         | 10/311 [01:54<56:58, 11.36s/it]Loading train:   4%|▎         | 11/311 [02:08<59:57, 11.99s/it]Loading train:   4%|▍         | 12/311 [02:18<57:21, 11.51s/it]Loading train:   4%|▍         | 13/311 [02:28<55:13, 11.12s/it]Loading train:   5%|▍         | 14/311 [02:41<57:25, 11.60s/it]Loading train:   5%|▍         | 15/311 [02:51<54:28, 11.04s/it]Loading train:   5%|▌         | 16/311 [03:01<52:44, 10.73s/it]Loading train:   5%|▌         | 17/311 [03:10<51:22, 10.49s/it]Loading train:   6%|▌         | 18/311 [03:20<50:27, 10.33s/it]Loading train:   6%|▌         | 19/311 [03:30<49:28, 10.17s/it]Loading train:   6%|▋         | 20/311 [03:40<48:54, 10.08s/it]Loading train:   7%|▋         | 21/311 [03:50<48:26, 10.02s/it]Loading train:   7%|▋         | 22/311 [04:00<48:08,  9.99s/it]Loading train:   7%|▋         | 23/311 [04:10<48:43, 10.15s/it]Loading train:   8%|▊         | 24/311 [04:20<48:16, 10.09s/it]Loading train:   8%|▊         | 25/311 [04:30<47:48, 10.03s/it]Loading train:   8%|▊         | 26/311 [04:40<46:59,  9.89s/it]Loading train:   9%|▊         | 27/311 [04:50<46:49,  9.89s/it]Loading train:   9%|▉         | 28/311 [05:00<46:41,  9.90s/it]Loading train:   9%|▉         | 29/311 [05:10<46:41,  9.93s/it]Loading train:  10%|▉         | 30/311 [05:20<46:32,  9.94s/it]Loading train:  10%|▉         | 31/311 [05:29<46:14,  9.91s/it]Loading train:  10%|█         | 32/311 [05:39<45:37,  9.81s/it]Loading train:  11%|█         | 33/311 [05:44<38:46,  8.37s/it]Loading train:  11%|█         | 34/311 [05:49<34:09,  7.40s/it]Loading train:  11%|█▏        | 35/311 [05:54<30:51,  6.71s/it]Loading train:  12%|█▏        | 36/311 [05:59<28:23,  6.19s/it]Loading train:  12%|█▏        | 37/311 [06:04<26:38,  5.83s/it]Loading train:  12%|█▏        | 38/311 [06:09<25:28,  5.60s/it]Loading train:  13%|█▎        | 39/311 [06:14<24:45,  5.46s/it]Loading train:  13%|█▎        | 40/311 [06:19<23:40,  5.24s/it]Loading train:  13%|█▎        | 41/311 [06:24<22:51,  5.08s/it]Loading train:  14%|█▎        | 42/311 [06:29<22:11,  4.95s/it]Loading train:  14%|█▍        | 43/311 [06:33<21:48,  4.88s/it]Loading train:  14%|█▍        | 44/311 [06:38<21:31,  4.84s/it]Loading train:  14%|█▍        | 45/311 [06:43<21:33,  4.86s/it]Loading train:  15%|█▍        | 46/311 [06:48<21:27,  4.86s/it]Loading train:  15%|█▌        | 47/311 [06:53<21:11,  4.81s/it]Loading train:  15%|█▌        | 48/311 [06:57<21:00,  4.79s/it]Loading train:  16%|█▌        | 49/311 [07:02<20:58,  4.80s/it]Loading train:  16%|█▌        | 50/311 [07:07<20:47,  4.78s/it]Loading train:  16%|█▋        | 51/311 [07:13<22:08,  5.11s/it]Loading train:  17%|█▋        | 52/311 [07:18<22:58,  5.32s/it]Loading train:  17%|█▋        | 53/311 [07:25<23:51,  5.55s/it]Loading train:  17%|█▋        | 54/311 [07:30<23:58,  5.60s/it]Loading train:  18%|█▊        | 55/311 [07:36<24:10,  5.67s/it]Loading train:  18%|█▊        | 56/311 [07:42<24:24,  5.74s/it]Loading train:  18%|█▊        | 57/311 [07:48<24:32,  5.80s/it]Loading train:  19%|█▊        | 58/311 [07:54<24:29,  5.81s/it]Loading train:  19%|█▉        | 59/311 [08:00<24:49,  5.91s/it]Loading train:  19%|█▉        | 60/311 [08:06<24:40,  5.90s/it]Loading train:  20%|█▉        | 61/311 [08:12<24:32,  5.89s/it]Loading train:  20%|█▉        | 62/311 [08:17<24:18,  5.86s/it]Loading train:  20%|██        | 63/311 [08:23<24:21,  5.89s/it]Loading train:  21%|██        | 64/311 [08:29<24:12,  5.88s/it]Loading train:  21%|██        | 65/311 [08:35<24:16,  5.92s/it]Loading train:  21%|██        | 66/311 [08:41<24:02,  5.89s/it]Loading train:  22%|██▏       | 67/311 [08:47<23:37,  5.81s/it]Loading train:  22%|██▏       | 68/311 [08:52<23:20,  5.76s/it]Loading train:  22%|██▏       | 69/311 [08:58<23:20,  5.79s/it]Loading train:  23%|██▎       | 70/311 [09:04<23:01,  5.73s/it]Loading train:  23%|██▎       | 71/311 [09:09<22:46,  5.69s/it]Loading train:  23%|██▎       | 72/311 [09:15<22:35,  5.67s/it]Loading train:  23%|██▎       | 73/311 [09:21<22:25,  5.65s/it]Loading train:  24%|██▍       | 74/311 [09:26<22:09,  5.61s/it]Loading train:  24%|██▍       | 75/311 [09:32<22:00,  5.60s/it]Loading train:  24%|██▍       | 76/311 [09:37<21:58,  5.61s/it]Loading train:  25%|██▍       | 77/311 [09:43<22:04,  5.66s/it]Loading train:  25%|██▌       | 78/311 [09:49<21:43,  5.60s/it]Loading train:  25%|██▌       | 79/311 [09:54<21:40,  5.60s/it]Loading train:  26%|██▌       | 80/311 [10:00<21:29,  5.58s/it]Loading train:  26%|██▌       | 81/311 [10:05<21:25,  5.59s/it]Loading train:  26%|██▋       | 82/311 [10:11<21:25,  5.61s/it]Loading train:  27%|██▋       | 83/311 [10:17<21:15,  5.59s/it]Loading train:  27%|██▋       | 84/311 [10:22<21:24,  5.66s/it]Loading train:  27%|██▋       | 85/311 [10:28<20:49,  5.53s/it]Loading train:  28%|██▊       | 86/311 [10:33<20:17,  5.41s/it]Loading train:  28%|██▊       | 87/311 [10:38<19:59,  5.35s/it]Loading train:  28%|██▊       | 88/311 [10:43<19:31,  5.25s/it]Loading train:  29%|██▊       | 89/311 [10:48<19:28,  5.27s/it]Loading train:  29%|██▉       | 90/311 [10:53<19:16,  5.23s/it]Loading train:  29%|██▉       | 91/311 [10:59<19:00,  5.18s/it]Loading train:  30%|██▉       | 92/311 [11:04<18:44,  5.14s/it]Loading train:  30%|██▉       | 93/311 [11:09<18:38,  5.13s/it]Loading train:  30%|███       | 94/311 [11:14<18:41,  5.17s/it]Loading train:  31%|███       | 95/311 [11:19<18:31,  5.15s/it]Loading train:  31%|███       | 96/311 [11:24<18:27,  5.15s/it]Loading train:  31%|███       | 97/311 [11:30<18:34,  5.21s/it]Loading train:  32%|███▏      | 98/311 [11:35<18:42,  5.27s/it]Loading train:  32%|███▏      | 99/311 [11:40<18:38,  5.28s/it]Loading train:  32%|███▏      | 100/311 [11:46<18:33,  5.28s/it]Loading train:  32%|███▏      | 101/311 [11:51<18:30,  5.29s/it]Loading train:  33%|███▎      | 102/311 [11:56<18:39,  5.36s/it]Loading train:  33%|███▎      | 103/311 [12:02<18:52,  5.44s/it]Loading train:  33%|███▎      | 104/311 [12:08<18:53,  5.48s/it]Loading train:  34%|███▍      | 105/311 [12:13<18:46,  5.47s/it]Loading train:  34%|███▍      | 106/311 [12:19<18:44,  5.49s/it]Loading train:  34%|███▍      | 107/311 [12:24<18:38,  5.48s/it]Loading train:  35%|███▍      | 108/311 [12:29<18:18,  5.41s/it]Loading train:  35%|███▌      | 109/311 [12:35<18:10,  5.40s/it]Loading train:  35%|███▌      | 110/311 [12:40<18:07,  5.41s/it]Loading train:  36%|███▌      | 111/311 [12:46<18:07,  5.44s/it]Loading train:  36%|███▌      | 112/311 [12:51<17:59,  5.43s/it]Loading train:  36%|███▋      | 113/311 [12:56<17:58,  5.45s/it]Loading train:  37%|███▋      | 114/311 [13:06<22:11,  6.76s/it]Loading train:  37%|███▋      | 115/311 [13:16<24:43,  7.57s/it]Loading train:  37%|███▋      | 116/311 [13:25<26:36,  8.19s/it]Loading train:  38%|███▊      | 117/311 [13:35<27:52,  8.62s/it]Loading train:  38%|███▊      | 118/311 [13:45<28:48,  8.96s/it]Loading train:  38%|███▊      | 119/311 [13:54<29:06,  9.10s/it]Loading train:  39%|███▊      | 120/311 [14:04<29:25,  9.24s/it]Loading train:  39%|███▉      | 121/311 [14:13<29:42,  9.38s/it]Loading train:  39%|███▉      | 122/311 [14:23<29:49,  9.47s/it]Loading train:  40%|███▉      | 123/311 [14:33<29:44,  9.49s/it]Loading train:  40%|███▉      | 124/311 [14:42<29:38,  9.51s/it]Loading train:  40%|████      | 125/311 [14:52<29:34,  9.54s/it]Loading train:  41%|████      | 126/311 [15:01<29:29,  9.57s/it]Loading train:  41%|████      | 127/311 [15:11<29:22,  9.58s/it]Loading train:  41%|████      | 128/311 [15:21<29:12,  9.58s/it]Loading train:  41%|████▏     | 129/311 [15:30<29:07,  9.60s/it]Loading train:  42%|████▏     | 130/311 [15:40<29:21,  9.73s/it]Loading train:  42%|████▏     | 131/311 [15:51<29:43,  9.91s/it]Loading train:  42%|████▏     | 132/311 [15:56<25:24,  8.52s/it]Loading train:  43%|████▎     | 133/311 [16:01<22:10,  7.47s/it]Loading train:  43%|████▎     | 134/311 [16:06<19:51,  6.73s/it]Loading train:  43%|████▎     | 135/311 [16:11<18:22,  6.26s/it]Loading train:  44%|████▎     | 136/311 [16:16<17:23,  5.97s/it]Loading train:  44%|████▍     | 137/311 [16:22<16:35,  5.72s/it]Loading train:  44%|████▍     | 138/311 [16:27<16:09,  5.60s/it]Loading train:  45%|████▍     | 139/311 [16:32<15:47,  5.51s/it]Loading train:  45%|████▌     | 140/311 [16:37<15:28,  5.43s/it]Loading train:  45%|████▌     | 141/311 [16:43<15:06,  5.33s/it]Loading train:  46%|████▌     | 142/311 [16:48<14:46,  5.25s/it]Loading train:  46%|████▌     | 143/311 [16:53<14:54,  5.32s/it]Loading train:  46%|████▋     | 144/311 [16:58<14:38,  5.26s/it]Loading train:  47%|████▋     | 145/311 [17:04<14:41,  5.31s/it]Loading train:  47%|████▋     | 146/311 [17:09<14:30,  5.27s/it]Loading train:  47%|████▋     | 147/311 [17:14<14:22,  5.26s/it]Loading train:  48%|████▊     | 148/311 [17:19<14:02,  5.17s/it]Loading train:  48%|████▊     | 149/311 [17:24<13:57,  5.17s/it]Loading train:  48%|████▊     | 150/311 [17:30<14:46,  5.51s/it]Loading train:  49%|████▊     | 151/311 [17:37<15:31,  5.82s/it]Loading train:  49%|████▉     | 152/311 [17:43<15:43,  5.93s/it]Loading train:  49%|████▉     | 153/311 [17:49<15:46,  5.99s/it]Loading train:  50%|████▉     | 154/311 [17:56<15:52,  6.06s/it]Loading train:  50%|████▉     | 155/311 [18:02<16:07,  6.20s/it]Loading train:  50%|█████     | 156/311 [18:08<16:01,  6.20s/it]Loading train:  50%|█████     | 157/311 [18:15<15:56,  6.21s/it]Loading train:  51%|█████     | 158/311 [18:21<15:55,  6.24s/it]Loading train:  51%|█████     | 159/311 [18:27<15:55,  6.28s/it]Loading train:  51%|█████▏    | 160/311 [18:34<15:58,  6.34s/it]Loading train:  52%|█████▏    | 161/311 [18:40<15:37,  6.25s/it]Loading train:  52%|█████▏    | 162/311 [18:46<15:20,  6.18s/it]Loading train:  52%|█████▏    | 163/311 [18:52<15:17,  6.20s/it]Loading train:  53%|█████▎    | 164/311 [18:58<15:17,  6.24s/it]Loading train:  53%|█████▎    | 165/311 [19:05<15:17,  6.29s/it]Loading train:  53%|█████▎    | 166/311 [19:11<15:12,  6.29s/it]Loading train:  54%|█████▎    | 167/311 [19:17<14:55,  6.22s/it]Loading train:  54%|█████▍    | 168/311 [19:23<14:35,  6.12s/it]Loading train:  54%|█████▍    | 169/311 [19:29<14:26,  6.10s/it]Loading train:  55%|█████▍    | 170/311 [19:35<14:24,  6.13s/it]Loading train:  55%|█████▍    | 171/311 [19:41<14:10,  6.08s/it]Loading train:  55%|█████▌    | 172/311 [19:47<14:05,  6.09s/it]Loading train:  56%|█████▌    | 173/311 [19:53<14:03,  6.11s/it]Loading train:  56%|█████▌    | 174/311 [19:59<13:52,  6.07s/it]Loading train:  56%|█████▋    | 175/311 [20:05<13:41,  6.04s/it]Loading train:  57%|█████▋    | 176/311 [20:11<13:36,  6.05s/it]Loading train:  57%|█████▋    | 177/311 [20:17<13:27,  6.03s/it]Loading train:  57%|█████▋    | 178/311 [20:23<13:15,  5.98s/it]Loading train:  58%|█████▊    | 179/311 [20:29<13:04,  5.95s/it]Loading train:  58%|█████▊    | 180/311 [20:35<12:47,  5.86s/it]Loading train:  58%|█████▊    | 181/311 [20:41<12:45,  5.89s/it]Loading train:  59%|█████▊    | 182/311 [20:46<12:29,  5.81s/it]Loading train:  59%|█████▉    | 183/311 [20:53<12:37,  5.91s/it]Loading train:  59%|█████▉    | 184/311 [20:58<12:24,  5.86s/it]Loading train:  59%|█████▉    | 185/311 [21:04<11:54,  5.67s/it]Loading train:  60%|█████▉    | 186/311 [21:09<11:34,  5.55s/it]Loading train:  60%|██████    | 187/311 [21:14<11:16,  5.45s/it]Loading train:  60%|██████    | 188/311 [21:19<10:54,  5.32s/it]Loading train:  61%|██████    | 189/311 [21:24<10:29,  5.16s/it]Loading train:  61%|██████    | 190/311 [21:29<10:21,  5.14s/it]Loading train:  61%|██████▏   | 191/311 [21:34<10:15,  5.13s/it]Loading train:  62%|██████▏   | 192/311 [21:39<10:02,  5.06s/it]Loading train:  62%|██████▏   | 193/311 [21:44<09:51,  5.01s/it]Loading train:  62%|██████▏   | 194/311 [21:49<09:52,  5.06s/it]Loading train:  63%|██████▎   | 195/311 [21:54<09:46,  5.06s/it]Loading train:  63%|██████▎   | 196/311 [21:59<09:42,  5.07s/it]Loading train:  63%|██████▎   | 197/311 [22:04<09:39,  5.08s/it]Loading train:  64%|██████▎   | 198/311 [22:09<09:38,  5.12s/it]Loading train:  64%|██████▍   | 199/311 [22:14<09:29,  5.08s/it]Loading train:  64%|██████▍   | 200/311 [22:20<09:24,  5.08s/it]Loading train:  65%|██████▍   | 201/311 [22:25<09:24,  5.13s/it]Loading train:  65%|██████▍   | 202/311 [22:30<09:08,  5.03s/it]Loading train:  65%|██████▌   | 203/311 [22:35<09:09,  5.09s/it]Loading train:  66%|██████▌   | 204/311 [22:40<09:10,  5.15s/it]Loading train:  66%|██████▌   | 205/311 [22:45<09:05,  5.14s/it]Loading train:  66%|██████▌   | 206/311 [22:50<08:58,  5.13s/it]Loading train:  67%|██████▋   | 207/311 [22:55<08:53,  5.13s/it]Loading train:  67%|██████▋   | 208/311 [23:01<08:48,  5.13s/it]Loading train:  67%|██████▋   | 209/311 [23:06<08:40,  5.10s/it]Loading train:  68%|██████▊   | 210/311 [23:11<08:29,  5.05s/it]Loading train:  68%|██████▊   | 211/311 [23:15<08:20,  5.00s/it]Loading train:  68%|██████▊   | 212/311 [23:20<08:14,  4.99s/it]Loading train:  68%|██████▊   | 213/311 [23:29<10:03,  6.16s/it]Loading train:  69%|██████▉   | 214/311 [23:39<11:31,  7.13s/it]Loading train:  69%|██████▉   | 215/311 [23:48<12:24,  7.75s/it]Loading train:  69%|██████▉   | 216/311 [23:57<13:07,  8.29s/it]Loading train:  70%|██████▉   | 217/311 [24:07<13:26,  8.58s/it]Loading train:  70%|███████   | 218/311 [24:16<13:36,  8.78s/it]Loading train:  70%|███████   | 219/311 [24:25<13:45,  8.98s/it]Loading train:  71%|███████   | 220/311 [24:34<13:36,  8.97s/it]Loading train:  71%|███████   | 221/311 [24:44<13:36,  9.08s/it]Loading train:  71%|███████▏  | 222/311 [24:53<13:25,  9.05s/it]Loading train:  72%|███████▏  | 223/311 [25:02<13:22,  9.12s/it]Loading train:  72%|███████▏  | 224/311 [25:11<13:17,  9.16s/it]Loading train:  72%|███████▏  | 225/311 [25:20<13:07,  9.16s/it]Loading train:  73%|███████▎  | 226/311 [25:30<13:05,  9.24s/it]Loading train:  73%|███████▎  | 227/311 [25:39<12:58,  9.27s/it]Loading train:  73%|███████▎  | 228/311 [25:48<12:48,  9.25s/it]Loading train:  74%|███████▎  | 229/311 [25:58<12:49,  9.39s/it]Loading train:  74%|███████▍  | 230/311 [26:07<12:42,  9.41s/it]Loading train:  74%|███████▍  | 231/311 [26:12<10:39,  8.00s/it]Loading train:  75%|███████▍  | 232/311 [26:17<09:12,  7.00s/it]Loading train:  75%|███████▍  | 233/311 [26:22<08:16,  6.37s/it]Loading train:  75%|███████▌  | 234/311 [26:26<07:25,  5.79s/it]Loading train:  76%|███████▌  | 235/311 [26:31<06:53,  5.43s/it]Loading train:  76%|███████▌  | 236/311 [26:36<06:34,  5.26s/it]Loading train:  76%|███████▌  | 237/311 [26:40<06:12,  5.03s/it]Loading train:  77%|███████▋  | 238/311 [26:45<05:56,  4.88s/it]Loading train:  77%|███████▋  | 239/311 [26:49<05:45,  4.80s/it]Loading train:  77%|███████▋  | 240/311 [26:54<05:37,  4.75s/it]Loading train:  77%|███████▋  | 241/311 [26:59<05:29,  4.70s/it]Loading train:  78%|███████▊  | 242/311 [27:03<05:22,  4.68s/it]Loading train:  78%|███████▊  | 243/311 [27:08<05:20,  4.71s/it]Loading train:  78%|███████▊  | 244/311 [27:12<05:11,  4.65s/it]Loading train:  79%|███████▉  | 245/311 [27:17<05:07,  4.66s/it]Loading train:  79%|███████▉  | 246/311 [27:22<05:04,  4.69s/it]Loading train:  79%|███████▉  | 247/311 [27:27<05:03,  4.74s/it]Loading train:  80%|███████▉  | 248/311 [27:31<04:53,  4.66s/it]Loading train:  80%|████████  | 249/311 [27:37<05:05,  4.93s/it]Loading train:  80%|████████  | 250/311 [27:42<05:09,  5.07s/it]Loading train:  81%|████████  | 251/311 [27:48<05:15,  5.25s/it]Loading train:  81%|████████  | 252/311 [27:54<05:17,  5.39s/it]Loading train:  81%|████████▏ | 253/311 [27:59<05:16,  5.46s/it]Loading train:  82%|████████▏ | 254/311 [28:05<05:15,  5.54s/it]Loading train:  82%|████████▏ | 255/311 [28:11<05:13,  5.60s/it]Loading train:  82%|████████▏ | 256/311 [28:16<05:07,  5.58s/it]Loading train:  83%|████████▎ | 257/311 [28:22<04:59,  5.54s/it]Loading train:  83%|████████▎ | 258/311 [28:27<04:55,  5.57s/it]Loading train:  83%|████████▎ | 259/311 [28:33<04:51,  5.60s/it]Loading train:  84%|████████▎ | 260/311 [28:39<04:51,  5.71s/it]Loading train:  84%|████████▍ | 261/311 [28:45<04:46,  5.73s/it]Loading train:  84%|████████▍ | 262/311 [28:50<04:41,  5.74s/it]Loading train:  85%|████████▍ | 263/311 [28:57<04:40,  5.85s/it]Loading train:  85%|████████▍ | 264/311 [29:02<04:28,  5.72s/it]Loading train:  85%|████████▌ | 265/311 [29:08<04:21,  5.67s/it]Loading train:  86%|████████▌ | 266/311 [29:13<04:15,  5.68s/it]Loading train:  86%|████████▌ | 267/311 [29:19<04:09,  5.67s/it]Loading train:  86%|████████▌ | 268/311 [29:24<04:02,  5.65s/it]Loading train:  86%|████████▋ | 269/311 [29:30<03:58,  5.68s/it]Loading train:  87%|████████▋ | 270/311 [29:36<03:52,  5.67s/it]Loading train:  87%|████████▋ | 271/311 [29:41<03:44,  5.61s/it]Loading train:  87%|████████▋ | 272/311 [29:47<03:39,  5.63s/it]Loading train:  88%|████████▊ | 273/311 [29:52<03:31,  5.56s/it]Loading train:  88%|████████▊ | 274/311 [29:58<03:25,  5.56s/it]Loading train:  88%|████████▊ | 275/311 [30:04<03:22,  5.62s/it]Loading train:  89%|████████▊ | 276/311 [30:09<03:16,  5.61s/it]Loading train:  89%|████████▉ | 277/311 [30:15<03:09,  5.58s/it]Loading train:  89%|████████▉ | 278/311 [30:21<03:05,  5.61s/it]Loading train:  90%|████████▉ | 279/311 [30:26<03:01,  5.67s/it]Loading train:  90%|█████████ | 280/311 [30:32<02:54,  5.64s/it]Loading train:  90%|█████████ | 281/311 [30:38<02:52,  5.74s/it]Loading train:  91%|█████████ | 282/311 [30:43<02:45,  5.70s/it]Loading train:  91%|█████████ | 283/311 [30:48<02:32,  5.45s/it]Loading train:  91%|█████████▏| 284/311 [30:53<02:23,  5.30s/it]Loading train:  92%|█████████▏| 285/311 [30:58<02:14,  5.18s/it]Loading train:  92%|█████████▏| 286/311 [31:03<02:07,  5.11s/it]Loading train:  92%|█████████▏| 287/311 [31:08<02:03,  5.14s/it]Loading train:  93%|█████████▎| 288/311 [31:14<01:58,  5.16s/it]Loading train:  93%|█████████▎| 289/311 [31:19<01:53,  5.16s/it]Loading train:  93%|█████████▎| 290/311 [31:24<01:49,  5.24s/it]Loading train:  94%|█████████▎| 291/311 [31:29<01:44,  5.24s/it]Loading train:  94%|█████████▍| 292/311 [31:34<01:38,  5.18s/it]Loading train:  94%|█████████▍| 293/311 [31:40<01:34,  5.24s/it]Loading train:  95%|█████████▍| 294/311 [31:45<01:29,  5.26s/it]Loading train:  95%|█████████▍| 295/311 [31:50<01:23,  5.20s/it]Loading train:  95%|█████████▌| 296/311 [31:55<01:18,  5.22s/it]Loading train:  95%|█████████▌| 297/311 [32:01<01:13,  5.22s/it]Loading train:  96%|█████████▌| 298/311 [32:05<01:06,  5.10s/it]Loading train:  96%|█████████▌| 299/311 [32:11<01:02,  5.18s/it]Loading train:  96%|█████████▋| 300/311 [32:16<00:58,  5.29s/it]Loading train:  97%|█████████▋| 301/311 [32:22<00:52,  5.27s/it]Loading train:  97%|█████████▋| 302/311 [32:27<00:46,  5.21s/it]Loading train:  97%|█████████▋| 303/311 [32:32<00:41,  5.24s/it]Loading train:  98%|█████████▊| 304/311 [32:37<00:36,  5.19s/it]Loading train:  98%|█████████▊| 305/311 [32:42<00:30,  5.15s/it]Loading train:  98%|█████████▊| 306/311 [32:47<00:25,  5.19s/it]Loading train:  99%|█████████▊| 307/311 [32:52<00:20,  5.14s/it]Loading train:  99%|█████████▉| 308/311 [32:57<00:15,  5.09s/it]Loading train:  99%|█████████▉| 309/311 [33:03<00:10,  5.17s/it]Loading train: 100%|█████████▉| 310/311 [33:08<00:05,  5.20s/it]Loading train: 100%|██████████| 311/311 [33:13<00:00,  5.18s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 25/311 [00:00<00:01, 246.79it/s]concatenating: train:  16%|█▋        | 51/311 [00:00<00:01, 247.86it/s]concatenating: train:  25%|██▌       | 78/311 [00:00<00:00, 253.40it/s]concatenating: train:  34%|███▍      | 105/311 [00:00<00:00, 256.21it/s]concatenating: train:  43%|████▎     | 133/311 [00:00<00:00, 261.77it/s]concatenating: train:  51%|█████▏    | 160/311 [00:00<00:00, 264.12it/s]concatenating: train:  60%|██████    | 187/311 [00:00<00:00, 264.14it/s]concatenating: train:  69%|██████▉   | 214/311 [00:00<00:00, 265.76it/s]concatenating: train:  77%|███████▋  | 241/311 [00:00<00:00, 264.01it/s]concatenating: train:  86%|████████▋ | 269/311 [00:01<00:00, 266.88it/s]concatenating: train:  96%|█████████▌| 298/311 [00:01<00:00, 272.06it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 264.22it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 11.68s/it]Loading test:  50%|█████     | 2/4 [00:22<00:23, 11.56s/it]Loading test:  75%|███████▌  | 3/4 [00:34<00:11, 11.70s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.59s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 117.25it/s]
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25350       dropout_4[0][0]                  2019-07-08 05:54:02.927704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 05:54:02.927784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 05:54:02.927798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 05:54:02.927807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 05:54:02.928205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [5.88176395e-02 2.85713643e-02 1.22080201e-01 1.04952659e-02
 3.15779544e-02 5.46270752e-03 7.23535399e-02 1.13294426e-01
 7.88079565e-02 1.27907394e-02 2.93002722e-01 1.72516551e-01
 2.28932584e-04]
Train on 20529 samples, validate on 262 samples
Epoch 1/300
 - 26s - loss: 9928.7074 - acc: 0.8833 - mDice: 0.2724 - val_loss: 3954.5570 - val_acc: 0.9053 - val_mDice: 0.4339

Epoch 00001: val_mDice improved from -inf to 0.43387, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 3411.7622 - acc: 0.9179 - mDice: 0.5124 - val_loss: 2751.2267 - val_acc: 0.9272 - val_mDice: 0.5496

Epoch 00002: val_mDice improved from 0.43387 to 0.54956, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 2582.1136 - acc: 0.9308 - mDice: 0.5991 - val_loss: 2222.1359 - val_acc: 0.9373 - val_mDice: 0.6144

Epoch 00003: val_mDice improved from 0.54956 to 0.61441, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 18s - loss: 2174.2063 - acc: 0.9375 - mDice: 0.6466 - val_loss: 1946.2158 - val_acc: 0.9437 - val_mDice: 0.6533

Epoch 00004: val_mDice improved from 0.61441 to 0.65328, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 1949.4828 - acc: 0.9414 - mDice: 0.6753 - val_loss: 2025.5022 - val_acc: 0.9418 - val_mDice: 0.6436

Epoch 00005: val_mDice did not improve from 0.65328
Epoch 6/300
 - 18s - loss: 1792.8023 - acc: 0.9442 - mDice: 0.6962 - val_loss: 1703.2612 - val_acc: 0.9508 - val_mDice: 0.6887

Epoch 00006: val_mDice improved from 0.65328 to 0.68867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 18s - loss: 1673.7220 - acc: 0.9463 - mDice: 0.7127 - val_loss: 1718.2847 - val_acc: 0.9493 - val_mDice: 0.6849

Epoch 00007: val_mDice did not improve from 0.68867
Epoch 8/300
 - 18s - loss: 1585.8116 - acc: 0.9479 - mDice: 0.7249 - val_loss: 1673.3347 - val_acc: 0.9515 - val_mDice: 0.6927

Epoch 00008: val_mDice improved from 0.68867 to 0.69272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 1515.1235 - acc: 0.9494 - mDice: 0.7355 - val_loss: 1630.6882 - val_acc: 0.9521 - val_mDice: 0.6977

Epoch 00009: val_mDice improved from 0.69272 to 0.69768, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 1454.0731 - acc: 0.9505 - mDice: 0.7443 - val_loss: 1603.5006 - val_acc: 0.9547 - val_mDice: 0.7023

Epoch 00010: val_mDice improved from 0.69768 to 0.70231, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 19s - loss: 1404.9069 - acc: 0.9514 - mDice: 0.7515 - val_loss: 1567.0442 - val_acc: 0.9556 - val_mDice: 0.7068

Epoch 00011: val_mDice improved from 0.70231 to 0.70677, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 1351.8975 - acc: 0.9524 - mDice: 0.7596 - val_loss: 1714.1896 - val_acc: 0.9552 - val_mDice: 0.6891

Epoch 00012: val_mDice did not improve from 0.70677
Epoch 13/300
 - 18s - loss: 1313.5907 - acc: 0.9533 - mDice: 0.7654 - val_loss: 1617.5972 - val_acc: 0.9544 - val_mDice: 0.6992

Epoch 00013: val_mDice did not improve from 0.70677
Epoch 14/300
 - 19s - loss: 1276.7391 - acc: 0.9539 - mDice: 0.7710 - val_loss: 1524.8979 - val_acc: 0.9577 - val_mDice: 0.7139

Epoch 00014: val_mDice improved from 0.70677 to 0.71389, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 18s - loss: 1255.5959 - acc: 0.9546 - mDice: 0.7744 - val_loss: 1555.3054 - val_acc: 0.9564 - val_mDice: 0.7093

Epoch 00015: val_mDice did not improve from 0.71389
Epoch 16/300
 - 18s - loss: 1214.1630 - acc: 0.9552 - mDice: 0.7808 - val_loss: 1619.9969 - val_acc: 0.9573 - val_mDice: 0.7012

Epoch 00016: val_mDice did not improve from 0.71389
Epoch 17/300
 - 18s - loss: 1187.6885 - acc: 0.9558 - mDice: 0.7850 - val_loss: 1565.2740 - val_acc: 0.9576 - val_mDice: 0.7085

Epoch 00017: val_mDice did not improve from 0.71389
Epoch 18/300
 - 18s - loss: 1165.0016 - acc: 0.9562 - mDice: 0.7886 - val_loss: 1548.8884 - val_acc: 0.9591 - val_mDice: 0.7106

Epoch 00018: val_mDice did not improve from 0.71389
Epoch 19/300
 - 19s - loss: 1146.4364 - acc: 0.9567 - mDice: 0.7920 - val_loss: 1563.7938 - val_acc: 0.9593 - val_mDice: 0.7100

Epoch 00019: val_mDice did not improve from 0.71389
Epoch 20/300
 - 18s - loss: 1125.7242 - acc: 0.9571 - mDice: 0.7949 - val_loss: 1594.9192 - val_acc: 0.9563 - val_mDice: 0.7022

Epoch 00020: val_mDice did not improve from 0.71389
Epoch 21/300
 - 18s - loss: 1100.5999 - acc: 0.9575 - mDice: 0.7989 - val_loss: 1556.0493 - val_acc: 0.9580 - val_mDice: 0.7093

Epoch 00021: val_mDice did not improve from 0.71389
Epoch 22/300
 - 19s - loss: 1077.1320 - acc: 0.9580 - mDice: 0.8027 - val_loss: 1560.9761 - val_acc: 0.9587 - val_mDice: 0.7096

Epoch 00022: val_mDice did not improve from 0.71389
Epoch 23/300
 - 18s - loss: 1058.3506 - acc: 0.9583 - mDice: 0.8057 - val_loss: 1634.9488 - val_acc: 0.9596 - val_mDice: 0.6997

Epoch 00023: val_mDice did not improve from 0.71389
Epoch 24/300
 - 19s - loss: 1046.9609 - acc: 0.9586 - mDice: 0.8075 - val_loss: 1541.3159 - val_acc: 0.9600 - val_mDice: 0.7123

Epoch 00024: val_mDice did not improve from 0.71389
Epoch 25/300
 - 18s - loss: 1026.3550 - acc: 0.9590 - mDice: 0.8110 - val_loss: 1570.7944 - val_acc: 0.9594 - val_mDice: 0.7082

Epoch 00025: val_mDice did not improve from 0.71389
Epoch 26/300
 - 18s - loss: 1055.8287 - acc: 0.9591 - mDice: 0.8108 - val_loss: 1532.1337 - val_acc: 0.9589 - val_mDice: 0.7125

Epoch 00026: val_mDice did not improve from 0.71389
Epoch 27/300
 - 19s - loss: 997.0031 - acc: 0.9595 - mDice: 0.8157 - val_loss: 1671.5428 - val_acc: 0.9566 - val_mDice: 0.6930

Epoch 00027: val_mDice did not improve from 0.71389
Epoch 28/300
 - 18s - loss: 980.9451 - acc: 0.9598 - mDice: 0.8184 - val_loss: 1644.4820 - val_acc: 0.9561 - val_mDice: 0.6955

Epoch 00028: val_mDice did not improve from 0.71389
Epoch 29/300
 - 19s - loss: 970.6226 - acc: 0.9600 - mDice: 0.8201 - val_loss: 1564.1520 - val_acc: 0.9594 - val_mDice: 0.7090

Epoch 00029: val_mDice did not improve from 0.71389
Epoch 30/300
 - 18s - loss: 952.4481 - acc: 0.9603 - mDice: 0.8231 - val_loss: 1533.6617 - val_acc: 0.9588 - val_mDice: 0.7135

Epoch 00030: val_mDice did not improve from 0.71389
Epoch 31/300
 - 18s - loss: 937.6692 - acc: 0.9606 - mDice: 0.8256 - val_loss: 1602.6031 - val_acc: 0.9594 - val_mDice: 0.7049

Epoch 00031: val_mDice did not improve from 0.71389
Epoch 32/300
 - 18s - loss: 923.3928 - acc: 0.9608 - mDice: 0.8280 - val_loss: 1627.4218 - val_acc: 0.9580 - val_mDice: 0.7012

Epoch 00032: val_mDice did not improve from 0.71389
Epoch 33/300
 - 18s - loss: 918.0782 - acc: 0.9610 - mDice: 0.8289 - val_loss: 1600.1401 - val_acc: 0.9610 - val_mDice: 0.7033

Epoch 00033: val_mDice did not improve from 0.71389
Epoch 34/300
 - 19s - loss: 899.6357 - acc: 0.9613 - mDice: 0.8320 - val_loss: 1576.9789 - val_acc: 0.9604 - val_mDice: 0.7081

Epoch 00034: val_mDice did not improve from 0.71389
Epoch 35/300
 - 18s - loss: 892.9655 - acc: 0.9614 - mDice: 0.8331 - val_loss: 1675.3384 - val_acc: 0.9596 - val_mDice: 0.6943

Epoch 00035: val_mDice did not improve from 0.71389
Epoch 36/300
 - 18s - loss: 881.2173 - acc: 0.9616 - mDice: 0.8350 - val_loss: 1661.4382 - val_acc: 0.9585 - val_mDice: 0.6951

Epoch 00036: val_mDice did not improve from 0.71389
Epoch 37/300
 - 18s - loss: 872.6188 - acc: 0.9617 - mDice: 0.8365 - val_loss: 1591.5335 - val_acc: 0.9602 - val_mDice: 0.7060

Epoch 00037: val_mDice did not improve from 0.71389
Epoch 38/300
 - 18s - loss: 858.2561 - acc: 0.9620 - mDice: 0.8390 - val_loss: 1571.9171 - val_acc: 0.9614 - val_mDice: 0.7082

Epoch 00038: val_mDice did not improve from 0.71389
Epoch 39/300
 - 18s - loss: 853.2497 - acc: 0.9622 - mDice: 0.8400 - val_loss: 2308.9125 - val_acc: 0.9364 - val_mDice: 0.6229

Epoch 00039: val_mDice did not improve from 0.71389
Epoch 40/300
 - 18s - loss: 903.6584 - acc: 0.9615 - mDice: 0.8314 - val_loss: 1608.6430 - val_acc: 0.9605 - val_mDice: 0.7034

Epoch 00040: val_mDice did not improve from 0.71389
Epoch 41/300
 - 19s - loss: 846.9292 - acc: 0.9624 - mDice: 0.8408 - val_loss: 1656.1765 - val_acc: 0.9604 - val_mDice: 0.6971

Epoch 00041: val_mDice did not improve from 0.71389
Epoch 42/300
 - 18s - loss: 836.9259 - acc: 0.9625 - mDice: 0.8427 - val_loss: 1651.6237 - val_acc: 0.9613 - val_mDice: 0.6987

Epoch 00042: val_mDice did not improve from 0.71389
Epoch 43/300
 - 19s - loss: 820.0777 - acc: 0.9627 - mDice: 0.8455 - val_loss: 1623.0660 - val_acc: 0.9595 - val_mDice: 0.7014

Epoch 00043: val_mDice did not improve from 0.71389
Epoch 44/300
 - 18s - loss: 810.5503 - acc: 0.9629 - mDice: 0.8472 - val_loss: 1522.1406 - val_acc: 0.9606 - val_mDice: 0.7156

Epoch 00044: val_mDice improved from 0.71389 to 0.71558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 18s - loss: 802.2093 - acc: 0.9631 - mDice: 0.8486 - val_loss: 1637.2885 - val_acc: 0.9599 - val_mDice: 0.6997

Epoch 00045: val_mDice did not improve from 0.71558
Epoch 46/300
 - 19s - loss: 797.9482 - acc: 0.9631 - mDice: 0.8494 - val_loss: 1519.9840 - val_acc: 0.9613 - val_mDice: 0.7166

Epoch 00046: val_mDice improved from 0.71558 to 0.71657, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 18s - loss: 792.6073 - acc: 0.9633 - mDice: 0.8503 - val_loss: 1684.9137 - val_acc: 0.9596 - val_mDice: 0.6934

Epoch 00047: val_mDice did not improve from 0.71657
Epoch 48/300
 - 18s - loss: 782.8306 - acc: 0.9633 - mDice: 0.8519 - val_loss: 1583.5306 - val_acc: 0.9608 - val_mDice: 0.7076

Epoch 00048: val_mDice did not improve from 0.71657
Epoch 49/300
 - 18s - loss: 774.9195 - acc: 0.9634 - mDice: 0.8533 - val_loss: 1766.7995 - val_acc: 0.9590 - val_mDice: 0.6822

Epoch 00049: val_mDice did not improve from 0.71657
Epoch 50/300
 - 18s - loss: 771.4478 - acc: 0.9636 - mDice: 0.8539 - val_loss: 1787.7521 - val_acc: 0.9586 - val_mDice: 0.6804

Epoch 00050: val_mDice did not improve from 0.71657
Epoch 51/300
 - 19s - loss: 761.9410 - acc: 0.9637 - mDice: 0.8556 - val_loss: 1601.4100 - val_acc: 0.9614 - val_mDice: 0.7050

Epoch 00051: val_mDice did not improve from 0.71657
Epoch 52/300
 - 18s - loss: 757.9551 - acc: 0.9637 - mDice: 0.8563 - val_loss: 1589.8282 - val_acc: 0.9596 - val_mDice: 0.7051

Epoch 00052: val_mDice did not improve from 0.71657
Epoch 53/300
 - 18s - loss: 752.6867 - acc: 0.9639 - mDice: 0.8572 - val_loss: 1706.6156 - val_acc: 0.9580 - val_mDice: 0.6898

Epoch 00053: val_mDice did not improve from 0.71657
Epoch 54/300
 - 18s - loss: 745.2509 - acc: 0.9640 - mDice: 0.8585 - val_loss: 1615.6176 - val_acc: 0.9597 - val_mDice: 0.7024

Epoch 00054: val_mDice did not improve from 0.71657
Epoch 55/300
 - 18s - loss: 735.1141 - acc: 0.9640 - mDice: 0.8603 - val_loss: 1550.5663 - val_acc: 0.9613 - val_mDice: 0.7117

Epoch 00055: val_mDice did not improve from 0.71657
Epoch 56/300
 - 19s - loss: 735.4690 - acc: 0.9641 - mDice: 0.8602 - val_loss: 1696.8158 - val_acc: 0.9565 - val_mDice: 0.6896

Epoch 00056: val_mDice did not improve from 0.71657
Epoch 57/300
 - 18s - loss: 726.5668 - acc: 0.9642 - mDice: 0.8618 - val_loss: 1610.1474 - val_acc: 0.9600 - val_mDice: 0.7056

Epoch 00057: val_mDice did not improve from 0.71657
Epoch 58/300
 - 18s - loss: 721.6321 - acc: 0.9643 - mDice: 0.8627 - val_loss: 1614.3068 - val_acc: 0.9605 - val_mDice: 0.7033

Epoch 00058: val_mDice did not improve from 0.71657
Epoch 59/300
 - 18s - loss: 718.9832 - acc: 0.9644 - mDice: 0.8631 - val_loss: 1892.6443 - val_acc: 0.9523 - val_mDice: 0.6618

Epoch 00059: val_mDice did not improve from 0.71657
Epoch 60/300
 - 18s - loss: 714.6547 - acc: 0.9644 - mDice: 0.8643 - val_loss: 1698.0169 - val_acc: 0.9593 - val_mDice: 0.6904

Epoch 00060: val_mDice did not improve from 0.71657
Epoch 61/300
 - 19s - loss: 709.7986 - acc: 0.9645 - mDice: 0.8647 - val_loss: 1674.8366 - val_acc: 0.9607 - val_mDice: 0.6949

Epoch 00061: val_mDice did not improve from 0.71657
Epoch 62/300
 - 18s - loss: 704.5382 - acc: 0.9646 - mDice: 0.8657 - val_loss: 1586.8234 - val_acc: 0.9614 - val_mDice: 0.7090

Epoch 00062: val_mDice did not improve from 0.71657
Epoch 63/300
 - 19s - loss: 695.4287 - acc: 0.9647 - mDice: 0.8672 - val_loss: 1534.3651 - val_acc: 0.9614 - val_mDice: 0.7151

Epoch 00063: val_mDice did not improve from 0.71657
Epoch 64/300
 - 18s - loss: 693.2418 - acc: 0.9648 - mDice: 0.8677 - val_loss: 1679.2421 - val_acc: 0.9590 - val_mDice: 0.6947

Epoch 00064: val_mDice did not improve from 0.71657
Epoch 65/300
 - 18s - loss: 686.6563 - acc: 0.9648 - mDice: 0.8688 - val_loss: 1785.3814 - val_acc: 0.9586 - val_mDice: 0.6793

Epoch 00065: val_mDice did not improve from 0.71657
Epoch 66/300
 - 19s - loss: 686.2845 - acc: 0.9649 - mDice: 0.8689 - val_loss: 1636.3002 - val_acc: 0.9606 - val_mDice: 0.7026

Epoch 00066: val_mDice did not improve from 0.71657
Epoch 67/300
 - 18s - loss: 679.4327 - acc: 0.9650 - mDice: 0.8701 - val_loss: 1821.4707 - val_acc: 0.9599 - val_mDice: 0.6771

Epoch 00067: val_mDice did not improve from 0.71657
Epoch 68/300
 - 18s - loss: 680.2805 - acc: 0.9650 - mDice: 0.8700 - val_loss: 1550.4440 - val_acc: 0.9610 - val_mDice: 0.7125

Epoch 00068: val_mDice did not improve from 0.71657
Epoch 69/300
 - 19s - loss: 672.3555 - acc: 0.9650 - mDice: 0.8713 - val_loss: 1662.2766 - val_acc: 0.9599 - val_mDice: 0.6964

Epoch 00069: val_mDice did not improve from 0.71657
Epoch 70/300
 - 18s - loss: 666.2006 - acc: 0.9651 - mDice: 0.8724 - val_loss: 1625.4456 - val_acc: 0.9602 - val_mDice: 0.7029

Epoch 00070: val_mDice did not improve from 0.71657
Epoch 71/300
 - 19s - loss: 662.9443 - acc: 0.9652 - mDice: 0.8730 - val_loss: 1556.0875 - val_acc: 0.9614 - val_mDice: 0.7125

Epoch 00071: val_mDice did not improve from 0.71657
Epoch 72/300
 - 18s - loss: 661.6364 - acc: 0.9653 - mDice: 0.8733 - val_loss: 1669.0219 - val_acc: 0.9601 - val_mDice: 0.6950

Epoch 00072: val_mDice did not improve from 0.71657
Epoch 73/300
 - 18s - loss: 660.3162 - acc: 0.9653 - mDice: 0.8736 - val_loss: 1698.8187 - val_acc: 0.9597 - val_mDice: 0.6918

Epoch 00073: val_mDice did not improve from 0.71657
Epoch 74/300
 - 19s - loss: 662.3488 - acc: 0.9653 - mDice: 0.8731 - val_loss: 1598.8707 - val_acc: 0.9616 - val_mDice: 0.7053

Epoch 00074: val_mDice did not improve from 0.71657
Epoch 75/300
 - 18s - loss: 653.3856 - acc: 0.9654 - mDice: 0.8748 - val_loss: 1599.9133 - val_acc: 0.9609 - val_mDice: 0.7074

Epoch 00075: val_mDice did not improve from 0.71657
Epoch 76/300
 - 19s - loss: 650.5358 - acc: 0.9653 - mDice: 0.8753 - val_loss: 1582.7160 - val_acc: 0.9611 - val_mDice: 0.7073

Epoch 00076: val_mDice did not improve from 0.71657
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [3954.5569816764073, 2751.2267395485446, 2222.13586798515, 1946.2157560159233, 2025.5021916746184, 1703.2611503309877, 1718.2846521275644, 1673.3346692733182, 1630.6882063305104, 1603.500615942569, 1567.0442453631917, 1714.1896134005249, 1617.5971800825978, 1524.8978774674977, 1555.305438558564, 1619.996947310353, 1565.2739891459923, 1548.888392324666, 1563.7938008781607, 1594.9192034306418, 1556.0492530415077, 1560.976134787989, 1634.9487854469824, 1541.315863922352, 1570.7943692971733, 1532.1336586056775, 1671.5428103381441, 1644.482012799678, 1564.1520362446327, 1533.661735709387, 1602.6031186635257, 1627.4218489086354, 1600.1401218093988, 1576.9789032681297, 1675.3384189751312, 1661.4382128533516, 1591.5334733569896, 1571.9171328945015, 2308.9124690630965, 1608.6430347238788, 1656.1764745348282, 1651.6237429553316, 1623.0660419027313, 1522.1406156816556, 1637.2885360135376, 1519.9840423351027, 1684.9136916298903, 1583.530615420742, 1766.7995260690004, 1787.7520798544847, 1601.4100444298665, 1589.8281641370468, 1706.615559585222, 1615.617569552123, 1550.5662944298665, 1696.8158266489743, 1610.1474320506322, 1614.3068130143727, 1892.6443467467795, 1698.0169239772185, 1674.8366065571327, 1586.8234313498926, 1534.365061053793, 1679.2421185442508, 1785.3813905206346, 1636.300205376312, 1821.47072828453, 1550.4440498643248, 1662.2766001461116, 1625.4455585042938, 1556.087548641758, 1669.021876677302, 1698.8186519710162, 1598.8706893338501, 1599.913269508886, 1582.7160113385617], 'val_acc': [0.9053339198345446, 0.9271562777402746, 0.9372896847834113, 0.9436910065985818, 0.9418136659469313, 0.9508234999562037, 0.9492722121813825, 0.9515377242146558, 0.9521051863677629, 0.9546868819316835, 0.9556001479389103, 0.9552402082290358, 0.9543819786938093, 0.9576637940552398, 0.9563637703429652, 0.9573278522673454, 0.9576129835980539, 0.9590696706116655, 0.9593420997830747, 0.9562734156164504, 0.9580322135495776, 0.9586518716266137, 0.959645600264309, 0.9599815475121709, 0.9593745733945425, 0.9588763108690277, 0.9566291206665621, 0.9560758134790959, 0.9594437493622758, 0.9588480751023037, 0.9593519923341183, 0.9579503154026643, 0.9609766916464303, 0.9604416871798858, 0.9595651267139056, 0.9585417563678654, 0.960197509245108, 0.9613761155659916, 0.9363933519552682, 0.9605391102892752, 0.9603824119531471, 0.9613140398309431, 0.9594832881716372, 0.9606054429789536, 0.9598982406936529, 0.9613380250129991, 0.9595721750768996, 0.9607917634585431, 0.9590033479319274, 0.9585968146797355, 0.9614241255148677, 0.9596018399901063, 0.9580322058146237, 0.9597189703970465, 0.9613295429535494, 0.9565006813020197, 0.9599533017355067, 0.9604967450367585, 0.9522858248412154, 0.9592856655594046, 0.9606661405272157, 0.9613775524474283, 0.9614424801054802, 0.9589962813690418, 0.9585798678507331, 0.9606407371186118, 0.959851682641124, 0.9609667749805305, 0.9598516821861267, 0.9602200857555593, 0.9613606110783933, 0.9600591664095871, 0.9596554700654881, 0.9616203235305902, 0.960928687612519, 0.9611319248912898], 'val_mDice': [0.4338744005174127, 0.5495550809925749, 0.6144121616851282, 0.653275330558078, 0.6436003624027922, 0.6886737360299089, 0.6849160012398058, 0.6927215056564971, 0.6976813683073029, 0.7023126765061881, 0.7067676809907869, 0.6890563678195458, 0.6991805793674848, 0.7138919857622102, 0.7093264064716018, 0.7011785889399871, 0.7085130942686824, 0.7106219762154208, 0.710000112766528, 0.7022229569558879, 0.7092631263587311, 0.7096353182355866, 0.6996539590012936, 0.7123308941608167, 0.7081896489813128, 0.7125185737173065, 0.6930085807356215, 0.6955083608627319, 0.7090109186318084, 0.7134696613741285, 0.7049415261690853, 0.7012414295254773, 0.7032943008510211, 0.708144735288984, 0.6943373425316265, 0.6951158861167558, 0.7059932851609383, 0.7082194199088876, 0.6229372738881875, 0.7034443261969181, 0.6970646467827658, 0.6987289695339348, 0.7013888322670041, 0.7155779145146144, 0.6996870195592633, 0.716566127220183, 0.6934273247500412, 0.707614010981931, 0.68219203211879, 0.6803864472694979, 0.7049570365716483, 0.7051064940809294, 0.6897604647483534, 0.7024037728782828, 0.7117477819209791, 0.6895933497043056, 0.7056349124617249, 0.7032510597287244, 0.6617846143154698, 0.6904113970640051, 0.6949299137100918, 0.7089996055792306, 0.71505730843726, 0.6947413660187758, 0.6792562449251422, 0.7025610244911136, 0.6771176316355931, 0.7125068916619279, 0.6963607436828031, 0.7028841298955087, 0.7124959148523462, 0.6950008359574179, 0.6917780778790248, 0.7052745436894075, 0.7074405200608814, 0.7072747545387909], 'loss': [9928.707369947695, 3411.762232344384, 2582.113554235824, 2174.206300082781, 1949.4828239090461, 1792.8023443122167, 1673.7220243819766, 1585.811626176594, 1515.123494748592, 1454.0730723778186, 1404.9068698967606, 1351.8974730752575, 1313.5907221371435, 1276.7390686329495, 1255.5958884959853, 1214.1630113523547, 1187.688529680241, 1165.001609083123, 1146.4364128731572, 1125.724152843686, 1100.599869366808, 1077.1319739407563, 1058.3505886133069, 1046.9609456760768, 1026.3549552492696, 1055.8287080940092, 997.0031329774724, 980.9451275794422, 970.6225926196083, 952.4480892443216, 937.6692129794142, 923.3927819085102, 918.0782448954761, 899.6357163169066, 892.9654966483794, 881.2172764227134, 872.6188402991188, 858.2560981625246, 853.2496811330066, 903.6584183312326, 846.9291891428503, 836.9259407132279, 820.0777144888488, 810.5503076819717, 802.2093019873373, 797.9482134998765, 792.6072723568545, 782.8306487177878, 774.9194929074705, 771.447800877811, 761.941013028278, 757.9550648448215, 752.6866773172108, 745.2508710093491, 735.114063354177, 735.4690387879504, 726.5667618915, 721.6321149728773, 718.983182066548, 714.6547235175507, 709.7986295496507, 704.5382011882213, 695.4286673069813, 693.2417510870376, 686.6563118453312, 686.2844668461812, 679.4326872267466, 680.2804764807036, 672.3554820859245, 666.2006294889337, 662.9443136703266, 661.6364087919571, 660.3161877919187, 662.3488140954469, 653.3856047142021, 650.5358026788729], 'acc': [0.8833123321272823, 0.9179071353614066, 0.930774448824275, 0.9374990634878958, 0.9413563223343643, 0.944184962442135, 0.9463141489071901, 0.94792001023493, 0.9493804180248719, 0.9504877798764819, 0.9514166678500376, 0.9524250376200709, 0.9533207791600331, 0.9539061078483371, 0.9545565811992766, 0.9552392473849826, 0.9557890718954968, 0.9562402291870238, 0.956747523438966, 0.9570631907003541, 0.9575407453673611, 0.957993541593541, 0.9583004040971026, 0.9586040236161464, 0.9589816611203015, 0.9591103218936079, 0.9594992953075215, 0.959759822140435, 0.9600186208306137, 0.960335211309271, 0.9605742604421613, 0.9608351871305216, 0.9609908698375008, 0.9612981818307538, 0.9614494148618415, 0.9616434328786826, 0.9617163376050021, 0.9620340260355348, 0.9621857458625676, 0.9615198517717896, 0.9623651181683515, 0.9625325458560431, 0.962709504392923, 0.9628762107683091, 0.9630784077130788, 0.9631472957791004, 0.9632537606235277, 0.9633452737463206, 0.9634426440380361, 0.9636106999683812, 0.9637038766643877, 0.9637389858906347, 0.9639267678197857, 0.9639718600938182, 0.9640235099559509, 0.9641422258848872, 0.9642198516625832, 0.9642859274485449, 0.9643742338158987, 0.964437450686806, 0.9644807010033991, 0.9645863613027111, 0.9647249619961598, 0.964785816738682, 0.9648146752555334, 0.9648543089211576, 0.9650092868392876, 0.9649507954387868, 0.965048886491155, 0.9651394779355, 0.9651863691264315, 0.9652799030438256, 0.9652557823805368, 0.9652586094390876, 0.9653634741213512, 0.9653481426708905], 'mDice': [0.2723938469296453, 0.5123700468932387, 0.5991061131188499, 0.646637443705491, 0.6753115814319455, 0.6961886458764138, 0.712686686306993, 0.7249462679983015, 0.7355279994809951, 0.7443469646577567, 0.751522679897179, 0.7596334784974763, 0.7653866471634077, 0.7710445243980482, 0.774446368002614, 0.7807782545748918, 0.7849691166694946, 0.7885523022275108, 0.7919526209531138, 0.7948731546470731, 0.7988751022691088, 0.8026885858286582, 0.8056740734323883, 0.8075264307601202, 0.8109805216669159, 0.8108134102882903, 0.8156777539396781, 0.8183884924453049, 0.8200915723311767, 0.8231328029686921, 0.8255855073489369, 0.8279939049363014, 0.828871503895504, 0.8319886287825741, 0.8331080539273336, 0.8350357985965716, 0.836544018364538, 0.839001607901285, 0.8400426089423939, 0.831350934770256, 0.8408463754344541, 0.8426680905801867, 0.8455269463232196, 0.8471850032400845, 0.8485693901558058, 0.8493849672317226, 0.8503053947049961, 0.8519196286459999, 0.8533228519882785, 0.853942633488133, 0.8555621117813634, 0.8563039044971745, 0.8572272834528601, 0.858517592588201, 0.860259365815381, 0.8602360923573976, 0.861775300777326, 0.8626797269744703, 0.8631390701244285, 0.8642648696911028, 0.8647008854285201, 0.8656655949806237, 0.8672424976287649, 0.8676577911606208, 0.8687828312464154, 0.8689057236146553, 0.8701303364954269, 0.869968329084977, 0.8713185786242794, 0.8724209100459496, 0.8730070970974649, 0.8733094748254933, 0.8735553254467506, 0.8730728647968925, 0.8747590159387351, 0.8752625008125069]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:44, 14.83s/it]predicting test subjects:  50%|█████     | 2/4 [00:27<00:28, 14.28s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:42<00:14, 14.38s/it]predicting test subjects: 100%|██████████| 4/4 [00:56<00:00, 14.37s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:21<1:52:44, 21.82s/it]predicting train subjects:   1%|          | 2/311 [00:31<1:34:04, 18.27s/it]predicting train subjects:   1%|          | 3/311 [00:44<1:25:42, 16.70s/it]predicting train subjects:   1%|▏         | 4/311 [00:57<1:18:53, 15.42s/it]predicting train subjects:   2%|▏         | 5/311 [01:08<1:12:42, 14.26s/it]predicting train subjects:   2%|▏         | 6/311 [01:20<1:08:11, 13.41s/it]predicting train subjects:   2%|▏         | 7/311 [01:32<1:06:40, 13.16s/it]predicting train subjects:   3%|▎         | 8/311 [01:47<1:09:06, 13.68s/it]predicting train subjects:   3%|▎         | 9/311 [02:01<1:08:49, 13.67s/it]predicting train subjects:   3%|▎         | 10/311 [02:13<1:05:35, 13.07s/it]predicting train subjects:   4%|▎         | 11/311 [02:28<1:08:30, 13.70s/it]predicting train subjects:   4%|▍         | 12/311 [02:39<1:05:21, 13.12s/it]predicting train subjects:   4%|▍         | 13/311 [02:51<1:03:07, 12.71s/it]predicting train subjects:   5%|▍         | 14/311 [03:06<1:06:07, 13.36s/it]predicting train subjects:   5%|▍         | 15/311 [03:28<1:18:43, 15.96s/it]predicting train subjects:   5%|▌         | 16/311 [03:50<1:27:35, 17.81s/it]predicting train subjects:   5%|▌         | 17/311 [04:12<1:33:10, 19.02s/it]predicting train subjects:   6%|▌         | 18/311 [04:33<1:36:17, 19.72s/it]predicting train subjects:   6%|▌         | 19/311 [04:55<1:38:21, 20.21s/it]predicting train subjects:   6%|▋         | 20/311 [05:16<1:39:34, 20.53s/it]predicting train subjects:   7%|▋         | 21/311 [05:38<1:40:54, 20.88s/it]predicting train subjects:   7%|▋         | 22/311 [05:59<1:41:22, 21.05s/it]predicting train subjects:   7%|▋         | 23/311 [06:21<1:41:59, 21.25s/it]predicting train subjects:   8%|▊         | 24/311 [06:42<1:41:27, 21.21s/it]predicting train subjects:   8%|▊         | 25/311 [07:04<1:42:26, 21.49s/it]predicting train subjects:   8%|▊         | 26/311 [07:25<1:41:30, 21.37s/it]predicting train subjects:   9%|▊         | 27/311 [07:47<1:42:03, 21.56s/it]predicting train subjects:   9%|▉         | 28/311 [08:09<1:41:15, 21.47s/it]predicting train subjects:   9%|▉         | 29/311 [08:31<1:42:03, 21.72s/it]predicting train subjects:  10%|▉         | 30/311 [08:52<1:41:18, 21.63s/it]predicting train subjects:  10%|▉         | 31/311 [09:13<1:39:55, 21.41s/it]predicting train subjects:  10%|█         | 32/311 [09:35<1:40:37, 21.64s/it]predicting train subjects:  11%|█         | 33/311 [09:46<1:24:24, 18.22s/it]predicting train subjects:  11%|█         | 34/311 [09:56<1:12:42, 15.75s/it]predicting train subjects:  11%|█▏        | 35/311 [10:06<1:04:53, 14.11s/it]predicting train subjects:  12%|█▏        | 36/311 [10:16<59:17, 12.94s/it]  predicting train subjects:  12%|█▏        | 37/311 [10:26<55:07, 12.07s/it]predicting train subjects:  12%|█▏        | 38/311 [10:36<52:23, 11.51s/it]predicting train subjects:  13%|█▎        | 39/311 [10:47<50:37, 11.17s/it]predicting train subjects:  13%|█▎        | 40/311 [10:57<49:04, 10.87s/it]predicting train subjects:  13%|█▎        | 41/311 [11:07<47:26, 10.54s/it]predicting train subjects:  14%|█▎        | 42/311 [11:17<46:48, 10.44s/it]predicting train subjects:  14%|█▍        | 43/311 [11:27<46:43, 10.46s/it]predicting train subjects:  14%|█▍        | 44/311 [11:38<46:10, 10.38s/it]predicting train subjects:  14%|█▍        | 45/311 [11:48<45:44, 10.32s/it]predicting train subjects:  15%|█▍        | 46/311 [11:58<45:49, 10.37s/it]predicting train subjects:  15%|█▌        | 47/311 [12:09<45:35, 10.36s/it]predicting train subjects:  15%|█▌        | 48/311 [12:18<44:29, 10.15s/it]predicting train subjects:  16%|█▌        | 49/311 [12:28<44:30, 10.19s/it]predicting train subjects:  16%|█▌        | 50/311 [12:39<45:02, 10.36s/it]predicting train subjects:  16%|█▋        | 51/311 [12:52<48:17, 11.14s/it]predicting train subjects:  17%|█▋        | 52/311 [13:05<50:12, 11.63s/it]predicting train subjects:  17%|█▋        | 53/311 [13:19<52:54, 12.30s/it]predicting train subjects:  17%|█▋        | 54/311 [13:31<53:04, 12.39s/it]predicting train subjects:  18%|█▊        | 55/311 [13:45<53:45, 12.60s/it]predicting train subjects:  18%|█▊        | 56/311 [13:57<53:50, 12.67s/it]predicting train subjects:  18%|█▊        | 57/311 [14:10<53:57, 12.74s/it]predicting train subjects:  19%|█▊        | 58/311 [14:23<53:49, 12.77s/it]predicting train subjects:  19%|█▉        | 59/311 [14:36<53:58, 12.85s/it]predicting train subjects:  19%|█▉        | 60/311 [14:49<53:53, 12.88s/it]predicting train subjects:  20%|█▉        | 61/311 [15:02<53:55, 12.94s/it]predicting train subjects:  20%|█▉        | 62/311 [15:15<54:05, 13.03s/it]predicting train subjects:  20%|██        | 63/311 [15:29<54:02, 13.07s/it]predicting train subjects:  21%|██        | 64/311 [15:41<53:16, 12.94s/it]predicting train subjects:  21%|██        | 65/311 [15:54<52:37, 12.84s/it]predicting train subjects:  21%|██        | 66/311 [16:06<51:59, 12.73s/it]predicting train subjects:  22%|██▏       | 67/311 [16:19<51:33, 12.68s/it]predicting train subjects:  22%|██▏       | 68/311 [16:31<51:09, 12.63s/it]predicting train subjects:  22%|██▏       | 69/311 [16:44<50:43, 12.58s/it]predicting train subjects:  23%|██▎       | 70/311 [16:56<50:35, 12.59s/it]predicting train subjects:  23%|██▎       | 71/311 [17:09<50:28, 12.62s/it]predicting train subjects:  23%|██▎       | 72/311 [17:21<49:50, 12.51s/it]predicting train subjects:  23%|██▎       | 73/311 [17:33<49:03, 12.37s/it]predicting train subjects:  24%|██▍       | 74/311 [17:46<48:55, 12.39s/it]predicting train subjects:  24%|██▍       | 75/311 [17:58<48:52, 12.43s/it]predicting train subjects:  24%|██▍       | 76/311 [18:11<48:58, 12.51s/it]predicting train subjects:  25%|██▍       | 77/311 [18:23<48:29, 12.43s/it]predicting train subjects:  25%|██▌       | 78/311 [18:35<47:48, 12.31s/it]predicting train subjects:  25%|██▌       | 79/311 [18:48<47:47, 12.36s/it]predicting train subjects:  26%|██▌       | 80/311 [19:00<47:42, 12.39s/it]predicting train subjects:  26%|██▌       | 81/311 [19:12<47:11, 12.31s/it]predicting train subjects:  26%|██▋       | 82/311 [19:25<46:57, 12.30s/it]predicting train subjects:  27%|██▋       | 83/311 [19:37<46:55, 12.35s/it]predicting train subjects:  27%|██▋       | 84/311 [19:50<47:00, 12.43s/it]predicting train subjects:  27%|██▋       | 85/311 [20:01<45:31, 12.09s/it]predicting train subjects:  28%|██▊       | 86/311 [20:12<44:22, 11.83s/it]predicting train subjects:  28%|██▊       | 87/311 [20:24<43:47, 11.73s/it]predicting train subjects:  28%|██▊       | 88/311 [20:35<43:00, 11.57s/it]predicting train subjects:  29%|██▊       | 89/311 [20:46<42:14, 11.42s/it]predicting train subjects:  29%|██▉       | 90/311 [20:58<42:12, 11.46s/it]predicting train subjects:  29%|██▉       | 91/311 [21:09<42:09, 11.50s/it]predicting train subjects:  30%|██▉       | 92/311 [21:20<41:32, 11.38s/it]predicting train subjects:  30%|██▉       | 93/311 [21:32<41:42, 11.48s/it]predicting train subjects:  30%|███       | 94/311 [21:44<41:46, 11.55s/it]predicting train subjects:  31%|███       | 95/311 [21:55<41:17, 11.47s/it]predicting train subjects:  31%|███       | 96/311 [22:06<40:36, 11.33s/it]predicting train subjects:  31%|███       | 97/311 [22:17<40:25, 11.34s/it]predicting train subjects:  32%|███▏      | 98/311 [22:29<40:31, 11.42s/it]predicting train subjects:  32%|███▏      | 99/311 [22:40<39:40, 11.23s/it]predicting train subjects:  32%|███▏      | 100/311 [22:51<39:30, 11.23s/it]predicting train subjects:  32%|███▏      | 101/311 [23:02<39:25, 11.26s/it]predicting train subjects:  33%|███▎      | 102/311 [23:14<39:14, 11.27s/it]predicting train subjects:  33%|███▎      | 103/311 [23:25<39:21, 11.35s/it]predicting train subjects:  33%|███▎      | 104/311 [23:37<39:54, 11.57s/it]predicting train subjects:  34%|███▍      | 105/311 [23:49<40:03, 11.67s/it]predicting train subjects:  34%|███▍      | 106/311 [24:01<39:38, 11.60s/it]predicting train subjects:  34%|███▍      | 107/311 [24:12<39:18, 11.56s/it]predicting train subjects:  35%|███▍      | 108/311 [24:24<39:11, 11.58s/it]predicting train subjects:  35%|███▌      | 109/311 [24:35<39:01, 11.59s/it]predicting train subjects:  35%|███▌      | 110/311 [24:46<38:25, 11.47s/it]predicting train subjects:  36%|███▌      | 111/311 [24:58<38:25, 11.53s/it]predicting train subjects:  36%|███▌      | 112/311 [25:10<38:24, 11.58s/it]predicting train subjects:  36%|███▋      | 113/311 [25:22<38:22, 11.63s/it]predicting train subjects:  37%|███▋      | 114/311 [25:43<47:36, 14.50s/it]predicting train subjects:  37%|███▋      | 115/311 [26:05<54:44, 16.76s/it]predicting train subjects:  37%|███▋      | 116/311 [26:26<59:12, 18.22s/it]predicting train subjects:  38%|███▊      | 117/311 [26:48<1:01:52, 19.13s/it]predicting train subjects:  38%|███▊      | 118/311 [27:09<1:03:50, 19.85s/it]predicting train subjects:  38%|███▊      | 119/311 [27:31<1:05:09, 20.36s/it]predicting train subjects:  39%|███▊      | 120/311 [27:53<1:06:17, 20.82s/it]predicting train subjects:  39%|███▉      | 121/311 [28:13<1:05:53, 20.81s/it]predicting train subjects:  39%|███▉      | 122/311 [28:35<1:06:24, 21.08s/it]predicting train subjects:  40%|███▉      | 123/311 [28:57<1:06:40, 21.28s/it]predicting train subjects:  40%|███▉      | 124/311 [29:19<1:06:48, 21.43s/it]predicting train subjects:  40%|████      | 125/311 [29:40<1:06:28, 21.44s/it]predicting train subjects:  41%|████      | 126/311 [30:02<1:06:17, 21.50s/it]predicting train subjects:  41%|████      | 127/311 [30:23<1:06:00, 21.53s/it]predicting train subjects:  41%|████      | 128/311 [30:45<1:06:07, 21.68s/it]predicting train subjects:  41%|████▏     | 129/311 [31:07<1:05:31, 21.60s/it]predicting train subjects:  42%|████▏     | 130/311 [31:29<1:05:47, 21.81s/it]predicting train subjects:  42%|████▏     | 131/311 [31:51<1:05:22, 21.79s/it]predicting train subjects:  42%|████▏     | 132/311 [32:02<55:00, 18.44s/it]  predicting train subjects:  43%|████▎     | 133/311 [32:12<47:24, 15.98s/it]predicting train subjects:  43%|████▎     | 134/311 [32:21<41:34, 14.09s/it]predicting train subjects:  43%|████▎     | 135/311 [32:32<38:04, 12.98s/it]predicting train subjects:  44%|████▎     | 136/311 [32:42<35:38, 12.22s/it]predicting train subjects:  44%|████▍     | 137/311 [32:52<33:24, 11.52s/it]predicting train subjects:  44%|████▍     | 138/311 [33:03<32:14, 11.18s/it]predicting train subjects:  45%|████▍     | 139/311 [33:13<31:33, 11.01s/it]predicting train subjects:  45%|████▌     | 140/311 [33:24<31:04, 10.90s/it]predicting train subjects:  45%|████▌     | 141/311 [33:34<30:04, 10.61s/it]predicting train subjects:  46%|████▌     | 142/311 [33:44<29:38, 10.52s/it]predicting train subjects:  46%|████▌     | 143/311 [33:55<29:33, 10.56s/it]predicting train subjects:  46%|████▋     | 144/311 [34:05<29:01, 10.43s/it]predicting train subjects:  47%|████▋     | 145/311 [34:15<28:29, 10.30s/it]predicting train subjects:  47%|████▋     | 146/311 [34:25<28:15, 10.27s/it]predicting train subjects:  47%|████▋     | 147/311 [34:35<28:07, 10.29s/it]predicting train subjects:  48%|████▊     | 148/311 [34:45<27:17, 10.05s/it]predicting train subjects:  48%|████▊     | 149/311 [34:55<27:26, 10.17s/it]predicting train subjects:  48%|████▊     | 150/311 [35:08<29:40, 11.06s/it]predicting train subjects:  49%|████▊     | 151/311 [35:22<31:09, 11.68s/it]predicting train subjects:  49%|████▉     | 152/311 [35:34<31:40, 11.95s/it]predicting train subjects:  49%|████▉     | 153/311 [35:46<31:34, 11.99s/it]predicting train subjects:  50%|████▉     | 154/311 [35:59<31:47, 12.15s/it]predicting train subjects:  50%|████▉     | 155/311 [36:12<32:11, 12.38s/it]predicting train subjects:  50%|█████     | 156/311 [36:25<32:23, 12.54s/it]predicting train subjects:  50%|█████     | 157/311 [36:37<32:22, 12.62s/it]predicting train subjects:  51%|█████     | 158/311 [36:50<32:17, 12.67s/it]predicting train subjects:  51%|█████     | 159/311 [37:03<32:10, 12.70s/it]predicting train subjects:  51%|█████▏    | 160/311 [37:16<31:58, 12.71s/it]predicting train subjects:  52%|█████▏    | 161/311 [37:29<32:16, 12.91s/it]predicting train subjects:  52%|█████▏    | 162/311 [37:42<31:54, 12.85s/it]predicting train subjects:  52%|█████▏    | 163/311 [37:55<31:39, 12.84s/it]predicting train subjects:  53%|█████▎    | 164/311 [38:07<31:29, 12.85s/it]predicting train subjects:  53%|█████▎    | 165/311 [38:20<31:16, 12.85s/it]predicting train subjects:  53%|█████▎    | 166/311 [38:33<30:49, 12.75s/it]predicting train subjects:  54%|█████▎    | 167/311 [38:45<30:16, 12.61s/it]predicting train subjects:  54%|█████▍    | 168/311 [38:57<29:42, 12.47s/it]predicting train subjects:  54%|█████▍    | 169/311 [39:10<29:21, 12.41s/it]predicting train subjects:  55%|█████▍    | 170/311 [39:22<29:15, 12.45s/it]predicting train subjects:  55%|█████▍    | 171/311 [39:35<29:07, 12.48s/it]predicting train subjects:  55%|█████▌    | 172/311 [39:48<29:24, 12.69s/it]predicting train subjects:  56%|█████▌    | 173/311 [40:00<29:03, 12.63s/it]predicting train subjects:  56%|█████▌    | 174/311 [40:12<28:30, 12.49s/it]predicting train subjects:  56%|█████▋    | 175/311 [40:25<28:09, 12.43s/it]predicting train subjects:  57%|█████▋    | 176/311 [40:37<27:48, 12.36s/it]predicting train subjects:  57%|█████▋    | 177/311 [40:50<27:44, 12.42s/it]predicting train subjects:  57%|█████▋    | 178/311 [41:03<28:05, 12.67s/it]predicting train subjects:  58%|█████▊    | 179/311 [41:15<27:46, 12.63s/it]predicting train subjects:  58%|█████▊    | 180/311 [41:28<27:20, 12.52s/it]predicting train subjects:  58%|█████▊    | 181/311 [41:40<26:57, 12.44s/it]predicting train subjects:  59%|█████▊    | 182/311 [41:52<26:41, 12.41s/it]predicting train subjects:  59%|█████▉    | 183/311 [42:05<26:33, 12.45s/it]predicting train subjects:  59%|█████▉    | 184/311 [42:16<25:45, 12.17s/it]predicting train subjects:  59%|█████▉    | 185/311 [42:27<24:57, 11.89s/it]predicting train subjects:  60%|█████▉    | 186/311 [42:39<24:14, 11.64s/it]predicting train subjects:  60%|██████    | 187/311 [42:50<23:50, 11.54s/it]predicting train subjects:  60%|██████    | 188/311 [43:01<23:42, 11.57s/it]predicting train subjects:  61%|██████    | 189/311 [43:13<23:42, 11.66s/it]predicting train subjects:  61%|██████    | 190/311 [43:25<23:13, 11.52s/it]predicting train subjects:  61%|██████▏   | 191/311 [43:35<22:40, 11.34s/it]predicting train subjects:  62%|██████▏   | 192/311 [43:47<22:35, 11.39s/it]predicting train subjects:  62%|██████▏   | 193/311 [43:59<22:33, 11.47s/it]predicting train subjects:  62%|██████▏   | 194/311 [44:10<22:28, 11.52s/it]predicting train subjects:  63%|██████▎   | 195/311 [44:21<22:04, 11.42s/it]predicting train subjects:  63%|██████▎   | 196/311 [44:33<21:42, 11.33s/it]predicting train subjects:  63%|██████▎   | 197/311 [44:44<21:36, 11.37s/it]predicting train subjects:  64%|██████▎   | 198/311 [44:56<21:30, 11.42s/it]predicting train subjects:  64%|██████▍   | 199/311 [45:07<21:19, 11.42s/it]predicting train subjects:  64%|██████▍   | 200/311 [45:18<20:53, 11.29s/it]predicting train subjects:  65%|██████▍   | 201/311 [45:29<20:44, 11.31s/it]predicting train subjects:  65%|██████▍   | 202/311 [45:41<20:44, 11.42s/it]predicting train subjects:  65%|██████▌   | 203/311 [45:53<20:40, 11.49s/it]predicting train subjects:  66%|██████▌   | 204/311 [46:04<20:25, 11.45s/it]predicting train subjects:  66%|██████▌   | 205/311 [46:16<20:40, 11.70s/it]predicting train subjects:  66%|██████▌   | 206/311 [46:28<20:19, 11.61s/it]predicting train subjects:  67%|██████▋   | 207/311 [46:39<20:08, 11.62s/it]predicting train subjects:  67%|██████▋   | 208/311 [46:52<20:26, 11.91s/it]predicting train subjects:  67%|██████▋   | 209/311 [47:03<20:01, 11.78s/it]predicting train subjects:  68%|██████▊   | 210/311 [47:14<19:29, 11.58s/it]predicting train subjects:  68%|██████▊   | 211/311 [47:26<19:15, 11.55s/it]predicting train subjects:  68%|██████▊   | 212/311 [47:38<19:23, 11.75s/it]predicting train subjects:  68%|██████▊   | 213/311 [48:00<24:05, 14.75s/it]predicting train subjects:  69%|██████▉   | 214/311 [48:21<26:53, 16.63s/it]predicting train subjects:  69%|██████▉   | 215/311 [48:43<29:09, 18.22s/it]predicting train subjects:  69%|██████▉   | 216/311 [49:05<30:29, 19.25s/it]predicting train subjects:  70%|██████▉   | 217/311 [49:26<31:10, 19.90s/it]predicting train subjects:  70%|███████   | 218/311 [49:47<31:33, 20.36s/it]predicting train subjects:  70%|███████   | 219/311 [50:09<31:37, 20.63s/it]predicting train subjects:  71%|███████   | 220/311 [50:30<31:48, 20.97s/it]predicting train subjects:  71%|███████   | 221/311 [50:52<31:37, 21.08s/it]predicting train subjects:  71%|███████▏  | 222/311 [51:13<31:28, 21.22s/it]predicting train subjects:  72%|███████▏  | 223/311 [51:34<31:04, 21.18s/it]predicting train subjects:  72%|███████▏  | 224/311 [51:56<30:56, 21.34s/it]predicting train subjects:  72%|███████▏  | 225/311 [52:17<30:21, 21.18s/it]predicting train subjects:  73%|███████▎  | 226/311 [52:37<29:45, 21.00s/it]predicting train subjects:  73%|███████▎  | 227/311 [52:59<29:45, 21.26s/it]predicting train subjects:  73%|███████▎  | 228/311 [53:22<29:49, 21.55s/it]predicting train subjects:  74%|███████▎  | 229/311 [53:44<29:51, 21.84s/it]predicting train subjects:  74%|███████▍  | 230/311 [54:06<29:24, 21.78s/it]predicting train subjects:  74%|███████▍  | 231/311 [54:16<24:24, 18.30s/it]predicting train subjects:  75%|███████▍  | 232/311 [54:27<21:14, 16.13s/it]predicting train subjects:  75%|███████▍  | 233/311 [54:37<18:43, 14.40s/it]predicting train subjects:  75%|███████▌  | 234/311 [54:47<16:47, 13.08s/it]predicting train subjects:  76%|███████▌  | 235/311 [54:57<15:23, 12.15s/it]predicting train subjects:  76%|███████▌  | 236/311 [55:08<14:42, 11.76s/it]predicting train subjects:  76%|███████▌  | 237/311 [55:18<13:54, 11.28s/it]predicting train subjects:  77%|███████▋  | 238/311 [55:29<13:20, 10.96s/it]predicting train subjects:  77%|███████▋  | 239/311 [55:39<13:00, 10.84s/it]predicting train subjects:  77%|███████▋  | 240/311 [55:49<12:33, 10.62s/it]predicting train subjects:  77%|███████▋  | 241/311 [55:59<12:13, 10.48s/it]predicting train subjects:  78%|███████▊  | 242/311 [56:10<12:01, 10.45s/it]predicting train subjects:  78%|███████▊  | 243/311 [56:19<11:34, 10.22s/it]predicting train subjects:  78%|███████▊  | 244/311 [56:30<11:25, 10.24s/it]predicting train subjects:  79%|███████▉  | 245/311 [56:40<11:23, 10.35s/it]predicting train subjects:  79%|███████▉  | 246/311 [56:50<11:05, 10.24s/it]predicting train subjects:  79%|███████▉  | 247/311 [57:01<10:59, 10.30s/it]predicting train subjects:  80%|███████▉  | 248/311 [57:11<10:53, 10.37s/it]predicting train subjects:  80%|████████  | 249/311 [57:24<11:34, 11.21s/it]predicting train subjects:  80%|████████  | 250/311 [57:37<11:54, 11.71s/it]predicting train subjects:  81%|████████  | 251/311 [57:50<12:06, 12.11s/it]predicting train subjects:  81%|████████  | 252/311 [58:04<12:21, 12.56s/it]predicting train subjects:  81%|████████▏ | 253/311 [58:17<12:20, 12.76s/it]predicting train subjects:  82%|████████▏ | 254/311 [58:31<12:32, 13.20s/it]predicting train subjects:  82%|████████▏ | 255/311 [58:46<12:39, 13.56s/it]predicting train subjects:  82%|████████▏ | 256/311 [58:59<12:15, 13.38s/it]predicting train subjects:  83%|████████▎ | 257/311 [59:12<11:54, 13.23s/it]predicting train subjects:  83%|████████▎ | 258/311 [59:25<11:34, 13.10s/it]predicting train subjects:  83%|████████▎ | 259/311 [59:37<11:17, 13.03s/it]predicting train subjects:  84%|████████▎ | 260/311 [59:50<11:05, 13.05s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:00:04<10:53, 13.06s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:00:16<10:38, 13.02s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:00:29<10:22, 12.96s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:00:42<10:05, 12.88s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:00:54<09:41, 12.65s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:01:06<09:21, 12.49s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:01:19<09:09, 12.48s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:01:31<08:58, 12.53s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:01:44<08:52, 12.68s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:01:57<08:33, 12.53s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:02:09<08:17, 12.45s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:02:21<08:05, 12.44s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:02:34<07:54, 12.48s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:02:46<07:42, 12.49s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:02:59<07:29, 12.48s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:03:11<07:14, 12.42s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:03:23<07:00, 12.36s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:03:36<06:49, 12.40s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:03:48<06:38, 12.45s/it]predicting train subjects:  90%|█████████ | 280/311 [1:04:01<06:28, 12.53s/it]predicting train subjects:  90%|█████████ | 281/311 [1:04:14<06:16, 12.55s/it]predicting train subjects:  91%|█████████ | 282/311 [1:04:26<06:02, 12.50s/it]predicting train subjects:  91%|█████████ | 283/311 [1:04:37<05:37, 12.05s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:04:48<05:18, 11.81s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:05:00<05:06, 11.77s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:05:11<04:51, 11.64s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:05:22<04:34, 11.43s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:05:34<04:21, 11.39s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:05:45<04:12, 11.47s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:05:57<04:00, 11.43s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:06:08<03:46, 11.32s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:06:19<03:36, 11.37s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:06:31<03:26, 11.45s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:06:42<03:15, 11.53s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:06:54<03:02, 11.42s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:07:05<02:49, 11.29s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:07:16<02:38, 11.34s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:07:28<02:28, 11.46s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:07:39<02:17, 11.44s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:07:50<02:04, 11.35s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:08:02<01:54, 11.45s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:08:14<01:43, 11.51s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:08:25<01:32, 11.57s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:08:37<01:20, 11.51s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:08:48<01:08, 11.35s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:08:59<00:57, 11.48s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:09:11<00:45, 11.48s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:09:22<00:34, 11.47s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:09:34<00:22, 11.38s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:09:45<00:11, 11.41s/it]predicting train subjects: 100%|██████████| 311/311 [1:09:57<00:00, 11.57s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:16<1:26:43, 16.79s/it]Loading train:   1%|          | 2/311 [00:24<1:13:08, 14.20s/it]Loading train:   1%|          | 3/311 [00:35<1:06:43, 13.00s/it]Loading train:   1%|▏         | 4/311 [00:45<1:01:46, 12.07s/it]Loading train:   2%|▏         | 5/311 [00:54<56:58, 11.17s/it]  Loading train:   2%|▏         | 6/311 [01:03<53:45, 10.58s/it]Loading train:   2%|▏         | 7/311 [01:14<53:44, 10.61s/it]Loading train:   3%|▎         | 8/311 [01:26<56:09, 11.12s/it]Loading train:   3%|▎         | 9/311 [01:37<55:53, 11.10s/it]Loading train:   3%|▎         | 10/311 [01:47<53:28, 10.66s/it]Loading train:   4%|▎         | 11/311 [01:59<55:35, 11.12s/it]Loading train:   4%|▍         | 12/311 [02:09<53:33, 10.75s/it]Loading train:   4%|▍         | 13/311 [02:18<51:44, 10.42s/it]Loading train:   5%|▍         | 14/311 [02:30<54:10, 10.94s/it]Loading train:   5%|▍         | 15/311 [02:39<51:09, 10.37s/it]Loading train:   5%|▌         | 16/311 [02:49<49:06,  9.99s/it]Loading train:   5%|▌         | 17/311 [02:57<47:19,  9.66s/it]Loading train:   6%|▌         | 18/311 [03:06<46:16,  9.47s/it]Loading train:   6%|▌         | 19/311 [03:16<45:35,  9.37s/it]Loading train:   6%|▋         | 20/311 [03:25<45:09,  9.31s/it]Loading train:   7%|▋         | 21/311 [03:34<45:00,  9.31s/it]Loading train:   7%|▋         | 22/311 [03:43<44:29,  9.24s/it]Loading train:   7%|▋         | 23/311 [03:52<44:04,  9.18s/it]Loading train:   8%|▊         | 24/311 [04:01<43:52,  9.17s/it]Loading train:   8%|▊         | 25/311 [04:11<43:49,  9.20s/it]Loading train:   8%|▊         | 26/311 [04:20<43:31,  9.16s/it]Loading train:   9%|▊         | 27/311 [04:29<43:22,  9.16s/it]Loading train:   9%|▉         | 28/311 [04:38<43:14,  9.17s/it]Loading train:   9%|▉         | 29/311 [04:47<43:03,  9.16s/it]Loading train:  10%|▉         | 30/311 [04:57<43:13,  9.23s/it]Loading train:  10%|▉         | 31/311 [05:06<43:05,  9.23s/it]Loading train:  10%|█         | 32/311 [05:15<42:58,  9.24s/it]Loading train:  11%|█         | 33/311 [05:20<36:09,  7.80s/it]Loading train:  11%|█         | 34/311 [05:24<31:27,  6.82s/it]Loading train:  11%|█▏        | 35/311 [05:29<28:16,  6.15s/it]Loading train:  12%|█▏        | 36/311 [05:33<26:01,  5.68s/it]Loading train:  12%|█▏        | 37/311 [05:38<24:23,  5.34s/it]Loading train:  12%|█▏        | 38/311 [05:42<23:18,  5.12s/it]Loading train:  13%|█▎        | 39/311 [05:47<22:20,  4.93s/it]Loading train:  13%|█▎        | 40/311 [05:51<21:46,  4.82s/it]Loading train:  13%|█▎        | 41/311 [05:56<21:29,  4.78s/it]Loading train:  14%|█▎        | 42/311 [06:01<21:19,  4.76s/it]Loading train:  14%|█▍        | 43/311 [06:05<20:56,  4.69s/it]Loading train:  14%|█▍        | 44/311 [06:10<20:41,  4.65s/it]Loading train:  14%|█▍        | 45/311 [06:14<20:30,  4.63s/it]Loading train:  15%|█▍        | 46/311 [06:19<20:25,  4.62s/it]Loading train:  15%|█▌        | 47/311 [06:24<20:14,  4.60s/it]Loading train:  15%|█▌        | 48/311 [06:28<20:03,  4.58s/it]Loading train:  16%|█▌        | 49/311 [06:33<19:47,  4.53s/it]Loading train:  16%|█▌        | 50/311 [06:37<19:34,  4.50s/it]Loading train:  16%|█▋        | 51/311 [06:43<21:07,  4.88s/it]Loading train:  17%|█▋        | 52/311 [06:48<21:51,  5.06s/it]Loading train:  17%|█▋        | 53/311 [06:54<22:33,  5.25s/it]Loading train:  17%|█▋        | 54/311 [07:00<22:55,  5.35s/it]Loading train:  18%|█▊        | 55/311 [07:05<23:17,  5.46s/it]Loading train:  18%|█▊        | 56/311 [07:11<23:25,  5.51s/it]Loading train:  18%|█▊        | 57/311 [07:17<23:34,  5.57s/it]Loading train:  19%|█▊        | 58/311 [07:22<23:34,  5.59s/it]Loading train:  19%|█▉        | 59/311 [07:28<23:24,  5.57s/it]Loading train:  19%|█▉        | 60/311 [07:33<23:22,  5.59s/it]Loading train:  20%|█▉        | 61/311 [07:39<23:01,  5.53s/it]Loading train:  20%|█▉        | 62/311 [07:44<23:04,  5.56s/it]Loading train:  20%|██        | 63/311 [07:50<23:22,  5.66s/it]Loading train:  21%|██        | 64/311 [07:56<23:07,  5.62s/it]Loading train:  21%|██        | 65/311 [08:02<23:16,  5.68s/it]Loading train:  21%|██        | 66/311 [08:07<23:13,  5.69s/it]Loading train:  22%|██▏       | 67/311 [08:13<22:53,  5.63s/it]Loading train:  22%|██▏       | 68/311 [08:18<22:35,  5.58s/it]Loading train:  22%|██▏       | 69/311 [08:24<22:25,  5.56s/it]Loading train:  23%|██▎       | 70/311 [08:29<22:08,  5.51s/it]Loading train:  23%|██▎       | 71/311 [08:35<21:53,  5.47s/it]Loading train:  23%|██▎       | 72/311 [08:40<21:59,  5.52s/it]Loading train:  23%|██▎       | 73/311 [08:46<22:03,  5.56s/it]Loading train:  24%|██▍       | 74/311 [08:51<21:53,  5.54s/it]Loading train:  24%|██▍       | 75/311 [08:57<21:45,  5.53s/it]Loading train:  24%|██▍       | 76/311 [09:02<21:47,  5.56s/it]Loading train:  25%|██▍       | 77/311 [09:08<21:30,  5.51s/it]Loading train:  25%|██▌       | 78/311 [09:13<21:15,  5.48s/it]Loading train:  25%|██▌       | 79/311 [09:19<21:08,  5.47s/it]Loading train:  26%|██▌       | 80/311 [09:24<21:03,  5.47s/it]Loading train:  26%|██▌       | 81/311 [09:30<20:57,  5.47s/it]Loading train:  26%|██▋       | 82/311 [09:35<20:34,  5.39s/it]Loading train:  27%|██▋       | 83/311 [09:40<20:28,  5.39s/it]Loading train:  27%|██▋       | 84/311 [09:46<20:19,  5.37s/it]Loading train:  27%|██▋       | 85/311 [09:51<19:46,  5.25s/it]Loading train:  28%|██▊       | 86/311 [09:56<19:23,  5.17s/it]Loading train:  28%|██▊       | 87/311 [10:00<18:54,  5.07s/it]Loading train:  28%|██▊       | 88/311 [10:05<18:49,  5.06s/it]Loading train:  29%|██▊       | 89/311 [10:10<18:30,  5.00s/it]Loading train:  29%|██▉       | 90/311 [10:15<18:10,  4.93s/it]Loading train:  29%|██▉       | 91/311 [10:20<17:58,  4.90s/it]Loading train:  30%|██▉       | 92/311 [10:25<18:06,  4.96s/it]Loading train:  30%|██▉       | 93/311 [10:30<18:00,  4.95s/it]Loading train:  30%|███       | 94/311 [10:35<17:52,  4.94s/it]Loading train:  31%|███       | 95/311 [10:40<17:47,  4.94s/it]Loading train:  31%|███       | 96/311 [10:45<17:45,  4.95s/it]Loading train:  31%|███       | 97/311 [10:50<17:34,  4.93s/it]Loading train:  32%|███▏      | 98/311 [10:55<17:37,  4.97s/it]Loading train:  32%|███▏      | 99/311 [11:00<17:29,  4.95s/it]Loading train:  32%|███▏      | 100/311 [11:04<17:20,  4.93s/it]Loading train:  32%|███▏      | 101/311 [11:09<17:17,  4.94s/it]Loading train:  33%|███▎      | 102/311 [11:14<17:09,  4.92s/it]Loading train:  33%|███▎      | 103/311 [11:19<17:14,  4.97s/it]Loading train:  33%|███▎      | 104/311 [11:24<17:16,  5.01s/it]Loading train:  34%|███▍      | 105/311 [11:29<17:03,  4.97s/it]Loading train:  34%|███▍      | 106/311 [11:34<16:50,  4.93s/it]Loading train:  34%|███▍      | 107/311 [11:39<16:38,  4.89s/it]Loading train:  35%|███▍      | 108/311 [11:44<16:29,  4.87s/it]Loading train:  35%|███▌      | 109/311 [11:49<16:24,  4.87s/it]Loading train:  35%|███▌      | 110/311 [11:54<16:33,  4.94s/it]Loading train:  36%|███▌      | 111/311 [11:59<16:44,  5.02s/it]Loading train:  36%|███▌      | 112/311 [12:04<16:34,  5.00s/it]Loading train:  36%|███▋      | 113/311 [12:09<16:23,  4.97s/it]Loading train:  37%|███▋      | 114/311 [12:18<20:19,  6.19s/it]Loading train:  37%|███▋      | 115/311 [12:27<22:42,  6.95s/it]Loading train:  37%|███▋      | 116/311 [12:36<24:34,  7.56s/it]Loading train:  38%|███▊      | 117/311 [12:45<26:00,  8.05s/it]Loading train:  38%|███▊      | 118/311 [12:54<26:49,  8.34s/it]Loading train:  38%|███▊      | 119/311 [13:03<27:07,  8.48s/it]Loading train:  39%|███▊      | 120/311 [13:12<27:36,  8.67s/it]Loading train:  39%|███▉      | 121/311 [13:21<27:40,  8.74s/it]Loading train:  39%|███▉      | 122/311 [13:30<27:49,  8.83s/it]Loading train:  40%|███▉      | 123/311 [13:38<27:29,  8.77s/it]Loading train:  40%|███▉      | 124/311 [13:47<27:38,  8.87s/it]Loading train:  40%|████      | 125/311 [13:57<27:57,  9.02s/it]Loading train:  41%|████      | 126/311 [14:06<27:57,  9.07s/it]Loading train:  41%|████      | 127/311 [14:16<28:15,  9.21s/it]Loading train:  41%|████      | 128/311 [14:25<28:29,  9.34s/it]Loading train:  41%|████▏     | 129/311 [14:35<28:39,  9.45s/it]Loading train:  42%|████▏     | 130/311 [14:44<28:24,  9.42s/it]Loading train:  42%|████▏     | 131/311 [14:54<28:21,  9.45s/it]Loading train:  42%|████▏     | 132/311 [14:59<24:08,  8.09s/it]Loading train:  43%|████▎     | 133/311 [15:03<21:04,  7.10s/it]Loading train:  43%|████▎     | 134/311 [15:09<19:24,  6.58s/it]Loading train:  43%|████▎     | 135/311 [15:14<18:09,  6.19s/it]Loading train:  44%|████▎     | 136/311 [15:19<17:02,  5.84s/it]Loading train:  44%|████▍     | 137/311 [15:24<16:26,  5.67s/it]Loading train:  44%|████▍     | 138/311 [15:29<15:45,  5.47s/it]Loading train:  45%|████▍     | 139/311 [15:35<15:28,  5.40s/it]Loading train:  45%|████▌     | 140/311 [15:40<15:05,  5.29s/it]Loading train:  45%|████▌     | 141/311 [15:45<14:43,  5.20s/it]Loading train:  46%|████▌     | 142/311 [15:50<14:28,  5.14s/it]Loading train:  46%|████▌     | 143/311 [15:55<14:17,  5.11s/it]Loading train:  46%|████▋     | 144/311 [16:00<14:18,  5.14s/it]Loading train:  47%|████▋     | 145/311 [16:05<14:31,  5.25s/it]Loading train:  47%|████▋     | 146/311 [16:11<14:19,  5.21s/it]Loading train:  47%|████▋     | 147/311 [16:16<14:15,  5.22s/it]Loading train:  48%|████▊     | 148/311 [16:21<14:04,  5.18s/it]Loading train:  48%|████▊     | 149/311 [16:26<13:46,  5.10s/it]Loading train:  48%|████▊     | 150/311 [16:32<14:33,  5.42s/it]Loading train:  49%|████▊     | 151/311 [16:38<15:07,  5.67s/it]Loading train:  49%|████▉     | 152/311 [16:45<15:41,  5.92s/it]Loading train:  49%|████▉     | 153/311 [16:51<15:47,  6.00s/it]Loading train:  50%|████▉     | 154/311 [16:57<15:44,  6.02s/it]Loading train:  50%|████▉     | 155/311 [17:04<16:06,  6.20s/it]Loading train:  50%|█████     | 156/311 [17:10<15:50,  6.13s/it]Loading train:  50%|█████     | 157/311 [17:16<15:46,  6.15s/it]Loading train:  51%|█████     | 158/311 [17:22<15:50,  6.21s/it]Loading train:  51%|█████     | 159/311 [17:29<16:30,  6.52s/it]Loading train:  51%|█████▏    | 160/311 [17:36<16:21,  6.50s/it]Loading train:  52%|█████▏    | 161/311 [17:43<16:27,  6.58s/it]Loading train:  52%|█████▏    | 162/311 [17:49<16:13,  6.53s/it]Loading train:  52%|█████▏    | 163/311 [17:55<15:59,  6.48s/it]Loading train:  53%|█████▎    | 164/311 [18:01<15:34,  6.36s/it]Loading train:  53%|█████▎    | 165/311 [18:08<15:33,  6.39s/it]Loading train:  53%|█████▎    | 166/311 [18:14<15:15,  6.31s/it]Loading train:  54%|█████▎    | 167/311 [18:20<15:05,  6.29s/it]Loading train:  54%|█████▍    | 168/311 [18:26<14:50,  6.22s/it]Loading train:  54%|█████▍    | 169/311 [18:32<14:40,  6.20s/it]Loading train:  55%|█████▍    | 170/311 [18:39<14:39,  6.24s/it]Loading train:  55%|█████▍    | 171/311 [18:45<14:31,  6.22s/it]Loading train:  55%|█████▌    | 172/311 [18:51<14:31,  6.27s/it]Loading train:  56%|█████▌    | 173/311 [18:58<14:31,  6.31s/it]Loading train:  56%|█████▌    | 174/311 [19:04<14:17,  6.26s/it]Loading train:  56%|█████▋    | 175/311 [19:10<14:13,  6.27s/it]Loading train:  57%|█████▋    | 176/311 [19:16<13:54,  6.18s/it]Loading train:  57%|█████▋    | 177/311 [19:22<13:50,  6.20s/it]Loading train:  57%|█████▋    | 178/311 [19:29<13:48,  6.23s/it]Loading train:  58%|█████▊    | 179/311 [19:35<13:43,  6.24s/it]Loading train:  58%|█████▊    | 180/311 [19:41<13:42,  6.28s/it]Loading train:  58%|█████▊    | 181/311 [19:47<13:21,  6.17s/it]Loading train:  59%|█████▊    | 182/311 [19:53<13:03,  6.07s/it]Loading train:  59%|█████▉    | 183/311 [19:59<12:54,  6.05s/it]Loading train:  59%|█████▉    | 184/311 [20:05<12:47,  6.05s/it]Loading train:  59%|█████▉    | 185/311 [20:11<12:18,  5.86s/it]Loading train:  60%|█████▉    | 186/311 [20:16<12:02,  5.78s/it]Loading train:  60%|██████    | 187/311 [20:22<11:58,  5.79s/it]Loading train:  60%|██████    | 188/311 [20:28<11:55,  5.82s/it]Loading train:  61%|██████    | 189/311 [20:33<11:42,  5.76s/it]Loading train:  61%|██████    | 190/311 [20:39<11:21,  5.64s/it]Loading train:  61%|██████▏   | 191/311 [20:44<11:16,  5.64s/it]Loading train:  62%|██████▏   | 192/311 [20:50<11:09,  5.63s/it]Loading train:  62%|██████▏   | 193/311 [20:56<11:10,  5.68s/it]Loading train:  62%|██████▏   | 194/311 [21:01<10:51,  5.57s/it]Loading train:  63%|██████▎   | 195/311 [21:07<10:58,  5.68s/it]Loading train:  63%|██████▎   | 196/311 [21:13<10:53,  5.68s/it]Loading train:  63%|██████▎   | 197/311 [21:18<10:46,  5.67s/it]Loading train:  64%|██████▎   | 198/311 [21:24<10:37,  5.64s/it]Loading train:  64%|██████▍   | 199/311 [21:30<10:46,  5.77s/it]Loading train:  64%|██████▍   | 200/311 [21:36<10:40,  5.77s/it]Loading train:  65%|██████▍   | 201/311 [21:42<10:32,  5.75s/it]Loading train:  65%|██████▍   | 202/311 [21:47<10:22,  5.71s/it]Loading train:  65%|██████▌   | 203/311 [21:53<10:16,  5.71s/it]Loading train:  66%|██████▌   | 204/311 [21:59<10:17,  5.77s/it]Loading train:  66%|██████▌   | 205/311 [22:04<10:05,  5.71s/it]Loading train:  66%|██████▌   | 206/311 [22:10<09:58,  5.70s/it]Loading train:  67%|██████▋   | 207/311 [22:16<10:10,  5.87s/it]Loading train:  67%|██████▋   | 208/311 [22:22<09:57,  5.80s/it]Loading train:  67%|██████▋   | 209/311 [22:28<10:11,  6.00s/it]Loading train:  68%|██████▊   | 210/311 [22:34<09:59,  5.94s/it]Loading train:  68%|██████▊   | 211/311 [22:40<09:50,  5.90s/it]Loading train:  68%|██████▊   | 212/311 [22:46<09:46,  5.93s/it]Loading train:  68%|██████▊   | 213/311 [22:56<11:45,  7.20s/it]Loading train:  69%|██████▉   | 214/311 [23:07<13:17,  8.22s/it]Loading train:  69%|██████▉   | 215/311 [23:17<13:55,  8.71s/it]Loading train:  69%|██████▉   | 216/311 [23:27<14:39,  9.25s/it]Loading train:  70%|██████▉   | 217/311 [23:38<15:11,  9.69s/it]Loading train:  70%|███████   | 218/311 [23:49<15:34, 10.05s/it]Loading train:  70%|███████   | 219/311 [23:59<15:32, 10.13s/it]Loading train:  71%|███████   | 220/311 [24:09<15:25, 10.17s/it]Loading train:  71%|███████   | 221/311 [24:19<14:57,  9.97s/it]Loading train:  71%|███████▏  | 222/311 [24:28<14:34,  9.83s/it]Loading train:  72%|███████▏  | 223/311 [24:38<14:18,  9.76s/it]Loading train:  72%|███████▏  | 224/311 [24:47<13:58,  9.63s/it]Loading train:  72%|███████▏  | 225/311 [24:57<13:42,  9.56s/it]Loading train:  73%|███████▎  | 226/311 [25:06<13:26,  9.49s/it]Loading train:  73%|███████▎  | 227/311 [25:16<13:19,  9.51s/it]Loading train:  73%|███████▎  | 228/311 [25:25<13:09,  9.51s/it]Loading train:  74%|███████▎  | 229/311 [25:34<12:55,  9.45s/it]Loading train:  74%|███████▍  | 230/311 [25:44<12:50,  9.51s/it]Loading train:  74%|███████▍  | 231/311 [25:49<10:49,  8.11s/it]Loading train:  75%|███████▍  | 232/311 [25:54<09:19,  7.08s/it]Loading train:  75%|███████▍  | 233/311 [25:58<08:17,  6.38s/it]Loading train:  75%|███████▌  | 234/311 [26:03<07:38,  5.95s/it]Loading train:  76%|███████▌  | 235/311 [26:08<07:01,  5.55s/it]Loading train:  76%|███████▌  | 236/311 [26:13<06:37,  5.29s/it]Loading train:  76%|███████▌  | 237/311 [26:17<06:16,  5.09s/it]Loading train:  77%|███████▋  | 238/311 [26:22<06:00,  4.94s/it]Loading train:  77%|███████▋  | 239/311 [26:26<05:38,  4.70s/it]Loading train:  77%|███████▋  | 240/311 [26:30<05:25,  4.58s/it]Loading train:  77%|███████▋  | 241/311 [26:34<05:11,  4.46s/it]Loading train:  78%|███████▊  | 242/311 [26:39<05:05,  4.43s/it]Loading train:  78%|███████▊  | 243/311 [26:43<04:56,  4.36s/it]Loading train:  78%|███████▊  | 244/311 [26:47<04:49,  4.32s/it]Loading train:  79%|███████▉  | 245/311 [26:51<04:43,  4.30s/it]Loading train:  79%|███████▉  | 246/311 [26:56<04:44,  4.37s/it]Loading train:  79%|███████▉  | 247/311 [27:00<04:35,  4.30s/it]Loading train:  80%|███████▉  | 248/311 [27:04<04:30,  4.29s/it]Loading train:  80%|████████  | 249/311 [27:10<04:43,  4.57s/it]Loading train:  80%|████████  | 250/311 [27:15<04:51,  4.78s/it]Loading train:  81%|████████  | 251/311 [27:20<04:56,  4.95s/it]Loading train:  81%|████████  | 252/311 [27:26<04:58,  5.07s/it]Loading train:  81%|████████▏ | 253/311 [27:31<05:03,  5.24s/it]Loading train:  82%|████████▏ | 254/311 [27:37<05:02,  5.30s/it]Loading train:  82%|████████▏ | 255/311 [27:42<04:58,  5.34s/it]Loading train:  82%|████████▏ | 256/311 [27:48<04:57,  5.41s/it]Loading train:  83%|████████▎ | 257/311 [27:53<04:50,  5.39s/it]Loading train:  83%|████████▎ | 258/311 [27:58<04:45,  5.38s/it]Loading train:  83%|████████▎ | 259/311 [28:04<04:36,  5.32s/it]Loading train:  84%|████████▎ | 260/311 [28:09<04:33,  5.37s/it]Loading train:  84%|████████▍ | 261/311 [28:14<04:28,  5.37s/it]Loading train:  84%|████████▍ | 262/311 [28:20<04:22,  5.35s/it]Loading train:  85%|████████▍ | 263/311 [28:25<04:16,  5.35s/it]Loading train:  85%|████████▍ | 264/311 [28:30<04:09,  5.32s/it]Loading train:  85%|████████▌ | 265/311 [28:36<04:06,  5.35s/it]Loading train:  86%|████████▌ | 266/311 [28:41<04:00,  5.35s/it]Loading train:  86%|████████▌ | 267/311 [28:46<03:48,  5.20s/it]Loading train:  86%|████████▌ | 268/311 [28:51<03:45,  5.24s/it]Loading train:  86%|████████▋ | 269/311 [28:57<03:43,  5.31s/it]Loading train:  87%|████████▋ | 270/311 [29:02<03:35,  5.25s/it]Loading train:  87%|████████▋ | 271/311 [29:07<03:29,  5.23s/it]Loading train:  87%|████████▋ | 272/311 [29:13<03:28,  5.35s/it]Loading train:  88%|████████▊ | 273/311 [29:18<03:21,  5.31s/it]Loading train:  88%|████████▊ | 274/311 [29:23<03:15,  5.29s/it]Loading train:  88%|████████▊ | 275/311 [29:29<03:12,  5.33s/it]Loading train:  89%|████████▊ | 276/311 [29:34<03:08,  5.39s/it]Loading train:  89%|████████▉ | 277/311 [29:39<03:01,  5.35s/it]Loading train:  89%|████████▉ | 278/311 [29:45<02:55,  5.33s/it]Loading train:  90%|████████▉ | 279/311 [29:50<02:50,  5.33s/it]Loading train:  90%|█████████ | 280/311 [29:55<02:44,  5.32s/it]Loading train:  90%|█████████ | 281/311 [30:01<02:39,  5.33s/it]Loading train:  91%|█████████ | 282/311 [30:06<02:36,  5.39s/it]Loading train:  91%|█████████ | 283/311 [30:11<02:24,  5.15s/it]Loading train:  91%|█████████▏| 284/311 [30:15<02:14,  4.98s/it]Loading train:  92%|█████████▏| 285/311 [30:20<02:09,  4.99s/it]Loading train:  92%|█████████▏| 286/311 [30:25<02:04,  4.97s/it]Loading train:  92%|█████████▏| 287/311 [30:30<01:58,  4.95s/it]Loading train:  93%|█████████▎| 288/311 [30:35<01:53,  4.95s/it]Loading train:  93%|█████████▎| 289/311 [30:40<01:49,  4.96s/it]Loading train:  93%|█████████▎| 290/311 [30:45<01:43,  4.93s/it]Loading train:  94%|█████████▎| 291/311 [30:50<01:39,  5.00s/it]Loading train:  94%|█████████▍| 292/311 [30:55<01:35,  5.03s/it]Loading train:  94%|█████████▍| 293/311 [31:00<01:29,  4.99s/it]Loading train:  95%|█████████▍| 294/311 [31:05<01:25,  5.04s/it]Loading train:  95%|█████████▍| 295/311 [31:10<01:21,  5.09s/it]Loading train:  95%|█████████▌| 296/311 [31:15<01:13,  4.91s/it]Loading train:  95%|█████████▌| 297/311 [31:20<01:09,  4.94s/it]Loading train:  96%|█████████▌| 298/311 [31:25<01:04,  4.99s/it]Loading train:  96%|█████████▌| 299/311 [31:30<00:59,  4.96s/it]Loading train:  96%|█████████▋| 300/311 [31:35<00:54,  4.94s/it]Loading train:  97%|█████████▋| 301/311 [31:40<00:50,  5.02s/it]Loading train:  97%|█████████▋| 302/311 [31:45<00:44,  4.97s/it]Loading train:  97%|█████████▋| 303/311 [31:50<00:39,  4.89s/it]Loading train:  98%|█████████▊| 304/311 [31:54<00:34,  4.87s/it]Loading train:  98%|█████████▊| 305/311 [31:59<00:29,  4.92s/it]Loading train:  98%|█████████▊| 306/311 [32:04<00:24,  4.83s/it]Loading train:  99%|█████████▊| 307/311 [32:09<00:19,  4.81s/it]Loading train:  99%|█████████▉| 308/311 [32:14<00:14,  4.90s/it]Loading train:  99%|█████████▉| 309/311 [32:19<00:09,  4.92s/it]Loading train: 100%|█████████▉| 310/311 [32:24<00:04,  4.88s/it]Loading train: 100%|██████████| 311/311 [32:29<00:00,  4.95s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/311 [00:00<00:04, 60.83it/s]concatenating: train:   7%|▋         | 21/311 [00:00<00:03, 72.78it/s]concatenating: train:  14%|█▍        | 44/311 [00:00<00:02, 91.26it/s]concatenating: train:  24%|██▍       | 74/311 [00:00<00:02, 115.28it/s]concatenating: train:  31%|███       | 95/311 [00:00<00:01, 132.83it/s]concatenating: train:  37%|███▋      | 116/311 [00:00<00:01, 148.68it/s]concatenating: train:  45%|████▌     | 141/311 [00:00<00:01, 165.42it/s]concatenating: train:  55%|█████▌    | 172/311 [00:00<00:00, 191.97it/s]concatenating: train:  63%|██████▎   | 195/311 [00:00<00:00, 196.87it/s]concatenating: train:  70%|███████   | 219/311 [00:01<00:00, 207.78it/s]concatenating: train:  78%|███████▊  | 244/311 [00:01<00:00, 214.18it/s]concatenating: train:  88%|████████▊ | 273/311 [00:01<00:00, 231.52it/s]concatenating: train:  96%|█████████▌| 298/311 [00:01<00:00, 231.66it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 220.38it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:33, 11.25s/it]Loading test:  50%|█████     | 2/4 [00:22<00:22, 11.13s/it]Loading test:  75%|███████▌  | 3/4 [00:34<00:11, 11.36s/it]Loading test: 100%|██████████| 4/4 [00:45<00:00, 11.36s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 60.65it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-08 08:02:18.529549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 08:02:18.529675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 08:02:18.529693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 08:02:18.529703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 08:02:18.530136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 40, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [5.87995836e-02 2.85625934e-02 1.22042724e-01 1.04920441e-02
 3.15682606e-02 5.46103058e-03 7.22892131e-02 1.13259646e-01
 7.87837639e-02 1.27868129e-02 2.92912776e-01 1.72791632e-01
 2.49918858e-04]
Train on 12355 samples, validate on 158 samples
Epoch 1/300
 - 24s - loss: 21472.2247 - acc: 0.8485 - mDice: 0.1906 - val_loss: 7231.1260 - val_acc: 0.8803 - val_mDice: 0.3453

Epoch 00001: val_mDice improved from -inf to 0.34527, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 6368.9585 - acc: 0.8899 - mDice: 0.4428 - val_loss: 4663.4835 - val_acc: 0.8956 - val_mDice: 0.5021

Epoch 00002: val_mDice improved from 0.34527 to 0.50206, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 4561.8464 - acc: 0.9147 - mDice: 0.5511 - val_loss: 3707.2469 - val_acc: 0.9183 - val_mDice: 0.5692

Epoch 00003: val_mDice improved from 0.50206 to 0.56924, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 15s - loss: 3789.8183 - acc: 0.9263 - mDice: 0.6085 - val_loss: 3372.9585 - val_acc: 0.9297 - val_mDice: 0.6005

Epoch 00004: val_mDice improved from 0.56924 to 0.60053, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 3390.8959 - acc: 0.9316 - mDice: 0.6406 - val_loss: 3087.4532 - val_acc: 0.9352 - val_mDice: 0.6278

Epoch 00005: val_mDice improved from 0.60053 to 0.62775, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 15s - loss: 3140.5627 - acc: 0.9350 - mDice: 0.6620 - val_loss: 2861.3612 - val_acc: 0.9393 - val_mDice: 0.6480

Epoch 00006: val_mDice improved from 0.62775 to 0.64798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 2949.3963 - acc: 0.9375 - mDice: 0.6786 - val_loss: 2846.9511 - val_acc: 0.9396 - val_mDice: 0.6487

Epoch 00007: val_mDice improved from 0.64798 to 0.64871, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 15s - loss: 2803.9162 - acc: 0.9394 - mDice: 0.6913 - val_loss: 2732.8498 - val_acc: 0.9421 - val_mDice: 0.6622

Epoch 00008: val_mDice improved from 0.64871 to 0.66220, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 15s - loss: 2677.5241 - acc: 0.9409 - mDice: 0.7027 - val_loss: 2692.9800 - val_acc: 0.9429 - val_mDice: 0.6651

Epoch 00009: val_mDice improved from 0.66220 to 0.66507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 15s - loss: 2577.9497 - acc: 0.9424 - mDice: 0.7118 - val_loss: 2605.9069 - val_acc: 0.9445 - val_mDice: 0.6736

Epoch 00010: val_mDice improved from 0.66507 to 0.67361, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 2486.9909 - acc: 0.9436 - mDice: 0.7204 - val_loss: 2676.4487 - val_acc: 0.9452 - val_mDice: 0.6688

Epoch 00011: val_mDice did not improve from 0.67361
Epoch 12/300
 - 15s - loss: 2406.2974 - acc: 0.9446 - mDice: 0.7280 - val_loss: 2588.9908 - val_acc: 0.9447 - val_mDice: 0.6767

Epoch 00012: val_mDice improved from 0.67361 to 0.67669, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 15s - loss: 2338.9603 - acc: 0.9454 - mDice: 0.7343 - val_loss: 2542.4258 - val_acc: 0.9468 - val_mDice: 0.6808

Epoch 00013: val_mDice improved from 0.67669 to 0.68076, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 15s - loss: 2283.9540 - acc: 0.9461 - mDice: 0.7396 - val_loss: 2510.0883 - val_acc: 0.9467 - val_mDice: 0.6845

Epoch 00014: val_mDice improved from 0.68076 to 0.68445, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 2226.6983 - acc: 0.9469 - mDice: 0.7451 - val_loss: 2593.7182 - val_acc: 0.9469 - val_mDice: 0.6795

Epoch 00015: val_mDice did not improve from 0.68445
Epoch 16/300
 - 15s - loss: 2174.8838 - acc: 0.9475 - mDice: 0.7501 - val_loss: 2486.7092 - val_acc: 0.9500 - val_mDice: 0.6866

Epoch 00016: val_mDice improved from 0.68445 to 0.68661, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 15s - loss: 2119.4608 - acc: 0.9481 - mDice: 0.7554 - val_loss: 2595.5274 - val_acc: 0.9474 - val_mDice: 0.6769

Epoch 00017: val_mDice did not improve from 0.68661
Epoch 18/300
 - 15s - loss: 2080.6855 - acc: 0.9487 - mDice: 0.7592 - val_loss: 2530.7540 - val_acc: 0.9486 - val_mDice: 0.6844

Epoch 00018: val_mDice did not improve from 0.68661
Epoch 19/300
 - 15s - loss: 2038.3494 - acc: 0.9492 - mDice: 0.7635 - val_loss: 2536.0060 - val_acc: 0.9488 - val_mDice: 0.6842

Epoch 00019: val_mDice did not improve from 0.68661
Epoch 20/300
 - 15s - loss: 1992.9627 - acc: 0.9497 - mDice: 0.7680 - val_loss: 2520.7952 - val_acc: 0.9501 - val_mDice: 0.6856

Epoch 00020: val_mDice did not improve from 0.68661
Epoch 21/300
 - 16s - loss: 1971.2787 - acc: 0.9503 - mDice: 0.7702 - val_loss: 2670.8912 - val_acc: 0.9476 - val_mDice: 0.6726

Epoch 00021: val_mDice did not improve from 0.68661
Epoch 22/300
 - 15s - loss: 1929.5700 - acc: 0.9508 - mDice: 0.7743 - val_loss: 2393.5754 - val_acc: 0.9529 - val_mDice: 0.6966

Epoch 00022: val_mDice improved from 0.68661 to 0.69660, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 16s - loss: 1903.2286 - acc: 0.9511 - mDice: 0.7771 - val_loss: 2496.1889 - val_acc: 0.9507 - val_mDice: 0.6880

Epoch 00023: val_mDice did not improve from 0.69660
Epoch 24/300
 - 15s - loss: 1859.7236 - acc: 0.9515 - mDice: 0.7815 - val_loss: 2622.0357 - val_acc: 0.9485 - val_mDice: 0.6758

Epoch 00024: val_mDice did not improve from 0.69660
Epoch 25/300
 - 16s - loss: 1837.2178 - acc: 0.9519 - mDice: 0.7838 - val_loss: 2803.4687 - val_acc: 0.9480 - val_mDice: 0.6658

Epoch 00025: val_mDice did not improve from 0.69660
Epoch 26/300
 - 15s - loss: 1812.9763 - acc: 0.9522 - mDice: 0.7863 - val_loss: 2685.8026 - val_acc: 0.9498 - val_mDice: 0.6720

Epoch 00026: val_mDice did not improve from 0.69660
Epoch 27/300
 - 16s - loss: 1787.0086 - acc: 0.9525 - mDice: 0.7889 - val_loss: 2750.9944 - val_acc: 0.9472 - val_mDice: 0.6665

Epoch 00027: val_mDice did not improve from 0.69660
Epoch 28/300
 - 15s - loss: 1758.2911 - acc: 0.9529 - mDice: 0.7919 - val_loss: 2494.8562 - val_acc: 0.9533 - val_mDice: 0.6880

Epoch 00028: val_mDice did not improve from 0.69660
Epoch 29/300
 - 16s - loss: 1738.5918 - acc: 0.9532 - mDice: 0.7940 - val_loss: 2429.1219 - val_acc: 0.9532 - val_mDice: 0.6934

Epoch 00029: val_mDice did not improve from 0.69660
Epoch 30/300
 - 15s - loss: 1702.8646 - acc: 0.9535 - mDice: 0.7976 - val_loss: 2471.2665 - val_acc: 0.9536 - val_mDice: 0.6898

Epoch 00030: val_mDice did not improve from 0.69660
Epoch 31/300
 - 16s - loss: 1687.3254 - acc: 0.9538 - mDice: 0.7993 - val_loss: 2533.7583 - val_acc: 0.9528 - val_mDice: 0.6851

Epoch 00031: val_mDice did not improve from 0.69660
Epoch 32/300
 - 15s - loss: 1658.6949 - acc: 0.9541 - mDice: 0.8023 - val_loss: 2403.3196 - val_acc: 0.9542 - val_mDice: 0.6954

Epoch 00032: val_mDice did not improve from 0.69660
Epoch 33/300
 - 16s - loss: 1643.0195 - acc: 0.9543 - mDice: 0.8039 - val_loss: 2669.6190 - val_acc: 0.9521 - val_mDice: 0.6748

Epoch 00033: val_mDice did not improve from 0.69660
Epoch 34/300
 - 15s - loss: 1619.7333 - acc: 0.9546 - mDice: 0.8064 - val_loss: 2744.1896 - val_acc: 0.9510 - val_mDice: 0.6654

Epoch 00034: val_mDice did not improve from 0.69660
Epoch 35/300
 - 16s - loss: 1590.1284 - acc: 0.9549 - mDice: 0.8095 - val_loss: 2568.0801 - val_acc: 0.9523 - val_mDice: 0.6816

Epoch 00035: val_mDice did not improve from 0.69660
Epoch 36/300
 - 15s - loss: 1582.2503 - acc: 0.9551 - mDice: 0.8103 - val_loss: 2631.1528 - val_acc: 0.9501 - val_mDice: 0.6795

Epoch 00036: val_mDice did not improve from 0.69660
Epoch 37/300
 - 16s - loss: 1563.6580 - acc: 0.9553 - mDice: 0.8124 - val_loss: 2502.1220 - val_acc: 0.9536 - val_mDice: 0.6858

Epoch 00037: val_mDice did not improve from 0.69660
Epoch 38/300
 - 15s - loss: 1538.7410 - acc: 0.9556 - mDice: 0.8150 - val_loss: 2567.3234 - val_acc: 0.9541 - val_mDice: 0.6845

Epoch 00038: val_mDice did not improve from 0.69660
Epoch 39/300
 - 15s - loss: 1523.5941 - acc: 0.9558 - mDice: 0.8166 - val_loss: 2408.4065 - val_acc: 0.9545 - val_mDice: 0.6947

Epoch 00039: val_mDice did not improve from 0.69660
Epoch 40/300
 - 15s - loss: 1517.0374 - acc: 0.9559 - mDice: 0.8173 - val_loss: 2659.4179 - val_acc: 0.9490 - val_mDice: 0.6731

Epoch 00040: val_mDice did not improve from 0.69660
Epoch 41/300
 - 15s - loss: 1495.0530 - acc: 0.9562 - mDice: 0.8197 - val_loss: 2929.5308 - val_acc: 0.9472 - val_mDice: 0.6487

Epoch 00041: val_mDice did not improve from 0.69660
Epoch 42/300
 - 15s - loss: 1478.0024 - acc: 0.9564 - mDice: 0.8216 - val_loss: 2438.8480 - val_acc: 0.9547 - val_mDice: 0.6936

Epoch 00042: val_mDice did not improve from 0.69660
Epoch 43/300
 - 15s - loss: 1455.9590 - acc: 0.9566 - mDice: 0.8240 - val_loss: 2484.3249 - val_acc: 0.9534 - val_mDice: 0.6863

Epoch 00043: val_mDice did not improve from 0.69660
Epoch 44/300
 - 15s - loss: 1445.8999 - acc: 0.9567 - mDice: 0.8250 - val_loss: 2544.6008 - val_acc: 0.9524 - val_mDice: 0.6825

Epoch 00044: val_mDice did not improve from 0.69660
Epoch 45/300
 - 15s - loss: 1434.9303 - acc: 0.9569 - mDice: 0.8262 - val_loss: 2521.1894 - val_acc: 0.9511 - val_mDice: 0.6843

Epoch 00045: val_mDice did not improve from 0.69660
Epoch 46/300
 - 15s - loss: 1418.1528 - acc: 0.9570 - mDice: 0.8281 - val_loss: 2384.3542 - val_acc: 0.9546 - val_mDice: 0.6977

Epoch 00046: val_mDice improved from 0.69660 to 0.69772, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 15s - loss: 1404.8037 - acc: 0.9572 - mDice: 0.8295 - val_loss: 2631.6716 - val_acc: 0.9516 - val_mDice: 0.6717

Epoch 00047: val_mDice did not improve from 0.69772
Epoch 48/300
 - 15s - loss: 1404.5698 - acc: 0.9573 - mDice: 0.8296 - val_loss: 2536.9512 - val_acc: 0.9520 - val_mDice: 0.6826

Epoch 00048: val_mDice did not improve from 0.69772
Epoch 49/300
 - 15s - loss: 1380.7575 - acc: 0.9576 - mDice: 0.8322 - val_loss: 2401.2917 - val_acc: 0.9537 - val_mDice: 0.6954

Epoch 00049: val_mDice did not improve from 0.69772
Epoch 50/300
 - 15s - loss: 1372.2879 - acc: 0.9576 - mDice: 0.8331 - val_loss: 2551.6131 - val_acc: 0.9535 - val_mDice: 0.6818

Epoch 00050: val_mDice did not improve from 0.69772
Epoch 51/300
 - 15s - loss: 1357.7539 - acc: 0.9578 - mDice: 0.8347 - val_loss: 2436.2667 - val_acc: 0.9551 - val_mDice: 0.6927

Epoch 00051: val_mDice did not improve from 0.69772
Epoch 52/300
 - 16s - loss: 1341.7035 - acc: 0.9580 - mDice: 0.8365 - val_loss: 2815.2267 - val_acc: 0.9510 - val_mDice: 0.6581

Epoch 00052: val_mDice did not improve from 0.69772
Epoch 53/300
 - 15s - loss: 1327.6283 - acc: 0.9581 - mDice: 0.8380 - val_loss: 2442.4205 - val_acc: 0.9539 - val_mDice: 0.6911

Epoch 00053: val_mDice did not improve from 0.69772
Epoch 54/300
 - 16s - loss: 1322.3111 - acc: 0.9582 - mDice: 0.8387 - val_loss: 2529.1263 - val_acc: 0.9518 - val_mDice: 0.6831

Epoch 00054: val_mDice did not improve from 0.69772
Epoch 55/300
 - 15s - loss: 1306.1379 - acc: 0.9584 - mDice: 0.8405 - val_loss: 2466.6354 - val_acc: 0.9540 - val_mDice: 0.6883

Epoch 00055: val_mDice did not improve from 0.69772
Epoch 56/300
 - 16s - loss: 1298.0659 - acc: 0.9586 - mDice: 0.8414 - val_loss: 2792.8424 - val_acc: 0.9496 - val_mDice: 0.6612

Epoch 00056: val_mDice did not improve from 0.69772
Epoch 57/300
 - 15s - loss: 1284.8463 - acc: 0.9588 - mDice: 0.8429 - val_loss: 2821.4072 - val_acc: 0.9482 - val_mDice: 0.6593

Epoch 00057: val_mDice did not improve from 0.69772
Epoch 58/300
 - 16s - loss: 1277.2532 - acc: 0.9588 - mDice: 0.8437 - val_loss: 2459.5034 - val_acc: 0.9544 - val_mDice: 0.6895

Epoch 00058: val_mDice did not improve from 0.69772
Epoch 59/300
 - 15s - loss: 1258.4742 - acc: 0.9590 - mDice: 0.8457 - val_loss: 2517.1828 - val_acc: 0.9540 - val_mDice: 0.6860

Epoch 00059: val_mDice did not improve from 0.69772
Epoch 60/300
 - 16s - loss: 1247.3819 - acc: 0.9592 - mDice: 0.8470 - val_loss: 2548.1246 - val_acc: 0.9544 - val_mDice: 0.6803

Epoch 00060: val_mDice did not improve from 0.69772
Epoch 61/300
 - 15s - loss: 1246.1876 - acc: 0.9592 - mDice: 0.8471 - val_loss: 2445.1169 - val_acc: 0.9542 - val_mDice: 0.6903

Epoch 00061: val_mDice did not improve from 0.69772
Epoch 62/300
 - 16s - loss: 1239.0785 - acc: 0.9594 - mDice: 0.8480 - val_loss: 2425.0157 - val_acc: 0.9540 - val_mDice: 0.6933

Epoch 00062: val_mDice did not improve from 0.69772
Epoch 63/300
 - 15s - loss: 1232.8964 - acc: 0.9594 - mDice: 0.8487 - val_loss: 2423.9474 - val_acc: 0.9554 - val_mDice: 0.6925

Epoch 00063: val_mDice did not improve from 0.69772
Epoch 64/300
 - 15s - loss: 1217.0494 - acc: 0.9596 - mDice: 0.8504 - val_loss: 2540.5065 - val_acc: 0.9538 - val_mDice: 0.6826

Epoch 00064: val_mDice did not improve from 0.69772
Epoch 65/300
 - 15s - loss: 1215.5715 - acc: 0.9596 - mDice: 0.8506 - val_loss: 2473.7638 - val_acc: 0.9535 - val_mDice: 0.6875

Epoch 00065: val_mDice did not improve from 0.69772
Epoch 66/300
 - 16s - loss: 1201.5890 - acc: 0.9597 - mDice: 0.8522 - val_loss: 2521.3707 - val_acc: 0.9539 - val_mDice: 0.6840

Epoch 00066: val_mDice did not improve from 0.69772
Epoch 67/300
 - 15s - loss: 1192.1223 - acc: 0.9599 - mDice: 0.8533 - val_loss: 2583.5428 - val_acc: 0.9540 - val_mDice: 0.6771

Epoch 00067: val_mDice did not improve from 0.69772
Epoch 68/300
 - 16s - loss: 1181.2718 - acc: 0.9600 - mDice: 0.8545 - val_loss: 2683.9688 - val_acc: 0.9515 - val_mDice: 0.6685

Epoch 00068: val_mDice did not improve from 0.69772
Epoch 69/300
 - 15s - loss: 1179.5800 - acc: 0.9600 - mDice: 0.8547 - val_loss: 2599.2359 - val_acc: 0.9545 - val_mDice: 0.6781

Epoch 00069: val_mDice did not improve from 0.69772
Epoch 70/300
 - 15s - loss: 1166.3055 - acc: 0.9602 - mDice: 0.8562 - val_loss: 2642.3952 - val_acc: 0.9530 - val_mDice: 0.6733

Epoch 00070: val_mDice did not improve from 0.69772
Epoch 71/300
 - 15s - loss: 1162.4025 - acc: 0.9603 - mDice: 0.8566 - val_loss: 2589.8594 - val_acc: 0.9532 - val_mDice: 0.6769

Epoch 00071: val_mDice did not improve from 0.69772
Epoch 72/300
 - 15s - loss: 1148.3571 - acc: 0.9603 - mDice: 0.8582 - val_loss: 2449.9201 - val_acc: 0.9558 - val_mDice: 0.6913

Epoch 00072: val_mDice did not improve from 0.69772
Epoch 73/300
 - 15s - loss: 1140.8451 - acc: 0.9605 - mDice: 0.8591 - val_loss: 2669.7692 - val_acc: 0.9511 - val_mDice: 0.6702

Epoch 00073: val_mDice did not improve from 0.69772
Epoch 74/300
 - 15s - loss: 1130.2844 - acc: 0.9606 - mDice: 0.8603 - val_loss: 2538.8408 - val_acc: 0.9521 - val_mDice: 0.6846

Epoch 00074: val_mDice did not improve from 0.69772
Epoch 75/300
 - 16s - loss: 1125.5896 - acc: 0.9606 - mDice: 0.8608 - val_loss: 2501.5625 - val_acc: 0.9539 - val_mDice: 0.6867

Epoch 00075: val_mDice did not improve from 0.69772
Epoch 76/300
 - 15s - loss: 1115.4483 - acc: 0.9607 - mDice: 0.8620 - val_loss: 2397.8792 - val_acc: 0.9551 - val_mDice: 0.6952

Epoch 00076: val_mDice did not improve from 0.69772
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [7231.125964200949, 4663.48346333564, 3707.2468601661394, 3372.9585455399524, 3087.4531744462024, 2861.361236958564, 2846.9511193384096, 2732.849845789656, 2692.9799742879745, 2605.906898981408, 2676.4486624802216, 2588.9908184582673, 2542.4257843403875, 2510.088250655162, 2593.7182030013846, 2486.7091991569423, 2595.5274009221716, 2530.7539680577534, 2536.0059845357, 2520.795249456092, 2670.8911534562894, 2393.575430181962, 2496.1888844936707, 2622.035723336135, 2803.468694373022, 2685.8025613132913, 2750.9943909464005, 2494.8561517256726, 2429.121867892108, 2471.266545935522, 2533.758254425435, 2403.3195769877375, 2669.6189582921284, 2744.189627731903, 2568.0801368423654, 2631.1528335764438, 2502.1220455893986, 2567.3234059780457, 2408.40652040892, 2659.4178791287577, 2929.5307740803005, 2438.847965288766, 2484.3249202679986, 2544.600788357892, 2521.1893820460837, 2384.3542140526106, 2631.6716339497625, 2536.9512429539163, 2401.291656880439, 2551.613054106507, 2436.2667159068433, 2815.226672208762, 2442.4204719640034, 2529.1263443186313, 2466.6354176967957, 2792.8423562351663, 2821.407166299941, 2459.50341796875, 2517.1827578001385, 2548.124646150613, 2445.1168753708466, 2425.015731618374, 2423.9474232347707, 2540.506531534316, 2473.7638294847707, 2521.3706672765034, 2583.542761694027, 2683.9687809038764, 2599.2358923803404, 2642.395157053501, 2589.8593626384495, 2449.920142837718, 2669.769171219838, 2538.840764685522, 2501.562462915348, 2397.87919674644], 'val_acc': [0.8802701845953737, 0.8956152660937249, 0.9182813748528685, 0.9296829489213002, 0.935181330276441, 0.9392983332464967, 0.9396117412591283, 0.9421099190470539, 0.942920822885972, 0.9444635691522043, 0.9452257873136786, 0.9447374132615102, 0.946789788294442, 0.9466513644290876, 0.9469145642051214, 0.9500076227550265, 0.9474059818666193, 0.9486398530911796, 0.9487676371501971, 0.9501156391976755, 0.9476326696480377, 0.9529439316520208, 0.9506511763681339, 0.9485302824008314, 0.9479978031749967, 0.9497763627692114, 0.9472020894666261, 0.9533456081076513, 0.9532071683980241, 0.9536179583283919, 0.9527628806572926, 0.9541763067245483, 0.9521299721319464, 0.9509980369217789, 0.9522608360157737, 0.9500760926476007, 0.9536194507079788, 0.9540926202943053, 0.9544562297531322, 0.948968473869034, 0.9472462361371969, 0.9547072792355018, 0.95341100345684, 0.9523703621912606, 0.9510999917984009, 0.954646444018883, 0.9516309673273111, 0.9519565429868577, 0.9537031597728971, 0.9535160132601291, 0.9550967465473127, 0.9510300068915645, 0.953934419004223, 0.9518333145334751, 0.9540469759627234, 0.9495952853673622, 0.9482153759726996, 0.9543512689916394, 0.9539830722386324, 0.9544455869288384, 0.9541854232172423, 0.9539663663393334, 0.9554390756389762, 0.9537807401222519, 0.953509920760046, 0.9539283174502698, 0.953995250448396, 0.9514681583718408, 0.9545110320743126, 0.9529835121541084, 0.9531873728655562, 0.9557661678217635, 0.9511197714865962, 0.9520904436896119, 0.9538537648659718, 0.955064811284029], 'val_mDice': [0.3452677349501018, 0.5020578865763508, 0.5692360355884214, 0.6005274743973454, 0.6277509195895135, 0.647979052760933, 0.648714217958571, 0.6622001415566553, 0.6650655020641375, 0.6736076225208331, 0.6688449375237091, 0.6766908387594586, 0.6807630824137337, 0.6844505562057978, 0.6794885555400124, 0.6866056768200065, 0.6769469327564481, 0.6843631765510463, 0.684209371669383, 0.6856375600718245, 0.6726462961752203, 0.6966002847574935, 0.6880361573605598, 0.6758007595810709, 0.6658401210096818, 0.6719951886164991, 0.6664796720577192, 0.6880364387850219, 0.6933784711210034, 0.689840862268134, 0.6850910986526103, 0.6953511660612082, 0.674809719942793, 0.6653846698471263, 0.6816484120827687, 0.6794649777533133, 0.6858302920679503, 0.6844541588916054, 0.6947485947910743, 0.6730806646467764, 0.648721802838241, 0.6936029044887687, 0.6862668078156966, 0.6825208890287182, 0.6843341211729412, 0.6977163077909735, 0.6717308073104182, 0.682562387442287, 0.6954161124893382, 0.6817565688604041, 0.6926644135125076, 0.6580787014357651, 0.6910907437529745, 0.6830740774734111, 0.6883032555821575, 0.6612127981608427, 0.6592687730547748, 0.6895466959929164, 0.6859949072705039, 0.6803251897232442, 0.6902875719191153, 0.6932973371276373, 0.6925219674653644, 0.6825954076610034, 0.6874783333343796, 0.6840269437319115, 0.6770757866811149, 0.6685378219507918, 0.6781411774550812, 0.6732648475260674, 0.6768814280063291, 0.6912975824331935, 0.6701950989192045, 0.6845878453194341, 0.6867230617547337, 0.6951835268660437], 'loss': [21472.224738608482, 6368.958476135674, 4561.846375870251, 3789.8182687732383, 3390.8958875593603, 3140.5626510688044, 2949.396311223869, 2803.9161656069787, 2677.5240820865793, 2577.9497234818423, 2486.9909133447995, 2406.2973521165836, 2338.960266977802, 2283.9539767257215, 2226.698313769808, 2174.8838245819475, 2119.4608040674166, 2080.685499894479, 2038.3493981602605, 1992.962748250803, 1971.278739728507, 1929.5700082875417, 1903.2286208001094, 1859.7235722466548, 1837.2178170093396, 1812.9762643638867, 1787.0086045490978, 1758.2910587028277, 1738.5918494625546, 1702.864582427645, 1687.3253946956572, 1658.6948601581075, 1643.0194973607913, 1619.733313393371, 1590.12840623597, 1582.250293764109, 1563.658002580915, 1538.7410493956456, 1523.5941336742542, 1517.0373564549952, 1495.0530103546846, 1478.002386966151, 1455.959005370501, 1445.899863959034, 1434.930333247507, 1418.1527770971393, 1404.8036740842208, 1404.569801963519, 1380.757483735156, 1372.2879286935483, 1357.7538985928172, 1341.7034905687221, 1327.6283215376493, 1322.311057238577, 1306.137922730826, 1298.0659080885143, 1284.8462904309126, 1277.2532465713607, 1258.4742359267898, 1247.381928737614, 1246.187594677359, 1239.0784812813006, 1232.8963987133561, 1217.0493833942483, 1215.5715069463986, 1201.588956504831, 1192.1223157622562, 1181.2717548958544, 1179.580038011243, 1166.305509115703, 1162.40248834725, 1148.3571175143381, 1140.8451035181938, 1130.284357605845, 1125.5896283361603, 1115.44834444794], 'acc': [0.8484799072405723, 0.8899466513091859, 0.9147017114995125, 0.9263078062122334, 0.9315501764109143, 0.9350416522574106, 0.9375408967223451, 0.9394232712984567, 0.9409443389930401, 0.9424044473940233, 0.9436097009516785, 0.9445660619637302, 0.9454041692661592, 0.9460776139733666, 0.9468719061691719, 0.9474550960807847, 0.9481319840356726, 0.9486742182233371, 0.9492462783967469, 0.9497487187289072, 0.9502720013170385, 0.9507556902353989, 0.9511439239916074, 0.9515461285362259, 0.9519081519278183, 0.9522213664724488, 0.952539944204904, 0.9528816007303834, 0.9531724149039379, 0.9534997140671356, 0.9538424393755374, 0.95407548632423, 0.9542558455650548, 0.954609159466131, 0.9549155002516418, 0.9550736995179467, 0.9552947068349498, 0.9556159331508128, 0.9557689401071982, 0.9558679910383452, 0.956170423003837, 0.9563974394628463, 0.9566097702636549, 0.956730536269254, 0.9569405682749808, 0.9569911568187017, 0.9572012458239331, 0.9573078493220948, 0.9575511320116837, 0.9576413280468921, 0.9578344759937242, 0.9580310239380837, 0.9581205653111879, 0.9582426534013582, 0.9584408958447409, 0.9585814292688497, 0.9587871620694619, 0.9588124167094197, 0.9589868249414615, 0.9591611536202379, 0.9592057468919125, 0.9593662271997505, 0.9593723728945264, 0.9595729328514062, 0.959573084938531, 0.9597270060820601, 0.9599001078121289, 0.9600003304533609, 0.9599922717654816, 0.9601775783124311, 0.9602530893407241, 0.9603473950088482, 0.9604607489802779, 0.9606001331274542, 0.9606164386039897, 0.9607362905430533], 'mDice': [0.19060289830976485, 0.4428154232288748, 0.5510759475210908, 0.6084541549377719, 0.640642248875021, 0.6619906614831178, 0.6786451877152471, 0.6913136132378078, 0.7027198664575682, 0.7118261565760725, 0.7203763266508997, 0.7280059557412617, 0.7342794797817062, 0.7395609170499962, 0.7450640879146293, 0.750103753088747, 0.7554412478138589, 0.7592382273274556, 0.7634975341880239, 0.7679842947369787, 0.7701986477665456, 0.7743348629548935, 0.7771089471143926, 0.781505363424603, 0.7838033504787122, 0.7862512397891546, 0.7888794047105945, 0.7919226090756566, 0.7940304964865234, 0.7976235118244207, 0.7993205186086645, 0.8022765901251777, 0.8039058751540838, 0.8063623658417208, 0.8095285835559433, 0.8103402786918711, 0.8123911612191117, 0.8149740623105928, 0.8166497220929361, 0.8173401146367318, 0.8196687624551949, 0.8215583326458593, 0.8239624679016228, 0.8250381922924485, 0.8262403927945454, 0.8280640899387268, 0.8295488832499613, 0.8295562142835653, 0.8321871390857951, 0.8331354071813187, 0.8347269843243144, 0.8364976146644737, 0.8380431460494795, 0.8386666344419176, 0.8404501223554499, 0.841371911419205, 0.8428607000748863, 0.8436589558951433, 0.8457375417494765, 0.8470499569807203, 0.8471467719296124, 0.847983777137094, 0.8486501525066874, 0.850387547311393, 0.850645883731734, 0.8521957934409295, 0.8532657515708371, 0.8544981170887409, 0.8547099114477466, 0.8562091830673125, 0.8565958370230353, 0.8582117034085411, 0.8591143682580976, 0.860258878459336, 0.8608363520177643, 0.8619924203339302]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:42, 14.27s/it]predicting test subjects:  50%|█████     | 2/4 [00:27<00:27, 13.95s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:41<00:13, 14.00s/it]predicting test subjects: 100%|██████████| 4/4 [00:54<00:00, 13.80s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:21<1:49:06, 21.12s/it]predicting train subjects:   1%|          | 2/311 [00:30<1:31:02, 17.68s/it]predicting train subjects:   1%|          | 3/311 [00:43<1:22:31, 16.08s/it]predicting train subjects:   1%|▏         | 4/311 [00:55<1:16:14, 14.90s/it]predicting train subjects:   2%|▏         | 5/311 [01:06<1:10:02, 13.74s/it]predicting train subjects:   2%|▏         | 6/311 [01:17<1:05:18, 12.85s/it]predicting train subjects:   2%|▏         | 7/311 [01:29<1:04:58, 12.83s/it]predicting train subjects:   3%|▎         | 8/311 [01:44<1:07:42, 13.41s/it]predicting train subjects:   3%|▎         | 9/311 [01:58<1:07:37, 13.43s/it]predicting train subjects:   3%|▎         | 10/311 [02:09<1:03:46, 12.71s/it]predicting train subjects:   4%|▎         | 11/311 [02:23<1:06:36, 13.32s/it]predicting train subjects:   4%|▍         | 12/311 [02:34<1:02:59, 12.64s/it]predicting train subjects:   4%|▍         | 13/311 [02:46<1:00:36, 12.20s/it]predicting train subjects:   5%|▍         | 14/311 [03:00<1:03:51, 12.90s/it]predicting train subjects:   5%|▍         | 15/311 [03:21<1:15:19, 15.27s/it]predicting train subjects:   5%|▌         | 16/311 [03:42<1:23:03, 16.89s/it]predicting train subjects:   5%|▌         | 17/311 [04:04<1:30:24, 18.45s/it]predicting train subjects:   6%|▌         | 18/311 [04:24<1:32:56, 19.03s/it]predicting train subjects:   6%|▌         | 19/311 [04:46<1:36:49, 19.90s/it]predicting train subjects:   6%|▋         | 20/311 [05:06<1:37:21, 20.08s/it]predicting train subjects:   7%|▋         | 21/311 [05:27<1:37:39, 20.21s/it]predicting train subjects:   7%|▋         | 22/311 [05:48<1:38:04, 20.36s/it]predicting train subjects:   7%|▋         | 23/311 [06:09<1:39:04, 20.64s/it]predicting train subjects:   8%|▊         | 24/311 [06:30<1:39:05, 20.72s/it]predicting train subjects:   8%|▊         | 25/311 [06:52<1:40:14, 21.03s/it]predicting train subjects:   8%|▊         | 26/311 [07:12<1:39:24, 20.93s/it]predicting train subjects:   9%|▊         | 27/311 [07:34<1:39:38, 21.05s/it]predicting train subjects:   9%|▉         | 28/311 [07:54<1:38:42, 20.93s/it]predicting train subjects:   9%|▉         | 29/311 [08:16<1:38:43, 21.01s/it]predicting train subjects:  10%|▉         | 30/311 [08:36<1:37:17, 20.77s/it]predicting train subjects:  10%|▉         | 31/311 [08:57<1:37:44, 20.94s/it]predicting train subjects:  10%|█         | 32/311 [09:18<1:37:23, 20.95s/it]predicting train subjects:  11%|█         | 33/311 [09:28<1:21:38, 17.62s/it]predicting train subjects:  11%|█         | 34/311 [09:38<1:10:41, 15.31s/it]predicting train subjects:  11%|█▏        | 35/311 [09:48<1:02:39, 13.62s/it]predicting train subjects:  12%|█▏        | 36/311 [09:58<57:28, 12.54s/it]  predicting train subjects:  12%|█▏        | 37/311 [10:08<53:50, 11.79s/it]predicting train subjects:  12%|█▏        | 38/311 [10:18<51:09, 11.24s/it]predicting train subjects:  13%|█▎        | 39/311 [10:27<48:36, 10.72s/it]predicting train subjects:  13%|█▎        | 40/311 [10:37<47:40, 10.55s/it]predicting train subjects:  13%|█▎        | 41/311 [10:47<46:41, 10.38s/it]predicting train subjects:  14%|█▎        | 42/311 [10:57<45:36, 10.17s/it]predicting train subjects:  14%|█▍        | 43/311 [11:07<44:50, 10.04s/it]predicting train subjects:  14%|█▍        | 44/311 [11:17<44:29, 10.00s/it]predicting train subjects:  14%|█▍        | 45/311 [11:26<43:40,  9.85s/it]predicting train subjects:  15%|█▍        | 46/311 [11:36<43:11,  9.78s/it]predicting train subjects:  15%|█▌        | 47/311 [11:46<43:17,  9.84s/it]predicting train subjects:  15%|█▌        | 48/311 [11:55<42:43,  9.75s/it]predicting train subjects:  16%|█▌        | 49/311 [12:05<42:30,  9.73s/it]predicting train subjects:  16%|█▌        | 50/311 [12:15<42:51,  9.85s/it]predicting train subjects:  16%|█▋        | 51/311 [12:27<45:52, 10.59s/it]predicting train subjects:  17%|█▋        | 52/311 [12:40<48:17, 11.19s/it]predicting train subjects:  17%|█▋        | 53/311 [12:52<49:42, 11.56s/it]predicting train subjects:  17%|█▋        | 54/311 [13:05<50:53, 11.88s/it]predicting train subjects:  18%|█▊        | 55/311 [13:17<51:35, 12.09s/it]predicting train subjects:  18%|█▊        | 56/311 [13:30<51:43, 12.17s/it]predicting train subjects:  18%|█▊        | 57/311 [13:42<52:07, 12.31s/it]predicting train subjects:  19%|█▊        | 58/311 [13:55<52:18, 12.41s/it]predicting train subjects:  19%|█▉        | 59/311 [14:08<52:14, 12.44s/it]predicting train subjects:  19%|█▉        | 60/311 [14:20<52:11, 12.48s/it]predicting train subjects:  20%|█▉        | 61/311 [14:33<51:57, 12.47s/it]predicting train subjects:  20%|█▉        | 62/311 [14:45<52:09, 12.57s/it]predicting train subjects:  20%|██        | 63/311 [14:58<51:41, 12.51s/it]predicting train subjects:  21%|██        | 64/311 [15:10<51:06, 12.42s/it]predicting train subjects:  21%|██        | 65/311 [15:22<50:38, 12.35s/it]predicting train subjects:  21%|██        | 66/311 [15:34<50:13, 12.30s/it]predicting train subjects:  22%|██▏       | 67/311 [15:47<50:40, 12.46s/it]predicting train subjects:  22%|██▏       | 68/311 [16:00<50:16, 12.41s/it]predicting train subjects:  22%|██▏       | 69/311 [16:12<49:34, 12.29s/it]predicting train subjects:  23%|██▎       | 70/311 [16:24<49:15, 12.26s/it]predicting train subjects:  23%|██▎       | 71/311 [16:36<48:28, 12.12s/it]predicting train subjects:  23%|██▎       | 72/311 [16:47<47:37, 11.96s/it]predicting train subjects:  23%|██▎       | 73/311 [16:59<47:18, 11.93s/it]predicting train subjects:  24%|██▍       | 74/311 [17:11<47:15, 11.96s/it]predicting train subjects:  24%|██▍       | 75/311 [17:23<47:07, 11.98s/it]predicting train subjects:  24%|██▍       | 76/311 [17:35<47:12, 12.05s/it]predicting train subjects:  25%|██▍       | 77/311 [17:47<47:12, 12.10s/it]predicting train subjects:  25%|██▌       | 78/311 [18:00<47:08, 12.14s/it]predicting train subjects:  25%|██▌       | 79/311 [18:11<46:30, 12.03s/it]predicting train subjects:  26%|██▌       | 80/311 [18:23<46:10, 11.99s/it]predicting train subjects:  26%|██▌       | 81/311 [18:35<45:54, 11.97s/it]predicting train subjects:  26%|██▋       | 82/311 [18:48<46:28, 12.18s/it]predicting train subjects:  27%|██▋       | 83/311 [19:00<46:02, 12.11s/it]predicting train subjects:  27%|██▋       | 84/311 [19:12<45:33, 12.04s/it]predicting train subjects:  27%|██▋       | 85/311 [19:23<44:04, 11.70s/it]predicting train subjects:  28%|██▊       | 86/311 [19:34<43:31, 11.61s/it]predicting train subjects:  28%|██▊       | 87/311 [19:45<42:53, 11.49s/it]predicting train subjects:  28%|██▊       | 88/311 [19:56<42:06, 11.33s/it]predicting train subjects:  29%|██▊       | 89/311 [20:07<41:10, 11.13s/it]predicting train subjects:  29%|██▉       | 90/311 [20:18<41:03, 11.15s/it]predicting train subjects:  29%|██▉       | 91/311 [20:29<40:54, 11.16s/it]predicting train subjects:  30%|██▉       | 92/311 [20:40<40:44, 11.16s/it]predicting train subjects:  30%|██▉       | 93/311 [20:51<40:11, 11.06s/it]predicting train subjects:  30%|███       | 94/311 [21:02<39:59, 11.06s/it]predicting train subjects:  31%|███       | 95/311 [21:14<40:12, 11.17s/it]predicting train subjects:  31%|███       | 96/311 [21:26<40:48, 11.39s/it]predicting train subjects:  31%|███       | 97/311 [21:37<40:22, 11.32s/it]predicting train subjects:  32%|███▏      | 98/311 [21:48<39:46, 11.20s/it]predicting train subjects:  32%|███▏      | 99/311 [21:59<39:50, 11.28s/it]predicting train subjects:  32%|███▏      | 100/311 [22:10<39:22, 11.20s/it]predicting train subjects:  32%|███▏      | 101/311 [22:22<39:26, 11.27s/it]predicting train subjects:  33%|███▎      | 102/311 [22:33<38:59, 11.19s/it]predicting train subjects:  33%|███▎      | 103/311 [22:43<38:22, 11.07s/it]predicting train subjects:  33%|███▎      | 104/311 [22:54<38:09, 11.06s/it]predicting train subjects:  34%|███▍      | 105/311 [23:06<38:09, 11.11s/it]predicting train subjects:  34%|███▍      | 106/311 [23:17<38:04, 11.15s/it]predicting train subjects:  34%|███▍      | 107/311 [23:28<37:53, 11.15s/it]predicting train subjects:  35%|███▍      | 108/311 [23:39<37:27, 11.07s/it]predicting train subjects:  35%|███▌      | 109/311 [23:50<37:29, 11.14s/it]predicting train subjects:  35%|███▌      | 110/311 [24:01<37:15, 11.12s/it]predicting train subjects:  36%|███▌      | 111/311 [24:12<37:05, 11.13s/it]predicting train subjects:  36%|███▌      | 112/311 [24:24<37:16, 11.24s/it]predicting train subjects:  36%|███▋      | 113/311 [24:35<36:58, 11.20s/it]predicting train subjects:  37%|███▋      | 114/311 [24:56<46:29, 14.16s/it]predicting train subjects:  37%|███▋      | 115/311 [25:18<53:18, 16.32s/it]predicting train subjects:  37%|███▋      | 116/311 [25:38<57:28, 17.68s/it]predicting train subjects:  38%|███▊      | 117/311 [25:59<1:00:07, 18.60s/it]predicting train subjects:  38%|███▊      | 118/311 [26:20<1:02:19, 19.37s/it]predicting train subjects:  38%|███▊      | 119/311 [26:41<1:03:11, 19.75s/it]predicting train subjects:  39%|███▊      | 120/311 [27:03<1:04:40, 20.31s/it]predicting train subjects:  39%|███▉      | 121/311 [27:24<1:04:58, 20.52s/it]predicting train subjects:  39%|███▉      | 122/311 [27:44<1:04:57, 20.62s/it]predicting train subjects:  40%|███▉      | 123/311 [28:05<1:04:54, 20.72s/it]predicting train subjects:  40%|███▉      | 124/311 [28:27<1:05:05, 20.88s/it]predicting train subjects:  40%|████      | 125/311 [28:48<1:04:46, 20.89s/it]predicting train subjects:  41%|████      | 126/311 [29:09<1:04:29, 20.92s/it]predicting train subjects:  41%|████      | 127/311 [29:30<1:04:27, 21.02s/it]predicting train subjects:  41%|████      | 128/311 [29:51<1:04:20, 21.10s/it]predicting train subjects:  41%|████▏     | 129/311 [30:13<1:04:28, 21.26s/it]predicting train subjects:  42%|████▏     | 130/311 [30:34<1:03:58, 21.21s/it]predicting train subjects:  42%|████▏     | 131/311 [30:55<1:03:26, 21.15s/it]predicting train subjects:  42%|████▏     | 132/311 [31:05<53:05, 17.80s/it]  predicting train subjects:  43%|████▎     | 133/311 [31:15<45:37, 15.38s/it]predicting train subjects:  43%|████▎     | 134/311 [31:25<40:45, 13.81s/it]predicting train subjects:  43%|████▎     | 135/311 [31:35<37:18, 12.72s/it]predicting train subjects:  44%|████▎     | 136/311 [31:44<34:20, 11.78s/it]predicting train subjects:  44%|████▍     | 137/311 [31:55<32:48, 11.32s/it]predicting train subjects:  44%|████▍     | 138/311 [32:05<31:26, 10.90s/it]predicting train subjects:  45%|████▍     | 139/311 [32:15<30:31, 10.65s/it]predicting train subjects:  45%|████▌     | 140/311 [32:25<30:15, 10.62s/it]predicting train subjects:  45%|████▌     | 141/311 [32:36<29:58, 10.58s/it]predicting train subjects:  46%|████▌     | 142/311 [32:45<29:05, 10.33s/it]predicting train subjects:  46%|████▌     | 143/311 [32:55<28:35, 10.21s/it]predicting train subjects:  46%|████▋     | 144/311 [33:05<28:20, 10.19s/it]predicting train subjects:  47%|████▋     | 145/311 [33:15<27:52, 10.07s/it]predicting train subjects:  47%|████▋     | 146/311 [33:25<27:30, 10.01s/it]predicting train subjects:  47%|████▋     | 147/311 [33:35<27:13,  9.96s/it]predicting train subjects:  48%|████▊     | 148/311 [33:44<26:32,  9.77s/it]predicting train subjects:  48%|████▊     | 149/311 [33:54<26:27,  9.80s/it]predicting train subjects:  48%|████▊     | 150/311 [34:07<28:31, 10.63s/it]predicting train subjects:  49%|████▊     | 151/311 [34:19<29:37, 11.11s/it]predicting train subjects:  49%|████▉     | 152/311 [34:31<30:09, 11.38s/it]predicting train subjects:  49%|████▉     | 153/311 [34:44<31:05, 11.81s/it]predicting train subjects:  50%|████▉     | 154/311 [34:57<31:44, 12.13s/it]predicting train subjects:  50%|████▉     | 155/311 [35:09<31:58, 12.30s/it]predicting train subjects:  50%|█████     | 156/311 [35:22<31:38, 12.25s/it]predicting train subjects:  50%|█████     | 157/311 [35:34<31:31, 12.28s/it]predicting train subjects:  51%|█████     | 158/311 [35:46<31:19, 12.29s/it]predicting train subjects:  51%|█████     | 159/311 [35:59<31:19, 12.36s/it]predicting train subjects:  51%|█████▏    | 160/311 [36:12<31:52, 12.66s/it]predicting train subjects:  52%|█████▏    | 161/311 [36:25<31:44, 12.69s/it]predicting train subjects:  52%|█████▏    | 162/311 [36:37<31:16, 12.60s/it]predicting train subjects:  52%|█████▏    | 163/311 [36:50<31:29, 12.76s/it]predicting train subjects:  53%|█████▎    | 164/311 [37:03<31:00, 12.66s/it]predicting train subjects:  53%|█████▎    | 165/311 [37:15<30:44, 12.63s/it]predicting train subjects:  53%|█████▎    | 166/311 [37:28<30:14, 12.51s/it]predicting train subjects:  54%|█████▎    | 167/311 [37:40<29:35, 12.33s/it]predicting train subjects:  54%|█████▍    | 168/311 [37:51<29:08, 12.22s/it]predicting train subjects:  54%|█████▍    | 169/311 [38:04<28:51, 12.20s/it]predicting train subjects:  55%|█████▍    | 170/311 [38:16<28:52, 12.29s/it]predicting train subjects:  55%|█████▍    | 171/311 [38:28<28:42, 12.30s/it]predicting train subjects:  55%|█████▌    | 172/311 [38:40<28:18, 12.22s/it]predicting train subjects:  56%|█████▌    | 173/311 [38:54<28:40, 12.47s/it]predicting train subjects:  56%|█████▌    | 174/311 [39:05<28:04, 12.29s/it]predicting train subjects:  56%|█████▋    | 175/311 [39:17<27:42, 12.23s/it]predicting train subjects:  57%|█████▋    | 176/311 [39:30<27:27, 12.20s/it]predicting train subjects:  57%|█████▋    | 177/311 [39:41<26:56, 12.07s/it]predicting train subjects:  57%|█████▋    | 178/311 [39:54<27:08, 12.25s/it]predicting train subjects:  58%|█████▊    | 179/311 [40:06<26:49, 12.19s/it]predicting train subjects:  58%|█████▊    | 180/311 [40:18<26:38, 12.20s/it]predicting train subjects:  58%|█████▊    | 181/311 [40:30<26:24, 12.19s/it]predicting train subjects:  59%|█████▊    | 182/311 [40:43<26:27, 12.31s/it]predicting train subjects:  59%|█████▉    | 183/311 [40:55<25:54, 12.14s/it]predicting train subjects:  59%|█████▉    | 184/311 [41:06<25:09, 11.88s/it]predicting train subjects:  59%|█████▉    | 185/311 [41:17<24:32, 11.68s/it]predicting train subjects:  60%|█████▉    | 186/311 [41:28<23:44, 11.39s/it]predicting train subjects:  60%|██████    | 187/311 [41:39<23:30, 11.37s/it]predicting train subjects:  60%|██████    | 188/311 [41:51<23:13, 11.33s/it]predicting train subjects:  61%|██████    | 189/311 [42:01<22:43, 11.18s/it]predicting train subjects:  61%|██████    | 190/311 [42:12<22:21, 11.09s/it]predicting train subjects:  61%|██████▏   | 191/311 [42:24<22:16, 11.14s/it]predicting train subjects:  62%|██████▏   | 192/311 [42:35<22:13, 11.21s/it]predicting train subjects:  62%|██████▏   | 193/311 [42:45<21:33, 10.96s/it]predicting train subjects:  62%|██████▏   | 194/311 [42:57<21:36, 11.08s/it]predicting train subjects:  63%|██████▎   | 195/311 [43:08<21:32, 11.15s/it]predicting train subjects:  63%|██████▎   | 196/311 [43:19<21:13, 11.07s/it]predicting train subjects:  63%|██████▎   | 197/311 [43:30<20:50, 10.97s/it]predicting train subjects:  64%|██████▎   | 198/311 [43:41<21:02, 11.17s/it]predicting train subjects:  64%|██████▍   | 199/311 [43:53<20:57, 11.22s/it]predicting train subjects:  64%|██████▍   | 200/311 [44:04<20:40, 11.18s/it]predicting train subjects:  65%|██████▍   | 201/311 [44:15<20:31, 11.19s/it]predicting train subjects:  65%|██████▍   | 202/311 [44:26<20:13, 11.14s/it]predicting train subjects:  65%|██████▌   | 203/311 [44:38<20:21, 11.31s/it]predicting train subjects:  66%|██████▌   | 204/311 [44:49<20:12, 11.33s/it]predicting train subjects:  66%|██████▌   | 205/311 [45:00<20:04, 11.36s/it]predicting train subjects:  66%|██████▌   | 206/311 [45:11<19:38, 11.23s/it]predicting train subjects:  67%|██████▋   | 207/311 [45:22<19:24, 11.20s/it]predicting train subjects:  67%|██████▋   | 208/311 [45:34<19:23, 11.30s/it]predicting train subjects:  67%|██████▋   | 209/311 [45:46<19:20, 11.38s/it]predicting train subjects:  68%|██████▊   | 210/311 [45:57<19:03, 11.32s/it]predicting train subjects:  68%|██████▊   | 211/311 [46:08<18:40, 11.20s/it]predicting train subjects:  68%|██████▊   | 212/311 [46:19<18:31, 11.23s/it]predicting train subjects:  68%|██████▊   | 213/311 [46:40<23:16, 14.25s/it]predicting train subjects:  69%|██████▉   | 214/311 [47:01<26:17, 16.26s/it]predicting train subjects:  69%|██████▉   | 215/311 [47:22<28:19, 17.70s/it]predicting train subjects:  69%|██████▉   | 216/311 [47:43<29:29, 18.63s/it]predicting train subjects:  70%|██████▉   | 217/311 [48:04<30:24, 19.41s/it]predicting train subjects:  70%|███████   | 218/311 [48:25<30:53, 19.93s/it]predicting train subjects:  70%|███████   | 219/311 [48:46<31:03, 20.25s/it]predicting train subjects:  71%|███████   | 220/311 [49:07<31:01, 20.46s/it]predicting train subjects:  71%|███████   | 221/311 [49:28<30:52, 20.59s/it]predicting train subjects:  71%|███████▏  | 222/311 [49:49<30:38, 20.66s/it]predicting train subjects:  72%|███████▏  | 223/311 [50:10<30:26, 20.76s/it]predicting train subjects:  72%|███████▏  | 224/311 [50:31<30:15, 20.87s/it]predicting train subjects:  72%|███████▏  | 225/311 [50:51<29:39, 20.69s/it]predicting train subjects:  73%|███████▎  | 226/311 [51:12<29:22, 20.73s/it]predicting train subjects:  73%|███████▎  | 227/311 [51:33<28:56, 20.67s/it]predicting train subjects:  73%|███████▎  | 228/311 [51:53<28:26, 20.56s/it]predicting train subjects:  74%|███████▎  | 229/311 [52:14<28:25, 20.80s/it]predicting train subjects:  74%|███████▍  | 230/311 [52:35<28:05, 20.81s/it]predicting train subjects:  74%|███████▍  | 231/311 [52:45<23:26, 17.58s/it]predicting train subjects:  75%|███████▍  | 232/311 [52:55<20:01, 15.21s/it]predicting train subjects:  75%|███████▍  | 233/311 [53:05<17:37, 13.56s/it]predicting train subjects:  75%|███████▌  | 234/311 [53:15<16:01, 12.48s/it]predicting train subjects:  76%|███████▌  | 235/311 [53:25<14:48, 11.70s/it]predicting train subjects:  76%|███████▌  | 236/311 [53:34<13:53, 11.11s/it]predicting train subjects:  76%|███████▌  | 237/311 [53:44<13:18, 10.79s/it]predicting train subjects:  77%|███████▋  | 238/311 [53:54<12:48, 10.53s/it]predicting train subjects:  77%|███████▋  | 239/311 [54:04<12:15, 10.21s/it]predicting train subjects:  77%|███████▋  | 240/311 [54:14<12:03, 10.19s/it]predicting train subjects:  77%|███████▋  | 241/311 [54:24<11:46, 10.09s/it]predicting train subjects:  78%|███████▊  | 242/311 [54:33<11:22,  9.89s/it]predicting train subjects:  78%|███████▊  | 243/311 [54:43<11:15,  9.93s/it]predicting train subjects:  78%|███████▊  | 244/311 [54:53<11:07,  9.96s/it]predicting train subjects:  79%|███████▉  | 245/311 [55:03<10:48,  9.82s/it]predicting train subjects:  79%|███████▉  | 246/311 [55:13<10:39,  9.84s/it]predicting train subjects:  79%|███████▉  | 247/311 [55:23<10:34,  9.92s/it]predicting train subjects:  80%|███████▉  | 248/311 [55:32<10:15,  9.78s/it]predicting train subjects:  80%|████████  | 249/311 [55:44<10:52, 10.53s/it]predicting train subjects:  80%|████████  | 250/311 [55:57<11:22, 11.19s/it]predicting train subjects:  81%|████████  | 251/311 [56:10<11:40, 11.67s/it]predicting train subjects:  81%|████████  | 252/311 [56:23<11:44, 11.95s/it]predicting train subjects:  81%|████████▏ | 253/311 [56:35<11:41, 12.09s/it]predicting train subjects:  82%|████████▏ | 254/311 [56:47<11:33, 12.17s/it]predicting train subjects:  82%|████████▏ | 255/311 [57:00<11:20, 12.16s/it]predicting train subjects:  82%|████████▏ | 256/311 [57:12<11:10, 12.20s/it]predicting train subjects:  83%|████████▎ | 257/311 [57:24<11:03, 12.29s/it]predicting train subjects:  83%|████████▎ | 258/311 [57:37<10:58, 12.43s/it]predicting train subjects:  83%|████████▎ | 259/311 [57:50<10:47, 12.46s/it]predicting train subjects:  84%|████████▎ | 260/311 [58:02<10:35, 12.46s/it]predicting train subjects:  84%|████████▍ | 261/311 [58:14<10:19, 12.38s/it]predicting train subjects:  84%|████████▍ | 262/311 [58:26<10:02, 12.29s/it]predicting train subjects:  85%|████████▍ | 263/311 [58:39<09:52, 12.34s/it]predicting train subjects:  85%|████████▍ | 264/311 [58:51<09:41, 12.38s/it]predicting train subjects:  85%|████████▌ | 265/311 [59:04<09:35, 12.51s/it]predicting train subjects:  86%|████████▌ | 266/311 [59:16<09:18, 12.42s/it]predicting train subjects:  86%|████████▌ | 267/311 [59:28<08:58, 12.23s/it]predicting train subjects:  86%|████████▌ | 268/311 [59:41<08:50, 12.33s/it]predicting train subjects:  86%|████████▋ | 269/311 [59:52<08:31, 12.19s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:00:05<08:19, 12.18s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:00:17<08:08, 12.20s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:00:29<07:54, 12.18s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:00:41<07:42, 12.16s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:00:53<07:29, 12.15s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:01:05<07:12, 12.02s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:01:17<07:03, 12.10s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:01:30<06:53, 12.17s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:01:42<06:41, 12.17s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:01:54<06:26, 12.08s/it]predicting train subjects:  90%|█████████ | 280/311 [1:02:05<06:11, 12.00s/it]predicting train subjects:  90%|█████████ | 281/311 [1:02:17<05:58, 11.96s/it]predicting train subjects:  91%|█████████ | 282/311 [1:02:29<05:48, 12.02s/it]predicting train subjects:  91%|█████████ | 283/311 [1:02:41<05:29, 11.77s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:02:51<05:09, 11.45s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:03:03<05:01, 11.58s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:03:15<04:48, 11.53s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:03:26<04:34, 11.43s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:03:37<04:18, 11.25s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:03:48<04:05, 11.17s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:03:59<03:55, 11.20s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:04:10<03:41, 11.09s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:04:20<03:28, 10.98s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:04:32<03:19, 11.08s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:04:43<03:08, 11.10s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:04:55<03:00, 11.29s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:05:05<02:47, 11.13s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:05:17<02:36, 11.17s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:05:29<02:29, 11.47s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:05:40<02:16, 11.37s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:05:51<02:04, 11.35s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:06:03<01:54, 11.42s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:06:14<01:41, 11.27s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:06:25<01:29, 11.15s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:06:36<01:18, 11.17s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:06:47<01:06, 11.16s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:06:58<00:55, 11.12s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:07:09<00:44, 11.20s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:07:21<00:33, 11.26s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:07:32<00:22, 11.21s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:07:43<00:11, 11.07s/it]predicting train subjects: 100%|██████████| 311/311 [1:07:54<00:00, 11.07s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:29,  1.37s/it]Loading train:   1%|          | 2/285 [00:02<06:43,  1.43s/it]Loading train:   1%|          | 3/285 [00:04<06:38,  1.41s/it]Loading train:   1%|▏         | 4/285 [00:06<07:04,  1.51s/it]Loading train:   2%|▏         | 5/285 [00:07<06:47,  1.46s/it]Loading train:   2%|▏         | 6/285 [00:09<07:17,  1.57s/it]Loading train:   2%|▏         | 7/285 [00:11<07:40,  1.66s/it]Loading train:   3%|▎         | 8/285 [00:12<07:57,  1.72s/it]Loading train:   3%|▎         | 9/285 [00:14<07:32,  1.64s/it]Loading train:   4%|▎         | 10/285 [00:15<07:12,  1.57s/it]Loading train:   4%|▍         | 11/285 [00:17<06:43,  1.47s/it]Loading train:   4%|▍         | 12/285 [00:18<06:20,  1.39s/it]Loading train:   5%|▍         | 13/285 [00:19<05:54,  1.30s/it]Loading train:   5%|▍         | 14/285 [00:20<05:48,  1.29s/it]Loading train:   5%|▌         | 15/285 [00:22<06:03,  1.35s/it]Loading train:   6%|▌         | 16/285 [00:23<06:05,  1.36s/it]Loading train:   6%|▌         | 17/285 [00:24<06:05,  1.36s/it]Loading train:   6%|▋         | 18/285 [00:26<05:58,  1.34s/it]Loading train:   7%|▋         | 19/285 [00:27<05:48,  1.31s/it]Loading train:   7%|▋         | 20/285 [00:28<05:44,  1.30s/it]Loading train:   7%|▋         | 21/285 [00:29<05:32,  1.26s/it]Loading train:   8%|▊         | 22/285 [00:31<05:38,  1.29s/it]Loading train:   8%|▊         | 23/285 [00:32<05:48,  1.33s/it]Loading train:   8%|▊         | 24/285 [00:33<05:50,  1.34s/it]Loading train:   9%|▉         | 25/285 [00:35<05:33,  1.28s/it]Loading train:   9%|▉         | 26/285 [00:36<05:26,  1.26s/it]Loading train:   9%|▉         | 27/285 [00:37<05:29,  1.28s/it]Loading train:  10%|▉         | 28/285 [00:39<05:37,  1.31s/it]Loading train:  10%|█         | 29/285 [00:40<05:40,  1.33s/it]Loading train:  11%|█         | 30/285 [00:41<05:40,  1.34s/it]Loading train:  11%|█         | 31/285 [00:43<05:34,  1.32s/it]Loading train:  11%|█         | 32/285 [00:44<05:33,  1.32s/it]Loading train:  12%|█▏        | 33/285 [00:45<05:40,  1.35s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:33,  1.33s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:18,  1.28s/it]Loading train:  13%|█▎        | 36/285 [00:49<05:22,  1.29s/it]Loading train:  13%|█▎        | 37/285 [00:50<05:21,  1.30s/it]Loading train:  13%|█▎        | 38/285 [00:52<05:30,  1.34s/it]Loading train:  14%|█▎        | 39/285 [00:53<05:19,  1.30s/it]Loading train:  14%|█▍        | 40/285 [00:54<05:13,  1.28s/it]Loading train:  14%|█▍        | 41/285 [00:56<05:13,  1.29s/it]Loading train:  15%|█▍        | 42/285 [00:57<05:16,  1.30s/it]Loading train:  15%|█▌        | 43/285 [00:58<05:08,  1.28s/it]Loading train:  15%|█▌        | 44/285 [00:59<05:15,  1.31s/it]Loading train:  16%|█▌        | 45/285 [01:01<05:05,  1.27s/it]Loading train:  16%|█▌        | 46/285 [01:02<04:53,  1.23s/it]Loading train:  16%|█▋        | 47/285 [01:03<04:45,  1.20s/it]Loading train:  17%|█▋        | 48/285 [01:04<04:27,  1.13s/it]Loading train:  17%|█▋        | 49/285 [01:05<04:17,  1.09s/it]Loading train:  18%|█▊        | 50/285 [01:06<03:58,  1.02s/it]Loading train:  18%|█▊        | 51/285 [01:07<03:58,  1.02s/it]Loading train:  18%|█▊        | 52/285 [01:08<04:01,  1.04s/it]Loading train:  19%|█▊        | 53/285 [01:09<04:15,  1.10s/it]Loading train:  19%|█▉        | 54/285 [01:10<04:18,  1.12s/it]Loading train:  19%|█▉        | 55/285 [01:11<04:17,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:12<04:10,  1.10s/it]Loading train:  20%|██        | 57/285 [01:13<04:07,  1.09s/it]Loading train:  20%|██        | 58/285 [01:15<04:08,  1.09s/it]Loading train:  21%|██        | 59/285 [01:16<04:03,  1.08s/it]Loading train:  21%|██        | 60/285 [01:17<03:56,  1.05s/it]Loading train:  21%|██▏       | 61/285 [01:18<04:06,  1.10s/it]Loading train:  22%|██▏       | 62/285 [01:19<04:06,  1.10s/it]Loading train:  22%|██▏       | 63/285 [01:20<04:13,  1.14s/it]Loading train:  22%|██▏       | 64/285 [01:22<04:39,  1.26s/it]Loading train:  23%|██▎       | 65/285 [01:23<05:05,  1.39s/it]Loading train:  23%|██▎       | 66/285 [01:26<05:57,  1.63s/it]Loading train:  24%|██▎       | 67/285 [01:27<05:16,  1.45s/it]Loading train:  24%|██▍       | 68/285 [01:27<04:34,  1.27s/it]Loading train:  24%|██▍       | 69/285 [01:28<04:08,  1.15s/it]Loading train:  25%|██▍       | 70/285 [01:29<03:43,  1.04s/it]Loading train:  25%|██▍       | 71/285 [01:30<03:40,  1.03s/it]Loading train:  25%|██▌       | 72/285 [01:31<03:32,  1.00it/s]Loading train:  26%|██▌       | 73/285 [01:32<03:36,  1.02s/it]Loading train:  26%|██▌       | 74/285 [01:33<03:38,  1.03s/it]Loading train:  26%|██▋       | 75/285 [01:34<03:43,  1.07s/it]Loading train:  27%|██▋       | 76/285 [01:35<03:28,  1.00it/s]Loading train:  27%|██▋       | 77/285 [01:36<03:21,  1.03it/s]Loading train:  27%|██▋       | 78/285 [01:37<03:12,  1.08it/s]Loading train:  28%|██▊       | 79/285 [01:38<03:01,  1.14it/s]Loading train:  28%|██▊       | 80/285 [01:38<02:53,  1.18it/s]Loading train:  28%|██▊       | 81/285 [01:39<02:47,  1.22it/s]Loading train:  29%|██▉       | 82/285 [01:40<02:41,  1.25it/s]Loading train:  29%|██▉       | 83/285 [01:41<02:43,  1.23it/s]Loading train:  29%|██▉       | 84/285 [01:42<02:41,  1.25it/s]Loading train:  30%|██▉       | 85/285 [01:43<02:50,  1.17it/s]Loading train:  30%|███       | 86/285 [01:43<02:55,  1.13it/s]Loading train:  31%|███       | 87/285 [01:44<02:58,  1.11it/s]Loading train:  31%|███       | 88/285 [01:45<03:02,  1.08it/s]Loading train:  31%|███       | 89/285 [01:46<03:03,  1.07it/s]Loading train:  32%|███▏      | 90/285 [01:47<03:04,  1.06it/s]Loading train:  32%|███▏      | 91/285 [01:48<03:09,  1.02it/s]Loading train:  32%|███▏      | 92/285 [01:49<03:06,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:50<03:07,  1.02it/s]Loading train:  33%|███▎      | 94/285 [01:51<03:02,  1.05it/s]Loading train:  33%|███▎      | 95/285 [01:52<02:58,  1.07it/s]Loading train:  34%|███▎      | 96/285 [01:53<02:55,  1.08it/s]Loading train:  34%|███▍      | 97/285 [01:54<02:55,  1.07it/s]Loading train:  34%|███▍      | 98/285 [01:55<03:02,  1.03it/s]Loading train:  35%|███▍      | 99/285 [01:56<02:57,  1.05it/s]Loading train:  35%|███▌      | 100/285 [01:57<02:57,  1.04it/s]Loading train:  35%|███▌      | 101/285 [01:58<02:57,  1.04it/s]Loading train:  36%|███▌      | 102/285 [01:59<02:53,  1.06it/s]Loading train:  36%|███▌      | 103/285 [02:00<02:46,  1.10it/s]Loading train:  36%|███▋      | 104/285 [02:01<02:42,  1.11it/s]Loading train:  37%|███▋      | 105/285 [02:01<02:38,  1.14it/s]Loading train:  37%|███▋      | 106/285 [02:02<02:36,  1.14it/s]Loading train:  38%|███▊      | 107/285 [02:03<02:34,  1.15it/s]Loading train:  38%|███▊      | 108/285 [02:04<02:31,  1.17it/s]Loading train:  38%|███▊      | 109/285 [02:05<02:32,  1.15it/s]Loading train:  39%|███▊      | 110/285 [02:06<02:29,  1.17it/s]Loading train:  39%|███▉      | 111/285 [02:06<02:26,  1.19it/s]Loading train:  39%|███▉      | 112/285 [02:07<02:26,  1.18it/s]Loading train:  40%|███▉      | 113/285 [02:08<02:28,  1.16it/s]Loading train:  40%|████      | 114/285 [02:09<02:30,  1.13it/s]Loading train:  40%|████      | 115/285 [02:10<02:27,  1.15it/s]Loading train:  41%|████      | 116/285 [02:11<02:25,  1.16it/s]Loading train:  41%|████      | 117/285 [02:12<02:23,  1.17it/s]Loading train:  41%|████▏     | 118/285 [02:12<02:22,  1.17it/s]Loading train:  42%|████▏     | 119/285 [02:13<02:20,  1.18it/s]Loading train:  42%|████▏     | 120/285 [02:14<02:20,  1.17it/s]Loading train:  42%|████▏     | 121/285 [02:15<02:37,  1.04it/s]Loading train:  43%|████▎     | 122/285 [02:16<02:43,  1.00s/it]Loading train:  43%|████▎     | 123/285 [02:18<02:48,  1.04s/it]Loading train:  44%|████▎     | 124/285 [02:18<02:36,  1.03it/s]Loading train:  44%|████▍     | 125/285 [02:19<02:24,  1.11it/s]Loading train:  44%|████▍     | 126/285 [02:20<02:16,  1.17it/s]Loading train:  45%|████▍     | 127/285 [02:21<02:11,  1.20it/s]Loading train:  45%|████▍     | 128/285 [02:21<02:05,  1.25it/s]Loading train:  45%|████▌     | 129/285 [02:22<02:02,  1.28it/s]Loading train:  46%|████▌     | 130/285 [02:23<02:01,  1.28it/s]Loading train:  46%|████▌     | 131/285 [02:24<02:01,  1.27it/s]Loading train:  46%|████▋     | 132/285 [02:24<01:57,  1.30it/s]Loading train:  47%|████▋     | 133/285 [02:25<01:59,  1.27it/s]Loading train:  47%|████▋     | 134/285 [02:26<01:56,  1.29it/s]Loading train:  47%|████▋     | 135/285 [02:27<01:55,  1.30it/s]Loading train:  48%|████▊     | 136/285 [02:28<01:55,  1.29it/s]Loading train:  48%|████▊     | 137/285 [02:28<01:54,  1.29it/s]Loading train:  48%|████▊     | 138/285 [02:29<01:51,  1.32it/s]Loading train:  49%|████▉     | 139/285 [02:30<01:48,  1.35it/s]Loading train:  49%|████▉     | 140/285 [02:30<01:44,  1.38it/s]Loading train:  49%|████▉     | 141/285 [02:31<01:45,  1.36it/s]Loading train:  50%|████▉     | 142/285 [02:32<01:43,  1.38it/s]Loading train:  50%|█████     | 143/285 [02:33<01:43,  1.37it/s]Loading train:  51%|█████     | 144/285 [02:33<01:43,  1.36it/s]Loading train:  51%|█████     | 145/285 [02:34<01:40,  1.39it/s]Loading train:  51%|█████     | 146/285 [02:35<01:37,  1.42it/s]Loading train:  52%|█████▏    | 147/285 [02:35<01:37,  1.41it/s]Loading train:  52%|█████▏    | 148/285 [02:36<01:35,  1.44it/s]Loading train:  52%|█████▏    | 149/285 [02:37<01:33,  1.45it/s]Loading train:  53%|█████▎    | 150/285 [02:38<01:34,  1.43it/s]Loading train:  53%|█████▎    | 151/285 [02:38<01:34,  1.41it/s]Loading train:  53%|█████▎    | 152/285 [02:39<01:35,  1.39it/s]Loading train:  54%|█████▎    | 153/285 [02:40<01:32,  1.43it/s]Loading train:  54%|█████▍    | 154/285 [02:40<01:34,  1.39it/s]Loading train:  54%|█████▍    | 155/285 [02:41<01:32,  1.41it/s]Loading train:  55%|█████▍    | 156/285 [02:42<01:29,  1.44it/s]Loading train:  55%|█████▌    | 157/285 [02:42<01:28,  1.44it/s]Loading train:  55%|█████▌    | 158/285 [02:43<01:28,  1.44it/s]Loading train:  56%|█████▌    | 159/285 [02:44<01:29,  1.41it/s]Loading train:  56%|█████▌    | 160/285 [02:45<01:31,  1.36it/s]Loading train:  56%|█████▋    | 161/285 [02:45<01:28,  1.40it/s]Loading train:  57%|█████▋    | 162/285 [02:46<01:26,  1.42it/s]Loading train:  57%|█████▋    | 163/285 [02:47<01:26,  1.41it/s]Loading train:  58%|█████▊    | 164/285 [02:47<01:24,  1.44it/s]Loading train:  58%|█████▊    | 165/285 [02:48<01:23,  1.43it/s]Loading train:  58%|█████▊    | 166/285 [02:49<01:25,  1.39it/s]Loading train:  59%|█████▊    | 167/285 [02:50<01:23,  1.41it/s]Loading train:  59%|█████▉    | 168/285 [02:50<01:23,  1.40it/s]Loading train:  59%|█████▉    | 169/285 [02:51<01:21,  1.42it/s]Loading train:  60%|█████▉    | 170/285 [02:52<01:19,  1.44it/s]Loading train:  60%|██████    | 171/285 [02:52<01:18,  1.45it/s]Loading train:  60%|██████    | 172/285 [02:53<01:17,  1.45it/s]Loading train:  61%|██████    | 173/285 [02:54<01:19,  1.40it/s]Loading train:  61%|██████    | 174/285 [02:54<01:17,  1.43it/s]Loading train:  61%|██████▏   | 175/285 [02:55<01:14,  1.47it/s]Loading train:  62%|██████▏   | 176/285 [02:56<01:13,  1.48it/s]Loading train:  62%|██████▏   | 177/285 [02:57<01:14,  1.44it/s]Loading train:  62%|██████▏   | 178/285 [02:57<01:14,  1.44it/s]Loading train:  63%|██████▎   | 179/285 [02:58<01:13,  1.45it/s]Loading train:  63%|██████▎   | 180/285 [02:59<01:10,  1.48it/s]Loading train:  64%|██████▎   | 181/285 [02:59<01:08,  1.52it/s]Loading train:  64%|██████▍   | 182/285 [03:00<01:10,  1.47it/s]Loading train:  64%|██████▍   | 183/285 [03:01<01:08,  1.48it/s]Loading train:  65%|██████▍   | 184/285 [03:01<01:08,  1.47it/s]Loading train:  65%|██████▍   | 185/285 [03:02<01:06,  1.51it/s]Loading train:  65%|██████▌   | 186/285 [03:03<01:05,  1.52it/s]Loading train:  66%|██████▌   | 187/285 [03:03<01:05,  1.50it/s]Loading train:  66%|██████▌   | 188/285 [03:04<01:03,  1.52it/s]Loading train:  66%|██████▋   | 189/285 [03:05<01:03,  1.51it/s]Loading train:  67%|██████▋   | 190/285 [03:05<01:02,  1.53it/s]Loading train:  67%|██████▋   | 191/285 [03:06<01:00,  1.55it/s]Loading train:  67%|██████▋   | 192/285 [03:06<00:59,  1.55it/s]Loading train:  68%|██████▊   | 193/285 [03:07<00:59,  1.55it/s]Loading train:  68%|██████▊   | 194/285 [03:08<00:59,  1.52it/s]Loading train:  68%|██████▊   | 195/285 [03:08<00:59,  1.52it/s]Loading train:  69%|██████▉   | 196/285 [03:09<01:00,  1.46it/s]Loading train:  69%|██████▉   | 197/285 [03:10<01:00,  1.46it/s]Loading train:  69%|██████▉   | 198/285 [03:11<01:00,  1.43it/s]Loading train:  70%|██████▉   | 199/285 [03:11<01:00,  1.43it/s]Loading train:  70%|███████   | 200/285 [03:12<01:01,  1.39it/s]Loading train:  71%|███████   | 201/285 [03:13<01:00,  1.38it/s]Loading train:  71%|███████   | 202/285 [03:13<00:59,  1.40it/s]Loading train:  71%|███████   | 203/285 [03:14<00:59,  1.38it/s]Loading train:  72%|███████▏  | 204/285 [03:15<00:59,  1.35it/s]Loading train:  72%|███████▏  | 205/285 [03:16<00:58,  1.36it/s]Loading train:  72%|███████▏  | 206/285 [03:17<00:59,  1.34it/s]Loading train:  73%|███████▎  | 207/285 [03:17<00:59,  1.31it/s]Loading train:  73%|███████▎  | 208/285 [03:18<01:00,  1.28it/s]Loading train:  73%|███████▎  | 209/285 [03:19<01:00,  1.27it/s]Loading train:  74%|███████▎  | 210/285 [03:20<00:59,  1.27it/s]Loading train:  74%|███████▍  | 211/285 [03:20<00:57,  1.28it/s]Loading train:  74%|███████▍  | 212/285 [03:21<00:56,  1.30it/s]Loading train:  75%|███████▍  | 213/285 [03:22<00:56,  1.28it/s]Loading train:  75%|███████▌  | 214/285 [03:23<00:56,  1.25it/s]Loading train:  75%|███████▌  | 215/285 [03:24<00:53,  1.30it/s]Loading train:  76%|███████▌  | 216/285 [03:24<00:51,  1.33it/s]Loading train:  76%|███████▌  | 217/285 [03:25<00:49,  1.36it/s]Loading train:  76%|███████▋  | 218/285 [03:26<00:49,  1.37it/s]Loading train:  77%|███████▋  | 219/285 [03:26<00:47,  1.38it/s]Loading train:  77%|███████▋  | 220/285 [03:27<00:46,  1.40it/s]Loading train:  78%|███████▊  | 221/285 [03:28<00:45,  1.42it/s]Loading train:  78%|███████▊  | 222/285 [03:28<00:43,  1.45it/s]Loading train:  78%|███████▊  | 223/285 [03:29<00:43,  1.43it/s]Loading train:  79%|███████▊  | 224/285 [03:30<00:42,  1.44it/s]Loading train:  79%|███████▉  | 225/285 [03:31<00:41,  1.46it/s]Loading train:  79%|███████▉  | 226/285 [03:31<00:40,  1.46it/s]Loading train:  80%|███████▉  | 227/285 [03:32<00:39,  1.45it/s]Loading train:  80%|████████  | 228/285 [03:33<00:39,  1.45it/s]Loading train:  80%|████████  | 229/285 [03:33<00:38,  1.45it/s]Loading train:  81%|████████  | 230/285 [03:34<00:38,  1.44it/s]Loading train:  81%|████████  | 231/285 [03:35<00:37,  1.45it/s]Loading train:  81%|████████▏ | 232/285 [03:36<00:39,  1.33it/s]Loading train:  82%|████████▏ | 233/285 [03:36<00:40,  1.27it/s]Loading train:  82%|████████▏ | 234/285 [03:37<00:41,  1.24it/s]Loading train:  82%|████████▏ | 235/285 [03:38<00:42,  1.18it/s]Loading train:  83%|████████▎ | 236/285 [03:39<00:42,  1.16it/s]Loading train:  83%|████████▎ | 237/285 [03:40<00:42,  1.14it/s]Loading train:  84%|████████▎ | 238/285 [03:41<00:40,  1.15it/s]Loading train:  84%|████████▍ | 239/285 [03:42<00:40,  1.13it/s]Loading train:  84%|████████▍ | 240/285 [03:43<00:40,  1.11it/s]Loading train:  85%|████████▍ | 241/285 [03:44<00:39,  1.12it/s]Loading train:  85%|████████▍ | 242/285 [03:45<00:38,  1.11it/s]Loading train:  85%|████████▌ | 243/285 [03:45<00:37,  1.12it/s]Loading train:  86%|████████▌ | 244/285 [03:46<00:36,  1.12it/s]Loading train:  86%|████████▌ | 245/285 [03:47<00:35,  1.11it/s]Loading train:  86%|████████▋ | 246/285 [03:48<00:34,  1.14it/s]Loading train:  87%|████████▋ | 247/285 [03:49<00:34,  1.10it/s]Loading train:  87%|████████▋ | 248/285 [03:50<00:33,  1.10it/s]Loading train:  87%|████████▋ | 249/285 [03:51<00:33,  1.09it/s]Loading train:  88%|████████▊ | 250/285 [03:52<00:29,  1.17it/s]Loading train:  88%|████████▊ | 251/285 [03:52<00:26,  1.26it/s]Loading train:  88%|████████▊ | 252/285 [03:53<00:24,  1.33it/s]Loading train:  89%|████████▉ | 253/285 [03:54<00:23,  1.39it/s]Loading train:  89%|████████▉ | 254/285 [03:54<00:22,  1.37it/s]Loading train:  89%|████████▉ | 255/285 [03:55<00:21,  1.41it/s]Loading train:  90%|████████▉ | 256/285 [03:56<00:19,  1.45it/s]Loading train:  90%|█████████ | 257/285 [03:56<00:18,  1.48it/s]Loading train:  91%|█████████ | 258/285 [03:57<00:18,  1.45it/s]Loading train:  91%|█████████ | 259/285 [03:58<00:17,  1.47it/s]Loading train:  91%|█████████ | 260/285 [03:58<00:17,  1.45it/s]Loading train:  92%|█████████▏| 261/285 [03:59<00:16,  1.48it/s]Loading train:  92%|█████████▏| 262/285 [04:00<00:15,  1.47it/s]Loading train:  92%|█████████▏| 263/285 [04:00<00:15,  1.44it/s]Loading train:  93%|█████████▎| 264/285 [04:01<00:14,  1.48it/s]Loading train:  93%|█████████▎| 265/285 [04:02<00:13,  1.48it/s]Loading train:  93%|█████████▎| 266/285 [04:02<00:12,  1.48it/s]Loading train:  94%|█████████▎| 267/285 [04:03<00:12,  1.49it/s]Loading train:  94%|█████████▍| 268/285 [04:04<00:12,  1.35it/s]Loading train:  94%|█████████▍| 269/285 [04:05<00:12,  1.26it/s]Loading train:  95%|█████████▍| 270/285 [04:06<00:12,  1.22it/s]Loading train:  95%|█████████▌| 271/285 [04:07<00:11,  1.18it/s]Loading train:  95%|█████████▌| 272/285 [04:08<00:11,  1.16it/s]Loading train:  96%|█████████▌| 273/285 [04:08<00:10,  1.15it/s]Loading train:  96%|█████████▌| 274/285 [04:09<00:09,  1.12it/s]Loading train:  96%|█████████▋| 275/285 [04:10<00:09,  1.10it/s]Loading train:  97%|█████████▋| 276/285 [04:11<00:08,  1.11it/s]Loading train:  97%|█████████▋| 277/285 [04:12<00:07,  1.08it/s]Loading train:  98%|█████████▊| 278/285 [04:13<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:14<00:05,  1.12it/s]Loading train:  98%|█████████▊| 280/285 [04:15<00:04,  1.12it/s]Loading train:  99%|█████████▊| 281/285 [04:16<00:03,  1.14it/s]Loading train:  99%|█████████▉| 282/285 [04:17<00:02,  1.12it/s]Loading train:  99%|█████████▉| 283/285 [04:18<00:01,  1.09it/s]Loading train: 100%|█████████▉| 284/285 [04:19<00:00,  1.07it/s]Loading train: 100%|██████████| 285/285 [04:19<00:00,  1.07it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:01, 226.24it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:00, 245.36it/s]concatenating: train:  29%|██▉       | 83/285 [00:00<00:00, 254.72it/s]concatenating: train:  39%|███▊      | 110/285 [00:00<00:00, 257.87it/s]concatenating: train:  50%|████▉     | 142/285 [00:00<00:00, 272.35it/s]concatenating: train:  60%|██████    | 171/285 [00:00<00:00, 265.45it/s]concatenating: train:  72%|███████▏  | 205/285 [00:00<00:00, 283.07it/s]concatenating: train:  85%|████████▍ | 242/285 [00:00<00:00, 302.79it/s]concatenating: train:  97%|█████████▋| 276/285 [00:00<00:00, 312.31it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 291.40it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 762.37it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-08 09:36:14.833449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 09:36:14.833568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 09:36:14.833583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 09:36:14.833593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 09:36:14.834012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 16s - loss: 17978.4693 - acc: 0.5273 - mDice: 0.0517 - val_loss: 13309.5291 - val_acc: 0.9030 - val_mDice: 0.0707

Epoch 00001: val_mDice improved from -inf to 0.07069, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 7s - loss: 10191.5819 - acc: 0.8592 - mDice: 0.1489 - val_loss: 6901.3009 - val_acc: 0.9050 - val_mDice: 0.2322

Epoch 00002: val_mDice improved from 0.07069 to 0.23221, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 7s - loss: 6368.3831 - acc: 0.8706 - mDice: 0.2764 - val_loss: 5826.0535 - val_acc: 0.9051 - val_mDice: 0.2928

Epoch 00003: val_mDice improved from 0.23221 to 0.29280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 8s - loss: 5157.9253 - acc: 0.8740 - mDice: 0.3517 - val_loss: 4326.7960 - val_acc: 0.9077 - val_mDice: 0.3944

Epoch 00004: val_mDice improved from 0.29280 to 0.39441, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 7s - loss: 4520.6323 - acc: 0.8762 - mDice: 0.4004 - val_loss: 3982.7200 - val_acc: 0.9090 - val_mDice: 0.4275

Epoch 00005: val_mDice improved from 0.39441 to 0.42746, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 7s - loss: 4077.5027 - acc: 0.8782 - mDice: 0.4377 - val_loss: 3833.4573 - val_acc: 0.9084 - val_mDice: 0.4349

Epoch 00006: val_mDice improved from 0.42746 to 0.43490, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 7s - loss: 3757.2453 - acc: 0.8807 - mDice: 0.4672 - val_loss: 3732.4609 - val_acc: 0.9103 - val_mDice: 0.4478

Epoch 00007: val_mDice improved from 0.43490 to 0.44776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 7s - loss: 3526.2138 - acc: 0.8837 - mDice: 0.4896 - val_loss: 3536.1678 - val_acc: 0.9122 - val_mDice: 0.4642

Epoch 00008: val_mDice improved from 0.44776 to 0.46418, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 7s - loss: 3384.4009 - acc: 0.8864 - mDice: 0.5041 - val_loss: 3526.2896 - val_acc: 0.9142 - val_mDice: 0.4648

Epoch 00009: val_mDice improved from 0.46418 to 0.46482, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 7s - loss: 3230.7724 - acc: 0.8902 - mDice: 0.5200 - val_loss: 3303.8173 - val_acc: 0.9155 - val_mDice: 0.4892

Epoch 00010: val_mDice improved from 0.46482 to 0.48918, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 7s - loss: 3096.3778 - acc: 0.8940 - mDice: 0.5342 - val_loss: 3497.0701 - val_acc: 0.9171 - val_mDice: 0.4707

Epoch 00011: val_mDice did not improve from 0.48918
Epoch 12/300
 - 7s - loss: 2989.3844 - acc: 0.8986 - mDice: 0.5459 - val_loss: 3174.3061 - val_acc: 0.9251 - val_mDice: 0.5036

Epoch 00012: val_mDice improved from 0.48918 to 0.50364, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 7s - loss: 2904.2100 - acc: 0.9038 - mDice: 0.5552 - val_loss: 3050.1674 - val_acc: 0.9342 - val_mDice: 0.5148

Epoch 00013: val_mDice improved from 0.50364 to 0.51484, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 7s - loss: 2816.6886 - acc: 0.9110 - mDice: 0.5650 - val_loss: 3178.7537 - val_acc: 0.9382 - val_mDice: 0.5006

Epoch 00014: val_mDice did not improve from 0.51484
Epoch 15/300
 - 7s - loss: 2741.3988 - acc: 0.9178 - mDice: 0.5734 - val_loss: 3052.1991 - val_acc: 0.9392 - val_mDice: 0.5141

Epoch 00015: val_mDice did not improve from 0.51484
Epoch 16/300
 - 7s - loss: 2659.6829 - acc: 0.9212 - mDice: 0.5827 - val_loss: 3492.5511 - val_acc: 0.9366 - val_mDice: 0.4662

Epoch 00016: val_mDice did not improve from 0.51484
Epoch 17/300
 - 7s - loss: 2604.3841 - acc: 0.9234 - mDice: 0.5893 - val_loss: 3189.6535 - val_acc: 0.9359 - val_mDice: 0.5018

Epoch 00017: val_mDice did not improve from 0.51484
Epoch 18/300
 - 7s - loss: 2542.5586 - acc: 0.9250 - mDice: 0.5966 - val_loss: 3053.0487 - val_acc: 0.9407 - val_mDice: 0.5140

Epoch 00018: val_mDice did not improve from 0.51484
Epoch 19/300
 - 7s - loss: 2485.6253 - acc: 0.9261 - mDice: 0.6035 - val_loss: 2905.5815 - val_acc: 0.9418 - val_mDice: 0.5295

Epoch 00019: val_mDice improved from 0.51484 to 0.52947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 7s - loss: 2446.7454 - acc: 0.9270 - mDice: 0.6082 - val_loss: 3053.3380 - val_acc: 0.9410 - val_mDice: 0.5142

Epoch 00020: val_mDice did not improve from 0.52947
Epoch 21/300
 - 7s - loss: 2405.2470 - acc: 0.9276 - mDice: 0.6134 - val_loss: 2965.0212 - val_acc: 0.9441 - val_mDice: 0.5236

Epoch 00021: val_mDice did not improve from 0.52947
Epoch 22/300
 - 7s - loss: 2372.8295 - acc: 0.9283 - mDice: 0.6176 - val_loss: 3102.3241 - val_acc: 0.9430 - val_mDice: 0.5063

Epoch 00022: val_mDice did not improve from 0.52947
Epoch 23/300
 - 7s - loss: 2334.3436 - acc: 0.9286 - mDice: 0.6223 - val_loss: 3061.3121 - val_acc: 0.9410 - val_mDice: 0.5133

Epoch 00023: val_mDice did not improve from 0.52947
Epoch 24/300
 - 7s - loss: 2283.9173 - acc: 0.9297 - mDice: 0.6288 - val_loss: 2971.7573 - val_acc: 0.9448 - val_mDice: 0.5211

Epoch 00024: val_mDice did not improve from 0.52947
Epoch 25/300
 - 7s - loss: 2257.4422 - acc: 0.9300 - mDice: 0.6322 - val_loss: 3250.1451 - val_acc: 0.9419 - val_mDice: 0.4922

Epoch 00025: val_mDice did not improve from 0.52947
Epoch 26/300
 - 7s - loss: 2240.4846 - acc: 0.9300 - mDice: 0.6343 - val_loss: 2982.7788 - val_acc: 0.9425 - val_mDice: 0.5203

Epoch 00026: val_mDice did not improve from 0.52947
Epoch 27/300
 - 7s - loss: 2200.9096 - acc: 0.9308 - mDice: 0.6396 - val_loss: 3116.9919 - val_acc: 0.9433 - val_mDice: 0.5049

Epoch 00027: val_mDice did not improve from 0.52947
Epoch 28/300
 - 7s - loss: 2191.4296 - acc: 0.9312 - mDice: 0.6410 - val_loss: 3088.6881 - val_acc: 0.9443 - val_mDice: 0.5109

Epoch 00028: val_mDice did not improve from 0.52947
Epoch 29/300
 - 7s - loss: 2159.5520 - acc: 0.9315 - mDice: 0.6450 - val_loss: 2922.9661 - val_acc: 0.9462 - val_mDice: 0.5280

Epoch 00029: val_mDice did not improve from 0.52947
Epoch 30/300
 - 7s - loss: 2134.5355 - acc: 0.9320 - mDice: 0.6483 - val_loss: 2987.1414 - val_acc: 0.9451 - val_mDice: 0.5193

Epoch 00030: val_mDice did not improve from 0.52947
Epoch 31/300
 - 7s - loss: 2113.8754 - acc: 0.9322 - mDice: 0.6509 - val_loss: 3102.4568 - val_acc: 0.9454 - val_mDice: 0.5075

Epoch 00031: val_mDice did not improve from 0.52947
Epoch 32/300
 - 7s - loss: 2096.4799 - acc: 0.9326 - mDice: 0.6534 - val_loss: 2902.2552 - val_acc: 0.9450 - val_mDice: 0.5289

Epoch 00032: val_mDice did not improve from 0.52947
Epoch 33/300
 - 7s - loss: 2078.4792 - acc: 0.9324 - mDice: 0.6556 - val_loss: 3327.9032 - val_acc: 0.9411 - val_mDice: 0.4837

Epoch 00033: val_mDice did not improve from 0.52947
Epoch 34/300
 - 7s - loss: 2051.8556 - acc: 0.9331 - mDice: 0.6593 - val_loss: 3114.3093 - val_acc: 0.9394 - val_mDice: 0.5080

Epoch 00034: val_mDice did not improve from 0.52947
Epoch 35/300
 - 7s - loss: 2044.8203 - acc: 0.9330 - mDice: 0.6602 - val_loss: 3089.5559 - val_acc: 0.9437 - val_mDice: 0.5098

Epoch 00035: val_mDice did not improve from 0.52947
Epoch 36/300
 - 7s - loss: 2017.5466 - acc: 0.9335 - mDice: 0.6638 - val_loss: 2997.1681 - val_acc: 0.9462 - val_mDice: 0.5199

Epoch 00036: val_mDice did not improve from 0.52947
Epoch 37/300
 - 7s - loss: 2011.2843 - acc: 0.9336 - mDice: 0.6646 - val_loss: 2929.7276 - val_acc: 0.9441 - val_mDice: 0.5260

Epoch 00037: val_mDice did not improve from 0.52947
Epoch 38/300
 - 7s - loss: 1984.0601 - acc: 0.9339 - mDice: 0.6683 - val_loss: 2799.4044 - val_acc: 0.9464 - val_mDice: 0.5404

Epoch 00038: val_mDice improved from 0.52947 to 0.54036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 39/300
 - 7s - loss: 1968.9891 - acc: 0.9341 - mDice: 0.6703 - val_loss: 3127.3653 - val_acc: 0.9441 - val_mDice: 0.5035

Epoch 00039: val_mDice did not improve from 0.54036
Epoch 40/300
 - 7s - loss: 1956.2471 - acc: 0.9344 - mDice: 0.6720 - val_loss: 2856.2858 - val_acc: 0.9478 - val_mDice: 0.5340

Epoch 00040: val_mDice did not improve from 0.54036
Epoch 41/300
 - 7s - loss: 1946.9526 - acc: 0.9345 - mDice: 0.6733 - val_loss: 3060.1442 - val_acc: 0.9421 - val_mDice: 0.5172

Epoch 00041: val_mDice did not improve from 0.54036
Epoch 42/300
 - 7s - loss: 1932.2804 - acc: 0.9343 - mDice: 0.6753 - val_loss: 3063.2296 - val_acc: 0.9451 - val_mDice: 0.5100

Epoch 00042: val_mDice did not improve from 0.54036
Epoch 43/300
 - 7s - loss: 1925.3646 - acc: 0.9346 - mDice: 0.6763 - val_loss: 3079.5407 - val_acc: 0.9460 - val_mDice: 0.5108

Epoch 00043: val_mDice did not improve from 0.54036
Epoch 44/300
 - 7s - loss: 1896.1208 - acc: 0.9353 - mDice: 0.6804 - val_loss: 3890.5520 - val_acc: 0.9350 - val_mDice: 0.4255

Epoch 00044: val_mDice did not improve from 0.54036
Epoch 45/300
 - 7s - loss: 1890.4731 - acc: 0.9351 - mDice: 0.6811 - val_loss: 3218.8095 - val_acc: 0.9429 - val_mDice: 0.4953

Epoch 00045: val_mDice did not improve from 0.54036
Epoch 46/300
 - 7s - loss: 1881.5912 - acc: 0.9352 - mDice: 0.6823 - val_loss: 2767.1809 - val_acc: 0.9484 - val_mDice: 0.5442

Epoch 00046: val_mDice improved from 0.54036 to 0.54420, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 47/300
 - 7s - loss: 1870.9103 - acc: 0.9354 - mDice: 0.6839 - val_loss: 2982.4769 - val_acc: 0.9434 - val_mDice: 0.5213

Epoch 00047: val_mDice did not improve from 0.54420
Epoch 48/300
 - 7s - loss: 1857.2562 - acc: 0.9356 - mDice: 0.6858 - val_loss: 3048.5141 - val_acc: 0.9469 - val_mDice: 0.5123

Epoch 00048: val_mDice did not improve from 0.54420
Epoch 49/300
 - 7s - loss: 1854.5213 - acc: 0.9355 - mDice: 0.6861 - val_loss: 2860.5544 - val_acc: 0.9476 - val_mDice: 0.5354

Epoch 00049: val_mDice did not improve from 0.54420
Epoch 50/300
 - 7s - loss: 1837.7703 - acc: 0.9360 - mDice: 0.6886 - val_loss: 2890.3318 - val_acc: 0.9452 - val_mDice: 0.5325

Epoch 00050: val_mDice did not improve from 0.54420
Epoch 51/300
 - 7s - loss: 1837.1554 - acc: 0.9360 - mDice: 0.6887 - val_loss: 2968.5868 - val_acc: 0.9473 - val_mDice: 0.5236

Epoch 00051: val_mDice did not improve from 0.54420
Epoch 52/300
 - 7s - loss: 1821.1640 - acc: 0.9361 - mDice: 0.6908 - val_loss: 2883.9837 - val_acc: 0.9461 - val_mDice: 0.5316

Epoch 00052: val_mDice did not improve from 0.54420
Epoch 53/300
 - 7s - loss: 1811.7971 - acc: 0.9363 - mDice: 0.6923 - val_loss: 2909.5823 - val_acc: 0.9472 - val_mDice: 0.5287

Epoch 00053: val_mDice did not improve from 0.54420
Epoch 54/300
 - 7s - loss: 1791.2046 - acc: 0.9368 - mDice: 0.6952 - val_loss: 2902.6833 - val_acc: 0.9441 - val_mDice: 0.5289

Epoch 00054: val_mDice did not improve from 0.54420
Epoch 55/300
 - 7s - loss: 1789.2291 - acc: 0.9366 - mDice: 0.6953 - val_loss: 3002.6102 - val_acc: 0.9446 - val_mDice: 0.5210

Epoch 00055: val_mDice did not improve from 0.54420
Epoch 56/300
 - 7s - loss: 1789.2235 - acc: 0.9367 - mDice: 0.6955 - val_loss: 2943.7632 - val_acc: 0.9484 - val_mDice: 0.5241

Epoch 00056: val_mDice did not improve from 0.54420
Epoch 57/300
 - 7s - loss: 1774.4570 - acc: 0.9370 - mDice: 0.6974 - val_loss: 2839.4903 - val_acc: 0.9480 - val_mDice: 0.5369

Epoch 00057: val_mDice did not improve from 0.54420
Epoch 58/300
 - 7s - loss: 1761.0328 - acc: 0.9371 - mDice: 0.6994 - val_loss: 2767.2646 - val_acc: 0.9453 - val_mDice: 0.5458

Epoch 00058: val_mDice improved from 0.54420 to 0.54582, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 59/300
 - 7s - loss: 1760.2265 - acc: 0.9373 - mDice: 0.6994 - val_loss: 3122.5929 - val_acc: 0.9458 - val_mDice: 0.5044

Epoch 00059: val_mDice did not improve from 0.54582
Epoch 60/300
 - 7s - loss: 1755.4241 - acc: 0.9373 - mDice: 0.7001 - val_loss: 2922.5231 - val_acc: 0.9460 - val_mDice: 0.5245

Epoch 00060: val_mDice did not improve from 0.54582
Epoch 61/300
 - 7s - loss: 1737.9066 - acc: 0.9377 - mDice: 0.7027 - val_loss: 2986.4571 - val_acc: 0.9447 - val_mDice: 0.5186

Epoch 00061: val_mDice did not improve from 0.54582
Epoch 62/300
 - 7s - loss: 1751.8173 - acc: 0.9374 - mDice: 0.7007 - val_loss: 2939.8108 - val_acc: 0.9466 - val_mDice: 0.5295

Epoch 00062: val_mDice did not improve from 0.54582
Epoch 63/300
 - 7s - loss: 1735.4229 - acc: 0.9379 - mDice: 0.7030 - val_loss: 3198.3813 - val_acc: 0.9421 - val_mDice: 0.4961

Epoch 00063: val_mDice did not improve from 0.54582
Epoch 64/300
 - 7s - loss: 1737.4611 - acc: 0.9378 - mDice: 0.7027 - val_loss: 2955.4366 - val_acc: 0.9478 - val_mDice: 0.5241

Epoch 00064: val_mDice did not improve from 0.54582
Epoch 65/300
 - 7s - loss: 1716.3451 - acc: 0.9382 - mDice: 0.7057 - val_loss: 2816.4864 - val_acc: 0.9484 - val_mDice: 0.5399

Epoch 00065: val_mDice did not improve from 0.54582
Epoch 66/300
 - 7s - loss: 1711.4711 - acc: 0.9383 - mDice: 0.7064 - val_loss: 3113.9582 - val_acc: 0.9411 - val_mDice: 0.5109

Epoch 00066: val_mDice did not improve from 0.54582
Epoch 67/300
 - 7s - loss: 1705.7520 - acc: 0.9383 - mDice: 0.7073 - val_loss: 2956.2884 - val_acc: 0.9422 - val_mDice: 0.5237

Epoch 00067: val_mDice did not improve from 0.54582
Epoch 68/300
 - 7s - loss: 1710.0496 - acc: 0.9384 - mDice: 0.7067 - val_loss: 3177.5865 - val_acc: 0.9347 - val_mDice: 0.5034

Epoch 00068: val_mDice did not improve from 0.54582
Epoch 69/300
 - 7s - loss: 1691.3863 - acc: 0.9387 - mDice: 0.7092 - val_loss: 3118.1770 - val_acc: 0.9451 - val_mDice: 0.5075

Epoch 00069: val_mDice did not improve from 0.54582
Epoch 70/300
 - 7s - loss: 1685.7065 - acc: 0.9388 - mDice: 0.7101 - val_loss: 3202.3845 - val_acc: 0.9470 - val_mDice: 0.4973

Epoch 00070: val_mDice did not improve from 0.54582
Epoch 71/300
 - 7s - loss: 1691.5413 - acc: 0.9386 - mDice: 0.7093 - val_loss: 2921.7444 - val_acc: 0.9473 - val_mDice: 0.5273

Epoch 00071: val_mDice did not improve from 0.54582
Epoch 72/300
 - 7s - loss: 1675.0760 - acc: 0.9388 - mDice: 0.7117 - val_loss: 2940.1723 - val_acc: 0.9465 - val_mDice: 0.5231

Epoch 00072: val_mDice did not improve from 0.54582
Epoch 73/300
 - 7s - loss: 1673.3673 - acc: 0.9391 - mDice: 0.7119 - val_loss: 3379.4053 - val_acc: 0.9439 - val_mDice: 0.4786

Epoch 00073: val_mDice did not improve from 0.54582
Epoch 74/300
 - 7s - loss: 1664.5478 - acc: 0.9391 - mDice: 0.7131 - val_loss: 2842.8021 - val_acc: 0.9477 - val_mDice: 0.5343

Epoch 00074: val_mDice did not improve from 0.54582
Epoch 75/300
 - 7s - loss: 1666.1646 - acc: 0.9391 - mDice: 0.7130 - val_loss: 2808.7794 - val_acc: 0.9420 - val_mDice: 0.5372

Epoch 00075: val_mDice did not improve from 0.54582
Epoch 76/300
 - 7s - loss: 1652.2641 - acc: 0.9394 - mDice: 0.7149 - val_loss: 2868.9412 - val_acc: 0.9459 - val_mDice: 0.5332

Epoch 00076: val_mDice did not improve from 0.54582
Epoch 77/300
 - 7s - loss: 1654.7390 - acc: 0.9392 - mDice: 0.7144 - val_loss: 2946.7015 - val_acc: 0.9466 - val_mDice: 0.5247

Epoch 00077: val_mDice did not improve from 0.54582
Epoch 78/300
 - 7s - loss: 1655.3662 - acc: 0.9392 - mDice: 0.7145 - val_loss: 2871.6014 - val_acc: 0.9463 - val_mDice: 0.5330

Epoch 00078: val_mDice did not improve from 0.54582
Epoch 79/300
 - 7s - loss: 1644.5012 - acc: 0.9394 - mDice: 0.7160 - val_loss: 2876.7475 - val_acc: 0.9462 - val_mDice: 0.5283

Epoch 00079: val_mDice did not improve from 0.54582
Epoch 80/300
 - 7s - loss: 1646.0013 - acc: 0.9395 - mDice: 0.7159 - val_loss: 2903.4450 - val_acc: 0.9442 - val_mDice: 0.5275

Epoch 00080: val_mDice did not improve from 0.54582
Epoch 81/300
 - 7s - loss: 1648.3927 - acc: 0.9393 - mDice: 0.7155 - val_loss: 2964.2555 - val_acc: 0.9455 - val_mDice: 0.5222

Epoch 00081: val_mDice did not improve from 0.54582
Epoch 82/300
 - 7s - loss: 1644.3967 - acc: 0.9395 - mDice: 0.7161 - val_loss: 2809.0672 - val_acc: 0.9482 - val_mDice: 0.5390

Epoch 00082: val_mDice did not improve from 0.54582
Epoch 83/300
 - 7s - loss: 1641.5807 - acc: 0.9396 - mDice: 0.7165 - val_loss: 2813.6355 - val_acc: 0.9456 - val_mDice: 0.5393

Epoch 00083: val_mDice did not improve from 0.54582
Epoch 84/300
 - 7s - loss: 1626.5973 - acc: 0.9398 - mDice: 0.7187 - val_loss: 3348.5825 - val_acc: 0.9451 - val_mDice: 0.4883

Epoch 00084: val_mDice did not improve from 0.54582
Epoch 85/300
 - 7s - loss: 1628.0045 - acc: 0.9400 - mDice: 0.7185 - val_loss: 2909.9613 - val_acc: 0.9479 - val_mDice: 0.5270

Epoch 00085: val_mDice did not improve from 0.54582
Epoch 86/300
 - 7s - loss: 1617.8743 - acc: 0.9401 - mDice: 0.7198 - val_loss: 2950.6694 - val_acc: 0.9491 - val_mDice: 0.5212

Epoch 00086: val_mDice did not improve from 0.54582
Epoch 87/300
 - 7s - loss: 1615.0077 - acc: 0.9404 - mDice: 0.7205 - val_loss: 2872.4741 - val_acc: 0.9486 - val_mDice: 0.5309

Epoch 00087: val_mDice did not improve from 0.54582
Epoch 88/300
 - 7s - loss: 1618.5311 - acc: 0.9402 - mDice: 0.7198 - val_loss: 2733.4662 - val_acc: 0.9494 - val_mDice: 0.5432

Epoch 00088: val_mDice did not improve from 0.54582
Restoring model weights from the end of the best epoch
Epoch 00088: early stopping
{'val_loss': [13309.529134114584, 6901.300851004465, 5826.053455171131, 4326.795968191965, 3982.720040457589, 3833.4573335193454, 3732.4609491257443, 3536.167794363839, 3526.289597284226, 3303.8172898065477, 3497.070109049479, 3174.3060942150296, 3050.1674223400296, 3178.753731863839, 3052.1990966796875, 3492.551089332217, 3189.6534598214284, 3053.0487351190477, 2905.5815080915177, 3053.3380010695682, 2965.021222795759, 3102.3240908668154, 3061.312052408854, 2971.7572719029017, 3250.1451241629466, 2982.778826032366, 3116.9918910435267, 3088.6881394159227, 2922.966064453125, 2987.141444614955, 3102.456816173735, 2902.2551792689733, 3327.9032156808034, 3114.309302920387, 3089.5559430803573, 2997.1681373232886, 2929.72756812686, 2799.4043956938244, 3127.365275065104, 2856.285824730283, 3060.144246419271, 3063.2296026320682, 3079.5406610398068, 3890.551972888765, 3218.809547061012, 2767.180914015997, 2982.4769054594494, 3048.514136904762, 2860.5543503534227, 2890.331810360863, 2968.5868094308034, 2883.9837007068454, 2909.582292829241, 2902.683303106399, 3002.6102411179318, 2943.763215564546, 2839.490280877976, 2767.264625186012, 3122.5929420107886, 2922.5230829148068, 2986.4570835658483, 2939.810767764137, 3198.381330217634, 2955.4365757533483, 2816.4863804408483, 3113.958234514509, 2956.2883823939733, 3177.586466471354, 3118.1770368303573, 3202.3845418294272, 2921.7443644205728, 2940.172293526786, 3379.405337379092, 2842.8021182105654, 2808.7794305710568, 2868.9412144252233, 2946.7015119280136, 2871.6013706752233, 2876.7474568684897, 2903.4449666341147, 2964.2555076962426, 2809.067170642671, 2813.635474795387, 3348.5825398763022, 2909.9612775530136, 2950.669436500186, 2872.474118187314, 2733.4661690848216], 'val_acc': [0.9029899182773772, 0.9049656476293292, 0.9050984240713573, 0.9076762937364125, 0.9089720589773995, 0.9084317968005226, 0.9102518132754734, 0.9122344312213716, 0.9141964486667088, 0.9155105295635405, 0.9170947869618734, 0.925148796467554, 0.9342147338958013, 0.9381730556488037, 0.9392422068686712, 0.9366415001097179, 0.9358882818903241, 0.9406547376087734, 0.9417971769968668, 0.9410050397827512, 0.9441071606817699, 0.942996811299097, 0.9409866985820589, 0.9448282832191104, 0.9418704396202451, 0.942470249675569, 0.9433333192552839, 0.9443475462141491, 0.9462179626737323, 0.9451258892104739, 0.9454097747802734, 0.9450206103779021, 0.9411034811110723, 0.9394047600882394, 0.9437270902452015, 0.9461836162067595, 0.9441231545947847, 0.9464262582006908, 0.9440979616982597, 0.9477815883500236, 0.9420878915559678, 0.9451373730387006, 0.9459523672149295, 0.9349610578446161, 0.9429166487285069, 0.9484317700068156, 0.9433974339848473, 0.9469139121827626, 0.9476419602121625, 0.9451648138818287, 0.9473306139310201, 0.9460645403180804, 0.9472481920605614, 0.9440750678380331, 0.9445879317465282, 0.948386013507843, 0.9479532894634065, 0.9453410903612772, 0.9458287670498803, 0.9460256156467256, 0.9447229618117923, 0.9465934151694888, 0.9420718579065233, 0.9477678310303461, 0.9484363510495141, 0.9410668611526489, 0.9422000845273336, 0.9347344438234965, 0.9451007559185937, 0.9470123478344509, 0.9473374485969543, 0.9464903814452035, 0.9439262946446737, 0.9476808650153024, 0.9420444028718131, 0.9459317638760522, 0.9466323171343122, 0.9463209538232713, 0.946201931862604, 0.9442491105624607, 0.9454738866715204, 0.9482211697669256, 0.945588387194134, 0.9451144593102592, 0.9478777505102611, 0.9490773933274406, 0.9486355071976071, 0.9494116107622782], 'val_mDice': [0.07068951778291237, 0.23220567445137671, 0.29279521941429093, 0.39441320796807605, 0.42745926692372277, 0.434898839819999, 0.4477572098729156, 0.464175812367882, 0.46481800434135256, 0.4891792214697316, 0.4706681624409698, 0.5036399540092263, 0.5148431371365275, 0.5006440743094399, 0.5141301573742003, 0.46621984527224586, 0.5018224634584927, 0.5139560252428055, 0.5294706856920606, 0.5142256991849059, 0.5235814947102752, 0.5062525336231504, 0.5133018933591389, 0.5210555875230403, 0.49223153044780094, 0.5202830611240297, 0.50487733738763, 0.5109057969280651, 0.5280263698881581, 0.5192710890301636, 0.5075132069843156, 0.5289192330979166, 0.4836840643769219, 0.507984571158886, 0.5098097592237449, 0.5198773940404257, 0.5260126745062215, 0.5403648315086251, 0.5035081136794317, 0.5339754555551779, 0.5172290184668132, 0.5100416821383295, 0.5108048793460641, 0.4255048070280325, 0.495338265030157, 0.5442021812001864, 0.5213364119685832, 0.5123091340065002, 0.5353887391587099, 0.5324613464375337, 0.5235623319943746, 0.5315517206631956, 0.528728457256442, 0.5288817793840453, 0.5209600689510504, 0.5241336634471303, 0.5368682655195395, 0.5458239570614838, 0.5044348931738308, 0.5244738693748202, 0.5186010583170823, 0.5295395345560142, 0.4961272960617429, 0.5240949236211323, 0.5399062693828628, 0.5109227885093007, 0.523725185365904, 0.5034051232394718, 0.5074512701304186, 0.4973140660495985, 0.527271531522274, 0.5231170134530181, 0.4785812835962999, 0.534289344790436, 0.5372417162926424, 0.5331594658394655, 0.524713973913874, 0.5329900550700369, 0.5283085978811696, 0.527507541789895, 0.5221900143438861, 0.5390353067999795, 0.5393049415378344, 0.48829645947331474, 0.5270265681403024, 0.5212053356780892, 0.5308663892958846, 0.5431883033542406], 'loss': [17978.46929448019, 10191.581891929343, 6368.383138020833, 5157.925298663952, 4520.632254934963, 4077.502702161805, 3757.245327392249, 3526.213816824965, 3384.4008783414365, 3230.772367649141, 3096.3777900844357, 2989.384373785651, 2904.2100203370505, 2816.6886194603094, 2741.398768245358, 2659.682926893556, 2604.384121855307, 2542.5585905258563, 2485.6252914437537, 2446.745432212216, 2405.246977471285, 2372.8295379750457, 2334.343638567008, 2283.9172943627095, 2257.4421931293077, 2240.4845566581344, 2200.9095940487864, 2191.429590163811, 2159.552023463105, 2134.535548324688, 2113.8753689173354, 2096.479850702854, 2078.4792243011752, 2051.85557702945, 2044.8202893191135, 2017.5465522090985, 2011.2843028639056, 1984.0600996839303, 1968.9891463089064, 1956.2470714891947, 1946.9526352596486, 1932.2803952489396, 1925.3646476750018, 1896.1208226395315, 1890.4730663281175, 1881.5911765686, 1870.9102518211469, 1857.25622276187, 1854.5212789005643, 1837.770313563732, 1837.1554418695853, 1821.1639778015126, 1811.7970923590526, 1791.204567015872, 1789.2290977358887, 1789.2235006932144, 1774.4570188476375, 1761.032761393794, 1760.226469164573, 1755.424111190687, 1737.90661519898, 1751.817338309905, 1735.4228713309717, 1737.4610968009342, 1716.3451074821219, 1711.4711266409713, 1705.7520026638485, 1710.0495919646246, 1691.3862680053123, 1685.7064973600618, 1691.5413026443814, 1675.0759876516713, 1673.3672507355755, 1664.5478265459699, 1666.1645808811015, 1652.2640686800007, 1654.7390447601501, 1655.366233765378, 1644.5011503603134, 1646.0013292885158, 1648.39266096431, 1644.3966857074704, 1641.580696901697, 1626.5973056420348, 1628.0045410062114, 1617.874338085674, 1615.0076510574816, 1618.531113950554], 'acc': [0.5272829106329998, 0.8591738455047814, 0.8705503150565054, 0.8739629436348223, 0.8761659614815058, 0.8782447040460233, 0.8807344486057495, 0.8836578773767336, 0.8863840656218925, 0.89021731615756, 0.8939690180474769, 0.8986217384281383, 0.9037978641785062, 0.9110242554349478, 0.9177789843700652, 0.9211896223462982, 0.9234393071135459, 0.9249964346999674, 0.9261001297244912, 0.9269871705755554, 0.9275562243354052, 0.9282689418364334, 0.928605030767486, 0.9296585122284596, 0.9300093564863997, 0.9300218423207601, 0.9308464411184326, 0.9311741818024838, 0.9314893401034516, 0.9319908488961987, 0.9321625085839513, 0.9325787901579586, 0.9324118116238868, 0.9330749891961221, 0.9330389362919508, 0.933528696638048, 0.9335524503357819, 0.9338944170868924, 0.9340715899342444, 0.934382901086912, 0.9345017737889074, 0.9343287973061953, 0.93462284859927, 0.9352629935555268, 0.935058800694293, 0.9352363657349219, 0.9353515758826044, 0.9355701103889806, 0.9355432560431468, 0.9360055326151439, 0.9360103782188095, 0.9361313778195327, 0.9362897137605503, 0.9368434286149729, 0.9365730562811301, 0.9366990440793181, 0.9369685769035151, 0.9371340754911438, 0.93730566039443, 0.937312356293121, 0.9377446690344824, 0.9374249209460437, 0.9378580314611593, 0.937787564016386, 0.9381664443939941, 0.9382861525377649, 0.9382916233179678, 0.9384321827798399, 0.9387082982458589, 0.9387938211780994, 0.9386215190311055, 0.9388227611234337, 0.9390738065219325, 0.9390516573348118, 0.9390528828095259, 0.9393714940315822, 0.939240228205902, 0.9392164294283492, 0.9393880641228297, 0.9395257273298572, 0.9393232503055906, 0.9394816566989076, 0.9395660939808639, 0.9398106012428016, 0.9399603636411428, 0.9400686219590281, 0.9403739107558327, 0.940175442870743], 'mDice': [0.051746062831337314, 0.1489003600729714, 0.276444123054208, 0.35167733028442016, 0.4003948467830851, 0.43774011311145883, 0.4671905768361192, 0.4896177430246661, 0.504064385868438, 0.5199747220707326, 0.534216279707273, 0.5459016230332959, 0.5552144783963949, 0.564953422291283, 0.5734461894700907, 0.5826771281141064, 0.5892871274915026, 0.596552935298385, 0.6034609801695253, 0.6082224805437348, 0.6134416019385643, 0.6176026339404083, 0.6223433889794814, 0.6287604023754333, 0.632191037934066, 0.6343086785104478, 0.6396415410805741, 0.6409667341355669, 0.6450077472267203, 0.6482585727053846, 0.6509496234781094, 0.6534076209515994, 0.6556218160653542, 0.6592572696157933, 0.6601861449870986, 0.6637798276093738, 0.6646134874621682, 0.6682987328161273, 0.6703171737395847, 0.6720325688716418, 0.673331944060413, 0.675345795529643, 0.6763292150458826, 0.680375488088934, 0.6811253059707857, 0.6822754457343031, 0.6838770538183543, 0.6858204814057969, 0.6861396635086614, 0.6886080521045219, 0.6887320186881769, 0.6907910739201122, 0.6922616906678123, 0.6951842950630077, 0.6952649918001512, 0.6955205331722941, 0.6974238662308803, 0.6993703932253778, 0.699377436421385, 0.700138575589011, 0.7026753315742659, 0.7007149371517999, 0.7030178545894296, 0.7026820501794883, 0.7056961095997288, 0.7063612941029859, 0.7073424255799668, 0.7067186761872258, 0.7092422249231215, 0.7101075215125465, 0.7092726700379942, 0.7117137726685756, 0.7119285311914028, 0.7131189526747664, 0.713026069022797, 0.7149124612048892, 0.7144364064912334, 0.7145319221473416, 0.7160479490044996, 0.7158552721697218, 0.71548323173249, 0.7161088243187198, 0.7165078453551558, 0.71867070532222, 0.7184717786870574, 0.7198462736314722, 0.720457079313108, 0.7198411166633465]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.23s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:55,  1.46s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:10,  1.52s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:04,  1.51s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:39,  1.64s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:15,  1.56s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:47,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:13,  1.78s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:31,  1.85s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:10,  1.78s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:26,  1.84s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:37,  1.89s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:38,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:41,  1.92s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:37,  1.91s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:42,  1.94s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:42,  1.94s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:49,  1.98s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:52,  2.00s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:38,  1.96s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:38,  1.96s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:37,  1.97s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:39,  1.98s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:35,  1.98s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:36,  1.99s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:35,  1.99s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:29,  1.97s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:19,  1.94s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:06,  1.90s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:03,  1.90s/it]predicting train subjects:  11%|█         | 31/285 [00:58<07:57,  1.88s/it]predicting train subjects:  11%|█         | 32/285 [01:00<07:53,  1.87s/it]predicting train subjects:  12%|█▏        | 33/285 [01:02<07:46,  1.85s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:40,  1.84s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<07:38,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:40,  1.85s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:45,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:47,  1.89s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:45,  1.89s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<07:42,  1.89s/it]predicting train subjects:  14%|█▍        | 41/285 [01:17<07:42,  1.89s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:49,  1.93s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:47,  1.93s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:41,  1.91s/it]predicting train subjects:  16%|█▌        | 45/285 [01:24<07:33,  1.89s/it]predicting train subjects:  16%|█▌        | 46/285 [01:26<07:10,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<06:52,  1.73s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<06:33,  1.67s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<06:21,  1.62s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<06:15,  1.60s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<06:12,  1.60s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<06:14,  1.61s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<06:08,  1.60s/it]predicting train subjects:  19%|█▉        | 55/285 [01:40<06:07,  1.60s/it]predicting train subjects:  20%|█▉        | 56/285 [01:42<06:07,  1.61s/it]predicting train subjects:  20%|██        | 57/285 [01:43<06:03,  1.60s/it]predicting train subjects:  20%|██        | 58/285 [01:45<06:01,  1.59s/it]predicting train subjects:  21%|██        | 59/285 [01:47<05:58,  1.59s/it]predicting train subjects:  21%|██        | 60/285 [01:48<05:58,  1.59s/it]predicting train subjects:  21%|██▏       | 61/285 [01:50<05:55,  1.59s/it]predicting train subjects:  22%|██▏       | 62/285 [01:51<05:56,  1.60s/it]predicting train subjects:  22%|██▏       | 63/285 [01:53<05:57,  1.61s/it]predicting train subjects:  22%|██▏       | 64/285 [01:55<06:03,  1.64s/it]predicting train subjects:  23%|██▎       | 65/285 [01:57<06:21,  1.73s/it]predicting train subjects:  23%|██▎       | 66/285 [01:59<06:29,  1.78s/it]predicting train subjects:  24%|██▎       | 67/285 [02:00<06:20,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [02:02<06:11,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [02:04<06:09,  1.71s/it]predicting train subjects:  25%|██▍       | 70/285 [02:05<06:06,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:07<06:01,  1.69s/it]predicting train subjects:  25%|██▌       | 72/285 [02:09<05:59,  1.69s/it]predicting train subjects:  26%|██▌       | 73/285 [02:10<05:57,  1.68s/it]predicting train subjects:  26%|██▌       | 74/285 [02:12<05:58,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:14<05:54,  1.69s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<05:45,  1.65s/it]predicting train subjects:  27%|██▋       | 77/285 [02:17<05:44,  1.66s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<05:40,  1.65s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<05:40,  1.65s/it]predicting train subjects:  28%|██▊       | 80/285 [02:22<05:36,  1.64s/it]predicting train subjects:  28%|██▊       | 81/285 [02:24<05:41,  1.67s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:41,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:27<05:37,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:29<05:35,  1.67s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:44,  1.72s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:50,  1.76s/it]predicting train subjects:  31%|███       | 87/285 [02:34<05:52,  1.78s/it]predicting train subjects:  31%|███       | 88/285 [02:36<05:58,  1.82s/it]predicting train subjects:  31%|███       | 89/285 [02:38<05:59,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:40<06:02,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:42<06:02,  1.87s/it]predicting train subjects:  32%|███▏      | 92/285 [02:44<06:09,  1.91s/it]predicting train subjects:  33%|███▎      | 93/285 [02:46<06:06,  1.91s/it]predicting train subjects:  33%|███▎      | 94/285 [02:47<06:01,  1.89s/it]predicting train subjects:  33%|███▎      | 95/285 [02:49<05:52,  1.85s/it]predicting train subjects:  34%|███▎      | 96/285 [02:51<05:49,  1.85s/it]predicting train subjects:  34%|███▍      | 97/285 [02:53<05:49,  1.86s/it]predicting train subjects:  34%|███▍      | 98/285 [02:55<05:47,  1.86s/it]predicting train subjects:  35%|███▍      | 99/285 [02:57<05:48,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [02:59<05:48,  1.89s/it]predicting train subjects:  35%|███▌      | 101/285 [03:00<05:44,  1.87s/it]predicting train subjects:  36%|███▌      | 102/285 [03:02<05:54,  1.94s/it]predicting train subjects:  36%|███▌      | 103/285 [03:04<05:44,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:06<05:41,  1.89s/it]predicting train subjects:  37%|███▋      | 105/285 [03:08<05:39,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:10<05:36,  1.88s/it]predicting train subjects:  38%|███▊      | 107/285 [03:12<05:47,  1.95s/it]predicting train subjects:  38%|███▊      | 108/285 [03:14<05:36,  1.90s/it]predicting train subjects:  38%|███▊      | 109/285 [03:16<05:32,  1.89s/it]predicting train subjects:  39%|███▊      | 110/285 [03:18<05:28,  1.88s/it]predicting train subjects:  39%|███▉      | 111/285 [03:19<05:24,  1.87s/it]predicting train subjects:  39%|███▉      | 112/285 [03:21<05:25,  1.88s/it]predicting train subjects:  40%|███▉      | 113/285 [03:23<05:21,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:21,  1.88s/it]predicting train subjects:  40%|████      | 115/285 [03:27<05:15,  1.85s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:13,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:30<05:08,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:32<05:07,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [03:34<05:08,  1.86s/it]predicting train subjects:  42%|████▏     | 120/285 [03:36<05:04,  1.85s/it]predicting train subjects:  42%|████▏     | 121/285 [03:38<04:52,  1.78s/it]predicting train subjects:  43%|████▎     | 122/285 [03:39<04:34,  1.68s/it]predicting train subjects:  43%|████▎     | 123/285 [03:41<04:19,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:42<04:18,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:44<04:16,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:45<04:16,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:47<04:14,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [03:49<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:50<04:10,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [03:52<04:08,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [03:53<04:03,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [03:55<04:04,  1.60s/it]predicting train subjects:  47%|████▋     | 133/285 [03:57<04:02,  1.60s/it]predicting train subjects:  47%|████▋     | 134/285 [03:58<04:03,  1.61s/it]predicting train subjects:  47%|████▋     | 135/285 [04:00<04:02,  1.61s/it]predicting train subjects:  48%|████▊     | 136/285 [04:01<04:02,  1.63s/it]predicting train subjects:  48%|████▊     | 137/285 [04:03<04:02,  1.64s/it]predicting train subjects:  48%|████▊     | 138/285 [04:05<03:59,  1.63s/it]predicting train subjects:  49%|████▉     | 139/285 [04:06<03:58,  1.63s/it]predicting train subjects:  49%|████▉     | 140/285 [04:08<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:10<03:53,  1.62s/it]predicting train subjects:  50%|████▉     | 142/285 [04:11<03:46,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:13<03:41,  1.56s/it]predicting train subjects:  51%|█████     | 144/285 [04:14<03:33,  1.51s/it]predicting train subjects:  51%|█████     | 145/285 [04:16<03:29,  1.50s/it]predicting train subjects:  51%|█████     | 146/285 [04:17<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:18<03:22,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:20<03:19,  1.45s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:21<03:17,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:23<03:18,  1.47s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:24<03:18,  1.48s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:26<03:14,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:27<03:14,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:29<03:13,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:30<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:32<03:15,  1.52s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:33<03:13,  1.51s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:35<03:07,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:36<03:06,  1.48s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:38<03:04,  1.48s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:39<03:03,  1.48s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:41<03:00,  1.47s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:42<02:56,  1.45s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:43<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:45<02:54,  1.45s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:46<02:52,  1.45s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:48<02:50,  1.44s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:49<02:49,  1.45s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:51<02:48,  1.46s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:52<02:45,  1.44s/it]predicting train subjects:  60%|██████    | 171/285 [04:54<02:45,  1.45s/it]predicting train subjects:  60%|██████    | 172/285 [04:55<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:56<02:40,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:58<02:40,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:59<02:37,  1.43s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:01<02:39,  1.46s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:02<02:38,  1.47s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:04<02:35,  1.45s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:05<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:07<02:31,  1.44s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:08<02:28,  1.43s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:09<02:26,  1.42s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:11<02:23,  1.41s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:12<02:22,  1.41s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:14<02:21,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:15<02:19,  1.41s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:16<02:17,  1.40s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:18<02:16,  1.40s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:19<02:13,  1.40s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:20<02:12,  1.40s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:22<02:09,  1.38s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:23<02:09,  1.39s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:25<02:06,  1.38s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:26<02:05,  1.38s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:27<02:04,  1.38s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:29<02:09,  1.46s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:31<02:14,  1.53s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:32<02:16,  1.57s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:34<02:17,  1.60s/it]predicting train subjects:  70%|███████   | 200/285 [05:36<02:17,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [05:37<02:17,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:39<02:16,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:41<02:14,  1.64s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:42<02:12,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:44<02:11,  1.64s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:46<02:09,  1.64s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:47<02:10,  1.67s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:49<02:08,  1.67s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:51<02:06,  1.66s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:52<02:05,  1.67s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:54<02:03,  1.67s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:56<02:01,  1.67s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:57<02:00,  1.67s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:59<01:55,  1.62s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:00<01:50,  1.57s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:02<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:03<01:42,  1.51s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:05<01:42,  1.53s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:06<01:41,  1.53s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:08<01:38,  1.52s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:09<01:35,  1.49s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:11<01:33,  1.48s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:12<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:14<01:30,  1.48s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:15<01:28,  1.47s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:17<01:27,  1.48s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:18<01:25,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:20<01:24,  1.47s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:23,  1.49s/it]predicting train subjects:  81%|████████  | 230/285 [06:23<01:21,  1.48s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:26<01:24,  1.59s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:28<01:26,  1.67s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:30<01:28,  1.73s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:29,  1.78s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:29,  1.83s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:28,  1.84s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:37<01:27,  1.86s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:39<01:26,  1.88s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:41<01:24,  1.87s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:43<01:23,  1.90s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:45<01:22,  1.93s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:47<01:22,  1.96s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:49<01:20,  1.96s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:51<01:17,  1.94s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:53<01:14,  1.92s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:55<01:12,  1.91s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:56<01:10,  1.92s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:58<01:09,  1.92s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:00<01:02,  1.79s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:01<00:57,  1.68s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:03<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:04<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:06<00:47,  1.52s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:07<00:44,  1.49s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:08<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [07:10<00:40,  1.45s/it]predicting train subjects:  91%|█████████ | 258/285 [07:11<00:39,  1.46s/it]predicting train subjects:  91%|█████████ | 259/285 [07:13<00:37,  1.43s/it]predicting train subjects:  91%|█████████ | 260/285 [07:14<00:36,  1.45s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:16<00:34,  1.43s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:17<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:18<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:20<00:29,  1.41s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:21<00:28,  1.41s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:23<00:26,  1.40s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:24<00:25,  1.41s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:26<00:26,  1.58s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:28<00:26,  1.67s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:30<00:26,  1.76s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:32<00:25,  1.80s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:34<00:23,  1.82s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:36<00:22,  1.84s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:37<00:20,  1.87s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:39<00:18,  1.89s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:41<00:17,  1.91s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:43<00:15,  1.91s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:45<00:13,  1.91s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:47<00:11,  1.88s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:49<00:09,  1.87s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:51<00:07,  1.88s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:53<00:05,  1.86s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:54<00:03,  1.87s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:56<00:01,  1.85s/it]predicting train subjects: 100%|██████████| 285/285 [07:58<00:00,  1.84s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:53,  1.46s/it]Loading train:   1%|          | 2/285 [00:03<07:00,  1.49s/it]Loading train:   1%|          | 3/285 [00:04<06:48,  1.45s/it]Loading train:   1%|▏         | 4/285 [00:05<06:55,  1.48s/it]Loading train:   2%|▏         | 5/285 [00:07<06:29,  1.39s/it]Loading train:   2%|▏         | 6/285 [00:08<06:54,  1.48s/it]Loading train:   2%|▏         | 7/285 [00:10<07:15,  1.57s/it]Loading train:   3%|▎         | 8/285 [00:12<07:27,  1.62s/it]Loading train:   3%|▎         | 9/285 [00:13<07:06,  1.54s/it]Loading train:   4%|▎         | 10/285 [00:14<06:29,  1.42s/it]Loading train:   4%|▍         | 11/285 [00:16<06:18,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:17<06:02,  1.33s/it]Loading train:   5%|▍         | 13/285 [00:18<06:03,  1.34s/it]Loading train:   5%|▍         | 14/285 [00:20<06:02,  1.34s/it]Loading train:   5%|▌         | 15/285 [00:21<05:51,  1.30s/it]Loading train:   6%|▌         | 16/285 [00:22<05:45,  1.28s/it]Loading train:   6%|▌         | 17/285 [00:23<05:43,  1.28s/it]Loading train:   6%|▋         | 18/285 [00:24<05:39,  1.27s/it]Loading train:   7%|▋         | 19/285 [00:26<05:30,  1.24s/it]Loading train:   7%|▋         | 20/285 [00:27<05:30,  1.25s/it]Loading train:   7%|▋         | 21/285 [00:28<05:30,  1.25s/it]Loading train:   8%|▊         | 22/285 [00:29<05:17,  1.21s/it]Loading train:   8%|▊         | 23/285 [00:31<05:26,  1.24s/it]Loading train:   8%|▊         | 24/285 [00:32<05:18,  1.22s/it]Loading train:   9%|▉         | 25/285 [00:33<05:13,  1.21s/it]Loading train:   9%|▉         | 26/285 [00:34<05:07,  1.19s/it]Loading train:   9%|▉         | 27/285 [00:35<05:02,  1.17s/it]Loading train:  10%|▉         | 28/285 [00:36<05:00,  1.17s/it]Loading train:  10%|█         | 29/285 [00:37<04:43,  1.11s/it]Loading train:  11%|█         | 30/285 [00:38<04:35,  1.08s/it]Loading train:  11%|█         | 31/285 [00:39<04:29,  1.06s/it]Loading train:  11%|█         | 32/285 [00:40<04:22,  1.04s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:38,  1.11s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:35,  1.10s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:38,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:34,  1.10s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:33,  1.10s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:31,  1.10s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:24,  1.07s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:23,  1.07s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:18,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:21,  1.07s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:20,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:18,  1.07s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:14,  1.06s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:13,  1.06s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:05,  1.03s/it]Loading train:  17%|█▋        | 48/285 [00:57<03:52,  1.02it/s]Loading train:  17%|█▋        | 49/285 [00:58<03:56,  1.00s/it]Loading train:  18%|█▊        | 50/285 [00:59<03:49,  1.02it/s]Loading train:  18%|█▊        | 51/285 [01:00<03:47,  1.03it/s]Loading train:  18%|█▊        | 52/285 [01:01<03:45,  1.03it/s]Loading train:  19%|█▊        | 53/285 [01:02<03:40,  1.05it/s]Loading train:  19%|█▉        | 54/285 [01:03<03:44,  1.03it/s]Loading train:  19%|█▉        | 55/285 [01:04<03:42,  1.03it/s]Loading train:  20%|█▉        | 56/285 [01:05<03:38,  1.05it/s]Loading train:  20%|██        | 57/285 [01:06<03:40,  1.03it/s]Loading train:  20%|██        | 58/285 [01:07<03:39,  1.04it/s]Loading train:  21%|██        | 59/285 [01:08<03:34,  1.05it/s]Loading train:  21%|██        | 60/285 [01:09<03:30,  1.07it/s]Loading train:  21%|██▏       | 61/285 [01:10<03:30,  1.07it/s]Loading train:  22%|██▏       | 62/285 [01:11<03:26,  1.08it/s]Loading train:  22%|██▏       | 63/285 [01:12<03:26,  1.08it/s]Loading train:  22%|██▏       | 64/285 [01:13<04:02,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:15<04:36,  1.26s/it]Loading train:  23%|██▎       | 66/285 [01:16<04:45,  1.30s/it]Loading train:  24%|██▎       | 67/285 [01:17<04:27,  1.23s/it]Loading train:  24%|██▍       | 68/285 [01:18<04:15,  1.18s/it]Loading train:  24%|██▍       | 69/285 [01:19<04:04,  1.13s/it]Loading train:  25%|██▍       | 70/285 [01:20<03:56,  1.10s/it]Loading train:  25%|██▍       | 71/285 [01:21<03:46,  1.06s/it]Loading train:  25%|██▌       | 72/285 [01:22<03:36,  1.02s/it]Loading train:  26%|██▌       | 73/285 [01:23<03:38,  1.03s/it]Loading train:  26%|██▌       | 74/285 [01:24<03:34,  1.01s/it]Loading train:  26%|██▋       | 75/285 [01:25<03:27,  1.01it/s]Loading train:  27%|██▋       | 76/285 [01:26<03:23,  1.03it/s]Loading train:  27%|██▋       | 77/285 [01:27<03:19,  1.04it/s]Loading train:  27%|██▋       | 78/285 [01:28<03:21,  1.03it/s]Loading train:  28%|██▊       | 79/285 [01:29<03:17,  1.04it/s]Loading train:  28%|██▊       | 80/285 [01:30<03:21,  1.02it/s]Loading train:  28%|██▊       | 81/285 [01:31<03:25,  1.01s/it]Loading train:  29%|██▉       | 82/285 [01:32<03:20,  1.01it/s]Loading train:  29%|██▉       | 83/285 [01:33<03:19,  1.01it/s]Loading train:  29%|██▉       | 84/285 [01:34<03:18,  1.01it/s]Loading train:  30%|██▉       | 85/285 [01:35<03:26,  1.03s/it]Loading train:  30%|███       | 86/285 [01:36<03:29,  1.05s/it]Loading train:  31%|███       | 87/285 [01:37<03:27,  1.05s/it]Loading train:  31%|███       | 88/285 [01:38<03:30,  1.07s/it]Loading train:  31%|███       | 89/285 [01:39<03:26,  1.06s/it]Loading train:  32%|███▏      | 90/285 [01:41<03:32,  1.09s/it]Loading train:  32%|███▏      | 91/285 [01:42<03:31,  1.09s/it]Loading train:  32%|███▏      | 92/285 [01:43<03:34,  1.11s/it]Loading train:  33%|███▎      | 93/285 [01:44<03:28,  1.08s/it]Loading train:  33%|███▎      | 94/285 [01:45<03:22,  1.06s/it]Loading train:  33%|███▎      | 95/285 [01:46<03:28,  1.10s/it]Loading train:  34%|███▎      | 96/285 [01:47<03:21,  1.07s/it]Loading train:  34%|███▍      | 97/285 [01:48<03:24,  1.09s/it]Loading train:  34%|███▍      | 98/285 [01:49<03:25,  1.10s/it]Loading train:  35%|███▍      | 99/285 [01:50<03:24,  1.10s/it]Loading train:  35%|███▌      | 100/285 [01:52<03:21,  1.09s/it]Loading train:  35%|███▌      | 101/285 [01:53<03:22,  1.10s/it]Loading train:  36%|███▌      | 102/285 [01:54<03:16,  1.07s/it]Loading train:  36%|███▌      | 103/285 [01:55<03:20,  1.10s/it]Loading train:  36%|███▋      | 104/285 [01:56<03:21,  1.11s/it]Loading train:  37%|███▋      | 105/285 [01:57<03:19,  1.11s/it]Loading train:  37%|███▋      | 106/285 [01:58<03:16,  1.10s/it]Loading train:  38%|███▊      | 107/285 [01:59<03:18,  1.11s/it]Loading train:  38%|███▊      | 108/285 [02:00<03:20,  1.13s/it]Loading train:  38%|███▊      | 109/285 [02:01<03:11,  1.09s/it]Loading train:  39%|███▊      | 110/285 [02:03<03:10,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:04<03:10,  1.09s/it]Loading train:  39%|███▉      | 112/285 [02:05<03:06,  1.08s/it]Loading train:  40%|███▉      | 113/285 [02:06<03:06,  1.09s/it]Loading train:  40%|████      | 114/285 [02:07<03:06,  1.09s/it]Loading train:  40%|████      | 115/285 [02:08<03:07,  1.10s/it]Loading train:  41%|████      | 116/285 [02:09<03:02,  1.08s/it]Loading train:  41%|████      | 117/285 [02:10<03:01,  1.08s/it]Loading train:  41%|████▏     | 118/285 [02:11<02:57,  1.06s/it]Loading train:  42%|████▏     | 119/285 [02:12<02:55,  1.06s/it]Loading train:  42%|████▏     | 120/285 [02:13<02:51,  1.04s/it]Loading train:  42%|████▏     | 121/285 [02:14<03:03,  1.12s/it]Loading train:  43%|████▎     | 122/285 [02:16<03:06,  1.14s/it]Loading train:  43%|████▎     | 123/285 [02:17<03:14,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:18<03:00,  1.12s/it]Loading train:  44%|████▍     | 125/285 [02:19<02:50,  1.06s/it]Loading train:  44%|████▍     | 126/285 [02:20<02:42,  1.02s/it]Loading train:  45%|████▍     | 127/285 [02:21<02:36,  1.01it/s]Loading train:  45%|████▍     | 128/285 [02:22<02:34,  1.02it/s]Loading train:  45%|████▌     | 129/285 [02:23<02:29,  1.04it/s]Loading train:  46%|████▌     | 130/285 [02:24<02:28,  1.04it/s]Loading train:  46%|████▌     | 131/285 [02:24<02:23,  1.07it/s]Loading train:  46%|████▋     | 132/285 [02:26<02:29,  1.02it/s]Loading train:  47%|████▋     | 133/285 [02:26<02:28,  1.02it/s]Loading train:  47%|████▋     | 134/285 [02:28<02:39,  1.05s/it]Loading train:  47%|████▋     | 135/285 [02:29<02:31,  1.01s/it]Loading train:  48%|████▊     | 136/285 [02:30<02:34,  1.04s/it]Loading train:  48%|████▊     | 137/285 [02:31<02:30,  1.02s/it]Loading train:  48%|████▊     | 138/285 [02:32<02:24,  1.01it/s]Loading train:  49%|████▉     | 139/285 [02:33<02:20,  1.04it/s]Loading train:  49%|████▉     | 140/285 [02:33<02:19,  1.04it/s]Loading train:  49%|████▉     | 141/285 [02:34<02:19,  1.03it/s]Loading train:  50%|████▉     | 142/285 [02:35<02:19,  1.02it/s]Loading train:  50%|█████     | 143/285 [02:36<02:17,  1.03it/s]Loading train:  51%|█████     | 144/285 [02:37<02:13,  1.06it/s]Loading train:  51%|█████     | 145/285 [02:38<02:11,  1.07it/s]Loading train:  51%|█████     | 146/285 [02:39<02:15,  1.02it/s]Loading train:  52%|█████▏    | 147/285 [02:40<02:13,  1.03it/s]Loading train:  52%|█████▏    | 148/285 [02:41<02:07,  1.07it/s]Loading train:  52%|█████▏    | 149/285 [02:42<02:03,  1.10it/s]Loading train:  53%|█████▎    | 150/285 [02:43<02:00,  1.12it/s]Loading train:  53%|█████▎    | 151/285 [02:44<01:59,  1.12it/s]Loading train:  53%|█████▎    | 152/285 [02:45<01:57,  1.14it/s]Loading train:  54%|█████▎    | 153/285 [02:46<02:06,  1.04it/s]Loading train:  54%|█████▍    | 154/285 [02:47<02:04,  1.05it/s]Loading train:  54%|█████▍    | 155/285 [02:47<02:00,  1.08it/s]Loading train:  55%|█████▍    | 156/285 [02:48<01:57,  1.10it/s]Loading train:  55%|█████▌    | 157/285 [02:49<01:56,  1.10it/s]Loading train:  55%|█████▌    | 158/285 [02:50<01:52,  1.13it/s]Loading train:  56%|█████▌    | 159/285 [02:51<01:51,  1.13it/s]Loading train:  56%|█████▌    | 160/285 [02:52<01:58,  1.06it/s]Loading train:  56%|█████▋    | 161/285 [02:53<01:56,  1.06it/s]Loading train:  57%|█████▋    | 162/285 [02:54<01:57,  1.05it/s]Loading train:  57%|█████▋    | 163/285 [02:55<01:54,  1.07it/s]Loading train:  58%|█████▊    | 164/285 [02:56<01:52,  1.08it/s]Loading train:  58%|█████▊    | 165/285 [02:57<01:52,  1.06it/s]Loading train:  58%|█████▊    | 166/285 [02:58<01:49,  1.09it/s]Loading train:  59%|█████▊    | 167/285 [02:59<01:47,  1.10it/s]Loading train:  59%|█████▉    | 168/285 [02:59<01:44,  1.12it/s]Loading train:  59%|█████▉    | 169/285 [03:00<01:42,  1.13it/s]Loading train:  60%|█████▉    | 170/285 [03:01<01:41,  1.13it/s]Loading train:  60%|██████    | 171/285 [03:02<01:41,  1.13it/s]Loading train:  60%|██████    | 172/285 [03:03<01:37,  1.15it/s]Loading train:  61%|██████    | 173/285 [03:04<01:40,  1.11it/s]Loading train:  61%|██████    | 174/285 [03:05<01:36,  1.15it/s]Loading train:  61%|██████▏   | 175/285 [03:05<01:36,  1.14it/s]Loading train:  62%|██████▏   | 176/285 [03:06<01:32,  1.18it/s]Loading train:  62%|██████▏   | 177/285 [03:07<01:30,  1.19it/s]Loading train:  62%|██████▏   | 178/285 [03:08<01:29,  1.19it/s]Loading train:  63%|██████▎   | 179/285 [03:09<01:29,  1.19it/s]Loading train:  63%|██████▎   | 180/285 [03:10<01:28,  1.18it/s]Loading train:  64%|██████▎   | 181/285 [03:11<01:32,  1.12it/s]Loading train:  64%|██████▍   | 182/285 [03:11<01:30,  1.14it/s]Loading train:  64%|██████▍   | 183/285 [03:12<01:30,  1.13it/s]Loading train:  65%|██████▍   | 184/285 [03:13<01:30,  1.11it/s]Loading train:  65%|██████▍   | 185/285 [03:14<01:30,  1.10it/s]Loading train:  65%|██████▌   | 186/285 [03:15<01:35,  1.04it/s]Loading train:  66%|██████▌   | 187/285 [03:16<01:30,  1.08it/s]Loading train:  66%|██████▌   | 188/285 [03:17<01:30,  1.08it/s]Loading train:  66%|██████▋   | 189/285 [03:18<01:25,  1.12it/s]Loading train:  67%|██████▋   | 190/285 [03:19<01:24,  1.13it/s]Loading train:  67%|██████▋   | 191/285 [03:20<01:25,  1.10it/s]Loading train:  67%|██████▋   | 192/285 [03:21<01:24,  1.10it/s]Loading train:  68%|██████▊   | 193/285 [03:22<01:23,  1.10it/s]Loading train:  68%|██████▊   | 194/285 [03:22<01:20,  1.13it/s]Loading train:  68%|██████▊   | 195/285 [03:23<01:19,  1.13it/s]Loading train:  69%|██████▉   | 196/285 [03:24<01:21,  1.09it/s]Loading train:  69%|██████▉   | 197/285 [03:25<01:22,  1.07it/s]Loading train:  69%|██████▉   | 198/285 [03:26<01:22,  1.06it/s]Loading train:  70%|██████▉   | 199/285 [03:27<01:21,  1.05it/s]Loading train:  70%|███████   | 200/285 [03:28<01:23,  1.02it/s]Loading train:  71%|███████   | 201/285 [03:29<01:21,  1.03it/s]Loading train:  71%|███████   | 202/285 [03:30<01:22,  1.01it/s]Loading train:  71%|███████   | 203/285 [03:31<01:20,  1.02it/s]Loading train:  72%|███████▏  | 204/285 [03:32<01:18,  1.03it/s]Loading train:  72%|███████▏  | 205/285 [03:33<01:15,  1.06it/s]Loading train:  72%|███████▏  | 206/285 [03:34<01:16,  1.03it/s]Loading train:  73%|███████▎  | 207/285 [03:35<01:14,  1.05it/s]Loading train:  73%|███████▎  | 208/285 [03:36<01:13,  1.05it/s]Loading train:  73%|███████▎  | 209/285 [03:37<01:15,  1.01it/s]Loading train:  74%|███████▎  | 210/285 [03:38<01:12,  1.03it/s]Loading train:  74%|███████▍  | 211/285 [03:39<01:12,  1.02it/s]Loading train:  74%|███████▍  | 212/285 [03:40<01:10,  1.03it/s]Loading train:  75%|███████▍  | 213/285 [03:41<01:10,  1.03it/s]Loading train:  75%|███████▌  | 214/285 [03:42<01:06,  1.07it/s]Loading train:  75%|███████▌  | 215/285 [03:43<01:05,  1.07it/s]Loading train:  76%|███████▌  | 216/285 [03:43<01:02,  1.11it/s]Loading train:  76%|███████▌  | 217/285 [03:44<01:03,  1.07it/s]Loading train:  76%|███████▋  | 218/285 [03:45<01:03,  1.06it/s]Loading train:  77%|███████▋  | 219/285 [03:46<01:04,  1.02it/s]Loading train:  77%|███████▋  | 220/285 [03:47<01:02,  1.04it/s]Loading train:  78%|███████▊  | 221/285 [03:49<01:04,  1.01s/it]Loading train:  78%|███████▊  | 222/285 [03:49<00:59,  1.06it/s]Loading train:  78%|███████▊  | 223/285 [03:50<00:57,  1.08it/s]Loading train:  79%|███████▊  | 224/285 [03:51<00:54,  1.11it/s]Loading train:  79%|███████▉  | 225/285 [03:52<00:53,  1.12it/s]Loading train:  79%|███████▉  | 226/285 [03:53<00:54,  1.08it/s]Loading train:  80%|███████▉  | 227/285 [03:54<00:53,  1.08it/s]Loading train:  80%|████████  | 228/285 [03:55<00:52,  1.09it/s]Loading train:  80%|████████  | 229/285 [03:56<00:51,  1.09it/s]Loading train:  81%|████████  | 230/285 [03:57<00:50,  1.10it/s]Loading train:  81%|████████  | 231/285 [03:57<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [03:58<00:49,  1.06it/s]Loading train:  82%|████████▏ | 233/285 [04:00<00:51,  1.02it/s]Loading train:  82%|████████▏ | 234/285 [04:01<00:50,  1.02it/s]Loading train:  82%|████████▏ | 235/285 [04:02<00:50,  1.02s/it]Loading train:  83%|████████▎ | 236/285 [04:03<00:49,  1.02s/it]Loading train:  83%|████████▎ | 237/285 [04:04<00:50,  1.05s/it]Loading train:  84%|████████▎ | 238/285 [04:05<00:48,  1.02s/it]Loading train:  84%|████████▍ | 239/285 [04:06<00:47,  1.04s/it]Loading train:  84%|████████▍ | 240/285 [04:07<00:46,  1.03s/it]Loading train:  85%|████████▍ | 241/285 [04:08<00:45,  1.04s/it]Loading train:  85%|████████▍ | 242/285 [04:09<00:45,  1.05s/it]Loading train:  85%|████████▌ | 243/285 [04:10<00:44,  1.05s/it]Loading train:  86%|████████▌ | 244/285 [04:11<00:42,  1.05s/it]Loading train:  86%|████████▌ | 245/285 [04:12<00:41,  1.05s/it]Loading train:  86%|████████▋ | 246/285 [04:13<00:41,  1.08s/it]Loading train:  87%|████████▋ | 247/285 [04:14<00:41,  1.10s/it]Loading train:  87%|████████▋ | 248/285 [04:15<00:40,  1.08s/it]Loading train:  87%|████████▋ | 249/285 [04:16<00:37,  1.04s/it]Loading train:  88%|████████▊ | 250/285 [04:17<00:33,  1.04it/s]Loading train:  88%|████████▊ | 251/285 [04:18<00:33,  1.02it/s]Loading train:  88%|████████▊ | 252/285 [04:19<00:30,  1.07it/s]Loading train:  89%|████████▉ | 253/285 [04:20<00:29,  1.07it/s]Loading train:  89%|████████▉ | 254/285 [04:21<00:29,  1.07it/s]Loading train:  89%|████████▉ | 255/285 [04:22<00:26,  1.11it/s]Loading train:  90%|████████▉ | 256/285 [04:23<00:25,  1.12it/s]Loading train:  90%|█████████ | 257/285 [04:23<00:24,  1.12it/s]Loading train:  91%|█████████ | 258/285 [04:24<00:24,  1.12it/s]Loading train:  91%|█████████ | 259/285 [04:25<00:22,  1.14it/s]Loading train:  91%|█████████ | 260/285 [04:26<00:22,  1.13it/s]Loading train:  92%|█████████▏| 261/285 [04:27<00:22,  1.09it/s]Loading train:  92%|█████████▏| 262/285 [04:28<00:21,  1.07it/s]Loading train:  92%|█████████▏| 263/285 [04:29<00:20,  1.06it/s]Loading train:  93%|█████████▎| 264/285 [04:30<00:19,  1.08it/s]Loading train:  93%|█████████▎| 265/285 [04:31<00:19,  1.04it/s]Loading train:  93%|█████████▎| 266/285 [04:32<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [04:33<00:16,  1.08it/s]Loading train:  94%|█████████▍| 268/285 [04:34<00:16,  1.01it/s]Loading train:  94%|█████████▍| 269/285 [04:35<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:36<00:15,  1.01s/it]Loading train:  95%|█████████▌| 271/285 [04:37<00:14,  1.03s/it]Loading train:  95%|█████████▌| 272/285 [04:38<00:13,  1.03s/it]Loading train:  96%|█████████▌| 273/285 [04:39<00:12,  1.05s/it]Loading train:  96%|█████████▌| 274/285 [04:40<00:11,  1.06s/it]Loading train:  96%|█████████▋| 275/285 [04:41<00:10,  1.06s/it]Loading train:  97%|█████████▋| 276/285 [04:42<00:09,  1.06s/it]Loading train:  97%|█████████▋| 277/285 [04:44<00:08,  1.09s/it]Loading train:  98%|█████████▊| 278/285 [04:45<00:07,  1.06s/it]Loading train:  98%|█████████▊| 279/285 [04:46<00:06,  1.08s/it]Loading train:  98%|█████████▊| 280/285 [04:47<00:05,  1.06s/it]Loading train:  99%|█████████▊| 281/285 [04:48<00:04,  1.08s/it]Loading train:  99%|█████████▉| 282/285 [04:49<00:03,  1.08s/it]Loading train:  99%|█████████▉| 283/285 [04:50<00:02,  1.07s/it]Loading train: 100%|█████████▉| 284/285 [04:51<00:01,  1.09s/it]Loading train: 100%|██████████| 285/285 [04:52<00:00,  1.14s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:01, 234.89it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:00, 251.26it/s]concatenating: train:  29%|██▉       | 83/285 [00:00<00:00, 256.65it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 265.27it/s]concatenating: train:  49%|████▉     | 140/285 [00:00<00:00, 268.37it/s]concatenating: train:  59%|█████▉    | 168/285 [00:00<00:00, 269.63it/s]concatenating: train:  68%|██████▊   | 193/285 [00:00<00:00, 198.00it/s]concatenating: train:  78%|███████▊  | 223/285 [00:00<00:00, 220.47it/s]concatenating: train:  89%|████████▉ | 255/285 [00:01<00:00, 242.39it/s]concatenating: train: 100%|█████████▉| 284/285 [00:01<00:00, 253.50it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 253.36it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.34s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.30s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 74.00it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 20)   0           batch_normalization_7[0][0]      2019-07-08 10:00:05.971482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 10:00:05.971597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 10:00:05.971616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 10:00:05.971627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 10:00:05.972046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 17s - loss: 14047.5436 - acc: 0.6872 - mDice: 0.1070 - val_loss: 6328.1309 - val_acc: 0.9115 - val_mDice: 0.2585

Epoch 00001: val_mDice improved from -inf to 0.25850, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 5796.2983 - acc: 0.8908 - mDice: 0.3179 - val_loss: 3828.3901 - val_acc: 0.9187 - val_mDice: 0.4314

Epoch 00002: val_mDice improved from 0.25850 to 0.43142, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 4471.5556 - acc: 0.8950 - mDice: 0.4098 - val_loss: 3553.3349 - val_acc: 0.9181 - val_mDice: 0.4662

Epoch 00003: val_mDice improved from 0.43142 to 0.46622, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 3861.5570 - acc: 0.8989 - mDice: 0.4621 - val_loss: 3082.5800 - val_acc: 0.9224 - val_mDice: 0.5079

Epoch 00004: val_mDice improved from 0.46622 to 0.50795, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 3463.7931 - acc: 0.9030 - mDice: 0.4991 - val_loss: 2845.0398 - val_acc: 0.9268 - val_mDice: 0.5328

Epoch 00005: val_mDice improved from 0.50795 to 0.53284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 10s - loss: 3295.2877 - acc: 0.9096 - mDice: 0.5163 - val_loss: 2783.1781 - val_acc: 0.9360 - val_mDice: 0.5475

Epoch 00006: val_mDice improved from 0.53284 to 0.54746, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 2971.3684 - acc: 0.9220 - mDice: 0.5490 - val_loss: 2576.7265 - val_acc: 0.9418 - val_mDice: 0.5637

Epoch 00007: val_mDice improved from 0.54746 to 0.56374, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 9s - loss: 2833.4088 - acc: 0.9287 - mDice: 0.5640 - val_loss: 2638.7555 - val_acc: 0.9432 - val_mDice: 0.5647

Epoch 00008: val_mDice improved from 0.56374 to 0.56473, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 2685.8653 - acc: 0.9315 - mDice: 0.5804 - val_loss: 2618.0337 - val_acc: 0.9407 - val_mDice: 0.5631

Epoch 00009: val_mDice did not improve from 0.56473
Epoch 10/300
 - 9s - loss: 2584.3051 - acc: 0.9332 - mDice: 0.5924 - val_loss: 2457.3751 - val_acc: 0.9458 - val_mDice: 0.5803

Epoch 00010: val_mDice improved from 0.56473 to 0.58034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 9s - loss: 2483.2129 - acc: 0.9352 - mDice: 0.6045 - val_loss: 2596.0226 - val_acc: 0.9501 - val_mDice: 0.5794

Epoch 00011: val_mDice did not improve from 0.58034
Epoch 12/300
 - 9s - loss: 2448.1074 - acc: 0.9359 - mDice: 0.6099 - val_loss: 2273.8486 - val_acc: 0.9479 - val_mDice: 0.6012

Epoch 00012: val_mDice improved from 0.58034 to 0.60120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 2637.1384 - acc: 0.9333 - mDice: 0.5918 - val_loss: 2633.1569 - val_acc: 0.9484 - val_mDice: 0.5663

Epoch 00013: val_mDice did not improve from 0.60120
Epoch 14/300
 - 10s - loss: 2379.0375 - acc: 0.9362 - mDice: 0.6179 - val_loss: 2313.3212 - val_acc: 0.9481 - val_mDice: 0.5965

Epoch 00014: val_mDice did not improve from 0.60120
Epoch 15/300
 - 9s - loss: 2257.6260 - acc: 0.9377 - mDice: 0.6329 - val_loss: 2303.0298 - val_acc: 0.9483 - val_mDice: 0.5977

Epoch 00015: val_mDice did not improve from 0.60120
Epoch 16/300
 - 9s - loss: 2173.5770 - acc: 0.9388 - mDice: 0.6438 - val_loss: 2297.7684 - val_acc: 0.9519 - val_mDice: 0.6051

Epoch 00016: val_mDice improved from 0.60120 to 0.60514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 2119.7530 - acc: 0.9393 - mDice: 0.6508 - val_loss: 2224.0634 - val_acc: 0.9512 - val_mDice: 0.6102

Epoch 00017: val_mDice improved from 0.60514 to 0.61020, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 9s - loss: 2068.5589 - acc: 0.9398 - mDice: 0.6576 - val_loss: 2335.7875 - val_acc: 0.9471 - val_mDice: 0.5943

Epoch 00018: val_mDice did not improve from 0.61020
Epoch 19/300
 - 9s - loss: 2027.7364 - acc: 0.9403 - mDice: 0.6631 - val_loss: 2349.5771 - val_acc: 0.9512 - val_mDice: 0.6010

Epoch 00019: val_mDice did not improve from 0.61020
Epoch 20/300
 - 10s - loss: 1999.0478 - acc: 0.9406 - mDice: 0.6669 - val_loss: 2198.4110 - val_acc: 0.9525 - val_mDice: 0.6150

Epoch 00020: val_mDice improved from 0.61020 to 0.61499, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 10s - loss: 1959.2442 - acc: 0.9409 - mDice: 0.6721 - val_loss: 2503.3873 - val_acc: 0.9522 - val_mDice: 0.5898

Epoch 00021: val_mDice did not improve from 0.61499
Epoch 22/300
 - 10s - loss: 1921.0832 - acc: 0.9412 - mDice: 0.6772 - val_loss: 2325.0419 - val_acc: 0.9517 - val_mDice: 0.6024

Epoch 00022: val_mDice did not improve from 0.61499
Epoch 23/300
 - 10s - loss: 1884.6085 - acc: 0.9416 - mDice: 0.6821 - val_loss: 2438.6501 - val_acc: 0.9512 - val_mDice: 0.5972

Epoch 00023: val_mDice did not improve from 0.61499
Epoch 24/300
 - 9s - loss: 1864.9698 - acc: 0.9417 - mDice: 0.6849 - val_loss: 2544.8334 - val_acc: 0.9523 - val_mDice: 0.5879

Epoch 00024: val_mDice did not improve from 0.61499
Epoch 25/300
 - 9s - loss: 1843.6646 - acc: 0.9419 - mDice: 0.6878 - val_loss: 2403.7886 - val_acc: 0.9527 - val_mDice: 0.6012

Epoch 00025: val_mDice did not improve from 0.61499
Epoch 26/300
 - 10s - loss: 1811.1289 - acc: 0.9421 - mDice: 0.6923 - val_loss: 2393.3685 - val_acc: 0.9519 - val_mDice: 0.6022

Epoch 00026: val_mDice did not improve from 0.61499
Epoch 27/300
 - 10s - loss: 1803.5163 - acc: 0.9418 - mDice: 0.6931 - val_loss: 2252.2867 - val_acc: 0.9524 - val_mDice: 0.6085

Epoch 00027: val_mDice did not improve from 0.61499
Epoch 28/300
 - 10s - loss: 1790.0207 - acc: 0.9420 - mDice: 0.6954 - val_loss: 2426.8704 - val_acc: 0.9491 - val_mDice: 0.5910

Epoch 00028: val_mDice did not improve from 0.61499
Epoch 29/300
 - 10s - loss: 1768.9988 - acc: 0.9418 - mDice: 0.6981 - val_loss: 2352.1892 - val_acc: 0.9503 - val_mDice: 0.5992

Epoch 00029: val_mDice did not improve from 0.61499
Epoch 30/300
 - 10s - loss: 1739.8355 - acc: 0.9421 - mDice: 0.7022 - val_loss: 2406.7612 - val_acc: 0.9516 - val_mDice: 0.5944

Epoch 00030: val_mDice did not improve from 0.61499
Epoch 31/300
 - 10s - loss: 1731.8037 - acc: 0.9422 - mDice: 0.7033 - val_loss: 2353.2824 - val_acc: 0.9508 - val_mDice: 0.6055

Epoch 00031: val_mDice did not improve from 0.61499
Epoch 32/300
 - 10s - loss: 1730.9032 - acc: 0.9424 - mDice: 0.7038 - val_loss: 2710.4197 - val_acc: 0.9514 - val_mDice: 0.5946

Epoch 00032: val_mDice did not improve from 0.61499
Epoch 33/300
 - 10s - loss: 1706.8175 - acc: 0.9426 - mDice: 0.7070 - val_loss: 2481.6716 - val_acc: 0.9506 - val_mDice: 0.5922

Epoch 00033: val_mDice did not improve from 0.61499
Epoch 34/300
 - 10s - loss: 1684.7838 - acc: 0.9429 - mDice: 0.7100 - val_loss: 2658.4389 - val_acc: 0.9477 - val_mDice: 0.5722

Epoch 00034: val_mDice did not improve from 0.61499
Epoch 35/300
 - 10s - loss: 1673.0785 - acc: 0.9430 - mDice: 0.7117 - val_loss: 2386.3778 - val_acc: 0.9516 - val_mDice: 0.5950

Epoch 00035: val_mDice did not improve from 0.61499
Epoch 36/300
 - 10s - loss: 1661.5111 - acc: 0.9433 - mDice: 0.7133 - val_loss: 2297.2946 - val_acc: 0.9526 - val_mDice: 0.6101

Epoch 00036: val_mDice did not improve from 0.61499
Epoch 37/300
 - 10s - loss: 1655.7230 - acc: 0.9435 - mDice: 0.7143 - val_loss: 2341.3138 - val_acc: 0.9521 - val_mDice: 0.6067

Epoch 00037: val_mDice did not improve from 0.61499
Epoch 38/300
 - 11s - loss: 1644.5853 - acc: 0.9434 - mDice: 0.7159 - val_loss: 2449.5036 - val_acc: 0.9500 - val_mDice: 0.5816

Epoch 00038: val_mDice did not improve from 0.61499
Epoch 39/300
 - 10s - loss: 1631.8954 - acc: 0.9435 - mDice: 0.7176 - val_loss: 2311.9977 - val_acc: 0.9506 - val_mDice: 0.5988

Epoch 00039: val_mDice did not improve from 0.61499
Epoch 40/300
 - 10s - loss: 1637.6757 - acc: 0.9436 - mDice: 0.7169 - val_loss: 2400.6452 - val_acc: 0.9496 - val_mDice: 0.5889

Epoch 00040: val_mDice did not improve from 0.61499
Epoch 41/300
 - 10s - loss: 1608.7650 - acc: 0.9439 - mDice: 0.7210 - val_loss: 2540.7410 - val_acc: 0.9513 - val_mDice: 0.5840

Epoch 00041: val_mDice did not improve from 0.61499
Epoch 42/300
 - 10s - loss: 1590.2761 - acc: 0.9441 - mDice: 0.7236 - val_loss: 2241.5893 - val_acc: 0.9525 - val_mDice: 0.6086

Epoch 00042: val_mDice did not improve from 0.61499
Epoch 43/300
 - 10s - loss: 1597.2587 - acc: 0.9439 - mDice: 0.7226 - val_loss: 2284.3377 - val_acc: 0.9522 - val_mDice: 0.6068

Epoch 00043: val_mDice did not improve from 0.61499
Epoch 44/300
 - 10s - loss: 1600.8989 - acc: 0.9439 - mDice: 0.7223 - val_loss: 2342.3424 - val_acc: 0.9513 - val_mDice: 0.5988

Epoch 00044: val_mDice did not improve from 0.61499
Epoch 45/300
 - 10s - loss: 1583.7387 - acc: 0.9440 - mDice: 0.7246 - val_loss: 2359.8012 - val_acc: 0.9530 - val_mDice: 0.5984

Epoch 00045: val_mDice did not improve from 0.61499
Epoch 46/300
 - 11s - loss: 1563.5495 - acc: 0.9443 - mDice: 0.7276 - val_loss: 2305.1070 - val_acc: 0.9510 - val_mDice: 0.6036

Epoch 00046: val_mDice did not improve from 0.61499
Epoch 47/300
 - 10s - loss: 1563.4571 - acc: 0.9443 - mDice: 0.7275 - val_loss: 2484.0208 - val_acc: 0.9527 - val_mDice: 0.5896

Epoch 00047: val_mDice did not improve from 0.61499
Epoch 48/300
 - 10s - loss: 1551.0623 - acc: 0.9445 - mDice: 0.7295 - val_loss: 2572.1745 - val_acc: 0.9530 - val_mDice: 0.5934

Epoch 00048: val_mDice did not improve from 0.61499
Epoch 49/300
 - 10s - loss: 1549.0396 - acc: 0.9447 - mDice: 0.7298 - val_loss: 2369.5683 - val_acc: 0.9523 - val_mDice: 0.5996

Epoch 00049: val_mDice did not improve from 0.61499
Epoch 50/300
 - 10s - loss: 1537.5208 - acc: 0.9447 - mDice: 0.7315 - val_loss: 2221.8446 - val_acc: 0.9532 - val_mDice: 0.6163

Epoch 00050: val_mDice improved from 0.61499 to 0.61630, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 51/300
 - 10s - loss: 1533.6372 - acc: 0.9448 - mDice: 0.7320 - val_loss: 2598.4586 - val_acc: 0.9527 - val_mDice: 0.5962

Epoch 00051: val_mDice did not improve from 0.61630
Epoch 52/300
 - 10s - loss: 1529.0676 - acc: 0.9449 - mDice: 0.7327 - val_loss: 2268.2897 - val_acc: 0.9528 - val_mDice: 0.6071

Epoch 00052: val_mDice did not improve from 0.61630
Epoch 53/300
 - 10s - loss: 1522.6809 - acc: 0.9451 - mDice: 0.7337 - val_loss: 2284.8916 - val_acc: 0.9523 - val_mDice: 0.6068

Epoch 00053: val_mDice did not improve from 0.61630
Epoch 54/300
 - 10s - loss: 1515.9096 - acc: 0.9453 - mDice: 0.7346 - val_loss: 2432.5263 - val_acc: 0.9528 - val_mDice: 0.5943

Epoch 00054: val_mDice did not improve from 0.61630
Epoch 55/300
 - 11s - loss: 1499.3018 - acc: 0.9455 - mDice: 0.7370 - val_loss: 2448.3056 - val_acc: 0.9531 - val_mDice: 0.5944

Epoch 00055: val_mDice did not improve from 0.61630
Epoch 56/300
 - 12s - loss: 1503.2181 - acc: 0.9454 - mDice: 0.7364 - val_loss: 2614.6563 - val_acc: 0.9517 - val_mDice: 0.5776

Epoch 00056: val_mDice did not improve from 0.61630
Epoch 57/300
 - 10s - loss: 1500.4747 - acc: 0.9456 - mDice: 0.7369 - val_loss: 2469.3844 - val_acc: 0.9525 - val_mDice: 0.5931

Epoch 00057: val_mDice did not improve from 0.61630
Epoch 58/300
 - 10s - loss: 1497.3997 - acc: 0.9457 - mDice: 0.7373 - val_loss: 2331.3350 - val_acc: 0.9527 - val_mDice: 0.6018

Epoch 00058: val_mDice did not improve from 0.61630
Epoch 59/300
 - 10s - loss: 1485.8483 - acc: 0.9460 - mDice: 0.7390 - val_loss: 2456.3983 - val_acc: 0.9514 - val_mDice: 0.5944

Epoch 00059: val_mDice did not improve from 0.61630
Epoch 60/300
 - 10s - loss: 1480.9698 - acc: 0.9460 - mDice: 0.7398 - val_loss: 2397.1055 - val_acc: 0.9517 - val_mDice: 0.5950

Epoch 00060: val_mDice did not improve from 0.61630
Epoch 61/300
 - 10s - loss: 1478.1955 - acc: 0.9462 - mDice: 0.7402 - val_loss: 2299.5871 - val_acc: 0.9530 - val_mDice: 0.6067

Epoch 00061: val_mDice did not improve from 0.61630
Epoch 62/300
 - 11s - loss: 1478.8560 - acc: 0.9462 - mDice: 0.7402 - val_loss: 2294.8716 - val_acc: 0.9534 - val_mDice: 0.6078

Epoch 00062: val_mDice did not improve from 0.61630
Epoch 63/300
 - 11s - loss: 1478.7459 - acc: 0.9462 - mDice: 0.7400 - val_loss: 2645.1884 - val_acc: 0.9525 - val_mDice: 0.5832

Epoch 00063: val_mDice did not improve from 0.61630
Epoch 64/300
 - 10s - loss: 1458.9245 - acc: 0.9467 - mDice: 0.7430 - val_loss: 2324.5378 - val_acc: 0.9507 - val_mDice: 0.5995

Epoch 00064: val_mDice did not improve from 0.61630
Epoch 65/300
 - 10s - loss: 1469.3160 - acc: 0.9466 - mDice: 0.7416 - val_loss: 2321.0121 - val_acc: 0.9534 - val_mDice: 0.6002

Epoch 00065: val_mDice did not improve from 0.61630
Epoch 66/300
 - 10s - loss: 1464.2194 - acc: 0.9467 - mDice: 0.7425 - val_loss: 2244.1004 - val_acc: 0.9518 - val_mDice: 0.6117

Epoch 00066: val_mDice did not improve from 0.61630
Epoch 67/300
 - 10s - loss: 1453.5107 - acc: 0.9469 - mDice: 0.7438 - val_loss: 2317.4268 - val_acc: 0.9519 - val_mDice: 0.6005

Epoch 00067: val_mDice did not improve from 0.61630
Epoch 68/300
 - 10s - loss: 1456.0289 - acc: 0.9468 - mDice: 0.7435 - val_loss: 2238.9690 - val_acc: 0.9531 - val_mDice: 0.6098

Epoch 00068: val_mDice did not improve from 0.61630
Epoch 69/300
 - 10s - loss: 1447.6751 - acc: 0.9472 - mDice: 0.7448 - val_loss: 2493.2712 - val_acc: 0.9518 - val_mDice: 0.5840

Epoch 00069: val_mDice did not improve from 0.61630
Epoch 70/300
 - 11s - loss: 1437.7896 - acc: 0.9473 - mDice: 0.7463 - val_loss: 2251.9647 - val_acc: 0.9518 - val_mDice: 0.6107

Epoch 00070: val_mDice did not improve from 0.61630
Epoch 71/300
 - 11s - loss: 1444.5531 - acc: 0.9473 - mDice: 0.7453 - val_loss: 2315.5944 - val_acc: 0.9531 - val_mDice: 0.6047

Epoch 00071: val_mDice did not improve from 0.61630
Epoch 72/300
 - 10s - loss: 1440.8836 - acc: 0.9474 - mDice: 0.7458 - val_loss: 2251.5954 - val_acc: 0.9527 - val_mDice: 0.6101

Epoch 00072: val_mDice did not improve from 0.61630
Epoch 73/300
 - 11s - loss: 1426.9598 - acc: 0.9476 - mDice: 0.7478 - val_loss: 2281.7739 - val_acc: 0.9517 - val_mDice: 0.6033

Epoch 00073: val_mDice did not improve from 0.61630
Epoch 74/300
 - 10s - loss: 1434.7125 - acc: 0.9476 - mDice: 0.7467 - val_loss: 2442.8532 - val_acc: 0.9508 - val_mDice: 0.5903

Epoch 00074: val_mDice did not improve from 0.61630
Epoch 75/300
 - 10s - loss: 1439.0896 - acc: 0.9476 - mDice: 0.7460 - val_loss: 2206.2150 - val_acc: 0.9526 - val_mDice: 0.6126

Epoch 00075: val_mDice did not improve from 0.61630
Epoch 76/300
 - 10s - loss: 1431.2175 - acc: 0.9478 - mDice: 0.7474 - val_loss: 2245.6597 - val_acc: 0.9533 - val_mDice: 0.6111

Epoch 00076: val_mDice did not improve from 0.61630
Epoch 77/300
 - 10s - loss: 1425.7238 - acc: 0.9478 - mDice: 0.7481 - val_loss: 2338.5064 - val_acc: 0.9537 - val_mDice: 0.6075

Epoch 00077: val_mDice did not improve from 0.61630
Epoch 78/300
 - 11s - loss: 1416.7592 - acc: 0.9480 - mDice: 0.7493 - val_loss: 2509.5464 - val_acc: 0.9509 - val_mDice: 0.5765

Epoch 00078: val_mDice did not improve from 0.61630
Epoch 79/300
 - 10s - loss: 1421.4805 - acc: 0.9481 - mDice: 0.7486 - val_loss: 2295.3349 - val_acc: 0.9522 - val_mDice: 0.6058

Epoch 00079: val_mDice did not improve from 0.61630
Epoch 80/300
 - 11s - loss: 1409.8485 - acc: 0.9483 - mDice: 0.7503 - val_loss: 2351.2004 - val_acc: 0.9531 - val_mDice: 0.6057

Epoch 00080: val_mDice did not improve from 0.61630
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
{'val_loss': [6328.130943937675, 3828.3901449022346, 3553.3349145644206, 3082.579986742755, 2845.0397894662187, 2783.178058986557, 2576.726450659043, 2638.755457020339, 2618.033717320618, 2457.3751241161835, 2596.0225864175977, 2273.8485837115923, 2633.1569360487956, 2313.321233142022, 2303.0298178901885, 2297.768351464298, 2224.0634056389663, 2335.787530824459, 2349.5771266148745, 2198.4109855097763, 2503.3872806826116, 2325.041930811365, 2438.6501151143507, 2544.833433353701, 2403.788600133118, 2393.36854595845, 2252.2867042925104, 2426.870439071229, 2352.189196709148, 2406.761165000873, 2353.2824284217877, 2710.4197200157123, 2481.6715831223814, 2658.4389321098115, 2386.3777810208626, 2297.294636816952, 2341.313807993628, 2449.503561179731, 2311.997735902584, 2400.6451695618016, 2540.740987255587, 2241.5893486491796, 2284.337710588338, 2342.342401088949, 2359.8011808768333, 2305.106994969885, 2484.0207955983765, 2572.17449917074, 2369.5682761762396, 2221.8446433637396, 2598.4585902038234, 2268.2897349096543, 2284.8915592811627, 2432.5263289979052, 2448.3055808637396, 2614.65628000611, 2469.3844369217004, 2331.3350455001746, 2456.3983488455833, 2397.1055014839385, 2299.5871418361558, 2294.871606581704, 2645.188401547224, 2324.5377831485685, 2321.0121279242317, 2244.1004018090957, 2317.4268164608065, 2238.9689600427723, 2493.2712115921786, 2251.9646528020253, 2315.5943623974335, 2251.595355326903, 2281.773860313373, 2442.8532019247555, 2206.2150142392634, 2245.659652965695, 2338.5063749345322, 2509.546442639228, 2295.3349009252793, 2351.2003930800456], 'val_acc': [0.9114574829959337, 0.9186576375082218, 0.9180977544305045, 0.9223868663750547, 0.9267813540037784, 0.9359917590738008, 0.9418056264269952, 0.9432374199009474, 0.940656925379897, 0.9457827829781857, 0.9500553674538043, 0.9479273577642174, 0.9484397083021409, 0.9480802326895005, 0.9483116375667423, 0.9519003719590896, 0.9512453901701133, 0.9470782186731946, 0.9511710198897889, 0.9525139541599338, 0.952241248924639, 0.9516772121690505, 0.9511958470557655, 0.9523445297885873, 0.9526647772202944, 0.9519210071537082, 0.9523610555925849, 0.9490988044765408, 0.9502909040317855, 0.9516482955916634, 0.9507722801336363, 0.9513962362065661, 0.9506256084202388, 0.9477021401154928, 0.9515863057621364, 0.9525924654646293, 0.9521400106019814, 0.9499789279932417, 0.9506255817812914, 0.9496421637481818, 0.9512908581914848, 0.9524643704211911, 0.9522453686378521, 0.9512908458709717, 0.9529581935712079, 0.9509665073629198, 0.9527309020804293, 0.9530304950042809, 0.9523466299366019, 0.953195762034901, 0.952735016465853, 0.9528342325594172, 0.952292875870646, 0.952786673047689, 0.9531275816469885, 0.951697885657156, 0.9525098261220495, 0.9527267880279925, 0.9514148095466571, 0.9517061304113719, 0.9530077490060689, 0.9534498626293417, 0.9524685117785491, 0.9507144353243225, 0.953352791304029, 0.9518114927760716, 0.9518858833685934, 0.9531007335838659, 0.9517805130122095, 0.9518032450249742, 0.9530966168675343, 0.9527081757284409, 0.9517495009486235, 0.9508280654193303, 0.9526255353869006, 0.9532618799023123, 0.9536833649907033, 0.9508859305408414, 0.9522453889500495, 0.9531317033581228], 'val_mDice': [0.2584986387018385, 0.43142340719366873, 0.4662164123364667, 0.5079479818570547, 0.5328419568152402, 0.5474580279941665, 0.5637356545672071, 0.5647324087233517, 0.5631201273902169, 0.5803360349639168, 0.5794347165017154, 0.6011994218027126, 0.5663011383743926, 0.5965344273178271, 0.5977206796241206, 0.6051423476394995, 0.6101972563972686, 0.5942920832660611, 0.601001729179361, 0.6149924540652909, 0.5897953097380739, 0.6024120446689968, 0.597201622398206, 0.5878912303700793, 0.6011501837043123, 0.6022195582949249, 0.6085097856361773, 0.590964985293383, 0.5992412926764462, 0.5943693675142426, 0.6055293406188155, 0.5945703723577148, 0.5922353300968362, 0.5721615776003406, 0.5950067506156154, 0.6100594731016532, 0.6067114702150143, 0.5815740617293885, 0.5988422305890302, 0.5889262939964592, 0.5840402794949835, 0.6085839637830937, 0.6068156145138448, 0.598805405574138, 0.5983835878318915, 0.6035676518632047, 0.5896024963709229, 0.5934241956838683, 0.5995964424570179, 0.616297157783082, 0.5961517295357901, 0.6071109189001541, 0.6068010463394933, 0.5943411199074218, 0.5943939432751533, 0.5775570576417379, 0.5930525667174569, 0.6018395610361792, 0.5944200834082491, 0.5950165564121481, 0.6067493807670125, 0.6077977085912694, 0.5831743525393183, 0.5995060325334858, 0.6001645026926222, 0.6117143880721577, 0.6004888188905556, 0.6098219199553548, 0.584042890777801, 0.6106614587027267, 0.6047400712300945, 0.610051374861648, 0.6032744762617782, 0.5902950307510418, 0.6126235497064431, 0.6111457804061847, 0.6075251238972115, 0.576499873033449, 0.6058284407221405, 0.6057068902021013], 'loss': [14047.54361395885, 5796.29827522181, 4471.555640979437, 3861.5570064303884, 3463.7931329575404, 3295.28771768552, 2971.368419059877, 2833.40881075074, 2685.86528760832, 2584.3050789813074, 2483.2129060092766, 2448.1074006002873, 2637.138355985406, 2379.037536331891, 2257.625963850859, 2173.576956998327, 2119.7529657215446, 2068.558928879912, 2027.736388578426, 1999.0478366170144, 1959.2441917042556, 1921.0832044373838, 1884.6085162462216, 1864.9698349039745, 1843.6645503158657, 1811.1289129382378, 1803.5162544988038, 1790.0207474256001, 1768.9987611069957, 1739.835496289052, 1731.8037047744817, 1730.9031966199907, 1706.817503536522, 1684.7837927935527, 1673.0785187816355, 1661.5111124472812, 1655.723021420471, 1644.585283355771, 1631.895419229915, 1637.675694236425, 1608.7649916983412, 1590.2760979826041, 1597.258666274166, 1600.8989018737916, 1583.7386819326205, 1563.5494933154587, 1563.4571073802297, 1551.0623441594053, 1549.0395715739576, 1537.5208440393892, 1533.63720779581, 1529.0675582092097, 1522.680885070199, 1515.9096387093716, 1499.301789897426, 1503.2180608322753, 1500.474702392033, 1497.3996570828783, 1485.848324295924, 1480.9698376198246, 1478.1954671638373, 1478.855999972928, 1478.7459364367962, 1458.9245232097542, 1469.3160153171816, 1464.2194489540925, 1453.5106973111529, 1456.0288922499094, 1447.6750806903315, 1437.7895802367545, 1444.5531324946824, 1440.8836473729134, 1426.9597779350806, 1434.712541729684, 1439.0896155055743, 1431.2175089396342, 1425.723825102661, 1416.7591685036496, 1421.4804867138355, 1409.8484769586084], 'acc': [0.6872245802120877, 0.8908168465624603, 0.8949966590347765, 0.8989499383525621, 0.9029847723967265, 0.9095857854236425, 0.9220106190218722, 0.9286986847996653, 0.9314690613647957, 0.9331765541563651, 0.9351881927709215, 0.9359423604888546, 0.9332987341893264, 0.936161740183551, 0.9377027463110488, 0.9387520101035215, 0.939329293871957, 0.9397721705428396, 0.940317224228501, 0.9405544753051532, 0.9408614571256436, 0.9412128885621683, 0.9415554190622125, 0.9417419509199227, 0.9419175074560295, 0.9420652057238832, 0.9418284784221135, 0.9419841767039138, 0.9418224995091203, 0.9421489961714365, 0.942240017359374, 0.9423520258261054, 0.9426483502250879, 0.9428831638967048, 0.9429936384552218, 0.9432643060622915, 0.9435198442666244, 0.9433979847242769, 0.9434791155535635, 0.9435873760402375, 0.9438873066484561, 0.9441414951278289, 0.9438669251354228, 0.9438911354345055, 0.9439995576662602, 0.9443017039045283, 0.9442518355604753, 0.9444891634924168, 0.9446626840239744, 0.9447383586795922, 0.9447664140025344, 0.9449320595986793, 0.9450708789656893, 0.9452534238371894, 0.9454934303845322, 0.945437919894865, 0.9456447336897209, 0.9456682794883966, 0.9459749396106633, 0.9460488608132637, 0.9461696492184949, 0.9461608258417428, 0.9462244758015916, 0.9466647543579163, 0.9465870079823578, 0.9467023975526733, 0.9469419849229906, 0.9468277205725419, 0.9471540380962975, 0.9473487688600286, 0.9473295902694261, 0.9473789778743121, 0.9476457400997443, 0.9475967549146712, 0.9476321398851548, 0.9478463477204356, 0.947838470898944, 0.9479842589419754, 0.9480600929274537, 0.9483143420957232], 'mDice': [0.10701022552726322, 0.3178743846545285, 0.4098184282766319, 0.4621275540585936, 0.4990957777787512, 0.5163162195288429, 0.548980848389665, 0.5640422361399975, 0.5803574044410585, 0.5924184803388508, 0.6044689925996887, 0.6099290500428122, 0.5917666352371084, 0.6179130553718771, 0.6328595246171959, 0.6437927873739328, 0.6508080613787778, 0.6576295890590476, 0.6631238947642615, 0.666869622911414, 0.6721055142260488, 0.677160143151041, 0.6821216111654265, 0.6848679352842848, 0.6877925207747216, 0.6923406606509752, 0.6931357592625086, 0.6954348927249018, 0.6980720785382097, 0.7021586306246659, 0.7032723089986543, 0.7037582363180395, 0.7069565214289344, 0.7100247605863295, 0.7117095255434925, 0.7132994454058029, 0.7143255597553926, 0.7159469142555379, 0.7175632205983858, 0.716924180948009, 0.7209924836608295, 0.7236020719652492, 0.7226316868288247, 0.7223208989006821, 0.7246301321154631, 0.7276066487848704, 0.7275192857561246, 0.7294747255497863, 0.7297737204192946, 0.7315180514458834, 0.7320191004613757, 0.732655518364396, 0.7337185885676254, 0.7345975651654547, 0.7370052074796526, 0.7364239270933429, 0.7369197863365374, 0.7373040652107579, 0.7390271207487834, 0.7397608058098504, 0.7402409899469152, 0.7401558489985446, 0.740033445349966, 0.7430428930256311, 0.7415543282371572, 0.7424650892414861, 0.7438220891757219, 0.7434793518010415, 0.7447849673666755, 0.7462773967507319, 0.7453220425643639, 0.7457959958621537, 0.7478241973385287, 0.7467217781491662, 0.745989965416041, 0.7473556589608904, 0.748122454919909, 0.7492955073403427, 0.7486471372078943, 0.7503256524195436]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.60s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:36,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:05,  1.93s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:46,  1.87s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<09:14,  1.97s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:00,  1.93s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<09:15,  1.99s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<10:08,  2.19s/it]predicting train subjects:   3%|▎         | 8/285 [00:16<10:20,  2.24s/it]predicting train subjects:   3%|▎         | 9/285 [00:19<10:04,  2.19s/it]predicting train subjects:   4%|▎         | 10/285 [00:21<10:39,  2.33s/it]predicting train subjects:   4%|▍         | 11/285 [00:24<10:56,  2.40s/it]predicting train subjects:   4%|▍         | 12/285 [00:26<10:52,  2.39s/it]predicting train subjects:   5%|▍         | 13/285 [00:29<11:10,  2.47s/it]predicting train subjects:   5%|▍         | 14/285 [00:31<11:04,  2.45s/it]predicting train subjects:   5%|▌         | 15/285 [00:34<11:20,  2.52s/it]predicting train subjects:   6%|▌         | 16/285 [00:36<11:13,  2.50s/it]predicting train subjects:   6%|▌         | 17/285 [00:39<11:10,  2.50s/it]predicting train subjects:   6%|▋         | 18/285 [00:42<11:38,  2.62s/it]predicting train subjects:   7%|▋         | 19/285 [00:44<11:25,  2.58s/it]predicting train subjects:   7%|▋         | 20/285 [00:47<11:36,  2.63s/it]predicting train subjects:   7%|▋         | 21/285 [00:49<11:01,  2.50s/it]predicting train subjects:   8%|▊         | 22/285 [00:51<10:39,  2.43s/it]predicting train subjects:   8%|▊         | 23/285 [00:54<10:19,  2.37s/it]predicting train subjects:   8%|▊         | 24/285 [00:56<10:21,  2.38s/it]predicting train subjects:   9%|▉         | 25/285 [00:59<10:50,  2.50s/it]predicting train subjects:   9%|▉         | 26/285 [01:01<10:57,  2.54s/it]predicting train subjects:   9%|▉         | 27/285 [01:04<11:01,  2.56s/it]predicting train subjects:  10%|▉         | 28/285 [01:06<10:31,  2.46s/it]predicting train subjects:  10%|█         | 29/285 [01:09<10:37,  2.49s/it]predicting train subjects:  11%|█         | 30/285 [01:11<10:00,  2.35s/it]predicting train subjects:  11%|█         | 31/285 [01:13<09:56,  2.35s/it]predicting train subjects:  11%|█         | 32/285 [01:15<09:31,  2.26s/it]predicting train subjects:  12%|█▏        | 33/285 [01:17<09:18,  2.22s/it]predicting train subjects:  12%|█▏        | 34/285 [01:20<09:17,  2.22s/it]predicting train subjects:  12%|█▏        | 35/285 [01:22<08:59,  2.16s/it]predicting train subjects:  13%|█▎        | 36/285 [01:24<08:43,  2.10s/it]predicting train subjects:  13%|█▎        | 37/285 [01:26<08:30,  2.06s/it]predicting train subjects:  13%|█▎        | 38/285 [01:27<08:20,  2.03s/it]predicting train subjects:  14%|█▎        | 39/285 [01:29<08:13,  2.01s/it]predicting train subjects:  14%|█▍        | 40/285 [01:31<08:09,  2.00s/it]predicting train subjects:  14%|█▍        | 41/285 [01:33<08:12,  2.02s/it]predicting train subjects:  15%|█▍        | 42/285 [01:35<08:06,  2.00s/it]predicting train subjects:  15%|█▌        | 43/285 [01:37<08:07,  2.02s/it]predicting train subjects:  15%|█▌        | 44/285 [01:39<08:04,  2.01s/it]predicting train subjects:  16%|█▌        | 45/285 [01:41<07:58,  2.00s/it]predicting train subjects:  16%|█▌        | 46/285 [01:43<07:36,  1.91s/it]predicting train subjects:  16%|█▋        | 47/285 [01:45<07:15,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:46<06:55,  1.76s/it]predicting train subjects:  17%|█▋        | 49/285 [01:48<06:57,  1.77s/it]predicting train subjects:  18%|█▊        | 50/285 [01:50<06:53,  1.76s/it]predicting train subjects:  18%|█▊        | 51/285 [01:52<06:48,  1.75s/it]predicting train subjects:  18%|█▊        | 52/285 [01:53<06:46,  1.74s/it]predicting train subjects:  19%|█▊        | 53/285 [01:55<06:45,  1.75s/it]predicting train subjects:  19%|█▉        | 54/285 [01:57<06:44,  1.75s/it]predicting train subjects:  19%|█▉        | 55/285 [01:59<06:41,  1.75s/it]predicting train subjects:  20%|█▉        | 56/285 [02:00<06:42,  1.76s/it]predicting train subjects:  20%|██        | 57/285 [02:02<06:37,  1.74s/it]predicting train subjects:  20%|██        | 58/285 [02:04<06:38,  1.76s/it]predicting train subjects:  21%|██        | 59/285 [02:06<06:34,  1.75s/it]predicting train subjects:  21%|██        | 60/285 [02:07<06:36,  1.76s/it]predicting train subjects:  21%|██▏       | 61/285 [02:09<06:29,  1.74s/it]predicting train subjects:  22%|██▏       | 62/285 [02:11<06:28,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [02:13<06:23,  1.73s/it]predicting train subjects:  22%|██▏       | 64/285 [02:14<06:28,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [02:16<06:35,  1.80s/it]predicting train subjects:  23%|██▎       | 66/285 [02:18<06:37,  1.81s/it]predicting train subjects:  24%|██▎       | 67/285 [02:20<06:35,  1.82s/it]predicting train subjects:  24%|██▍       | 68/285 [02:22<06:34,  1.82s/it]predicting train subjects:  24%|██▍       | 69/285 [02:24<06:28,  1.80s/it]predicting train subjects:  25%|██▍       | 70/285 [02:25<06:25,  1.79s/it]predicting train subjects:  25%|██▍       | 71/285 [02:27<06:21,  1.78s/it]predicting train subjects:  25%|██▌       | 72/285 [02:29<06:18,  1.78s/it]predicting train subjects:  26%|██▌       | 73/285 [02:31<06:20,  1.80s/it]predicting train subjects:  26%|██▌       | 74/285 [02:32<06:14,  1.78s/it]predicting train subjects:  26%|██▋       | 75/285 [02:34<06:10,  1.76s/it]predicting train subjects:  27%|██▋       | 76/285 [02:36<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 77/285 [02:38<06:01,  1.74s/it]predicting train subjects:  27%|██▋       | 78/285 [02:39<06:01,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:41<05:59,  1.75s/it]predicting train subjects:  28%|██▊       | 80/285 [02:43<05:55,  1.73s/it]predicting train subjects:  28%|██▊       | 81/285 [02:45<05:55,  1.74s/it]predicting train subjects:  29%|██▉       | 82/285 [02:46<05:51,  1.73s/it]predicting train subjects:  29%|██▉       | 83/285 [02:48<05:50,  1.74s/it]predicting train subjects:  29%|██▉       | 84/285 [02:50<05:49,  1.74s/it]predicting train subjects:  30%|██▉       | 85/285 [02:52<05:58,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:54<06:03,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:55<06:06,  1.85s/it]predicting train subjects:  31%|███       | 88/285 [02:57<06:08,  1.87s/it]predicting train subjects:  31%|███       | 89/285 [02:59<06:12,  1.90s/it]predicting train subjects:  32%|███▏      | 90/285 [03:01<06:16,  1.93s/it]predicting train subjects:  32%|███▏      | 91/285 [03:03<06:15,  1.93s/it]predicting train subjects:  32%|███▏      | 92/285 [03:05<06:11,  1.92s/it]predicting train subjects:  33%|███▎      | 93/285 [03:07<06:09,  1.93s/it]predicting train subjects:  33%|███▎      | 94/285 [03:09<06:07,  1.92s/it]predicting train subjects:  33%|███▎      | 95/285 [03:11<06:06,  1.93s/it]predicting train subjects:  34%|███▎      | 96/285 [03:13<06:07,  1.94s/it]predicting train subjects:  34%|███▍      | 97/285 [03:15<06:08,  1.96s/it]predicting train subjects:  34%|███▍      | 98/285 [03:17<06:04,  1.95s/it]predicting train subjects:  35%|███▍      | 99/285 [03:19<05:56,  1.92s/it]predicting train subjects:  35%|███▌      | 100/285 [03:21<05:55,  1.92s/it]predicting train subjects:  35%|███▌      | 101/285 [03:23<05:51,  1.91s/it]predicting train subjects:  36%|███▌      | 102/285 [03:24<05:51,  1.92s/it]predicting train subjects:  36%|███▌      | 103/285 [03:26<05:47,  1.91s/it]predicting train subjects:  36%|███▋      | 104/285 [03:28<05:44,  1.91s/it]predicting train subjects:  37%|███▋      | 105/285 [03:30<05:37,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:32<05:37,  1.89s/it]predicting train subjects:  38%|███▊      | 107/285 [03:34<05:36,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:36<05:38,  1.91s/it]predicting train subjects:  38%|███▊      | 109/285 [03:38<05:37,  1.92s/it]predicting train subjects:  39%|███▊      | 110/285 [03:40<05:31,  1.89s/it]predicting train subjects:  39%|███▉      | 111/285 [03:41<05:29,  1.89s/it]predicting train subjects:  39%|███▉      | 112/285 [03:43<05:30,  1.91s/it]predicting train subjects:  40%|███▉      | 113/285 [03:45<05:28,  1.91s/it]predicting train subjects:  40%|████      | 114/285 [03:47<05:30,  1.94s/it]predicting train subjects:  40%|████      | 115/285 [03:49<05:29,  1.94s/it]predicting train subjects:  41%|████      | 116/285 [03:51<05:29,  1.95s/it]predicting train subjects:  41%|████      | 117/285 [03:53<05:28,  1.96s/it]predicting train subjects:  41%|████▏     | 118/285 [03:55<05:23,  1.94s/it]predicting train subjects:  42%|████▏     | 119/285 [03:57<05:16,  1.90s/it]predicting train subjects:  42%|████▏     | 120/285 [03:59<05:15,  1.91s/it]predicting train subjects:  42%|████▏     | 121/285 [04:01<05:06,  1.87s/it]predicting train subjects:  43%|████▎     | 122/285 [04:02<04:51,  1.79s/it]predicting train subjects:  43%|████▎     | 123/285 [04:04<04:35,  1.70s/it]predicting train subjects:  44%|████▎     | 124/285 [04:05<04:35,  1.71s/it]predicting train subjects:  44%|████▍     | 125/285 [04:07<04:35,  1.72s/it]predicting train subjects:  44%|████▍     | 126/285 [04:09<04:37,  1.75s/it]predicting train subjects:  45%|████▍     | 127/285 [04:11<04:37,  1.75s/it]predicting train subjects:  45%|████▍     | 128/285 [04:13<04:33,  1.74s/it]predicting train subjects:  45%|████▌     | 129/285 [04:14<04:28,  1.72s/it]predicting train subjects:  46%|████▌     | 130/285 [04:16<04:25,  1.72s/it]predicting train subjects:  46%|████▌     | 131/285 [04:18<04:23,  1.71s/it]predicting train subjects:  46%|████▋     | 132/285 [04:19<04:19,  1.69s/it]predicting train subjects:  47%|████▋     | 133/285 [04:21<04:15,  1.68s/it]predicting train subjects:  47%|████▋     | 134/285 [04:23<04:15,  1.69s/it]predicting train subjects:  47%|████▋     | 135/285 [04:24<04:17,  1.71s/it]predicting train subjects:  48%|████▊     | 136/285 [04:26<04:16,  1.72s/it]predicting train subjects:  48%|████▊     | 137/285 [04:28<04:10,  1.69s/it]predicting train subjects:  48%|████▊     | 138/285 [04:29<04:07,  1.69s/it]predicting train subjects:  49%|████▉     | 139/285 [04:31<04:05,  1.68s/it]predicting train subjects:  49%|████▉     | 140/285 [04:33<04:05,  1.69s/it]predicting train subjects:  49%|████▉     | 141/285 [04:34<04:01,  1.68s/it]predicting train subjects:  50%|████▉     | 142/285 [04:36<03:54,  1.64s/it]predicting train subjects:  50%|█████     | 143/285 [04:38<03:49,  1.62s/it]predicting train subjects:  51%|█████     | 144/285 [04:39<03:45,  1.60s/it]predicting train subjects:  51%|█████     | 145/285 [04:41<03:39,  1.57s/it]predicting train subjects:  51%|█████     | 146/285 [04:42<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:44<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:45<03:31,  1.55s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:47<03:30,  1.55s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:48<03:33,  1.58s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:50<03:34,  1.60s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:52<03:31,  1.59s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:53<03:26,  1.56s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:55<03:22,  1.55s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:56<03:22,  1.56s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:58<03:21,  1.56s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:59<03:23,  1.59s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:01<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:03<03:17,  1.57s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:04<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:06<03:09,  1.53s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:07<03:09,  1.54s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:09<03:04,  1.52s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:10<03:05,  1.53s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:12<03:02,  1.52s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:13<03:01,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:15<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:16<02:56,  1.51s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:18<02:52,  1.49s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:19<02:53,  1.51s/it]predicting train subjects:  60%|██████    | 171/285 [05:21<02:54,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [05:22<02:52,  1.53s/it]predicting train subjects:  61%|██████    | 173/285 [05:24<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:25<02:44,  1.48s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:27<02:41,  1.47s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:28<02:40,  1.48s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:30<02:40,  1.48s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:31<02:38,  1.48s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:32<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:34<02:31,  1.44s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:35<02:29,  1.44s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:37<02:28,  1.44s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:38<02:31,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:40<02:30,  1.49s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:41<02:27,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:43<02:27,  1.49s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:44<02:24,  1.48s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:46<02:21,  1.46s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:47<02:22,  1.49s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:49<02:22,  1.50s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:50<02:22,  1.52s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:52<02:23,  1.54s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:53<02:22,  1.55s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:55<02:18,  1.53s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:56<02:18,  1.54s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:58<02:23,  1.62s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:00<02:26,  1.67s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:02<02:28,  1.70s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:04<02:26,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [06:05<02:25,  1.71s/it]predicting train subjects:  71%|███████   | 201/285 [06:07<02:25,  1.73s/it]predicting train subjects:  71%|███████   | 202/285 [06:09<02:22,  1.71s/it]predicting train subjects:  71%|███████   | 203/285 [06:10<02:22,  1.73s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:12<02:20,  1.74s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:14<02:17,  1.71s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:16<02:17,  1.74s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:17<02:15,  1.74s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:19<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:21<02:13,  1.76s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:23<02:12,  1.77s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:25<02:11,  1.78s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:26<02:09,  1.78s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:28<02:08,  1.79s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:30<02:01,  1.72s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:31<01:56,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:33<01:52,  1.63s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:34<01:47,  1.59s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:36<01:44,  1.57s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:37<01:42,  1.55s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:39<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:40<01:38,  1.54s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:42<01:39,  1.57s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:44<01:35,  1.54s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:45<01:33,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:47<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:48<01:29,  1.52s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:50<01:28,  1.52s/it]predicting train subjects:  80%|████████  | 228/285 [06:51<01:26,  1.52s/it]predicting train subjects:  80%|████████  | 229/285 [06:53<01:25,  1.53s/it]predicting train subjects:  81%|████████  | 230/285 [06:54<01:23,  1.52s/it]predicting train subjects:  81%|████████  | 231/285 [06:56<01:22,  1.53s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:58<01:26,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:59<01:28,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:01<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:03<01:29,  1.79s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:05<01:29,  1.82s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:07<01:28,  1.84s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:09<01:26,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:11<01:25,  1.85s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:13<01:23,  1.86s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:14<01:20,  1.84s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:16<01:19,  1.85s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:18<01:17,  1.85s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:20<01:14,  1.82s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:22<01:13,  1.84s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:24<01:12,  1.87s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:26<01:12,  1.90s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:28<01:11,  1.93s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:30<01:09,  1.93s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:31<01:03,  1.80s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:33<00:58,  1.71s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:34<00:54,  1.66s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:36<00:51,  1.61s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:37<00:48,  1.56s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:38<00:45,  1.52s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:40<00:43,  1.51s/it]predicting train subjects:  90%|█████████ | 257/285 [07:41<00:41,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [07:43<00:39,  1.48s/it]predicting train subjects:  91%|█████████ | 259/285 [07:44<00:38,  1.46s/it]predicting train subjects:  91%|█████████ | 260/285 [07:46<00:36,  1.48s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:47<00:35,  1.47s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:49<00:34,  1.48s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:50<00:33,  1.50s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:52<00:31,  1.52s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:53<00:30,  1.51s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:55<00:28,  1.48s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:56<00:26,  1.46s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:58<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:00<00:26,  1.69s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:02<00:26,  1.75s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:04<00:25,  1.82s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:06<00:24,  1.86s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:08<00:22,  1.90s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:10<00:20,  1.90s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:12<00:19,  1.96s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:14<00:17,  1.96s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:16<00:15,  1.97s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:18<00:13,  1.99s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:20<00:11,  1.99s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:22<00:09,  1.96s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:24<00:08,  2.01s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:26<00:05,  1.99s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:28<00:03,  1.98s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:30<00:01,  1.98s/it]predicting train subjects: 100%|██████████| 285/285 [08:32<00:00,  1.98s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:53,  1.24s/it]Loading train:   1%|          | 2/285 [00:02<06:05,  1.29s/it]Loading train:   1%|          | 3/285 [00:03<05:51,  1.25s/it]Loading train:   1%|▏         | 4/285 [00:05<06:10,  1.32s/it]Loading train:   2%|▏         | 5/285 [00:06<05:47,  1.24s/it]Loading train:   2%|▏         | 6/285 [00:07<06:05,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:34,  1.42s/it]Loading train:   3%|▎         | 8/285 [00:10<06:36,  1.43s/it]Loading train:   3%|▎         | 9/285 [00:12<06:22,  1.38s/it]Loading train:   4%|▎         | 10/285 [00:13<05:47,  1.27s/it]Loading train:   4%|▍         | 11/285 [00:14<05:20,  1.17s/it]Loading train:   4%|▍         | 12/285 [00:15<04:58,  1.09s/it]Loading train:   5%|▍         | 13/285 [00:16<04:48,  1.06s/it]Loading train:   5%|▍         | 14/285 [00:17<04:41,  1.04s/it]Loading train:   5%|▌         | 15/285 [00:18<04:42,  1.04s/it]Loading train:   6%|▌         | 16/285 [00:19<04:35,  1.02s/it]Loading train:   6%|▌         | 17/285 [00:20<04:30,  1.01s/it]Loading train:   6%|▋         | 18/285 [00:21<04:30,  1.01s/it]Loading train:   7%|▋         | 19/285 [00:22<04:24,  1.01it/s]Loading train:   7%|▋         | 20/285 [00:23<04:25,  1.00s/it]Loading train:   7%|▋         | 21/285 [00:24<04:21,  1.01it/s]Loading train:   8%|▊         | 22/285 [00:25<04:24,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:26<04:21,  1.00it/s]Loading train:   8%|▊         | 24/285 [00:26<04:18,  1.01it/s]Loading train:   9%|▉         | 25/285 [00:28<04:18,  1.01it/s]Loading train:   9%|▉         | 26/285 [00:28<04:15,  1.01it/s]Loading train:   9%|▉         | 27/285 [00:29<04:13,  1.02it/s]Loading train:  10%|▉         | 28/285 [00:31<04:19,  1.01s/it]Loading train:  10%|█         | 29/285 [00:31<04:12,  1.01it/s]Loading train:  11%|█         | 30/285 [00:32<04:06,  1.04it/s]Loading train:  11%|█         | 31/285 [00:33<04:00,  1.06it/s]Loading train:  11%|█         | 32/285 [00:34<03:57,  1.06it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:11,  1.00it/s]Loading train:  12%|█▏        | 34/285 [00:36<04:01,  1.04it/s]Loading train:  12%|█▏        | 35/285 [00:37<03:56,  1.06it/s]Loading train:  13%|█▎        | 36/285 [00:38<03:48,  1.09it/s]Loading train:  13%|█▎        | 37/285 [00:39<03:41,  1.12it/s]Loading train:  13%|█▎        | 38/285 [00:40<03:36,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:41<03:36,  1.14it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:33,  1.15it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:33,  1.14it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:44,  1.08it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:39,  1.10it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:37,  1.11it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:30,  1.14it/s]Loading train:  16%|█▌        | 46/285 [00:47<03:26,  1.16it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:20,  1.19it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:20,  1.18it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:17,  1.20it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:16,  1.19it/s]Loading train:  18%|█▊        | 51/285 [00:51<03:12,  1.22it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:15,  1.19it/s]Loading train:  19%|█▊        | 53/285 [00:52<03:11,  1.21it/s]Loading train:  19%|█▉        | 54/285 [00:53<03:11,  1.21it/s]Loading train:  19%|█▉        | 55/285 [00:54<03:07,  1.23it/s]Loading train:  20%|█▉        | 56/285 [00:55<03:08,  1.21it/s]Loading train:  20%|██        | 57/285 [00:56<03:06,  1.22it/s]Loading train:  20%|██        | 58/285 [00:57<03:02,  1.24it/s]Loading train:  21%|██        | 59/285 [00:57<03:00,  1.25it/s]Loading train:  21%|██        | 60/285 [00:58<02:59,  1.25it/s]Loading train:  21%|██▏       | 61/285 [00:59<02:58,  1.26it/s]Loading train:  22%|██▏       | 62/285 [01:00<03:03,  1.22it/s]Loading train:  22%|██▏       | 63/285 [01:01<03:04,  1.20it/s]Loading train:  22%|██▏       | 64/285 [01:02<03:35,  1.02it/s]Loading train:  23%|██▎       | 65/285 [01:03<04:05,  1.11s/it]Loading train:  23%|██▎       | 66/285 [01:05<04:23,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:06<03:57,  1.09s/it]Loading train:  24%|██▍       | 68/285 [01:06<03:36,  1.00it/s]Loading train:  24%|██▍       | 69/285 [01:07<03:21,  1.07it/s]Loading train:  25%|██▍       | 70/285 [01:08<03:11,  1.12it/s]Loading train:  25%|██▍       | 71/285 [01:09<03:02,  1.18it/s]Loading train:  25%|██▌       | 72/285 [01:10<02:57,  1.20it/s]Loading train:  26%|██▌       | 73/285 [01:10<02:54,  1.21it/s]Loading train:  26%|██▌       | 74/285 [01:11<02:50,  1.24it/s]Loading train:  26%|██▋       | 75/285 [01:12<02:44,  1.28it/s]Loading train:  27%|██▋       | 76/285 [01:13<02:44,  1.27it/s]Loading train:  27%|██▋       | 77/285 [01:13<02:43,  1.28it/s]Loading train:  27%|██▋       | 78/285 [01:14<02:41,  1.29it/s]Loading train:  28%|██▊       | 79/285 [01:15<02:39,  1.29it/s]Loading train:  28%|██▊       | 80/285 [01:16<02:41,  1.27it/s]Loading train:  28%|██▊       | 81/285 [01:17<02:43,  1.25it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:44,  1.24it/s]Loading train:  29%|██▉       | 83/285 [01:18<02:40,  1.26it/s]Loading train:  29%|██▉       | 84/285 [01:19<02:37,  1.28it/s]Loading train:  30%|██▉       | 85/285 [01:20<02:42,  1.23it/s]Loading train:  30%|███       | 86/285 [01:21<02:45,  1.20it/s]Loading train:  31%|███       | 87/285 [01:22<02:46,  1.19it/s]Loading train:  31%|███       | 88/285 [01:23<02:53,  1.14it/s]Loading train:  31%|███       | 89/285 [01:23<02:54,  1.12it/s]Loading train:  32%|███▏      | 90/285 [01:24<03:01,  1.08it/s]Loading train:  32%|███▏      | 91/285 [01:25<02:57,  1.09it/s]Loading train:  32%|███▏      | 92/285 [01:26<02:54,  1.11it/s]Loading train:  33%|███▎      | 93/285 [01:27<02:51,  1.12it/s]Loading train:  33%|███▎      | 94/285 [01:28<02:50,  1.12it/s]Loading train:  33%|███▎      | 95/285 [01:29<02:48,  1.13it/s]Loading train:  34%|███▎      | 96/285 [01:30<02:46,  1.14it/s]Loading train:  34%|███▍      | 97/285 [01:31<02:46,  1.13it/s]Loading train:  34%|███▍      | 98/285 [01:32<02:49,  1.10it/s]Loading train:  35%|███▍      | 99/285 [01:32<02:46,  1.12it/s]Loading train:  35%|███▌      | 100/285 [01:33<02:49,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:34<02:51,  1.07it/s]Loading train:  36%|███▌      | 102/285 [01:35<02:47,  1.09it/s]Loading train:  36%|███▌      | 103/285 [01:36<02:46,  1.09it/s]Loading train:  36%|███▋      | 104/285 [01:37<02:43,  1.11it/s]Loading train:  37%|███▋      | 105/285 [01:38<02:44,  1.09it/s]Loading train:  37%|███▋      | 106/285 [01:39<02:43,  1.10it/s]Loading train:  38%|███▊      | 107/285 [01:40<02:43,  1.09it/s]Loading train:  38%|███▊      | 108/285 [01:41<02:39,  1.11it/s]Loading train:  38%|███▊      | 109/285 [01:42<02:39,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:42<02:38,  1.11it/s]Loading train:  39%|███▉      | 111/285 [01:43<02:36,  1.11it/s]Loading train:  39%|███▉      | 112/285 [01:44<02:35,  1.11it/s]Loading train:  40%|███▉      | 113/285 [01:45<02:36,  1.10it/s]Loading train:  40%|████      | 114/285 [01:46<02:32,  1.12it/s]Loading train:  40%|████      | 115/285 [01:47<02:34,  1.10it/s]Loading train:  41%|████      | 116/285 [01:48<02:32,  1.11it/s]Loading train:  41%|████      | 117/285 [01:49<02:31,  1.11it/s]Loading train:  41%|████▏     | 118/285 [01:50<02:31,  1.10it/s]Loading train:  42%|████▏     | 119/285 [01:51<02:27,  1.13it/s]Loading train:  42%|████▏     | 120/285 [01:51<02:28,  1.11it/s]Loading train:  42%|████▏     | 121/285 [01:53<02:47,  1.02s/it]Loading train:  43%|████▎     | 122/285 [01:54<02:59,  1.10s/it]Loading train:  43%|████▎     | 123/285 [01:55<02:57,  1.10s/it]Loading train:  44%|████▎     | 124/285 [01:56<02:44,  1.02s/it]Loading train:  44%|████▍     | 125/285 [01:57<02:32,  1.05it/s]Loading train:  44%|████▍     | 126/285 [01:58<02:23,  1.11it/s]Loading train:  45%|████▍     | 127/285 [01:58<02:15,  1.17it/s]Loading train:  45%|████▍     | 128/285 [01:59<02:12,  1.18it/s]Loading train:  45%|████▌     | 129/285 [02:00<02:08,  1.22it/s]Loading train:  46%|████▌     | 130/285 [02:01<02:09,  1.19it/s]Loading train:  46%|████▌     | 131/285 [02:02<02:05,  1.23it/s]Loading train:  46%|████▋     | 132/285 [02:02<02:03,  1.24it/s]Loading train:  47%|████▋     | 133/285 [02:03<02:01,  1.25it/s]Loading train:  47%|████▋     | 134/285 [02:04<01:57,  1.28it/s]Loading train:  47%|████▋     | 135/285 [02:05<02:00,  1.24it/s]Loading train:  48%|████▊     | 136/285 [02:05<01:58,  1.26it/s]Loading train:  48%|████▊     | 137/285 [02:06<02:01,  1.21it/s]Loading train:  48%|████▊     | 138/285 [02:07<02:02,  1.20it/s]Loading train:  49%|████▉     | 139/285 [02:08<02:00,  1.21it/s]Loading train:  49%|████▉     | 140/285 [02:09<02:00,  1.20it/s]Loading train:  49%|████▉     | 141/285 [02:10<01:59,  1.21it/s]Loading train:  50%|████▉     | 142/285 [02:11<01:59,  1.20it/s]Loading train:  50%|█████     | 143/285 [02:11<01:53,  1.25it/s]Loading train:  51%|█████     | 144/285 [02:12<01:54,  1.23it/s]Loading train:  51%|█████     | 145/285 [02:13<01:51,  1.25it/s]Loading train:  51%|█████     | 146/285 [02:14<01:49,  1.27it/s]Loading train:  52%|█████▏    | 147/285 [02:14<01:46,  1.30it/s]Loading train:  52%|█████▏    | 148/285 [02:15<01:44,  1.31it/s]Loading train:  52%|█████▏    | 149/285 [02:16<01:47,  1.27it/s]Loading train:  53%|█████▎    | 150/285 [02:17<01:43,  1.30it/s]Loading train:  53%|█████▎    | 151/285 [02:18<01:45,  1.27it/s]Loading train:  53%|█████▎    | 152/285 [02:18<01:42,  1.30it/s]Loading train:  54%|█████▎    | 153/285 [02:19<01:42,  1.29it/s]Loading train:  54%|█████▍    | 154/285 [02:20<01:40,  1.30it/s]Loading train:  54%|█████▍    | 155/285 [02:21<01:38,  1.31it/s]Loading train:  55%|█████▍    | 156/285 [02:21<01:41,  1.27it/s]Loading train:  55%|█████▌    | 157/285 [02:22<01:41,  1.26it/s]Loading train:  55%|█████▌    | 158/285 [02:23<01:39,  1.27it/s]Loading train:  56%|█████▌    | 159/285 [02:24<01:37,  1.29it/s]Loading train:  56%|█████▌    | 160/285 [02:25<01:38,  1.27it/s]Loading train:  56%|█████▋    | 161/285 [02:25<01:31,  1.35it/s]Loading train:  57%|█████▋    | 162/285 [02:26<01:27,  1.40it/s]Loading train:  57%|█████▋    | 163/285 [02:26<01:24,  1.44it/s]Loading train:  58%|█████▊    | 164/285 [02:27<01:22,  1.46it/s]Loading train:  58%|█████▊    | 165/285 [02:28<01:24,  1.42it/s]Loading train:  58%|█████▊    | 166/285 [02:29<01:24,  1.41it/s]Loading train:  59%|█████▊    | 167/285 [02:29<01:23,  1.42it/s]Loading train:  59%|█████▉    | 168/285 [02:30<01:21,  1.44it/s]Loading train:  59%|█████▉    | 169/285 [02:31<01:19,  1.46it/s]Loading train:  60%|█████▉    | 170/285 [02:31<01:19,  1.45it/s]Loading train:  60%|██████    | 171/285 [02:32<01:21,  1.40it/s]Loading train:  60%|██████    | 172/285 [02:33<01:18,  1.44it/s]Loading train:  61%|██████    | 173/285 [02:34<01:20,  1.40it/s]Loading train:  61%|██████    | 174/285 [02:34<01:18,  1.41it/s]Loading train:  61%|██████▏   | 175/285 [02:35<01:18,  1.40it/s]Loading train:  62%|██████▏   | 176/285 [02:36<01:23,  1.31it/s]Loading train:  62%|██████▏   | 177/285 [02:37<01:23,  1.30it/s]Loading train:  62%|██████▏   | 178/285 [02:37<01:24,  1.27it/s]Loading train:  63%|██████▎   | 179/285 [02:38<01:20,  1.32it/s]Loading train:  63%|██████▎   | 180/285 [02:39<01:19,  1.33it/s]Loading train:  64%|██████▎   | 181/285 [02:40<01:17,  1.35it/s]Loading train:  64%|██████▍   | 182/285 [02:40<01:14,  1.39it/s]Loading train:  64%|██████▍   | 183/285 [02:41<01:13,  1.39it/s]Loading train:  65%|██████▍   | 184/285 [02:42<01:12,  1.39it/s]Loading train:  65%|██████▍   | 185/285 [02:42<01:11,  1.41it/s]Loading train:  65%|██████▌   | 186/285 [02:43<01:10,  1.41it/s]Loading train:  66%|██████▌   | 187/285 [02:44<01:08,  1.43it/s]Loading train:  66%|██████▌   | 188/285 [02:44<01:06,  1.46it/s]Loading train:  66%|██████▋   | 189/285 [02:45<01:04,  1.48it/s]Loading train:  67%|██████▋   | 190/285 [02:46<01:04,  1.48it/s]Loading train:  67%|██████▋   | 191/285 [02:46<01:03,  1.48it/s]Loading train:  67%|██████▋   | 192/285 [02:47<01:02,  1.49it/s]Loading train:  68%|██████▊   | 193/285 [02:48<01:01,  1.51it/s]Loading train:  68%|██████▊   | 194/285 [02:48<01:00,  1.50it/s]Loading train:  68%|██████▊   | 195/285 [02:49<01:02,  1.45it/s]Loading train:  69%|██████▉   | 196/285 [02:50<01:06,  1.34it/s]Loading train:  69%|██████▉   | 197/285 [02:51<01:05,  1.34it/s]Loading train:  69%|██████▉   | 198/285 [02:52<01:06,  1.32it/s]Loading train:  70%|██████▉   | 199/285 [02:52<01:06,  1.30it/s]Loading train:  70%|███████   | 200/285 [02:53<01:05,  1.30it/s]Loading train:  71%|███████   | 201/285 [02:54<01:06,  1.27it/s]Loading train:  71%|███████   | 202/285 [02:55<01:07,  1.23it/s]Loading train:  71%|███████   | 203/285 [02:56<01:06,  1.23it/s]Loading train:  72%|███████▏  | 204/285 [02:56<01:06,  1.21it/s]Loading train:  72%|███████▏  | 205/285 [02:57<01:06,  1.21it/s]Loading train:  72%|███████▏  | 206/285 [02:58<01:05,  1.21it/s]Loading train:  73%|███████▎  | 207/285 [02:59<01:03,  1.23it/s]Loading train:  73%|███████▎  | 208/285 [03:00<01:02,  1.23it/s]Loading train:  73%|███████▎  | 209/285 [03:01<01:04,  1.18it/s]Loading train:  74%|███████▎  | 210/285 [03:01<01:01,  1.21it/s]Loading train:  74%|███████▍  | 211/285 [03:02<01:00,  1.23it/s]Loading train:  74%|███████▍  | 212/285 [03:03<01:01,  1.19it/s]Loading train:  75%|███████▍  | 213/285 [03:04<01:00,  1.19it/s]Loading train:  75%|███████▌  | 214/285 [03:05<01:00,  1.18it/s]Loading train:  75%|███████▌  | 215/285 [03:06<00:58,  1.20it/s]Loading train:  76%|███████▌  | 216/285 [03:06<00:55,  1.25it/s]Loading train:  76%|███████▌  | 217/285 [03:07<00:52,  1.28it/s]Loading train:  76%|███████▋  | 218/285 [03:08<00:51,  1.31it/s]Loading train:  77%|███████▋  | 219/285 [03:09<00:49,  1.32it/s]Loading train:  77%|███████▋  | 220/285 [03:09<00:49,  1.32it/s]Loading train:  78%|███████▊  | 221/285 [03:10<00:48,  1.33it/s]Loading train:  78%|███████▊  | 222/285 [03:11<00:47,  1.32it/s]Loading train:  78%|███████▊  | 223/285 [03:12<00:46,  1.33it/s]Loading train:  79%|███████▊  | 224/285 [03:12<00:45,  1.35it/s]Loading train:  79%|███████▉  | 225/285 [03:13<00:44,  1.35it/s]Loading train:  79%|███████▉  | 226/285 [03:14<00:43,  1.35it/s]Loading train:  80%|███████▉  | 227/285 [03:14<00:42,  1.37it/s]Loading train:  80%|████████  | 228/285 [03:15<00:41,  1.36it/s]Loading train:  80%|████████  | 229/285 [03:16<00:40,  1.40it/s]Loading train:  81%|████████  | 230/285 [03:17<00:39,  1.40it/s]Loading train:  81%|████████  | 231/285 [03:17<00:38,  1.41it/s]Loading train:  81%|████████▏ | 232/285 [03:18<00:40,  1.32it/s]Loading train:  82%|████████▏ | 233/285 [03:19<00:41,  1.25it/s]Loading train:  82%|████████▏ | 234/285 [03:20<00:42,  1.20it/s]Loading train:  82%|████████▏ | 235/285 [03:21<00:42,  1.19it/s]Loading train:  83%|████████▎ | 236/285 [03:22<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [03:23<00:41,  1.16it/s]Loading train:  84%|████████▎ | 238/285 [03:24<00:41,  1.13it/s]Loading train:  84%|████████▍ | 239/285 [03:25<00:41,  1.10it/s]Loading train:  84%|████████▍ | 240/285 [03:25<00:40,  1.11it/s]Loading train:  85%|████████▍ | 241/285 [03:26<00:39,  1.12it/s]Loading train:  85%|████████▍ | 242/285 [03:27<00:38,  1.11it/s]Loading train:  85%|████████▌ | 243/285 [03:28<00:37,  1.11it/s]Loading train:  86%|████████▌ | 244/285 [03:29<00:36,  1.11it/s]Loading train:  86%|████████▌ | 245/285 [03:30<00:37,  1.08it/s]Loading train:  86%|████████▋ | 246/285 [03:31<00:36,  1.06it/s]Loading train:  87%|████████▋ | 247/285 [03:32<00:35,  1.08it/s]Loading train:  87%|████████▋ | 248/285 [03:33<00:33,  1.10it/s]Loading train:  87%|████████▋ | 249/285 [03:34<00:32,  1.11it/s]Loading train:  88%|████████▊ | 250/285 [03:34<00:29,  1.18it/s]Loading train:  88%|████████▊ | 251/285 [03:35<00:27,  1.26it/s]Loading train:  88%|████████▊ | 252/285 [03:36<00:25,  1.29it/s]Loading train:  89%|████████▉ | 253/285 [03:36<00:23,  1.34it/s]Loading train:  89%|████████▉ | 254/285 [03:37<00:22,  1.36it/s]Loading train:  89%|████████▉ | 255/285 [03:38<00:21,  1.38it/s]Loading train:  90%|████████▉ | 256/285 [03:38<00:20,  1.39it/s]Loading train:  90%|█████████ | 257/285 [03:39<00:20,  1.37it/s]Loading train:  91%|█████████ | 258/285 [03:40<00:20,  1.34it/s]Loading train:  91%|█████████ | 259/285 [03:41<00:19,  1.31it/s]Loading train:  91%|█████████ | 260/285 [03:41<00:18,  1.36it/s]Loading train:  92%|█████████▏| 261/285 [03:42<00:16,  1.44it/s]Loading train:  92%|█████████▏| 262/285 [03:43<00:16,  1.43it/s]Loading train:  92%|█████████▏| 263/285 [03:44<00:15,  1.43it/s]Loading train:  93%|█████████▎| 264/285 [03:44<00:14,  1.41it/s]Loading train:  93%|█████████▎| 265/285 [03:45<00:14,  1.40it/s]Loading train:  93%|█████████▎| 266/285 [03:46<00:13,  1.36it/s]Loading train:  94%|█████████▎| 267/285 [03:47<00:13,  1.33it/s]Loading train:  94%|█████████▍| 268/285 [03:47<00:13,  1.27it/s]Loading train:  94%|█████████▍| 269/285 [03:48<00:12,  1.23it/s]Loading train:  95%|█████████▍| 270/285 [03:49<00:12,  1.19it/s]Loading train:  95%|█████████▌| 271/285 [03:50<00:11,  1.17it/s]Loading train:  95%|█████████▌| 272/285 [03:51<00:11,  1.14it/s]Loading train:  96%|█████████▌| 273/285 [03:52<00:10,  1.15it/s]Loading train:  96%|█████████▌| 274/285 [03:53<00:09,  1.10it/s]Loading train:  96%|█████████▋| 275/285 [03:54<00:09,  1.07it/s]Loading train:  97%|█████████▋| 276/285 [03:55<00:08,  1.07it/s]Loading train:  97%|█████████▋| 277/285 [03:56<00:07,  1.08it/s]Loading train:  98%|█████████▊| 278/285 [03:57<00:06,  1.09it/s]Loading train:  98%|█████████▊| 279/285 [03:58<00:05,  1.09it/s]Loading train:  98%|█████████▊| 280/285 [03:58<00:04,  1.10it/s]Loading train:  99%|█████████▊| 281/285 [03:59<00:03,  1.11it/s]Loading train:  99%|█████████▉| 282/285 [04:00<00:02,  1.11it/s]Loading train:  99%|█████████▉| 283/285 [04:01<00:01,  1.11it/s]Loading train: 100%|█████████▉| 284/285 [04:02<00:00,  1.11it/s]Loading train: 100%|██████████| 285/285 [04:03<00:00,  1.14it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:00, 273.44it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:00, 279.04it/s]concatenating: train:  30%|███       | 86/285 [00:00<00:00, 277.44it/s]concatenating: train:  40%|███▉      | 113/285 [00:00<00:00, 273.52it/s]concatenating: train:  48%|████▊     | 137/285 [00:00<00:00, 260.13it/s]concatenating: train:  59%|█████▊    | 167/285 [00:00<00:00, 268.87it/s]concatenating: train:  69%|██████▉   | 198/285 [00:00<00:00, 278.07it/s]concatenating: train:  80%|████████  | 229/285 [00:00<00:00, 285.71it/s]concatenating: train:  91%|█████████ | 259/285 [00:00<00:00, 289.58it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 287.72it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 770.30it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 20)   0           batch_normalization_7[0][0]      2019-07-08 10:26:53.642202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 10:26:53.642348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 10:26:53.642366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 10:26:53.642378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 10:26:53.642813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 27144.9546 - acc: 0.5968 - mDice: 0.0556 - val_loss: 16381.0574 - val_acc: 0.8705 - val_mDice: 0.1283

Epoch 00001: val_mDice improved from -inf to 0.12828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 7s - loss: 13389.6540 - acc: 0.8685 - mDice: 0.1870 - val_loss: 11425.6977 - val_acc: 0.9009 - val_mDice: 0.2372

Epoch 00002: val_mDice improved from 0.12828 to 0.23716, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 7s - loss: 10128.7575 - acc: 0.8775 - mDice: 0.2685 - val_loss: 8752.8090 - val_acc: 0.9024 - val_mDice: 0.3117

Epoch 00003: val_mDice improved from 0.23716 to 0.31169, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 8s - loss: 8613.1293 - acc: 0.8819 - mDice: 0.3232 - val_loss: 7597.3148 - val_acc: 0.9056 - val_mDice: 0.3535

Epoch 00004: val_mDice improved from 0.31169 to 0.35352, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 8s - loss: 7693.9060 - acc: 0.8845 - mDice: 0.3638 - val_loss: 6683.8602 - val_acc: 0.9069 - val_mDice: 0.3987

Epoch 00005: val_mDice improved from 0.35352 to 0.39870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 7s - loss: 6859.2514 - acc: 0.8890 - mDice: 0.4050 - val_loss: 5775.9256 - val_acc: 0.9113 - val_mDice: 0.4527

Epoch 00006: val_mDice improved from 0.39870 to 0.45269, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 7s - loss: 6151.1414 - acc: 0.8955 - mDice: 0.4438 - val_loss: 5349.3805 - val_acc: 0.9190 - val_mDice: 0.4774

Epoch 00007: val_mDice improved from 0.45269 to 0.47743, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 7s - loss: 5653.6759 - acc: 0.9036 - mDice: 0.4737 - val_loss: 5143.6552 - val_acc: 0.9267 - val_mDice: 0.4900

Epoch 00008: val_mDice improved from 0.47743 to 0.48997, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 7s - loss: 5216.4005 - acc: 0.9114 - mDice: 0.5008 - val_loss: 5034.9124 - val_acc: 0.9324 - val_mDice: 0.4961

Epoch 00009: val_mDice improved from 0.48997 to 0.49613, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 7s - loss: 4868.5927 - acc: 0.9161 - mDice: 0.5242 - val_loss: 4729.4678 - val_acc: 0.9323 - val_mDice: 0.5149

Epoch 00010: val_mDice improved from 0.49613 to 0.51489, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 7s - loss: 4593.1963 - acc: 0.9193 - mDice: 0.5433 - val_loss: 4700.1875 - val_acc: 0.9299 - val_mDice: 0.5188

Epoch 00011: val_mDice improved from 0.51489 to 0.51875, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 7s - loss: 4437.5389 - acc: 0.9208 - mDice: 0.5547 - val_loss: 4602.6339 - val_acc: 0.9333 - val_mDice: 0.5245

Epoch 00012: val_mDice improved from 0.51875 to 0.52453, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 8s - loss: 4268.9801 - acc: 0.9224 - mDice: 0.5673 - val_loss: 4532.2978 - val_acc: 0.9298 - val_mDice: 0.5290

Epoch 00013: val_mDice improved from 0.52453 to 0.52899, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 8s - loss: 4147.0083 - acc: 0.9234 - mDice: 0.5765 - val_loss: 4809.4930 - val_acc: 0.9217 - val_mDice: 0.5115

Epoch 00014: val_mDice did not improve from 0.52899
Epoch 15/300
 - 7s - loss: 4000.0453 - acc: 0.9248 - mDice: 0.5878 - val_loss: 4563.7601 - val_acc: 0.9262 - val_mDice: 0.5290

Epoch 00015: val_mDice improved from 0.52899 to 0.52899, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 7s - loss: 3895.4566 - acc: 0.9256 - mDice: 0.5961 - val_loss: 4732.6964 - val_acc: 0.9266 - val_mDice: 0.5175

Epoch 00016: val_mDice did not improve from 0.52899
Epoch 17/300
 - 7s - loss: 3814.7014 - acc: 0.9262 - mDice: 0.6025 - val_loss: 4429.2814 - val_acc: 0.9334 - val_mDice: 0.5379

Epoch 00017: val_mDice improved from 0.52899 to 0.53787, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 7s - loss: 3720.5190 - acc: 0.9272 - mDice: 0.6103 - val_loss: 4630.4100 - val_acc: 0.9282 - val_mDice: 0.5242

Epoch 00018: val_mDice did not improve from 0.53787
Epoch 19/300
 - 7s - loss: 3643.5454 - acc: 0.9278 - mDice: 0.6163 - val_loss: 4636.4859 - val_acc: 0.9299 - val_mDice: 0.5234

Epoch 00019: val_mDice did not improve from 0.53787
Epoch 20/300
 - 7s - loss: 3570.3323 - acc: 0.9284 - mDice: 0.6224 - val_loss: 4386.2509 - val_acc: 0.9317 - val_mDice: 0.5409

Epoch 00020: val_mDice improved from 0.53787 to 0.54094, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 7s - loss: 3517.5093 - acc: 0.9288 - mDice: 0.6269 - val_loss: 4504.1684 - val_acc: 0.9367 - val_mDice: 0.5330

Epoch 00021: val_mDice did not improve from 0.54094
Epoch 22/300
 - 7s - loss: 3457.2823 - acc: 0.9293 - mDice: 0.6319 - val_loss: 4377.9846 - val_acc: 0.9336 - val_mDice: 0.5411

Epoch 00022: val_mDice improved from 0.54094 to 0.54114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 7s - loss: 3428.2250 - acc: 0.9295 - mDice: 0.6345 - val_loss: 4668.5482 - val_acc: 0.9369 - val_mDice: 0.5216

Epoch 00023: val_mDice did not improve from 0.54114
Epoch 24/300
 - 8s - loss: 3345.5311 - acc: 0.9300 - mDice: 0.6413 - val_loss: 4539.3241 - val_acc: 0.9345 - val_mDice: 0.5310

Epoch 00024: val_mDice did not improve from 0.54114
Epoch 25/300
 - 8s - loss: 3311.2619 - acc: 0.9303 - mDice: 0.6443 - val_loss: 4383.3231 - val_acc: 0.9358 - val_mDice: 0.5415

Epoch 00025: val_mDice improved from 0.54114 to 0.54149, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 7s - loss: 3252.9275 - acc: 0.9305 - mDice: 0.6493 - val_loss: 4410.3348 - val_acc: 0.9379 - val_mDice: 0.5418

Epoch 00026: val_mDice improved from 0.54149 to 0.54176, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 7s - loss: 3225.5590 - acc: 0.9308 - mDice: 0.6516 - val_loss: 4472.5989 - val_acc: 0.9340 - val_mDice: 0.5367

Epoch 00027: val_mDice did not improve from 0.54176
Epoch 28/300
 - 7s - loss: 3168.6816 - acc: 0.9311 - mDice: 0.6565 - val_loss: 4457.2069 - val_acc: 0.9383 - val_mDice: 0.5364

Epoch 00028: val_mDice did not improve from 0.54176
Epoch 29/300
 - 7s - loss: 3141.9968 - acc: 0.9313 - mDice: 0.6589 - val_loss: 4449.8943 - val_acc: 0.9363 - val_mDice: 0.5365

Epoch 00029: val_mDice did not improve from 0.54176
Epoch 30/300
 - 7s - loss: 3097.5805 - acc: 0.9314 - mDice: 0.6627 - val_loss: 4511.8515 - val_acc: 0.9395 - val_mDice: 0.5353

Epoch 00030: val_mDice did not improve from 0.54176
Epoch 31/300
 - 7s - loss: 3081.9235 - acc: 0.9315 - mDice: 0.6643 - val_loss: 4334.5209 - val_acc: 0.9380 - val_mDice: 0.5457

Epoch 00031: val_mDice improved from 0.54176 to 0.54568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 7s - loss: 3052.5712 - acc: 0.9316 - mDice: 0.6669 - val_loss: 4869.7363 - val_acc: 0.9398 - val_mDice: 0.5123

Epoch 00032: val_mDice did not improve from 0.54568
Epoch 33/300
 - 7s - loss: 3007.2155 - acc: 0.9317 - mDice: 0.6708 - val_loss: 4363.4737 - val_acc: 0.9397 - val_mDice: 0.5432

Epoch 00033: val_mDice did not improve from 0.54568
Epoch 34/300
 - 8s - loss: 2982.3423 - acc: 0.9320 - mDice: 0.6730 - val_loss: 4548.0884 - val_acc: 0.9408 - val_mDice: 0.5312

Epoch 00034: val_mDice did not improve from 0.54568
Epoch 35/300
 - 7s - loss: 2958.4976 - acc: 0.9320 - mDice: 0.6751 - val_loss: 4737.9835 - val_acc: 0.9332 - val_mDice: 0.5174

Epoch 00035: val_mDice did not improve from 0.54568
Epoch 36/300
 - 7s - loss: 2927.4420 - acc: 0.9321 - mDice: 0.6779 - val_loss: 4366.8682 - val_acc: 0.9389 - val_mDice: 0.5410

Epoch 00036: val_mDice did not improve from 0.54568
Epoch 37/300
 - 7s - loss: 2905.5172 - acc: 0.9322 - mDice: 0.6799 - val_loss: 4192.8934 - val_acc: 0.9380 - val_mDice: 0.5558

Epoch 00037: val_mDice improved from 0.54568 to 0.55582, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 7s - loss: 2897.3061 - acc: 0.9323 - mDice: 0.6807 - val_loss: 4433.7255 - val_acc: 0.9392 - val_mDice: 0.5423

Epoch 00038: val_mDice did not improve from 0.55582
Epoch 39/300
 - 7s - loss: 2871.9389 - acc: 0.9325 - mDice: 0.6828 - val_loss: 4430.3871 - val_acc: 0.9391 - val_mDice: 0.5403

Epoch 00039: val_mDice did not improve from 0.55582
Epoch 40/300
 - 7s - loss: 2837.6608 - acc: 0.9326 - mDice: 0.6859 - val_loss: 4553.9871 - val_acc: 0.9340 - val_mDice: 0.5272

Epoch 00040: val_mDice did not improve from 0.55582
Epoch 41/300
 - 7s - loss: 2832.1858 - acc: 0.9325 - mDice: 0.6864 - val_loss: 4571.0711 - val_acc: 0.9340 - val_mDice: 0.5312

Epoch 00041: val_mDice did not improve from 0.55582
Epoch 42/300
 - 7s - loss: 2803.0471 - acc: 0.9330 - mDice: 0.6890 - val_loss: 4330.9083 - val_acc: 0.9381 - val_mDice: 0.5456

Epoch 00042: val_mDice did not improve from 0.55582
Epoch 43/300
 - 7s - loss: 2788.5923 - acc: 0.9331 - mDice: 0.6903 - val_loss: 4577.6807 - val_acc: 0.9355 - val_mDice: 0.5306

Epoch 00043: val_mDice did not improve from 0.55582
Epoch 44/300
 - 8s - loss: 2748.9652 - acc: 0.9338 - mDice: 0.6939 - val_loss: 4340.5120 - val_acc: 0.9380 - val_mDice: 0.5454

Epoch 00044: val_mDice did not improve from 0.55582
Epoch 45/300
 - 8s - loss: 2781.7656 - acc: 0.9336 - mDice: 0.6912 - val_loss: 4389.5952 - val_acc: 0.9390 - val_mDice: 0.5426

Epoch 00045: val_mDice did not improve from 0.55582
Epoch 46/300
 - 7s - loss: 2746.3605 - acc: 0.9339 - mDice: 0.6943 - val_loss: 4709.6049 - val_acc: 0.9365 - val_mDice: 0.5214

Epoch 00046: val_mDice did not improve from 0.55582
Epoch 47/300
 - 7s - loss: 2723.6537 - acc: 0.9345 - mDice: 0.6963 - val_loss: 4332.3874 - val_acc: 0.9409 - val_mDice: 0.5470

Epoch 00047: val_mDice did not improve from 0.55582
Epoch 48/300
 - 7s - loss: 2711.3092 - acc: 0.9345 - mDice: 0.6974 - val_loss: 4135.8629 - val_acc: 0.9394 - val_mDice: 0.5597

Epoch 00048: val_mDice improved from 0.55582 to 0.55969, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 49/300
 - 7s - loss: 2701.7741 - acc: 0.9348 - mDice: 0.6985 - val_loss: 4410.4801 - val_acc: 0.9360 - val_mDice: 0.5410

Epoch 00049: val_mDice did not improve from 0.55969
Epoch 50/300
 - 7s - loss: 2676.5527 - acc: 0.9354 - mDice: 0.7006 - val_loss: 4352.6100 - val_acc: 0.9386 - val_mDice: 0.5426

Epoch 00050: val_mDice did not improve from 0.55969
Epoch 51/300
 - 7s - loss: 2673.8513 - acc: 0.9353 - mDice: 0.7009 - val_loss: 4505.2054 - val_acc: 0.9407 - val_mDice: 0.5386

Epoch 00051: val_mDice did not improve from 0.55969
Epoch 52/300
 - 7s - loss: 2671.9405 - acc: 0.9356 - mDice: 0.7012 - val_loss: 4383.8614 - val_acc: 0.9370 - val_mDice: 0.5417

Epoch 00052: val_mDice did not improve from 0.55969
Epoch 53/300
 - 8s - loss: 2652.8522 - acc: 0.9363 - mDice: 0.7030 - val_loss: 4297.3759 - val_acc: 0.9406 - val_mDice: 0.5519

Epoch 00053: val_mDice did not improve from 0.55969
Epoch 54/300
 - 8s - loss: 2636.1598 - acc: 0.9365 - mDice: 0.7045 - val_loss: 4167.6350 - val_acc: 0.9417 - val_mDice: 0.5575

Epoch 00054: val_mDice did not improve from 0.55969
Epoch 55/300
 - 7s - loss: 2628.7225 - acc: 0.9367 - mDice: 0.7053 - val_loss: 4442.4071 - val_acc: 0.9339 - val_mDice: 0.5388

Epoch 00055: val_mDice did not improve from 0.55969
Epoch 56/300
 - 7s - loss: 2607.4541 - acc: 0.9370 - mDice: 0.7072 - val_loss: 4350.6174 - val_acc: 0.9390 - val_mDice: 0.5463

Epoch 00056: val_mDice did not improve from 0.55969
Epoch 57/300
 - 7s - loss: 2596.9485 - acc: 0.9375 - mDice: 0.7082 - val_loss: 4477.8845 - val_acc: 0.9409 - val_mDice: 0.5385

Epoch 00057: val_mDice did not improve from 0.55969
Epoch 58/300
 - 7s - loss: 2602.4898 - acc: 0.9376 - mDice: 0.7078 - val_loss: 4321.9368 - val_acc: 0.9375 - val_mDice: 0.5467

Epoch 00058: val_mDice did not improve from 0.55969
Epoch 59/300
 - 7s - loss: 2588.0172 - acc: 0.9380 - mDice: 0.7090 - val_loss: 4659.8737 - val_acc: 0.9400 - val_mDice: 0.5270

Epoch 00059: val_mDice did not improve from 0.55969
Epoch 60/300
 - 7s - loss: 2584.7099 - acc: 0.9384 - mDice: 0.7093 - val_loss: 4601.4177 - val_acc: 0.9396 - val_mDice: 0.5296

Epoch 00060: val_mDice did not improve from 0.55969
Epoch 61/300
 - 7s - loss: 2552.9345 - acc: 0.9384 - mDice: 0.7123 - val_loss: 4643.6051 - val_acc: 0.9393 - val_mDice: 0.5280

Epoch 00061: val_mDice did not improve from 0.55969
Epoch 62/300
 - 7s - loss: 2572.5638 - acc: 0.9385 - mDice: 0.7105 - val_loss: 4501.1146 - val_acc: 0.9339 - val_mDice: 0.5362

Epoch 00062: val_mDice did not improve from 0.55969
Epoch 63/300
 - 7s - loss: 2540.3142 - acc: 0.9390 - mDice: 0.7134 - val_loss: 4550.2115 - val_acc: 0.9394 - val_mDice: 0.5320

Epoch 00063: val_mDice did not improve from 0.55969
Epoch 64/300
 - 7s - loss: 2538.9427 - acc: 0.9390 - mDice: 0.7137 - val_loss: 4598.7053 - val_acc: 0.9356 - val_mDice: 0.5267

Epoch 00064: val_mDice did not improve from 0.55969
Epoch 65/300
 - 7s - loss: 2538.3288 - acc: 0.9394 - mDice: 0.7138 - val_loss: 4446.4141 - val_acc: 0.9379 - val_mDice: 0.5398

Epoch 00065: val_mDice did not improve from 0.55969
Epoch 66/300
 - 7s - loss: 2540.1493 - acc: 0.9393 - mDice: 0.7136 - val_loss: 4575.4537 - val_acc: 0.9380 - val_mDice: 0.5326

Epoch 00066: val_mDice did not improve from 0.55969
Epoch 67/300
 - 8s - loss: 2526.8046 - acc: 0.9397 - mDice: 0.7149 - val_loss: 4346.0023 - val_acc: 0.9407 - val_mDice: 0.5433

Epoch 00067: val_mDice did not improve from 0.55969
Epoch 68/300
 - 7s - loss: 2513.8501 - acc: 0.9398 - mDice: 0.7160 - val_loss: 4459.3913 - val_acc: 0.9318 - val_mDice: 0.5370

Epoch 00068: val_mDice did not improve from 0.55969
Epoch 69/300
 - 7s - loss: 2501.4467 - acc: 0.9401 - mDice: 0.7172 - val_loss: 4154.9464 - val_acc: 0.9410 - val_mDice: 0.5578

Epoch 00069: val_mDice did not improve from 0.55969
Epoch 70/300
 - 7s - loss: 2488.0765 - acc: 0.9402 - mDice: 0.7186 - val_loss: 4324.4270 - val_acc: 0.9417 - val_mDice: 0.5493

Epoch 00070: val_mDice did not improve from 0.55969
Epoch 71/300
 - 7s - loss: 2488.2223 - acc: 0.9403 - mDice: 0.7185 - val_loss: 4471.8014 - val_acc: 0.9397 - val_mDice: 0.5366

Epoch 00071: val_mDice did not improve from 0.55969
Epoch 72/300
 - 7s - loss: 2490.9802 - acc: 0.9403 - mDice: 0.7182 - val_loss: 4492.8833 - val_acc: 0.9319 - val_mDice: 0.5379

Epoch 00072: val_mDice did not improve from 0.55969
Epoch 73/300
 - 7s - loss: 2452.0178 - acc: 0.9406 - mDice: 0.7220 - val_loss: 4502.3654 - val_acc: 0.9380 - val_mDice: 0.5386

Epoch 00073: val_mDice did not improve from 0.55969
Epoch 74/300
 - 7s - loss: 2457.2431 - acc: 0.9408 - mDice: 0.7215 - val_loss: 4458.2685 - val_acc: 0.9423 - val_mDice: 0.5417

Epoch 00074: val_mDice did not improve from 0.55969
Epoch 75/300
 - 7s - loss: 2447.5214 - acc: 0.9408 - mDice: 0.7224 - val_loss: 4347.2841 - val_acc: 0.9403 - val_mDice: 0.5485

Epoch 00075: val_mDice did not improve from 0.55969
Epoch 76/300
 - 7s - loss: 2439.6787 - acc: 0.9411 - mDice: 0.7231 - val_loss: 4203.4378 - val_acc: 0.9429 - val_mDice: 0.5556

Epoch 00076: val_mDice did not improve from 0.55969
Epoch 77/300
 - 7s - loss: 2440.0311 - acc: 0.9410 - mDice: 0.7231 - val_loss: 4270.3376 - val_acc: 0.9372 - val_mDice: 0.5491

Epoch 00077: val_mDice did not improve from 0.55969
Epoch 78/300
 - 7s - loss: 2446.7389 - acc: 0.9412 - mDice: 0.7225 - val_loss: 4272.7239 - val_acc: 0.9398 - val_mDice: 0.5524

Epoch 00078: val_mDice did not improve from 0.55969
Restoring model weights from the end of the best epoch
Epoch 00078: early stopping
{'val_loss': [16381.057401216947, 11425.69766000601, 8752.80898813101, 7597.314828725962, 6683.860182542067, 5775.92564039964, 5349.380474384015, 5143.65517953726, 5034.912362905649, 4729.4677734375, 4700.187509390024, 4602.63388296274, 4532.2977952223555, 4809.49302321214, 4563.760108360877, 4732.696439302885, 4429.281447190505, 4630.410029484676, 4636.485872708834, 4386.250910832332, 4504.1684006911055, 4377.9845628004805, 4668.54819899339, 4539.324068509615, 4383.3230543870195, 4410.334754356971, 4472.598858173077, 4457.206946739783, 4449.894258939303, 4511.851459209735, 4334.5209397536055, 4869.7362717848555, 4363.47367976262, 4548.088416466346, 4737.983497032752, 4366.868248572717, 4192.893446702224, 4433.725473257212, 4430.387108435998, 4553.987135667067, 4571.071077786959, 4330.908339280349, 4577.680706317608, 4340.511972280649, 4389.5952383188105, 4709.604895958533, 4332.387418306791, 4135.862868088942, 4410.480144794171, 4352.6099524864785, 4505.205350435697, 4383.861440805288, 4297.375873272235, 4167.634995680589, 4442.407062237079, 4350.617384690505, 4477.884455754207, 4321.936828613281, 4659.873671311599, 4601.417729304387, 4643.605140099158, 4501.114614633413, 4550.211453951322, 4598.705270620493, 4446.4141188401445, 4575.453693096454, 4346.002342810998, 4459.391338641827, 4154.946439302885, 4324.426983173077, 4471.801429161658, 4492.883296086238, 4502.365403395433, 4458.2684983473555, 4347.284076397235, 4203.437753530649, 4270.337566669171, 4272.7239004281855], 'val_acc': [0.8705066419564761, 0.9008575013050666, 0.9023991983670455, 0.9055566031199235, 0.9069249102702508, 0.9113489297720102, 0.919048146559642, 0.9266618696542887, 0.932442653637666, 0.9323201454602755, 0.9298885877315815, 0.9333256414303412, 0.9297661093565134, 0.9216577525322254, 0.9262019235354203, 0.9265509270704709, 0.9333580021674817, 0.9281573822865119, 0.9299255792911236, 0.9316914975643158, 0.9366933061526372, 0.9336214638673342, 0.9369036532365359, 0.9344836519314692, 0.935796490082374, 0.9379160266656142, 0.9339866913281955, 0.938288165972783, 0.9363350570201874, 0.9395386439103347, 0.9380177305294917, 0.9398114108122312, 0.9396657485228318, 0.9407960268167349, 0.933237795646374, 0.9388868602422568, 0.9380223498894618, 0.9391988676327926, 0.9391410832221692, 0.9340444803237915, 0.9339728034459628, 0.9380894211622385, 0.935509917827753, 0.9379807435549222, 0.9390046963324914, 0.9364829842860882, 0.9408607528759882, 0.9393560267411746, 0.9360369054170755, 0.9385910011254824, 0.9407151226813977, 0.9369729780233823, 0.9405926305514115, 0.9417136747103471, 0.9338896297491514, 0.9390439918408027, 0.9409070014953613, 0.937488452746318, 0.9400194103901203, 0.9396172142945803, 0.9392751753330231, 0.933896548472918, 0.9394369515088888, 0.9355977475643158, 0.9379276105990777, 0.9380292915380918, 0.9406550618318411, 0.9318163096904755, 0.9409670715148633, 0.9416628227784083, 0.9396865803461808, 0.9319411149391761, 0.9379668946449573, 0.942300762121494, 0.9402597821675814, 0.9428577766968653, 0.9372018392269428, 0.9397905904513139], 'val_mDice': [0.12828296279677978, 0.23716436025614923, 0.31169407757428974, 0.35352084427498853, 0.3986977212704145, 0.4526932348425572, 0.4774253351184038, 0.4899680568621709, 0.4961306151862328, 0.51489059942273, 0.5187549619720533, 0.5245300972690949, 0.5289854235374011, 0.5114732224207658, 0.528992527952561, 0.5175192559567782, 0.5378696881234646, 0.5241520846119294, 0.5233599073611773, 0.54094311566307, 0.5329930653365759, 0.5411410535184237, 0.5215552257230649, 0.5309946806384966, 0.5414895879534575, 0.5417633744386526, 0.5367357897070738, 0.536383314201465, 0.5365436140161294, 0.5353353355939572, 0.5456780447409704, 0.5123269357360326, 0.5431673202950221, 0.5312191855448943, 0.5174403566007431, 0.5410362894718463, 0.5558172647769635, 0.5423445159999224, 0.5402803300664976, 0.5272133152645367, 0.5312496417990098, 0.545576542042769, 0.5305971182309664, 0.5453505112001529, 0.542554686562373, 0.5214089676737785, 0.5470045271974343, 0.5596874608443334, 0.5410244040764295, 0.5426370123258004, 0.5385580234802686, 0.5417420583275648, 0.5518748118327215, 0.5575490238574835, 0.538801107269067, 0.5462682304474024, 0.5384892282577661, 0.5467220828510247, 0.5270116776227951, 0.5295820637391164, 0.5280235736415937, 0.5362186876053994, 0.5319819307098022, 0.5266610541595862, 0.5397578351772748, 0.532602017888656, 0.5433324778882357, 0.537034331032863, 0.5578482535022956, 0.5492768161571943, 0.5365922514062661, 0.5378817927378875, 0.5386125247638959, 0.5416625199409631, 0.5485129479605418, 0.5555925675882742, 0.5491241892943015, 0.5524286816899593], 'loss': [27144.954598174656, 13389.654040192981, 10128.757521638745, 8613.129305525634, 7693.906039318102, 6859.251430349289, 6151.141363883958, 5653.675893762284, 5216.400533218616, 4868.592693933622, 4593.196251933671, 4437.538903762436, 4268.980126664921, 4147.008289984844, 4000.045314711068, 3895.456608884242, 3814.701397192277, 3720.5190437905826, 3643.5454111019208, 3570.332349501929, 3517.5093033496914, 3457.28225196051, 3428.2250374260398, 3345.531109950688, 3311.2619330457114, 3252.9274745294883, 3225.5590363913857, 3168.6815756889528, 3141.99676496222, 3097.580493904838, 3081.923454326182, 3052.571166676964, 3007.215493459472, 2982.3423198420965, 2958.4975823030627, 2927.441992644574, 2905.517194261545, 2897.3060725921964, 2871.9388811406443, 2837.6607509979976, 2832.1858218062093, 2803.0471260530267, 2788.5922753618047, 2748.9652477427294, 2781.7656427313236, 2746.3605003817806, 2723.6536763462204, 2711.309247422282, 2701.774089708744, 2676.5526840855887, 2673.851307608001, 2671.9404978996204, 2652.8521795388046, 2636.159774041468, 2628.7224743660227, 2607.4540967103094, 2596.948546873559, 2602.4898318908404, 2588.0172047202113, 2584.7098765701735, 2552.934494366145, 2572.5638334630853, 2540.3142146921723, 2538.9426665024203, 2538.328807053658, 2540.149257880498, 2526.804610337783, 2513.850064737907, 2501.446652931777, 2488.0765354515693, 2488.2223185217604, 2490.980158941559, 2452.017785891081, 2457.243127203863, 2447.521376731793, 2439.6787269576103, 2440.0310518707524, 2446.7389196226827], 'acc': [0.5967827533115532, 0.8684568082968556, 0.877506626006324, 0.8818736728086668, 0.8845030496198072, 0.8890020804498443, 0.8955424767484703, 0.9036234203524379, 0.9114091899093091, 0.916116081336916, 0.919313038823614, 0.9207681414661708, 0.9224085781249483, 0.9234015496412811, 0.9248291861523916, 0.9256121232304463, 0.9262311664947359, 0.9271809092848149, 0.927826307685813, 0.9284065085661034, 0.9288355354661157, 0.9293123790668757, 0.9295311295974082, 0.9299864033804843, 0.9302817433838869, 0.9305289346639888, 0.9307604928105935, 0.9311376898576553, 0.9313106553356421, 0.9314363136135827, 0.9314778590569536, 0.9315931849689443, 0.9316606260001258, 0.9319976454377888, 0.9319911485150172, 0.9320762375123847, 0.932167333188031, 0.932266139669699, 0.9324885908004752, 0.9326330912813515, 0.932534859484548, 0.93304489085587, 0.9331270953248504, 0.9337540761874543, 0.933608731148945, 0.933912966564266, 0.9344950475057728, 0.9345271070922838, 0.9347991272827735, 0.9353548967892159, 0.9352954129203928, 0.9355678787632071, 0.9362617658258287, 0.9365213681089695, 0.9367204317909803, 0.9370428418350167, 0.9375360054931529, 0.9375819141856201, 0.9379831648264315, 0.9383500945048062, 0.9384455569641601, 0.9385143031243258, 0.938972877491931, 0.9390473036564639, 0.939386830056801, 0.939295071825752, 0.9396983782963417, 0.939841993601793, 0.9400689210507369, 0.940206597066394, 0.9402560083494298, 0.9403199502421978, 0.9406434421300515, 0.940766150140239, 0.9408275415061156, 0.9410739798756045, 0.9410366194390903, 0.9412116299671165], 'mDice': [0.05562314442464987, 0.1870035853903089, 0.26845855959104037, 0.32318326969115063, 0.36384314755435626, 0.40502945153209474, 0.44377322243630507, 0.47369457418371325, 0.5008115035674234, 0.5242108265588197, 0.5433459874394744, 0.5546603644893562, 0.5672847519201908, 0.5765240325497204, 0.5877638660837867, 0.5960643861848556, 0.6025055598137421, 0.6103236850893586, 0.6163215269343633, 0.6223700769128124, 0.6268850078246784, 0.6318974946957502, 0.6344712763147953, 0.6412709475849911, 0.6443153430832209, 0.6492812983732233, 0.6516463783441914, 0.6565145649318929, 0.6588718800882039, 0.6627351790460441, 0.6643265092283842, 0.6669047798638105, 0.6707527734449865, 0.6729816140629846, 0.6751237777802576, 0.6778569628279181, 0.679892679806797, 0.6807001334521687, 0.6828132810313841, 0.685910535438094, 0.686446923232437, 0.6890424093416913, 0.6903380547888679, 0.6939368102423634, 0.6912260638120638, 0.6942672143505364, 0.6963340605546504, 0.6974145019174249, 0.6984649889750376, 0.7006409219695909, 0.7009481488586429, 0.7011999767512443, 0.7030042458216027, 0.7044712266314682, 0.705279622066508, 0.7071998669390286, 0.7081866863303152, 0.7077608681149471, 0.7090323116741287, 0.7093287612815125, 0.7123277675101736, 0.7105422097412102, 0.7134205905161781, 0.7136774517937273, 0.7138418401616817, 0.713639587452521, 0.7149057427059952, 0.715962453015141, 0.7172272525776535, 0.7185586615153193, 0.7184650745436262, 0.7182463993943069, 0.7219986650959808, 0.7214632821590997, 0.7224000555545677, 0.7230859143173498, 0.7231463624313398, 0.722516072678146]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.10s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:36,  1.40s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:03,  1.50s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:03,  1.50s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:31,  1.61s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:17,  1.56s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:46,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:11,  1.77s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:18,  1.80s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:03,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:14,  1.80s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:31,  1.87s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:47,  1.93s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:50,  1.95s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:53,  1.97s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:54,  1.98s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:52,  1.98s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:50,  1.98s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:44,  1.97s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:49,  2.00s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:40,  1.97s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:33,  1.95s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:35,  1.97s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:34,  1.97s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:43,  2.01s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:37,  2.00s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:41,  2.02s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:37,  2.01s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:29,  1.99s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:28,  2.00s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:21,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:21,  1.98s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<08:14,  1.96s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<08:13,  1.97s/it]predicting train subjects:  12%|█▏        | 35/285 [01:06<08:05,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:08<08:06,  1.95s/it]predicting train subjects:  13%|█▎        | 37/285 [01:10<08:05,  1.96s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<08:05,  1.96s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<07:56,  1.94s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:49,  1.91s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:54,  1.95s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:46,  1.92s/it]predicting train subjects:  15%|█▌        | 43/285 [01:22<07:46,  1.93s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:46,  1.93s/it]predicting train subjects:  16%|█▌        | 45/285 [01:26<07:34,  1.89s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:14,  1.82s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<06:55,  1.75s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<06:43,  1.70s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<06:37,  1.68s/it]predicting train subjects:  18%|█▊        | 50/285 [01:34<06:28,  1.65s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<06:27,  1.65s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<06:26,  1.66s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<06:25,  1.66s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<06:21,  1.65s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<06:18,  1.64s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<06:20,  1.66s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:15,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:10,  1.63s/it]predicting train subjects:  21%|██        | 59/285 [01:48<06:06,  1.62s/it]predicting train subjects:  21%|██        | 60/285 [01:50<06:07,  1.63s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<06:03,  1.62s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<06:11,  1.67s/it]predicting train subjects:  22%|██▏       | 63/285 [01:55<06:07,  1.66s/it]predicting train subjects:  22%|██▏       | 64/285 [01:57<06:05,  1.65s/it]predicting train subjects:  23%|██▎       | 65/285 [01:59<06:23,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [02:01<06:25,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [02:02<06:13,  1.71s/it]predicting train subjects:  24%|██▍       | 68/285 [02:04<06:05,  1.69s/it]predicting train subjects:  24%|██▍       | 69/285 [02:05<06:03,  1.68s/it]predicting train subjects:  25%|██▍       | 70/285 [02:07<05:59,  1.67s/it]predicting train subjects:  25%|██▍       | 71/285 [02:09<05:53,  1.65s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<05:51,  1.65s/it]predicting train subjects:  26%|██▌       | 73/285 [02:12<05:56,  1.68s/it]predicting train subjects:  26%|██▌       | 74/285 [02:14<05:53,  1.68s/it]predicting train subjects:  26%|██▋       | 75/285 [02:15<05:49,  1.66s/it]predicting train subjects:  27%|██▋       | 76/285 [02:17<05:49,  1.67s/it]predicting train subjects:  27%|██▋       | 77/285 [02:19<05:49,  1.68s/it]predicting train subjects:  27%|██▋       | 78/285 [02:21<05:51,  1.70s/it]predicting train subjects:  28%|██▊       | 79/285 [02:22<05:52,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:24<05:52,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:26<05:53,  1.73s/it]predicting train subjects:  29%|██▉       | 82/285 [02:27<05:49,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:29<05:47,  1.72s/it]predicting train subjects:  29%|██▉       | 84/285 [02:31<05:46,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:33<05:58,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:35<06:06,  1.84s/it]predicting train subjects:  31%|███       | 87/285 [02:37<06:13,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:39<06:10,  1.88s/it]predicting train subjects:  31%|███       | 89/285 [02:41<06:13,  1.91s/it]predicting train subjects:  32%|███▏      | 90/285 [02:43<06:09,  1.90s/it]predicting train subjects:  32%|███▏      | 91/285 [02:44<06:09,  1.91s/it]predicting train subjects:  32%|███▏      | 92/285 [02:46<06:12,  1.93s/it]predicting train subjects:  33%|███▎      | 93/285 [02:48<06:17,  1.96s/it]predicting train subjects:  33%|███▎      | 94/285 [02:50<06:09,  1.93s/it]predicting train subjects:  33%|███▎      | 95/285 [02:52<06:02,  1.91s/it]predicting train subjects:  34%|███▎      | 96/285 [02:54<05:55,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [02:56<05:48,  1.85s/it]predicting train subjects:  34%|███▍      | 98/285 [02:58<05:50,  1.87s/it]predicting train subjects:  35%|███▍      | 99/285 [03:00<05:49,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [03:02<05:51,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:03<05:47,  1.89s/it]predicting train subjects:  36%|███▌      | 102/285 [03:05<05:42,  1.87s/it]predicting train subjects:  36%|███▌      | 103/285 [03:07<05:36,  1.85s/it]predicting train subjects:  36%|███▋      | 104/285 [03:09<05:35,  1.85s/it]predicting train subjects:  37%|███▋      | 105/285 [03:11<05:36,  1.87s/it]predicting train subjects:  37%|███▋      | 106/285 [03:13<05:29,  1.84s/it]predicting train subjects:  38%|███▊      | 107/285 [03:14<05:27,  1.84s/it]predicting train subjects:  38%|███▊      | 108/285 [03:16<05:29,  1.86s/it]predicting train subjects:  38%|███▊      | 109/285 [03:18<05:22,  1.83s/it]predicting train subjects:  39%|███▊      | 110/285 [03:20<05:25,  1.86s/it]predicting train subjects:  39%|███▉      | 111/285 [03:22<05:26,  1.88s/it]predicting train subjects:  39%|███▉      | 112/285 [03:24<05:29,  1.90s/it]predicting train subjects:  40%|███▉      | 113/285 [03:26<05:26,  1.90s/it]predicting train subjects:  40%|████      | 114/285 [03:28<05:20,  1.87s/it]predicting train subjects:  40%|████      | 115/285 [03:29<05:16,  1.86s/it]predicting train subjects:  41%|████      | 116/285 [03:31<05:12,  1.85s/it]predicting train subjects:  41%|████      | 117/285 [03:33<05:11,  1.85s/it]predicting train subjects:  41%|████▏     | 118/285 [03:35<05:08,  1.85s/it]predicting train subjects:  42%|████▏     | 119/285 [03:37<05:11,  1.88s/it]predicting train subjects:  42%|████▏     | 120/285 [03:39<05:08,  1.87s/it]predicting train subjects:  42%|████▏     | 121/285 [03:40<04:54,  1.79s/it]predicting train subjects:  43%|████▎     | 122/285 [03:42<04:41,  1.73s/it]predicting train subjects:  43%|████▎     | 123/285 [03:43<04:25,  1.64s/it]predicting train subjects:  44%|████▎     | 124/285 [03:45<04:21,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:47<04:20,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:48<04:17,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:50<04:16,  1.62s/it]predicting train subjects:  45%|████▍     | 128/285 [03:52<04:21,  1.67s/it]predicting train subjects:  45%|████▌     | 129/285 [03:53<04:18,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [03:55<04:15,  1.65s/it]predicting train subjects:  46%|████▌     | 131/285 [03:57<04:12,  1.64s/it]predicting train subjects:  46%|████▋     | 132/285 [03:58<04:10,  1.64s/it]predicting train subjects:  47%|████▋     | 133/285 [04:00<04:07,  1.63s/it]predicting train subjects:  47%|████▋     | 134/285 [04:01<04:06,  1.63s/it]predicting train subjects:  47%|████▋     | 135/285 [04:03<04:07,  1.65s/it]predicting train subjects:  48%|████▊     | 136/285 [04:05<04:04,  1.64s/it]predicting train subjects:  48%|████▊     | 137/285 [04:06<04:05,  1.66s/it]predicting train subjects:  48%|████▊     | 138/285 [04:08<04:05,  1.67s/it]predicting train subjects:  49%|████▉     | 139/285 [04:10<04:04,  1.68s/it]predicting train subjects:  49%|████▉     | 140/285 [04:11<04:00,  1.66s/it]predicting train subjects:  49%|████▉     | 141/285 [04:13<03:59,  1.66s/it]predicting train subjects:  50%|████▉     | 142/285 [04:15<03:49,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:16<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:18<03:40,  1.56s/it]predicting train subjects:  51%|█████     | 145/285 [04:19<03:39,  1.57s/it]predicting train subjects:  51%|█████     | 146/285 [04:21<03:34,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:22<03:31,  1.53s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:24<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:25<03:34,  1.58s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:27<03:31,  1.57s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:28<03:26,  1.54s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:30<03:19,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:31<03:19,  1.51s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:33<03:18,  1.51s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:34<03:14,  1.50s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:36<03:12,  1.50s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:37<03:10,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:39<03:08,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:40<03:06,  1.48s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:42<03:05,  1.49s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:43<03:03,  1.48s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:45<03:00,  1.47s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:46<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:48<02:55,  1.45s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:49<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:50<02:55,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:52<02:52,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:53<02:52,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:55<02:51,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:56<02:48,  1.47s/it]predicting train subjects:  60%|██████    | 171/285 [04:58<02:48,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [04:59<02:46,  1.47s/it]predicting train subjects:  61%|██████    | 173/285 [05:01<02:43,  1.46s/it]predicting train subjects:  61%|██████    | 174/285 [05:02<02:44,  1.48s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:04<02:41,  1.47s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:05<02:38,  1.45s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:07<02:37,  1.46s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:08<02:34,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:09<02:34,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:11<02:33,  1.46s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:12<02:31,  1.46s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:14<02:30,  1.46s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:15<02:27,  1.45s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:17<02:26,  1.45s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:18<02:24,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:20<02:23,  1.45s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:21<02:20,  1.43s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:23<02:19,  1.44s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:24<02:18,  1.44s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:25<02:17,  1.45s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:27<02:16,  1.46s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:28<02:13,  1.43s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:30<02:11,  1.43s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:31<02:09,  1.42s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:33<02:08,  1.43s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:34<02:14,  1.51s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:36<02:16,  1.55s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:38<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:39<02:20,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:41<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [05:43<02:19,  1.66s/it]predicting train subjects:  71%|███████   | 202/285 [05:44<02:18,  1.66s/it]predicting train subjects:  71%|███████   | 203/285 [05:46<02:16,  1.67s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:48<02:15,  1.67s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:49<02:15,  1.69s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:51<02:14,  1.70s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:53<02:13,  1.72s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:55<02:10,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:56<02:08,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:58<02:06,  1.69s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:00<02:02,  1.66s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:01<02:01,  1.66s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:03<01:58,  1.65s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:04<01:53,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:06<01:48,  1.55s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:07<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:09<01:43,  1.53s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:10<01:40,  1.49s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:12<01:38,  1.50s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:13<01:37,  1.51s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:15<01:35,  1.49s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:16<01:34,  1.50s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:18<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:19<01:30,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:21<01:29,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:22<01:27,  1.49s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:24<01:25,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:25<01:23,  1.47s/it]predicting train subjects:  80%|████████  | 229/285 [06:26<01:22,  1.47s/it]predicting train subjects:  81%|████████  | 230/285 [06:28<01:20,  1.46s/it]predicting train subjects:  81%|████████  | 231/285 [06:29<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:31<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:33<01:24,  1.63s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:35<01:25,  1.68s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:37<01:25,  1.71s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:38<01:26,  1.77s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:40<01:24,  1.76s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:42<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:44<01:22,  1.79s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:46<01:21,  1.81s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:47<01:19,  1.81s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:49<01:17,  1.80s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:51<01:15,  1.80s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:53<01:13,  1.78s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:54<01:10,  1.76s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:56<01:09,  1.79s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:58<01:09,  1.82s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:00<01:07,  1.82s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:02<01:06,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:03<01:00,  1.73s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:05<00:55,  1.63s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:06<00:52,  1.59s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:08<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:09<00:48,  1.56s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:11<00:45,  1.51s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:12<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [07:13<00:39,  1.42s/it]predicting train subjects:  91%|█████████ | 258/285 [07:15<00:38,  1.42s/it]predicting train subjects:  91%|█████████ | 259/285 [07:16<00:36,  1.42s/it]predicting train subjects:  91%|█████████ | 260/285 [07:18<00:35,  1.42s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:19<00:34,  1.42s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:21<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:22<00:31,  1.42s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:23<00:30,  1.44s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:25<00:28,  1.43s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:26<00:27,  1.45s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:28<00:26,  1.45s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:30<00:27,  1.59s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:32<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:34<00:26,  1.77s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:36<00:25,  1.83s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:38<00:24,  1.88s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:40<00:22,  1.91s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:41<00:20,  1.89s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:43<00:18,  1.89s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:45<00:16,  1.89s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:47<00:15,  1.88s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:49<00:13,  1.92s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:51<00:11,  1.93s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:53<00:09,  1.98s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:55<00:08,  2.01s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:57<00:06,  2.02s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:59<00:04,  2.06s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:02<00:02,  2.09s/it]predicting train subjects: 100%|██████████| 285/285 [08:04<00:00,  2.12s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:40,  1.41s/it]Loading train:   1%|          | 2/285 [00:03<06:54,  1.46s/it]Loading train:   1%|          | 3/285 [00:04<07:00,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:06<07:51,  1.68s/it]Loading train:   2%|▏         | 5/285 [00:08<07:43,  1.65s/it]Loading train:   2%|▏         | 6/285 [00:10<08:15,  1.78s/it]Loading train:   2%|▏         | 7/285 [00:12<08:45,  1.89s/it]Loading train:   3%|▎         | 8/285 [00:14<09:09,  1.98s/it]Loading train:   3%|▎         | 9/285 [00:16<08:39,  1.88s/it]Loading train:   4%|▎         | 10/285 [00:18<08:22,  1.83s/it]Loading train:   4%|▍         | 11/285 [00:19<07:56,  1.74s/it]Loading train:   4%|▍         | 12/285 [00:20<07:23,  1.63s/it]Loading train:   5%|▍         | 13/285 [00:22<07:26,  1.64s/it]Loading train:   5%|▍         | 14/285 [00:24<07:08,  1.58s/it]Loading train:   5%|▌         | 15/285 [00:25<06:50,  1.52s/it]Loading train:   6%|▌         | 16/285 [00:26<06:34,  1.47s/it]Loading train:   6%|▌         | 17/285 [00:28<06:24,  1.43s/it]Loading train:   6%|▋         | 18/285 [00:29<06:30,  1.46s/it]Loading train:   7%|▋         | 19/285 [00:31<06:30,  1.47s/it]Loading train:   7%|▋         | 20/285 [00:32<06:39,  1.51s/it]Loading train:   7%|▋         | 21/285 [00:34<07:00,  1.59s/it]Loading train:   8%|▊         | 22/285 [00:36<07:08,  1.63s/it]Loading train:   8%|▊         | 23/285 [00:37<06:54,  1.58s/it]Loading train:   8%|▊         | 24/285 [00:39<06:40,  1.54s/it]Loading train:   9%|▉         | 25/285 [00:40<06:36,  1.52s/it]Loading train:   9%|▉         | 26/285 [00:42<06:23,  1.48s/it]Loading train:   9%|▉         | 27/285 [00:43<06:08,  1.43s/it]Loading train:  10%|▉         | 28/285 [00:44<06:25,  1.50s/it]Loading train:  10%|█         | 29/285 [00:46<06:16,  1.47s/it]Loading train:  11%|█         | 30/285 [00:47<05:52,  1.38s/it]Loading train:  11%|█         | 31/285 [00:48<05:42,  1.35s/it]Loading train:  11%|█         | 32/285 [00:50<05:42,  1.36s/it]Loading train:  12%|█▏        | 33/285 [00:51<05:59,  1.43s/it]Loading train:  12%|█▏        | 34/285 [00:53<05:47,  1.38s/it]Loading train:  12%|█▏        | 35/285 [00:54<06:01,  1.45s/it]Loading train:  13%|█▎        | 36/285 [00:55<05:45,  1.39s/it]Loading train:  13%|█▎        | 37/285 [00:57<05:26,  1.31s/it]Loading train:  13%|█▎        | 38/285 [00:58<05:18,  1.29s/it]Loading train:  14%|█▎        | 39/285 [00:59<05:30,  1.34s/it]Loading train:  14%|█▍        | 40/285 [01:01<05:52,  1.44s/it]Loading train:  14%|█▍        | 41/285 [01:03<05:59,  1.48s/it]Loading train:  15%|█▍        | 42/285 [01:04<05:38,  1.39s/it]Loading train:  15%|█▌        | 43/285 [01:05<05:18,  1.32s/it]Loading train:  15%|█▌        | 44/285 [01:06<05:11,  1.29s/it]Loading train:  16%|█▌        | 45/285 [01:07<05:10,  1.30s/it]Loading train:  16%|█▌        | 46/285 [01:09<05:10,  1.30s/it]Loading train:  16%|█▋        | 47/285 [01:10<04:51,  1.23s/it]Loading train:  17%|█▋        | 48/285 [01:11<04:45,  1.20s/it]Loading train:  17%|█▋        | 49/285 [01:12<05:03,  1.29s/it]Loading train:  18%|█▊        | 50/285 [01:14<05:16,  1.35s/it]Loading train:  18%|█▊        | 51/285 [01:15<05:15,  1.35s/it]Loading train:  18%|█▊        | 52/285 [01:16<04:57,  1.28s/it]Loading train:  19%|█▊        | 53/285 [01:17<04:42,  1.22s/it]Loading train:  19%|█▉        | 54/285 [01:19<05:09,  1.34s/it]Loading train:  19%|█▉        | 55/285 [01:20<05:02,  1.32s/it]Loading train:  20%|█▉        | 56/285 [01:22<05:01,  1.32s/it]Loading train:  20%|██        | 57/285 [01:23<05:03,  1.33s/it]Loading train:  20%|██        | 58/285 [01:24<04:45,  1.26s/it]Loading train:  21%|██        | 59/285 [01:25<04:32,  1.21s/it]Loading train:  21%|██        | 60/285 [01:26<04:28,  1.19s/it]Loading train:  21%|██▏       | 61/285 [01:28<04:32,  1.22s/it]Loading train:  22%|██▏       | 62/285 [01:29<04:24,  1.19s/it]Loading train:  22%|██▏       | 63/285 [01:30<04:10,  1.13s/it]Loading train:  22%|██▏       | 64/285 [01:31<04:41,  1.27s/it]Loading train:  23%|██▎       | 65/285 [01:33<05:10,  1.41s/it]Loading train:  23%|██▎       | 66/285 [01:35<05:24,  1.48s/it]Loading train:  24%|██▎       | 67/285 [01:36<05:00,  1.38s/it]Loading train:  24%|██▍       | 68/285 [01:37<04:41,  1.30s/it]Loading train:  24%|██▍       | 69/285 [01:38<04:33,  1.27s/it]Loading train:  25%|██▍       | 70/285 [01:39<04:23,  1.22s/it]Loading train:  25%|██▍       | 71/285 [01:41<04:32,  1.27s/it]Loading train:  25%|██▌       | 72/285 [01:42<04:19,  1.22s/it]Loading train:  26%|██▌       | 73/285 [01:43<04:22,  1.24s/it]Loading train:  26%|██▌       | 74/285 [01:44<04:16,  1.21s/it]Loading train:  26%|██▋       | 75/285 [01:45<04:13,  1.21s/it]Loading train:  27%|██▋       | 76/285 [01:47<04:14,  1.22s/it]Loading train:  27%|██▋       | 77/285 [01:48<04:23,  1.27s/it]Loading train:  27%|██▋       | 78/285 [01:49<04:14,  1.23s/it]Loading train:  28%|██▊       | 79/285 [01:50<04:04,  1.19s/it]Loading train:  28%|██▊       | 80/285 [01:51<03:58,  1.16s/it]Loading train:  28%|██▊       | 81/285 [01:53<04:08,  1.22s/it]Loading train:  29%|██▉       | 82/285 [01:54<04:05,  1.21s/it]Loading train:  29%|██▉       | 83/285 [01:55<04:01,  1.19s/it]Loading train:  29%|██▉       | 84/285 [01:56<04:00,  1.20s/it]Loading train:  30%|██▉       | 85/285 [01:58<04:11,  1.26s/it]Loading train:  30%|███       | 86/285 [01:59<04:31,  1.37s/it]Loading train:  31%|███       | 87/285 [02:01<04:36,  1.40s/it]Loading train:  31%|███       | 88/285 [02:02<04:29,  1.37s/it]Loading train:  31%|███       | 89/285 [02:03<04:29,  1.37s/it]Loading train:  32%|███▏      | 90/285 [02:05<04:18,  1.32s/it]Loading train:  32%|███▏      | 91/285 [02:06<04:16,  1.32s/it]Loading train:  32%|███▏      | 92/285 [02:07<04:12,  1.31s/it]Loading train:  33%|███▎      | 93/285 [02:09<04:25,  1.38s/it]Loading train:  33%|███▎      | 94/285 [02:10<04:16,  1.34s/it]Loading train:  33%|███▎      | 95/285 [02:11<04:18,  1.36s/it]Loading train:  34%|███▎      | 96/285 [02:13<04:12,  1.34s/it]Loading train:  34%|███▍      | 97/285 [02:14<04:07,  1.32s/it]Loading train:  34%|███▍      | 98/285 [02:15<04:16,  1.37s/it]Loading train:  35%|███▍      | 99/285 [02:17<04:13,  1.36s/it]Loading train:  35%|███▌      | 100/285 [02:18<04:08,  1.34s/it]Loading train:  35%|███▌      | 101/285 [02:19<03:59,  1.30s/it]Loading train:  36%|███▌      | 102/285 [02:21<04:01,  1.32s/it]Loading train:  36%|███▌      | 103/285 [02:22<03:51,  1.27s/it]Loading train:  36%|███▋      | 104/285 [02:23<03:48,  1.26s/it]Loading train:  37%|███▋      | 105/285 [02:24<03:33,  1.19s/it]Loading train:  37%|███▋      | 106/285 [02:25<03:33,  1.19s/it]Loading train:  38%|███▊      | 107/285 [02:26<03:32,  1.19s/it]Loading train:  38%|███▊      | 108/285 [02:28<03:29,  1.18s/it]Loading train:  38%|███▊      | 109/285 [02:29<03:30,  1.20s/it]Loading train:  39%|███▊      | 110/285 [02:30<03:25,  1.17s/it]Loading train:  39%|███▉      | 111/285 [02:31<03:26,  1.19s/it]Loading train:  39%|███▉      | 112/285 [02:32<03:16,  1.14s/it]Loading train:  40%|███▉      | 113/285 [02:33<03:21,  1.17s/it]Loading train:  40%|████      | 114/285 [02:35<03:26,  1.21s/it]Loading train:  40%|████      | 115/285 [02:36<03:26,  1.21s/it]Loading train:  41%|████      | 116/285 [02:37<03:22,  1.20s/it]Loading train:  41%|████      | 117/285 [02:39<03:33,  1.27s/it]Loading train:  41%|████▏     | 118/285 [02:40<03:29,  1.25s/it]Loading train:  42%|████▏     | 119/285 [02:41<03:31,  1.27s/it]Loading train:  42%|████▏     | 120/285 [02:42<03:28,  1.27s/it]Loading train:  42%|████▏     | 121/285 [02:44<03:45,  1.38s/it]Loading train:  43%|████▎     | 122/285 [02:45<03:41,  1.36s/it]Loading train:  43%|████▎     | 123/285 [02:47<04:10,  1.55s/it]Loading train:  44%|████▎     | 124/285 [02:49<04:05,  1.52s/it]Loading train:  44%|████▍     | 125/285 [02:50<03:55,  1.47s/it]Loading train:  44%|████▍     | 126/285 [02:51<03:45,  1.42s/it]Loading train:  45%|████▍     | 127/285 [02:53<03:43,  1.41s/it]Loading train:  45%|████▍     | 128/285 [02:54<03:33,  1.36s/it]Loading train:  45%|████▌     | 129/285 [02:56<03:51,  1.49s/it]Loading train:  46%|████▌     | 130/285 [02:57<03:48,  1.47s/it]Loading train:  46%|████▌     | 131/285 [02:59<03:41,  1.44s/it]Loading train:  46%|████▋     | 132/285 [03:00<03:47,  1.48s/it]Loading train:  47%|████▋     | 133/285 [03:01<03:31,  1.39s/it]Loading train:  47%|████▋     | 134/285 [03:03<03:23,  1.35s/it]Loading train:  47%|████▋     | 135/285 [03:04<03:22,  1.35s/it]Loading train:  48%|████▊     | 136/285 [03:05<03:08,  1.26s/it]Loading train:  48%|████▊     | 137/285 [03:06<02:58,  1.20s/it]Loading train:  48%|████▊     | 138/285 [03:07<02:55,  1.20s/it]Loading train:  49%|████▉     | 139/285 [03:08<02:49,  1.16s/it]Loading train:  49%|████▉     | 140/285 [03:10<02:52,  1.19s/it]Loading train:  49%|████▉     | 141/285 [03:11<02:59,  1.24s/it]Loading train:  50%|████▉     | 142/285 [03:12<02:59,  1.25s/it]Loading train:  50%|█████     | 143/285 [03:13<02:47,  1.18s/it]Loading train:  51%|█████     | 144/285 [03:14<02:38,  1.12s/it]Loading train:  51%|█████     | 145/285 [03:15<02:34,  1.10s/it]Loading train:  51%|█████     | 146/285 [03:17<02:49,  1.22s/it]Loading train:  52%|█████▏    | 147/285 [03:18<02:47,  1.21s/it]Loading train:  52%|█████▏    | 148/285 [03:19<02:54,  1.27s/it]Loading train:  52%|█████▏    | 149/285 [03:20<02:43,  1.21s/it]Loading train:  53%|█████▎    | 150/285 [03:22<02:36,  1.16s/it]Loading train:  53%|█████▎    | 151/285 [03:23<02:35,  1.16s/it]Loading train:  53%|█████▎    | 152/285 [03:24<02:27,  1.11s/it]Loading train:  54%|█████▎    | 153/285 [03:25<02:23,  1.09s/it]Loading train:  54%|█████▍    | 154/285 [03:26<02:22,  1.09s/it]Loading train:  54%|█████▍    | 155/285 [03:27<02:19,  1.07s/it]Loading train:  55%|█████▍    | 156/285 [03:28<02:16,  1.06s/it]Loading train:  55%|█████▌    | 157/285 [03:29<02:21,  1.10s/it]Loading train:  55%|█████▌    | 158/285 [03:30<02:22,  1.12s/it]Loading train:  56%|█████▌    | 159/285 [03:31<02:19,  1.10s/it]Loading train:  56%|█████▌    | 160/285 [03:33<02:38,  1.27s/it]Loading train:  56%|█████▋    | 161/285 [03:34<02:41,  1.30s/it]Loading train:  57%|█████▋    | 162/285 [03:36<02:39,  1.30s/it]Loading train:  57%|█████▋    | 163/285 [03:37<02:41,  1.32s/it]Loading train:  58%|█████▊    | 164/285 [03:38<02:34,  1.28s/it]Loading train:  58%|█████▊    | 165/285 [03:39<02:19,  1.16s/it]Loading train:  58%|█████▊    | 166/285 [03:40<02:19,  1.17s/it]Loading train:  59%|█████▊    | 167/285 [03:41<02:16,  1.16s/it]Loading train:  59%|█████▉    | 168/285 [03:43<02:13,  1.14s/it]Loading train:  59%|█████▉    | 169/285 [03:44<02:11,  1.13s/it]Loading train:  60%|█████▉    | 170/285 [03:45<02:16,  1.19s/it]Loading train:  60%|██████    | 171/285 [03:46<02:14,  1.18s/it]Loading train:  60%|██████    | 172/285 [03:47<02:10,  1.15s/it]Loading train:  61%|██████    | 173/285 [03:49<02:15,  1.21s/it]Loading train:  61%|██████    | 174/285 [03:50<02:14,  1.22s/it]Loading train:  61%|██████▏   | 175/285 [03:51<02:21,  1.29s/it]Loading train:  62%|██████▏   | 176/285 [03:53<02:22,  1.31s/it]Loading train:  62%|██████▏   | 177/285 [03:54<02:16,  1.27s/it]Loading train:  62%|██████▏   | 178/285 [03:55<02:09,  1.21s/it]Loading train:  63%|██████▎   | 179/285 [03:56<02:03,  1.17s/it]Loading train:  63%|██████▎   | 180/285 [03:57<02:06,  1.21s/it]Loading train:  64%|██████▎   | 181/285 [03:58<02:06,  1.22s/it]Loading train:  64%|██████▍   | 182/285 [04:00<02:06,  1.22s/it]Loading train:  64%|██████▍   | 183/285 [04:01<02:10,  1.28s/it]Loading train:  65%|██████▍   | 184/285 [04:02<02:05,  1.24s/it]Loading train:  65%|██████▍   | 185/285 [04:03<01:59,  1.19s/it]Loading train:  65%|██████▌   | 186/285 [04:04<01:50,  1.12s/it]Loading train:  66%|██████▌   | 187/285 [04:05<01:48,  1.11s/it]Loading train:  66%|██████▌   | 188/285 [04:06<01:45,  1.09s/it]Loading train:  66%|██████▋   | 189/285 [04:08<01:45,  1.10s/it]Loading train:  67%|██████▋   | 190/285 [04:09<01:41,  1.06s/it]Loading train:  67%|██████▋   | 191/285 [04:10<01:45,  1.12s/it]Loading train:  67%|██████▋   | 192/285 [04:11<01:41,  1.09s/it]Loading train:  68%|██████▊   | 193/285 [04:12<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [04:13<01:34,  1.04s/it]Loading train:  68%|██████▊   | 195/285 [04:14<01:43,  1.15s/it]Loading train:  69%|██████▉   | 196/285 [04:15<01:45,  1.19s/it]Loading train:  69%|██████▉   | 197/285 [04:17<01:50,  1.25s/it]Loading train:  69%|██████▉   | 198/285 [04:18<01:52,  1.30s/it]Loading train:  70%|██████▉   | 199/285 [04:19<01:47,  1.25s/it]Loading train:  70%|███████   | 200/285 [04:20<01:41,  1.20s/it]Loading train:  71%|███████   | 201/285 [04:22<01:37,  1.16s/it]Loading train:  71%|███████   | 202/285 [04:23<01:36,  1.17s/it]Loading train:  71%|███████   | 203/285 [04:24<01:41,  1.24s/it]Loading train:  72%|███████▏  | 204/285 [04:26<01:46,  1.31s/it]Loading train:  72%|███████▏  | 205/285 [04:27<01:36,  1.21s/it]Loading train:  72%|███████▏  | 206/285 [04:28<01:32,  1.17s/it]Loading train:  73%|███████▎  | 207/285 [04:29<01:40,  1.29s/it]Loading train:  73%|███████▎  | 208/285 [04:30<01:37,  1.26s/it]Loading train:  73%|███████▎  | 209/285 [04:32<01:35,  1.25s/it]Loading train:  74%|███████▎  | 210/285 [04:33<01:45,  1.41s/it]Loading train:  74%|███████▍  | 211/285 [04:35<01:39,  1.34s/it]Loading train:  74%|███████▍  | 212/285 [04:36<01:37,  1.34s/it]Loading train:  75%|███████▍  | 213/285 [04:38<01:40,  1.40s/it]Loading train:  75%|███████▌  | 214/285 [04:39<01:36,  1.36s/it]Loading train:  75%|███████▌  | 215/285 [04:40<01:30,  1.30s/it]Loading train:  76%|███████▌  | 216/285 [04:41<01:28,  1.28s/it]Loading train:  76%|███████▌  | 217/285 [04:42<01:24,  1.25s/it]Loading train:  76%|███████▋  | 218/285 [04:43<01:18,  1.17s/it]Loading train:  77%|███████▋  | 219/285 [04:44<01:14,  1.14s/it]Loading train:  77%|███████▋  | 220/285 [04:45<01:11,  1.10s/it]Loading train:  78%|███████▊  | 221/285 [04:47<01:13,  1.14s/it]Loading train:  78%|███████▊  | 222/285 [04:48<01:11,  1.13s/it]Loading train:  78%|███████▊  | 223/285 [04:49<01:09,  1.12s/it]Loading train:  79%|███████▊  | 224/285 [04:50<01:06,  1.08s/it]Loading train:  79%|███████▉  | 225/285 [04:51<01:01,  1.03s/it]Loading train:  79%|███████▉  | 226/285 [04:52<01:04,  1.09s/it]Loading train:  80%|███████▉  | 227/285 [04:53<01:03,  1.09s/it]Loading train:  80%|████████  | 228/285 [04:55<01:11,  1.25s/it]Loading train:  80%|████████  | 229/285 [04:56<01:07,  1.20s/it]Loading train:  81%|████████  | 230/285 [04:57<01:06,  1.22s/it]Loading train:  81%|████████  | 231/285 [04:58<01:03,  1.18s/it]Loading train:  81%|████████▏ | 232/285 [05:00<01:08,  1.30s/it]Loading train:  82%|████████▏ | 233/285 [05:01<01:10,  1.36s/it]Loading train:  82%|████████▏ | 234/285 [05:03<01:16,  1.50s/it]Loading train:  82%|████████▏ | 235/285 [05:05<01:16,  1.53s/it]Loading train:  83%|████████▎ | 236/285 [05:06<01:13,  1.49s/it]Loading train:  83%|████████▎ | 237/285 [05:08<01:11,  1.49s/it]Loading train:  84%|████████▎ | 238/285 [05:09<01:11,  1.53s/it]Loading train:  84%|████████▍ | 239/285 [05:11<01:10,  1.53s/it]Loading train:  84%|████████▍ | 240/285 [05:12<01:05,  1.46s/it]Loading train:  85%|████████▍ | 241/285 [05:13<01:03,  1.44s/it]Loading train:  85%|████████▍ | 242/285 [05:15<01:05,  1.52s/it]Loading train:  85%|████████▌ | 243/285 [05:17<01:04,  1.53s/it]Loading train:  86%|████████▌ | 244/285 [05:18<01:06,  1.63s/it]Loading train:  86%|████████▌ | 245/285 [05:20<01:03,  1.60s/it]Loading train:  86%|████████▋ | 246/285 [05:21<01:00,  1.55s/it]Loading train:  87%|████████▋ | 247/285 [05:23<00:56,  1.50s/it]Loading train:  87%|████████▋ | 248/285 [05:24<00:55,  1.49s/it]Loading train:  87%|████████▋ | 249/285 [05:26<00:56,  1.58s/it]Loading train:  88%|████████▊ | 250/285 [05:27<00:49,  1.42s/it]Loading train:  88%|████████▊ | 251/285 [05:28<00:43,  1.28s/it]Loading train:  88%|████████▊ | 252/285 [05:29<00:37,  1.15s/it]Loading train:  89%|████████▉ | 253/285 [05:30<00:32,  1.02s/it]Loading train:  89%|████████▉ | 254/285 [05:31<00:33,  1.09s/it]Loading train:  89%|████████▉ | 255/285 [05:32<00:34,  1.14s/it]Loading train:  90%|████████▉ | 256/285 [05:33<00:33,  1.15s/it]Loading train:  90%|█████████ | 257/285 [05:34<00:32,  1.16s/it]Loading train:  91%|█████████ | 258/285 [05:36<00:30,  1.12s/it]Loading train:  91%|█████████ | 259/285 [05:37<00:28,  1.11s/it]Loading train:  91%|█████████ | 260/285 [05:37<00:25,  1.04s/it]Loading train:  92%|█████████▏| 261/285 [05:38<00:23,  1.02it/s]Loading train:  92%|█████████▏| 262/285 [05:39<00:21,  1.06it/s]Loading train:  92%|█████████▏| 263/285 [05:40<00:20,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [05:41<00:18,  1.13it/s]Loading train:  93%|█████████▎| 265/285 [05:42<00:17,  1.14it/s]Loading train:  93%|█████████▎| 266/285 [05:43<00:16,  1.13it/s]Loading train:  94%|█████████▎| 267/285 [05:43<00:15,  1.17it/s]Loading train:  94%|█████████▍| 268/285 [05:44<00:15,  1.12it/s]Loading train:  94%|█████████▍| 269/285 [05:45<00:14,  1.08it/s]Loading train:  95%|█████████▍| 270/285 [05:47<00:14,  1.01it/s]Loading train:  95%|█████████▌| 271/285 [05:48<00:13,  1.01it/s]Loading train:  95%|█████████▌| 272/285 [05:49<00:13,  1.01s/it]Loading train:  96%|█████████▌| 273/285 [05:50<00:11,  1.00it/s]Loading train:  96%|█████████▌| 274/285 [05:51<00:10,  1.01it/s]Loading train:  96%|█████████▋| 275/285 [05:52<00:10,  1.00s/it]Loading train:  97%|█████████▋| 276/285 [05:53<00:08,  1.01it/s]Loading train:  97%|█████████▋| 277/285 [05:53<00:07,  1.02it/s]Loading train:  98%|█████████▊| 278/285 [05:54<00:06,  1.03it/s]Loading train:  98%|█████████▊| 279/285 [05:55<00:05,  1.01it/s]Loading train:  98%|█████████▊| 280/285 [05:56<00:04,  1.03it/s]Loading train:  99%|█████████▊| 281/285 [05:57<00:03,  1.03it/s]Loading train:  99%|█████████▉| 282/285 [05:58<00:02,  1.01it/s]Loading train:  99%|█████████▉| 283/285 [05:59<00:01,  1.02it/s]Loading train: 100%|█████████▉| 284/285 [06:00<00:00,  1.03it/s]Loading train: 100%|██████████| 285/285 [06:01<00:00,  1.04it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 64.53it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:03, 83.44it/s]concatenating: train:  23%|██▎       | 66/285 [00:00<00:02, 107.20it/s]concatenating: train:  34%|███▍      | 97/285 [00:00<00:01, 133.36it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:00, 163.32it/s]concatenating: train:  59%|█████▊    | 167/285 [00:00<00:00, 194.09it/s]concatenating: train:  72%|███████▏  | 204/285 [00:00<00:00, 225.56it/s]concatenating: train:  83%|████████▎ | 237/285 [00:00<00:00, 249.09it/s]concatenating: train:  94%|█████████▍| 269/285 [00:00<00:00, 265.50it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 296.08it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.26s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 829.84it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-08 10:51:39.415385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 10:51:39.415507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 10:51:39.415523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 10:51:39.415533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 10:51:39.415949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 18s - loss: 15764.8616 - acc: 0.5139 - mDice: 0.0801 - val_loss: 7827.5776 - val_acc: 0.8997 - val_mDice: 0.2116

Epoch 00001: val_mDice improved from -inf to 0.21157, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 9s - loss: 5730.3860 - acc: 0.8714 - mDice: 0.3258 - val_loss: 6668.2409 - val_acc: 0.9054 - val_mDice: 0.2923

Epoch 00002: val_mDice improved from 0.21157 to 0.29235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 8s - loss: 3810.3708 - acc: 0.8785 - mDice: 0.4620 - val_loss: 4827.1834 - val_acc: 0.9066 - val_mDice: 0.3540

Epoch 00003: val_mDice improved from 0.29235 to 0.35396, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 8s - loss: 3173.7359 - acc: 0.8817 - mDice: 0.5250 - val_loss: 3569.5431 - val_acc: 0.9072 - val_mDice: 0.4625

Epoch 00004: val_mDice improved from 0.35396 to 0.46249, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 8s - loss: 2777.9703 - acc: 0.8856 - mDice: 0.5687 - val_loss: 3327.1202 - val_acc: 0.9145 - val_mDice: 0.4894

Epoch 00005: val_mDice improved from 0.46249 to 0.48943, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 8s - loss: 2540.2764 - acc: 0.8892 - mDice: 0.5968 - val_loss: 3127.4027 - val_acc: 0.9188 - val_mDice: 0.5046

Epoch 00006: val_mDice improved from 0.48943 to 0.50460, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 8s - loss: 2361.3946 - acc: 0.8931 - mDice: 0.6192 - val_loss: 2998.3302 - val_acc: 0.9183 - val_mDice: 0.5189

Epoch 00007: val_mDice improved from 0.50460 to 0.51890, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 9s - loss: 2228.6953 - acc: 0.8972 - mDice: 0.6362 - val_loss: 2922.4947 - val_acc: 0.9293 - val_mDice: 0.5289

Epoch 00008: val_mDice improved from 0.51890 to 0.52894, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 8s - loss: 2129.6487 - acc: 0.9028 - mDice: 0.6491 - val_loss: 2967.5767 - val_acc: 0.9251 - val_mDice: 0.5221

Epoch 00009: val_mDice did not improve from 0.52894
Epoch 10/300
 - 8s - loss: 2031.2401 - acc: 0.9102 - mDice: 0.6619 - val_loss: 3006.1184 - val_acc: 0.9309 - val_mDice: 0.5171

Epoch 00010: val_mDice did not improve from 0.52894
Epoch 11/300
 - 8s - loss: 1947.5673 - acc: 0.9184 - mDice: 0.6730 - val_loss: 2906.6500 - val_acc: 0.9403 - val_mDice: 0.5303

Epoch 00011: val_mDice improved from 0.52894 to 0.53034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 8s - loss: 1886.0782 - acc: 0.9256 - mDice: 0.6811 - val_loss: 2966.9847 - val_acc: 0.9408 - val_mDice: 0.5224

Epoch 00012: val_mDice did not improve from 0.53034
Epoch 13/300
 - 8s - loss: 1811.5683 - acc: 0.9331 - mDice: 0.6911 - val_loss: 2879.6375 - val_acc: 0.9448 - val_mDice: 0.5317

Epoch 00013: val_mDice improved from 0.53034 to 0.53172, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 9s - loss: 1759.1862 - acc: 0.9372 - mDice: 0.6982 - val_loss: 2761.3931 - val_acc: 0.9449 - val_mDice: 0.5438

Epoch 00014: val_mDice improved from 0.53172 to 0.54375, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 8s - loss: 1739.4753 - acc: 0.9389 - mDice: 0.7009 - val_loss: 2959.0661 - val_acc: 0.9444 - val_mDice: 0.5243

Epoch 00015: val_mDice did not improve from 0.54375
Epoch 16/300
 - 8s - loss: 1671.1015 - acc: 0.9406 - mDice: 0.7105 - val_loss: 2954.1501 - val_acc: 0.9435 - val_mDice: 0.5234

Epoch 00016: val_mDice did not improve from 0.54375
Epoch 17/300
 - 8s - loss: 1638.0136 - acc: 0.9416 - mDice: 0.7154 - val_loss: 2900.5773 - val_acc: 0.9458 - val_mDice: 0.5280

Epoch 00017: val_mDice did not improve from 0.54375
Epoch 18/300
 - 8s - loss: 1610.1719 - acc: 0.9419 - mDice: 0.7195 - val_loss: 2692.9322 - val_acc: 0.9433 - val_mDice: 0.5510

Epoch 00018: val_mDice improved from 0.54375 to 0.55105, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 8s - loss: 1569.5385 - acc: 0.9427 - mDice: 0.7253 - val_loss: 2846.3077 - val_acc: 0.9442 - val_mDice: 0.5333

Epoch 00019: val_mDice did not improve from 0.55105
Epoch 20/300
 - 8s - loss: 1556.1745 - acc: 0.9431 - mDice: 0.7274 - val_loss: 3087.0111 - val_acc: 0.9436 - val_mDice: 0.5095

Epoch 00020: val_mDice did not improve from 0.55105
Epoch 21/300
 - 8s - loss: 1522.4395 - acc: 0.9438 - mDice: 0.7324 - val_loss: 2842.5771 - val_acc: 0.9400 - val_mDice: 0.5349

Epoch 00021: val_mDice did not improve from 0.55105
Epoch 22/300
 - 8s - loss: 1501.6764 - acc: 0.9441 - mDice: 0.7354 - val_loss: 2812.1334 - val_acc: 0.9429 - val_mDice: 0.5376

Epoch 00022: val_mDice did not improve from 0.55105
Epoch 23/300
 - 9s - loss: 1483.0252 - acc: 0.9445 - mDice: 0.7382 - val_loss: 2817.6555 - val_acc: 0.9465 - val_mDice: 0.5364

Epoch 00023: val_mDice did not improve from 0.55105
Epoch 24/300
 - 8s - loss: 1452.9798 - acc: 0.9450 - mDice: 0.7427 - val_loss: 2927.1400 - val_acc: 0.9421 - val_mDice: 0.5263

Epoch 00024: val_mDice did not improve from 0.55105
Epoch 25/300
 - 8s - loss: 1432.8834 - acc: 0.9453 - mDice: 0.7458 - val_loss: 2859.3798 - val_acc: 0.9461 - val_mDice: 0.5315

Epoch 00025: val_mDice did not improve from 0.55105
Epoch 26/300
 - 8s - loss: 1423.2197 - acc: 0.9457 - mDice: 0.7473 - val_loss: 2776.8726 - val_acc: 0.9369 - val_mDice: 0.5436

Epoch 00026: val_mDice did not improve from 0.55105
Epoch 27/300
 - 8s - loss: 1408.6519 - acc: 0.9458 - mDice: 0.7495 - val_loss: 2906.3746 - val_acc: 0.9411 - val_mDice: 0.5309

Epoch 00027: val_mDice did not improve from 0.55105
Epoch 28/300
 - 8s - loss: 1382.5908 - acc: 0.9462 - mDice: 0.7535 - val_loss: 2833.3370 - val_acc: 0.9437 - val_mDice: 0.5385

Epoch 00028: val_mDice did not improve from 0.55105
Epoch 29/300
 - 8s - loss: 1371.2399 - acc: 0.9466 - mDice: 0.7553 - val_loss: 3025.2342 - val_acc: 0.9410 - val_mDice: 0.5185

Epoch 00029: val_mDice did not improve from 0.55105
Epoch 30/300
 - 8s - loss: 1361.3507 - acc: 0.9468 - mDice: 0.7568 - val_loss: 3096.5430 - val_acc: 0.9389 - val_mDice: 0.5110

Epoch 00030: val_mDice did not improve from 0.55105
Epoch 31/300
 - 8s - loss: 1348.3770 - acc: 0.9471 - mDice: 0.7588 - val_loss: 3014.2186 - val_acc: 0.9416 - val_mDice: 0.5191

Epoch 00031: val_mDice did not improve from 0.55105
Epoch 32/300
 - 8s - loss: 1338.2066 - acc: 0.9471 - mDice: 0.7603 - val_loss: 2801.0396 - val_acc: 0.9417 - val_mDice: 0.5388

Epoch 00032: val_mDice did not improve from 0.55105
Epoch 33/300
 - 8s - loss: 1322.8744 - acc: 0.9474 - mDice: 0.7627 - val_loss: 3114.5070 - val_acc: 0.9422 - val_mDice: 0.5082

Epoch 00033: val_mDice did not improve from 0.55105
Epoch 34/300
 - 9s - loss: 1314.3775 - acc: 0.9476 - mDice: 0.7641 - val_loss: 3011.2110 - val_acc: 0.9443 - val_mDice: 0.5217

Epoch 00034: val_mDice did not improve from 0.55105
Epoch 35/300
 - 8s - loss: 1299.2010 - acc: 0.9480 - mDice: 0.7664 - val_loss: 2725.0782 - val_acc: 0.9427 - val_mDice: 0.5487

Epoch 00035: val_mDice did not improve from 0.55105
Epoch 36/300
 - 8s - loss: 1283.3865 - acc: 0.9482 - mDice: 0.7689 - val_loss: 2846.8841 - val_acc: 0.9448 - val_mDice: 0.5376

Epoch 00036: val_mDice did not improve from 0.55105
Epoch 37/300
 - 8s - loss: 1278.3883 - acc: 0.9484 - mDice: 0.7697 - val_loss: 2885.1182 - val_acc: 0.9436 - val_mDice: 0.5323

Epoch 00037: val_mDice did not improve from 0.55105
Epoch 38/300
 - 8s - loss: 1272.7574 - acc: 0.9484 - mDice: 0.7705 - val_loss: 2933.8426 - val_acc: 0.9447 - val_mDice: 0.5269

Epoch 00038: val_mDice did not improve from 0.55105
Epoch 39/300
 - 8s - loss: 1265.7035 - acc: 0.9486 - mDice: 0.7717 - val_loss: 3233.7227 - val_acc: 0.9429 - val_mDice: 0.4964

Epoch 00039: val_mDice did not improve from 0.55105
Epoch 40/300
 - 8s - loss: 1250.7420 - acc: 0.9487 - mDice: 0.7741 - val_loss: 2859.6282 - val_acc: 0.9460 - val_mDice: 0.5342

Epoch 00040: val_mDice did not improve from 0.55105
Epoch 41/300
 - 8s - loss: 1242.5911 - acc: 0.9489 - mDice: 0.7753 - val_loss: 2920.9761 - val_acc: 0.9455 - val_mDice: 0.5264

Epoch 00041: val_mDice did not improve from 0.55105
Epoch 42/300
 - 8s - loss: 1234.8626 - acc: 0.9491 - mDice: 0.7766 - val_loss: 2833.5796 - val_acc: 0.9467 - val_mDice: 0.5387

Epoch 00042: val_mDice did not improve from 0.55105
Epoch 43/300
 - 8s - loss: 1230.1655 - acc: 0.9492 - mDice: 0.7773 - val_loss: 2953.1596 - val_acc: 0.9464 - val_mDice: 0.5238

Epoch 00043: val_mDice did not improve from 0.55105
Epoch 44/300
 - 8s - loss: 1225.2788 - acc: 0.9493 - mDice: 0.7781 - val_loss: 2952.9614 - val_acc: 0.9447 - val_mDice: 0.5232

Epoch 00044: val_mDice did not improve from 0.55105
Epoch 45/300
 - 9s - loss: 1211.2226 - acc: 0.9495 - mDice: 0.7803 - val_loss: 2905.7381 - val_acc: 0.9455 - val_mDice: 0.5293

Epoch 00045: val_mDice did not improve from 0.55105
Epoch 46/300
 - 8s - loss: 1212.0301 - acc: 0.9494 - mDice: 0.7802 - val_loss: 2894.6662 - val_acc: 0.9440 - val_mDice: 0.5305

Epoch 00046: val_mDice did not improve from 0.55105
Epoch 47/300
 - 8s - loss: 1202.3258 - acc: 0.9498 - mDice: 0.7818 - val_loss: 3541.6187 - val_acc: 0.9386 - val_mDice: 0.4624

Epoch 00047: val_mDice did not improve from 0.55105
Epoch 48/300
 - 8s - loss: 1192.0167 - acc: 0.9500 - mDice: 0.7833 - val_loss: 2944.7572 - val_acc: 0.9458 - val_mDice: 0.5265

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.26s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.84s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:28,  1.37s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:45,  1.43s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:50,  1.46s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:24,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:05,  1.52s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:32,  1.62s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:59,  1.73s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:13,  1.78s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:01,  1.74s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:28,  1.85s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:46,  1.92s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:46,  1.93s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:49,  1.95s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:52,  1.97s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<09:03,  2.01s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<09:04,  2.02s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:57,  2.01s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:57,  2.01s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:50,  2.00s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:59,  2.03s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:53,  2.02s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:51,  2.02s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:53,  2.04s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:51,  2.04s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:50,  2.04s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:44,  2.03s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:43,  2.03s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:41,  2.03s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:58,  2.10s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:40,  2.04s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:27,  2.00s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:15,  1.96s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<08:12,  1.95s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<08:04,  1.93s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<07:58,  1.91s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<07:58,  1.92s/it]predicting train subjects:  13%|█▎        | 37/285 [01:11<07:48,  1.89s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<07:47,  1.89s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<07:46,  1.89s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:38,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:44,  1.90s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:44,  1.91s/it]predicting train subjects:  15%|█▌        | 43/285 [01:22<07:39,  1.90s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:39,  1.91s/it]predicting train subjects:  16%|█▌        | 45/285 [01:26<07:38,  1.91s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:13,  1.82s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<06:58,  1.76s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<06:44,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<06:37,  1.68s/it]predicting train subjects:  18%|█▊        | 50/285 [01:34<06:30,  1.66s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<06:29,  1.66s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<06:27,  1.66s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<06:26,  1.67s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<06:25,  1.67s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<06:24,  1.67s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<06:18,  1.65s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:13,  1.64s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:09,  1.63s/it]predicting train subjects:  21%|██        | 59/285 [01:49<06:08,  1.63s/it]predicting train subjects:  21%|██        | 60/285 [01:50<06:03,  1.62s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<06:01,  1.61s/it]predicting train subjects:  22%|██▏       | 62/285 [01:53<06:00,  1.62s/it]predicting train subjects:  22%|██▏       | 63/285 [01:55<06:03,  1.64s/it]predicting train subjects:  22%|██▏       | 64/285 [01:57<06:04,  1.65s/it]predicting train subjects:  23%|██▎       | 65/285 [01:59<06:20,  1.73s/it]predicting train subjects:  23%|██▎       | 66/285 [02:01<06:26,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [02:02<06:21,  1.75s/it]predicting train subjects:  24%|██▍       | 68/285 [02:04<06:14,  1.73s/it]predicting train subjects:  24%|██▍       | 69/285 [02:06<06:23,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:08<06:16,  1.75s/it]predicting train subjects:  25%|██▍       | 71/285 [02:09<06:15,  1.76s/it]predicting train subjects:  25%|██▌       | 72/285 [02:11<06:14,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:13<06:09,  1.74s/it]predicting train subjects:  26%|██▌       | 74/285 [02:14<06:01,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:16<05:58,  1.71s/it]predicting train subjects:  27%|██▋       | 76/285 [02:18<05:56,  1.70s/it]predicting train subjects:  27%|██▋       | 77/285 [02:20<05:54,  1.71s/it]predicting train subjects:  27%|██▋       | 78/285 [02:21<05:53,  1.71s/it]predicting train subjects:  28%|██▊       | 79/285 [02:23<05:52,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:25<05:51,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:26<05:47,  1.70s/it]predicting train subjects:  29%|██▉       | 82/285 [02:28<05:41,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:30<05:43,  1.70s/it]predicting train subjects:  29%|██▉       | 84/285 [02:32<05:44,  1.71s/it]predicting train subjects:  30%|██▉       | 85/285 [02:33<05:57,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:35<05:59,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:37<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:39<06:04,  1.85s/it]predicting train subjects:  31%|███       | 89/285 [02:41<06:10,  1.89s/it]predicting train subjects:  32%|███▏      | 90/285 [02:43<06:08,  1.89s/it]predicting train subjects:  32%|███▏      | 91/285 [02:45<06:03,  1.87s/it]predicting train subjects:  32%|███▏      | 92/285 [02:47<06:01,  1.87s/it]predicting train subjects:  33%|███▎      | 93/285 [02:49<06:04,  1.90s/it]predicting train subjects:  33%|███▎      | 94/285 [02:51<06:03,  1.90s/it]predicting train subjects:  33%|███▎      | 95/285 [02:52<06:01,  1.90s/it]predicting train subjects:  34%|███▎      | 96/285 [02:54<06:01,  1.91s/it]predicting train subjects:  34%|███▍      | 97/285 [02:56<06:01,  1.92s/it]predicting train subjects:  34%|███▍      | 98/285 [02:58<06:07,  1.96s/it]predicting train subjects:  35%|███▍      | 99/285 [03:00<06:02,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [03:02<05:59,  1.95s/it]predicting train subjects:  35%|███▌      | 101/285 [03:04<05:59,  1.96s/it]predicting train subjects:  36%|███▌      | 102/285 [03:06<05:58,  1.96s/it]predicting train subjects:  36%|███▌      | 103/285 [03:08<05:47,  1.91s/it]predicting train subjects:  36%|███▋      | 104/285 [03:10<05:39,  1.88s/it]predicting train subjects:  37%|███▋      | 105/285 [03:12<05:34,  1.86s/it]predicting train subjects:  37%|███▋      | 106/285 [03:13<05:31,  1.85s/it]predicting train subjects:  38%|███▊      | 107/285 [03:15<05:30,  1.86s/it]predicting train subjects:  38%|███▊      | 108/285 [03:17<05:32,  1.88s/it]predicting train subjects:  38%|███▊      | 109/285 [03:19<05:31,  1.88s/it]predicting train subjects:  39%|███▊      | 110/285 [03:21<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:23<05:19,  1.84s/it]predicting train subjects:  39%|███▉      | 112/285 [03:25<05:16,  1.83s/it]predicting train subjects:  40%|███▉      | 113/285 [03:26<05:14,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:28<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:30<05:12,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:32<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:34<05:09,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:36<05:09,  1.85s/it]predicting train subjects:  42%|████▏     | 119/285 [03:37<05:08,  1.86s/it]predicting train subjects:  42%|████▏     | 120/285 [03:39<05:09,  1.87s/it]predicting train subjects:  42%|████▏     | 121/285 [03:41<04:56,  1.81s/it]predicting train subjects:  43%|████▎     | 122/285 [03:43<04:39,  1.71s/it]predicting train subjects:  43%|████▎     | 123/285 [03:44<04:24,  1.63s/it]predicting train subjects:  44%|████▎     | 124/285 [03:46<04:24,  1.64s/it]predicting train subjects:  44%|████▍     | 125/285 [03:47<04:25,  1.66s/it]predicting train subjects:  44%|████▍     | 126/285 [03:49<04:30,  1.70s/it]predicting train subjects:  45%|████▍     | 127/285 [03:51<04:27,  1.70s/it]predicting train subjects:  45%|████▍     | 128/285 [03:53<04:27,  1.70s/it]predicting train subjects:  45%|████▌     | 129/285 [03:54<04:25,  1.70s/it]predicting train subjects:  46%|████▌     | 130/285 [03:56<04:21,  1.69s/it]predicting train subjects:  46%|████▌     | 131/285 [03:58<04:17,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [03:59<04:14,  1.67s/it]predicting train subjects:  47%|████▋     | 133/285 [04:01<04:15,  1.68s/it]predicting train subjects:  47%|████▋     | 134/285 [04:03<04:12,  1.68s/it]predicting train subjects:  47%|████▋     | 135/285 [04:04<04:11,  1.68s/it]predicting train subjects:  48%|████▊     | 136/285 [04:06<04:12,  1.70s/it]predicting train subjects:  48%|████▊     | 137/285 [04:08<04:11,  1.70s/it]predicting train subjects:  48%|████▊     | 138/285 [04:09<04:08,  1.69s/it]predicting train subjects:  49%|████▉     | 139/285 [04:11<04:07,  1.69s/it]predicting train subjects:  49%|████▉     | 140/285 [04:13<04:04,  1.69s/it]predicting train subjects:  49%|████▉     | 141/285 [04:14<04:00,  1.67s/it]predicting train subjects:  50%|████▉     | 142/285 [04:16<03:54,  1.64s/it]predicting train subjects:  50%|█████     | 143/285 [04:17<03:48,  1.61s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<03:49,  1.63s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<03:41,  1.58s/it]predicting train subjects:  51%|█████     | 146/285 [04:22<03:34,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:25<03:30,  1.54s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:28<03:24,  1.52s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:30<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:31<03:20,  1.51s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:33<03:17,  1.49s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:34<03:15,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:36<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:37<03:10,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:39<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:40<03:09,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:41<03:06,  1.48s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:43<03:06,  1.49s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:44<03:01,  1.46s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:46<03:00,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:47<02:59,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:49<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:50<02:57,  1.48s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:52<02:56,  1.48s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:53<02:53,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:55<02:51,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:56<02:51,  1.48s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:58<02:48,  1.46s/it]predicting train subjects:  60%|██████    | 171/285 [04:59<02:50,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [05:01<02:47,  1.48s/it]predicting train subjects:  61%|██████    | 173/285 [05:02<02:44,  1.47s/it]predicting train subjects:  61%|██████    | 174/285 [05:03<02:40,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:05<02:39,  1.45s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:06<02:38,  1.45s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:08<02:36,  1.45s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:09<02:33,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:11<02:32,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:12<02:29,  1.43s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:13<02:27,  1.42s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:15<02:24,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:16<02:22,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:18<02:19,  1.38s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:19<02:16,  1.37s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:20<02:17,  1.39s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:22<02:17,  1.40s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:23<02:15,  1.40s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:25<02:13,  1.39s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:26<02:13,  1.40s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:27<02:12,  1.41s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:29<02:12,  1.42s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:30<02:10,  1.41s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:32<02:06,  1.39s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:33<02:06,  1.40s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:35<02:10,  1.47s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:36<02:14,  1.53s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:38<02:17,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:40<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:41<02:18,  1.63s/it]predicting train subjects:  71%|███████   | 201/285 [05:43<02:16,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:45<02:16,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:46<02:16,  1.67s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:48<02:14,  1.66s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:50<02:13,  1.67s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:51<02:12,  1.68s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:53<02:12,  1.70s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:55<02:10,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:57<02:09,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:58<02:08,  1.71s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:00<02:05,  1.69s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:02<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:03<02:00,  1.68s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:05<01:56,  1.64s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:06<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:08<01:48,  1.57s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:09<01:46,  1.56s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:11<01:43,  1.54s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:12<01:41,  1.53s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:14<01:39,  1.53s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:15<01:38,  1.53s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:17<01:37,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:19<01:35,  1.54s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:20<01:33,  1.53s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:21<01:29,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:23<01:29,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:25<01:27,  1.51s/it]predicting train subjects:  80%|████████  | 228/285 [06:26<01:26,  1.51s/it]predicting train subjects:  80%|████████  | 229/285 [06:28<01:24,  1.51s/it]predicting train subjects:  81%|████████  | 230/285 [06:29<01:22,  1.51s/it]predicting train subjects:  81%|████████  | 231/285 [06:31<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:32<01:25,  1.62s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:34<01:29,  1.72s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:36<01:30,  1.78s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:38<01:31,  1.82s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:40<01:30,  1.86s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:42<01:29,  1.87s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:44<01:28,  1.88s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:46<01:27,  1.89s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:48<01:25,  1.90s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:50<01:23,  1.90s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:52<01:22,  1.93s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:54<01:20,  1.91s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:55<01:18,  1.91s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:57<01:17,  1.94s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:59<01:14,  1.92s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:01<01:12,  1.90s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:03<01:10,  1.90s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:05<01:08,  1.89s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:06<01:01,  1.75s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:08<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:09<00:52,  1.58s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:11<00:48,  1.53s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:12<00:47,  1.53s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:14<00:45,  1.51s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:15<00:43,  1.51s/it]predicting train subjects:  90%|█████████ | 257/285 [07:17<00:41,  1.49s/it]predicting train subjects:  91%|█████████ | 258/285 [07:18<00:39,  1.48s/it]predicting train subjects:  91%|█████████ | 259/285 [07:19<00:37,  1.45s/it]predicting train subjects:  91%|█████████ | 260/285 [07:21<00:36,  1.45s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:22<00:34,  1.45s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:24<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:25<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:27<00:29,  1.42s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:28<00:28,  1.42s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:29<00:27,  1.43s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:31<00:25,  1.43s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:33<00:27,  1.59s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:35<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:37<00:26,  1.75s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:39<00:25,  1.83s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:41<00:24,  1.88s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:43<00:22,  1.90s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:45<00:21,  1.96s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:47<00:19,  1.98s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:49<00:17,  1.99s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:51<00:15,  1.94s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:52<00:13,  1.92s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:54<00:11,  1.94s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:56<00:09,  1.97s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:58<00:07,  1.95s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:00<00:05,  1.93s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:02<00:03,  1.92s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:04<00:01,  1.93s/it]predicting train subjects: 100%|██████████| 285/285 [08:06<00:00,  1.95s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:37,  1.40s/it]Loading train:   1%|          | 2/285 [00:02<06:41,  1.42s/it]Loading train:   1%|          | 3/285 [00:04<06:28,  1.38s/it]Loading train:   1%|▏         | 4/285 [00:05<06:47,  1.45s/it]Loading train:   2%|▏         | 5/285 [00:07<06:48,  1.46s/it]Loading train:   2%|▏         | 6/285 [00:08<07:04,  1.52s/it]Loading train:   2%|▏         | 7/285 [00:10<07:38,  1.65s/it]Loading train:   3%|▎         | 8/285 [00:12<07:35,  1.65s/it]Loading train:   3%|▎         | 9/285 [00:13<07:10,  1.56s/it]Loading train:   4%|▎         | 10/285 [00:15<06:43,  1.47s/it]Loading train:   4%|▍         | 11/285 [00:16<06:33,  1.44s/it]Loading train:   4%|▍         | 12/285 [00:17<06:14,  1.37s/it]Loading train:   5%|▍         | 13/285 [00:18<05:57,  1.31s/it]Loading train:   5%|▍         | 14/285 [00:20<05:57,  1.32s/it]Loading train:   5%|▌         | 15/285 [00:21<05:54,  1.31s/it]Loading train:   6%|▌         | 16/285 [00:22<05:51,  1.31s/it]Loading train:   6%|▌         | 17/285 [00:24<05:47,  1.30s/it]Loading train:   6%|▋         | 18/285 [00:25<05:40,  1.27s/it]Loading train:   7%|▋         | 19/285 [00:26<05:37,  1.27s/it]Loading train:   7%|▋         | 20/285 [00:27<05:42,  1.29s/it]Loading train:   7%|▋         | 21/285 [00:29<05:38,  1.28s/it]Loading train:   8%|▊         | 22/285 [00:30<05:43,  1.30s/it]Loading train:   8%|▊         | 23/285 [00:31<05:37,  1.29s/it]Loading train:   8%|▊         | 24/285 [00:32<05:31,  1.27s/it]Loading train:   9%|▉         | 25/285 [00:34<05:33,  1.28s/it]Loading train:   9%|▉         | 26/285 [00:35<05:19,  1.23s/it]Loading train:   9%|▉         | 27/285 [00:36<05:22,  1.25s/it]Loading train:  10%|▉         | 28/285 [00:37<05:09,  1.20s/it]Loading train:  10%|█         | 29/285 [00:38<04:52,  1.14s/it]Loading train:  11%|█         | 30/285 [00:39<04:44,  1.12s/it]Loading train:  11%|█         | 31/285 [00:40<04:38,  1.10s/it]Loading train:  11%|█         | 32/285 [00:41<04:35,  1.09s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:29,  1.07s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:26,  1.06s/it]Loading train:  12%|█▏        | 35/285 [00:45<04:22,  1.05s/it]Loading train:  13%|█▎        | 36/285 [00:46<04:31,  1.09s/it]Loading train:  13%|█▎        | 37/285 [00:47<04:23,  1.06s/it]Loading train:  13%|█▎        | 38/285 [00:48<04:20,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:49<04:23,  1.07s/it]Loading train:  14%|█▍        | 40/285 [00:50<04:20,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:18,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:23,  1.08s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:20,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:20,  1.08s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:15,  1.07s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:11,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:06,  1.04s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:01,  1.02s/it]Loading train:  17%|█▋        | 49/285 [00:59<03:52,  1.01it/s]Loading train:  18%|█▊        | 50/285 [01:00<03:49,  1.02it/s]Loading train:  18%|█▊        | 51/285 [01:01<03:43,  1.05it/s]Loading train:  18%|█▊        | 52/285 [01:02<03:33,  1.09it/s]Loading train:  19%|█▊        | 53/285 [01:03<03:41,  1.05it/s]Loading train:  19%|█▉        | 54/285 [01:04<03:41,  1.04it/s]Loading train:  19%|█▉        | 55/285 [01:05<03:41,  1.04it/s]Loading train:  20%|█▉        | 56/285 [01:06<03:38,  1.05it/s]Loading train:  20%|██        | 57/285 [01:07<03:37,  1.05it/s]Loading train:  20%|██        | 58/285 [01:08<03:37,  1.05it/s]Loading train:  21%|██        | 59/285 [01:09<03:41,  1.02it/s]Loading train:  21%|██        | 60/285 [01:10<03:36,  1.04it/s]Loading train:  21%|██▏       | 61/285 [01:11<03:48,  1.02s/it]Loading train:  22%|██▏       | 62/285 [01:12<03:50,  1.04s/it]Loading train:  22%|██▏       | 63/285 [01:13<03:52,  1.05s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:26,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:16<04:49,  1.32s/it]Loading train:  23%|██▎       | 66/285 [01:18<04:51,  1.33s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:41,  1.29s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:21,  1.20s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:12,  1.17s/it]Loading train:  25%|██▍       | 70/285 [01:22<03:59,  1.11s/it]Loading train:  25%|██▍       | 71/285 [01:23<03:54,  1.09s/it]Loading train:  25%|██▌       | 72/285 [01:24<03:53,  1.10s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:45,  1.07s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:33,  1.01s/it]Loading train:  26%|██▋       | 75/285 [01:27<03:37,  1.04s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:42,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:40,  1.06s/it]Loading train:  27%|██▋       | 78/285 [01:30<03:45,  1.09s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:37,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:32<03:35,  1.05s/it]Loading train:  28%|██▊       | 81/285 [01:33<03:24,  1.00s/it]Loading train:  29%|██▉       | 82/285 [01:34<03:25,  1.01s/it]Loading train:  29%|██▉       | 83/285 [01:35<03:31,  1.05s/it]Loading train:  29%|██▉       | 84/285 [01:36<03:27,  1.03s/it]Loading train:  30%|██▉       | 85/285 [01:38<03:38,  1.09s/it]Loading train:  30%|███       | 86/285 [01:39<03:52,  1.17s/it]Loading train:  31%|███       | 87/285 [01:40<03:49,  1.16s/it]Loading train:  31%|███       | 88/285 [01:41<03:49,  1.16s/it]Loading train:  31%|███       | 89/285 [01:43<04:01,  1.23s/it]Loading train:  32%|███▏      | 90/285 [01:44<03:49,  1.18s/it]Loading train:  32%|███▏      | 91/285 [01:45<03:40,  1.14s/it]Loading train:  32%|███▏      | 92/285 [01:46<03:43,  1.16s/it]Loading train:  33%|███▎      | 93/285 [01:47<03:43,  1.17s/it]Loading train:  33%|███▎      | 94/285 [01:48<03:39,  1.15s/it]Loading train:  33%|███▎      | 95/285 [01:49<03:39,  1.16s/it]Loading train:  34%|███▎      | 96/285 [01:51<03:38,  1.16s/it]Loading train:  34%|███▍      | 97/285 [01:52<03:45,  1.20s/it]Loading train:  34%|███▍      | 98/285 [01:53<03:51,  1.24s/it]Loading train:  35%|███▍      | 99/285 [01:54<03:48,  1.23s/it]Loading train:  35%|███▌      | 100/285 [01:56<03:50,  1.25s/it]Loading train:  35%|███▌      | 101/285 [01:57<03:52,  1.27s/it]Loading train:  36%|███▌      | 102/285 [01:58<03:49,  1.26s/it]Loading train:  36%|███▌      | 103/285 [01:59<03:49,  1.26s/it]Loading train:  36%|███▋      | 104/285 [02:01<03:38,  1.21s/it]Loading train:  37%|███▋      | 105/285 [02:02<03:46,  1.26s/it]Loading train:  37%|███▋      | 106/285 [02:03<03:45,  1.26s/it]Loading train:  38%|███▊      | 107/285 [02:04<03:43,  1.26s/it]Loading train:  38%|███▊      | 108/285 [02:06<03:40,  1.25s/it]Loading train:  38%|███▊      | 109/285 [02:07<03:31,  1.20s/it]Loading train:  39%|███▊      | 110/285 [02:08<03:25,  1.17s/it]Loading train:  39%|███▉      | 111/285 [02:09<03:21,  1.16s/it]Loading train:  39%|███▉      | 112/285 [02:10<03:21,  1.17s/it]Loading train:  40%|███▉      | 113/285 [02:12<03:32,  1.24s/it]Loading train:  40%|████      | 114/285 [02:13<03:33,  1.25s/it]Loading train:  40%|████      | 115/285 [02:14<03:30,  1.24s/it]Loading train:  41%|████      | 116/285 [02:15<03:25,  1.21s/it]Loading train:  41%|████      | 117/285 [02:16<03:20,  1.19s/it]Loading train:  41%|████▏     | 118/285 [02:18<03:19,  1.19s/it]Loading train:  42%|████▏     | 119/285 [02:19<03:14,  1.17s/it]Loading train:  42%|████▏     | 120/285 [02:20<03:23,  1.23s/it]Loading train:  42%|████▏     | 121/285 [02:21<03:31,  1.29s/it]Loading train:  43%|████▎     | 122/285 [02:23<03:31,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:24<03:33,  1.32s/it]Loading train:  44%|████▎     | 124/285 [02:25<03:19,  1.24s/it]Loading train:  44%|████▍     | 125/285 [02:26<03:18,  1.24s/it]Loading train:  44%|████▍     | 126/285 [02:28<03:08,  1.19s/it]Loading train:  45%|████▍     | 127/285 [02:29<02:58,  1.13s/it]Loading train:  45%|████▍     | 128/285 [02:30<02:58,  1.14s/it]Loading train:  45%|████▌     | 129/285 [02:31<02:55,  1.13s/it]Loading train:  46%|████▌     | 130/285 [02:32<02:45,  1.07s/it]Loading train:  46%|████▌     | 131/285 [02:33<02:39,  1.03s/it]Loading train:  46%|████▋     | 132/285 [02:34<02:40,  1.05s/it]Loading train:  47%|████▋     | 133/285 [02:35<02:36,  1.03s/it]Loading train:  47%|████▋     | 134/285 [02:36<02:32,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:37<02:30,  1.00s/it]Loading train:  48%|████▊     | 136/285 [02:38<02:34,  1.03s/it]Loading train:  48%|████▊     | 137/285 [02:39<02:30,  1.02s/it]Loading train:  48%|████▊     | 138/285 [02:40<02:36,  1.06s/it]Loading train:  49%|████▉     | 139/285 [02:41<02:32,  1.05s/it]Loading train:  49%|████▉     | 140/285 [02:42<02:31,  1.04s/it]Loading train:  49%|████▉     | 141/285 [02:43<02:29,  1.04s/it]Loading train:  50%|████▉     | 142/285 [02:44<02:24,  1.01s/it]Loading train:  50%|█████     | 143/285 [02:45<02:19,  1.01it/s]Loading train:  51%|█████     | 144/285 [02:46<02:22,  1.01s/it]Loading train:  51%|█████     | 145/285 [02:47<02:30,  1.08s/it]Loading train:  51%|█████     | 146/285 [02:48<02:29,  1.07s/it]Loading train:  52%|█████▏    | 147/285 [02:49<02:25,  1.06s/it]Loading train:  52%|█████▏    | 148/285 [02:50<02:21,  1.04s/it]Loading train:  52%|█████▏    | 149/285 [02:51<02:21,  1.04s/it]Loading train:  53%|█████▎    | 150/285 [02:52<02:15,  1.00s/it]Loading train:  53%|█████▎    | 151/285 [02:53<02:13,  1.00it/s]Loading train:  53%|█████▎    | 152/285 [02:54<02:09,  1.03it/s]Loading train:  54%|█████▎    | 153/285 [02:55<02:07,  1.04it/s]Loading train:  54%|█████▍    | 154/285 [02:56<02:03,  1.06it/s]Loading train:  54%|█████▍    | 155/285 [02:57<02:02,  1.06it/s]Loading train:  55%|█████▍    | 156/285 [02:58<02:04,  1.04it/s]Loading train:  55%|█████▌    | 157/285 [02:59<02:01,  1.05it/s]Loading train:  55%|█████▌    | 158/285 [03:00<02:00,  1.05it/s]Loading train:  56%|█████▌    | 159/285 [03:01<01:59,  1.05it/s]Loading train:  56%|█████▌    | 160/285 [03:02<01:57,  1.07it/s]Loading train:  56%|█████▋    | 161/285 [03:03<02:03,  1.00it/s]Loading train:  57%|█████▋    | 162/285 [03:04<02:00,  1.02it/s]Loading train:  57%|█████▋    | 163/285 [03:05<02:02,  1.00s/it]Loading train:  58%|█████▊    | 164/285 [03:06<01:57,  1.03it/s]Loading train:  58%|█████▊    | 165/285 [03:07<01:55,  1.04it/s]Loading train:  58%|█████▊    | 166/285 [03:07<01:52,  1.06it/s]Loading train:  59%|█████▊    | 167/285 [03:08<01:50,  1.07it/s]Loading train:  59%|█████▉    | 168/285 [03:09<01:52,  1.04it/s]Loading train:  59%|█████▉    | 169/285 [03:10<01:49,  1.06it/s]Loading train:  60%|█████▉    | 170/285 [03:11<01:52,  1.02it/s]Loading train:  60%|██████    | 171/285 [03:12<01:50,  1.04it/s]Loading train:  60%|██████    | 172/285 [03:13<01:48,  1.04it/s]Loading train:  61%|██████    | 173/285 [03:14<01:47,  1.04it/s]Loading train:  61%|██████    | 174/285 [03:15<01:45,  1.05it/s]Loading train:  61%|██████▏   | 175/285 [03:16<01:44,  1.06it/s]Loading train:  62%|██████▏   | 176/285 [03:17<01:46,  1.02it/s]Loading train:  62%|██████▏   | 177/285 [03:18<01:42,  1.05it/s]Loading train:  62%|██████▏   | 178/285 [03:19<01:45,  1.02it/s]Loading train:  63%|██████▎   | 179/285 [03:20<01:42,  1.03it/s]Loading train:  63%|██████▎   | 180/285 [03:21<01:39,  1.06it/s]Loading train:  64%|██████▎   | 181/285 [03:22<01:35,  1.09it/s]Loading train:  64%|██████▍   | 182/285 [03:23<01:38,  1.05it/s]Loading train:  64%|██████▍   | 183/285 [03:24<01:34,  1.07it/s]Loading train:  65%|██████▍   | 184/285 [03:25<01:34,  1.07it/s]Loading train:  65%|██████▍   | 185/285 [03:26<01:33,  1.07it/s]Loading train:  65%|██████▌   | 186/285 [03:26<01:31,  1.09it/s]Loading train:  66%|██████▌   | 187/285 [03:28<01:37,  1.01it/s]Loading train:  66%|██████▌   | 188/285 [03:28<01:32,  1.05it/s]Loading train:  66%|██████▋   | 189/285 [03:29<01:33,  1.03it/s]Loading train:  67%|██████▋   | 190/285 [03:30<01:29,  1.06it/s]Loading train:  67%|██████▋   | 191/285 [03:31<01:28,  1.06it/s]Loading train:  67%|██████▋   | 192/285 [03:32<01:28,  1.05it/s]Loading train:  68%|██████▊   | 193/285 [03:33<01:27,  1.06it/s]Loading train:  68%|██████▊   | 194/285 [03:34<01:27,  1.04it/s]Loading train:  68%|██████▊   | 195/285 [03:35<01:24,  1.06it/s]Loading train:  69%|██████▉   | 196/285 [03:36<01:26,  1.02it/s]Loading train:  69%|██████▉   | 197/285 [03:38<01:39,  1.13s/it]Loading train:  69%|██████▉   | 198/285 [03:39<01:42,  1.17s/it]Loading train:  70%|██████▉   | 199/285 [03:40<01:40,  1.17s/it]Loading train:  70%|███████   | 200/285 [03:41<01:38,  1.16s/it]Loading train:  71%|███████   | 201/285 [03:43<01:41,  1.21s/it]Loading train:  71%|███████   | 202/285 [03:44<01:48,  1.30s/it]Loading train:  71%|███████   | 203/285 [03:45<01:49,  1.33s/it]Loading train:  72%|███████▏  | 204/285 [03:47<01:50,  1.37s/it]Loading train:  72%|███████▏  | 205/285 [03:49<01:54,  1.43s/it]Loading train:  72%|███████▏  | 206/285 [03:50<01:58,  1.50s/it]Loading train:  73%|███████▎  | 207/285 [03:51<01:52,  1.44s/it]Loading train:  73%|███████▎  | 208/285 [03:53<01:56,  1.51s/it]Loading train:  73%|███████▎  | 209/285 [03:55<01:51,  1.47s/it]Loading train:  74%|███████▎  | 210/285 [03:56<01:45,  1.41s/it]Loading train:  74%|███████▍  | 211/285 [03:57<01:41,  1.36s/it]Loading train:  74%|███████▍  | 212/285 [03:58<01:32,  1.26s/it]Loading train:  75%|███████▍  | 213/285 [03:59<01:34,  1.31s/it]Loading train:  75%|███████▌  | 214/285 [04:01<01:30,  1.27s/it]Loading train:  75%|███████▌  | 215/285 [04:02<01:22,  1.18s/it]Loading train:  76%|███████▌  | 216/285 [04:03<01:19,  1.15s/it]Loading train:  76%|███████▌  | 217/285 [04:04<01:16,  1.13s/it]Loading train:  76%|███████▋  | 218/285 [04:05<01:15,  1.12s/it]Loading train:  77%|███████▋  | 219/285 [04:06<01:17,  1.17s/it]Loading train:  77%|███████▋  | 220/285 [04:07<01:15,  1.16s/it]Loading train:  78%|███████▊  | 221/285 [04:09<01:15,  1.17s/it]Loading train:  78%|███████▊  | 222/285 [04:10<01:13,  1.17s/it]Loading train:  78%|███████▊  | 223/285 [04:11<01:17,  1.24s/it]Loading train:  79%|███████▊  | 224/285 [04:12<01:16,  1.25s/it]Loading train:  79%|███████▉  | 225/285 [04:13<01:09,  1.15s/it]Loading train:  79%|███████▉  | 226/285 [04:15<01:13,  1.24s/it]Loading train:  80%|███████▉  | 227/285 [04:16<01:12,  1.25s/it]Loading train:  80%|████████  | 228/285 [04:17<01:12,  1.28s/it]Loading train:  80%|████████  | 229/285 [04:19<01:16,  1.37s/it]Loading train:  81%|████████  | 230/285 [04:21<01:18,  1.43s/it]Loading train:  81%|████████  | 231/285 [04:22<01:13,  1.35s/it]Loading train:  81%|████████▏ | 232/285 [04:23<01:17,  1.45s/it]Loading train:  82%|████████▏ | 233/285 [04:25<01:13,  1.41s/it]Loading train:  82%|████████▏ | 234/285 [04:26<01:08,  1.35s/it]Loading train:  82%|████████▏ | 235/285 [04:27<01:05,  1.31s/it]Loading train:  83%|████████▎ | 236/285 [04:28<01:03,  1.30s/it]Loading train:  83%|████████▎ | 237/285 [04:30<01:04,  1.34s/it]Loading train:  84%|████████▎ | 238/285 [04:31<01:06,  1.41s/it]Loading train:  84%|████████▍ | 239/285 [04:33<01:03,  1.38s/it]Loading train:  84%|████████▍ | 240/285 [04:34<01:01,  1.36s/it]Loading train:  85%|████████▍ | 241/285 [04:36<01:02,  1.41s/it]Loading train:  85%|████████▍ | 242/285 [04:37<00:59,  1.39s/it]Loading train:  85%|████████▌ | 243/285 [04:39<01:01,  1.46s/it]Loading train:  86%|████████▌ | 244/285 [04:40<00:57,  1.41s/it]Loading train:  86%|████████▌ | 245/285 [04:41<00:59,  1.49s/it]Loading train:  86%|████████▋ | 246/285 [04:43<00:57,  1.48s/it]Loading train:  87%|████████▋ | 247/285 [04:44<00:53,  1.41s/it]Loading train:  87%|████████▋ | 248/285 [04:46<00:53,  1.45s/it]Loading train:  87%|████████▋ | 249/285 [04:47<00:50,  1.40s/it]Loading train:  88%|████████▊ | 250/285 [04:48<00:47,  1.36s/it]Loading train:  88%|████████▊ | 251/285 [04:50<00:49,  1.46s/it]Loading train:  88%|████████▊ | 252/285 [04:51<00:47,  1.45s/it]Loading train:  89%|████████▉ | 253/285 [04:53<00:43,  1.37s/it]Loading train:  89%|████████▉ | 254/285 [04:54<00:42,  1.39s/it]Loading train:  89%|████████▉ | 255/285 [04:55<00:41,  1.39s/it]Loading train:  90%|████████▉ | 256/285 [04:57<00:39,  1.36s/it]Loading train:  90%|█████████ | 257/285 [04:58<00:37,  1.33s/it]Loading train:  91%|█████████ | 258/285 [04:59<00:34,  1.28s/it]Loading train:  91%|█████████ | 259/285 [05:00<00:32,  1.27s/it]Loading train:  91%|█████████ | 260/285 [05:02<00:31,  1.27s/it]Loading train:  92%|█████████▏| 261/285 [05:03<00:29,  1.23s/it]Loading train:  92%|█████████▏| 262/285 [05:04<00:27,  1.21s/it]Loading train:  92%|█████████▏| 263/285 [05:05<00:26,  1.21s/it]Loading train:  93%|█████████▎| 264/285 [05:07<00:26,  1.26s/it]Loading train:  93%|█████████▎| 265/285 [05:08<00:24,  1.24s/it]Loading train:  93%|█████████▎| 266/285 [05:09<00:22,  1.18s/it]Loading train:  94%|█████████▎| 267/285 [05:10<00:21,  1.21s/it]Loading train:  94%|█████████▍| 268/285 [05:12<00:23,  1.38s/it]Loading train:  94%|█████████▍| 269/285 [05:14<00:23,  1.49s/it]Loading train:  95%|█████████▍| 270/285 [05:15<00:23,  1.59s/it]Loading train:  95%|█████████▌| 271/285 [05:17<00:21,  1.54s/it]Loading train:  95%|█████████▌| 272/285 [05:18<00:19,  1.50s/it]Loading train:  96%|█████████▌| 273/285 [05:20<00:17,  1.48s/it]Loading train:  96%|█████████▌| 274/285 [05:21<00:16,  1.53s/it]Loading train:  96%|█████████▋| 275/285 [05:23<00:14,  1.46s/it]Loading train:  97%|█████████▋| 276/285 [05:24<00:13,  1.50s/it]Loading train:  97%|█████████▋| 277/285 [05:26<00:11,  1.47s/it]Loading train:  98%|█████████▊| 278/285 [05:27<00:09,  1.40s/it]Loading train:  98%|█████████▊| 279/285 [05:29<00:09,  1.54s/it]Loading train:  98%|█████████▊| 280/285 [05:30<00:07,  1.58s/it]Loading train:  99%|█████████▊| 281/285 [05:32<00:06,  1.54s/it]Loading train:  99%|█████████▉| 282/285 [05:33<00:04,  1.46s/it]Loading train:  99%|█████████▉| 283/285 [05:35<00:02,  1.47s/it]Loading train: 100%|█████████▉| 284/285 [05:36<00:01,  1.48s/it]Loading train: 100%|██████████| 285/285 [05:38<00:00,  1.51s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:09, 29.75it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:09, 29.91it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:09, 30.30it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:08, 33.53it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:06, 40.57it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:05, 49.09it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:04, 56.47it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:04, 54.87it/s]concatenating: train:  20%|██        | 57/285 [00:01<00:03, 58.09it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:03, 64.36it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:02, 74.20it/s]concatenating: train:  31%|███       | 87/285 [00:01<00:02, 74.47it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:02, 79.60it/s]concatenating: train:  38%|███▊      | 107/285 [00:01<00:02, 75.88it/s]concatenating: train:  41%|████      | 116/285 [00:01<00:02, 67.07it/s]concatenating: train:  44%|████▎     | 124/285 [00:01<00:02, 64.69it/s]concatenating: train:  46%|████▌     | 131/285 [00:02<00:02, 61.40it/s]concatenating: train:  49%|████▉     | 139/285 [00:02<00:02, 65.28it/s]concatenating: train:  53%|█████▎    | 152/285 [00:02<00:01, 76.18it/s]concatenating: train:  58%|█████▊    | 165/285 [00:02<00:01, 86.32it/s]concatenating: train:  62%|██████▏   | 178/285 [00:02<00:01, 95.14it/s]concatenating: train:  67%|██████▋   | 191/285 [00:02<00:00, 102.50it/s]concatenating: train:  72%|███████▏  | 204/285 [00:02<00:00, 108.33it/s]concatenating: train:  76%|███████▌  | 216/285 [00:03<00:01, 64.32it/s] concatenating: train:  79%|███████▉  | 226/285 [00:03<00:00, 61.82it/s]concatenating: train:  82%|████████▏ | 235/285 [00:03<00:00, 57.98it/s]concatenating: train:  85%|████████▌ | 243/285 [00:03<00:00, 50.52it/s]concatenating: train:  88%|████████▊ | 251/285 [00:03<00:00, 54.93it/s]concatenating: train:  91%|█████████ | 259/285 [00:03<00:00, 59.63it/s]concatenating: train:  94%|█████████▎| 267/285 [00:03<00:00, 63.72it/s]concatenating: train:  99%|█████████▊| 281/285 [00:04<00:00, 75.24it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 70.60it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.90s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.89s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 29.65it/s]
Epoch 00048: val_mDice did not improve from 0.55105
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
{'val_loss': [7827.577625093006, 6668.240931919643, 4827.183442615327, 3569.5431198846727, 3327.1202450706846, 3127.4026867094494, 2998.3301595052085, 2922.4947102864585, 2967.576683407738, 3006.118384951637, 2906.6500302269346, 2966.9846947079614, 2879.6375267392114, 2761.3931477864585, 2959.066098167783, 2954.150076729911, 2900.5773402622767, 2692.932192847842, 2846.3076753162204, 3087.0110909598216, 2842.5770728701636, 2812.1334286644346, 2817.655540829613, 2927.1399855840773, 2859.379813058036, 2776.872564406622, 2906.3746105375744, 2833.3369663783483, 3025.234194800967, 3096.543015252976, 3014.2186221168154, 2801.03955078125, 3114.5069812593006, 3011.2109956287204, 2725.0782005673364, 2846.8841378348216, 2885.1181524367557, 2933.842569986979, 3233.722673688616, 2859.628191266741, 2920.976097470238, 2833.579566592262, 2953.159627278646, 2952.9613676525296, 2905.7380952380954, 2894.6661841982886, 3541.61873953683, 2944.7571963355654], 'val_acc': [0.8997412948381334, 0.9053800446646554, 0.9066025614738464, 0.907229829402197, 0.9145100514094034, 0.9187705857413155, 0.9183104463985988, 0.9292971633729481, 0.9250938665299189, 0.9309043117931911, 0.9403022016797747, 0.940789832955315, 0.9448054035504659, 0.9448511969475519, 0.9443543950716654, 0.943514190969013, 0.9458424676032293, 0.9432783666111174, 0.9441895825522286, 0.9436492778006054, 0.9399519392422268, 0.9429098254158383, 0.9464995520455497, 0.9420970791862124, 0.9461011829830351, 0.9368658292861212, 0.9410966152236575, 0.9437431352479118, 0.9409523890131996, 0.9389079752422514, 0.9415590677942548, 0.9416850010553995, 0.9421520091238476, 0.9443452329862685, 0.942694624265035, 0.9448259955360776, 0.9436401270684742, 0.9446520180929274, 0.9428868889808655, 0.9460416861942836, 0.9454990682147798, 0.9466803953761146, 0.9463759320122855, 0.9446863588832674, 0.9455494596844628, 0.9439789283843267, 0.9385531232470558, 0.9458035996982029], 'val_mDice': [0.2115744516430866, 0.2923452237751224, 0.35395804544289905, 0.46249366072671755, 0.489433865994215, 0.5046002524239677, 0.5188991594172659, 0.5289398190521059, 0.5221280260455041, 0.5171142295002937, 0.5303415393545514, 0.5224435249609607, 0.5317194213469824, 0.5437538806526434, 0.5242590393338885, 0.5233808610410917, 0.5279947505110786, 0.5510469004511833, 0.5332762065033118, 0.5095269843226388, 0.5349298861055147, 0.5376180417480922, 0.5363919021827834, 0.5262714624404907, 0.5315286075430257, 0.5436029602729139, 0.5309455948216575, 0.5385016589647248, 0.5185265157903943, 0.5110467448830605, 0.5191105018768992, 0.5388121588953904, 0.5082044998804728, 0.5216685781876246, 0.5487065081085477, 0.5375777181415331, 0.5322891828559694, 0.5269421030368123, 0.49644914801631657, 0.5341504292473906, 0.5263931925098101, 0.5386739399816308, 0.5238466757748809, 0.5231863941465106, 0.5292807248021875, 0.5304634737826529, 0.4624257857600848, 0.5265178472868034], 'loss': [15764.861633971497, 5730.38595385135, 3810.3708463616977, 3173.73590244391, 2777.970268336293, 2540.276440566184, 2361.3946148894624, 2228.695306028179, 2129.648749865386, 2031.2401484998177, 1947.567298208148, 1886.0781729856117, 1811.5683399595368, 1759.186249079354, 1739.475289669298, 1671.1015193859046, 1638.0135651958547, 1610.1718882966506, 1569.5384721287141, 1556.1744967229522, 1522.4394914381808, 1501.6763787520558, 1483.025219015839, 1452.9797635803752, 1432.8833768310312, 1423.2197467781157, 1408.6518646705028, 1382.5907964020628, 1371.2399321762564, 1361.3507227164969, 1348.3770018519292, 1338.206605380639, 1322.8744088756296, 1314.3775343298337, 1299.2010410736125, 1283.3864798221327, 1278.388266574263, 1272.7574129886013, 1265.7034699598305, 1250.741958338699, 1242.5911187105196, 1234.8626252779823, 1230.1654588248152, 1225.278833904454, 1211.2226043106941, 1212.0300819657316, 1202.3258172545056, 1192.0167198791562], 'acc': [0.5139325757505394, 0.8713547692653736, 0.8785483722905559, 0.8817196937454949, 0.8855542400587908, 0.8892199070163607, 0.8931474619364954, 0.8972378713514204, 0.9027646304969501, 0.9101636768513524, 0.9183717897132755, 0.9256394749458111, 0.9331369761076648, 0.9371885021274803, 0.9388729547613132, 0.9405881572785533, 0.9415629946337469, 0.9418853873436176, 0.9427451997311652, 0.9430935906380248, 0.9437513430039961, 0.9440614297621186, 0.9444776880780189, 0.9449610984667846, 0.9453309470342721, 0.9456778508471873, 0.945823068422965, 0.9462287618471796, 0.9465768022047248, 0.9467658163243138, 0.9470520108243002, 0.947124931034105, 0.9473708541447978, 0.9476343891007928, 0.9479504991455623, 0.9482225335722189, 0.9484225782972093, 0.948444218977536, 0.94859288767029, 0.9487342126502314, 0.9489123117310109, 0.9490895103185605, 0.9491684109759694, 0.9492818110017205, 0.9494833155751159, 0.9494142859731769, 0.9498064686320341, 0.9499687420303752], 'mDice': [0.0801460955759533, 0.32584683285390154, 0.4619717433293109, 0.5249871611824977, 0.5687313132003848, 0.5967988308302947, 0.6191518190671466, 0.6361757294162289, 0.6491062355128837, 0.6619439945874565, 0.6729787425289776, 0.681112205623684, 0.6910962188131252, 0.6982136672003227, 0.700910395226406, 0.7105449337432534, 0.7153756375806465, 0.7194527207897282, 0.7252766606617875, 0.7274128651949903, 0.7323531729880385, 0.7354491260760961, 0.738249115029672, 0.7427138098407302, 0.7458105405240659, 0.7473096958308958, 0.7495156157469506, 0.7535040093819622, 0.7552601812615293, 0.756772970576403, 0.7587829379877282, 0.7603330933360528, 0.7627083100127144, 0.7640572381497625, 0.7664483625442507, 0.768882641459973, 0.7696975946817091, 0.7705480171486387, 0.7716829256903857, 0.7740580593434193, 0.7753042754971593, 0.7765646692827209, 0.7772870891489964, 0.778086053088655, 0.7802917706109159, 0.7801632758094231, 0.7817505222077495, 0.7833384253947933]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________2019-07-08 11:13:02.291984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 11:13:02.292097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 11:13:02.292114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 11:13:02.292124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 11:13:02.315650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

conv2d_10 (Conv2D)              (None, 52, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 24s - loss: 12113.5449 - acc: 0.7382 - mDice: 0.1703 - val_loss: 4551.3659 - val_acc: 0.9196 - val_mDice: 0.3747

Epoch 00001: val_mDice improved from -inf to 0.37472, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 13s - loss: 3832.3662 - acc: 0.9014 - mDice: 0.4642 - val_loss: 2889.9497 - val_acc: 0.9326 - val_mDice: 0.5276

Epoch 00002: val_mDice improved from 0.37472 to 0.52761, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 2957.9825 - acc: 0.9125 - mDice: 0.5507 - val_loss: 2607.7247 - val_acc: 0.9473 - val_mDice: 0.5603

Epoch 00003: val_mDice improved from 0.52761 to 0.56032, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 2579.1364 - acc: 0.9274 - mDice: 0.5940 - val_loss: 2693.9504 - val_acc: 0.9435 - val_mDice: 0.5522

Epoch 00004: val_mDice did not improve from 0.56032
Epoch 5/300
 - 12s - loss: 2273.9176 - acc: 0.9390 - mDice: 0.6301 - val_loss: 2452.6366 - val_acc: 0.9493 - val_mDice: 0.5857

Epoch 00005: val_mDice improved from 0.56032 to 0.58571, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 12s - loss: 2094.8465 - acc: 0.9436 - mDice: 0.6530 - val_loss: 2411.5514 - val_acc: 0.9466 - val_mDice: 0.5848

Epoch 00006: val_mDice did not improve from 0.58571
Epoch 7/300
 - 12s - loss: 1964.8277 - acc: 0.9459 - mDice: 0.6702 - val_loss: 2669.7771 - val_acc: 0.9508 - val_mDice: 0.5630

Epoch 00007: val_mDice did not improve from 0.58571
Epoch 8/300
 - 13s - loss: 1870.3814 - acc: 0.9472 - mDice: 0.6832 - val_loss: 2353.7546 - val_acc: 0.9490 - val_mDice: 0.5947

Epoch 00008: val_mDice improved from 0.58571 to 0.59473, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 12s - loss: 1801.3678 - acc: 0.9481 - mDice: 0.6928 - val_loss: 2392.0339 - val_acc: 0.9462 - val_mDice: 0.5885

Epoch 00009: val_mDice did not improve from 0.59473
Epoch 10/300
 - 12s - loss: 1734.0814 - acc: 0.9490 - mDice: 0.7023 - val_loss: 2288.7847 - val_acc: 0.9522 - val_mDice: 0.6024

Epoch 00010: val_mDice improved from 0.59473 to 0.60240, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 12s - loss: 1685.4480 - acc: 0.9497 - mDice: 0.7093 - val_loss: 2389.5507 - val_acc: 0.9491 - val_mDice: 0.5894

Epoch 00011: val_mDice did not improve from 0.60240
Epoch 12/300
 - 12s - loss: 1631.1987 - acc: 0.9506 - mDice: 0.7170 - val_loss: 2417.0858 - val_acc: 0.9512 - val_mDice: 0.5899

Epoch 00012: val_mDice did not improve from 0.60240
Epoch 13/300
 - 13s - loss: 1595.4416 - acc: 0.9510 - mDice: 0.7221 - val_loss: 2268.8258 - val_acc: 0.9523 - val_mDice: 0.6080

Epoch 00013: val_mDice improved from 0.60240 to 0.60796, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 12s - loss: 1557.3194 - acc: 0.9516 - mDice: 0.7278 - val_loss: 2311.5991 - val_acc: 0.9493 - val_mDice: 0.6015

Epoch 00014: val_mDice did not improve from 0.60796
Epoch 15/300
 - 12s - loss: 1523.0604 - acc: 0.9520 - mDice: 0.7328 - val_loss: 2225.2650 - val_acc: 0.9482 - val_mDice: 0.6079

Epoch 00015: val_mDice did not improve from 0.60796
Epoch 16/300
 - 12s - loss: 1497.6157 - acc: 0.9524 - mDice: 0.7368 - val_loss: 2293.9549 - val_acc: 0.9513 - val_mDice: 0.6041

Epoch 00016: val_mDice did not improve from 0.60796
Epoch 17/300
 - 12s - loss: 1465.8964 - acc: 0.9529 - mDice: 0.7413 - val_loss: 2228.7527 - val_acc: 0.9500 - val_mDice: 0.6085

Epoch 00017: val_mDice improved from 0.60796 to 0.60847, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 12s - loss: 1448.8003 - acc: 0.9531 - mDice: 0.7439 - val_loss: 2306.3207 - val_acc: 0.9514 - val_mDice: 0.6025

Epoch 00018: val_mDice did not improve from 0.60847
Epoch 19/300
 - 12s - loss: 1417.3376 - acc: 0.9537 - mDice: 0.7487 - val_loss: 2483.0794 - val_acc: 0.9530 - val_mDice: 0.5852

Epoch 00019: val_mDice did not improve from 0.60847
Epoch 20/300
 - 12s - loss: 1399.5044 - acc: 0.9539 - mDice: 0.7514 - val_loss: 2216.5753 - val_acc: 0.9519 - val_mDice: 0.6133

Epoch 00020: val_mDice improved from 0.60847 to 0.61333, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 12s - loss: 1385.4883 - acc: 0.9541 - mDice: 0.7536 - val_loss: 2460.5227 - val_acc: 0.9536 - val_mDice: 0.5895

Epoch 00021: val_mDice did not improve from 0.61333
Epoch 22/300
 - 12s - loss: 1359.6964 - acc: 0.9545 - mDice: 0.7575 - val_loss: 2402.9648 - val_acc: 0.9530 - val_mDice: 0.5904

Epoch 00022: val_mDice did not improve from 0.61333
Epoch 23/300
 - 11s - loss: 1346.5867 - acc: 0.9547 - mDice: 0.7595 - val_loss: 2251.5934 - val_acc: 0.9531 - val_mDice: 0.6074

Epoch 00023: val_mDice did not improve from 0.61333
Epoch 24/300
 - 12s - loss: 1316.4664 - acc: 0.9551 - mDice: 0.7641 - val_loss: 2329.6880 - val_acc: 0.9525 - val_mDice: 0.5965

Epoch 00024: val_mDice did not improve from 0.61333
Epoch 25/300
 - 11s - loss: 1315.1194 - acc: 0.9551 - mDice: 0.7643 - val_loss: 2389.4599 - val_acc: 0.9523 - val_mDice: 0.5934

Epoch 00025: val_mDice did not improve from 0.61333
Epoch 26/300
 - 12s - loss: 1305.2705 - acc: 0.9554 - mDice: 0.7658 - val_loss: 2222.4505 - val_acc: 0.9528 - val_mDice: 0.6108

Epoch 00026: val_mDice did not improve from 0.61333
Epoch 27/300
 - 12s - loss: 1295.7091 - acc: 0.9556 - mDice: 0.7673 - val_loss: 2187.6911 - val_acc: 0.9534 - val_mDice: 0.6156

Epoch 00027: val_mDice improved from 0.61333 to 0.61555, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 11s - loss: 1274.4797 - acc: 0.9559 - mDice: 0.7707 - val_loss: 2236.3991 - val_acc: 0.9528 - val_mDice: 0.6092

Epoch 00028: val_mDice did not improve from 0.61555
Epoch 29/300
 - 11s - loss: 1264.6161 - acc: 0.9560 - mDice: 0.7721 - val_loss: 2230.0864 - val_acc: 0.9555 - val_mDice: 0.6144

Epoch 00029: val_mDice did not improve from 0.61555
Epoch 30/300
 - 12s - loss: 1260.3779 - acc: 0.9562 - mDice: 0.7728 - val_loss: 2327.3456 - val_acc: 0.9533 - val_mDice: 0.5982

Epoch 00030: val_mDice did not improve from 0.61555
Epoch 31/300
 - 11s - loss: 1243.7246 - acc: 0.9564 - mDice: 0.7754 - val_loss: 2428.5913 - val_acc: 0.9527 - val_mDice: 0.5908

Epoch 00031: val_mDice did not improve from 0.61555
Epoch 32/300
 - 11s - loss: 1245.5909 - acc: 0.9565 - mDice: 0.7752 - val_loss: 2159.5157 - val_acc: 0.9514 - val_mDice: 0.6197

Epoch 00032: val_mDice improved from 0.61555 to 0.61971, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 33/300
 - 11s - loss: 1219.1311 - acc: 0.9568 - mDice: 0.7792 - val_loss: 2243.8383 - val_acc: 0.9553 - val_mDice: 0.6102

Epoch 00033: val_mDice did not improve from 0.61971
Epoch 34/300
 - 12s - loss: 1215.8901 - acc: 0.9569 - mDice: 0.7799 - val_loss: 2292.7503 - val_acc: 0.9529 - val_mDice: 0.6035

Epoch 00034: val_mDice did not improve from 0.61971
Epoch 35/300
 - 11s - loss: 1216.0571 - acc: 0.9569 - mDice: 0.7799 - val_loss: 2342.5265 - val_acc: 0.9537 - val_mDice: 0.5988

Epoch 00035: val_mDice did not improve from 0.61971
Epoch 36/300
 - 11s - loss: 1198.8151 - acc: 0.9572 - mDice: 0.7825 - val_loss: 2195.3854 - val_acc: 0.9528 - val_mDice: 0.6132

Epoch 00036: val_mDice did not improve from 0.61971
Epoch 37/300
 - 11s - loss: 1190.9590 - acc: 0.9574 - mDice: 0.7837 - val_loss: 2409.6611 - val_acc: 0.9527 - val_mDice: 0.5916

Epoch 00037: val_mDice did not improve from 0.61971
Epoch 38/300
 - 12s - loss: 1192.4921 - acc: 0.9573 - mDice: 0.7835 - val_loss: 2266.3998 - val_acc: 0.9545 - val_mDice: 0.6095

Epoch 00038: val_mDice did not improve from 0.61971
Epoch 39/300
 - 12s - loss: 1180.4226 - acc: 0.9575 - mDice: 0.7855 - val_loss: 2294.3826 - val_acc: 0.9544 - val_mDice: 0.6026

Epoch 00039: val_mDice did not improve from 0.61971
Epoch 40/300
 - 11s - loss: 1168.5012 - acc: 0.9577 - mDice: 0.7873 - val_loss: 2139.8250 - val_acc: 0.9533 - val_mDice: 0.6209

Epoch 00040: val_mDice improved from 0.61971 to 0.62088, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 41/300
 - 11s - loss: 1172.2382 - acc: 0.9576 - mDice: 0.7868 - val_loss: 2320.4281 - val_acc: 0.9527 - val_mDice: 0.6008

Epoch 00041: val_mDice did not improve from 0.62088
Epoch 42/300
 - 11s - loss: 1166.4853 - acc: 0.9577 - mDice: 0.7876 - val_loss: 2375.2353 - val_acc: 0.9547 - val_mDice: 0.5974

Epoch 00042: val_mDice did not improve from 0.62088
Epoch 43/300
 - 11s - loss: 1151.0906 - acc: 0.9581 - mDice: 0.7901 - val_loss: 2309.9886 - val_acc: 0.9539 - val_mDice: 0.6070

Epoch 00043: val_mDice did not improve from 0.62088
Epoch 44/300
 - 12s - loss: 1145.5383 - acc: 0.9581 - mDice: 0.7911 - val_loss: 2222.6082 - val_acc: 0.9533 - val_mDice: 0.6098

Epoch 00044: val_mDice did not improve from 0.62088
Epoch 45/300
 - 12s - loss: 1142.1124 - acc: 0.9582 - mDice: 0.7915 - val_loss: 2199.6541 - val_acc: 0.9530 - val_mDice: 0.6146

Epoch 00045: val_mDice did not improve from 0.62088
Epoch 46/300
 - 11s - loss: 1137.5666 - acc: 0.9583 - mDice: 0.7923 - val_loss: 2438.0072 - val_acc: 0.9533 - val_mDice: 0.5900

Epoch 00046: val_mDice did not improve from 0.62088
Epoch 47/300
 - 11s - loss: 1144.3099 - acc: 0.9583 - mDice: 0.7913 - val_loss: 2464.0955 - val_acc: 0.9545 - val_mDice: 0.5890

Epoch 00047: val_mDice did not improve from 0.62088
Epoch 48/300
 - 11s - loss: 1139.1998 - acc: 0.9583 - mDice: 0.7920 - val_loss: 2234.0863 - val_acc: 0.9514 - val_mDice: 0.6092

Epoch 00048: val_mDice did not improve from 0.62088
Epoch 49/300
 - 11s - loss: 1124.8136 - acc: 0.9586 - mDice: 0.7943 - val_loss: 2287.6698 - val_acc: 0.9549 - val_mDice: 0.6060

Epoch 00049: val_mDice did not improve from 0.62088
Epoch 50/300
 - 11s - loss: 1125.0491 - acc: 0.9586 - mDice: 0.7944 - val_loss: 2132.4281 - val_acc: 0.9533 - val_mDice: 0.6215

Epoch 00050: val_mDice improved from 0.62088 to 0.62150, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 51/300
 - 12s - loss: 1122.1994 - acc: 0.9587 - mDice: 0.7948 - val_loss: 2275.1119 - val_acc: 0.9499 - val_mDice: 0.6044

Epoch 00051: val_mDice did not improve from 0.62150
Epoch 52/300
 - 12s - loss: 1115.0265 - acc: 0.9588 - mDice: 0.7959 - val_loss: 2267.8373 - val_acc: 0.9549 - val_mDice: 0.6071

Epoch 00052: val_mDice did not improve from 0.62150
Epoch 53/300
 - 12s - loss: 1118.8457 - acc: 0.9588 - mDice: 0.7954 - val_loss: 2432.2167 - val_acc: 0.9539 - val_mDice: 0.5865

Epoch 00053: val_mDice did not improve from 0.62150
Epoch 54/300
 - 12s - loss: 1108.3197 - acc: 0.9589 - mDice: 0.7970 - val_loss: 2231.3268 - val_acc: 0.9528 - val_mDice: 0.6100

Epoch 00054: val_mDice did not improve from 0.62150
Epoch 55/300
 - 12s - loss: 1104.1671 - acc: 0.9590 - mDice: 0.7976 - val_loss: 2187.6949 - val_acc: 0.9546 - val_mDice: 0.6148

Epoch 00055: val_mDice did not improve from 0.62150
Epoch 56/300
 - 12s - loss: 1104.8308 - acc: 0.9590 - mDice: 0.7977 - val_loss: 2191.9160 - val_acc: 0.9522 - val_mDice: 0.6132

Epoch 00056: val_mDice did not improve from 0.62150
Epoch 57/300
 - 12s - loss: 1105.7734 - acc: 0.9590 - mDice: 0.7975 - val_loss: 2412.7152 - val_acc: 0.9543 - val_mDice: 0.5937

Epoch 00057: val_mDice did not improve from 0.62150
Epoch 58/300
 - 12s - loss: 1093.6885 - acc: 0.9591 - mDice: 0.7995 - val_loss: 2180.0040 - val_acc: 0.9537 - val_mDice: 0.6153

Epoch 00058: val_mDice did not improve from 0.62150
Epoch 59/300
 - 13s - loss: 1093.6888 - acc: 0.9592 - mDice: 0.7994 - val_loss: 2370.9342 - val_acc: 0.9539 - val_mDice: 0.5944

Epoch 00059: val_mDice did not improve from 0.62150
Epoch 60/300
 - 12s - loss: 1091.7468 - acc: 0.9592 - mDice: 0.7997 - val_loss: 2316.9536 - val_acc: 0.9550 - val_mDice: 0.5986

Epoch 00060: val_mDice did not improve from 0.62150
Epoch 61/300
 - 12s - loss: 1088.8334 - acc: 0.9592 - mDice: 0.8002 - val_loss: 2168.0603 - val_acc: 0.9550 - val_mDice: 0.6176

Epoch 00061: val_mDice did not improve from 0.62150
Epoch 62/300
 - 12s - loss: 1093.9783 - acc: 0.9593 - mDice: 0.7994 - val_loss: 2161.5998 - val_acc: 0.9525 - val_mDice: 0.6165

Epoch 00062: val_mDice did not improve from 0.62150
Epoch 63/300
 - 12s - loss: 1082.7751 - acc: 0.9594 - mDice: 0.8012 - val_loss: 2207.7855 - val_acc: 0.9544 - val_mDice: 0.6122

Epoch 00063: val_mDice did not improve from 0.62150
Epoch 64/300
 - 12s - loss: 1084.2250 - acc: 0.9595 - mDice: 0.8010 - val_loss: 2189.7087 - val_acc: 0.9524 - val_mDice: 0.6131

Epoch 00064: val_mDice did not improve from 0.62150
Epoch 65/300
 - 12s - loss: 1078.6793 - acc: 0.9595 - mDice: 0.8018 - val_loss: 2258.7705 - val_acc: 0.9534 - val_mDice: 0.6069

Epoch 00065: val_mDice did not improve from 0.62150
Epoch 66/300
 - 12s - loss: 1072.0955 - acc: 0.9596 - mDice: 0.8029 - val_loss: 2215.6797 - val_acc: 0.9502 - val_mDice: 0.6105

Epoch 00066: val_mDice did not improve from 0.62150
Epoch 67/300
 - 12s - loss: 1071.3564 - acc: 0.9596 - mDice: 0.8031 - val_loss: 2201.4918 - val_acc: 0.9526 - val_mDice: 0.6148

Epoch 00067: val_mDice did not improve from 0.62150
Epoch 68/300
 - 12s - loss: 1068.8443 - acc: 0.9596 - mDice: 0.8035 - val_loss: 2197.1694 - val_acc: 0.9528 - val_mDice: 0.6136

Epoch 00068: val_mDice did not improve from 0.62150
Epoch 69/300
 - 12s - loss: 1066.5233 - acc: 0.9596 - mDice: 0.8038 - val_loss: 2255.2478 - val_acc: 0.9521 - val_mDice: 0.6079

Epoch 00069: val_mDice did not improve from 0.62150
Epoch 70/300
 - 12s - loss: 1065.1465 - acc: 0.9597 - mDice: 0.8041 - val_loss: 2176.4546 - val_acc: 0.9536 - val_mDice: 0.6166

Epoch 00070: val_mDice did not improve from 0.62150
Epoch 71/300
 - 12s - loss: 1060.7134 - acc: 0.9598 - mDice: 0.8048 - val_loss: 2399.5349 - val_acc: 0.9547 - val_mDice: 0.5928

Epoch 00071: val_mDice did not improve from 0.62150
Epoch 72/300
 - 12s - loss: 1069.7058 - acc: 0.9597 - mDice: 0.8033 - val_loss: 2170.5564 - val_acc: 0.9528 - val_mDice: 0.6168

Epoch 00072: val_mDice did not improve from 0.62150
Epoch 73/300
 - 12s - loss: 1062.5641 - acc: 0.9597 - mDice: 0.8045 - val_loss: 2143.1541 - val_acc: 0.9516 - val_mDice: 0.6204

Epoch 00073: val_mDice did not improve from 0.62150
Epoch 74/300
 - 12s - loss: 1061.2450 - acc: 0.9598 - mDice: 0.8048 - val_loss: 2190.9137 - val_acc: 0.9536 - val_mDice: 0.6142

Epoch 00074: val_mDice did not improve from 0.62150
Epoch 75/300
 - 12s - loss: 1048.7262 - acc: 0.9599 - mDice: 0.8067 - val_loss: 2344.5212 - val_acc: 0.9551 - val_mDice: 0.5985

Epoch 00075: val_mDice did not improve from 0.62150
Epoch 76/300
 - 12s - loss: 1052.4331 - acc: 0.9599 - mDice: 0.8062 - val_loss: 2417.0405 - val_acc: 0.9531 - val_mDice: 0.5933

Epoch 00076: val_mDice did not improve from 0.62150
Epoch 77/300
 - 12s - loss: 1048.3771 - acc: 0.9600 - mDice: 0.8068 - val_loss: 2338.5256 - val_acc: 0.9534 - val_mDice: 0.5976

Epoch 00077: val_mDice did not improve from 0.62150
Epoch 78/300
 - 12s - loss: 1051.4769 - acc: 0.9599 - mDice: 0.8063 - val_loss: 2136.6119 - val_acc: 0.9525 - val_mDice: 0.6211

Epoch 00078: val_mDice did not improve from 0.62150
Epoch 79/300
 - 12s - loss: 1047.9255 - acc: 0.9599 - mDice: 0.8069 - val_loss: 2301.1673 - val_acc: 0.9545 - val_mDice: 0.6057

Epoch 00079: val_mDice did not improve from 0.62150
Epoch 80/300
 - 12s - loss: 1047.5803 - acc: 0.9601 - mDice: 0.8070 - val_loss: 2336.7768 - val_acc: 0.9550 - val_mDice: 0.5979

Epoch 00080: val_mDice did not improve from 0.62150
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
{'val_loss': [4551.3658863259425, 2889.9497356734464, 2607.724672115049, 2693.950425813984, 2452.636567355534, 2411.551411378317, 2669.7770764228353, 2353.7545909348814, 2392.033905540765, 2288.7846747883204, 2389.550663953387, 2417.0857656468224, 2268.8257572451116, 2311.5990665371855, 2225.265024877793, 2293.9549049079087, 2228.75270054993, 2306.320660298097, 2483.079396167947, 2216.575296242144, 2460.5226627967877, 2402.964845113914, 2251.5933831071056, 2329.688000556477, 2389.459896833537, 2222.4505185601433, 2187.691087094099, 2236.3991262766235, 2230.0863521298884, 2327.3455558222763, 2428.59133859986, 2159.5156850122207, 2243.8382793405203, 2292.750285058048, 2342.5265404045913, 2195.385408028544, 2409.661097350733, 2266.399835511959, 2294.3825956376572, 2139.8249538997034, 2320.4280508030724, 2375.235336559445, 2309.9885717637044, 2222.6081924864698, 2199.654062281774, 2438.007196010824, 2464.095498537884, 2234.0863166681215, 2287.669778664019, 2132.4281394574896, 2275.1119255193785, 2267.837327328474, 2432.2167014010124, 2231.3267951837465, 2187.69490059794, 2191.9159815271473, 2412.715218826379, 2180.0039512591657, 2370.934185688722, 2316.9535914586245, 2168.060250905639, 2161.599778500349, 2207.7854576750174, 2189.7087129560928, 2258.7704696229052, 2215.6796547660615, 2201.4917783257683, 2197.1694104072103, 2255.2478259209147, 2176.454599391149, 2399.5349284763442, 2170.5563787534916, 2143.154119566166, 2190.913665600995, 2344.521200680866, 2417.040540982891, 2338.5256320377966, 2136.6119132441513, 2301.1673058877445, 2336.7767845452163], 'val_acc': [0.9195977006544614, 0.9326468732769929, 0.9472785971684163, 0.9434977263711685, 0.9493198727762233, 0.9466195326277663, 0.9508073945951195, 0.948954141672763, 0.9461856640916962, 0.9521978490845451, 0.9491215095173713, 0.9512371237717527, 0.9523073464798528, 0.9492764682743137, 0.9482145013089952, 0.9513197867563983, 0.9500119742734472, 0.9513817659303463, 0.9529747047237844, 0.9519024138344067, 0.953586239721522, 0.953042849149118, 0.9530511528420049, 0.952456126332949, 0.9523424902441782, 0.9528052647020564, 0.9534230152321927, 0.9528238560234368, 0.9555262636871977, 0.9532660229246044, 0.9526503445715878, 0.9513611220780698, 0.9553299689426102, 0.9529085752018337, 0.9537081505333245, 0.9527557006095375, 0.9526978458106184, 0.954530428241751, 0.9544436508716818, 0.9533135175038983, 0.9526689368919288, 0.9546523184083694, 0.953920944775949, 0.9532680821152373, 0.9530346040619152, 0.9533197253775996, 0.954480845501969, 0.9514086256480084, 0.9549105863331416, 0.953309410444185, 0.9498673674114589, 0.9548610049253069, 0.9539312693659819, 0.9527866643900312, 0.9545655586866028, 0.9521937433567793, 0.9543176283383502, 0.953701957644031, 0.9538569037474733, 0.9550118116693124, 0.9550221572375165, 0.9524747189862768, 0.9543672134090402, 0.9523858884193378, 0.9533796357042963, 0.9502475151802574, 0.9526441370308733, 0.9527949707468129, 0.9521028369498652, 0.9535717731081573, 0.9546543925834101, 0.952782546674739, 0.9515511799791005, 0.9535945260990931, 0.9550820485839631, 0.9530862623086854, 0.9534064957549452, 0.9525243090517694, 0.954524224030905, 0.9549601680739632], 'val_mDice': [0.37471999019883867, 0.5276114780809626, 0.560319362738945, 0.5521516809916364, 0.5857097786232079, 0.5848091474458492, 0.5630456908455108, 0.5947273756538689, 0.5885171194316289, 0.6024006255512131, 0.5894326933935368, 0.5898618578244854, 0.6079580037953467, 0.6014522633739023, 0.6078895403686182, 0.6041027850278929, 0.6084734108194959, 0.6025482349555585, 0.5852020599322612, 0.6133325712640858, 0.5894718007002463, 0.5904066609270746, 0.607399424361117, 0.5964510720535363, 0.5934072852800678, 0.6107587784362238, 0.615553765323575, 0.6092296092869849, 0.614400035842171, 0.598163947046802, 0.590762225609252, 0.6197100664650261, 0.6102405553423492, 0.6034901421829308, 0.5987500012253916, 0.6132151001658519, 0.5915674910199042, 0.60954504405986, 0.6025945337791017, 0.6208753419322008, 0.6007674100012753, 0.5973688031042088, 0.606980957132478, 0.6098453685558042, 0.6145859850185543, 0.5900149551849792, 0.5890195036733616, 0.6091857689052986, 0.6060156569134589, 0.6214976920095902, 0.6043933303662519, 0.6070742513880384, 0.5865121493792401, 0.6100433112522743, 0.6147614600938126, 0.6131969620395639, 0.593654449758583, 0.615321742089767, 0.5943596213223548, 0.598600911694532, 0.6175940476316314, 0.6164746078033021, 0.6121607972256964, 0.6131081664362433, 0.6068879825442863, 0.610492284071512, 0.6148347245248337, 0.6135767408589411, 0.6079112730878692, 0.6165772703106843, 0.5928178606086603, 0.6167947316968907, 0.6204225077975396, 0.6142453821011762, 0.5984544204600031, 0.593349894664807, 0.5975526025175383, 0.6211163944372252, 0.6057031843915331, 0.5979245787892262], 'loss': [12113.54489379238, 3832.3661972153104, 2957.982500039624, 2579.1363896168978, 2273.9176203433376, 2094.8464565157637, 1964.8277215849087, 1870.3814082359945, 1801.367774057126, 1734.0813567019918, 1685.4479610953583, 1631.198669569885, 1595.4416390551921, 1557.3193836327466, 1523.0603881523466, 1497.6156655402947, 1465.8963584419976, 1448.800337612405, 1417.3375967514098, 1399.504436076775, 1385.488314611409, 1359.6964086529788, 1346.5866716936596, 1316.4664491232, 1315.1193531128415, 1305.270459193133, 1295.7090523344104, 1274.4797435582032, 1264.6161012231416, 1260.3778580681742, 1243.7246183369728, 1245.590851114295, 1219.1310845345922, 1215.8900572842915, 1216.057105806566, 1198.8150924666827, 1190.9590349556295, 1192.4920572688407, 1180.4225782156834, 1168.5012480909934, 1172.2381912047786, 1166.4853210000456, 1151.090637300108, 1145.5383454025664, 1142.1124491427993, 1137.5665589293053, 1144.3099431252467, 1139.1997909500192, 1124.8135543947067, 1125.049105763325, 1122.19944822437, 1115.0264979937415, 1118.8456771199878, 1108.319690247895, 1104.167127095772, 1104.830752709574, 1105.7734056810077, 1093.6885074108334, 1093.6887528179686, 1091.7468280699782, 1088.833446344164, 1093.9782805228037, 1082.7750922238852, 1084.224986894777, 1078.679342370973, 1072.0954730988171, 1071.3564089327413, 1068.8442605133248, 1066.5233234608916, 1065.1464714572603, 1060.7133798702605, 1069.7057677614332, 1062.5641366337309, 1061.2449577734183, 1048.7262283141536, 1052.4330620151493, 1048.3771117479282, 1051.4768954625506, 1047.9255110378795, 1047.5802982384964], 'acc': [0.738180626857145, 0.9013576845699169, 0.9125379181708082, 0.9274130358064131, 0.939039615428199, 0.9436371292685393, 0.9458915731900528, 0.9472119040195994, 0.9481009212066637, 0.9490045394800593, 0.9497311919007282, 0.9505703971215982, 0.951005440032675, 0.9515842729310546, 0.9520355486336126, 0.9524166926625546, 0.9528587411369454, 0.9531390340842035, 0.9537454633455404, 0.9539326572494825, 0.9541003579674227, 0.9544627078769838, 0.9546537549983546, 0.9550790671663122, 0.9550539907316556, 0.9553947879120088, 0.9555626273914838, 0.9558828810150668, 0.9559757758164664, 0.9561981605708252, 0.9564472135034862, 0.9564635287630461, 0.9567536114347857, 0.9569025976382195, 0.9569260255033872, 0.9572394485956937, 0.9573608235455593, 0.9572965705825199, 0.9575314810674542, 0.9576679037148498, 0.9576127758038329, 0.9577499622483443, 0.9581093519745904, 0.9581003040830058, 0.9582318332445764, 0.9583488563671655, 0.9583493592912975, 0.9582783193520994, 0.9585616329378386, 0.9585966799463181, 0.9586772045910757, 0.958796083268163, 0.9587818200659255, 0.9589020699322675, 0.9589835441415719, 0.95899058966639, 0.9590029602093372, 0.9591404861123803, 0.9591881810245635, 0.9592159586718617, 0.9591704983998472, 0.9593048253341683, 0.9593950582838715, 0.9594658564933017, 0.9594831373020102, 0.9595814505684811, 0.9596142593074692, 0.9596265662528677, 0.9596153284189171, 0.9597492110144241, 0.9597669151521289, 0.9596520057658693, 0.959711504403909, 0.959793158280915, 0.9599279902007454, 0.9598918119700579, 0.9599776376982438, 0.9599444448223989, 0.9599406781600949, 0.9600611237047103], 'mDice': [0.1702859687635802, 0.46418441036974484, 0.5507193393978923, 0.5939804063234952, 0.6300897970028702, 0.6529655439467622, 0.6701508807328316, 0.6831647687783903, 0.6928050642270395, 0.7023200690632688, 0.7092910165406541, 0.7169728140400928, 0.7221111798752602, 0.7277639915166509, 0.7327858086284433, 0.736799479777449, 0.7413322973936953, 0.7438957800234619, 0.7486539322088165, 0.7514394163260837, 0.7536051807908164, 0.7574845081995947, 0.7594951728052397, 0.7640702058388434, 0.7642854144939261, 0.76582288189876, 0.7673415415791227, 0.7706622913618583, 0.7721096804235361, 0.7728123880537706, 0.7754002287785061, 0.7751956549249672, 0.779187811679891, 0.7798708903751215, 0.7798827491835775, 0.7824672243348537, 0.7837275976702562, 0.7835462360845387, 0.7854826813377551, 0.7873313225670634, 0.7867507451721074, 0.7876288622177853, 0.7900585127671517, 0.7910747153717061, 0.7915222922134202, 0.7922910100675786, 0.7913025675188202, 0.7920105489833469, 0.794332732231579, 0.794366396328546, 0.7948180462279018, 0.7959291426569709, 0.7953596985370633, 0.7970086537144503, 0.7976364940055919, 0.7976563204724858, 0.797476046018225, 0.7994535241561495, 0.7993734331667524, 0.7997303019518635, 0.8002091243982405, 0.799405183980917, 0.8011875312628683, 0.8009798262745302, 0.8018309832541202, 0.802926586705429, 0.8030541299325787, 0.8034692135201801, 0.8038135060271461, 0.8041095359900258, 0.8048148894126909, 0.803335839305774, 0.8044772171505422, 0.8047706206297668, 0.8066637777281018, 0.8062128911291837, 0.8067972979983968, 0.806325864781482, 0.8068697564184169, 0.8070260805798267]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.70s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.54s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.33s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:19,  1.97s/it]predicting train subjects:   1%|          | 2/285 [00:04<09:23,  1.99s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:09,  1.95s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<09:23,  2.00s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:51,  1.90s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<09:10,  1.97s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<09:53,  2.14s/it]predicting train subjects:   3%|▎         | 8/285 [00:16<10:00,  2.17s/it]predicting train subjects:   3%|▎         | 9/285 [00:18<09:40,  2.10s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<10:09,  2.22s/it]predicting train subjects:   4%|▍         | 11/285 [00:23<10:22,  2.27s/it]predicting train subjects:   4%|▍         | 12/285 [00:25<10:46,  2.37s/it]predicting train subjects:   5%|▍         | 13/285 [00:28<11:24,  2.52s/it]predicting train subjects:   5%|▍         | 14/285 [00:31<11:50,  2.62s/it]predicting train subjects:   5%|▌         | 15/285 [00:34<11:50,  2.63s/it]predicting train subjects:   6%|▌         | 16/285 [00:36<11:33,  2.58s/it]predicting train subjects:   6%|▌         | 17/285 [00:39<11:24,  2.56s/it]predicting train subjects:   6%|▋         | 18/285 [00:41<11:25,  2.57s/it]predicting train subjects:   7%|▋         | 19/285 [00:44<11:30,  2.59s/it]predicting train subjects:   7%|▋         | 20/285 [00:47<11:21,  2.57s/it]predicting train subjects:   7%|▋         | 21/285 [00:49<11:17,  2.57s/it]predicting train subjects:   8%|▊         | 22/285 [00:52<11:06,  2.53s/it]predicting train subjects:   8%|▊         | 23/285 [00:54<10:45,  2.47s/it]predicting train subjects:   8%|▊         | 24/285 [00:57<11:02,  2.54s/it]predicting train subjects:   9%|▉         | 25/285 [00:59<11:05,  2.56s/it]predicting train subjects:   9%|▉         | 26/285 [01:02<10:43,  2.49s/it]predicting train subjects:   9%|▉         | 27/285 [01:04<10:42,  2.49s/it]predicting train subjects:  10%|▉         | 28/285 [01:06<10:19,  2.41s/it]predicting train subjects:  10%|█         | 29/285 [01:08<09:46,  2.29s/it]predicting train subjects:  11%|█         | 30/285 [01:10<09:20,  2.20s/it]predicting train subjects:  11%|█         | 31/285 [01:12<09:06,  2.15s/it]predicting train subjects:  11%|█         | 32/285 [01:14<09:01,  2.14s/it]predicting train subjects:  12%|█▏        | 33/285 [01:16<08:51,  2.11s/it]predicting train subjects:  12%|█▏        | 34/285 [01:19<09:03,  2.16s/it]predicting train subjects:  12%|█▏        | 35/285 [01:21<08:46,  2.11s/it]predicting train subjects:  13%|█▎        | 36/285 [01:23<08:32,  2.06s/it]predicting train subjects:  13%|█▎        | 37/285 [01:25<08:27,  2.05s/it]predicting train subjects:  13%|█▎        | 38/285 [01:27<08:18,  2.02s/it]predicting train subjects:  14%|█▎        | 39/285 [01:29<08:09,  1.99s/it]predicting train subjects:  14%|█▍        | 40/285 [01:31<08:05,  1.98s/it]predicting train subjects:  14%|█▍        | 41/285 [01:33<08:04,  1.99s/it]predicting train subjects:  15%|█▍        | 42/285 [01:35<08:04,  1.99s/it]predicting train subjects:  15%|█▌        | 43/285 [01:37<08:07,  2.01s/it]predicting train subjects:  15%|█▌        | 44/285 [01:39<07:59,  1.99s/it]predicting train subjects:  16%|█▌        | 45/285 [01:40<07:56,  1.98s/it]predicting train subjects:  16%|█▌        | 46/285 [01:42<07:40,  1.93s/it]predicting train subjects:  16%|█▋        | 47/285 [01:44<07:33,  1.91s/it]predicting train subjects:  17%|█▋        | 48/285 [01:46<07:24,  1.88s/it]predicting train subjects:  17%|█▋        | 49/285 [01:48<07:18,  1.86s/it]predicting train subjects:  18%|█▊        | 50/285 [01:50<07:11,  1.84s/it]predicting train subjects:  18%|█▊        | 51/285 [01:51<07:03,  1.81s/it]predicting train subjects:  18%|█▊        | 52/285 [01:53<07:06,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:55<07:04,  1.83s/it]predicting train subjects:  19%|█▉        | 54/285 [01:57<06:56,  1.81s/it]predicting train subjects:  19%|█▉        | 55/285 [01:59<06:53,  1.80s/it]predicting train subjects:  20%|█▉        | 56/285 [02:00<06:57,  1.82s/it]predicting train subjects:  20%|██        | 57/285 [02:02<07:11,  1.89s/it]predicting train subjects:  20%|██        | 58/285 [02:04<07:16,  1.92s/it]predicting train subjects:  21%|██        | 59/285 [02:06<07:08,  1.90s/it]predicting train subjects:  21%|██        | 60/285 [02:08<06:58,  1.86s/it]predicting train subjects:  21%|██▏       | 61/285 [02:10<06:56,  1.86s/it]predicting train subjects:  22%|██▏       | 62/285 [02:12<06:58,  1.88s/it]predicting train subjects:  22%|██▏       | 63/285 [02:14<06:47,  1.84s/it]predicting train subjects:  22%|██▏       | 64/285 [02:16<06:51,  1.86s/it]predicting train subjects:  23%|██▎       | 65/285 [02:18<07:05,  1.93s/it]predicting train subjects:  23%|██▎       | 66/285 [02:20<07:12,  1.97s/it]predicting train subjects:  24%|██▎       | 67/285 [02:22<07:06,  1.96s/it]predicting train subjects:  24%|██▍       | 68/285 [02:24<07:02,  1.95s/it]predicting train subjects:  24%|██▍       | 69/285 [02:25<06:53,  1.91s/it]predicting train subjects:  25%|██▍       | 70/285 [02:27<06:52,  1.92s/it]predicting train subjects:  25%|██▍       | 71/285 [02:29<06:57,  1.95s/it]predicting train subjects:  25%|██▌       | 72/285 [02:31<06:52,  1.94s/it]predicting train subjects:  26%|██▌       | 73/285 [02:33<06:53,  1.95s/it]predicting train subjects:  26%|██▌       | 74/285 [02:35<06:56,  1.98s/it]predicting train subjects:  26%|██▋       | 75/285 [02:37<06:56,  1.98s/it]predicting train subjects:  27%|██▋       | 76/285 [02:39<07:00,  2.01s/it]predicting train subjects:  27%|██▋       | 77/285 [02:41<06:48,  1.97s/it]predicting train subjects:  27%|██▋       | 78/285 [02:43<06:38,  1.93s/it]predicting train subjects:  28%|██▊       | 79/285 [02:45<06:36,  1.92s/it]predicting train subjects:  28%|██▊       | 80/285 [02:47<06:29,  1.90s/it]predicting train subjects:  28%|██▊       | 81/285 [02:49<06:25,  1.89s/it]predicting train subjects:  29%|██▉       | 82/285 [02:50<06:21,  1.88s/it]predicting train subjects:  29%|██▉       | 83/285 [02:52<06:19,  1.88s/it]predicting train subjects:  29%|██▉       | 84/285 [02:54<06:20,  1.89s/it]predicting train subjects:  30%|██▉       | 85/285 [02:57<06:39,  2.00s/it]predicting train subjects:  30%|███       | 86/285 [02:59<06:38,  2.00s/it]predicting train subjects:  31%|███       | 87/285 [03:01<06:44,  2.04s/it]predicting train subjects:  31%|███       | 88/285 [03:03<06:40,  2.03s/it]predicting train subjects:  31%|███       | 89/285 [03:05<06:38,  2.03s/it]predicting train subjects:  32%|███▏      | 90/285 [03:07<06:40,  2.05s/it]predicting train subjects:  32%|███▏      | 91/285 [03:09<06:50,  2.12s/it]predicting train subjects:  32%|███▏      | 92/285 [03:11<06:49,  2.12s/it]predicting train subjects:  33%|███▎      | 93/285 [03:13<06:50,  2.14s/it]predicting train subjects:  33%|███▎      | 94/285 [03:15<06:42,  2.11s/it]predicting train subjects:  33%|███▎      | 95/285 [03:17<06:36,  2.09s/it]predicting train subjects:  34%|███▎      | 96/285 [03:20<06:32,  2.08s/it]predicting train subjects:  34%|███▍      | 97/285 [03:22<06:26,  2.06s/it]predicting train subjects:  34%|███▍      | 98/285 [03:24<06:24,  2.06s/it]predicting train subjects:  35%|███▍      | 99/285 [03:26<06:23,  2.06s/it]predicting train subjects:  35%|███▌      | 100/285 [03:28<06:18,  2.05s/it]predicting train subjects:  35%|███▌      | 101/285 [03:30<06:14,  2.04s/it]predicting train subjects:  36%|███▌      | 102/285 [03:32<06:23,  2.09s/it]predicting train subjects:  36%|███▌      | 103/285 [03:34<06:17,  2.07s/it]predicting train subjects:  36%|███▋      | 104/285 [03:36<06:11,  2.05s/it]predicting train subjects:  37%|███▋      | 105/285 [03:38<06:12,  2.07s/it]predicting train subjects:  37%|███▋      | 106/285 [03:40<06:09,  2.06s/it]predicting train subjects:  38%|███▊      | 107/285 [03:42<06:06,  2.06s/it]predicting train subjects:  38%|███▊      | 108/285 [03:44<06:04,  2.06s/it]predicting train subjects:  38%|███▊      | 109/285 [03:46<06:02,  2.06s/it]predicting train subjects:  39%|███▊      | 110/285 [03:48<05:59,  2.05s/it]predicting train subjects:  39%|███▉      | 111/285 [03:50<05:55,  2.04s/it]predicting train subjects:  39%|███▉      | 112/285 [03:52<05:55,  2.05s/it]predicting train subjects:  40%|███▉      | 113/285 [03:54<05:51,  2.04s/it]predicting train subjects:  40%|████      | 114/285 [03:57<05:56,  2.08s/it]predicting train subjects:  40%|████      | 115/285 [03:59<05:51,  2.07s/it]predicting train subjects:  41%|████      | 116/285 [04:01<05:48,  2.06s/it]predicting train subjects:  41%|████      | 117/285 [04:03<05:46,  2.06s/it]predicting train subjects:  41%|████▏     | 118/285 [04:05<05:42,  2.05s/it]predicting train subjects:  42%|████▏     | 119/285 [04:07<05:39,  2.04s/it]predicting train subjects:  42%|████▏     | 120/285 [04:09<05:35,  2.03s/it]predicting train subjects:  42%|████▏     | 121/285 [04:11<05:24,  1.98s/it]predicting train subjects:  43%|████▎     | 122/285 [04:12<05:07,  1.88s/it]predicting train subjects:  43%|████▎     | 123/285 [04:14<04:52,  1.81s/it]predicting train subjects:  44%|████▎     | 124/285 [04:16<04:50,  1.81s/it]predicting train subjects:  44%|████▍     | 125/285 [04:18<04:49,  1.81s/it]predicting train subjects:  44%|████▍     | 126/285 [04:19<04:49,  1.82s/it]predicting train subjects:  45%|████▍     | 127/285 [04:21<04:49,  1.83s/it]predicting train subjects:  45%|████▍     | 128/285 [04:23<04:44,  1.81s/it]predicting train subjects:  45%|████▌     | 129/285 [04:25<04:46,  1.83s/it]predicting train subjects:  46%|████▌     | 130/285 [04:27<04:39,  1.80s/it]predicting train subjects:  46%|████▌     | 131/285 [04:28<04:39,  1.81s/it]predicting train subjects:  46%|████▋     | 132/285 [04:30<04:36,  1.81s/it]predicting train subjects:  47%|████▋     | 133/285 [04:32<04:37,  1.83s/it]predicting train subjects:  47%|████▋     | 134/285 [04:34<04:41,  1.86s/it]predicting train subjects:  47%|████▋     | 135/285 [04:36<04:44,  1.90s/it]predicting train subjects:  48%|████▊     | 136/285 [04:38<04:42,  1.90s/it]predicting train subjects:  48%|████▊     | 137/285 [04:40<04:41,  1.90s/it]predicting train subjects:  48%|████▊     | 138/285 [04:42<04:39,  1.90s/it]predicting train subjects:  49%|████▉     | 139/285 [04:44<04:38,  1.91s/it]predicting train subjects:  49%|████▉     | 140/285 [04:46<04:33,  1.89s/it]predicting train subjects:  49%|████▉     | 141/285 [04:47<04:32,  1.89s/it]predicting train subjects:  50%|████▉     | 142/285 [04:49<04:24,  1.85s/it]predicting train subjects:  50%|█████     | 143/285 [04:51<04:16,  1.81s/it]predicting train subjects:  51%|█████     | 144/285 [04:53<04:11,  1.78s/it]predicting train subjects:  51%|█████     | 145/285 [04:54<04:05,  1.75s/it]predicting train subjects:  51%|█████     | 146/285 [04:56<04:01,  1.74s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:58<03:57,  1.72s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:59<03:54,  1.71s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:01<03:55,  1.73s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:03<03:53,  1.73s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:05<03:48,  1.71s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:06<03:47,  1.71s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:08<03:47,  1.72s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:10<03:41,  1.69s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:11<03:39,  1.69s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:13<03:39,  1.70s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:15<03:40,  1.72s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:16<03:36,  1.71s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:18<03:38,  1.73s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:20<03:34,  1.71s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:22<03:27,  1.68s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:23<03:26,  1.68s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:25<03:28,  1.71s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:27<03:24,  1.69s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:28<03:19,  1.67s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:30<03:15,  1.64s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:31<03:12,  1.63s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:33<03:11,  1.64s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:35<03:10,  1.64s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:36<03:06,  1.62s/it]predicting train subjects:  60%|██████    | 171/285 [05:38<03:09,  1.66s/it]predicting train subjects:  60%|██████    | 172/285 [05:40<03:08,  1.67s/it]predicting train subjects:  61%|██████    | 173/285 [05:41<03:04,  1.65s/it]predicting train subjects:  61%|██████    | 174/285 [05:43<03:01,  1.64s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:45<03:01,  1.65s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:46<03:02,  1.67s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:48<02:58,  1.65s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:50<02:54,  1.63s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:51<02:53,  1.64s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:53<02:52,  1.64s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:54<02:48,  1.62s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:56<02:48,  1.63s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:58<02:47,  1.64s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:59<02:46,  1.65s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:01<02:43,  1.64s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:03<02:38,  1.60s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:04<02:37,  1.61s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:06<02:35,  1.61s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:07<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:09<02:31,  1.60s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:11<02:30,  1.60s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:12<02:28,  1.60s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:14<02:28,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:15<02:26,  1.61s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:17<02:24,  1.60s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:19<02:30,  1.69s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:21<02:34,  1.75s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:23<02:35,  1.79s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:25<02:35,  1.81s/it]predicting train subjects:  70%|███████   | 200/285 [06:27<02:37,  1.85s/it]predicting train subjects:  71%|███████   | 201/285 [06:28<02:37,  1.88s/it]predicting train subjects:  71%|███████   | 202/285 [06:30<02:34,  1.86s/it]predicting train subjects:  71%|███████   | 203/285 [06:32<02:32,  1.86s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:34<02:30,  1.86s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:36<02:30,  1.88s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:38<02:29,  1.89s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:40<02:27,  1.90s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:42<02:25,  1.89s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:44<02:25,  1.91s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:45<02:22,  1.91s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:47<02:20,  1.90s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:49<02:21,  1.94s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:51<02:22,  1.98s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:53<02:14,  1.89s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:55<02:07,  1.82s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:56<02:01,  1.76s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:58<01:59,  1.76s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:00<01:55,  1.73s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:02<01:54,  1.74s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:03<01:52,  1.72s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:05<01:48,  1.70s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:07<01:46,  1.68s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:08<01:43,  1.66s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:10<01:42,  1.69s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:12<01:42,  1.71s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:13<01:41,  1.71s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:15<01:38,  1.70s/it]predicting train subjects:  80%|████████  | 228/285 [07:17<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [07:18<01:34,  1.70s/it]predicting train subjects:  81%|████████  | 230/285 [07:20<01:31,  1.67s/it]predicting train subjects:  81%|████████  | 231/285 [07:22<01:30,  1.67s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:24<01:35,  1.80s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:26<01:39,  1.92s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:28<01:39,  1.95s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:30<01:40,  2.01s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:32<01:39,  2.02s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:34<01:36,  2.01s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:36<01:35,  2.02s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:38<01:33,  2.03s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:40<01:30,  2.02s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:42<01:28,  2.01s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:44<01:26,  2.01s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:46<01:23,  1.99s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:48<01:21,  1.99s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:50<01:19,  1.98s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:52<01:17,  1.98s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:54<01:15,  1.98s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:56<01:13,  1.98s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:58<01:11,  1.99s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:00<01:06,  1.89s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:02<01:02,  1.83s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:03<00:57,  1.75s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:05<00:54,  1.70s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:06<00:52,  1.70s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:08<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:10<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [08:11<00:46,  1.68s/it]predicting train subjects:  91%|█████████ | 258/285 [08:13<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [08:15<00:42,  1.64s/it]predicting train subjects:  91%|█████████ | 260/285 [08:16<00:40,  1.64s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:18<00:39,  1.63s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:19<00:37,  1.63s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:21<00:35,  1.62s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:23<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:24<00:32,  1.60s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:26<00:30,  1.59s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:27<00:29,  1.61s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:30<00:29,  1.76s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:32<00:29,  1.85s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:34<00:29,  1.95s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:36<00:27,  2.00s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:38<00:26,  2.04s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:40<00:24,  2.05s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:42<00:22,  2.06s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:44<00:20,  2.06s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:46<00:18,  2.06s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:48<00:16,  2.07s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:51<00:14,  2.12s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:53<00:12,  2.11s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:55<00:10,  2.10s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:57<00:08,  2.12s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:59<00:06,  2.13s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:01<00:04,  2.12s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:03<00:02,  2.08s/it]predicting train subjects: 100%|██████████| 285/285 [09:05<00:00,  2.07s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:24,  1.35s/it]Loading train:   1%|          | 2/285 [00:02<06:36,  1.40s/it]Loading train:   1%|          | 3/285 [00:04<06:27,  1.37s/it]Loading train:   1%|▏         | 4/285 [00:05<06:52,  1.47s/it]Loading train:   2%|▏         | 5/285 [00:07<06:39,  1.43s/it]Loading train:   2%|▏         | 6/285 [00:09<07:36,  1.64s/it]Loading train:   2%|▏         | 7/285 [00:11<07:48,  1.68s/it]Loading train:   3%|▎         | 8/285 [00:12<07:50,  1.70s/it]Loading train:   3%|▎         | 9/285 [00:14<07:24,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<06:55,  1.51s/it]Loading train:   4%|▍         | 11/285 [00:16<06:24,  1.40s/it]Loading train:   4%|▍         | 12/285 [00:17<05:55,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:18<05:36,  1.24s/it]Loading train:   5%|▍         | 14/285 [00:20<05:31,  1.22s/it]Loading train:   5%|▌         | 15/285 [00:21<05:19,  1.18s/it]Loading train:   6%|▌         | 16/285 [00:22<05:13,  1.16s/it]Loading train:   6%|▌         | 17/285 [00:23<05:02,  1.13s/it]Loading train:   6%|▋         | 18/285 [00:24<05:02,  1.13s/it]Loading train:   7%|▋         | 19/285 [00:25<05:05,  1.15s/it]Loading train:   7%|▋         | 20/285 [00:26<05:12,  1.18s/it]Loading train:   7%|▋         | 21/285 [00:28<05:26,  1.24s/it]Loading train:   8%|▊         | 22/285 [00:29<05:15,  1.20s/it]Loading train:   8%|▊         | 23/285 [00:30<05:11,  1.19s/it]Loading train:   8%|▊         | 24/285 [00:31<05:14,  1.21s/it]Loading train:   9%|▉         | 25/285 [00:33<05:20,  1.23s/it]Loading train:   9%|▉         | 26/285 [00:34<05:07,  1.19s/it]Loading train:   9%|▉         | 27/285 [00:35<05:00,  1.17s/it]Loading train:  10%|▉         | 28/285 [00:36<04:59,  1.17s/it]Loading train:  10%|█         | 29/285 [00:37<04:59,  1.17s/it]Loading train:  11%|█         | 30/285 [00:38<04:46,  1.12s/it]Loading train:  11%|█         | 31/285 [00:39<04:44,  1.12s/it]Loading train:  11%|█         | 32/285 [00:40<04:45,  1.13s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:51,  1.16s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:37,  1.11s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:39,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:40,  1.13s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:28,  1.08s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:36,  1.12s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:23,  1.07s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:18,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:17,  1.05s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:21,  1.08s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:22,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:22,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:18,  1.08s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:35,  1.15s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:25,  1.12s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:18,  1.09s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:03,  1.03s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:00,  1.02s/it]Loading train:  18%|█▊        | 51/285 [01:01<03:56,  1.01s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:00,  1.03s/it]Loading train:  19%|█▊        | 53/285 [01:03<03:51,  1.00it/s]Loading train:  19%|█▉        | 54/285 [01:04<03:58,  1.03s/it]Loading train:  19%|█▉        | 55/285 [01:05<03:53,  1.02s/it]Loading train:  20%|█▉        | 56/285 [01:06<03:57,  1.04s/it]Loading train:  20%|██        | 57/285 [01:07<03:45,  1.01it/s]Loading train:  20%|██        | 58/285 [01:08<04:07,  1.09s/it]Loading train:  21%|██        | 59/285 [01:09<04:08,  1.10s/it]Loading train:  21%|██        | 60/285 [01:10<03:56,  1.05s/it]Loading train:  21%|██▏       | 61/285 [01:11<04:00,  1.07s/it]Loading train:  22%|██▏       | 62/285 [01:12<03:52,  1.04s/it]Loading train:  22%|██▏       | 63/285 [01:13<03:51,  1.04s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:29,  1.22s/it]Loading train:  23%|██▎       | 65/285 [01:17<04:56,  1.35s/it]Loading train:  23%|██▎       | 66/285 [01:18<05:01,  1.38s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:43,  1.30s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:23,  1.22s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:04,  1.13s/it]Loading train:  25%|██▍       | 70/285 [01:22<03:52,  1.08s/it]Loading train:  25%|██▍       | 71/285 [01:23<03:42,  1.04s/it]Loading train:  25%|██▌       | 72/285 [01:24<03:51,  1.09s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:51,  1.09s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:43,  1.06s/it]Loading train:  26%|██▋       | 75/285 [01:27<03:44,  1.07s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:33,  1.02s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:27,  1.00it/s]Loading train:  27%|██▋       | 78/285 [01:30<03:36,  1.05s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:30,  1.02s/it]Loading train:  28%|██▊       | 80/285 [01:32<03:29,  1.02s/it]Loading train:  28%|██▊       | 81/285 [01:34<03:33,  1.05s/it]Loading train:  29%|██▉       | 82/285 [01:34<03:26,  1.02s/it]Loading train:  29%|██▉       | 83/285 [01:35<03:20,  1.01it/s]Loading train:  29%|██▉       | 84/285 [01:36<03:15,  1.03it/s]Loading train:  30%|██▉       | 85/285 [01:38<03:48,  1.14s/it]Loading train:  30%|███       | 86/285 [01:39<03:44,  1.13s/it]Loading train:  31%|███       | 87/285 [01:40<03:46,  1.14s/it]Loading train:  31%|███       | 88/285 [01:41<03:41,  1.13s/it]Loading train:  31%|███       | 89/285 [01:43<03:52,  1.19s/it]Loading train:  32%|███▏      | 90/285 [01:44<03:41,  1.14s/it]Loading train:  32%|███▏      | 91/285 [01:45<03:45,  1.16s/it]Loading train:  32%|███▏      | 92/285 [01:46<03:41,  1.15s/it]Loading train:  33%|███▎      | 93/285 [01:47<03:39,  1.14s/it]Loading train:  33%|███▎      | 94/285 [01:48<03:30,  1.10s/it]Loading train:  33%|███▎      | 95/285 [01:49<03:22,  1.07s/it]Loading train:  34%|███▎      | 96/285 [01:50<03:21,  1.06s/it]Loading train:  34%|███▍      | 97/285 [01:51<03:19,  1.06s/it]Loading train:  34%|███▍      | 98/285 [01:52<03:13,  1.04s/it]Loading train:  35%|███▍      | 99/285 [01:53<03:18,  1.07s/it]Loading train:  35%|███▌      | 100/285 [01:54<03:14,  1.05s/it]Loading train:  35%|███▌      | 101/285 [01:55<03:17,  1.07s/it]Loading train:  36%|███▌      | 102/285 [01:56<03:15,  1.07s/it]Loading train:  36%|███▌      | 103/285 [01:58<03:20,  1.10s/it]Loading train:  36%|███▋      | 104/285 [01:59<03:23,  1.12s/it]Loading train:  37%|███▋      | 105/285 [02:00<03:17,  1.10s/it]Loading train:  37%|███▋      | 106/285 [02:01<03:12,  1.08s/it]Loading train:  38%|███▊      | 107/285 [02:02<03:09,  1.07s/it]Loading train:  38%|███▊      | 108/285 [02:03<03:07,  1.06s/it]Loading train:  38%|███▊      | 109/285 [02:04<02:58,  1.02s/it]Loading train:  39%|███▊      | 110/285 [02:05<03:00,  1.03s/it]Loading train:  39%|███▉      | 111/285 [02:06<02:56,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:07<03:05,  1.08s/it]Loading train:  40%|███▉      | 113/285 [02:08<03:04,  1.07s/it]Loading train:  40%|████      | 114/285 [02:09<03:10,  1.12s/it]Loading train:  40%|████      | 115/285 [02:11<03:20,  1.18s/it]Loading train:  41%|████      | 116/285 [02:12<03:17,  1.17s/it]Loading train:  41%|████      | 117/285 [02:13<03:09,  1.13s/it]Loading train:  41%|████▏     | 118/285 [02:14<03:15,  1.17s/it]Loading train:  42%|████▏     | 119/285 [02:15<03:10,  1.15s/it]Loading train:  42%|████▏     | 120/285 [02:16<03:10,  1.16s/it]Loading train:  42%|████▏     | 121/285 [02:18<03:20,  1.22s/it]Loading train:  43%|████▎     | 122/285 [02:19<03:21,  1.24s/it]Loading train:  43%|████▎     | 123/285 [02:20<03:26,  1.28s/it]Loading train:  44%|████▎     | 124/285 [02:21<03:08,  1.17s/it]Loading train:  44%|████▍     | 125/285 [02:22<02:54,  1.09s/it]Loading train:  44%|████▍     | 126/285 [02:23<02:45,  1.04s/it]Loading train:  45%|████▍     | 127/285 [02:24<02:37,  1.00it/s]Loading train:  45%|████▍     | 128/285 [02:25<02:40,  1.02s/it]Loading train:  45%|████▌     | 129/285 [02:26<02:33,  1.01it/s]Loading train:  46%|████▌     | 130/285 [02:27<02:30,  1.03it/s]Loading train:  46%|████▌     | 131/285 [02:28<02:32,  1.01it/s]Loading train:  46%|████▋     | 132/285 [02:29<02:28,  1.03it/s]Loading train:  47%|████▋     | 133/285 [02:30<02:28,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:31<02:23,  1.05it/s]Loading train:  47%|████▋     | 135/285 [02:32<02:31,  1.01s/it]Loading train:  48%|████▊     | 136/285 [02:33<02:31,  1.02s/it]Loading train:  48%|████▊     | 137/285 [02:34<02:35,  1.05s/it]Loading train:  48%|████▊     | 138/285 [02:35<02:29,  1.02s/it]Loading train:  49%|████▉     | 139/285 [02:36<02:28,  1.02s/it]Loading train:  49%|████▉     | 140/285 [02:37<02:23,  1.01it/s]Loading train:  49%|████▉     | 141/285 [02:38<02:19,  1.03it/s]Loading train:  50%|████▉     | 142/285 [02:39<02:28,  1.04s/it]Loading train:  50%|█████     | 143/285 [02:40<02:19,  1.02it/s]Loading train:  51%|█████     | 144/285 [02:41<02:17,  1.03it/s]Loading train:  51%|█████     | 145/285 [02:42<02:20,  1.00s/it]Loading train:  51%|█████     | 146/285 [02:43<02:15,  1.03it/s]Loading train:  52%|█████▏    | 147/285 [02:44<02:19,  1.01s/it]Loading train:  52%|█████▏    | 148/285 [02:45<02:13,  1.02it/s]Loading train:  52%|█████▏    | 149/285 [02:46<02:10,  1.04it/s]Loading train:  53%|█████▎    | 150/285 [02:47<02:05,  1.07it/s]Loading train:  53%|█████▎    | 151/285 [02:48<02:04,  1.08it/s]Loading train:  53%|█████▎    | 152/285 [02:48<01:58,  1.12it/s]Loading train:  54%|█████▎    | 153/285 [02:49<01:58,  1.12it/s]Loading train:  54%|█████▍    | 154/285 [02:50<01:58,  1.10it/s]Loading train:  54%|█████▍    | 155/285 [02:51<02:00,  1.08it/s]Loading train:  55%|█████▍    | 156/285 [02:52<01:59,  1.08it/s]Loading train:  55%|█████▌    | 157/285 [02:53<01:55,  1.11it/s]Loading train:  55%|█████▌    | 158/285 [02:54<01:54,  1.11it/s]Loading train:  56%|█████▌    | 159/285 [02:55<02:00,  1.05it/s]Loading train:  56%|█████▌    | 160/285 [02:56<01:55,  1.08it/s]Loading train:  56%|█████▋    | 161/285 [02:57<01:57,  1.05it/s]Loading train:  57%|█████▋    | 162/285 [02:58<01:59,  1.03it/s]Loading train:  57%|█████▋    | 163/285 [02:59<01:55,  1.06it/s]Loading train:  58%|█████▊    | 164/285 [03:00<01:58,  1.02it/s]Loading train:  58%|█████▊    | 165/285 [03:01<01:53,  1.06it/s]Loading train:  58%|█████▊    | 166/285 [03:02<01:50,  1.08it/s]Loading train:  59%|█████▊    | 167/285 [03:02<01:45,  1.11it/s]Loading train:  59%|█████▉    | 168/285 [03:03<01:45,  1.11it/s]Loading train:  59%|█████▉    | 169/285 [03:04<01:41,  1.15it/s]Loading train:  60%|█████▉    | 170/285 [03:05<01:38,  1.17it/s]Loading train:  60%|██████    | 171/285 [03:06<01:43,  1.10it/s]Loading train:  60%|██████    | 172/285 [03:07<01:40,  1.12it/s]Loading train:  61%|██████    | 173/285 [03:08<01:41,  1.10it/s]Loading train:  61%|██████    | 174/285 [03:09<01:42,  1.08it/s]Loading train:  61%|██████▏   | 175/285 [03:10<01:43,  1.06it/s]Loading train:  62%|██████▏   | 176/285 [03:11<01:40,  1.08it/s]Loading train:  62%|██████▏   | 177/285 [03:12<01:39,  1.08it/s]Loading train:  62%|██████▏   | 178/285 [03:12<01:35,  1.12it/s]Loading train:  63%|██████▎   | 179/285 [03:13<01:30,  1.17it/s]Loading train:  63%|██████▎   | 180/285 [03:14<01:29,  1.17it/s]Loading train:  64%|██████▎   | 181/285 [03:15<01:28,  1.17it/s]Loading train:  64%|██████▍   | 182/285 [03:16<01:28,  1.16it/s]Loading train:  64%|██████▍   | 183/285 [03:17<01:26,  1.18it/s]Loading train:  65%|██████▍   | 184/285 [03:17<01:24,  1.20it/s]Loading train:  65%|██████▍   | 185/285 [03:18<01:27,  1.14it/s]Loading train:  65%|██████▌   | 186/285 [03:19<01:25,  1.16it/s]Loading train:  66%|██████▌   | 187/285 [03:20<01:24,  1.16it/s]Loading train:  66%|██████▌   | 188/285 [03:21<01:24,  1.15it/s]Loading train:  66%|██████▋   | 189/285 [03:22<01:27,  1.09it/s]Loading train:  67%|██████▋   | 190/285 [03:23<01:35,  1.00s/it]Loading train:  67%|██████▋   | 191/285 [03:24<01:31,  1.02it/s]Loading train:  67%|██████▋   | 192/285 [03:25<01:33,  1.00s/it]Loading train:  68%|██████▊   | 193/285 [03:26<01:28,  1.04it/s]Loading train:  68%|██████▊   | 194/285 [03:27<01:30,  1.01it/s]Loading train:  68%|██████▊   | 195/285 [03:28<01:34,  1.05s/it]Loading train:  69%|██████▉   | 196/285 [03:29<01:38,  1.10s/it]Loading train:  69%|██████▉   | 197/285 [03:31<01:41,  1.15s/it]Loading train:  69%|██████▉   | 198/285 [03:32<01:38,  1.13s/it]Loading train:  70%|██████▉   | 199/285 [03:33<01:37,  1.14s/it]Loading train:  70%|███████   | 200/285 [03:34<01:44,  1.23s/it]Loading train:  71%|███████   | 201/285 [03:35<01:38,  1.17s/it]Loading train:  71%|███████   | 202/285 [03:37<01:35,  1.14s/it]Loading train:  71%|███████   | 203/285 [03:38<01:34,  1.16s/it]Loading train:  72%|███████▏  | 204/285 [03:39<01:39,  1.23s/it]Loading train:  72%|███████▏  | 205/285 [03:40<01:40,  1.26s/it]Loading train:  72%|███████▏  | 206/285 [03:42<01:36,  1.22s/it]Loading train:  73%|███████▎  | 207/285 [03:43<01:31,  1.17s/it]Loading train:  73%|███████▎  | 208/285 [03:44<01:27,  1.14s/it]Loading train:  73%|███████▎  | 209/285 [03:45<01:28,  1.17s/it]Loading train:  74%|███████▎  | 210/285 [03:46<01:27,  1.16s/it]Loading train:  74%|███████▍  | 211/285 [03:47<01:27,  1.18s/it]Loading train:  74%|███████▍  | 212/285 [03:49<01:29,  1.22s/it]Loading train:  75%|███████▍  | 213/285 [03:50<01:29,  1.25s/it]Loading train:  75%|███████▌  | 214/285 [03:51<01:27,  1.24s/it]Loading train:  75%|███████▌  | 215/285 [03:52<01:22,  1.18s/it]Loading train:  76%|███████▌  | 216/285 [03:53<01:15,  1.09s/it]Loading train:  76%|███████▌  | 217/285 [03:54<01:15,  1.11s/it]Loading train:  76%|███████▋  | 218/285 [03:55<01:12,  1.08s/it]Loading train:  77%|███████▋  | 219/285 [03:56<01:11,  1.08s/it]Loading train:  77%|███████▋  | 220/285 [03:57<01:11,  1.11s/it]Loading train:  78%|███████▊  | 221/285 [03:59<01:11,  1.12s/it]Loading train:  78%|███████▊  | 222/285 [04:00<01:08,  1.09s/it]Loading train:  78%|███████▊  | 223/285 [04:01<01:13,  1.18s/it]Loading train:  79%|███████▊  | 224/285 [04:02<01:14,  1.22s/it]Loading train:  79%|███████▉  | 225/285 [04:03<01:10,  1.18s/it]Loading train:  79%|███████▉  | 226/285 [04:05<01:08,  1.17s/it]Loading train:  80%|███████▉  | 227/285 [04:06<01:08,  1.19s/it]Loading train:  80%|████████  | 228/285 [04:07<01:05,  1.16s/it]Loading train:  80%|████████  | 229/285 [04:08<01:03,  1.13s/it]Loading train:  81%|████████  | 230/285 [04:09<01:00,  1.11s/it]Loading train:  81%|████████  | 231/285 [04:10<00:56,  1.05s/it]Loading train:  81%|████████▏ | 232/285 [04:11<00:58,  1.11s/it]Loading train:  82%|████████▏ | 233/285 [04:13<01:02,  1.19s/it]Loading train:  82%|████████▏ | 234/285 [04:14<01:02,  1.23s/it]Loading train:  82%|████████▏ | 235/285 [04:15<01:02,  1.26s/it]Loading train:  83%|████████▎ | 236/285 [04:17<01:03,  1.30s/it]Loading train:  83%|████████▎ | 237/285 [04:18<01:02,  1.31s/it]Loading train:  84%|████████▎ | 238/285 [04:19<00:58,  1.25s/it]Loading train:  84%|████████▍ | 239/285 [04:21<01:02,  1.35s/it]Loading train:  84%|████████▍ | 240/285 [04:22<01:01,  1.36s/it]Loading train:  85%|████████▍ | 241/285 [04:23<00:59,  1.35s/it]Loading train:  85%|████████▍ | 242/285 [04:25<00:56,  1.31s/it]Loading train:  85%|████████▌ | 243/285 [04:26<00:53,  1.27s/it]Loading train:  86%|████████▌ | 244/285 [04:27<00:50,  1.23s/it]Loading train:  86%|████████▌ | 245/285 [04:28<00:48,  1.21s/it]Loading train:  86%|████████▋ | 246/285 [04:30<00:50,  1.30s/it]Loading train:  87%|████████▋ | 247/285 [04:31<00:47,  1.26s/it]Loading train:  87%|████████▋ | 248/285 [04:32<00:49,  1.34s/it]Loading train:  87%|████████▋ | 249/285 [04:34<00:50,  1.40s/it]Loading train:  88%|████████▊ | 250/285 [04:35<00:46,  1.32s/it]Loading train:  88%|████████▊ | 251/285 [04:36<00:42,  1.25s/it]Loading train:  88%|████████▊ | 252/285 [04:37<00:41,  1.27s/it]Loading train:  89%|████████▉ | 253/285 [04:38<00:38,  1.21s/it]Loading train:  89%|████████▉ | 254/285 [04:39<00:36,  1.17s/it]Loading train:  89%|████████▉ | 255/285 [04:40<00:33,  1.12s/it]Loading train:  90%|████████▉ | 256/285 [04:42<00:32,  1.13s/it]Loading train:  90%|█████████ | 257/285 [04:43<00:31,  1.11s/it]Loading train:  91%|█████████ | 258/285 [04:44<00:31,  1.16s/it]Loading train:  91%|█████████ | 259/285 [04:45<00:29,  1.15s/it]Loading train:  91%|█████████ | 260/285 [04:46<00:29,  1.17s/it]Loading train:  92%|█████████▏| 261/285 [04:47<00:26,  1.12s/it]Loading train:  92%|█████████▏| 262/285 [04:48<00:25,  1.11s/it]Loading train:  92%|█████████▏| 263/285 [04:49<00:23,  1.07s/it]Loading train:  93%|█████████▎| 264/285 [04:51<00:24,  1.19s/it]Loading train:  93%|█████████▎| 265/285 [04:52<00:22,  1.14s/it]Loading train:  93%|█████████▎| 266/285 [04:53<00:21,  1.13s/it]Loading train:  94%|█████████▎| 267/285 [04:54<00:20,  1.15s/it]Loading train:  94%|█████████▍| 268/285 [04:56<00:22,  1.31s/it]Loading train:  94%|█████████▍| 269/285 [04:57<00:21,  1.35s/it]Loading train:  95%|█████████▍| 270/285 [04:58<00:19,  1.30s/it]Loading train:  95%|█████████▌| 271/285 [05:00<00:17,  1.27s/it]Loading train:  95%|█████████▌| 272/285 [05:01<00:16,  1.26s/it]Loading train:  96%|█████████▌| 273/285 [05:02<00:15,  1.27s/it]Loading train:  96%|█████████▌| 274/285 [05:04<00:14,  1.33s/it]Loading train:  96%|█████████▋| 275/285 [05:05<00:13,  1.32s/it]Loading train:  97%|█████████▋| 276/285 [05:06<00:11,  1.31s/it]Loading train:  97%|█████████▋| 277/285 [05:08<00:11,  1.40s/it]Loading train:  98%|█████████▊| 278/285 [05:09<00:09,  1.42s/it]Loading train:  98%|█████████▊| 279/285 [05:10<00:08,  1.34s/it]Loading train:  98%|█████████▊| 280/285 [05:12<00:06,  1.29s/it]Loading train:  99%|█████████▊| 281/285 [05:13<00:05,  1.28s/it]Loading train:  99%|█████████▉| 282/285 [05:14<00:04,  1.35s/it]Loading train:  99%|█████████▉| 283/285 [05:16<00:02,  1.33s/it]Loading train: 100%|█████████▉| 284/285 [05:17<00:01,  1.27s/it]Loading train: 100%|██████████| 285/285 [05:18<00:00,  1.24s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:03, 84.50it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:03, 85.78it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:02, 92.47it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:02, 93.05it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:02, 91.00it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:02, 98.20it/s]concatenating: train:  27%|██▋       | 76/285 [00:00<00:02, 103.07it/s]concatenating: train:  31%|███       | 89/285 [00:00<00:01, 107.60it/s]concatenating: train:  36%|███▌      | 102/285 [00:00<00:01, 111.94it/s]concatenating: train:  40%|████      | 114/285 [00:01<00:01, 101.91it/s]concatenating: train:  44%|████▍     | 125/285 [00:01<00:01, 101.75it/s]concatenating: train:  48%|████▊     | 136/285 [00:01<00:01, 88.19it/s] concatenating: train:  51%|█████     | 146/285 [00:01<00:01, 79.17it/s]concatenating: train:  54%|█████▍    | 155/285 [00:01<00:01, 69.32it/s]concatenating: train:  57%|█████▋    | 163/285 [00:01<00:01, 71.35it/s]concatenating: train:  60%|██████    | 171/285 [00:01<00:01, 64.23it/s]concatenating: train:  62%|██████▏   | 178/285 [00:02<00:01, 57.72it/s]concatenating: train:  66%|██████▋   | 189/285 [00:02<00:01, 67.27it/s]concatenating: train:  69%|██████▉   | 197/285 [00:02<00:01, 66.48it/s]concatenating: train:  73%|███████▎  | 207/285 [00:02<00:01, 73.85it/s]concatenating: train:  76%|███████▌  | 216/285 [00:02<00:00, 72.83it/s]concatenating: train:  79%|███████▉  | 225/285 [00:02<00:00, 76.38it/s]concatenating: train:  82%|████████▏ | 234/285 [00:02<00:00, 73.08it/s]concatenating: train:  85%|████████▍ | 242/285 [00:02<00:00, 67.44it/s]concatenating: train:  88%|████████▊ | 250/285 [00:03<00:00, 65.86it/s]concatenating: train:  90%|█████████ | 257/285 [00:03<00:00, 60.72it/s]concatenating: train:  93%|█████████▎| 264/285 [00:03<00:00, 57.10it/s]concatenating: train:  95%|█████████▌| 271/285 [00:03<00:00, 58.62it/s]concatenating: train:  98%|█████████▊| 278/285 [00:03<00:00, 59.72it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 55.86it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.72s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.66s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.61s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 65.51it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 30)   0           batch_normalization_7[0][0]      2019-07-08 11:44:15.930374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 11:44:15.930527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 11:44:15.930549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 11:44:15.930563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 11:44:15.931002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 20s - loss: 24671.8289 - acc: 0.6499 - mDice: 0.0831 - val_loss: 13547.8020 - val_acc: 0.8738 - val_mDice: 0.1806

Epoch 00001: val_mDice improved from -inf to 0.18057, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 10463.8675 - acc: 0.8769 - mDice: 0.2711 - val_loss: 11770.6044 - val_acc: 0.8984 - val_mDice: 0.2214

Epoch 00002: val_mDice improved from 0.18057 to 0.22143, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 6931.6951 - acc: 0.8873 - mDice: 0.4036 - val_loss: 7004.1506 - val_acc: 0.9065 - val_mDice: 0.3772

Epoch 00003: val_mDice improved from 0.22143 to 0.37722, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 5401.5773 - acc: 0.8936 - mDice: 0.4902 - val_loss: 5162.7262 - val_acc: 0.9186 - val_mDice: 0.4907

Epoch 00004: val_mDice improved from 0.37722 to 0.49074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 4598.1093 - acc: 0.9028 - mDice: 0.5451 - val_loss: 4776.8479 - val_acc: 0.9302 - val_mDice: 0.5143

Epoch 00005: val_mDice improved from 0.49074 to 0.51432, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 4132.2581 - acc: 0.9133 - mDice: 0.5793 - val_loss: 5016.3815 - val_acc: 0.9345 - val_mDice: 0.4976

Epoch 00006: val_mDice did not improve from 0.51432
Epoch 7/300
 - 10s - loss: 3824.9219 - acc: 0.9234 - mDice: 0.6032 - val_loss: 4532.7580 - val_acc: 0.9380 - val_mDice: 0.5318

Epoch 00007: val_mDice improved from 0.51432 to 0.53178, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 9s - loss: 3566.0159 - acc: 0.9310 - mDice: 0.6238 - val_loss: 4261.6283 - val_acc: 0.9360 - val_mDice: 0.5513

Epoch 00008: val_mDice improved from 0.53178 to 0.55126, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 3415.3686 - acc: 0.9347 - mDice: 0.6360 - val_loss: 4286.4369 - val_acc: 0.9325 - val_mDice: 0.5479

Epoch 00009: val_mDice did not improve from 0.55126
Epoch 10/300
 - 9s - loss: 3248.4044 - acc: 0.9369 - mDice: 0.6499 - val_loss: 4555.0206 - val_acc: 0.9347 - val_mDice: 0.5307

Epoch 00010: val_mDice did not improve from 0.55126
Epoch 11/300
 - 9s - loss: 3145.8853 - acc: 0.9380 - mDice: 0.6589 - val_loss: 4311.2758 - val_acc: 0.9328 - val_mDice: 0.5459

Epoch 00011: val_mDice did not improve from 0.55126
Epoch 12/300
 - 9s - loss: 3016.5700 - acc: 0.9395 - mDice: 0.6701 - val_loss: 4524.1604 - val_acc: 0.9297 - val_mDice: 0.5309

Epoch 00012: val_mDice did not improve from 0.55126
Epoch 13/300
 - 9s - loss: 2925.0049 - acc: 0.9405 - mDice: 0.6781 - val_loss: 4389.3145 - val_acc: 0.9307 - val_mDice: 0.5433

Epoch 00013: val_mDice did not improve from 0.55126
Epoch 14/300
 - 9s - loss: 2851.5449 - acc: 0.9411 - mDice: 0.6848 - val_loss: 4219.6216 - val_acc: 0.9361 - val_mDice: 0.5544

Epoch 00014: val_mDice improved from 0.55126 to 0.55441, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 10s - loss: 2783.5919 - acc: 0.9417 - mDice: 0.6909 - val_loss: 4928.0475 - val_acc: 0.9381 - val_mDice: 0.5096

Epoch 00015: val_mDice did not improve from 0.55441
Epoch 16/300
 - 9s - loss: 2725.0297 - acc: 0.9424 - mDice: 0.6962 - val_loss: 4425.0368 - val_acc: 0.9296 - val_mDice: 0.5388

Epoch 00016: val_mDice did not improve from 0.55441
Epoch 17/300
 - 9s - loss: 2644.9207 - acc: 0.9432 - mDice: 0.7033 - val_loss: 4636.7584 - val_acc: 0.9384 - val_mDice: 0.5242

Epoch 00017: val_mDice did not improve from 0.55441
Epoch 18/300
 - 9s - loss: 2618.5274 - acc: 0.9436 - mDice: 0.7059 - val_loss: 4559.7185 - val_acc: 0.9420 - val_mDice: 0.5331

Epoch 00018: val_mDice did not improve from 0.55441
Epoch 19/300
 - 9s - loss: 2563.8911 - acc: 0.9440 - mDice: 0.7110 - val_loss: 4416.6161 - val_acc: 0.9352 - val_mDice: 0.5383

Epoch 00019: val_mDice did not improve from 0.55441
Epoch 20/300
 - 9s - loss: 2517.4694 - acc: 0.9444 - mDice: 0.7153 - val_loss: 4723.4401 - val_acc: 0.9337 - val_mDice: 0.5205

Epoch 00020: val_mDice did not improve from 0.55441
Epoch 21/300
 - 9s - loss: 2489.1423 - acc: 0.9448 - mDice: 0.7181 - val_loss: 4208.8483 - val_acc: 0.9387 - val_mDice: 0.5545

Epoch 00021: val_mDice improved from 0.55441 to 0.55446, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 9s - loss: 2449.0246 - acc: 0.9451 - mDice: 0.7218 - val_loss: 4348.8520 - val_acc: 0.9353 - val_mDice: 0.5460

Epoch 00022: val_mDice did not improve from 0.55446
Epoch 23/300
 - 9s - loss: 2415.5853 - acc: 0.9455 - mDice: 0.7249 - val_loss: 4153.8246 - val_acc: 0.9359 - val_mDice: 0.5602

Epoch 00023: val_mDice improved from 0.55446 to 0.56022, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 10s - loss: 2381.3923 - acc: 0.9458 - mDice: 0.7283 - val_loss: 4818.2606 - val_acc: 0.9315 - val_mDice: 0.5153

Epoch 00024: val_mDice did not improve from 0.56022
Epoch 25/300
 - 9s - loss: 2330.2452 - acc: 0.9464 - mDice: 0.7332 - val_loss: 4503.4210 - val_acc: 0.9395 - val_mDice: 0.5371

Epoch 00025: val_mDice did not improve from 0.56022
Epoch 26/300
 - 9s - loss: 2331.7733 - acc: 0.9463 - mDice: 0.7331 - val_loss: 4585.0351 - val_acc: 0.9410 - val_mDice: 0.5305

Epoch 00026: val_mDice did not improve from 0.56022
Epoch 27/300
 - 9s - loss: 2283.1530 - acc: 0.9469 - mDice: 0.7378 - val_loss: 4143.8158 - val_acc: 0.9380 - val_mDice: 0.5598

Epoch 00027: val_mDice did not improve from 0.56022
Epoch 28/300
 - 9s - loss: 2255.9362 - acc: 0.9472 - mDice: 0.7406 - val_loss: 4907.5418 - val_acc: 0.9378 - val_mDice: 0.5122

Epoch 00028: val_mDice did not improve from 0.56022
Epoch 29/300
 - 9s - loss: 2232.8904 - acc: 0.9473 - mDice: 0.7427 - val_loss: 4268.9324 - val_acc: 0.9389 - val_mDice: 0.5505

Epoch 00029: val_mDice did not improve from 0.56022
Epoch 30/300
 - 9s - loss: 2216.7812 - acc: 0.9475 - mDice: 0.7443 - val_loss: 4499.1021 - val_acc: 0.9381 - val_mDice: 0.5361

Epoch 00030: val_mDice did not improve from 0.56022
Epoch 31/300
 - 9s - loss: 2203.1739 - acc: 0.9475 - mDice: 0.7457 - val_loss: 4227.3082 - val_acc: 0.9393 - val_mDice: 0.5528

Epoch 00031: val_mDice did not improve from 0.56022
Epoch 32/300
 - 9s - loss: 2166.5181 - acc: 0.9478 - mDice: 0.7493 - val_loss: 4204.8041 - val_acc: 0.9359 - val_mDice: 0.5555

Epoch 00032: val_mDice did not improve from 0.56022
Epoch 33/300
 - 9s - loss: 2159.4620 - acc: 0.9481 - mDice: 0.7501 - val_loss: 4366.6264 - val_acc: 0.9403 - val_mDice: 0.5488

Epoch 00033: val_mDice did not improve from 0.56022
Epoch 34/300
 - 9s - loss: 2141.9855 - acc: 0.9482 - mDice: 0.7518 - val_loss: 4217.5708 - val_acc: 0.9410 - val_mDice: 0.5557

Epoch 00034: val_mDice did not improve from 0.56022
Epoch 35/300
 - 10s - loss: 2106.4805 - acc: 0.9485 - mDice: 0.7554 - val_loss: 4222.3540 - val_acc: 0.9400 - val_mDice: 0.5560

Epoch 00035: val_mDice did not improve from 0.56022
Epoch 36/300
 - 9s - loss: 2099.8655 - acc: 0.9486 - mDice: 0.7560 - val_loss: 4295.4717 - val_acc: 0.9378 - val_mDice: 0.5481

Epoch 00036: val_mDice did not improve from 0.56022
Epoch 37/300
 - 9s - loss: 2081.5342 - acc: 0.9486 - mDice: 0.7579 - val_loss: 4373.0939 - val_acc: 0.9420 - val_mDice: 0.5464

Epoch 00037: val_mDice did not improve from 0.56022
Epoch 38/300
 - 9s - loss: 2066.3503 - acc: 0.9489 - mDice: 0.7595 - val_loss: 4842.6562 - val_acc: 0.9331 - val_mDice: 0.5153

Epoch 00038: val_mDice did not improve from 0.56022
Epoch 39/300
 - 9s - loss: 2071.3723 - acc: 0.9488 - mDice: 0.7590 - val_loss: 4279.4182 - val_acc: 0.9409 - val_mDice: 0.5517

Epoch 00039: val_mDice did not improve from 0.56022
Epoch 40/300
 - 9s - loss: 2039.4138 - acc: 0.9492 - mDice: 0.7622 - val_loss: 4768.1817 - val_acc: 0.9371 - val_mDice: 0.5194

Epoch 00040: val_mDice did not improve from 0.56022
Epoch 41/300
 - 9s - loss: 2029.7350 - acc: 0.9492 - mDice: 0.7632 - val_loss: 4518.6565 - val_acc: 0.9410 - val_mDice: 0.5350

Epoch 00041: val_mDice did not improve from 0.56022
Epoch 42/300
 - 9s - loss: 2017.6125 - acc: 0.9493 - mDice: 0.7644 - val_loss: 4212.6350 - val_acc: 0.9436 - val_mDice: 0.5544

Epoch 00042: val_mDice did not improve from 0.56022
Epoch 43/300
 - 9s - loss: 2018.4514 - acc: 0.9492 - mDice: 0.7643 - val_loss: 4806.7739 - val_acc: 0.9383 - val_mDice: 0.5297

Epoch 00043: val_mDice did not improve from 0.56022
Epoch 44/300
 - 9s - loss: 1994.6497 - acc: 0.9497 - mDice: 0.7668 - val_loss: 4153.4814 - val_acc: 0.9435 - val_mDice: 0.5597

Epoch 00044: val_mDice did not improve from 0.56022
Epoch 45/300
 - 9s - loss: 1991.4438 - acc: 0.9496 - mDice: 0.7671 - val_loss: 4237.6546 - val_acc: 0.9421 - val_mDice: 0.5548

Epoch 00045: val_mDice did not improve from 0.56022
Epoch 46/300
 - 9s - loss: 1963.3264 - acc: 0.9498 - mDice: 0.7700 - val_loss: 4352.5606 - val_acc: 0.9436 - val_mDice: 0.5465

Epoch 00046: val_mDice did not improve from 0.56022
Epoch 47/300
 - 9s - loss: 1952.9603 - acc: 0.9501 - mDice: 0.7710 - val_loss: 4153.7486 - val_acc: 0.9405 - val_mDice: 0.5605

Epoch 00047: val_mDice improved from 0.56022 to 0.56053, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 48/300
 - 9s - loss: 1952.0699 - acc: 0.9501 - mDice: 0.7712 - val_loss: 4250.0405 - val_acc: 0.9405 - val_mDice: 0.5568

Epoch 00048: val_mDice did not improve from 0.56053
Epoch 49/300
 - 10s - loss: 1955.1061 - acc: 0.9500 - mDice: 0.7709 - val_loss: 4089.0272 - val_acc: 0.9429 - val_mDice: 0.5658

Epoch 00049: val_mDice improved from 0.56053 to 0.56579, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 50/300
 - 9s - loss: 1942.5470 - acc: 0.9502 - mDice: 0.7721 - val_loss: 4241.9922 - val_acc: 0.9430 - val_mDice: 0.5551

Epoch 00050: val_mDice did not improve from 0.56579
Epoch 51/300
 - 9s - loss: 1909.2922 - acc: 0.9504 - mDice: 0.7756 - val_loss: 4010.0885 - val_acc: 0.9398 - val_mDice: 0.5706

Epoch 00051: val_mDice improved from 0.56579 to 0.57056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 52/300
 - 9s - loss: 1913.1799 - acc: 0.9504 - mDice: 0.7752 - val_loss: 4511.5695 - val_acc: 0.9392 - val_mDice: 0.5388

Epoch 00052: val_mDice did not improve from 0.57056
Epoch 53/300
 - 9s - loss: 1901.6285 - acc: 0.9506 - mDice: 0.7763 - val_loss: 4036.7227 - val_acc: 0.9433 - val_mDice: 0.5688

Epoch 00053: val_mDice did not improve from 0.57056
Epoch 54/300
 - 9s - loss: 1892.8231 - acc: 0.9508 - mDice: 0.7772 - val_loss: 3995.7123 - val_acc: 0.9436 - val_mDice: 0.5715

Epoch 00054: val_mDice improved from 0.57056 to 0.57153, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 55/300
 - 9s - loss: 1878.7692 - acc: 0.9509 - mDice: 0.7787 - val_loss: 4057.8876 - val_acc: 0.9411 - val_mDice: 0.5668

Epoch 00055: val_mDice did not improve from 0.57153
Epoch 56/300
 - 9s - loss: 1890.3049 - acc: 0.9508 - mDice: 0.7775 - val_loss: 4148.0569 - val_acc: 0.9428 - val_mDice: 0.5608

Epoch 00056: val_mDice did not improve from 0.57153
Epoch 57/300
 - 9s - loss: 1871.0431 - acc: 0.9511 - mDice: 0.7795 - val_loss: 5698.0652 - val_acc: 0.9318 - val_mDice: 0.4907

Epoch 00057: val_mDice did not improve from 0.57153
Epoch 58/300
 - 9s - loss: 1873.3662 - acc: 0.9510 - mDice: 0.7793 - val_loss: 4242.2790 - val_acc: 0.9419 - val_mDice: 0.5575

Epoch 00058: val_mDice did not improve from 0.57153
Epoch 59/300
 - 9s - loss: 1865.9430 - acc: 0.9512 - mDice: 0.7801 - val_loss: 4434.7313 - val_acc: 0.9386 - val_mDice: 0.5418

Epoch 00059: val_mDice did not improve from 0.57153
Epoch 60/300
 - 9s - loss: 1855.5411 - acc: 0.9513 - mDice: 0.7811 - val_loss: 4590.3574 - val_acc: 0.9434 - val_mDice: 0.5340

Epoch 00060: val_mDice did not improve from 0.57153
Epoch 61/300
 - 9s - loss: 1838.3824 - acc: 0.9513 - mDice: 0.7829 - val_loss: 4532.8742 - val_acc: 0.9389 - val_mDice: 0.5345

Epoch 00061: val_mDice did not improve from 0.57153
Epoch 62/300
 - 9s - loss: 1841.8015 - acc: 0.9513 - mDice: 0.7825 - val_loss: 4262.9547 - val_acc: 0.9401 - val_mDice: 0.5532

Epoch 00062: val_mDice did not improve from 0.57153
Epoch 63/300
 - 9s - loss: 1842.6383 - acc: 0.9513 - mDice: 0.7824 - val_loss: 3996.1652 - val_acc: 0.9440 - val_mDice: 0.5730

Epoch 00063: val_mDice improved from 0.57153 to 0.57300, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 64/300
 - 9s - loss: 1822.5904 - acc: 0.9515 - mDice: 0.7845 - val_loss: 4143.2192 - val_acc: 0.9428 - val_mDice: 0.5625

Epoch 00064: val_mDice did not improve from 0.57300
Epoch 65/300
 - 9s - loss: 1828.6274 - acc: 0.9515 - mDice: 0.7839 - val_loss: 4192.5077 - val_acc: 0.9433 - val_mDice: 0.5569

Epoch 00065: val_mDice did not improve from 0.57300
Epoch 66/300
 - 9s - loss: 1819.8256 - acc: 0.9514 - mDice: 0.7848 - val_loss: 4481.3481 - val_acc: 0.9415 - val_mDice: 0.5388

Epoch 00066: val_mDice did not improve from 0.57300
Epoch 67/300
 - 9s - loss: 1810.1408 - acc: 0.9513 - mDice: 0.7858 - val_loss: 4568.9513 - val_acc: 0.9428 - val_mDice: 0.5341

Epoch 00067: val_mDice did not improve from 0.57300
Epoch 68/300
 - 10s - loss: 1812.3436 - acc: 0.9514 - mDice: 0.7856 - val_loss: 4219.6295 - val_acc: 0.9445 - val_mDice: 0.5560

Epoch 00068: val_mDice did not improve from 0.57300
Epoch 69/300
 - 9s - loss: 1788.7443 - acc: 0.9517 - mDice: 0.7880 - val_loss: 4177.8017 - val_acc: 0.9444 - val_mDice: 0.5590

Epoch 00069: val_mDice did not improve from 0.57300
Epoch 70/300
 - 9s - loss: 1802.0297 - acc: 0.9515 - mDice: 0.7867 - val_loss: 4288.8141 - val_acc: 0.9428 - val_mDice: 0.5531

Epoch 00070: val_mDice did not improve from 0.57300
Epoch 71/300
 - 9s - loss: 1782.9377 - acc: 0.9516 - mDice: 0.7886 - val_loss: 4459.1220 - val_acc: 0.9360 - val_mDice: 0.5408

Epoch 00071: val_mDice did not improve from 0.57300
Epoch 72/300
 - 9s - loss: 1785.7454 - acc: 0.9517 - mDice: 0.7884 - val_loss: 4366.0943 - val_acc: 0.9407 - val_mDice: 0.5495

Epoch 00072: val_mDice did not improve from 0.57300
Epoch 73/300
 - 9s - loss: 1776.1632 - acc: 0.9518 - mDice: 0.7893 - val_loss: 4244.2805 - val_acc: 0.9422 - val_mDice: 0.5540

Epoch 00073: val_mDice did not improve from 0.57300
Epoch 74/300
 - 9s - loss: 1764.8383 - acc: 0.9520 - mDice: 0.7906 - val_loss: 4486.4974 - val_acc: 0.9426 - val_mDice: 0.5453

Epoch 00074: val_mDice did not improve from 0.57300
Epoch 75/300
 - 9s - loss: 1770.1780 - acc: 0.9518 - mDice: 0.7899 - val_loss: 4364.4064 - val_acc: 0.9412 - val_mDice: 0.5494

Epoch 00075: val_mDice did not improve from 0.57300
Epoch 76/300
 - 9s - loss: 1765.6733 - acc: 0.9519 - mDice: 0.7905 - val_loss: 4122.7786 - val_acc: 0.9433 - val_mDice: 0.5615

Epoch 00076: val_mDice did not improve from 0.57300
Epoch 77/300
 - 9s - loss: 1751.6870 - acc: 0.9522 - mDice: 0.7919 - val_loss: 4531.8078 - val_acc: 0.9418 - val_mDice: 0.5354

Epoch 00077: val_mDice did not improve from 0.57300
Epoch 78/300
 - 9s - loss: 1758.5788 - acc: 0.9520 - mDice: 0.7912 - val_loss: 4120.0627 - val_acc: 0.9430 - val_mDice: 0.5612

Epoch 00078: val_mDice did not improve from 0.57300
Epoch 79/300
 - 9s - loss: 1761.9492 - acc: 0.9520 - mDice: 0.7909 - val_loss: 4239.8276 - val_acc: 0.9411 - val_mDice: 0.5525

Epoch 00079: val_mDice did not improve from 0.57300
Epoch 80/300
 - 9s - loss: 1738.5780 - acc: 0.9522 - mDice: 0.7933 - val_loss: 4550.6255 - val_acc: 0.9412 - val_mDice: 0.5371

Epoch 00080: val_mDice did not improve from 0.57300
Epoch 81/300
 - 9s - loss: 1743.0596 - acc: 0.9522 - mDice: 0.7929 - val_loss: 4230.0361 - val_acc: 0.9434 - val_mDice: 0.5576

Epoch 00081: val_mDice did not improve from 0.57300
Epoch 82/300
 - 9s - loss: 1742.5010 - acc: 0.9523 - mDice: 0.7928 - val_loss: 4121.6265 - val_acc: 0.9446 - val_mDice: 0.5629

Epoch 00082: val_mDice did not improve from 0.57300
Epoch 83/300
 - 9s - loss: 1735.9310 - acc: 0.9524 - mDice: 0.7936 - val_loss: 4142.4858 - val_acc: 0.9428 - val_mDice: 0.5610

Epoch 00083: val_mDice did not improve from 0.57300
Epoch 84/300
 - 9s - loss: 1734.9840 - acc: 0.9524 - mDice: 0.7937 - val_loss: 4107.0140 - val_acc: 0.9471 - val_mDice: 0.5646

Epoch 00084: val_mDice did not improve from 0.57300
Epoch 85/300
 - 9s - loss: 1727.6833 - acc: 0.9524 - mDice: 0.7944 - val_loss: 4200.9992 - val_acc: 0.9424 - val_mDice: 0.5543

Epoch 00085: val_mDice did not improve from 0.57300
Epoch 86/300
 - 9s - loss: 1719.2898 - acc: 0.9526 - mDice: 0.7953 - val_loss: 4309.8741 - val_acc: 0.9412 - val_mDice: 0.5483

Epoch 00086: val_mDice did not improve from 0.57300
Epoch 87/300
 - 9s - loss: 1717.8089 - acc: 0.9525 - mDice: 0.7955 - val_loss: 4466.7001 - val_acc: 0.9433 - val_mDice: 0.5374

Epoch 00087: val_mDice did not improve from 0.57300
Epoch 88/300
 - 9s - loss: 1713.2834 - acc: 0.9527 - mDice: 0.7960 - val_loss: 4490.6823 - val_acc: 0.9359 - val_mDice: 0.5358

Epoch 00088: val_mDice did not improve from 0.57300
Epoch 89/300
 - 9s - loss: 1706.3027 - acc: 0.9527 - mDice: 0.7967 - val_loss: 4674.3007 - val_acc: 0.9407 - val_mDice: 0.5296

Epoch 00089: val_mDice did not improve from 0.57300
Epoch 90/300
 - 9s - loss: 1709.4040 - acc: 0.9528 - mDice: 0.7964 - val_loss: 4192.8949 - val_acc: 0.9452 - val_mDice: 0.5604

Epoch 00090: val_mDice did not improve from 0.57300
Epoch 91/300
 - 9s - loss: 1705.9808 - acc: 0.9528 - mDice: 0.7967 - val_loss: 4564.2581 - val_acc: 0.9421 - val_mDice: 0.5385

Epoch 00091: val_mDice did not improve from 0.57300
Epoch 92/300
 - 9s - loss: 1702.8823 - acc: 0.9528 - mDice: 0.7970 - val_loss: 4914.2649 - val_acc: 0.9346 - val_mDice: 0.5128

Epoch 00092: val_mDice did not improve from 0.57300
Epoch 93/300
 - 9s - loss: 1687.0716 - acc: 0.9530 - mDice: 0.7987 - val_loss: 4268.4129 - val_acc: 0.9407 - val_mDice: 0.5512

Epoch 00093: val_mDice did not improve from 0.57300
Restoring model weights from the end of the best epoch
Epoch 00093: early stopping
{'val_loss': [13547.802011343148, 11770.604417067309, 7004.1505784254805, 5162.726186899038, 4776.847872220553, 5016.381544846755, 4532.757972130408, 4261.628333458533, 4286.436908428485, 4555.020620492788, 4311.275813176082, 4524.160353440505, 4389.314518855168, 4219.62158203125, 4928.047466571515, 4425.036799504207, 4636.758366511418, 4559.718477689303, 4416.616145207332, 4723.440101036658, 4208.848341721755, 4348.852022611178, 4153.824594350962, 4818.260629507212, 4503.420973557692, 4585.035128079928, 4143.815767728365, 4907.541813777043, 4268.932363656851, 4499.102069561298, 4227.308218149038, 4204.804086538462, 4366.626361553485, 4217.570819561298, 4222.353994516226, 4295.471651517428, 4373.0939378004805, 4842.656212439904, 4279.418161245493, 4768.181711050181, 4518.6564706655645, 4212.635023850661, 4806.77392578125, 4153.481360802283, 4237.654649000901, 4352.5606360802285, 4153.74858210637, 4250.040475698618, 4089.0271982046274, 4241.992220365084, 4010.0885385366587, 4511.569509652944, 4036.722736065204, 3995.7123413085938, 4057.8875779371997, 4148.056917630709, 5698.065239539514, 4242.2789963942305, 4434.731318547176, 4590.357393704928, 4532.874183067908, 4262.9547447791465, 3996.1652080829326, 4143.219196026142, 4192.507685734676, 4481.34809758113, 4568.95131272536, 4219.6294508713945, 4177.801682692308, 4288.8141197791465, 4459.121995192308, 4366.0942946213945, 4244.280498798077, 4486.497382530799, 4364.406423715444, 4122.7785879281855, 4531.807814378005, 4120.062725360577, 4239.8276132436895, 4550.625483586238, 4230.036118727464, 4121.626544658954, 4142.485811673678, 4107.014047475962, 4200.999187762921, 4309.874060997596, 4466.700115497296, 4490.6823331392725, 4674.300682654748, 4192.894902155949, 4564.258131760817, 4914.264878493089, 4268.412902832031], 'val_acc': [0.8737934529781342, 0.8984236144102536, 0.9065435391206008, 0.9186367415464841, 0.9301590323448181, 0.9345252307561728, 0.9379507051064417, 0.9360091411150419, 0.9324565277649806, 0.9346870298569019, 0.932757013119184, 0.9297129122110513, 0.9306582579245934, 0.9360715884428757, 0.9381402295369369, 0.9296089296157544, 0.9383967977303725, 0.9419863820075989, 0.9352140243236835, 0.9336792780802801, 0.9386741862847254, 0.9353342400147364, 0.9359167218208313, 0.9314811275555537, 0.9394924342632294, 0.9410133293041816, 0.9380085239043603, 0.9378097217816573, 0.9389145924494817, 0.9381241018955524, 0.9393444749025198, 0.9359166828485636, 0.940280584188608, 0.9409809823219593, 0.9399801194667816, 0.9378398014948919, 0.9419586704327509, 0.9330967962741852, 0.9409347153626956, 0.9371140209528116, 0.9410295073802655, 0.9436367337520306, 0.9382558235755334, 0.9434749415287604, 0.9421297059609339, 0.9435558479565841, 0.940539504473026, 0.9405394907181079, 0.9428970767901494, 0.9430403801111075, 0.9398067868672885, 0.9392242729663849, 0.943292322067114, 0.94361133988087, 0.941091911150859, 0.9427769138262823, 0.9317978001557864, 0.9418708269412701, 0.9386325822426722, 0.9434171525331644, 0.9388799231785995, 0.9400887626868027, 0.9440042766240927, 0.942800019796078, 0.9433362713226905, 0.9414617167069361, 0.9427838577673986, 0.9445266012962048, 0.9443833461174598, 0.9427792108975924, 0.9359513406570141, 0.9406735392717215, 0.942226801927273, 0.9426173980419452, 0.9411589136490455, 0.9433246919741998, 0.9418246195866511, 0.9430288649522341, 0.941135837481572, 0.941163569688797, 0.9433801838984857, 0.9446445176234612, 0.9427861456687634, 0.9470969163454496, 0.942390882051908, 0.9411890071171981, 0.9432553465549762, 0.9359444609055152, 0.9406619668006897, 0.9451761062328632, 0.9421066022836245, 0.9346223106751075, 0.9406920304665198], 'val_mDice': [0.18056919884223205, 0.2214337014234983, 0.37721748277544975, 0.49073531851172447, 0.5143184593090644, 0.49757246042673403, 0.5317781286743971, 0.5512601326291378, 0.5478973950331028, 0.5307448423252656, 0.5459465705431424, 0.5309397297409865, 0.5432804166697539, 0.5544102174731401, 0.5095684009675796, 0.5387828725461776, 0.5242224903060839, 0.5330631646972436, 0.5382903688229047, 0.5204909294843674, 0.5544572567137388, 0.5460231579267062, 0.5602196265871708, 0.5153383360459254, 0.537101115171726, 0.5305463769114934, 0.5597890816055812, 0.512188276132712, 0.5504678576611556, 0.5361336314907441, 0.5528479238542227, 0.5554914915790925, 0.54877025863299, 0.5557299711956427, 0.5560144077126796, 0.5481155652266282, 0.5463820466628442, 0.5152533234885106, 0.5516775124348127, 0.5194348621253784, 0.5349747315049171, 0.5543727229994077, 0.5297176929620596, 0.5596873038090192, 0.5547873028195821, 0.5465449083309907, 0.5605259996194106, 0.5568207903550222, 0.5657874259811181, 0.5551210664785825, 0.5705629048439173, 0.5387776021200877, 0.5687586994698415, 0.5715318880975246, 0.5668125611085159, 0.560766288294242, 0.4907069962758284, 0.5575384170963213, 0.5418408994491284, 0.5339591543261821, 0.5345242914672081, 0.5532443428841921, 0.5729957334697247, 0.5625303760170937, 0.5568698088710125, 0.5387952339190704, 0.5340658638339776, 0.5559636022035892, 0.5589765310287476, 0.5531467875609031, 0.5407789057263961, 0.5494895399763033, 0.5540408996435312, 0.5452911658928945, 0.5493776878485312, 0.5614518895745277, 0.5354005998143783, 0.5612047910690308, 0.5525261461734772, 0.537104281095358, 0.5576006506498044, 0.5628735254017206, 0.5609920580799763, 0.5646138039345925, 0.5542953091745193, 0.5483253254340246, 0.5373669412846749, 0.5357609666310824, 0.5295630151835772, 0.5603975842778499, 0.538544105222592, 0.5127861494055161, 0.55115412404904], 'loss': [24671.82890490805, 10463.867531746611, 6931.695122465243, 5401.577344506536, 4598.109256509726, 4132.258097946165, 3824.9219230828467, 3566.0158883805184, 3415.368570419406, 3248.4044288973696, 3145.88526345302, 3016.569951220059, 2925.0049322913364, 2851.544894304199, 2783.5919157255294, 2725.029673758506, 2644.9206969646316, 2618.527415058066, 2563.8910942214843, 2517.469440699789, 2489.142250979264, 2449.0245877956977, 2415.585308764151, 2381.3922776832005, 2330.24517507605, 2331.7733312246382, 2283.1530120407733, 2255.9361902800015, 2232.89044352131, 2216.7812280413036, 2203.173857131194, 2166.518055182041, 2159.461983512999, 2141.9855386645527, 2106.4805311135983, 2099.8655497111113, 2081.5342183868174, 2066.3502760052206, 2071.3723392263173, 2039.413800250909, 2029.7349726187833, 2017.6124672978103, 2018.451393229467, 1994.6497151178594, 1991.4438447066584, 1963.3264238061495, 1952.9602746018006, 1952.069910927737, 1955.1060752119292, 1942.5469707604057, 1909.2922297534628, 1913.1799031466694, 1901.62849383067, 1892.8230589807094, 1878.7692119567077, 1890.3049024599325, 1871.0431433331755, 1873.3661992573423, 1865.9430314637216, 1855.5410588443976, 1838.3824214708384, 1841.8015431340173, 1842.6383488102833, 1822.5904417346678, 1828.6273627917528, 1819.8256393892786, 1810.1408069852994, 1812.3436120728181, 1788.7443485430638, 1802.0297290858643, 1782.9376973524465, 1785.74541851868, 1776.163152511584, 1764.8382823803015, 1770.178049108809, 1765.6732752398132, 1751.6869897037636, 1758.5788485224393, 1761.9491806135818, 1738.5780011227812, 1743.0596157722364, 1742.5009782962295, 1735.9309836597579, 1734.9839650236527, 1727.6832793595595, 1719.2897914769321, 1717.8088884952597, 1713.2834139813974, 1706.302655681697, 1709.4039637175013, 1705.980819115326, 1702.8822790066893, 1687.071563436439], 'acc': [0.6499183929451363, 0.8768909726868056, 0.8872855074300346, 0.8935546843611775, 0.9028134750811957, 0.9133206086878648, 0.9233802029383553, 0.9310357977650674, 0.9347315540142652, 0.9368822018147878, 0.9380276361690789, 0.9395176728449217, 0.9404773071695494, 0.94112485644453, 0.9417038586739298, 0.9423933553759445, 0.9431983088475141, 0.9435773242787551, 0.9439809429000183, 0.94443798812786, 0.9447938779848787, 0.9451409856474708, 0.9454748798953666, 0.9458201519130044, 0.9463995954300616, 0.9463239552173669, 0.9468958612562688, 0.9471579728548261, 0.9473359483882289, 0.9475100027847518, 0.9475377809129539, 0.9477949731576204, 0.9480557990483139, 0.9481720974180824, 0.9485165658092121, 0.9486000384339369, 0.9486070420044348, 0.9489127180952983, 0.9487648251794817, 0.9491828292990306, 0.9492382743168853, 0.9492631468629524, 0.949186684833971, 0.9496819559338018, 0.9495949605277991, 0.9498384744217505, 0.9501037968103268, 0.9501190722774758, 0.9499885159962338, 0.9502096133765112, 0.9504153252604438, 0.9504486230656987, 0.9506277082690473, 0.9508145782743709, 0.950892881373907, 0.9507866869561623, 0.9511132655103719, 0.9509852159774184, 0.9512176410272136, 0.9512700944778874, 0.9513147444915455, 0.9512600964047774, 0.9512548192251238, 0.9514581834897227, 0.9514501324815196, 0.9514172969077287, 0.9513184426840762, 0.9514028217303713, 0.9516507665147688, 0.9514874457532405, 0.9516371991992117, 0.9516648645441899, 0.9517906358252369, 0.9519598535161985, 0.951832844769505, 0.9518725522426643, 0.9521706657173075, 0.9520462503471048, 0.951993618022029, 0.9522447582981215, 0.952223186831319, 0.9522637997970451, 0.9523596424552047, 0.9524181234949818, 0.9524385643810142, 0.9525504560089305, 0.9525263753806292, 0.9527443682510871, 0.9527063756304386, 0.9527788238640609, 0.9527855375140045, 0.9528306996724509, 0.952955444695973], 'mDice': [0.08314239271593239, 0.27109648742590464, 0.40357113567531455, 0.49023028683488706, 0.5450649468768822, 0.5793442463540596, 0.6031746519872934, 0.6237944010536928, 0.6359663908468185, 0.6498765420245254, 0.6588712656650774, 0.6700861622879759, 0.6781016419231369, 0.6847689357683864, 0.6908815761317431, 0.6962242676665793, 0.7033349363926777, 0.7059234248132907, 0.710957044546074, 0.7153415650797211, 0.7180672460218906, 0.7218475124772862, 0.7249138650667246, 0.7282903917291161, 0.7331795085568188, 0.733069199956366, 0.7377894918197175, 0.7405523327370362, 0.7426720267840442, 0.7443415592662921, 0.7457106182751791, 0.7493219685754597, 0.7500749273976529, 0.7518297414283608, 0.755361079933304, 0.7560461747143901, 0.7579106527985237, 0.7594804235416333, 0.7589821619465487, 0.7622063227006785, 0.7631946153266067, 0.7644183260702091, 0.7643341303839187, 0.7667896214703908, 0.7670797873585578, 0.7699573555907827, 0.771023480949131, 0.7712047810397509, 0.7708982367703784, 0.772104902800891, 0.7755559910644324, 0.7751693965972465, 0.7763276483029069, 0.7771882603971718, 0.778694226767517, 0.7775163304527605, 0.7794543838001843, 0.7792949369172928, 0.7800614242128019, 0.7810969694859315, 0.7828520609093891, 0.7825046046835837, 0.7824446902023979, 0.7845462373533691, 0.7838872610604665, 0.7848197229396898, 0.7857982281454263, 0.7855794672804169, 0.7880445171862547, 0.7866669334653316, 0.7886188096262636, 0.7883809212497995, 0.789310986228527, 0.7905527566792636, 0.7899174586517019, 0.7904585630353016, 0.7919179766004204, 0.7912061175088057, 0.7909236506684443, 0.7932929226715143, 0.7928672244570126, 0.7928332122205798, 0.7936320802519641, 0.7937172463841075, 0.7944114858029151, 0.7953321523940355, 0.795490981885387, 0.7959922930526522, 0.7966938347193321, 0.7963738080530185, 0.7967464388224907, 0.7970356151899992, 0.7987135982014294]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.53s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.34s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.08s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:47,  1.43s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:28,  1.59s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:37,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:14,  1.76s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:06,  1.74s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:47,  1.89s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:14,  1.99s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:18,  2.02s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:05,  1.98s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:17,  2.03s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:26,  2.07s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:33,  2.10s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<09:45,  2.15s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<09:49,  2.17s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:50,  2.19s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:49,  2.19s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:44,  2.18s/it]predicting train subjects:   6%|▋         | 18/285 [00:37<09:48,  2.20s/it]predicting train subjects:   7%|▋         | 19/285 [00:39<09:40,  2.18s/it]predicting train subjects:   7%|▋         | 20/285 [00:41<09:57,  2.26s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:52,  2.25s/it]predicting train subjects:   8%|▊         | 22/285 [00:46<09:51,  2.25s/it]predicting train subjects:   8%|▊         | 23/285 [00:48<09:47,  2.24s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<09:37,  2.21s/it]predicting train subjects:   9%|▉         | 25/285 [00:52<09:36,  2.22s/it]predicting train subjects:   9%|▉         | 26/285 [00:54<09:30,  2.20s/it]predicting train subjects:   9%|▉         | 27/285 [00:56<09:14,  2.15s/it]predicting train subjects:  10%|▉         | 28/285 [00:58<08:59,  2.10s/it]predicting train subjects:  10%|█         | 29/285 [01:01<09:05,  2.13s/it]predicting train subjects:  11%|█         | 30/285 [01:03<09:09,  2.15s/it]predicting train subjects:  11%|█         | 31/285 [01:05<09:09,  2.16s/it]predicting train subjects:  11%|█         | 32/285 [01:07<08:55,  2.12s/it]predicting train subjects:  12%|█▏        | 33/285 [01:09<08:40,  2.07s/it]predicting train subjects:  12%|█▏        | 34/285 [01:11<08:44,  2.09s/it]predicting train subjects:  12%|█▏        | 35/285 [01:13<08:41,  2.09s/it]predicting train subjects:  13%|█▎        | 36/285 [01:15<08:41,  2.09s/it]predicting train subjects:  13%|█▎        | 37/285 [01:17<08:39,  2.10s/it]predicting train subjects:  13%|█▎        | 38/285 [01:20<08:44,  2.12s/it]predicting train subjects:  14%|█▎        | 39/285 [01:22<08:34,  2.09s/it]predicting train subjects:  14%|█▍        | 40/285 [01:24<08:32,  2.09s/it]predicting train subjects:  14%|█▍        | 41/285 [01:26<08:31,  2.10s/it]predicting train subjects:  15%|█▍        | 42/285 [01:28<08:37,  2.13s/it]predicting train subjects:  15%|█▌        | 43/285 [01:30<08:21,  2.07s/it]predicting train subjects:  15%|█▌        | 44/285 [01:32<08:24,  2.09s/it]predicting train subjects:  16%|█▌        | 45/285 [01:34<08:14,  2.06s/it]predicting train subjects:  16%|█▌        | 46/285 [01:36<07:57,  2.00s/it]predicting train subjects:  16%|█▋        | 47/285 [01:38<07:40,  1.93s/it]predicting train subjects:  17%|█▋        | 48/285 [01:39<07:21,  1.86s/it]predicting train subjects:  17%|█▋        | 49/285 [01:41<07:24,  1.89s/it]predicting train subjects:  18%|█▊        | 50/285 [01:43<07:19,  1.87s/it]predicting train subjects:  18%|█▊        | 51/285 [01:45<07:11,  1.85s/it]predicting train subjects:  18%|█▊        | 52/285 [01:47<07:09,  1.84s/it]predicting train subjects:  19%|█▊        | 53/285 [01:49<07:09,  1.85s/it]predicting train subjects:  19%|█▉        | 54/285 [01:51<07:10,  1.87s/it]predicting train subjects:  19%|█▉        | 55/285 [01:52<07:03,  1.84s/it]predicting train subjects:  20%|█▉        | 56/285 [01:54<06:57,  1.82s/it]predicting train subjects:  20%|██        | 57/285 [01:56<07:06,  1.87s/it]predicting train subjects:  20%|██        | 58/285 [01:58<07:03,  1.87s/it]predicting train subjects:  21%|██        | 59/285 [02:00<06:57,  1.85s/it]predicting train subjects:  21%|██        | 60/285 [02:02<06:55,  1.85s/it]predicting train subjects:  21%|██▏       | 61/285 [02:03<06:47,  1.82s/it]predicting train subjects:  22%|██▏       | 62/285 [02:05<06:55,  1.86s/it]predicting train subjects:  22%|██▏       | 63/285 [02:07<07:00,  1.89s/it]predicting train subjects:  22%|██▏       | 64/285 [02:09<07:02,  1.91s/it]predicting train subjects:  23%|██▎       | 65/285 [02:11<07:03,  1.92s/it]predicting train subjects:  23%|██▎       | 66/285 [02:13<06:59,  1.91s/it]predicting train subjects:  24%|██▎       | 67/285 [02:15<06:50,  1.88s/it]predicting train subjects:  24%|██▍       | 68/285 [02:17<06:44,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:19<06:37,  1.84s/it]predicting train subjects:  25%|██▍       | 70/285 [02:20<06:38,  1.85s/it]predicting train subjects:  25%|██▍       | 71/285 [02:22<06:28,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:24<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 73/285 [02:26<06:11,  1.75s/it]predicting train subjects:  26%|██▌       | 74/285 [02:27<06:09,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:29<06:09,  1.76s/it]predicting train subjects:  27%|██▋       | 76/285 [02:31<06:09,  1.77s/it]predicting train subjects:  27%|██▋       | 77/285 [02:32<05:59,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:34<05:56,  1.72s/it]predicting train subjects:  28%|██▊       | 79/285 [02:36<05:53,  1.72s/it]predicting train subjects:  28%|██▊       | 80/285 [02:38<05:54,  1.73s/it]predicting train subjects:  28%|██▊       | 81/285 [02:39<05:55,  1.75s/it]predicting train subjects:  29%|██▉       | 82/285 [02:41<05:55,  1.75s/it]predicting train subjects:  29%|██▉       | 83/285 [02:43<05:53,  1.75s/it]predicting train subjects:  29%|██▉       | 84/285 [02:45<05:53,  1.76s/it]predicting train subjects:  30%|██▉       | 85/285 [02:47<05:59,  1.80s/it]predicting train subjects:  30%|███       | 86/285 [02:49<06:06,  1.84s/it]predicting train subjects:  31%|███       | 87/285 [02:51<06:15,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:53<06:15,  1.90s/it]predicting train subjects:  31%|███       | 89/285 [02:54<06:18,  1.93s/it]predicting train subjects:  32%|███▏      | 90/285 [02:56<06:14,  1.92s/it]predicting train subjects:  32%|███▏      | 91/285 [02:58<06:11,  1.92s/it]predicting train subjects:  32%|███▏      | 92/285 [03:00<06:15,  1.95s/it]predicting train subjects:  33%|███▎      | 93/285 [03:02<06:13,  1.94s/it]predicting train subjects:  33%|███▎      | 94/285 [03:04<06:10,  1.94s/it]predicting train subjects:  33%|███▎      | 95/285 [03:06<06:07,  1.94s/it]predicting train subjects:  34%|███▎      | 96/285 [03:08<06:04,  1.93s/it]predicting train subjects:  34%|███▍      | 97/285 [03:10<06:03,  1.93s/it]predicting train subjects:  34%|███▍      | 98/285 [03:12<06:10,  1.98s/it]predicting train subjects:  35%|███▍      | 99/285 [03:14<06:07,  1.98s/it]predicting train subjects:  35%|███▌      | 100/285 [03:16<06:04,  1.97s/it]predicting train subjects:  35%|███▌      | 101/285 [03:18<06:09,  2.01s/it]predicting train subjects:  36%|███▌      | 102/285 [03:20<06:04,  1.99s/it]predicting train subjects:  36%|███▌      | 103/285 [03:22<05:53,  1.94s/it]predicting train subjects:  36%|███▋      | 104/285 [03:24<05:47,  1.92s/it]predicting train subjects:  37%|███▋      | 105/285 [03:26<05:44,  1.92s/it]predicting train subjects:  37%|███▋      | 106/285 [03:28<05:40,  1.90s/it]predicting train subjects:  38%|███▊      | 107/285 [03:29<05:40,  1.91s/it]predicting train subjects:  38%|███▊      | 108/285 [03:31<05:37,  1.90s/it]predicting train subjects:  38%|███▊      | 109/285 [03:33<05:34,  1.90s/it]predicting train subjects:  39%|███▊      | 110/285 [03:35<05:34,  1.91s/it]predicting train subjects:  39%|███▉      | 111/285 [03:37<05:30,  1.90s/it]predicting train subjects:  39%|███▉      | 112/285 [03:39<05:28,  1.90s/it]predicting train subjects:  40%|███▉      | 113/285 [03:41<05:24,  1.89s/it]predicting train subjects:  40%|████      | 114/285 [03:43<05:20,  1.87s/it]predicting train subjects:  40%|████      | 115/285 [03:45<05:19,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:46<05:18,  1.88s/it]predicting train subjects:  41%|████      | 117/285 [03:48<05:19,  1.90s/it]predicting train subjects:  41%|████▏     | 118/285 [03:50<05:17,  1.90s/it]predicting train subjects:  42%|████▏     | 119/285 [03:52<05:14,  1.89s/it]predicting train subjects:  42%|████▏     | 120/285 [03:54<05:12,  1.90s/it]predicting train subjects:  42%|████▏     | 121/285 [03:56<05:01,  1.84s/it]predicting train subjects:  43%|████▎     | 122/285 [03:57<04:46,  1.75s/it]predicting train subjects:  43%|████▎     | 123/285 [03:59<04:37,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [04:01<04:37,  1.73s/it]predicting train subjects:  44%|████▍     | 125/285 [04:02<04:31,  1.70s/it]predicting train subjects:  44%|████▍     | 126/285 [04:04<04:32,  1.71s/it]predicting train subjects:  45%|████▍     | 127/285 [04:06<04:32,  1.73s/it]predicting train subjects:  45%|████▍     | 128/285 [04:08<04:32,  1.73s/it]predicting train subjects:  45%|████▌     | 129/285 [04:09<04:29,  1.73s/it]predicting train subjects:  46%|████▌     | 130/285 [04:11<04:28,  1.73s/it]predicting train subjects:  46%|████▌     | 131/285 [04:13<04:23,  1.71s/it]predicting train subjects:  46%|████▋     | 132/285 [04:14<04:21,  1.71s/it]predicting train subjects:  47%|████▋     | 133/285 [04:16<04:22,  1.72s/it]predicting train subjects:  47%|████▋     | 134/285 [04:18<04:25,  1.76s/it]predicting train subjects:  47%|████▋     | 135/285 [04:20<04:22,  1.75s/it]predicting train subjects:  48%|████▊     | 136/285 [04:21<04:21,  1.76s/it]predicting train subjects:  48%|████▊     | 137/285 [04:23<04:22,  1.77s/it]predicting train subjects:  48%|████▊     | 138/285 [04:25<04:19,  1.77s/it]predicting train subjects:  49%|████▉     | 139/285 [04:27<04:15,  1.75s/it]predicting train subjects:  49%|████▉     | 140/285 [04:28<04:11,  1.74s/it]predicting train subjects:  49%|████▉     | 141/285 [04:30<04:10,  1.74s/it]predicting train subjects:  50%|████▉     | 142/285 [04:32<04:01,  1.69s/it]predicting train subjects:  50%|█████     | 143/285 [04:33<03:59,  1.69s/it]predicting train subjects:  51%|█████     | 144/285 [04:35<03:54,  1.66s/it]predicting train subjects:  51%|█████     | 145/285 [04:37<03:52,  1.66s/it]predicting train subjects:  51%|█████     | 146/285 [04:38<03:44,  1.62s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:40<03:44,  1.62s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:41<03:39,  1.60s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:43<03:39,  1.61s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:45<03:35,  1.60s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:46<03:32,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:48<03:31,  1.59s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:49<03:30,  1.60s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:51<03:30,  1.61s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:53<03:27,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:54<03:21,  1.57s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:56<03:23,  1.59s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:57<03:24,  1.61s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:59<03:19,  1.59s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:00<03:16,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:02<03:14,  1.57s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:03<03:08,  1.53s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:05<03:05,  1.52s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:07<03:05,  1.53s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:08<03:03,  1.53s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:10<03:02,  1.54s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:11<03:01,  1.54s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:13<03:01,  1.55s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:14<02:59,  1.55s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:16<02:58,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [05:18<03:00,  1.59s/it]predicting train subjects:  60%|██████    | 172/285 [05:19<02:58,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [05:21<02:54,  1.56s/it]predicting train subjects:  61%|██████    | 174/285 [05:22<02:54,  1.57s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:24<02:50,  1.55s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:25<02:48,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:27<02:44,  1.52s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:28<02:44,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:30<02:40,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:31<02:39,  1.51s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:33<02:36,  1.51s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:34<02:34,  1.50s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:36<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:37<02:28,  1.47s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:39<02:26,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:40<02:27,  1.49s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:42<02:25,  1.49s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:43<02:22,  1.47s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:45<02:22,  1.48s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:46<02:20,  1.48s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:47<02:18,  1.47s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:49<02:16,  1.47s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:50<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:52<02:15,  1.48s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:53<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:55<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:57<02:22,  1.62s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:59<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:00<02:26,  1.70s/it]predicting train subjects:  70%|███████   | 200/285 [06:02<02:25,  1.71s/it]predicting train subjects:  71%|███████   | 201/285 [06:04<02:23,  1.71s/it]predicting train subjects:  71%|███████   | 202/285 [06:06<02:25,  1.75s/it]predicting train subjects:  71%|███████   | 203/285 [06:08<02:25,  1.77s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:09<02:24,  1.78s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:11<02:22,  1.79s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:13<02:23,  1.81s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:15<02:19,  1.79s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:17<02:17,  1.79s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:18<02:16,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:20<02:14,  1.79s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:22<02:11,  1.78s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:24<02:09,  1.78s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:25<02:07,  1.77s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:27<02:02,  1.73s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:29<01:57,  1.68s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:30<01:54,  1.65s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:32<01:51,  1.63s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:33<01:47,  1.61s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:35<01:44,  1.59s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:36<01:43,  1.59s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:38<01:40,  1.57s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:39<01:36,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:41<01:36,  1.55s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:43<01:33,  1.53s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:44<01:31,  1.52s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:46<01:29,  1.52s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:47<01:28,  1.53s/it]predicting train subjects:  80%|████████  | 228/285 [06:49<01:29,  1.57s/it]predicting train subjects:  80%|████████  | 229/285 [06:50<01:27,  1.56s/it]predicting train subjects:  81%|████████  | 230/285 [06:52<01:26,  1.57s/it]predicting train subjects:  81%|████████  | 231/285 [06:54<01:25,  1.59s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:55<01:29,  1.70s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:57<01:32,  1.78s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:59<01:32,  1.81s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:01<01:31,  1.84s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:03<01:30,  1.84s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:05<01:29,  1.86s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:07<01:28,  1.88s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:09<01:27,  1.89s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:11<01:25,  1.89s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:13<01:23,  1.90s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:15<01:21,  1.90s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:16<01:19,  1.90s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:18<01:17,  1.89s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:20<01:16,  1.92s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:22<01:14,  1.91s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:24<01:12,  1.91s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:26<01:10,  1.91s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:28<01:07,  1.89s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:29<01:01,  1.76s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:31<00:56,  1.67s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:32<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:34<00:50,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:35<00:47,  1.55s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:37<00:45,  1.52s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:38<00:44,  1.53s/it]predicting train subjects:  90%|█████████ | 257/285 [07:40<00:43,  1.54s/it]predicting train subjects:  91%|█████████ | 258/285 [07:41<00:40,  1.51s/it]predicting train subjects:  91%|█████████ | 259/285 [07:43<00:39,  1.52s/it]predicting train subjects:  91%|█████████ | 260/285 [07:44<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:46<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:47<00:34,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:49<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:50<00:31,  1.51s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:52<00:30,  1.51s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:53<00:28,  1.49s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:55<00:26,  1.48s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:57<00:27,  1.62s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:59<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:00<00:26,  1.77s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:02<00:25,  1.83s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:04<00:24,  1.86s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:06<00:23,  1.92s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:08<00:21,  1.93s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:10<00:19,  1.94s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:12<00:17,  1.96s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:14<00:15,  1.95s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:16<00:13,  1.93s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:18<00:11,  1.91s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:20<00:09,  1.92s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:22<00:07,  1.90s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:24<00:05,  1.90s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:26<00:03,  1.92s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:28<00:01,  1.90s/it]predicting train subjects: 100%|██████████| 285/285 [08:29<00:00,  1.88s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:13,  1.31s/it]Loading train:   1%|          | 2/285 [00:02<06:27,  1.37s/it]Loading train:   1%|          | 3/285 [00:04<06:23,  1.36s/it]Loading train:   1%|▏         | 4/285 [00:05<06:46,  1.45s/it]Loading train:   2%|▏         | 5/285 [00:06<06:20,  1.36s/it]Loading train:   2%|▏         | 6/285 [00:08<06:44,  1.45s/it]Loading train:   2%|▏         | 7/285 [00:10<07:23,  1.59s/it]Loading train:   3%|▎         | 8/285 [00:12<07:27,  1.62s/it]Loading train:   3%|▎         | 9/285 [00:13<07:09,  1.56s/it]Loading train:   4%|▎         | 10/285 [00:15<07:04,  1.54s/it]Loading train:   4%|▍         | 11/285 [00:16<06:39,  1.46s/it]Loading train:   4%|▍         | 12/285 [00:17<06:05,  1.34s/it]Loading train:   5%|▍         | 13/285 [00:18<05:41,  1.26s/it]Loading train:   5%|▍         | 14/285 [00:19<05:24,  1.20s/it]Loading train:   5%|▌         | 15/285 [00:20<05:16,  1.17s/it]Loading train:   6%|▌         | 16/285 [00:21<05:07,  1.14s/it]Loading train:   6%|▌         | 17/285 [00:22<05:02,  1.13s/it]Loading train:   6%|▋         | 18/285 [00:23<05:01,  1.13s/it]Loading train:   7%|▋         | 19/285 [00:25<05:07,  1.16s/it]Loading train:   7%|▋         | 20/285 [00:26<04:56,  1.12s/it]Loading train:   7%|▋         | 21/285 [00:27<04:57,  1.13s/it]Loading train:   8%|▊         | 22/285 [00:28<05:16,  1.20s/it]Loading train:   8%|▊         | 23/285 [00:29<05:09,  1.18s/it]Loading train:   8%|▊         | 24/285 [00:31<05:07,  1.18s/it]Loading train:   9%|▉         | 25/285 [00:32<04:52,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:33<04:41,  1.09s/it]Loading train:   9%|▉         | 27/285 [00:34<04:40,  1.09s/it]Loading train:  10%|▉         | 28/285 [00:35<04:43,  1.10s/it]Loading train:  10%|█         | 29/285 [00:36<04:58,  1.17s/it]Loading train:  11%|█         | 30/285 [00:37<04:49,  1.13s/it]Loading train:  11%|█         | 31/285 [00:38<04:43,  1.11s/it]Loading train:  11%|█         | 32/285 [00:39<04:42,  1.12s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:46,  1.14s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:34,  1.09s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:33,  1.09s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:29,  1.08s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:25,  1.07s/it]Loading train:  13%|█▎        | 38/285 [00:46<04:23,  1.07s/it]Loading train:  14%|█▎        | 39/285 [00:47<04:34,  1.12s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:37,  1.13s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:26,  1.09s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:20,  1.07s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:15,  1.06s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:20,  1.08s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:10,  1.04s/it]Loading train:  16%|█▌        | 46/285 [00:55<04:25,  1.11s/it]Loading train:  16%|█▋        | 47/285 [00:55<04:07,  1.04s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:08,  1.05s/it]Loading train:  17%|█▋        | 49/285 [00:57<03:56,  1.00s/it]Loading train:  18%|█▊        | 50/285 [00:58<03:46,  1.04it/s]Loading train:  18%|█▊        | 51/285 [00:59<03:39,  1.06it/s]Loading train:  18%|█▊        | 52/285 [01:00<03:39,  1.06it/s]Loading train:  19%|█▊        | 53/285 [01:01<03:39,  1.05it/s]Loading train:  19%|█▉        | 54/285 [01:02<03:29,  1.10it/s]Loading train:  19%|█▉        | 55/285 [01:03<03:29,  1.10it/s]Loading train:  20%|█▉        | 56/285 [01:04<03:23,  1.12it/s]Loading train:  20%|██        | 57/285 [01:05<03:21,  1.13it/s]Loading train:  20%|██        | 58/285 [01:05<03:21,  1.13it/s]Loading train:  21%|██        | 59/285 [01:06<03:15,  1.15it/s]Loading train:  21%|██        | 60/285 [01:07<03:18,  1.13it/s]Loading train:  21%|██▏       | 61/285 [01:08<03:21,  1.11it/s]Loading train:  22%|██▏       | 62/285 [01:09<03:24,  1.09it/s]Loading train:  22%|██▏       | 63/285 [01:10<03:22,  1.09it/s]Loading train:  22%|██▏       | 64/285 [01:11<03:54,  1.06s/it]Loading train:  23%|██▎       | 65/285 [01:13<04:30,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:15<04:49,  1.32s/it]Loading train:  24%|██▎       | 67/285 [01:16<04:26,  1.22s/it]Loading train:  24%|██▍       | 68/285 [01:16<04:01,  1.11s/it]Loading train:  24%|██▍       | 69/285 [01:17<03:47,  1.05s/it]Loading train:  25%|██▍       | 70/285 [01:18<03:40,  1.03s/it]Loading train:  25%|██▍       | 71/285 [01:19<03:29,  1.02it/s]Loading train:  25%|██▌       | 72/285 [01:20<03:36,  1.01s/it]Loading train:  26%|██▌       | 73/285 [01:21<03:29,  1.01it/s]Loading train:  26%|██▌       | 74/285 [01:22<03:35,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:23<03:27,  1.01it/s]Loading train:  27%|██▋       | 76/285 [01:24<03:24,  1.02it/s]Loading train:  27%|██▋       | 77/285 [01:25<03:20,  1.04it/s]Loading train:  27%|██▋       | 78/285 [01:26<03:15,  1.06it/s]Loading train:  28%|██▊       | 79/285 [01:27<03:08,  1.09it/s]Loading train:  28%|██▊       | 80/285 [01:28<03:00,  1.13it/s]Loading train:  28%|██▊       | 81/285 [01:29<03:06,  1.09it/s]Loading train:  29%|██▉       | 82/285 [01:30<03:08,  1.08it/s]Loading train:  29%|██▉       | 83/285 [01:30<03:04,  1.10it/s]Loading train:  29%|██▉       | 84/285 [01:32<03:14,  1.04it/s]Loading train:  30%|██▉       | 85/285 [01:33<03:35,  1.08s/it]Loading train:  30%|███       | 86/285 [01:34<03:32,  1.07s/it]Loading train:  31%|███       | 87/285 [01:35<03:36,  1.10s/it]Loading train:  31%|███       | 88/285 [01:36<03:32,  1.08s/it]Loading train:  31%|███       | 89/285 [01:37<03:38,  1.11s/it]Loading train:  32%|███▏      | 90/285 [01:38<03:35,  1.11s/it]Loading train:  32%|███▏      | 91/285 [01:39<03:31,  1.09s/it]Loading train:  32%|███▏      | 92/285 [01:41<03:33,  1.11s/it]Loading train:  33%|███▎      | 93/285 [01:42<03:31,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:43<03:47,  1.19s/it]Loading train:  33%|███▎      | 95/285 [01:44<03:42,  1.17s/it]Loading train:  34%|███▎      | 96/285 [01:45<03:37,  1.15s/it]Loading train:  34%|███▍      | 97/285 [01:46<03:26,  1.10s/it]Loading train:  34%|███▍      | 98/285 [01:48<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [01:49<03:34,  1.15s/it]Loading train:  35%|███▌      | 100/285 [01:50<03:26,  1.11s/it]Loading train:  35%|███▌      | 101/285 [01:51<03:19,  1.08s/it]Loading train:  36%|███▌      | 102/285 [01:52<03:18,  1.09s/it]Loading train:  36%|███▌      | 103/285 [01:53<03:19,  1.09s/it]Loading train:  36%|███▋      | 104/285 [01:54<03:13,  1.07s/it]Loading train:  37%|███▋      | 105/285 [01:55<03:08,  1.05s/it]Loading train:  37%|███▋      | 106/285 [01:56<03:04,  1.03s/it]Loading train:  38%|███▊      | 107/285 [01:57<03:05,  1.04s/it]Loading train:  38%|███▊      | 108/285 [01:58<03:05,  1.05s/it]Loading train:  38%|███▊      | 109/285 [01:59<03:03,  1.04s/it]Loading train:  39%|███▊      | 110/285 [02:00<03:00,  1.03s/it]Loading train:  39%|███▉      | 111/285 [02:01<02:55,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:02<02:54,  1.01s/it]Loading train:  40%|███▉      | 113/285 [02:03<02:53,  1.01s/it]Loading train:  40%|████      | 114/285 [02:04<02:52,  1.01s/it]Loading train:  40%|████      | 115/285 [02:05<02:49,  1.00it/s]Loading train:  41%|████      | 116/285 [02:06<02:46,  1.01it/s]Loading train:  41%|████      | 117/285 [02:07<02:47,  1.00it/s]Loading train:  41%|████▏     | 118/285 [02:08<02:45,  1.01it/s]Loading train:  42%|████▏     | 119/285 [02:09<02:42,  1.02it/s]Loading train:  42%|████▏     | 120/285 [02:10<02:56,  1.07s/it]Loading train:  42%|████▏     | 121/285 [02:12<03:17,  1.20s/it]Loading train:  43%|████▎     | 122/285 [02:13<03:20,  1.23s/it]Loading train:  43%|████▎     | 123/285 [02:15<03:42,  1.37s/it]Loading train:  44%|████▎     | 124/285 [02:16<03:31,  1.32s/it]Loading train:  44%|████▍     | 125/285 [02:17<03:23,  1.27s/it]Loading train:  44%|████▍     | 126/285 [02:18<03:21,  1.27s/it]Loading train:  45%|████▍     | 127/285 [02:20<03:16,  1.24s/it]Loading train:  45%|████▍     | 128/285 [02:21<03:08,  1.20s/it]Loading train:  45%|████▌     | 129/285 [02:22<03:08,  1.21s/it]Loading train:  46%|████▌     | 130/285 [02:23<03:15,  1.26s/it]Loading train:  46%|████▌     | 131/285 [02:24<03:10,  1.24s/it]Loading train:  46%|████▋     | 132/285 [02:26<03:09,  1.24s/it]Loading train:  47%|████▋     | 133/285 [02:27<03:07,  1.23s/it]Loading train:  47%|████▋     | 134/285 [02:28<03:13,  1.28s/it]Loading train:  47%|████▋     | 135/285 [02:29<03:00,  1.20s/it]Loading train:  48%|████▊     | 136/285 [02:30<02:53,  1.17s/it]Loading train:  48%|████▊     | 137/285 [02:32<03:02,  1.23s/it]Loading train:  48%|████▊     | 138/285 [02:33<03:09,  1.29s/it]Loading train:  49%|████▉     | 139/285 [02:34<03:04,  1.27s/it]Loading train:  49%|████▉     | 140/285 [02:36<03:01,  1.25s/it]Loading train:  49%|████▉     | 141/285 [02:37<03:03,  1.27s/it]Loading train:  50%|████▉     | 142/285 [02:38<02:57,  1.24s/it]Loading train:  50%|█████     | 143/285 [02:39<02:47,  1.18s/it]Loading train:  51%|█████     | 144/285 [02:40<02:46,  1.18s/it]Loading train:  51%|█████     | 145/285 [02:41<02:40,  1.15s/it]Loading train:  51%|█████     | 146/285 [02:43<02:43,  1.18s/it]Loading train:  52%|█████▏    | 147/285 [02:44<02:49,  1.23s/it]Loading train:  52%|█████▏    | 148/285 [02:45<02:35,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [02:46<02:29,  1.10s/it]Loading train:  53%|█████▎    | 150/285 [02:47<02:27,  1.09s/it]Loading train:  53%|█████▎    | 151/285 [02:48<02:31,  1.13s/it]Loading train:  53%|█████▎    | 152/285 [02:49<02:26,  1.10s/it]Loading train:  54%|█████▎    | 153/285 [02:50<02:27,  1.11s/it]Loading train:  54%|█████▍    | 154/285 [02:52<02:24,  1.10s/it]Loading train:  54%|█████▍    | 155/285 [02:53<02:24,  1.11s/it]Loading train:  55%|█████▍    | 156/285 [02:54<02:22,  1.11s/it]Loading train:  55%|█████▌    | 157/285 [02:55<02:23,  1.12s/it]Loading train:  55%|█████▌    | 158/285 [02:56<02:23,  1.13s/it]Loading train:  56%|█████▌    | 159/285 [02:57<02:13,  1.06s/it]Loading train:  56%|█████▌    | 160/285 [02:58<02:16,  1.09s/it]Loading train:  56%|█████▋    | 161/285 [02:59<02:12,  1.07s/it]Loading train:  57%|█████▋    | 162/285 [03:00<02:14,  1.09s/it]Loading train:  57%|█████▋    | 163/285 [03:01<02:17,  1.12s/it]Loading train:  58%|█████▊    | 164/285 [03:03<02:16,  1.13s/it]Loading train:  58%|█████▊    | 165/285 [03:04<02:21,  1.18s/it]Loading train:  58%|█████▊    | 166/285 [03:05<02:21,  1.19s/it]Loading train:  59%|█████▊    | 167/285 [03:06<02:24,  1.22s/it]Loading train:  59%|█████▉    | 168/285 [03:08<02:23,  1.23s/it]Loading train:  59%|█████▉    | 169/285 [03:09<02:16,  1.18s/it]Loading train:  60%|█████▉    | 170/285 [03:10<02:12,  1.16s/it]Loading train:  60%|██████    | 171/285 [03:11<02:17,  1.20s/it]Loading train:  60%|██████    | 172/285 [03:12<02:12,  1.18s/it]Loading train:  61%|██████    | 173/285 [03:13<02:05,  1.12s/it]Loading train:  61%|██████    | 174/285 [03:14<02:03,  1.12s/it]Loading train:  61%|██████▏   | 175/285 [03:15<02:01,  1.11s/it]Loading train:  62%|██████▏   | 176/285 [03:17<02:00,  1.11s/it]Loading train:  62%|██████▏   | 177/285 [03:18<01:57,  1.09s/it]Loading train:  62%|██████▏   | 178/285 [03:19<01:55,  1.08s/it]Loading train:  63%|██████▎   | 179/285 [03:20<01:57,  1.11s/it]Loading train:  63%|██████▎   | 180/285 [03:21<01:52,  1.07s/it]Loading train:  64%|██████▎   | 181/285 [03:22<01:48,  1.04s/it]Loading train:  64%|██████▍   | 182/285 [03:23<01:43,  1.01s/it]Loading train:  64%|██████▍   | 183/285 [03:24<01:44,  1.02s/it]Loading train:  65%|██████▍   | 184/285 [03:25<01:43,  1.03s/it]Loading train:  65%|██████▍   | 185/285 [03:26<01:41,  1.01s/it]Loading train:  65%|██████▌   | 186/285 [03:27<01:44,  1.06s/it]Loading train:  66%|██████▌   | 187/285 [03:28<01:53,  1.16s/it]Loading train:  66%|██████▌   | 188/285 [03:30<01:55,  1.19s/it]Loading train:  66%|██████▋   | 189/285 [03:31<01:51,  1.16s/it]Loading train:  67%|██████▋   | 190/285 [03:32<01:55,  1.21s/it]Loading train:  67%|██████▋   | 191/285 [03:33<01:54,  1.22s/it]Loading train:  67%|██████▋   | 192/285 [03:34<01:54,  1.23s/it]Loading train:  68%|██████▊   | 193/285 [03:36<01:47,  1.17s/it]Loading train:  68%|██████▊   | 194/285 [03:36<01:37,  1.07s/it]Loading train:  68%|██████▊   | 195/285 [03:37<01:34,  1.06s/it]Loading train:  69%|██████▉   | 196/285 [03:38<01:34,  1.07s/it]Loading train:  69%|██████▉   | 197/285 [03:40<01:36,  1.10s/it]Loading train:  69%|██████▉   | 198/285 [03:41<01:39,  1.15s/it]Loading train:  70%|██████▉   | 199/285 [03:42<01:38,  1.14s/it]Loading train:  70%|███████   | 200/285 [03:43<01:36,  1.14s/it]Loading train:  71%|███████   | 201/285 [03:44<01:35,  1.14s/it]Loading train:  71%|███████   | 202/285 [03:46<01:43,  1.25s/it]Loading train:  71%|███████   | 203/285 [03:47<01:39,  1.22s/it]Loading train:  72%|███████▏  | 204/285 [03:48<01:35,  1.18s/it]Loading train:  72%|███████▏  | 205/285 [03:49<01:33,  1.17s/it]Loading train:  72%|███████▏  | 206/285 [03:50<01:31,  1.15s/it]Loading train:  73%|███████▎  | 207/285 [03:51<01:30,  1.15s/it]Loading train:  73%|███████▎  | 208/285 [03:53<01:28,  1.15s/it]Loading train:  73%|███████▎  | 209/285 [03:54<01:28,  1.16s/it]Loading train:  74%|███████▎  | 210/285 [03:55<01:24,  1.13s/it]Loading train:  74%|███████▍  | 211/285 [03:56<01:21,  1.10s/it]Loading train:  74%|███████▍  | 212/285 [03:57<01:19,  1.08s/it]Loading train:  75%|███████▍  | 213/285 [03:58<01:18,  1.08s/it]Loading train:  75%|███████▌  | 214/285 [03:59<01:18,  1.11s/it]Loading train:  75%|███████▌  | 215/285 [04:00<01:15,  1.08s/it]Loading train:  76%|███████▌  | 216/285 [04:01<01:15,  1.09s/it]Loading train:  76%|███████▌  | 217/285 [04:02<01:15,  1.10s/it]Loading train:  76%|███████▋  | 218/285 [04:04<01:14,  1.11s/it]Loading train:  77%|███████▋  | 219/285 [04:05<01:12,  1.09s/it]Loading train:  77%|███████▋  | 220/285 [04:06<01:09,  1.08s/it]Loading train:  78%|███████▊  | 221/285 [04:07<01:06,  1.04s/it]Loading train:  78%|███████▊  | 222/285 [04:08<01:10,  1.11s/it]Loading train:  78%|███████▊  | 223/285 [04:09<01:07,  1.09s/it]Loading train:  79%|███████▊  | 224/285 [04:10<01:06,  1.10s/it]Loading train:  79%|███████▉  | 225/285 [04:11<01:06,  1.11s/it]Loading train:  79%|███████▉  | 226/285 [04:12<01:04,  1.09s/it]Loading train:  80%|███████▉  | 227/285 [04:14<01:09,  1.19s/it]Loading train:  80%|████████  | 228/285 [04:15<01:08,  1.19s/it]Loading train:  80%|████████  | 229/285 [04:16<01:09,  1.24s/it]Loading train:  81%|████████  | 230/285 [04:17<01:05,  1.19s/it]Loading train:  81%|████████  | 231/285 [04:18<01:02,  1.16s/it]Loading train:  81%|████████▏ | 232/285 [04:20<01:06,  1.26s/it]Loading train:  82%|████████▏ | 233/285 [04:21<01:10,  1.35s/it]Loading train:  82%|████████▏ | 234/285 [04:23<01:12,  1.42s/it]Loading train:  82%|████████▏ | 235/285 [04:24<01:10,  1.42s/it]Loading train:  83%|████████▎ | 236/285 [04:26<01:09,  1.42s/it]Loading train:  83%|████████▎ | 237/285 [04:27<01:06,  1.39s/it]Loading train:  84%|████████▎ | 238/285 [04:29<01:04,  1.37s/it]Loading train:  84%|████████▍ | 239/285 [04:30<01:02,  1.37s/it]Loading train:  84%|████████▍ | 240/285 [04:31<01:02,  1.38s/it]Loading train:  85%|████████▍ | 241/285 [04:33<01:02,  1.41s/it]Loading train:  85%|████████▍ | 242/285 [04:34<00:59,  1.38s/it]Loading train:  85%|████████▌ | 243/285 [04:35<00:56,  1.34s/it]Loading train:  86%|████████▌ | 244/285 [04:37<00:54,  1.34s/it]Loading train:  86%|████████▌ | 245/285 [04:38<00:53,  1.33s/it]Loading train:  86%|████████▋ | 246/285 [04:39<00:51,  1.31s/it]Loading train:  87%|████████▋ | 247/285 [04:40<00:47,  1.26s/it]Loading train:  87%|████████▋ | 248/285 [04:42<00:49,  1.34s/it]Loading train:  87%|████████▋ | 249/285 [04:43<00:47,  1.32s/it]Loading train:  88%|████████▊ | 250/285 [04:44<00:43,  1.24s/it]Loading train:  88%|████████▊ | 251/285 [04:45<00:39,  1.16s/it]Loading train:  88%|████████▊ | 252/285 [04:46<00:39,  1.20s/it]Loading train:  89%|████████▉ | 253/285 [04:48<00:38,  1.19s/it]Loading train:  89%|████████▉ | 254/285 [04:49<00:34,  1.12s/it]Loading train:  89%|████████▉ | 255/285 [04:50<00:31,  1.07s/it]Loading train:  90%|████████▉ | 256/285 [04:50<00:29,  1.01s/it]Loading train:  90%|█████████ | 257/285 [04:52<00:29,  1.06s/it]Loading train:  91%|█████████ | 258/285 [04:53<00:28,  1.06s/it]Loading train:  91%|█████████ | 259/285 [04:54<00:28,  1.10s/it]Loading train:  91%|█████████ | 260/285 [04:55<00:27,  1.11s/it]Loading train:  92%|█████████▏| 261/285 [04:56<00:27,  1.14s/it]Loading train:  92%|█████████▏| 262/285 [04:57<00:26,  1.14s/it]Loading train:  92%|█████████▏| 263/285 [04:58<00:24,  1.11s/it]Loading train:  93%|█████████▎| 264/285 [04:59<00:22,  1.06s/it]Loading train:  93%|█████████▎| 265/285 [05:00<00:21,  1.05s/it]Loading train:  93%|█████████▎| 266/285 [05:01<00:19,  1.03s/it]Loading train:  94%|█████████▎| 267/285 [05:02<00:19,  1.07s/it]Loading train:  94%|█████████▍| 268/285 [05:04<00:18,  1.10s/it]Loading train:  94%|█████████▍| 269/285 [05:05<00:19,  1.19s/it]Loading train:  95%|█████████▍| 270/285 [05:06<00:18,  1.24s/it]Loading train:  95%|█████████▌| 271/285 [05:08<00:17,  1.24s/it]Loading train:  95%|█████████▌| 272/285 [05:09<00:15,  1.23s/it]Loading train:  96%|█████████▌| 273/285 [05:10<00:14,  1.23s/it]Loading train:  96%|█████████▌| 274/285 [05:11<00:13,  1.27s/it]Loading train:  96%|█████████▋| 275/285 [05:12<00:11,  1.19s/it]Loading train:  97%|█████████▋| 276/285 [05:14<00:11,  1.22s/it]Loading train:  97%|█████████▋| 277/285 [05:15<00:10,  1.28s/it]Loading train:  98%|█████████▊| 278/285 [05:16<00:09,  1.29s/it]Loading train:  98%|█████████▊| 279/285 [05:18<00:07,  1.32s/it]Loading train:  98%|█████████▊| 280/285 [05:19<00:06,  1.29s/it]Loading train:  99%|█████████▊| 281/285 [05:20<00:04,  1.24s/it]Loading train:  99%|█████████▉| 282/285 [05:22<00:03,  1.26s/it]Loading train:  99%|█████████▉| 283/285 [05:23<00:02,  1.27s/it]Loading train: 100%|█████████▉| 284/285 [05:24<00:01,  1.22s/it]Loading train: 100%|██████████| 285/285 [05:26<00:00,  1.33s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:05, 47.23it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 51.28it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:05, 50.74it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:04, 52.94it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:04, 53.13it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:04, 53.84it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:04, 54.41it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:04, 48.86it/s]concatenating: train:  18%|█▊        | 52/285 [00:01<00:04, 48.63it/s]concatenating: train:  20%|██        | 58/285 [00:01<00:04, 51.56it/s]concatenating: train:  24%|██▎       | 67/285 [00:01<00:03, 57.27it/s]concatenating: train:  28%|██▊       | 79/285 [00:01<00:03, 67.05it/s]concatenating: train:  32%|███▏      | 92/285 [00:01<00:02, 78.40it/s]concatenating: train:  37%|███▋      | 105/285 [00:01<00:02, 88.30it/s]concatenating: train:  41%|████▏     | 118/285 [00:01<00:01, 96.82it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:01, 103.84it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 109.29it/s]concatenating: train:  55%|█████▍    | 156/285 [00:01<00:01, 107.57it/s]concatenating: train:  59%|█████▉    | 168/285 [00:02<00:01, 103.38it/s]concatenating: train:  63%|██████▎   | 179/285 [00:02<00:01, 87.81it/s] concatenating: train:  66%|██████▋   | 189/285 [00:02<00:01, 79.80it/s]concatenating: train:  69%|██████▉   | 198/285 [00:02<00:01, 73.74it/s]concatenating: train:  72%|███████▏  | 206/285 [00:02<00:01, 63.86it/s]concatenating: train:  75%|███████▍  | 213/285 [00:02<00:01, 64.23it/s]concatenating: train:  78%|███████▊  | 222/285 [00:02<00:00, 68.35it/s]concatenating: train:  81%|████████  | 231/285 [00:03<00:00, 72.18it/s]concatenating: train:  86%|████████▌ | 244/285 [00:03<00:00, 82.09it/s]concatenating: train:  89%|████████▉ | 253/285 [00:03<00:00, 78.08it/s]concatenating: train:  93%|█████████▎| 266/285 [00:03<00:00, 87.28it/s]concatenating: train:  98%|█████████▊| 279/285 [00:03<00:00, 96.82it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 80.29it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.46s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 39.32it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-08 12:13:26.626192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 12:13:26.626300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 12:13:26.626320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 12:13:26.626330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 12:13:26.626741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 21s - loss: 12727.2063 - acc: 0.7311 - mDice: 0.1377 - val_loss: 6869.7877 - val_acc: 0.9076 - val_mDice: 0.2425

Epoch 00001: val_mDice improved from -inf to 0.24252, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 4546.8270 - acc: 0.8839 - mDice: 0.4036 - val_loss: 4427.4127 - val_acc: 0.9177 - val_mDice: 0.3909

Epoch 00002: val_mDice improved from 0.24252 to 0.39088, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 10s - loss: 3146.8418 - acc: 0.8966 - mDice: 0.5281 - val_loss: 4055.5772 - val_acc: 0.9208 - val_mDice: 0.4220

Epoch 00003: val_mDice improved from 0.39088 to 0.42198, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 2612.0451 - acc: 0.9106 - mDice: 0.5884 - val_loss: 3386.7194 - val_acc: 0.9316 - val_mDice: 0.4805

Epoch 00004: val_mDice improved from 0.42198 to 0.48047, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 11s - loss: 2260.3915 - acc: 0.9243 - mDice: 0.6313 - val_loss: 3444.4155 - val_acc: 0.9309 - val_mDice: 0.4774

Epoch 00005: val_mDice did not improve from 0.48047
Epoch 6/300
 - 10s - loss: 2038.2025 - acc: 0.9328 - mDice: 0.6599 - val_loss: 3250.4836 - val_acc: 0.9401 - val_mDice: 0.4966

Epoch 00006: val_mDice improved from 0.48047 to 0.49662, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 1928.6007 - acc: 0.9358 - mDice: 0.6745 - val_loss: 3193.2895 - val_acc: 0.9434 - val_mDice: 0.5007

Epoch 00007: val_mDice improved from 0.49662 to 0.50072, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 1806.5827 - acc: 0.9384 - mDice: 0.6914 - val_loss: 3097.5285 - val_acc: 0.9456 - val_mDice: 0.5128

Epoch 00008: val_mDice improved from 0.50072 to 0.51283, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 10s - loss: 1728.3005 - acc: 0.9401 - mDice: 0.7024 - val_loss: 2821.9348 - val_acc: 0.9445 - val_mDice: 0.5387

Epoch 00009: val_mDice improved from 0.51283 to 0.53870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 10s - loss: 1651.1600 - acc: 0.9415 - mDice: 0.7134 - val_loss: 3281.2105 - val_acc: 0.9448 - val_mDice: 0.4958

Epoch 00010: val_mDice did not improve from 0.53870
Epoch 11/300
 - 11s - loss: 1593.0426 - acc: 0.9428 - mDice: 0.7219 - val_loss: 3467.7669 - val_acc: 0.9421 - val_mDice: 0.4704

Epoch 00011: val_mDice did not improve from 0.53870
Epoch 12/300
 - 10s - loss: 1542.5095 - acc: 0.9438 - mDice: 0.7293 - val_loss: 2973.7844 - val_acc: 0.9487 - val_mDice: 0.5237

Epoch 00012: val_mDice did not improve from 0.53870
Epoch 13/300
 - 10s - loss: 1476.6415 - acc: 0.9450 - mDice: 0.7391 - val_loss: 2981.3185 - val_acc: 0.9424 - val_mDice: 0.5237

Epoch 00013: val_mDice did not improve from 0.53870
Epoch 14/300
 - 10s - loss: 1432.5650 - acc: 0.9457 - mDice: 0.7457 - val_loss: 3108.9279 - val_acc: 0.9446 - val_mDice: 0.5087

Epoch 00014: val_mDice did not improve from 0.53870
Epoch 15/300
 - 10s - loss: 1412.4389 - acc: 0.9462 - mDice: 0.7488 - val_loss: 3025.4812 - val_acc: 0.9417 - val_mDice: 0.5176

Epoch 00015: val_mDice did not improve from 0.53870
Epoch 16/300
 - 10s - loss: 1385.2897 - acc: 0.9468 - mDice: 0.7529 - val_loss: 2994.7201 - val_acc: 0.9449 - val_mDice: 0.5208

Epoch 00016: val_mDice did not improve from 0.53870
Epoch 17/300
 - 10s - loss: 1345.9380 - acc: 0.9477 - mDice: 0.7590 - val_loss: 2882.1887 - val_acc: 0.9447 - val_mDice: 0.5358

Epoch 00017: val_mDice did not improve from 0.53870
Epoch 18/300
 - 10s - loss: 1337.2647 - acc: 0.9478 - mDice: 0.7603 - val_loss: 3061.6338 - val_acc: 0.9450 - val_mDice: 0.5124

Epoch 00018: val_mDice did not improve from 0.53870
Epoch 19/300
 - 11s - loss: 1305.3811 - acc: 0.9486 - mDice: 0.7653 - val_loss: 2909.6813 - val_acc: 0.9472 - val_mDice: 0.5285

Epoch 00019: val_mDice did not improve from 0.53870
Epoch 20/300
 - 10s - loss: 1274.3771 - acc: 0.9492 - mDice: 0.7702 - val_loss: 2945.2927 - val_acc: 0.9428 - val_mDice: 0.5249

Epoch 00020: val_mDice did not improve from 0.53870
Epoch 21/300
 - 10s - loss: 1252.0981 - acc: 0.9497 - mDice: 0.7736 - val_loss: 2868.6240 - val_acc: 0.9456 - val_mDice: 0.5328

Epoch 00021: val_mDice did not improve from 0.53870
Epoch 22/300
 - 10s - loss: 1233.2959 - acc: 0.9501 - mDice: 0.7766 - val_loss: 3363.2208 - val_acc: 0.9420 - val_mDice: 0.4807

Epoch 00022: val_mDice did not improve from 0.53870
Epoch 23/300
 - 10s - loss: 1209.4827 - acc: 0.9507 - mDice: 0.7803 - val_loss: 2918.8420 - val_acc: 0.9462 - val_mDice: 0.5281

Epoch 00023: val_mDice did not improve from 0.53870
Epoch 24/300
 - 10s - loss: 1199.3834 - acc: 0.9509 - mDice: 0.7819 - val_loss: 3045.3334 - val_acc: 0.9453 - val_mDice: 0.5130

Epoch 00024: val_mDice did not improve from 0.53870
Epoch 25/300
 - 10s - loss: 1193.3641 - acc: 0.9510 - mDice: 0.7830 - val_loss: 2835.4800 - val_acc: 0.9468 - val_mDice: 0.5358

Epoch 00025: val_mDice did not improve from 0.53870
Epoch 26/300
 - 10s - loss: 1173.2052 - acc: 0.9514 - mDice: 0.7861 - val_loss: 2780.7110 - val_acc: 0.9476 - val_mDice: 0.5449

Epoch 00026: val_mDice improved from 0.53870 to 0.54488, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 27/300
 - 10s - loss: 1163.9107 - acc: 0.9516 - mDice: 0.7877 - val_loss: 2928.4173 - val_acc: 0.9424 - val_mDice: 0.5259

Epoch 00027: val_mDice did not improve from 0.54488
Epoch 28/300
 - 10s - loss: 1142.6134 - acc: 0.9520 - mDice: 0.7910 - val_loss: 2901.1068 - val_acc: 0.9419 - val_mDice: 0.5282

Epoch 00028: val_mDice did not improve from 0.54488
Epoch 29/300
 - 10s - loss: 1141.9464 - acc: 0.9521 - mDice: 0.7912 - val_loss: 2911.8199 - val_acc: 0.9464 - val_mDice: 0.5279

Epoch 00029: val_mDice did not improve from 0.54488
Epoch 30/300
 - 10s - loss: 1119.2308 - acc: 0.9525 - mDice: 0.7948 - val_loss: 3040.5291 - val_acc: 0.9435 - val_mDice: 0.5176

Epoch 00030: val_mDice did not improve from 0.54488
Epoch 31/300
 - 10s - loss: 1110.4034 - acc: 0.9528 - mDice: 0.7963 - val_loss: 2920.1652 - val_acc: 0.9482 - val_mDice: 0.5287

Epoch 00031: val_mDice did not improve from 0.54488
Epoch 32/300
 - 10s - loss: 1093.2885 - acc: 0.9532 - mDice: 0.7991 - val_loss: 2832.5993 - val_acc: 0.9475 - val_mDice: 0.5361

Epoch 00032: val_mDice did not improve from 0.54488
Epoch 33/300
 - 10s - loss: 1083.5277 - acc: 0.9534 - mDice: 0.8007 - val_loss: 2889.1807 - val_acc: 0.9464 - val_mDice: 0.5330

Epoch 00033: val_mDice did not improve from 0.54488
Epoch 34/300
 - 10s - loss: 1076.0973 - acc: 0.9535 - mDice: 0.8019 - val_loss: 2818.0554 - val_acc: 0.9467 - val_mDice: 0.5414

Epoch 00034: val_mDice did not improve from 0.54488
Epoch 35/300
 - 10s - loss: 1069.7079 - acc: 0.9538 - mDice: 0.8029 - val_loss: 3006.7392 - val_acc: 0.9450 - val_mDice: 0.5202

Epoch 00035: val_mDice did not improve from 0.54488
Epoch 36/300
 - 10s - loss: 1062.5492 - acc: 0.9539 - mDice: 0.8041 - val_loss: 2924.8156 - val_acc: 0.9414 - val_mDice: 0.5259

Epoch 00036: val_mDice did not improve from 0.54488
Epoch 37/300
 - 10s - loss: 1056.0769 - acc: 0.9539 - mDice: 0.8051 - val_loss: 2834.4920 - val_acc: 0.9451 - val_mDice: 0.5357

Epoch 00037: val_mDice did not improve from 0.54488
Epoch 38/300
 - 10s - loss: 1051.9079 - acc: 0.9541 - mDice: 0.8059 - val_loss: 3140.5126 - val_acc: 0.9433 - val_mDice: 0.5035

Epoch 00038: val_mDice did not improve from 0.54488
Epoch 39/300
 - 11s - loss: 1039.7757 - acc: 0.9542 - mDice: 0.8078 - val_loss: 2959.1773 - val_acc: 0.9447 - val_mDice: 0.5208

Epoch 00039: val_mDice did not improve from 0.54488
Epoch 40/300
 - 10s - loss: 1025.7721 - acc: 0.9544 - mDice: 0.8102 - val_loss: 3227.6568 - val_acc: 0.9423 - val_mDice: 0.4960

Epoch 00040: val_mDice did not improve from 0.54488
Epoch 41/300
 - 10s - loss: 1024.1666 - acc: 0.9546 - mDice: 0.8104 - val_loss: 3121.3297 - val_acc: 0.9440 - val_mDice: 0.5056

Epoch 00041: val_mDice did not improve from 0.54488
Epoch 42/300
 - 10s - loss: 1007.2911 - acc: 0.9550 - mDice: 0.8132 - val_loss: 2858.6807 - val_acc: 0.9460 - val_mDice: 0.5332

Epoch 00042: val_mDice did not improve from 0.54488
Epoch 43/300
 - 10s - loss: 1004.7461 - acc: 0.9550 - mDice: 0.8137 - val_loss: 3223.9934 - val_acc: 0.9416 - val_mDice: 0.4951

Epoch 00043: val_mDice did not improve from 0.54488
Epoch 44/300
 - 10s - loss: 1003.5119 - acc: 0.9550 - mDice: 0.8139 - val_loss: 2944.6417 - val_acc: 0.9461 - val_mDice: 0.5247

Epoch 00044: val_mDice did not improve from 0.54488
Epoch 45/300
 - 10s - loss: 996.7084 - acc: 0.9552 - mDice: 0.8150 - val_loss: 2725.4234 - val_acc: 0.9466 - val_mDice: 0.5472

Epoch 00045: val_mDice improved from 0.54488 to 0.54723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 46/300
 - 10s - loss: 997.1044 - acc: 0.9552 - mDice: 0.8150 - val_loss: 2709.3569 - val_acc: 0.9448 - val_mDice: 0.5499

Epoch 00046: val_mDice improved from 0.54723 to 0.54991, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 47/300
 - 10s - loss: 987.2509 - acc: 0.9554 - mDice: 0.8166 - val_loss: 2945.4977 - val_acc: 0.9444 - val_mDice: 0.5243

Epoch 00047: val_mDice did not improve from 0.54991
Epoch 48/300
 - 10s - loss: 973.6600 - acc: 0.9557 - mDice: 0.8189 - val_loss: 2873.8602 - val_acc: 0.9474 - val_mDice: 0.5306

Epoch 00048: val_mDice did not improve from 0.54991
Epoch 49/300
 - 10s - loss: 965.0960 - acc: 0.9557 - mDice: 0.8203 - val_loss: 2999.8465 - val_acc: 0.9393 - val_mDice: 0.5152

Epoch 00049: val_mDice did not improve from 0.54991
Epoch 50/300
 - 10s - loss: 965.8072 - acc: 0.9558 - mDice: 0.8202 - val_loss: 3176.9662 - val_acc: 0.9444 - val_mDice: 0.5022

Epoch 00050: val_mDice did not improve from 0.54991
Epoch 51/300
 - 10s - loss: 967.9566 - acc: 0.9556 - mDice: 0.8199 - val_loss: 3096.3797 - val_acc: 0.9477 - val_mDice: 0.5094

Epoch 00051: val_mDice did not improve from 0.54991
Epoch 52/300
 - 10s - loss: 958.6497 - acc: 0.9559 - mDice: 0.8213 - val_loss: 2946.0439 - val_acc: 0.9452 - val_mDice: 0.5248

Epoch 00052: val_mDice did not improve from 0.54991
Epoch 53/300
 - 10s - loss: 948.7304 - acc: 0.9561 - mDice: 0.8230 - val_loss: 3102.3440 - val_acc: 0.9427 - val_mDice: 0.5081

Epoch 00053: val_mDice did not improve from 0.54991
Epoch 54/300
 - 10s - loss: 948.2057 - acc: 0.9563 - mDice: 0.8231 - val_loss: 3023.4710 - val_acc: 0.9472 - val_mDice: 0.5160

Epoch 00054: val_mDice did not improve from 0.54991
Epoch 55/300
 - 10s - loss: 941.5703 - acc: 0.9562 - mDice: 0.8243 - val_loss: 2997.5474 - val_acc: 0.9436 - val_mDice: 0.5193

Epoch 00055: val_mDice did not improve from 0.54991
Epoch 56/300
 - 10s - loss: 937.8444 - acc: 0.9564 - mDice: 0.8249 - val_loss: 3243.3159 - val_acc: 0.9475 - val_mDice: 0.4939

Epoch 00056: val_mDice did not improve from 0.54991
Epoch 57/300
 - 10s - loss: 938.6539 - acc: 0.9564 - mDice: 0.8247 - val_loss: 3079.3436 - val_acc: 0.9426 - val_mDice: 0.5121

Epoch 00057: val_mDice did not improve from 0.54991
Epoch 58/300
 - 10s - loss: 942.7036 - acc: 0.9563 - mDice: 0.8241 - val_loss: 2895.7480 - val_acc: 0.9451 - val_mDice: 0.5303

Epoch 00058: val_mDice did not improve from 0.54991
Epoch 59/300
 - 10s - loss: 923.9372 - acc: 0.9566 - mDice: 0.8272 - val_loss: 2902.7496 - val_acc: 0.9438 - val_mDice: 0.5268

Epoch 00059: val_mDice did not improve from 0.54991
Epoch 60/300
 - 10s - loss: 924.7234 - acc: 0.9566 - mDice: 0.8271 - val_loss: 2776.5596 - val_acc: 0.9441 - val_mDice: 0.5412

Epoch 00060: val_mDice did not improve from 0.54991
Epoch 61/300
 - 10s - loss: 924.3403 - acc: 0.9566 - mDice: 0.8272 - val_loss: 3056.5209 - val_acc: 0.9407 - val_mDice: 0.5090

Epoch 00061: val_mDice did not improve from 0.54991
Epoch 62/300
 - 10s - loss: 912.0546 - acc: 0.9569 - mDice: 0.8292 - val_loss: 3303.2711 - val_acc: 0.9434 - val_mDice: 0.4906

Epoch 00062: val_mDice did not improve from 0.54991
Epoch 63/300
 - 11s - loss: 915.1443 - acc: 0.9567 - mDice: 0.8287 - val_loss: 3204.1355 - val_acc: 0.9414 - val_mDice: 0.4955

Epoch 00063: val_mDice did not improve from 0.54991
Epoch 64/300
 - 10s - loss: 912.1705 - acc: 0.9569 - mDice: 0.8292 - val_loss: 3049.7676 - val_acc: 0.9464 - val_mDice: 0.5127

Epoch 00064: val_mDice did not improve from 0.54991
Epoch 65/300
 - 10s - loss: 912.7220 - acc: 0.9570 - mDice: 0.8292 - val_loss: 2940.1985 - val_acc: 0.9432 - val_mDice: 0.5213

Epoch 00065: val_mDice did not improve from 0.54991
Epoch 66/300
 - 10s - loss: 906.9884 - acc: 0.9571 - mDice: 0.8301 - val_loss: 3028.7572 - val_acc: 0.9422 - val_mDice: 0.5148

Epoch 00066: val_mDice did not improve from 0.54991
Epoch 67/300
 - 10s - loss: 900.2175 - acc: 0.9572 - mDice: 0.8312 - val_loss: 2969.9829 - val_acc: 0.9443 - val_mDice: 0.5172

Epoch 00067: val_mDice did not improve from 0.54991
Epoch 68/300
 - 10s - loss: 897.5965 - acc: 0.9572 - mDice: 0.8317 - val_loss: 2967.6965 - val_acc: 0.9439 - val_mDice: 0.5196

Epoch 00068: val_mDice did not improve from 0.54991
Epoch 69/300
 - 10s - loss: 903.4890 - acc: 0.9571 - mDice: 0.8307 - val_loss: 3227.6628 - val_acc: 0.9473 - val_mDice: 0.4959

Epoch 00069: val_mDice did not improve from 0.54991
Epoch 70/300
 - 10s - loss: 895.8320 - acc: 0.9572 - mDice: 0.8320 - val_loss: 2937.5368 - val_acc: 0.9452 - val_mDice: 0.5236

Epoch 00070: val_mDice did not improve from 0.54991
Epoch 71/300
 - 10s - loss: 890.8884 - acc: 0.9574 - mDice: 0.8329 - val_loss: 3053.4827 - val_acc: 0.9432 - val_mDice: 0.5102

Epoch 00071: val_mDice did not improve from 0.54991
Epoch 72/300
 - 10s - loss: 890.3627 - acc: 0.9573 - mDice: 0.8329 - val_loss: 2951.9090 - val_acc: 0.9468 - val_mDice: 0.5195

Epoch 00072: val_mDice did not improve from 0.54991
Epoch 73/300
 - 10s - loss: 883.6800 - acc: 0.9575 - mDice: 0.8341 - val_loss: 2970.6060 - val_acc: 0.9402 - val_mDice: 0.5166

Epoch 00073: val_mDice did not improve from 0.54991
Epoch 74/300
 - 10s - loss: 887.1886 - acc: 0.9575 - mDice: 0.8335 - val_loss: 2951.4731 - val_acc: 0.9427 - val_mDice: 0.5179

Epoch 00074: val_mDice did not improve from 0.54991
Epoch 75/300
 - 10s - loss: 871.9239 - acc: 0.9577 - mDice: 0.8361 - val_loss: 2815.0653 - val_acc: 0.9428 - val_mDice: 0.5360

Epoch 00075: val_mDice did not improve from 0.54991
Epoch 76/300
 - 10s - loss: 877.8817 - acc: 0.9577 - mDice: 0.8351 - val_loss: 3075.5473 - val_acc: 0.9433 - val_mDice: 0.5082

Epoch 00076: val_mDice did not improve from 0.54991
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [6869.787702287947, 4427.412667410715, 4055.577218191964, 3386.7193777901784, 3444.415504092262, 3250.483642578125, 3193.2895159040177, 3097.5284598214284, 2821.934767950149, 3281.2105073474704, 3467.766863141741, 2973.784447079613, 2981.3185221354165, 3108.927932012649, 3025.481177920387, 2994.7200869605654, 2882.188738141741, 3061.63375999814, 2909.6812860398068, 2945.292701357887, 2868.6240350632443, 3363.2207612537204, 2918.842000325521, 3045.3333565848216, 2835.480003720238, 2780.7110305059523, 2928.417282831101, 2901.1068173363096, 2911.8198823474704, 3040.5290876116073, 2920.1651843843006, 2832.5993303571427, 2889.180681501116, 2818.055443173363, 3006.7391648065477, 2924.8155575706846, 2834.4920189267114, 3140.5125848679318, 2959.1772809709823, 3227.656778971354, 3121.3296712239585, 2858.680658249628, 3223.993448893229, 2944.6417061941966, 2725.423409598214, 2709.356869652158, 2945.4977097284227, 2873.8602469308034, 2999.8465343656994, 3176.9662097749256, 3096.3797433035716, 2946.043881370908, 3102.344034830729, 3023.4709821428573, 2997.547433035714, 3243.315854027158, 3079.343593052455, 2895.7479654947915, 2902.7496192568824, 2776.5595819382443, 3056.5209234328495, 3303.2710774739585, 3204.1354777018228, 3049.767572312128, 2940.198495047433, 3028.7571788969494, 2969.98292468843, 2967.696469261533, 3227.662786574591, 2937.536836170015, 3053.482729957217, 2951.908961704799, 2970.60597156343, 2951.4730689639136, 2815.0653308686756, 3075.5472702752977], 'val_acc': [0.9076030055681864, 0.9177312112989879, 0.9207509046509152, 0.9315704873629979, 0.930940948781513, 0.9400824365161714, 0.9433882662228176, 0.9455723507063729, 0.9445489928835914, 0.9448259813444955, 0.9420787323088873, 0.9486721356709799, 0.9423855514753432, 0.944626856417883, 0.9416712295441401, 0.9449015657107035, 0.9446954897471836, 0.9449725434893653, 0.9471817726180667, 0.9428434201649257, 0.9456273090271723, 0.9420329758099147, 0.9462316603887648, 0.9453388338997251, 0.9468108869734264, 0.9475961724917094, 0.9424358719871158, 0.9418566624323527, 0.9463713566462199, 0.9434844170297895, 0.9481776640528724, 0.947470261937096, 0.9463942391531808, 0.9467078504108247, 0.9450366553806123, 0.941355288028717, 0.9451075905845279, 0.9432669423875355, 0.9446657243229094, 0.942303098383404, 0.9440224454516456, 0.9460371023132688, 0.9415865483738127, 0.946114909081232, 0.946625448408581, 0.9448489121028355, 0.9443818557830084, 0.9474153092929295, 0.9392559783799308, 0.9443521045503163, 0.9476968731198993, 0.9452037782896132, 0.9426877214795067, 0.9472229878107706, 0.9436057465417045, 0.9474770909263974, 0.9425961659068153, 0.9451007105055309, 0.9438072301092602, 0.9441415099870591, 0.9407051205635071, 0.9434111884662083, 0.9413965401195344, 0.9464034125918434, 0.9432005740347362, 0.9421565873282296, 0.9443269059771583, 0.9438759315581549, 0.9472894015766326, 0.9451716826075599, 0.9431753385634649, 0.946831484635671, 0.9402220788456145, 0.9427495371727717, 0.9428068058831351, 0.9433012916928246], 'val_mDice': [0.24252244865610487, 0.3908816758720648, 0.42198136165028527, 0.4804747718430701, 0.47738301665300414, 0.4966244786268189, 0.5007203801402024, 0.5128348384584699, 0.538701247601282, 0.4957693911024502, 0.47041161890540806, 0.5236636048981121, 0.5237018350689184, 0.5087044379186063, 0.5176391449002993, 0.5207628194420111, 0.5358137477721486, 0.5123963565343902, 0.5285432838967868, 0.5249139792507603, 0.5328476993100983, 0.48074615250031155, 0.5280575440043495, 0.5130385809711048, 0.5357868634164333, 0.5448772314758528, 0.5258880913967178, 0.5281665946046511, 0.5278855872650942, 0.5175502208017168, 0.5287474954412097, 0.5360790865407103, 0.5330138431773299, 0.541424041525239, 0.520190474887689, 0.525928217740286, 0.5356621717413267, 0.5034869181967917, 0.5207676325170767, 0.49600881267161595, 0.5056205608305477, 0.5332305273484617, 0.49514603951857206, 0.5246715487114021, 0.5472316724203882, 0.5499088400531382, 0.5242949043001447, 0.5306427574583462, 0.5151814644535383, 0.5021585513438497, 0.5094451886557397, 0.5248483990629514, 0.508102916535877, 0.5160404206031844, 0.5192576703571138, 0.49393490081032115, 0.5121076238297281, 0.5303350438674291, 0.526801928523041, 0.5411667190492153, 0.5089836248329708, 0.49061737440171693, 0.49545628524252344, 0.512725286540531, 0.521343297724213, 0.5147811444032759, 0.5172146629719507, 0.5195512336989244, 0.4959191364191827, 0.5236402888383184, 0.5101625568100384, 0.51951026845546, 0.5165900854127747, 0.5179300788967383, 0.5360414492232459, 0.5081632041505405], 'loss': [12727.206275247163, 4546.827034345178, 3146.8418171141498, 2612.0451133938363, 2260.39145122798, 2038.2025029285578, 1928.6006729187752, 1806.5827419030222, 1728.3004602712083, 1651.1600000084723, 1593.0426385694554, 1542.5094892194052, 1476.6415343026285, 1432.5649681878224, 1412.4389058325087, 1385.2896918904835, 1345.938025205931, 1337.2646591336552, 1305.3811474887075, 1274.37705608579, 1252.0981075006664, 1233.2959373507952, 1209.482736252534, 1199.3833809494627, 1193.364149968427, 1173.205153998277, 1163.9106802910032, 1142.613432537643, 1141.9464460335785, 1119.2308444568641, 1110.4034437948462, 1093.2885465899574, 1083.527729305799, 1076.0973055478992, 1069.707944494556, 1062.5492473107347, 1056.076921759025, 1051.9078549998608, 1039.7756503803641, 1025.7721309452265, 1024.1665866043566, 1007.2910696588225, 1004.7461433123825, 1003.51186488372, 996.7084239388284, 997.104364869129, 987.2509432973396, 973.6599977727521, 965.0960271396641, 965.8071899649401, 967.9566132056591, 958.6496530021342, 948.7303562815166, 948.2057238950742, 941.5702847064701, 937.8444341420898, 938.653931452448, 942.7035872762962, 923.9371851870889, 924.723407016546, 924.3403193464807, 912.0546074612237, 915.1443450027563, 912.1705124345569, 912.7220396972563, 906.9884171582427, 900.2174611427156, 897.5964629638625, 903.4890207320434, 895.8320062217028, 890.88844205475, 890.362720025443, 883.6800021834748, 887.1886350279808, 871.9239196365501, 877.8816808138322], 'acc': [0.7311350653712543, 0.883935498425973, 0.896579605146757, 0.9105865617397779, 0.9242576659702487, 0.9328007251972267, 0.9357909363819635, 0.9383799711449519, 0.9401287278252023, 0.9415363731332796, 0.9427852876755872, 0.9438483417091605, 0.9449559545296338, 0.9457429176423048, 0.9461537335726574, 0.9468226776271053, 0.9476959538730969, 0.9477997179180297, 0.9485980796060145, 0.9491871787399967, 0.9497002015942113, 0.9501366458670905, 0.9506591947547085, 0.9508595587730592, 0.9510270677390575, 0.9514373484686526, 0.9516204304379812, 0.9520245499295583, 0.9521174216077395, 0.9525415814518124, 0.9528339861536477, 0.9532179164247566, 0.9534463692727244, 0.9535213296344934, 0.9537511500913283, 0.9538873756163976, 0.9539098097957672, 0.9541448400915531, 0.9541671982109374, 0.9543717385073813, 0.9545821400536308, 0.9550462698623903, 0.9550110713374254, 0.9549519601345338, 0.9552125747502137, 0.9551520055719761, 0.9554324513895561, 0.9556641023076751, 0.9557165338144106, 0.9557745386024925, 0.9555960673460364, 0.9559035359468675, 0.9561039724399617, 0.9562770877358816, 0.9561882695757357, 0.9563702372703016, 0.9564245095229089, 0.9562752574354738, 0.9566175046398251, 0.9566142405989267, 0.9566289273695563, 0.9569243944079655, 0.9567436075679411, 0.9569248814033088, 0.9569790533955488, 0.9570785090600178, 0.9571911019467195, 0.9572021076622693, 0.9570857169358331, 0.9572444440703964, 0.9573866247510275, 0.9573046418658474, 0.9575371046458823, 0.9575314706452486, 0.9577087850407044, 0.9576885335611336], 'mDice': [0.13774569609608406, 0.40361714411361016, 0.5281262093135473, 0.5884472891524598, 0.631323281202285, 0.6598858712081255, 0.6744875571896443, 0.6913600943785815, 0.7024338178628209, 0.7133556159562588, 0.7218936582233995, 0.7292940156731459, 0.739069335684051, 0.7457006125062192, 0.7487853919928856, 0.7529418501340058, 0.7590131565902604, 0.76033647935561, 0.7652852001368529, 0.7701572402837719, 0.7736370461120848, 0.7765915663182127, 0.780342056384913, 0.7819184068657195, 0.7829512959388908, 0.7861063889692301, 0.7876548192187129, 0.7910379538169274, 0.791150974772306, 0.794823686856398, 0.7963125650216694, 0.7990536694584588, 0.8006649121673713, 0.8018712687864684, 0.8029072671950565, 0.8040883287612197, 0.8051358119862742, 0.8058636446368701, 0.8078385552092281, 0.8101570998195143, 0.8104465558208527, 0.8132223376470286, 0.8136554407848199, 0.8138794631127887, 0.8150054388522459, 0.814986970237576, 0.8166081062488435, 0.8188566939321033, 0.820278278510879, 0.820176893745012, 0.819851877913669, 0.8213411087656104, 0.8230278342244067, 0.8231359007433473, 0.824255898735623, 0.8248872333853512, 0.8247325727653246, 0.8240950225014114, 0.8272333892066974, 0.8270759943341942, 0.8271557662857965, 0.8292443977975192, 0.8287267533942686, 0.829238526791719, 0.8291657207121113, 0.8301155009962861, 0.8312417708174994, 0.8317032495812687, 0.830735461374503, 0.8320169703956282, 0.8328596946474719, 0.8329400075339205, 0.8340962673741221, 0.8335222459400186, 0.8360799938032387, 0.8350972044506996]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.65s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.38s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.13s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:13,  1.53s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:43,  1.64s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:46,  1.65s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:18,  1.77s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:51,  1.68s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:18,  1.79s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:47,  1.90s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:57,  1.94s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:56,  1.94s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:28,  2.07s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:40,  2.12s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:53,  2.17s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<10:01,  2.21s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<09:57,  2.20s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:59,  2.22s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:56,  2.22s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:54,  2.22s/it]predicting train subjects:   6%|▋         | 18/285 [00:37<09:56,  2.23s/it]predicting train subjects:   7%|▋         | 19/285 [00:39<09:55,  2.24s/it]predicting train subjects:   7%|▋         | 20/285 [00:41<09:44,  2.21s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:30,  2.16s/it]predicting train subjects:   8%|▊         | 22/285 [00:45<09:30,  2.17s/it]predicting train subjects:   8%|▊         | 23/285 [00:48<09:34,  2.19s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<09:43,  2.24s/it]predicting train subjects:   9%|▉         | 25/285 [00:52<10:01,  2.31s/it]predicting train subjects:   9%|▉         | 26/285 [00:55<09:46,  2.27s/it]predicting train subjects:   9%|▉         | 27/285 [00:57<09:36,  2.23s/it]predicting train subjects:  10%|▉         | 28/285 [00:59<09:30,  2.22s/it]predicting train subjects:  10%|█         | 29/285 [01:01<09:19,  2.19s/it]predicting train subjects:  11%|█         | 30/285 [01:03<09:16,  2.18s/it]predicting train subjects:  11%|█         | 31/285 [01:05<09:08,  2.16s/it]predicting train subjects:  11%|█         | 32/285 [01:07<09:02,  2.15s/it]predicting train subjects:  12%|█▏        | 33/285 [01:10<09:02,  2.15s/it]predicting train subjects:  12%|█▏        | 34/285 [01:12<08:53,  2.13s/it]predicting train subjects:  12%|█▏        | 35/285 [01:14<08:57,  2.15s/it]predicting train subjects:  13%|█▎        | 36/285 [01:16<08:54,  2.14s/it]predicting train subjects:  13%|█▎        | 37/285 [01:18<08:43,  2.11s/it]predicting train subjects:  13%|█▎        | 38/285 [01:20<08:39,  2.10s/it]predicting train subjects:  14%|█▎        | 39/285 [01:22<08:24,  2.05s/it]predicting train subjects:  14%|█▍        | 40/285 [01:24<08:31,  2.09s/it]predicting train subjects:  14%|█▍        | 41/285 [01:26<08:35,  2.11s/it]predicting train subjects:  15%|█▍        | 42/285 [01:28<08:31,  2.11s/it]predicting train subjects:  15%|█▌        | 43/285 [01:30<08:20,  2.07s/it]predicting train subjects:  15%|█▌        | 44/285 [01:33<08:21,  2.08s/it]predicting train subjects:  16%|█▌        | 45/285 [01:35<08:18,  2.08s/it]predicting train subjects:  16%|█▌        | 46/285 [01:36<07:56,  1.99s/it]predicting train subjects:  16%|█▋        | 47/285 [01:38<07:39,  1.93s/it]predicting train subjects:  17%|█▋        | 48/285 [01:40<07:24,  1.88s/it]predicting train subjects:  17%|█▋        | 49/285 [01:42<07:25,  1.89s/it]predicting train subjects:  18%|█▊        | 50/285 [01:44<07:16,  1.86s/it]predicting train subjects:  18%|█▊        | 51/285 [01:46<07:19,  1.88s/it]predicting train subjects:  18%|█▊        | 52/285 [01:48<07:26,  1.92s/it]predicting train subjects:  19%|█▊        | 53/285 [01:49<07:18,  1.89s/it]predicting train subjects:  19%|█▉        | 54/285 [01:51<07:07,  1.85s/it]predicting train subjects:  19%|█▉        | 55/285 [01:53<07:11,  1.88s/it]predicting train subjects:  20%|█▉        | 56/285 [01:55<07:12,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:57<07:06,  1.87s/it]predicting train subjects:  20%|██        | 58/285 [01:59<07:09,  1.89s/it]predicting train subjects:  21%|██        | 59/285 [02:00<06:56,  1.84s/it]predicting train subjects:  21%|██        | 60/285 [02:02<06:48,  1.82s/it]predicting train subjects:  21%|██▏       | 61/285 [02:04<06:57,  1.86s/it]predicting train subjects:  22%|██▏       | 62/285 [02:06<06:50,  1.84s/it]predicting train subjects:  22%|██▏       | 63/285 [02:08<06:48,  1.84s/it]predicting train subjects:  22%|██▏       | 64/285 [02:10<06:57,  1.89s/it]predicting train subjects:  23%|██▎       | 65/285 [02:12<07:14,  1.98s/it]predicting train subjects:  23%|██▎       | 66/285 [02:14<07:19,  2.01s/it]predicting train subjects:  24%|██▎       | 67/285 [02:16<07:12,  1.98s/it]predicting train subjects:  24%|██▍       | 68/285 [02:18<07:08,  1.97s/it]predicting train subjects:  24%|██▍       | 69/285 [02:20<07:06,  1.97s/it]predicting train subjects:  25%|██▍       | 70/285 [02:22<07:04,  1.98s/it]predicting train subjects:  25%|██▍       | 71/285 [02:24<07:00,  1.97s/it]predicting train subjects:  25%|██▌       | 72/285 [02:26<06:47,  1.91s/it]predicting train subjects:  26%|██▌       | 73/285 [02:28<06:48,  1.93s/it]predicting train subjects:  26%|██▌       | 74/285 [02:30<06:57,  1.98s/it]predicting train subjects:  26%|██▋       | 75/285 [02:32<06:57,  1.99s/it]predicting train subjects:  27%|██▋       | 76/285 [02:34<06:58,  2.00s/it]predicting train subjects:  27%|██▋       | 77/285 [02:36<06:56,  2.00s/it]predicting train subjects:  27%|██▋       | 78/285 [02:38<06:54,  2.00s/it]predicting train subjects:  28%|██▊       | 79/285 [02:40<06:49,  1.99s/it]predicting train subjects:  28%|██▊       | 80/285 [02:42<06:48,  1.99s/it]predicting train subjects:  28%|██▊       | 81/285 [02:44<06:34,  1.93s/it]predicting train subjects:  29%|██▉       | 82/285 [02:45<06:19,  1.87s/it]predicting train subjects:  29%|██▉       | 83/285 [02:47<06:23,  1.90s/it]predicting train subjects:  29%|██▉       | 84/285 [02:49<06:19,  1.89s/it]predicting train subjects:  30%|██▉       | 85/285 [02:51<06:36,  1.98s/it]predicting train subjects:  30%|███       | 86/285 [02:54<06:50,  2.06s/it]predicting train subjects:  31%|███       | 87/285 [02:56<06:49,  2.07s/it]predicting train subjects:  31%|███       | 88/285 [02:58<06:59,  2.13s/it]predicting train subjects:  31%|███       | 89/285 [03:00<06:48,  2.09s/it]predicting train subjects:  32%|███▏      | 90/285 [03:02<06:59,  2.15s/it]predicting train subjects:  32%|███▏      | 91/285 [03:04<06:55,  2.14s/it]predicting train subjects:  32%|███▏      | 92/285 [03:06<06:52,  2.14s/it]predicting train subjects:  33%|███▎      | 93/285 [03:09<07:01,  2.20s/it]predicting train subjects:  33%|███▎      | 94/285 [03:11<07:06,  2.23s/it]predicting train subjects:  33%|███▎      | 95/285 [03:13<06:58,  2.20s/it]predicting train subjects:  34%|███▎      | 96/285 [03:15<06:56,  2.20s/it]predicting train subjects:  34%|███▍      | 97/285 [03:18<06:51,  2.19s/it]predicting train subjects:  34%|███▍      | 98/285 [03:20<06:48,  2.18s/it]predicting train subjects:  35%|███▍      | 99/285 [03:22<06:46,  2.18s/it]predicting train subjects:  35%|███▌      | 100/285 [03:24<06:36,  2.14s/it]predicting train subjects:  35%|███▌      | 101/285 [03:26<06:32,  2.13s/it]predicting train subjects:  36%|███▌      | 102/285 [03:28<06:32,  2.15s/it]predicting train subjects:  36%|███▌      | 103/285 [03:30<06:27,  2.13s/it]predicting train subjects:  36%|███▋      | 104/285 [03:32<06:24,  2.12s/it]predicting train subjects:  37%|███▋      | 105/285 [03:35<06:27,  2.15s/it]predicting train subjects:  37%|███▋      | 106/285 [03:37<06:31,  2.19s/it]predicting train subjects:  38%|███▊      | 107/285 [03:39<06:33,  2.21s/it]predicting train subjects:  38%|███▊      | 108/285 [03:41<06:20,  2.15s/it]predicting train subjects:  38%|███▊      | 109/285 [03:43<06:16,  2.14s/it]predicting train subjects:  39%|███▊      | 110/285 [03:46<06:20,  2.17s/it]predicting train subjects:  39%|███▉      | 111/285 [03:48<06:25,  2.21s/it]predicting train subjects:  39%|███▉      | 112/285 [03:50<06:17,  2.18s/it]predicting train subjects:  40%|███▉      | 113/285 [03:52<06:17,  2.20s/it]predicting train subjects:  40%|████      | 114/285 [03:54<06:16,  2.20s/it]predicting train subjects:  40%|████      | 115/285 [03:57<06:16,  2.21s/it]predicting train subjects:  41%|████      | 116/285 [03:59<06:05,  2.16s/it]predicting train subjects:  41%|████      | 117/285 [04:01<06:00,  2.15s/it]predicting train subjects:  41%|████▏     | 118/285 [04:03<05:55,  2.13s/it]predicting train subjects:  42%|████▏     | 119/285 [04:05<05:54,  2.14s/it]predicting train subjects:  42%|████▏     | 120/285 [04:07<05:58,  2.17s/it]predicting train subjects:  42%|████▏     | 121/285 [04:09<05:43,  2.10s/it]predicting train subjects:  43%|████▎     | 122/285 [04:11<05:24,  1.99s/it]predicting train subjects:  43%|████▎     | 123/285 [04:13<05:08,  1.90s/it]predicting train subjects:  44%|████▎     | 124/285 [04:15<05:07,  1.91s/it]predicting train subjects:  44%|████▍     | 125/285 [04:16<05:02,  1.89s/it]predicting train subjects:  44%|████▍     | 126/285 [04:18<05:01,  1.90s/it]predicting train subjects:  45%|████▍     | 127/285 [04:20<04:58,  1.89s/it]predicting train subjects:  45%|████▍     | 128/285 [04:22<05:00,  1.91s/it]predicting train subjects:  45%|████▌     | 129/285 [04:24<04:56,  1.90s/it]predicting train subjects:  46%|████▌     | 130/285 [04:26<05:00,  1.94s/it]predicting train subjects:  46%|████▌     | 131/285 [04:28<05:00,  1.95s/it]predicting train subjects:  46%|████▋     | 132/285 [04:30<04:58,  1.95s/it]predicting train subjects:  47%|████▋     | 133/285 [04:32<04:54,  1.94s/it]predicting train subjects:  47%|████▋     | 134/285 [04:34<04:53,  1.94s/it]predicting train subjects:  47%|████▋     | 135/285 [04:36<04:52,  1.95s/it]predicting train subjects:  48%|████▊     | 136/285 [04:38<04:56,  1.99s/it]predicting train subjects:  48%|████▊     | 137/285 [04:40<04:56,  2.00s/it]predicting train subjects:  48%|████▊     | 138/285 [04:42<04:44,  1.94s/it]predicting train subjects:  49%|████▉     | 139/285 [04:44<04:37,  1.90s/it]predicting train subjects:  49%|████▉     | 140/285 [04:46<04:36,  1.91s/it]predicting train subjects:  49%|████▉     | 141/285 [04:48<04:38,  1.94s/it]predicting train subjects:  50%|████▉     | 142/285 [04:49<04:23,  1.84s/it]predicting train subjects:  50%|█████     | 143/285 [04:51<04:18,  1.82s/it]predicting train subjects:  51%|█████     | 144/285 [04:53<04:17,  1.83s/it]predicting train subjects:  51%|█████     | 145/285 [04:55<04:17,  1.84s/it]predicting train subjects:  51%|█████     | 146/285 [04:56<04:10,  1.80s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:58<04:01,  1.75s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:00<03:56,  1.72s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:01<03:53,  1.71s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:03<03:50,  1.71s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:05<03:55,  1.76s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:07<03:52,  1.75s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:08<03:52,  1.76s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:10<03:50,  1.76s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:12<03:43,  1.72s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:14<03:42,  1.72s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:15<03:43,  1.74s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:17<03:41,  1.74s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:19<03:54,  1.86s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:21<03:48,  1.83s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:23<03:39,  1.77s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:24<03:35,  1.75s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:26<03:32,  1.74s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:28<03:25,  1.70s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:29<03:21,  1.68s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:31<03:17,  1.66s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:33<03:16,  1.66s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:34<03:17,  1.68s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:36<03:13,  1.67s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:38<03:13,  1.69s/it]predicting train subjects:  60%|██████    | 171/285 [05:39<03:17,  1.73s/it]predicting train subjects:  60%|██████    | 172/285 [05:41<03:16,  1.74s/it]predicting train subjects:  61%|██████    | 173/285 [05:43<03:14,  1.73s/it]predicting train subjects:  61%|██████    | 174/285 [05:45<03:09,  1.71s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:46<03:05,  1.69s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:48<03:03,  1.68s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:50<03:00,  1.67s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:51<02:57,  1.66s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:53<02:53,  1.64s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:54<02:50,  1.63s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:56<02:49,  1.63s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:58<02:45,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:59<02:47,  1.64s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:01<02:50,  1.69s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:03<02:47,  1.67s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:04<02:44,  1.66s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:06<02:43,  1.67s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:08<02:45,  1.71s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:09<02:41,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:11<02:40,  1.69s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:13<02:35,  1.66s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:14<02:28,  1.60s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:16<02:26,  1.59s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:17<02:22,  1.56s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:19<02:20,  1.56s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:21<02:29,  1.68s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:23<02:36,  1.78s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:25<02:35,  1.79s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:26<02:33,  1.79s/it]predicting train subjects:  70%|███████   | 200/285 [06:28<02:31,  1.78s/it]predicting train subjects:  71%|███████   | 201/285 [06:30<02:26,  1.75s/it]predicting train subjects:  71%|███████   | 202/285 [06:32<02:26,  1.76s/it]predicting train subjects:  71%|███████   | 203/285 [06:33<02:25,  1.77s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:35<02:22,  1.76s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:37<02:21,  1.77s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:39<02:18,  1.76s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:40<02:18,  1.77s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:42<02:16,  1.77s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:44<02:15,  1.78s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:46<02:15,  1.80s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:48<02:12,  1.79s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:49<02:11,  1.80s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:51<02:11,  1.82s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:53<02:05,  1.77s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:55<01:59,  1.70s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:56<01:54,  1.66s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:58<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:59<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:01<01:49,  1.66s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:03<01:46,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:04<01:44,  1.64s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:06<01:41,  1.61s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:07<01:39,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:09<01:37,  1.59s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:11<01:34,  1.57s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:12<01:31,  1.56s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:14<01:31,  1.57s/it]predicting train subjects:  80%|████████  | 228/285 [07:15<01:28,  1.56s/it]predicting train subjects:  80%|████████  | 229/285 [07:17<01:28,  1.58s/it]predicting train subjects:  81%|████████  | 230/285 [07:18<01:26,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [07:20<01:24,  1.56s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:22<01:30,  1.71s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:24<01:32,  1.78s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:26<01:33,  1.83s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:28<01:33,  1.87s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:30<01:32,  1.90s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:32<01:33,  1.94s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:34<01:32,  1.96s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:36<01:30,  1.97s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:38<01:29,  1.98s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:40<01:28,  2.00s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:42<01:25,  1.99s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:44<01:24,  2.00s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:46<01:21,  1.99s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:48<01:20,  2.02s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:50<01:18,  2.00s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:52<01:15,  1.99s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:54<01:13,  2.00s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:56<01:12,  2.00s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:57<01:04,  1.86s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:59<00:58,  1.73s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:00<00:54,  1.65s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:02<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:03<00:49,  1.61s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:05<00:47,  1.57s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:06<00:44,  1.54s/it]predicting train subjects:  90%|█████████ | 257/285 [08:08<00:42,  1.52s/it]predicting train subjects:  91%|█████████ | 258/285 [08:09<00:41,  1.52s/it]predicting train subjects:  91%|█████████ | 259/285 [08:11<00:39,  1.50s/it]predicting train subjects:  91%|█████████ | 260/285 [08:12<00:37,  1.50s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:14<00:36,  1.50s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:15<00:34,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:17<00:33,  1.51s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:18<00:31,  1.51s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:20<00:29,  1.50s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:21<00:28,  1.48s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:23<00:26,  1.50s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:25<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:27<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:29<00:27,  1.83s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:31<00:26,  1.89s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:33<00:25,  1.95s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:35<00:23,  1.96s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:37<00:21,  1.98s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:39<00:20,  2.01s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:41<00:18,  2.02s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:43<00:16,  2.01s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:45<00:14,  2.01s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:47<00:12,  2.01s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:49<00:10,  2.00s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:51<00:08,  2.02s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:53<00:06,  2.00s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:55<00:04,  2.04s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:57<00:02,  2.05s/it]predicting train subjects: 100%|██████████| 285/285 [08:59<00:00,  2.04s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:11,  1.52s/it]Loading train:   1%|          | 2/285 [00:03<07:17,  1.55s/it]Loading train:   1%|          | 3/285 [00:04<07:24,  1.57s/it]Loading train:   1%|▏         | 4/285 [00:06<07:39,  1.63s/it]Loading train:   2%|▏         | 5/285 [00:07<07:15,  1.55s/it]Loading train:   2%|▏         | 6/285 [00:09<07:45,  1.67s/it]Loading train:   2%|▏         | 7/285 [00:11<08:03,  1.74s/it]Loading train:   3%|▎         | 8/285 [00:13<07:56,  1.72s/it]Loading train:   3%|▎         | 9/285 [00:14<07:35,  1.65s/it]Loading train:   4%|▎         | 10/285 [00:16<07:09,  1.56s/it]Loading train:   4%|▍         | 11/285 [00:17<07:00,  1.54s/it]Loading train:   4%|▍         | 12/285 [00:19<06:37,  1.46s/it]Loading train:   5%|▍         | 13/285 [00:20<06:20,  1.40s/it]Loading train:   5%|▍         | 14/285 [00:21<06:14,  1.38s/it]Loading train:   5%|▌         | 15/285 [00:22<06:07,  1.36s/it]Loading train:   6%|▌         | 16/285 [00:24<06:04,  1.35s/it]Loading train:   6%|▌         | 17/285 [00:25<06:13,  1.39s/it]Loading train:   6%|▋         | 18/285 [00:27<06:00,  1.35s/it]Loading train:   7%|▋         | 19/285 [00:28<05:51,  1.32s/it]Loading train:   7%|▋         | 20/285 [00:29<05:53,  1.34s/it]Loading train:   7%|▋         | 21/285 [00:30<05:52,  1.33s/it]Loading train:   8%|▊         | 22/285 [00:32<05:56,  1.36s/it]Loading train:   8%|▊         | 23/285 [00:33<05:57,  1.36s/it]Loading train:   8%|▊         | 24/285 [00:35<05:57,  1.37s/it]Loading train:   9%|▉         | 25/285 [00:36<05:50,  1.35s/it]Loading train:   9%|▉         | 26/285 [00:37<06:03,  1.40s/it]Loading train:   9%|▉         | 27/285 [00:39<06:00,  1.40s/it]Loading train:  10%|▉         | 28/285 [00:40<05:45,  1.34s/it]Loading train:  10%|█         | 29/285 [00:41<05:28,  1.28s/it]Loading train:  11%|█         | 30/285 [00:42<05:20,  1.26s/it]Loading train:  11%|█         | 31/285 [00:43<05:05,  1.20s/it]Loading train:  11%|█         | 32/285 [00:45<04:58,  1.18s/it]Loading train:  12%|█▏        | 33/285 [00:46<05:00,  1.19s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:05,  1.22s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:02,  1.21s/it]Loading train:  13%|█▎        | 36/285 [00:49<04:57,  1.19s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:03,  1.22s/it]Loading train:  13%|█▎        | 38/285 [00:52<05:02,  1.23s/it]Loading train:  14%|█▎        | 39/285 [00:53<04:56,  1.21s/it]Loading train:  14%|█▍        | 40/285 [00:54<04:57,  1.22s/it]Loading train:  14%|█▍        | 41/285 [00:56<04:50,  1.19s/it]Loading train:  15%|█▍        | 42/285 [00:57<04:45,  1.17s/it]Loading train:  15%|█▌        | 43/285 [00:58<04:41,  1.16s/it]Loading train:  15%|█▌        | 44/285 [00:59<04:39,  1.16s/it]Loading train:  16%|█▌        | 45/285 [01:00<04:44,  1.19s/it]Loading train:  16%|█▌        | 46/285 [01:01<04:38,  1.16s/it]Loading train:  16%|█▋        | 47/285 [01:02<04:27,  1.12s/it]Loading train:  17%|█▋        | 48/285 [01:03<04:19,  1.09s/it]Loading train:  17%|█▋        | 49/285 [01:04<04:08,  1.05s/it]Loading train:  18%|█▊        | 50/285 [01:05<03:59,  1.02s/it]Loading train:  18%|█▊        | 51/285 [01:06<03:58,  1.02s/it]Loading train:  18%|█▊        | 52/285 [01:07<03:51,  1.00it/s]Loading train:  19%|█▊        | 53/285 [01:08<03:50,  1.01it/s]Loading train:  19%|█▉        | 54/285 [01:09<03:53,  1.01s/it]Loading train:  19%|█▉        | 55/285 [01:10<04:00,  1.05s/it]Loading train:  20%|█▉        | 56/285 [01:11<03:50,  1.01s/it]Loading train:  20%|██        | 57/285 [01:12<03:51,  1.02s/it]Loading train:  20%|██        | 58/285 [01:13<03:52,  1.02s/it]Loading train:  21%|██        | 59/285 [01:14<03:56,  1.05s/it]Loading train:  21%|██        | 60/285 [01:15<03:46,  1.01s/it]Loading train:  21%|██▏       | 61/285 [01:16<03:51,  1.03s/it]Loading train:  22%|██▏       | 62/285 [01:18<03:52,  1.04s/it]Loading train:  22%|██▏       | 63/285 [01:19<03:55,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:20<04:25,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:22<04:54,  1.34s/it]Loading train:  23%|██▎       | 66/285 [01:23<05:02,  1.38s/it]Loading train:  24%|██▎       | 67/285 [01:25<04:55,  1.36s/it]Loading train:  24%|██▍       | 68/285 [01:26<04:39,  1.29s/it]Loading train:  24%|██▍       | 69/285 [01:27<04:28,  1.24s/it]Loading train:  25%|██▍       | 70/285 [01:28<04:12,  1.17s/it]Loading train:  25%|██▍       | 71/285 [01:29<04:08,  1.16s/it]Loading train:  25%|██▌       | 72/285 [01:30<03:57,  1.12s/it]Loading train:  26%|██▌       | 73/285 [01:31<03:51,  1.09s/it]Loading train:  26%|██▌       | 74/285 [01:32<03:49,  1.09s/it]Loading train:  26%|██▋       | 75/285 [01:33<04:00,  1.15s/it]Loading train:  27%|██▋       | 76/285 [01:34<03:52,  1.11s/it]Loading train:  27%|██▋       | 77/285 [01:36<03:51,  1.11s/it]Loading train:  27%|██▋       | 78/285 [01:37<03:45,  1.09s/it]Loading train:  28%|██▊       | 79/285 [01:38<04:08,  1.21s/it]Loading train:  28%|██▊       | 80/285 [01:39<03:57,  1.16s/it]Loading train:  28%|██▊       | 81/285 [01:40<03:51,  1.13s/it]Loading train:  29%|██▉       | 82/285 [01:41<03:43,  1.10s/it]Loading train:  29%|██▉       | 83/285 [01:42<03:37,  1.08s/it]Loading train:  29%|██▉       | 84/285 [01:43<03:32,  1.06s/it]Loading train:  30%|██▉       | 85/285 [01:44<03:39,  1.10s/it]Loading train:  30%|███       | 86/285 [01:46<03:45,  1.13s/it]Loading train:  31%|███       | 87/285 [01:47<03:44,  1.13s/it]Loading train:  31%|███       | 88/285 [01:48<03:49,  1.16s/it]Loading train:  31%|███       | 89/285 [01:49<03:46,  1.16s/it]Loading train:  32%|███▏      | 90/285 [01:50<03:49,  1.18s/it]Loading train:  32%|███▏      | 91/285 [01:52<03:52,  1.20s/it]Loading train:  32%|███▏      | 92/285 [01:53<03:53,  1.21s/it]Loading train:  33%|███▎      | 93/285 [01:54<03:50,  1.20s/it]Loading train:  33%|███▎      | 94/285 [01:55<03:55,  1.23s/it]Loading train:  33%|███▎      | 95/285 [01:56<03:44,  1.18s/it]Loading train:  34%|███▎      | 96/285 [01:58<03:52,  1.23s/it]Loading train:  34%|███▍      | 97/285 [01:59<03:48,  1.21s/it]Loading train:  34%|███▍      | 98/285 [02:00<03:45,  1.21s/it]Loading train:  35%|███▍      | 99/285 [02:01<03:45,  1.21s/it]Loading train:  35%|███▌      | 100/285 [02:02<03:39,  1.19s/it]Loading train:  35%|███▌      | 101/285 [02:04<03:37,  1.18s/it]Loading train:  36%|███▌      | 102/285 [02:05<03:39,  1.20s/it]Loading train:  36%|███▌      | 103/285 [02:06<03:37,  1.20s/it]Loading train:  36%|███▋      | 104/285 [02:08<03:54,  1.30s/it]Loading train:  37%|███▋      | 105/285 [02:09<03:50,  1.28s/it]Loading train:  37%|███▋      | 106/285 [02:10<03:51,  1.29s/it]Loading train:  38%|███▊      | 107/285 [02:11<03:46,  1.27s/it]Loading train:  38%|███▊      | 108/285 [02:13<03:41,  1.25s/it]Loading train:  38%|███▊      | 109/285 [02:14<03:35,  1.22s/it]Loading train:  39%|███▊      | 110/285 [02:15<03:27,  1.19s/it]Loading train:  39%|███▉      | 111/285 [02:16<03:36,  1.25s/it]Loading train:  39%|███▉      | 112/285 [02:17<03:25,  1.19s/it]Loading train:  40%|███▉      | 113/285 [02:18<03:20,  1.16s/it]Loading train:  40%|████      | 114/285 [02:20<03:18,  1.16s/it]Loading train:  40%|████      | 115/285 [02:21<03:18,  1.17s/it]Loading train:  41%|████      | 116/285 [02:22<03:12,  1.14s/it]Loading train:  41%|████      | 117/285 [02:23<03:14,  1.16s/it]Loading train:  41%|████▏     | 118/285 [02:24<03:12,  1.15s/it]Loading train:  42%|████▏     | 119/285 [02:25<03:09,  1.14s/it]Loading train:  42%|████▏     | 120/285 [02:26<03:10,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:28<03:26,  1.26s/it]Loading train:  43%|████▎     | 122/285 [02:29<03:36,  1.33s/it]Loading train:  43%|████▎     | 123/285 [02:31<03:32,  1.31s/it]Loading train:  44%|████▎     | 124/285 [02:32<03:20,  1.24s/it]Loading train:  44%|████▍     | 125/285 [02:33<03:05,  1.16s/it]Loading train:  44%|████▍     | 126/285 [02:34<02:54,  1.10s/it]Loading train:  45%|████▍     | 127/285 [02:35<02:50,  1.08s/it]Loading train:  45%|████▍     | 128/285 [02:36<02:43,  1.04s/it]Loading train:  45%|████▌     | 129/285 [02:37<02:42,  1.04s/it]Loading train:  46%|████▌     | 130/285 [02:38<02:36,  1.01s/it]Loading train:  46%|████▌     | 131/285 [02:39<02:40,  1.04s/it]Loading train:  46%|████▋     | 132/285 [02:40<02:33,  1.00s/it]Loading train:  47%|████▋     | 133/285 [02:41<02:35,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:42<02:36,  1.04s/it]Loading train:  47%|████▋     | 135/285 [02:43<02:35,  1.03s/it]Loading train:  48%|████▊     | 136/285 [02:44<02:30,  1.01s/it]Loading train:  48%|████▊     | 137/285 [02:45<02:32,  1.03s/it]Loading train:  48%|████▊     | 138/285 [02:46<02:32,  1.04s/it]Loading train:  49%|████▉     | 139/285 [02:47<02:29,  1.03s/it]Loading train:  49%|████▉     | 140/285 [02:48<02:34,  1.07s/it]Loading train:  49%|████▉     | 141/285 [02:49<02:27,  1.02s/it]Loading train:  50%|████▉     | 142/285 [02:50<02:38,  1.11s/it]Loading train:  50%|█████     | 143/285 [02:51<02:34,  1.09s/it]Loading train:  51%|█████     | 144/285 [02:53<02:33,  1.09s/it]Loading train:  51%|█████     | 145/285 [02:54<02:28,  1.06s/it]Loading train:  51%|█████     | 146/285 [02:54<02:22,  1.02s/it]Loading train:  52%|█████▏    | 147/285 [02:55<02:17,  1.00it/s]Loading train:  52%|█████▏    | 148/285 [02:56<02:14,  1.02it/s]Loading train:  52%|█████▏    | 149/285 [02:57<02:10,  1.05it/s]Loading train:  53%|█████▎    | 150/285 [02:58<02:09,  1.04it/s]Loading train:  53%|█████▎    | 151/285 [02:59<02:10,  1.02it/s]Loading train:  53%|█████▎    | 152/285 [03:00<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [03:01<02:13,  1.01s/it]Loading train:  54%|█████▍    | 154/285 [03:02<02:10,  1.00it/s]Loading train:  54%|█████▍    | 155/285 [03:03<02:15,  1.04s/it]Loading train:  55%|█████▍    | 156/285 [03:04<02:11,  1.02s/it]Loading train:  55%|█████▌    | 157/285 [03:05<02:09,  1.01s/it]Loading train:  55%|█████▌    | 158/285 [03:06<02:07,  1.00s/it]Loading train:  56%|█████▌    | 159/285 [03:07<02:04,  1.01it/s]Loading train:  56%|█████▌    | 160/285 [03:08<02:03,  1.01it/s]Loading train:  56%|█████▋    | 161/285 [03:09<02:05,  1.01s/it]Loading train:  57%|█████▋    | 162/285 [03:10<02:01,  1.02it/s]Loading train:  57%|█████▋    | 163/285 [03:11<02:03,  1.01s/it]Loading train:  58%|█████▊    | 164/285 [03:12<01:59,  1.01it/s]Loading train:  58%|█████▊    | 165/285 [03:13<01:55,  1.04it/s]Loading train:  58%|█████▊    | 166/285 [03:14<01:53,  1.05it/s]Loading train:  59%|█████▊    | 167/285 [03:15<01:53,  1.04it/s]Loading train:  59%|█████▉    | 168/285 [03:16<01:55,  1.02it/s]Loading train:  59%|█████▉    | 169/285 [03:17<01:54,  1.02it/s]Loading train:  60%|█████▉    | 170/285 [03:18<01:54,  1.01it/s]Loading train:  60%|██████    | 171/285 [03:19<01:51,  1.02it/s]Loading train:  60%|██████    | 172/285 [03:20<01:52,  1.01it/s]Loading train:  61%|██████    | 173/285 [03:21<01:52,  1.00s/it]Loading train:  61%|██████    | 174/285 [03:22<01:53,  1.02s/it]Loading train:  61%|██████▏   | 175/285 [03:23<01:50,  1.00s/it]Loading train:  62%|██████▏   | 176/285 [03:24<01:47,  1.02it/s]Loading train:  62%|██████▏   | 177/285 [03:25<01:43,  1.05it/s]Loading train:  62%|██████▏   | 178/285 [03:26<01:39,  1.08it/s]Loading train:  63%|██████▎   | 179/285 [03:27<01:36,  1.09it/s]Loading train:  63%|██████▎   | 180/285 [03:28<01:43,  1.01it/s]Loading train:  64%|██████▎   | 181/285 [03:29<01:42,  1.02it/s]Loading train:  64%|██████▍   | 182/285 [03:30<01:40,  1.02it/s]Loading train:  64%|██████▍   | 183/285 [03:31<01:38,  1.03it/s]Loading train:  65%|██████▍   | 184/285 [03:32<01:37,  1.03it/s]Loading train:  65%|██████▍   | 185/285 [03:33<01:41,  1.01s/it]Loading train:  65%|██████▌   | 186/285 [03:34<01:41,  1.02s/it]Loading train:  66%|██████▌   | 187/285 [03:35<01:39,  1.02s/it]Loading train:  66%|██████▌   | 188/285 [03:36<01:38,  1.01s/it]Loading train:  66%|██████▋   | 189/285 [03:37<01:38,  1.03s/it]Loading train:  67%|██████▋   | 190/285 [03:38<01:34,  1.01it/s]Loading train:  67%|██████▋   | 191/285 [03:39<01:31,  1.02it/s]Loading train:  67%|██████▋   | 192/285 [03:40<01:28,  1.05it/s]Loading train:  68%|██████▊   | 193/285 [03:41<01:29,  1.03it/s]Loading train:  68%|██████▊   | 194/285 [03:42<01:29,  1.02it/s]Loading train:  68%|██████▊   | 195/285 [03:43<01:32,  1.03s/it]Loading train:  69%|██████▉   | 196/285 [03:44<01:34,  1.06s/it]Loading train:  69%|██████▉   | 197/285 [03:45<01:34,  1.07s/it]Loading train:  69%|██████▉   | 198/285 [03:46<01:35,  1.09s/it]Loading train:  70%|██████▉   | 199/285 [03:47<01:32,  1.07s/it]Loading train:  70%|███████   | 200/285 [03:48<01:30,  1.07s/it]Loading train:  71%|███████   | 201/285 [03:49<01:29,  1.07s/it]Loading train:  71%|███████   | 202/285 [03:50<01:26,  1.04s/it]Loading train:  71%|███████   | 203/285 [03:51<01:22,  1.01s/it]Loading train:  72%|███████▏  | 204/285 [03:52<01:19,  1.02it/s]Loading train:  72%|███████▏  | 205/285 [03:53<01:17,  1.03it/s]Loading train:  72%|███████▏  | 206/285 [03:54<01:18,  1.01it/s]Loading train:  73%|███████▎  | 207/285 [03:55<01:20,  1.03s/it]Loading train:  73%|███████▎  | 208/285 [03:56<01:18,  1.02s/it]Loading train:  73%|███████▎  | 209/285 [03:58<01:21,  1.07s/it]Loading train:  74%|███████▎  | 210/285 [03:59<01:18,  1.05s/it]Loading train:  74%|███████▍  | 211/285 [04:00<01:19,  1.08s/it]Loading train:  74%|███████▍  | 212/285 [04:01<01:17,  1.06s/it]Loading train:  75%|███████▍  | 213/285 [04:02<01:19,  1.11s/it]Loading train:  75%|███████▌  | 214/285 [04:03<01:13,  1.03s/it]Loading train:  75%|███████▌  | 215/285 [04:04<01:09,  1.01it/s]Loading train:  76%|███████▌  | 216/285 [04:05<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [04:06<01:08,  1.01s/it]Loading train:  76%|███████▋  | 218/285 [04:07<01:05,  1.02it/s]Loading train:  77%|███████▋  | 219/285 [04:08<01:04,  1.02it/s]Loading train:  77%|███████▋  | 220/285 [04:09<01:02,  1.03it/s]Loading train:  78%|███████▊  | 221/285 [04:09<01:01,  1.04it/s]Loading train:  78%|███████▊  | 222/285 [04:10<00:59,  1.06it/s]Loading train:  78%|███████▊  | 223/285 [04:11<00:57,  1.07it/s]Loading train:  79%|███████▊  | 224/285 [04:13<01:02,  1.02s/it]Loading train:  79%|███████▉  | 225/285 [04:14<01:01,  1.03s/it]Loading train:  79%|███████▉  | 226/285 [04:15<01:00,  1.02s/it]Loading train:  80%|███████▉  | 227/285 [04:16<00:57,  1.00it/s]Loading train:  80%|████████  | 228/285 [04:16<00:55,  1.02it/s]Loading train:  80%|████████  | 229/285 [04:17<00:54,  1.04it/s]Loading train:  81%|████████  | 230/285 [04:18<00:52,  1.06it/s]Loading train:  81%|████████  | 231/285 [04:19<00:52,  1.03it/s]Loading train:  81%|████████▏ | 232/285 [04:20<00:54,  1.03s/it]Loading train:  82%|████████▏ | 233/285 [04:22<00:55,  1.07s/it]Loading train:  82%|████████▏ | 234/285 [04:23<00:55,  1.10s/it]Loading train:  82%|████████▏ | 235/285 [04:24<00:55,  1.10s/it]Loading train:  83%|████████▎ | 236/285 [04:25<00:53,  1.09s/it]Loading train:  83%|████████▎ | 237/285 [04:26<00:53,  1.11s/it]Loading train:  84%|████████▎ | 238/285 [04:27<00:53,  1.13s/it]Loading train:  84%|████████▍ | 239/285 [04:29<00:54,  1.19s/it]Loading train:  84%|████████▍ | 240/285 [04:30<00:51,  1.15s/it]Loading train:  85%|████████▍ | 241/285 [04:31<00:49,  1.14s/it]Loading train:  85%|████████▍ | 242/285 [04:32<00:47,  1.11s/it]Loading train:  85%|████████▌ | 243/285 [04:33<00:51,  1.23s/it]Loading train:  86%|████████▌ | 244/285 [04:35<00:49,  1.21s/it]Loading train:  86%|████████▌ | 245/285 [04:36<00:46,  1.15s/it]Loading train:  86%|████████▋ | 246/285 [04:37<00:45,  1.17s/it]Loading train:  87%|████████▋ | 247/285 [04:38<00:44,  1.18s/it]Loading train:  87%|████████▋ | 248/285 [04:39<00:44,  1.19s/it]Loading train:  87%|████████▋ | 249/285 [04:40<00:41,  1.17s/it]Loading train:  88%|████████▊ | 250/285 [04:41<00:37,  1.09s/it]Loading train:  88%|████████▊ | 251/285 [04:42<00:34,  1.03s/it]Loading train:  88%|████████▊ | 252/285 [04:43<00:33,  1.01s/it]Loading train:  89%|████████▉ | 253/285 [04:44<00:31,  1.02it/s]Loading train:  89%|████████▉ | 254/285 [04:45<00:29,  1.04it/s]Loading train:  89%|████████▉ | 255/285 [04:46<00:28,  1.04it/s]Loading train:  90%|████████▉ | 256/285 [04:47<00:29,  1.02s/it]Loading train:  90%|█████████ | 257/285 [04:48<00:27,  1.01it/s]Loading train:  91%|█████████ | 258/285 [04:49<00:25,  1.05it/s]Loading train:  91%|█████████ | 259/285 [04:50<00:25,  1.03it/s]Loading train:  91%|█████████ | 260/285 [04:51<00:23,  1.07it/s]Loading train:  92%|█████████▏| 261/285 [04:51<00:21,  1.12it/s]Loading train:  92%|█████████▏| 262/285 [04:52<00:20,  1.12it/s]Loading train:  92%|█████████▏| 263/285 [04:53<00:19,  1.11it/s]Loading train:  93%|█████████▎| 264/285 [04:54<00:18,  1.11it/s]Loading train:  93%|█████████▎| 265/285 [04:55<00:18,  1.09it/s]Loading train:  93%|█████████▎| 266/285 [04:56<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [04:57<00:17,  1.05it/s]Loading train:  94%|█████████▍| 268/285 [04:58<00:16,  1.01it/s]Loading train:  94%|█████████▍| 269/285 [04:59<00:16,  1.02s/it]Loading train:  95%|█████████▍| 270/285 [05:00<00:15,  1.04s/it]Loading train:  95%|█████████▌| 271/285 [05:01<00:14,  1.05s/it]Loading train:  95%|█████████▌| 272/285 [05:03<00:14,  1.08s/it]Loading train:  96%|█████████▌| 273/285 [05:04<00:12,  1.07s/it]Loading train:  96%|█████████▌| 274/285 [05:05<00:12,  1.09s/it]Loading train:  96%|█████████▋| 275/285 [05:06<00:11,  1.14s/it]Loading train:  97%|█████████▋| 276/285 [05:07<00:10,  1.16s/it]Loading train:  97%|█████████▋| 277/285 [05:08<00:09,  1.14s/it]Loading train:  98%|█████████▊| 278/285 [05:09<00:07,  1.13s/it]Loading train:  98%|█████████▊| 279/285 [05:11<00:06,  1.13s/it]Loading train:  98%|█████████▊| 280/285 [05:12<00:05,  1.13s/it]Loading train:  99%|█████████▊| 281/285 [05:13<00:04,  1.08s/it]Loading train:  99%|█████████▉| 282/285 [05:14<00:03,  1.12s/it]Loading train:  99%|█████████▉| 283/285 [05:15<00:02,  1.11s/it]Loading train: 100%|█████████▉| 284/285 [05:16<00:01,  1.12s/it]Loading train: 100%|██████████| 285/285 [05:17<00:00,  1.11s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:05, 51.02it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 51.76it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:04, 60.02it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:03, 71.12it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:02, 82.84it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:02, 98.81it/s]concatenating: train:  34%|███▍      | 97/285 [00:00<00:01, 123.54it/s]concatenating: train:  45%|████▍     | 128/285 [00:00<00:01, 150.31it/s]concatenating: train:  56%|█████▌    | 159/285 [00:00<00:00, 177.61it/s]concatenating: train:  65%|██████▌   | 186/285 [00:01<00:00, 196.13it/s]concatenating: train:  74%|███████▍  | 211/285 [00:01<00:00, 173.24it/s]concatenating: train:  82%|████████▏ | 233/285 [00:01<00:00, 159.18it/s]concatenating: train:  88%|████████▊ | 252/285 [00:01<00:00, 143.26it/s]concatenating: train:  94%|█████████▍| 269/285 [00:01<00:00, 127.22it/s]concatenating: train: 100%|█████████▉| 284/285 [00:01<00:00, 126.61it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 153.09it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.49s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.46s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 130.73it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      2019-07-08 12:41:20.532058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 12:41:20.532171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 12:41:20.532196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 12:41:20.532207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 12:41:20.532641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 22s - loss: 9854.2206 - acc: 0.7878 - mDice: 0.2398 - val_loss: 5190.9820 - val_acc: 0.9171 - val_mDice: 0.3606

Epoch 00001: val_mDice improved from -inf to 0.36057, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 3259.9510 - acc: 0.9096 - mDice: 0.5207 - val_loss: 2839.5355 - val_acc: 0.9409 - val_mDice: 0.5377

Epoch 00002: val_mDice improved from 0.36057 to 0.53769, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 2376.7285 - acc: 0.9344 - mDice: 0.6180 - val_loss: 2233.5017 - val_acc: 0.9487 - val_mDice: 0.6080

Epoch 00003: val_mDice improved from 0.53769 to 0.60801, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 2033.1621 - acc: 0.9448 - mDice: 0.6616 - val_loss: 2310.7134 - val_acc: 0.9485 - val_mDice: 0.5995

Epoch 00004: val_mDice did not improve from 0.60801
Epoch 5/300
 - 14s - loss: 1837.6925 - acc: 0.9482 - mDice: 0.6877 - val_loss: 2457.8224 - val_acc: 0.9493 - val_mDice: 0.5913

Epoch 00005: val_mDice did not improve from 0.60801
Epoch 6/300
 - 14s - loss: 1706.3340 - acc: 0.9502 - mDice: 0.7061 - val_loss: 2483.9568 - val_acc: 0.9448 - val_mDice: 0.5790

Epoch 00006: val_mDice did not improve from 0.60801
Epoch 7/300
 - 14s - loss: 1605.7206 - acc: 0.9519 - mDice: 0.7207 - val_loss: 2529.9392 - val_acc: 0.9435 - val_mDice: 0.5714

Epoch 00007: val_mDice did not improve from 0.60801
Epoch 8/300
 - 13s - loss: 1529.3687 - acc: 0.9529 - mDice: 0.7317 - val_loss: 2562.6397 - val_acc: 0.9453 - val_mDice: 0.5731

Epoch 00008: val_mDice did not improve from 0.60801
Epoch 9/300
 - 14s - loss: 1482.9615 - acc: 0.9537 - mDice: 0.7387 - val_loss: 2433.7801 - val_acc: 0.9503 - val_mDice: 0.6025

Epoch 00009: val_mDice did not improve from 0.60801
Epoch 10/300
 - 14s - loss: 1420.7459 - acc: 0.9546 - mDice: 0.7480 - val_loss: 2311.7850 - val_acc: 0.9508 - val_mDice: 0.6001

Epoch 00010: val_mDice did not improve from 0.60801
Epoch 11/300
 - 14s - loss: 1367.2256 - acc: 0.9554 - mDice: 0.7561 - val_loss: 2269.0367 - val_acc: 0.9507 - val_mDice: 0.6073

Epoch 00011: val_mDice did not improve from 0.60801
Epoch 12/300
 - 14s - loss: 1337.4920 - acc: 0.9560 - mDice: 0.7608 - val_loss: 2330.0350 - val_acc: 0.9506 - val_mDice: 0.6004

Epoch 00012: val_mDice did not improve from 0.60801
Epoch 13/300
 - 13s - loss: 1292.0076 - acc: 0.9566 - mDice: 0.7677 - val_loss: 2300.8679 - val_acc: 0.9472 - val_mDice: 0.6020

Epoch 00013: val_mDice did not improve from 0.60801
Epoch 14/300
 - 13s - loss: 1265.7837 - acc: 0.9570 - mDice: 0.7718 - val_loss: 2598.4258 - val_acc: 0.9531 - val_mDice: 0.5805

Epoch 00014: val_mDice did not improve from 0.60801
Epoch 15/300
 - 14s - loss: 1239.6822 - acc: 0.9574 - mDice: 0.7758 - val_loss: 2668.8027 - val_acc: 0.9501 - val_mDice: 0.5745

Epoch 00015: val_mDice did not improve from 0.60801
Epoch 16/300
 - 14s - loss: 1212.3556 - acc: 0.9579 - mDice: 0.7801 - val_loss: 2572.0583 - val_acc: 0.9542 - val_mDice: 0.5844

Epoch 00016: val_mDice did not improve from 0.60801
Epoch 17/300
 - 14s - loss: 1199.0821 - acc: 0.9581 - mDice: 0.7823 - val_loss: 2463.7794 - val_acc: 0.9491 - val_mDice: 0.5898

Epoch 00017: val_mDice did not improve from 0.60801
Epoch 18/300
 - 14s - loss: 1170.1535 - acc: 0.9585 - mDice: 0.7869 - val_loss: 2275.4310 - val_acc: 0.9522 - val_mDice: 0.6072

Epoch 00018: val_mDice did not improve from 0.60801
Epoch 19/300
 - 14s - loss: 1571.8384 - acc: 0.9519 - mDice: 0.7335 - val_loss: 2229.6905 - val_acc: 0.9536 - val_mDice: 0.6211

Epoch 00019: val_mDice improved from 0.60801 to 0.62114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 14s - loss: 1304.4857 - acc: 0.9561 - mDice: 0.7658 - val_loss: 2393.1619 - val_acc: 0.9519 - val_mDice: 0.5963

Epoch 00020: val_mDice did not improve from 0.62114
Epoch 21/300
 - 13s - loss: 1215.0346 - acc: 0.9577 - mDice: 0.7798 - val_loss: 2446.0892 - val_acc: 0.9503 - val_mDice: 0.5905

Epoch 00021: val_mDice did not improve from 0.62114
Epoch 22/300
 - 13s - loss: 1167.9629 - acc: 0.9585 - mDice: 0.7872 - val_loss: 2247.1221 - val_acc: 0.9504 - val_mDice: 0.6092

Epoch 00022: val_mDice did not improve from 0.62114
Epoch 23/300
 - 14s - loss: 1151.2424 - acc: 0.9588 - mDice: 0.7900 - val_loss: 2305.8992 - val_acc: 0.9514 - val_mDice: 0.6024

Epoch 00023: val_mDice did not improve from 0.62114
Epoch 24/300
 - 14s - loss: 1119.0183 - acc: 0.9594 - mDice: 0.7951 - val_loss: 2260.9565 - val_acc: 0.9522 - val_mDice: 0.6096

Epoch 00024: val_mDice did not improve from 0.62114
Epoch 25/300
 - 13s - loss: 1111.6485 - acc: 0.9596 - mDice: 0.7963 - val_loss: 2358.9959 - val_acc: 0.9514 - val_mDice: 0.6014

Epoch 00025: val_mDice did not improve from 0.62114
Epoch 26/300
 - 13s - loss: 1101.4092 - acc: 0.9597 - mDice: 0.7980 - val_loss: 2337.2099 - val_acc: 0.9518 - val_mDice: 0.6006

Epoch 00026: val_mDice did not improve from 0.62114
Epoch 27/300
 - 15s - loss: 1077.9554 - acc: 0.9601 - mDice: 0.8018 - val_loss: 2395.4155 - val_acc: 0.9490 - val_mDice: 0.5938

Epoch 00027: val_mDice did not improve from 0.62114
Epoch 28/300
 - 14s - loss: 1063.4926 - acc: 0.9604 - mDice: 0.8041 - val_loss: 2306.7786 - val_acc: 0.9516 - val_mDice: 0.6057

Epoch 00028: val_mDice did not improve from 0.62114
Epoch 29/300
 - 14s - loss: 1058.5564 - acc: 0.9605 - mDice: 0.8050 - val_loss: 2408.9705 - val_acc: 0.9533 - val_mDice: 0.5972

Epoch 00029: val_mDice did not improve from 0.62114
Epoch 30/300
 - 14s - loss: 1059.2355 - acc: 0.9606 - mDice: 0.8051 - val_loss: 2340.3826 - val_acc: 0.9543 - val_mDice: 0.6003

Epoch 00030: val_mDice did not improve from 0.62114
Epoch 31/300
 - 14s - loss: 1040.3166 - acc: 0.9608 - mDice: 0.8080 - val_loss: 2219.6339 - val_acc: 0.9520 - val_mDice: 0.6138

Epoch 00031: val_mDice did not improve from 0.62114
Epoch 32/300
 - 14s - loss: 1033.2986 - acc: 0.9609 - mDice: 0.8091 - val_loss: 2255.4206 - val_acc: 0.9528 - val_mDice: 0.6114

Epoch 00032: val_mDice did not improve from 0.62114
Epoch 33/300
 - 13s - loss: 1025.2548 - acc: 0.9610 - mDice: 0.8104 - val_loss: 2216.7411 - val_acc: 0.9530 - val_mDice: 0.6130

Epoch 00033: val_mDice did not improve from 0.62114
Epoch 34/300
 - 14s - loss: 1013.5006 - acc: 0.9612 - mDice: 0.8124 - val_loss: 2293.9794 - val_acc: 0.9529 - val_mDice: 0.6042

Epoch 00034: val_mDice did not improve from 0.62114
Epoch 35/300
 - 14s - loss: 1004.7986 - acc: 0.9613 - mDice: 0.8138 - val_loss: 2189.6999 - val_acc: 0.9539 - val_mDice: 0.6175

Epoch 00035: val_mDice did not improve from 0.62114
Epoch 36/300
 - 14s - loss: 1008.8826 - acc: 0.9614 - mDice: 0.8132 - val_loss: 2313.0607 - val_acc: 0.9535 - val_mDice: 0.6015

Epoch 00036: val_mDice did not improve from 0.62114
Epoch 37/300
 - 14s - loss: 1002.6118 - acc: 0.9614 - mDice: 0.8142 - val_loss: 2229.0321 - val_acc: 0.9521 - val_mDice: 0.6103

Epoch 00037: val_mDice did not improve from 0.62114
Epoch 38/300
 - 14s - loss: 998.6602 - acc: 0.9616 - mDice: 0.8148 - val_loss: 2329.8403 - val_acc: 0.9526 - val_mDice: 0.6024

Epoch 00038: val_mDice did not improve from 0.62114
Epoch 39/300
 - 14s - loss: 984.7415 - acc: 0.9617 - mDice: 0.8172 - val_loss: 2232.9651 - val_acc: 0.9510 - val_mDice: 0.6092

Epoch 00039: val_mDice did not improve from 0.62114
Epoch 40/300
 - 13s - loss: 977.2751 - acc: 0.9619 - mDice: 0.8184 - val_loss: 2118.6194 - val_acc: 0.9519 - val_mDice: 0.6227

Epoch 00040: val_mDice improved from 0.62114 to 0.62275, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 41/300
 - 14s - loss: 973.3018 - acc: 0.9620 - mDice: 0.8191 - val_loss: 2436.6263 - val_acc: 0.9537 - val_mDice: 0.5933

Epoch 00041: val_mDice did not improve from 0.62275
Epoch 42/300
 - 14s - loss: 973.9072 - acc: 0.9620 - mDice: 0.8191 - val_loss: 2344.6165 - val_acc: 0.9520 - val_mDice: 0.6031

Epoch 00042: val_mDice did not improve from 0.62275
Epoch 43/300
 - 14s - loss: 966.8506 - acc: 0.9622 - mDice: 0.8202 - val_loss: 2295.8283 - val_acc: 0.9526 - val_mDice: 0.6059

Epoch 00043: val_mDice did not improve from 0.62275
Epoch 44/300
 - 14s - loss: 961.9885 - acc: 0.9623 - mDice: 0.8210 - val_loss: 2207.9179 - val_acc: 0.9524 - val_mDice: 0.6143

Epoch 00044: val_mDice did not improve from 0.62275
Epoch 45/300
 - 14s - loss: 957.3138 - acc: 0.9623 - mDice: 0.8217 - val_loss: 2442.8912 - val_acc: 0.9516 - val_mDice: 0.5906

Epoch 00045: val_mDice did not improve from 0.62275
Epoch 46/300
 - 14s - loss: 950.6742 - acc: 0.9624 - mDice: 0.8228 - val_loss: 2392.0207 - val_acc: 0.9531 - val_mDice: 0.5925

Epoch 00046: val_mDice did not improve from 0.62275
Epoch 47/300
 - 14s - loss: 948.5900 - acc: 0.9624 - mDice: 0.8232 - val_loss: 2447.6008 - val_acc: 0.9520 - val_mDice: 0.5873

Epoch 00047: val_mDice did not improve from 0.62275
Epoch 48/300
 - 14s - loss: 942.8387 - acc: 0.9625 - mDice: 0.8242 - val_loss: 2279.8289 - val_acc: 0.9531 - val_mDice: 0.6065

Epoch 00048: val_mDice did not improve from 0.62275
Epoch 49/300
 - 14s - loss: 935.4498 - acc: 0.9627 - mDice: 0.8254 - val_loss: 2391.8752 - val_acc: 0.9518 - val_mDice: 0.5912

Epoch 00049: val_mDice did not improve from 0.62275
Epoch 50/300
 - 13s - loss: 935.0143 - acc: 0.9628 - mDice: 0.8255 - val_loss: 2444.1564 - val_acc: 0.9535 - val_mDice: 0.5883

Epoch 00050: val_mDice did not improve from 0.62275
Epoch 51/300
 - 14s - loss: 937.2921 - acc: 0.9627 - mDice: 0.8251 - val_loss: 2289.2561 - val_acc: 0.9531 - val_mDice: 0.6063

Epoch 00051: val_mDice did not improve from 0.62275
Epoch 52/300
 - 13s - loss: 935.5250 - acc: 0.9627 - mDice: 0.8255 - val_loss: 2145.3671 - val_acc: 0.9536 - val_mDice: 0.6197

Epoch 00052: val_mDice did not improve from 0.62275
Epoch 53/300
 - 13s - loss: 927.4482 - acc: 0.9629 - mDice: 0.8268 - val_loss: 2240.7983 - val_acc: 0.9517 - val_mDice: 0.6092

Epoch 00053: val_mDice did not improve from 0.62275
Epoch 54/300
 - 14s - loss: 917.8917 - acc: 0.9631 - mDice: 0.8284 - val_loss: 2342.1922 - val_acc: 0.9529 - val_mDice: 0.5989

Epoch 00054: val_mDice did not improve from 0.62275
Epoch 55/300
 - 14s - loss: 917.9212 - acc: 0.9630 - mDice: 0.8284 - val_loss: 2290.8470 - val_acc: 0.9506 - val_mDice: 0.6080

Epoch 00055: val_mDice did not improve from 0.62275
Epoch 56/300
 - 13s - loss: 915.5939 - acc: 0.9631 - mDice: 0.8288 - val_loss: 2283.9945 - val_acc: 0.9508 - val_mDice: 0.6017

Epoch 00056: val_mDice did not improve from 0.62275
Epoch 57/300
 - 14s - loss: 913.5838 - acc: 0.9632 - mDice: 0.8291 - val_loss: 2304.5072 - val_acc: 0.9519 - val_mDice: 0.6014

Epoch 00057: val_mDice did not improve from 0.62275
Epoch 58/300
 - 13s - loss: 912.8655 - acc: 0.9632 - mDice: 0.8292 - val_loss: 2452.6612 - val_acc: 0.9520 - val_mDice: 0.5961

Epoch 00058: val_mDice did not improve from 0.62275
Epoch 59/300
 - 14s - loss: 907.9526 - acc: 0.9632 - mDice: 0.8300 - val_loss: 2462.8495 - val_acc: 0.9493 - val_mDice: 0.5841

Epoch 00059: val_mDice did not improve from 0.62275
Epoch 60/300
 - 14s - loss: 908.9324 - acc: 0.9632 - mDice: 0.8299 - val_loss: 2096.2999 - val_acc: 0.9536 - val_mDice: 0.6268

Epoch 00060: val_mDice improved from 0.62275 to 0.62679, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 61/300
 - 13s - loss: 902.8424 - acc: 0.9633 - mDice: 0.8310 - val_loss: 2272.0783 - val_acc: 0.9513 - val_mDice: 0.6067

Epoch 00061: val_mDice did not improve from 0.62679
Epoch 62/300
 - 14s - loss: 898.3017 - acc: 0.9634 - mDice: 0.8317 - val_loss: 2292.1701 - val_acc: 0.9536 - val_mDice: 0.6089

Epoch 00062: val_mDice did not improve from 0.62679
Epoch 63/300
 - 13s - loss: 896.2968 - acc: 0.9634 - mDice: 0.8321 - val_loss: 2416.2628 - val_acc: 0.9532 - val_mDice: 0.5961

Epoch 00063: val_mDice did not improve from 0.62679
Epoch 64/300
 - 14s - loss: 896.5362 - acc: 0.9634 - mDice: 0.8320 - val_loss: 2322.5968 - val_acc: 0.9535 - val_mDice: 0.6027

Epoch 00064: val_mDice did not improve from 0.62679
Epoch 65/300
 - 14s - loss: 890.7705 - acc: 0.9636 - mDice: 0.8330 - val_loss: 2251.9321 - val_acc: 0.9522 - val_mDice: 0.6101

Epoch 00065: val_mDice did not improve from 0.62679
Epoch 66/300
 - 13s - loss: 888.8402 - acc: 0.9635 - mDice: 0.8333 - val_loss: 2380.7804 - val_acc: 0.9544 - val_mDice: 0.5990

Epoch 00066: val_mDice did not improve from 0.62679
Epoch 67/300
 - 13s - loss: 891.7359 - acc: 0.9636 - mDice: 0.8328 - val_loss: 2207.1162 - val_acc: 0.9545 - val_mDice: 0.6144

Epoch 00067: val_mDice did not improve from 0.62679
Epoch 68/300
 - 14s - loss: 883.6307 - acc: 0.9636 - mDice: 0.8342 - val_loss: 2238.9373 - val_acc: 0.9523 - val_mDice: 0.6093

Epoch 00068: val_mDice did not improve from 0.62679
Epoch 69/300
 - 13s - loss: 883.1946 - acc: 0.9636 - mDice: 0.8343 - val_loss: 2204.0394 - val_acc: 0.9527 - val_mDice: 0.6150

Epoch 00069: val_mDice did not improve from 0.62679
Epoch 70/300
 - 13s - loss: 882.8708 - acc: 0.9637 - mDice: 0.8343 - val_loss: 2140.7518 - val_acc: 0.9537 - val_mDice: 0.6205

Epoch 00070: val_mDice did not improve from 0.62679
Epoch 71/300
 - 14s - loss: 888.2418 - acc: 0.9636 - mDice: 0.8334 - val_loss: 2204.4905 - val_acc: 0.9526 - val_mDice: 0.6128

Epoch 00071: val_mDice did not improve from 0.62679
Epoch 72/300
 - 14s - loss: 879.5051 - acc: 0.9637 - mDice: 0.8349 - val_loss: 2437.8718 - val_acc: 0.9523 - val_mDice: 0.5919

Epoch 00072: val_mDice did not improve from 0.62679
Epoch 73/300
 - 13s - loss: 878.0143 - acc: 0.9638 - mDice: 0.8352 - val_loss: 2181.6528 - val_acc: 0.9550 - val_mDice: 0.6183

Epoch 00073: val_mDice did not improve from 0.62679
Epoch 74/300
 - 15s - loss: 869.5569 - acc: 0.9639 - mDice: 0.8366 - val_loss: 2295.2805 - val_acc: 0.9542 - val_mDice: 0.6009

Epoch 00074: val_mDice did not improve from 0.62679
Epoch 75/300
 - 14s - loss: 869.4311 - acc: 0.9639 - mDice: 0.8367 - val_loss: 2300.1272 - val_acc: 0.9546 - val_mDice: 0.6026

Epoch 00075: val_mDice did not improve from 0.62679
Epoch 76/300
 - 13s - loss: 867.2701 - acc: 0.9640 - mDice: 0.8370 - val_loss: 2328.2544 - val_acc: 0.9519 - val_mDice: 0.6001

Epoch 00076: val_mDice did not improve from 0.62679
Epoch 77/300
 - 14s - loss: 869.2760 - acc: 0.9639 - mDice: 0.8367 - val_loss: 2270.8837 - val_acc: 0.9514 - val_mDice: 0.6043

Epoch 00077: val_mDice did not improve from 0.62679
Epoch 78/300
 - 14s - loss: 867.3576 - acc: 0.9640 - mDice: 0.8370 - val_loss: 2200.7764 - val_acc: 0.9532 - val_mDice: 0.6130

Epoch 00078: val_mDice did not improve from 0.62679
Epoch 79/300
 - 14s - loss: 862.5082 - acc: 0.9641 - mDice: 0.8378 - val_loss: 2351.5207 - val_acc: 0.9523 - val_mDice: 0.5997

Epoch 00079: val_mDice did not improve from 0.62679
Epoch 80/300
 - 13s - loss: 861.4794 - acc: 0.9641 - mDice: 0.8380 - val_loss: 2220.5923 - val_acc: 0.9509 - val_mDice: 0.6088

Epoch 00080: val_mDice did not improve from 0.62679
Epoch 81/300
 - 14s - loss: 867.5759 - acc: 0.9640 - mDice: 0.8370 - val_loss: 2221.0466 - val_acc: 0.9528 - val_mDice: 0.6118

Epoch 00081: val_mDice did not improve from 0.62679
Epoch 82/300
 - 13s - loss: 861.9743 - acc: 0.9641 - mDice: 0.8379 - val_loss: 2170.0506 - val_acc: 0.9537 - val_mDice: 0.6177

Epoch 00082: val_mDice did not improve from 0.62679
Epoch 83/300
 - 13s - loss: 855.8199 - acc: 0.9642 - mDice: 0.8390 - val_loss: 2358.4683 - val_acc: 0.9520 - val_mDice: 0.5970

Epoch 00083: val_mDice did not improve from 0.62679
Epoch 84/300
 - 14s - loss: 857.5899 - acc: 0.9641 - mDice: 0.8387 - val_loss: 2300.1708 - val_acc: 0.9528 - val_mDice: 0.6019

Epoch 00084: val_mDice did not improve from 0.62679
Epoch 85/300
 - 14s - loss: 855.7746 - acc: 0.9641 - mDice: 0.8390 - val_loss: 2221.1628 - val_acc: 0.9529 - val_mDice: 0.6116

Epoch 00085: val_mDice did not improve from 0.62679
Epoch 86/300
 - 14s - loss: 854.5670 - acc: 0.9642 - mDice: 0.8392 - val_loss: 2341.9359 - val_acc: 0.9516 - val_mDice: 0.6001

Epoch 00086: val_mDice did not improve from 0.62679
Epoch 87/300
 - 14s - loss: 853.5076 - acc: 0.9642 - mDice: 0.8394 - val_loss: 2242.7313 - val_acc: 0.9517 - val_mDice: 0.6085

Epoch 00087: val_mDice did not improve from 0.62679
Epoch 88/300
 - 13s - loss: 846.5908 - acc: 0.9643 - mDice: 0.8406 - val_loss: 2304.8246 - val_acc: 0.9541 - val_mDice: 0.6084

Epoch 00088: val_mDice did not improve from 0.62679
Epoch 89/300
 - 13s - loss: 847.4636 - acc: 0.9643 - mDice: 0.8404 - val_loss: 2313.3147 - val_acc: 0.9530 - val_mDice: 0.6029

Epoch 00089: val_mDice did not improve from 0.62679
Epoch 90/300
 - 14s - loss: 848.4090 - acc: 0.9644 - mDice: 0.8403 - val_loss: 2280.4457 - val_acc: 0.9527 - val_mDice: 0.6056

Epoch 00090: val_mDice did not improve from 0.62679
Restoring model weights from the end of the best epoch
Epoch 00090: early stopping
{'val_loss': [5190.98199360597, 2839.5355463294345, 2233.501729443087, 2310.7133748145075, 2457.822352915503, 2483.9568157515714, 2529.9392158039454, 2562.6397070858065, 2433.7801138595496, 2311.7850375894727, 2269.0367056564246, 2330.0350416812153, 2300.8678885518507, 2598.42581125611, 2668.802693457577, 2572.0583182393507, 2463.779360978963, 2275.4309613957753, 2229.690450146212, 2393.161915699197, 2446.0892095299405, 2247.1220525816166, 2305.8991644662187, 2260.9565102348115, 2358.9959287163933, 2337.2099036531076, 2395.4154536923884, 2306.778553541812, 2408.970510813111, 2340.382609276798, 2219.6338681695183, 2255.4206106516235, 2216.741146833537, 2293.979391257856, 2189.6999170740223, 2313.0606859942386, 2229.0320710762917, 2329.8402529242317, 2232.965098801938, 2118.6193561234286, 2436.6262998101433, 2344.616541004714, 2295.8283091284043, 2207.9178610007857, 2442.8912483087465, 2392.0207083078735, 2447.6007605185055, 2279.8288519662187, 2391.8752373210546, 2444.1564000305516, 2289.2561471608765, 2145.3671029373254, 2240.798303018069, 2342.1921714058135, 2290.847027485597, 2283.994515701379, 2304.507232836505, 2452.6611600907822, 2462.849466164019, 2096.2998524244936, 2272.0782695748953, 2292.170099183834, 2416.262785330831, 2322.596837901536, 2251.932108447538, 2380.7803948258556, 2207.1162177570704, 2238.9373104159395, 2204.0393775641587, 2140.751809914019, 2204.4904730599687, 2437.8718070770774, 2181.6528265755937, 2295.2805489481493, 2300.1272313634777, 2328.254446359986, 2270.8837154111384, 2200.7764244718924, 2351.5207246748428, 2220.5922783366796, 2221.046555844099, 2170.0505903020253, 2358.4683203670565, 2300.1707743213165, 2221.162776328998, 2341.9358905813547, 2242.7312857345496, 2304.8245624563547, 2313.3146795347416, 2280.445739405115], 'val_acc': [0.9170667955329298, 0.9409068909437297, 0.9487413667433755, 0.9484665710166846, 0.9492992132735651, 0.944826214340146, 0.9435452672356334, 0.9453488891351156, 0.9502846951591236, 0.9508094874174235, 0.9507495724289111, 0.950594607012232, 0.9472352113137698, 0.9530738668734801, 0.9500718895949465, 0.9542122673055979, 0.9490740182679459, 0.9522226492785875, 0.9536110275950511, 0.9519168824456924, 0.9502826399643328, 0.9504313931784816, 0.9513921118315372, 0.9522454019365364, 0.9514107028199308, 0.9518238978678953, 0.9490429925518995, 0.9516317494754685, 0.9533073216177231, 0.9542886954446078, 0.9519829763380508, 0.9528300922010198, 0.9529850093346068, 0.9529189114464062, 0.9539085403500989, 0.9534725916452248, 0.9520945668886494, 0.9525966168115925, 0.9510326065830679, 0.9519210028248792, 0.9537019606409126, 0.9520305228632922, 0.9525635329038737, 0.9523941365034221, 0.951615257303142, 0.9531090069749502, 0.9520119019060828, 0.9531193019291542, 0.9517805269976568, 0.9534953306507132, 0.9530821139586039, 0.953573856273843, 0.9516586131889727, 0.9529478326856091, 0.9505553588520881, 0.9507516439400572, 0.9518879735270026, 0.9520387839338633, 0.9492847446622795, 0.9536296355657737, 0.9512619399491635, 0.9536399624867147, 0.9531957643658089, 0.9534643535507458, 0.9521854659698529, 0.9543754588292298, 0.9545035801786285, 0.9523425005667703, 0.9526585866619088, 0.9537308878738787, 0.9525573799730013, 0.9523114891691581, 0.9549684381351791, 0.9541688561439514, 0.9546399276349797, 0.951945808346711, 0.9513611140863856, 0.9531606452425099, 0.9523445514327321, 0.950904521529235, 0.9527701559013495, 0.9536730274141834, 0.9519891925364233, 0.952755695281748, 0.9529437143043433, 0.9515966303521695, 0.9516709956376912, 0.9540882823187545, 0.9529560987509829, 0.9526813096840289], 'val_mDice': [0.36057304703323534, 0.5376876412823214, 0.6080127634815664, 0.5994776204311648, 0.591274287447583, 0.5790379576842878, 0.571414522285568, 0.5731207581871715, 0.6025375850373806, 0.6001204821650542, 0.6072659865437939, 0.6003767668201937, 0.601968070648236, 0.5805390037637849, 0.5744629855262501, 0.5844379237244249, 0.5897824671015394, 0.6071756332280249, 0.621135519203527, 0.5963407521807281, 0.5905233348548079, 0.6091925351979346, 0.602439748841291, 0.6095910645064029, 0.6013524578936273, 0.6005566999232969, 0.5938384776008861, 0.6056993070927412, 0.59724852958871, 0.6002796958278678, 0.6138345998758711, 0.6114413192152311, 0.6129681105054291, 0.604212019696582, 0.6175336308319476, 0.6014874840581883, 0.6102662029879053, 0.6024456976512291, 0.6091587117264391, 0.6227483090075701, 0.5933205921556697, 0.6030714858177654, 0.6059197194083443, 0.6143265902663076, 0.5906020945676879, 0.5925110844926461, 0.5873056134032137, 0.6065230702554714, 0.5911981686533496, 0.5883290105025861, 0.606340903143643, 0.6197241025264036, 0.6092338125798955, 0.5989243817728991, 0.6080387074854121, 0.6017333109285579, 0.6013938671383778, 0.5961304456828027, 0.5841381336723626, 0.6267915937487639, 0.6067343444131607, 0.6089189775163235, 0.5960531604356606, 0.6026663427246349, 0.6101298738458303, 0.5990406028385269, 0.6143791049552363, 0.6092527055873551, 0.6149515213247118, 0.6204979965806673, 0.6127616366860587, 0.591913152673391, 0.6182888563118834, 0.600918503446952, 0.6026476102168333, 0.6000756494825779, 0.6042680537234472, 0.6129512320683655, 0.5996803118529932, 0.6087983666851534, 0.611819785067489, 0.617675701000171, 0.5970102009160558, 0.6018624092613518, 0.6115550099138441, 0.6001228147378846, 0.6085452507328055, 0.6083988460748555, 0.6029025123106034, 0.6056022361004153], 'loss': [9854.220594850009, 3259.950951023537, 2376.72847941145, 2033.1621077660998, 1837.6925434432292, 1706.3340293377757, 1605.7206133656575, 1529.3687374691942, 1482.961517501855, 1420.7458560383272, 1367.2255615580088, 1337.4920431145083, 1292.0076495091073, 1265.7837108094527, 1239.6822325672877, 1212.3555568007173, 1199.0821350639496, 1170.1535101095308, 1571.838413969636, 1304.48574359562, 1215.0345577125513, 1167.9628700084738, 1151.2424192879948, 1119.0183060193501, 1111.6485341104649, 1101.4092481654816, 1077.955431325121, 1063.492606701593, 1058.5563814591092, 1059.2355025431525, 1040.3166481401593, 1033.2986111461996, 1025.2547605493853, 1013.5005686165597, 1004.7985840176167, 1008.8825987556207, 1002.6118307600327, 998.6601827203965, 984.7415216247615, 977.2750519781122, 973.3017726782055, 973.9072481164433, 966.850623028632, 961.9885033181106, 957.313813051999, 950.6741544259062, 948.5899544848796, 942.838726963874, 935.4498040406157, 935.0142886123004, 937.2920830371716, 935.5249533465495, 927.4481753549845, 917.8916849161595, 917.9211998702615, 915.59392945885, 913.5837991586809, 912.8654875872954, 907.9526461161895, 908.9323568481758, 902.8423591224425, 898.3016907838582, 896.296834601315, 896.5362316401888, 890.7704896558623, 888.8401852157873, 891.7358902747916, 883.6307249287883, 883.1945583280555, 882.8707808023003, 888.2418449870979, 879.505081046284, 878.0143241975817, 869.5569457010561, 869.4310532002646, 867.2701232886888, 869.2759730568263, 867.3575591234903, 862.5081944907909, 861.479448364916, 867.5758517071946, 861.9743083943262, 855.8199433106028, 857.5899220509153, 855.7745930592898, 854.5669922652856, 853.5075856583758, 846.5908099975885, 847.4635982585105, 848.4090290159957], 'acc': [0.7877841930347268, 0.9095661474932423, 0.9344212549339549, 0.944839328126537, 0.9481592291931488, 0.9501894964423095, 0.9518659544837714, 0.9528832129322946, 0.9536613899406723, 0.9545798335750082, 0.9554376488651015, 0.9559686265183419, 0.9566334424328683, 0.957025039582969, 0.9573540564917199, 0.9578983071426779, 0.9581342046345627, 0.9585031825637422, 0.9518822309212659, 0.95611294208545, 0.9576865764726683, 0.9585100902976582, 0.9588362863527249, 0.9593531016391657, 0.9595664027151306, 0.9597445820990773, 0.9600778231563135, 0.9603813174347311, 0.960492782837282, 0.9605624526162909, 0.960798657623474, 0.9608975697379182, 0.9610220872656621, 0.961227979222308, 0.9613466118261268, 0.9613712841723909, 0.9614496778431596, 0.9615933278970265, 0.9617418342475232, 0.9619338430744664, 0.961965766453508, 0.9620256103933535, 0.9621871457718782, 0.9622514803427366, 0.9622793941837752, 0.9624000034894009, 0.9624402668603228, 0.9625389845138425, 0.9626854108144863, 0.962796816102729, 0.9626524617719882, 0.9627119997482493, 0.9628878967979233, 0.9630737445705188, 0.9630439964477471, 0.9631452687094008, 0.9632003557694373, 0.9631811614701654, 0.963204586277353, 0.9632431177796638, 0.9633108568856363, 0.9633801031473656, 0.963435890812752, 0.9633847739492507, 0.9635808540808531, 0.9635407894591699, 0.9635504204900583, 0.9636392236457113, 0.963636245082052, 0.9637149392886526, 0.9636452476200886, 0.9637486741866274, 0.9637530463062972, 0.9639241704396203, 0.9639281570362789, 0.9640168626968991, 0.9639041081219416, 0.9639864898242174, 0.9640705390801312, 0.9640546071523545, 0.9640364390651578, 0.9641101384700485, 0.9642309086929576, 0.9640691494456071, 0.9641236736392554, 0.9642423705353235, 0.9642256902074587, 0.9642893000499828, 0.964311172386821, 0.9643510551593135], 'mDice': [0.23981783626340689, 0.5207461816222766, 0.618010420300889, 0.661585194110403, 0.6877140945569148, 0.7060967533749813, 0.7207032590187438, 0.7317185286284597, 0.7386925921649963, 0.7479793219503758, 0.756080194370373, 0.7607581954163135, 0.7677425647098757, 0.7717637211777443, 0.7758028550927373, 0.7801252454072911, 0.7823055875073474, 0.7868729360800515, 0.7334747077281111, 0.7658476041660649, 0.7798034294122549, 0.787199591945624, 0.7899520323268858, 0.7951041942561843, 0.7963488177142692, 0.7980044655443815, 0.8018269709957483, 0.804127473647698, 0.804978011655727, 0.8050557520646531, 0.8079780095978296, 0.809094262028317, 0.8104297412025481, 0.8123549220511469, 0.8138148012773371, 0.8131843456404706, 0.8142094553234361, 0.8148471419896042, 0.817214938652333, 0.8184334736985518, 0.8190939752054814, 0.819094095499023, 0.8201952208056507, 0.821003625098283, 0.8217463498021788, 0.8228305786317304, 0.8232042476259722, 0.8241987754483023, 0.8254153851388645, 0.8255417011225771, 0.8251241810356478, 0.8254544296060004, 0.8267844239258245, 0.828420694519976, 0.8283739782653533, 0.8288060807206585, 0.8291444467125709, 0.8292494426949547, 0.8300445861958203, 0.8299350949013118, 0.830963913787717, 0.8317430972481636, 0.8320674637285792, 0.8319974061119733, 0.8329969628867055, 0.833295889909306, 0.8328340779293025, 0.8342170743249898, 0.8342636564342644, 0.8343294690581268, 0.8334483800971374, 0.8348855040579942, 0.8351954141769993, 0.8365898602610418, 0.8366511074794571, 0.8369853967454502, 0.8366541597430376, 0.8370233503446802, 0.837791341113717, 0.8379914585291369, 0.8369563485235892, 0.8379316923243179, 0.838964433154797, 0.8386993677772849, 0.838953431356668, 0.8392033790634398, 0.8393624857563928, 0.8405521420519386, 0.8403886268941492, 0.8402903978097842]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.74s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.48s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:29,  1.79s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:53,  1.88s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:01,  1.92s/it]predicting train subjects:   1%|▏         | 4/285 [00:08<09:36,  2.05s/it]predicting train subjects:   2%|▏         | 5/285 [00:10<09:23,  2.01s/it]predicting train subjects:   2%|▏         | 6/285 [00:12<10:02,  2.16s/it]predicting train subjects:   2%|▏         | 7/285 [00:15<10:35,  2.29s/it]predicting train subjects:   3%|▎         | 8/285 [00:17<10:52,  2.36s/it]predicting train subjects:   3%|▎         | 9/285 [00:19<10:36,  2.31s/it]predicting train subjects:   4%|▎         | 10/285 [00:22<10:59,  2.40s/it]predicting train subjects:   4%|▍         | 11/285 [00:25<11:09,  2.44s/it]predicting train subjects:   4%|▍         | 12/285 [00:27<11:22,  2.50s/it]predicting train subjects:   5%|▍         | 13/285 [00:30<11:16,  2.49s/it]predicting train subjects:   5%|▍         | 14/285 [00:32<11:13,  2.49s/it]predicting train subjects:   5%|▌         | 15/285 [00:35<11:29,  2.55s/it]predicting train subjects:   6%|▌         | 16/285 [00:37<11:22,  2.54s/it]predicting train subjects:   6%|▌         | 17/285 [00:40<11:18,  2.53s/it]predicting train subjects:   6%|▋         | 18/285 [00:43<11:26,  2.57s/it]predicting train subjects:   7%|▋         | 19/285 [00:45<11:30,  2.60s/it]predicting train subjects:   7%|▋         | 20/285 [00:48<11:29,  2.60s/it]predicting train subjects:   7%|▋         | 21/285 [00:51<11:30,  2.61s/it]predicting train subjects:   8%|▊         | 22/285 [00:53<11:16,  2.57s/it]predicting train subjects:   8%|▊         | 23/285 [00:56<11:16,  2.58s/it]predicting train subjects:   8%|▊         | 24/285 [00:58<11:08,  2.56s/it]predicting train subjects:   9%|▉         | 25/285 [01:01<11:07,  2.57s/it]predicting train subjects:   9%|▉         | 26/285 [01:03<11:07,  2.58s/it]predicting train subjects:   9%|▉         | 27/285 [01:06<11:23,  2.65s/it]predicting train subjects:  10%|▉         | 28/285 [01:09<11:04,  2.59s/it]predicting train subjects:  10%|█         | 29/285 [01:11<10:53,  2.55s/it]predicting train subjects:  11%|█         | 30/285 [01:13<10:45,  2.53s/it]predicting train subjects:  11%|█         | 31/285 [01:16<10:24,  2.46s/it]predicting train subjects:  11%|█         | 32/285 [01:18<10:15,  2.43s/it]predicting train subjects:  12%|█▏        | 33/285 [01:20<09:58,  2.38s/it]predicting train subjects:  12%|█▏        | 34/285 [01:23<09:46,  2.34s/it]predicting train subjects:  12%|█▏        | 35/285 [01:25<09:49,  2.36s/it]predicting train subjects:  13%|█▎        | 36/285 [01:27<09:48,  2.36s/it]predicting train subjects:  13%|█▎        | 37/285 [01:30<09:52,  2.39s/it]predicting train subjects:  13%|█▎        | 38/285 [01:32<09:47,  2.38s/it]predicting train subjects:  14%|█▎        | 39/285 [01:35<09:49,  2.40s/it]predicting train subjects:  14%|█▍        | 40/285 [01:37<09:38,  2.36s/it]predicting train subjects:  14%|█▍        | 41/285 [01:39<09:39,  2.38s/it]predicting train subjects:  15%|█▍        | 42/285 [01:42<09:32,  2.36s/it]predicting train subjects:  15%|█▌        | 43/285 [01:44<09:50,  2.44s/it]predicting train subjects:  15%|█▌        | 44/285 [01:47<09:40,  2.41s/it]predicting train subjects:  16%|█▌        | 45/285 [01:49<09:40,  2.42s/it]predicting train subjects:  16%|█▌        | 46/285 [01:51<09:18,  2.34s/it]predicting train subjects:  16%|█▋        | 47/285 [01:54<09:13,  2.32s/it]predicting train subjects:  17%|█▋        | 48/285 [01:56<08:50,  2.24s/it]predicting train subjects:  17%|█▋        | 49/285 [01:58<08:47,  2.24s/it]predicting train subjects:  18%|█▊        | 50/285 [02:00<08:32,  2.18s/it]predicting train subjects:  18%|█▊        | 51/285 [02:02<08:22,  2.15s/it]predicting train subjects:  18%|█▊        | 52/285 [02:04<08:21,  2.15s/it]predicting train subjects:  19%|█▊        | 53/285 [02:06<08:18,  2.15s/it]predicting train subjects:  19%|█▉        | 54/285 [02:08<08:06,  2.11s/it]predicting train subjects:  19%|█▉        | 55/285 [02:10<07:57,  2.08s/it]predicting train subjects:  20%|█▉        | 56/285 [02:12<08:06,  2.12s/it]predicting train subjects:  20%|██        | 57/285 [02:14<07:57,  2.09s/it]predicting train subjects:  20%|██        | 58/285 [02:17<07:55,  2.10s/it]predicting train subjects:  21%|██        | 59/285 [02:19<07:46,  2.06s/it]predicting train subjects:  21%|██        | 60/285 [02:21<07:50,  2.09s/it]predicting train subjects:  21%|██▏       | 61/285 [02:23<07:50,  2.10s/it]predicting train subjects:  22%|██▏       | 62/285 [02:25<07:42,  2.07s/it]predicting train subjects:  22%|██▏       | 63/285 [02:27<07:38,  2.07s/it]predicting train subjects:  22%|██▏       | 64/285 [02:29<07:38,  2.08s/it]predicting train subjects:  23%|██▎       | 65/285 [02:31<08:01,  2.19s/it]predicting train subjects:  23%|██▎       | 66/285 [02:34<08:08,  2.23s/it]predicting train subjects:  24%|██▎       | 67/285 [02:36<08:10,  2.25s/it]predicting train subjects:  24%|██▍       | 68/285 [02:38<08:03,  2.23s/it]predicting train subjects:  24%|██▍       | 69/285 [02:40<07:53,  2.19s/it]predicting train subjects:  25%|██▍       | 70/285 [02:42<07:45,  2.17s/it]predicting train subjects:  25%|██▍       | 71/285 [02:45<07:46,  2.18s/it]predicting train subjects:  25%|██▌       | 72/285 [02:47<07:42,  2.17s/it]predicting train subjects:  26%|██▌       | 73/285 [02:49<07:24,  2.10s/it]predicting train subjects:  26%|██▌       | 74/285 [02:51<07:31,  2.14s/it]predicting train subjects:  26%|██▋       | 75/285 [02:53<07:27,  2.13s/it]predicting train subjects:  27%|██▋       | 76/285 [02:55<07:28,  2.15s/it]predicting train subjects:  27%|██▋       | 77/285 [02:57<07:19,  2.11s/it]predicting train subjects:  27%|██▋       | 78/285 [02:59<07:09,  2.07s/it]predicting train subjects:  28%|██▊       | 79/285 [03:01<07:09,  2.08s/it]predicting train subjects:  28%|██▊       | 80/285 [03:03<07:02,  2.06s/it]predicting train subjects:  28%|██▊       | 81/285 [03:06<07:07,  2.09s/it]predicting train subjects:  29%|██▉       | 82/285 [03:08<07:16,  2.15s/it]predicting train subjects:  29%|██▉       | 83/285 [03:10<07:19,  2.18s/it]predicting train subjects:  29%|██▉       | 84/285 [03:12<07:13,  2.16s/it]predicting train subjects:  30%|██▉       | 85/285 [03:15<07:35,  2.28s/it]predicting train subjects:  30%|███       | 86/285 [03:17<07:46,  2.35s/it]predicting train subjects:  31%|███       | 87/285 [03:20<07:43,  2.34s/it]predicting train subjects:  31%|███       | 88/285 [03:22<07:32,  2.30s/it]predicting train subjects:  31%|███       | 89/285 [03:24<07:26,  2.28s/it]predicting train subjects:  32%|███▏      | 90/285 [03:26<07:25,  2.29s/it]predicting train subjects:  32%|███▏      | 91/285 [03:29<07:22,  2.28s/it]predicting train subjects:  32%|███▏      | 92/285 [03:31<07:23,  2.30s/it]predicting train subjects:  33%|███▎      | 93/285 [03:33<07:21,  2.30s/it]predicting train subjects:  33%|███▎      | 94/285 [03:36<07:24,  2.33s/it]predicting train subjects:  33%|███▎      | 95/285 [03:38<07:21,  2.32s/it]predicting train subjects:  34%|███▎      | 96/285 [03:40<07:17,  2.32s/it]predicting train subjects:  34%|███▍      | 97/285 [03:42<07:08,  2.28s/it]predicting train subjects:  34%|███▍      | 98/285 [03:45<07:06,  2.28s/it]predicting train subjects:  35%|███▍      | 99/285 [03:47<07:00,  2.26s/it]predicting train subjects:  35%|███▌      | 100/285 [03:49<07:02,  2.29s/it]predicting train subjects:  35%|███▌      | 101/285 [03:52<07:11,  2.35s/it]predicting train subjects:  36%|███▌      | 102/285 [03:54<07:20,  2.41s/it]predicting train subjects:  36%|███▌      | 103/285 [03:57<07:18,  2.41s/it]predicting train subjects:  36%|███▋      | 104/285 [03:59<07:24,  2.46s/it]predicting train subjects:  37%|███▋      | 105/285 [04:02<07:18,  2.44s/it]predicting train subjects:  37%|███▋      | 106/285 [04:04<07:19,  2.46s/it]predicting train subjects:  38%|███▊      | 107/285 [04:07<07:14,  2.44s/it]predicting train subjects:  38%|███▊      | 108/285 [04:09<07:04,  2.40s/it]predicting train subjects:  38%|███▊      | 109/285 [04:11<06:57,  2.37s/it]predicting train subjects:  39%|███▊      | 110/285 [04:14<06:58,  2.39s/it]predicting train subjects:  39%|███▉      | 111/285 [04:16<06:52,  2.37s/it]predicting train subjects:  39%|███▉      | 112/285 [04:18<06:57,  2.41s/it]predicting train subjects:  40%|███▉      | 113/285 [04:21<06:47,  2.37s/it]predicting train subjects:  40%|████      | 114/285 [04:23<06:36,  2.32s/it]predicting train subjects:  40%|████      | 115/285 [04:25<06:34,  2.32s/it]predicting train subjects:  41%|████      | 116/285 [04:28<06:29,  2.30s/it]predicting train subjects:  41%|████      | 117/285 [04:30<06:29,  2.32s/it]predicting train subjects:  41%|████▏     | 118/285 [04:32<06:27,  2.32s/it]predicting train subjects:  42%|████▏     | 119/285 [04:35<06:27,  2.34s/it]predicting train subjects:  42%|████▏     | 120/285 [04:37<06:18,  2.29s/it]predicting train subjects:  42%|████▏     | 121/285 [04:39<06:10,  2.26s/it]predicting train subjects:  43%|████▎     | 122/285 [04:41<05:51,  2.16s/it]predicting train subjects:  43%|████▎     | 123/285 [04:43<05:36,  2.08s/it]predicting train subjects:  44%|████▎     | 124/285 [04:45<05:35,  2.08s/it]predicting train subjects:  44%|████▍     | 125/285 [04:47<05:36,  2.10s/it]predicting train subjects:  44%|████▍     | 126/285 [04:49<05:35,  2.11s/it]predicting train subjects:  45%|████▍     | 127/285 [04:51<05:34,  2.12s/it]predicting train subjects:  45%|████▍     | 128/285 [04:53<05:19,  2.03s/it]predicting train subjects:  45%|████▌     | 129/285 [04:55<05:11,  2.00s/it]predicting train subjects:  46%|████▌     | 130/285 [04:57<05:07,  1.99s/it]predicting train subjects:  46%|████▌     | 131/285 [04:59<05:14,  2.04s/it]predicting train subjects:  46%|████▋     | 132/285 [05:01<05:07,  2.01s/it]predicting train subjects:  47%|████▋     | 133/285 [05:03<05:04,  2.00s/it]predicting train subjects:  47%|████▋     | 134/285 [05:05<04:55,  1.96s/it]predicting train subjects:  47%|████▋     | 135/285 [05:07<04:50,  1.94s/it]predicting train subjects:  48%|████▊     | 136/285 [05:09<04:44,  1.91s/it]predicting train subjects:  48%|████▊     | 137/285 [05:11<04:44,  1.92s/it]predicting train subjects:  48%|████▊     | 138/285 [05:13<04:43,  1.93s/it]predicting train subjects:  49%|████▉     | 139/285 [05:15<04:49,  1.98s/it]predicting train subjects:  49%|████▉     | 140/285 [05:17<04:53,  2.02s/it]predicting train subjects:  49%|████▉     | 141/285 [05:19<04:52,  2.03s/it]predicting train subjects:  50%|████▉     | 142/285 [05:21<04:49,  2.02s/it]predicting train subjects:  50%|█████     | 143/285 [05:23<04:40,  1.97s/it]predicting train subjects:  51%|█████     | 144/285 [05:25<04:41,  1.99s/it]predicting train subjects:  51%|█████     | 145/285 [05:27<04:51,  2.08s/it]predicting train subjects:  51%|█████     | 146/285 [05:29<04:40,  2.02s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:31<04:30,  1.96s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:33<04:23,  1.93s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:35<04:24,  1.94s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:36<04:17,  1.91s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:38<04:07,  1.85s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:40<04:01,  1.82s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:41<03:53,  1.77s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:43<03:49,  1.75s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:45<03:52,  1.79s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:47<03:47,  1.76s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:49<03:47,  1.78s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:50<03:43,  1.76s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:52<03:43,  1.77s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:54<03:37,  1.74s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:56<03:36,  1.75s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:57<03:32,  1.73s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:59<03:37,  1.78s/it]predicting train subjects:  58%|█████▊    | 164/285 [06:01<03:32,  1.76s/it]predicting train subjects:  58%|█████▊    | 165/285 [06:02<03:25,  1.71s/it]predicting train subjects:  58%|█████▊    | 166/285 [06:04<03:22,  1.70s/it]predicting train subjects:  59%|█████▊    | 167/285 [06:06<03:22,  1.72s/it]predicting train subjects:  59%|█████▉    | 168/285 [06:08<03:20,  1.72s/it]predicting train subjects:  59%|█████▉    | 169/285 [06:09<03:21,  1.74s/it]predicting train subjects:  60%|█████▉    | 170/285 [06:11<03:19,  1.73s/it]predicting train subjects:  60%|██████    | 171/285 [06:13<03:16,  1.72s/it]predicting train subjects:  60%|██████    | 172/285 [06:15<03:16,  1.74s/it]predicting train subjects:  61%|██████    | 173/285 [06:16<03:16,  1.76s/it]predicting train subjects:  61%|██████    | 174/285 [06:18<03:14,  1.75s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:20<03:10,  1.73s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:22<03:10,  1.75s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:24<03:14,  1.80s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:25<03:06,  1.75s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:27<03:02,  1.72s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:28<03:00,  1.72s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:30<02:59,  1.73s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:32<02:59,  1.75s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:34<02:53,  1.70s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:35<02:53,  1.71s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:37<02:50,  1.71s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:39<02:44,  1.67s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:40<02:48,  1.72s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:42<02:43,  1.69s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:44<02:44,  1.71s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:45<02:40,  1.69s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:47<02:37,  1.68s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:49<02:37,  1.69s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:51<02:37,  1.71s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:52<02:34,  1.70s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:54<02:30,  1.68s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:56<02:39,  1.80s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:58<02:44,  1.87s/it]predicting train subjects:  69%|██████▉   | 198/285 [07:00<02:47,  1.93s/it]predicting train subjects:  70%|██████▉   | 199/285 [07:02<02:47,  1.95s/it]predicting train subjects:  70%|███████   | 200/285 [07:04<02:46,  1.96s/it]predicting train subjects:  71%|███████   | 201/285 [07:06<02:45,  1.97s/it]predicting train subjects:  71%|███████   | 202/285 [07:08<02:42,  1.95s/it]predicting train subjects:  71%|███████   | 203/285 [07:10<02:38,  1.93s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:12<02:36,  1.93s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:14<02:34,  1.93s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:16<02:35,  1.97s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:18<02:34,  1.98s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:20<02:32,  1.98s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:22<02:30,  1.98s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:24<02:31,  2.03s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:26<02:28,  2.01s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:28<02:26,  2.01s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:30<02:23,  2.00s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:32<02:15,  1.91s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:33<02:10,  1.86s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:35<02:03,  1.79s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:37<01:59,  1.76s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:38<01:57,  1.76s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:40<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:42<01:51,  1.71s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:43<01:49,  1.70s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:45<01:48,  1.72s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:47<01:45,  1.71s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:49<01:47,  1.75s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:51<01:47,  1.79s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:52<01:42,  1.73s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:54<01:41,  1.74s/it]predicting train subjects:  80%|████████  | 228/285 [07:56<01:43,  1.81s/it]predicting train subjects:  80%|████████  | 229/285 [07:58<01:40,  1.79s/it]predicting train subjects:  81%|████████  | 230/285 [07:59<01:37,  1.78s/it]predicting train subjects:  81%|████████  | 231/285 [08:01<01:35,  1.77s/it]predicting train subjects:  81%|████████▏ | 232/285 [08:03<01:40,  1.90s/it]predicting train subjects:  82%|████████▏ | 233/285 [08:05<01:40,  1.93s/it]predicting train subjects:  82%|████████▏ | 234/285 [08:07<01:40,  1.96s/it]predicting train subjects:  82%|████████▏ | 235/285 [08:10<01:42,  2.04s/it]predicting train subjects:  83%|████████▎ | 236/285 [08:12<01:40,  2.05s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:14<01:40,  2.09s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:16<01:36,  2.05s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:18<01:33,  2.03s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:20<01:31,  2.03s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:22<01:28,  2.02s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:24<01:29,  2.09s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:26<01:27,  2.09s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:28<01:26,  2.10s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:30<01:24,  2.11s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:33<01:23,  2.13s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:35<01:20,  2.13s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:37<01:18,  2.13s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:39<01:16,  2.12s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:41<01:08,  1.97s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:42<01:03,  1.88s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:44<00:59,  1.81s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:46<00:56,  1.77s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:47<00:55,  1.80s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:49<00:54,  1.81s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:51<00:52,  1.82s/it]predicting train subjects:  90%|█████████ | 257/285 [08:53<00:49,  1.76s/it]predicting train subjects:  91%|█████████ | 258/285 [08:55<00:48,  1.79s/it]predicting train subjects:  91%|█████████ | 259/285 [08:56<00:45,  1.75s/it]predicting train subjects:  91%|█████████ | 260/285 [08:58<00:44,  1.78s/it]predicting train subjects:  92%|█████████▏| 261/285 [09:00<00:42,  1.78s/it]predicting train subjects:  92%|█████████▏| 262/285 [09:01<00:39,  1.73s/it]predicting train subjects:  92%|█████████▏| 263/285 [09:03<00:37,  1.72s/it]predicting train subjects:  93%|█████████▎| 264/285 [09:05<00:35,  1.67s/it]predicting train subjects:  93%|█████████▎| 265/285 [09:07<00:34,  1.71s/it]predicting train subjects:  93%|█████████▎| 266/285 [09:08<00:32,  1.70s/it]predicting train subjects:  94%|█████████▎| 267/285 [09:10<00:31,  1.73s/it]predicting train subjects:  94%|█████████▍| 268/285 [09:12<00:31,  1.87s/it]predicting train subjects:  94%|█████████▍| 269/285 [09:14<00:31,  1.94s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:17<00:30,  2.02s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:19<00:28,  2.05s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:21<00:27,  2.12s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:23<00:26,  2.17s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:26<00:24,  2.27s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:28<00:22,  2.24s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:30<00:20,  2.28s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:33<00:18,  2.29s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:35<00:15,  2.28s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:37<00:13,  2.28s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:39<00:11,  2.24s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:41<00:08,  2.23s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:44<00:06,  2.20s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:46<00:04,  2.24s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:48<00:02,  2.21s/it]predicting train subjects: 100%|██████████| 285/285 [09:50<00:00,  2.18s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:29,  1.37s/it]Loading train:   1%|          | 2/285 [00:03<06:51,  1.45s/it]Loading train:   1%|          | 3/285 [00:04<06:46,  1.44s/it]Loading train:   1%|▏         | 4/285 [00:06<07:22,  1.57s/it]Loading train:   2%|▏         | 5/285 [00:07<06:56,  1.49s/it]Loading train:   2%|▏         | 6/285 [00:09<07:16,  1.56s/it]Loading train:   2%|▏         | 7/285 [00:11<07:40,  1.66s/it]Loading train:   3%|▎         | 8/285 [00:13<08:00,  1.73s/it]Loading train:   3%|▎         | 9/285 [00:14<07:39,  1.67s/it]Loading train:   4%|▎         | 10/285 [00:16<07:18,  1.59s/it]Loading train:   4%|▍         | 11/285 [00:17<07:03,  1.55s/it]Loading train:   4%|▍         | 12/285 [00:18<06:28,  1.42s/it]Loading train:   5%|▍         | 13/285 [00:19<06:15,  1.38s/it]Loading train:   5%|▍         | 14/285 [00:21<06:01,  1.33s/it]Loading train:   5%|▌         | 15/285 [00:22<05:59,  1.33s/it]Loading train:   6%|▌         | 16/285 [00:23<05:43,  1.28s/it]Loading train:   6%|▌         | 17/285 [00:24<05:36,  1.26s/it]Loading train:   6%|▋         | 18/285 [00:26<05:35,  1.25s/it]Loading train:   7%|▋         | 19/285 [00:27<05:27,  1.23s/it]Loading train:   7%|▋         | 20/285 [00:28<05:45,  1.30s/it]Loading train:   7%|▋         | 21/285 [00:29<05:37,  1.28s/it]Loading train:   8%|▊         | 22/285 [00:31<05:42,  1.30s/it]Loading train:   8%|▊         | 23/285 [00:32<05:48,  1.33s/it]Loading train:   8%|▊         | 24/285 [00:33<05:33,  1.28s/it]Loading train:   9%|▉         | 25/285 [00:35<05:45,  1.33s/it]Loading train:   9%|▉         | 26/285 [00:36<05:58,  1.38s/it]Loading train:   9%|▉         | 27/285 [00:38<06:15,  1.46s/it]Loading train:  10%|▉         | 28/285 [00:39<06:08,  1.43s/it]Loading train:  10%|█         | 29/285 [00:41<05:55,  1.39s/it]Loading train:  11%|█         | 30/285 [00:42<06:01,  1.42s/it]Loading train:  11%|█         | 31/285 [00:44<06:06,  1.44s/it]Loading train:  11%|█         | 32/285 [00:45<06:17,  1.49s/it]Loading train:  12%|█▏        | 33/285 [00:47<06:03,  1.44s/it]Loading train:  12%|█▏        | 34/285 [00:48<06:03,  1.45s/it]Loading train:  12%|█▏        | 35/285 [00:49<06:07,  1.47s/it]Loading train:  13%|█▎        | 36/285 [00:51<06:10,  1.49s/it]Loading train:  13%|█▎        | 37/285 [00:53<06:22,  1.54s/it]Loading train:  13%|█▎        | 38/285 [00:54<06:27,  1.57s/it]Loading train:  14%|█▎        | 39/285 [00:56<06:40,  1.63s/it]Loading train:  14%|█▍        | 40/285 [00:58<06:35,  1.62s/it]Loading train:  14%|█▍        | 41/285 [00:59<06:32,  1.61s/it]Loading train:  15%|█▍        | 42/285 [01:01<06:20,  1.57s/it]Loading train:  15%|█▌        | 43/285 [01:02<06:20,  1.57s/it]Loading train:  15%|█▌        | 44/285 [01:04<05:58,  1.49s/it]Loading train:  16%|█▌        | 45/285 [01:05<05:59,  1.50s/it]Loading train:  16%|█▌        | 46/285 [01:07<06:05,  1.53s/it]Loading train:  16%|█▋        | 47/285 [01:08<05:56,  1.50s/it]Loading train:  17%|█▋        | 48/285 [01:10<05:45,  1.46s/it]Loading train:  17%|█▋        | 49/285 [01:11<05:34,  1.42s/it]Loading train:  18%|█▊        | 50/285 [01:12<05:27,  1.39s/it]Loading train:  18%|█▊        | 51/285 [01:13<05:09,  1.32s/it]Loading train:  18%|█▊        | 52/285 [01:15<05:03,  1.30s/it]Loading train:  19%|█▊        | 53/285 [01:16<05:16,  1.36s/it]Loading train:  19%|█▉        | 54/285 [01:17<05:11,  1.35s/it]Loading train:  19%|█▉        | 55/285 [01:19<05:02,  1.32s/it]Loading train:  20%|█▉        | 56/285 [01:20<04:54,  1.29s/it]Loading train:  20%|██        | 57/285 [01:21<04:51,  1.28s/it]Loading train:  20%|██        | 58/285 [01:23<05:00,  1.32s/it]Loading train:  21%|██        | 59/285 [01:24<05:07,  1.36s/it]Loading train:  21%|██        | 60/285 [01:26<05:26,  1.45s/it]Loading train:  21%|██▏       | 61/285 [01:27<05:06,  1.37s/it]Loading train:  22%|██▏       | 62/285 [01:29<05:26,  1.47s/it]Loading train:  22%|██▏       | 63/285 [01:30<05:25,  1.47s/it]Loading train:  22%|██▏       | 64/285 [01:32<06:04,  1.65s/it]Loading train:  23%|██▎       | 65/285 [01:34<06:26,  1.76s/it]Loading train:  23%|██▎       | 66/285 [01:36<06:46,  1.86s/it]Loading train:  24%|██▎       | 67/285 [01:38<06:17,  1.73s/it]Loading train:  24%|██▍       | 68/285 [01:39<05:37,  1.55s/it]Loading train:  24%|██▍       | 69/285 [01:40<05:29,  1.53s/it]Loading train:  25%|██▍       | 70/285 [01:42<05:25,  1.51s/it]Loading train:  25%|██▍       | 71/285 [01:43<05:11,  1.46s/it]Loading train:  25%|██▌       | 72/285 [01:44<05:01,  1.42s/it]Loading train:  26%|██▌       | 73/285 [01:46<04:51,  1.38s/it]Loading train:  26%|██▌       | 74/285 [01:47<04:44,  1.35s/it]Loading train:  26%|██▋       | 75/285 [01:48<04:38,  1.33s/it]Loading train:  27%|██▋       | 76/285 [01:49<04:29,  1.29s/it]Loading train:  27%|██▋       | 77/285 [01:51<04:24,  1.27s/it]Loading train:  27%|██▋       | 78/285 [01:52<04:13,  1.23s/it]Loading train:  28%|██▊       | 79/285 [01:53<04:15,  1.24s/it]Loading train:  28%|██▊       | 80/285 [01:54<04:19,  1.27s/it]Loading train:  28%|██▊       | 81/285 [01:56<04:23,  1.29s/it]Loading train:  29%|██▉       | 82/285 [01:57<04:17,  1.27s/it]Loading train:  29%|██▉       | 83/285 [01:58<04:19,  1.29s/it]Loading train:  29%|██▉       | 84/285 [02:00<04:21,  1.30s/it]Loading train:  30%|██▉       | 85/285 [02:01<04:25,  1.33s/it]Loading train:  30%|███       | 86/285 [02:02<04:21,  1.32s/it]Loading train:  31%|███       | 87/285 [02:04<04:32,  1.38s/it]Loading train:  31%|███       | 88/285 [02:05<04:47,  1.46s/it]Loading train:  31%|███       | 89/285 [02:07<04:43,  1.45s/it]Loading train:  32%|███▏      | 90/285 [02:09<04:54,  1.51s/it]Loading train:  32%|███▏      | 91/285 [02:10<04:54,  1.52s/it]Loading train:  32%|███▏      | 92/285 [02:12<04:53,  1.52s/it]Loading train:  33%|███▎      | 93/285 [02:13<04:53,  1.53s/it]Loading train:  33%|███▎      | 94/285 [02:15<04:55,  1.55s/it]Loading train:  33%|███▎      | 95/285 [02:17<05:10,  1.63s/it]Loading train:  34%|███▎      | 96/285 [02:18<05:04,  1.61s/it]Loading train:  34%|███▍      | 97/285 [02:20<05:00,  1.60s/it]Loading train:  34%|███▍      | 98/285 [02:21<04:46,  1.53s/it]Loading train:  35%|███▍      | 99/285 [02:22<04:33,  1.47s/it]Loading train:  35%|███▌      | 100/285 [02:24<04:19,  1.40s/it]Loading train:  35%|███▌      | 101/285 [02:25<04:12,  1.37s/it]Loading train:  36%|███▌      | 102/285 [02:26<04:09,  1.37s/it]Loading train:  36%|███▌      | 103/285 [02:28<04:14,  1.40s/it]Loading train:  36%|███▋      | 104/285 [02:29<04:17,  1.42s/it]Loading train:  37%|███▋      | 105/285 [02:31<04:21,  1.45s/it]Loading train:  37%|███▋      | 106/285 [02:32<04:06,  1.38s/it]Loading train:  38%|███▊      | 107/285 [02:33<04:00,  1.35s/it]Loading train:  38%|███▊      | 108/285 [02:35<03:58,  1.35s/it]Loading train:  38%|███▊      | 109/285 [02:36<03:58,  1.36s/it]Loading train:  39%|███▊      | 110/285 [02:38<04:06,  1.41s/it]Loading train:  39%|███▉      | 111/285 [02:39<04:05,  1.41s/it]Loading train:  39%|███▉      | 112/285 [02:40<04:04,  1.41s/it]Loading train:  40%|███▉      | 113/285 [02:42<03:58,  1.39s/it]Loading train:  40%|████      | 114/285 [02:43<03:53,  1.37s/it]Loading train:  40%|████      | 115/285 [02:44<03:46,  1.33s/it]Loading train:  41%|████      | 116/285 [02:45<03:39,  1.30s/it]Loading train:  41%|████      | 117/285 [02:47<03:39,  1.31s/it]Loading train:  41%|████▏     | 118/285 [02:48<03:38,  1.31s/it]Loading train:  42%|████▏     | 119/285 [02:50<03:51,  1.39s/it]Loading train:  42%|████▏     | 120/285 [02:51<03:50,  1.40s/it]Loading train:  42%|████▏     | 121/285 [02:53<03:56,  1.44s/it]Loading train:  43%|████▎     | 122/285 [02:54<03:56,  1.45s/it]Loading train:  43%|████▎     | 123/285 [02:56<04:02,  1.50s/it]Loading train:  44%|████▎     | 124/285 [02:57<04:05,  1.52s/it]Loading train:  44%|████▍     | 125/285 [02:58<03:44,  1.41s/it]Loading train:  44%|████▍     | 126/285 [03:00<03:43,  1.40s/it]Loading train:  45%|████▍     | 127/285 [03:01<03:31,  1.34s/it]Loading train:  45%|████▍     | 128/285 [03:02<03:29,  1.33s/it]Loading train:  45%|████▌     | 129/285 [03:03<03:12,  1.23s/it]Loading train:  46%|████▌     | 130/285 [03:04<03:04,  1.19s/it]Loading train:  46%|████▌     | 131/285 [03:06<03:00,  1.17s/it]Loading train:  46%|████▋     | 132/285 [03:07<03:03,  1.20s/it]Loading train:  47%|████▋     | 133/285 [03:08<03:03,  1.21s/it]Loading train:  47%|████▋     | 134/285 [03:09<02:56,  1.17s/it]Loading train:  47%|████▋     | 135/285 [03:10<03:03,  1.22s/it]Loading train:  48%|████▊     | 136/285 [03:12<03:06,  1.25s/it]Loading train:  48%|████▊     | 137/285 [03:13<03:02,  1.23s/it]Loading train:  48%|████▊     | 138/285 [03:14<03:02,  1.24s/it]Loading train:  49%|████▉     | 139/285 [03:16<03:03,  1.25s/it]Loading train:  49%|████▉     | 140/285 [03:17<03:05,  1.28s/it]Loading train:  49%|████▉     | 141/285 [03:18<03:10,  1.32s/it]Loading train:  50%|████▉     | 142/285 [03:20<03:12,  1.34s/it]Loading train:  50%|█████     | 143/285 [03:21<03:12,  1.36s/it]Loading train:  51%|█████     | 144/285 [03:22<03:03,  1.30s/it]Loading train:  51%|█████     | 145/285 [03:23<02:58,  1.27s/it]Loading train:  51%|█████     | 146/285 [03:24<02:45,  1.19s/it]Loading train:  52%|█████▏    | 147/285 [03:26<03:04,  1.34s/it]Loading train:  52%|█████▏    | 148/285 [03:28<03:07,  1.37s/it]Loading train:  52%|█████▏    | 149/285 [03:29<02:57,  1.31s/it]Loading train:  53%|█████▎    | 150/285 [03:30<02:54,  1.29s/it]Loading train:  53%|█████▎    | 151/285 [03:32<03:03,  1.37s/it]Loading train:  53%|█████▎    | 152/285 [03:33<02:51,  1.29s/it]Loading train:  54%|█████▎    | 153/285 [03:34<02:50,  1.30s/it]Loading train:  54%|█████▍    | 154/285 [03:35<02:45,  1.27s/it]Loading train:  54%|█████▍    | 155/285 [03:36<02:35,  1.20s/it]Loading train:  55%|█████▍    | 156/285 [03:37<02:32,  1.18s/it]Loading train:  55%|█████▌    | 157/285 [03:39<02:34,  1.20s/it]Loading train:  55%|█████▌    | 158/285 [03:40<02:38,  1.25s/it]Loading train:  56%|█████▌    | 159/285 [03:41<02:39,  1.26s/it]Loading train:  56%|█████▌    | 160/285 [03:42<02:33,  1.23s/it]Loading train:  56%|█████▋    | 161/285 [03:44<02:30,  1.22s/it]Loading train:  57%|█████▋    | 162/285 [03:45<02:37,  1.28s/it]Loading train:  57%|█████▋    | 163/285 [03:46<02:35,  1.27s/it]Loading train:  58%|█████▊    | 164/285 [03:47<02:25,  1.20s/it]Loading train:  58%|█████▊    | 165/285 [03:48<02:24,  1.20s/it]Loading train:  58%|█████▊    | 166/285 [03:50<02:22,  1.20s/it]Loading train:  59%|█████▊    | 167/285 [03:51<02:21,  1.20s/it]Loading train:  59%|█████▉    | 168/285 [03:52<02:17,  1.17s/it]Loading train:  59%|█████▉    | 169/285 [03:53<02:17,  1.18s/it]Loading train:  60%|█████▉    | 170/285 [03:54<02:17,  1.19s/it]Loading train:  60%|██████    | 171/285 [03:55<02:07,  1.12s/it]Loading train:  60%|██████    | 172/285 [03:57<02:12,  1.17s/it]Loading train:  61%|██████    | 173/285 [03:58<02:04,  1.11s/it]Loading train:  61%|██████    | 174/285 [03:59<01:58,  1.07s/it]Loading train:  61%|██████▏   | 175/285 [04:00<01:58,  1.07s/it]Loading train:  62%|██████▏   | 176/285 [04:01<01:54,  1.05s/it]Loading train:  62%|██████▏   | 177/285 [04:02<02:00,  1.12s/it]Loading train:  62%|██████▏   | 178/285 [04:03<01:59,  1.12s/it]Loading train:  63%|██████▎   | 179/285 [04:04<01:57,  1.11s/it]Loading train:  63%|██████▎   | 180/285 [04:05<02:01,  1.16s/it]Loading train:  64%|██████▎   | 181/285 [04:06<01:52,  1.08s/it]Loading train:  64%|██████▍   | 182/285 [04:08<01:55,  1.12s/it]Loading train:  64%|██████▍   | 183/285 [04:09<01:56,  1.15s/it]Loading train:  65%|██████▍   | 184/285 [04:10<01:57,  1.16s/it]Loading train:  65%|██████▍   | 185/285 [04:11<02:00,  1.21s/it]Loading train:  65%|██████▌   | 186/285 [04:12<01:58,  1.19s/it]Loading train:  66%|██████▌   | 187/285 [04:14<01:55,  1.18s/it]Loading train:  66%|██████▌   | 188/285 [04:15<01:47,  1.11s/it]Loading train:  66%|██████▋   | 189/285 [04:16<01:45,  1.10s/it]Loading train:  67%|██████▋   | 190/285 [04:17<01:42,  1.08s/it]Loading train:  67%|██████▋   | 191/285 [04:18<01:43,  1.10s/it]Loading train:  67%|██████▋   | 192/285 [04:19<01:40,  1.08s/it]Loading train:  68%|██████▊   | 193/285 [04:20<01:41,  1.10s/it]Loading train:  68%|██████▊   | 194/285 [04:21<01:39,  1.09s/it]Loading train:  68%|██████▊   | 195/285 [04:22<01:39,  1.10s/it]Loading train:  69%|██████▉   | 196/285 [04:24<01:46,  1.20s/it]Loading train:  69%|██████▉   | 197/285 [04:25<01:41,  1.15s/it]Loading train:  69%|██████▉   | 198/285 [04:26<01:36,  1.11s/it]Loading train:  70%|██████▉   | 199/285 [04:27<01:43,  1.20s/it]Loading train:  70%|███████   | 200/285 [04:28<01:41,  1.19s/it]Loading train:  71%|███████   | 201/285 [04:29<01:40,  1.20s/it]Loading train:  71%|███████   | 202/285 [04:31<01:39,  1.20s/it]Loading train:  71%|███████   | 203/285 [04:32<01:34,  1.15s/it]Loading train:  72%|███████▏  | 204/285 [04:33<01:35,  1.18s/it]Loading train:  72%|███████▏  | 205/285 [04:34<01:34,  1.18s/it]Loading train:  72%|███████▏  | 206/285 [04:35<01:34,  1.20s/it]Loading train:  73%|███████▎  | 207/285 [04:36<01:31,  1.18s/it]Loading train:  73%|███████▎  | 208/285 [04:38<01:31,  1.19s/it]Loading train:  73%|███████▎  | 209/285 [04:39<01:32,  1.22s/it]Loading train:  74%|███████▎  | 210/285 [04:40<01:31,  1.21s/it]Loading train:  74%|███████▍  | 211/285 [04:42<01:32,  1.25s/it]Loading train:  74%|███████▍  | 212/285 [04:43<01:29,  1.22s/it]Loading train:  75%|███████▍  | 213/285 [04:44<01:35,  1.33s/it]Loading train:  75%|███████▌  | 214/285 [04:46<01:33,  1.32s/it]Loading train:  75%|███████▌  | 215/285 [04:47<01:33,  1.34s/it]Loading train:  76%|███████▌  | 216/285 [04:48<01:32,  1.34s/it]Loading train:  76%|███████▌  | 217/285 [04:49<01:27,  1.29s/it]Loading train:  76%|███████▋  | 218/285 [04:51<01:22,  1.23s/it]Loading train:  77%|███████▋  | 219/285 [04:52<01:22,  1.24s/it]Loading train:  77%|███████▋  | 220/285 [04:53<01:19,  1.23s/it]Loading train:  78%|███████▊  | 221/285 [04:54<01:14,  1.16s/it]Loading train:  78%|███████▊  | 222/285 [04:55<01:15,  1.20s/it]Loading train:  78%|███████▊  | 223/285 [04:56<01:12,  1.18s/it]Loading train:  79%|███████▊  | 224/285 [04:57<01:06,  1.09s/it]Loading train:  79%|███████▉  | 225/285 [04:58<01:06,  1.11s/it]Loading train:  79%|███████▉  | 226/285 [05:00<01:05,  1.11s/it]Loading train:  80%|███████▉  | 227/285 [05:01<01:08,  1.18s/it]Loading train:  80%|████████  | 228/285 [05:02<01:09,  1.21s/it]Loading train:  80%|████████  | 229/285 [05:04<01:11,  1.27s/it]Loading train:  81%|████████  | 230/285 [05:05<01:07,  1.23s/it]Loading train:  81%|████████  | 231/285 [05:06<01:10,  1.30s/it]Loading train:  81%|████████▏ | 232/285 [05:08<01:10,  1.33s/it]Loading train:  82%|████████▏ | 233/285 [05:09<01:11,  1.38s/it]Loading train:  82%|████████▏ | 234/285 [05:10<01:07,  1.32s/it]Loading train:  82%|████████▏ | 235/285 [05:11<01:03,  1.27s/it]Loading train:  83%|████████▎ | 236/285 [05:13<01:03,  1.30s/it]Loading train:  83%|████████▎ | 237/285 [05:14<01:03,  1.31s/it]Loading train:  84%|████████▎ | 238/285 [05:16<01:07,  1.43s/it]Loading train:  84%|████████▍ | 239/285 [05:17<01:02,  1.36s/it]Loading train:  84%|████████▍ | 240/285 [05:19<01:02,  1.40s/it]Loading train:  85%|████████▍ | 241/285 [05:20<01:01,  1.40s/it]Loading train:  85%|████████▍ | 242/285 [05:21<00:59,  1.39s/it]Loading train:  85%|████████▌ | 243/285 [05:23<00:57,  1.36s/it]Loading train:  86%|████████▌ | 244/285 [05:24<00:50,  1.24s/it]Loading train:  86%|████████▌ | 245/285 [05:25<00:48,  1.21s/it]Loading train:  86%|████████▋ | 246/285 [05:26<00:49,  1.26s/it]Loading train:  87%|████████▋ | 247/285 [05:27<00:49,  1.30s/it]Loading train:  87%|████████▋ | 248/285 [05:29<00:45,  1.24s/it]Loading train:  87%|████████▋ | 249/285 [05:30<00:47,  1.31s/it]Loading train:  88%|████████▊ | 250/285 [05:31<00:44,  1.28s/it]Loading train:  88%|████████▊ | 251/285 [05:32<00:40,  1.19s/it]Loading train:  88%|████████▊ | 252/285 [05:33<00:38,  1.16s/it]Loading train:  89%|████████▉ | 253/285 [05:35<00:38,  1.20s/it]Loading train:  89%|████████▉ | 254/285 [05:36<00:35,  1.16s/it]Loading train:  89%|████████▉ | 255/285 [05:37<00:34,  1.16s/it]Loading train:  90%|████████▉ | 256/285 [05:38<00:33,  1.17s/it]Loading train:  90%|█████████ | 257/285 [05:39<00:31,  1.13s/it]Loading train:  91%|█████████ | 258/285 [05:40<00:31,  1.16s/it]Loading train:  91%|█████████ | 259/285 [05:41<00:27,  1.07s/it]Loading train:  91%|█████████ | 260/285 [05:42<00:26,  1.06s/it]Loading train:  92%|█████████▏| 261/285 [05:43<00:26,  1.12s/it]Loading train:  92%|█████████▏| 262/285 [05:45<00:26,  1.15s/it]Loading train:  92%|█████████▏| 263/285 [05:46<00:24,  1.09s/it]Loading train:  93%|█████████▎| 264/285 [05:47<00:22,  1.08s/it]Loading train:  93%|█████████▎| 265/285 [05:48<00:22,  1.12s/it]Loading train:  93%|█████████▎| 266/285 [05:49<00:22,  1.18s/it]Loading train:  94%|█████████▎| 267/285 [05:50<00:20,  1.13s/it]Loading train:  94%|█████████▍| 268/285 [05:51<00:19,  1.17s/it]Loading train:  94%|█████████▍| 269/285 [05:53<00:20,  1.25s/it]Loading train:  95%|█████████▍| 270/285 [05:54<00:19,  1.27s/it]Loading train:  95%|█████████▌| 271/285 [05:55<00:17,  1.25s/it]Loading train:  95%|█████████▌| 272/285 [05:57<00:16,  1.25s/it]Loading train:  96%|█████████▌| 273/285 [05:58<00:15,  1.29s/it]Loading train:  96%|█████████▌| 274/285 [05:59<00:13,  1.27s/it]Loading train:  96%|█████████▋| 275/285 [06:00<00:12,  1.24s/it]Loading train:  97%|█████████▋| 276/285 [06:02<00:11,  1.24s/it]Loading train:  97%|█████████▋| 277/285 [06:03<00:09,  1.21s/it]Loading train:  98%|█████████▊| 278/285 [06:04<00:08,  1.27s/it]Loading train:  98%|█████████▊| 279/285 [06:06<00:07,  1.30s/it]Loading train:  98%|█████████▊| 280/285 [06:07<00:06,  1.28s/it]Loading train:  99%|█████████▊| 281/285 [06:08<00:05,  1.34s/it]Loading train:  99%|█████████▉| 282/285 [06:10<00:03,  1.33s/it]Loading train:  99%|█████████▉| 283/285 [06:11<00:02,  1.31s/it]Loading train: 100%|█████████▉| 284/285 [06:12<00:01,  1.27s/it]Loading train: 100%|██████████| 285/285 [06:13<00:00,  1.25s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 44.21it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:05, 47.53it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:05, 51.22it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:04, 53.52it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:04, 54.76it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:04, 56.33it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:04, 58.05it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:03, 60.55it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:03, 59.87it/s]concatenating: train:  23%|██▎       | 65/285 [00:01<00:03, 61.85it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:02, 72.49it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:02, 82.15it/s]concatenating: train:  36%|███▌      | 103/285 [00:01<00:01, 91.55it/s]concatenating: train:  40%|████      | 114/285 [00:01<00:02, 84.12it/s]concatenating: train:  44%|████▎     | 124/285 [00:01<00:02, 76.21it/s]concatenating: train:  47%|████▋     | 133/285 [00:01<00:02, 70.83it/s]concatenating: train:  49%|████▉     | 141/285 [00:01<00:02, 68.38it/s]concatenating: train:  52%|█████▏    | 149/285 [00:02<00:02, 66.91it/s]concatenating: train:  55%|█████▍    | 156/285 [00:02<00:02, 62.63it/s]concatenating: train:  57%|█████▋    | 163/285 [00:02<00:01, 63.28it/s]concatenating: train:  60%|██████    | 172/285 [00:02<00:01, 68.92it/s]concatenating: train:  65%|██████▍   | 184/285 [00:02<00:01, 78.30it/s]concatenating: train:  68%|██████▊   | 193/285 [00:02<00:01, 73.57it/s]concatenating: train:  71%|███████   | 203/285 [00:02<00:01, 78.90it/s]concatenating: train:  75%|███████▌  | 214/285 [00:02<00:00, 85.56it/s]concatenating: train:  79%|███████▊  | 224/285 [00:03<00:00, 69.35it/s]concatenating: train:  81%|████████▏ | 232/285 [00:03<00:00, 70.49it/s]concatenating: train:  84%|████████▍ | 240/285 [00:03<00:00, 72.62it/s]concatenating: train:  89%|████████▉ | 253/285 [00:03<00:00, 82.99it/s]concatenating: train:  93%|█████████▎| 265/285 [00:03<00:00, 90.72it/s]concatenating: train:  96%|█████████▋| 275/285 [00:03<00:00, 79.90it/s]concatenating: train: 100%|█████████▉| 284/285 [00:03<00:00, 73.02it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 73.79it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.48s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.44s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.48s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 34.17it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      2019-07-08 13:18:57.592704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 13:18:57.592822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 13:18:57.592838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 13:18:57.592848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 13:18:57.593296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 23s - loss: 19431.6616 - acc: 0.7650 - mDice: 0.1462 - val_loss: 8750.3686 - val_acc: 0.9048 - val_mDice: 0.3138

Epoch 00001: val_mDice improved from -inf to 0.31379, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 6572.1597 - acc: 0.8826 - mDice: 0.4259 - val_loss: 5645.7694 - val_acc: 0.9071 - val_mDice: 0.4588

Epoch 00002: val_mDice improved from 0.31379 to 0.45875, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 4579.0080 - acc: 0.8901 - mDice: 0.5479 - val_loss: 5263.4131 - val_acc: 0.9111 - val_mDice: 0.4926

Epoch 00003: val_mDice improved from 0.45875 to 0.49258, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 3744.1087 - acc: 0.9002 - mDice: 0.6109 - val_loss: 4812.2081 - val_acc: 0.9191 - val_mDice: 0.5172

Epoch 00004: val_mDice improved from 0.49258 to 0.51718, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 12s - loss: 3318.3344 - acc: 0.9167 - mDice: 0.6456 - val_loss: 4698.3730 - val_acc: 0.9382 - val_mDice: 0.5286

Epoch 00005: val_mDice improved from 0.51718 to 0.52857, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 3026.8838 - acc: 0.9328 - mDice: 0.6701 - val_loss: 4557.9274 - val_acc: 0.9386 - val_mDice: 0.5350

Epoch 00006: val_mDice improved from 0.52857 to 0.53498, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 11s - loss: 2846.6805 - acc: 0.9405 - mDice: 0.6855 - val_loss: 4266.4199 - val_acc: 0.9360 - val_mDice: 0.5526

Epoch 00007: val_mDice improved from 0.53498 to 0.55261, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 2723.5763 - acc: 0.9428 - mDice: 0.6963 - val_loss: 4506.7337 - val_acc: 0.9352 - val_mDice: 0.5390

Epoch 00008: val_mDice did not improve from 0.55261
Epoch 9/300
 - 11s - loss: 2578.2863 - acc: 0.9445 - mDice: 0.7096 - val_loss: 4416.2969 - val_acc: 0.9379 - val_mDice: 0.5435

Epoch 00009: val_mDice did not improve from 0.55261
Epoch 10/300
 - 11s - loss: 2519.0330 - acc: 0.9453 - mDice: 0.7152 - val_loss: 4209.4055 - val_acc: 0.9360 - val_mDice: 0.5567

Epoch 00010: val_mDice improved from 0.55261 to 0.55675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 11s - loss: 2425.9993 - acc: 0.9465 - mDice: 0.7239 - val_loss: 4331.4608 - val_acc: 0.9389 - val_mDice: 0.5514

Epoch 00011: val_mDice did not improve from 0.55675
Epoch 12/300
 - 11s - loss: 2347.6674 - acc: 0.9474 - mDice: 0.7315 - val_loss: 4573.7877 - val_acc: 0.9348 - val_mDice: 0.5350

Epoch 00012: val_mDice did not improve from 0.55675
Epoch 13/300
 - 11s - loss: 2280.7158 - acc: 0.9480 - mDice: 0.7378 - val_loss: 4698.5446 - val_acc: 0.9345 - val_mDice: 0.5314

Epoch 00013: val_mDice did not improve from 0.55675
Epoch 14/300
 - 11s - loss: 2255.3977 - acc: 0.9485 - mDice: 0.7404 - val_loss: 4770.2933 - val_acc: 0.9400 - val_mDice: 0.5304

Epoch 00014: val_mDice did not improve from 0.55675
Epoch 15/300
 - 11s - loss: 2190.4624 - acc: 0.9491 - mDice: 0.7467 - val_loss: 4178.5420 - val_acc: 0.9380 - val_mDice: 0.5607

Epoch 00015: val_mDice improved from 0.55675 to 0.56074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 11s - loss: 2159.8344 - acc: 0.9494 - mDice: 0.7498 - val_loss: 3978.1696 - val_acc: 0.9430 - val_mDice: 0.5761

Epoch 00016: val_mDice improved from 0.56074 to 0.57607, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 11s - loss: 2100.6929 - acc: 0.9502 - mDice: 0.7557 - val_loss: 4136.8958 - val_acc: 0.9384 - val_mDice: 0.5637

Epoch 00017: val_mDice did not improve from 0.57607
Epoch 18/300
 - 11s - loss: 2071.8766 - acc: 0.9506 - mDice: 0.7585 - val_loss: 4136.1518 - val_acc: 0.9390 - val_mDice: 0.5623

Epoch 00018: val_mDice did not improve from 0.57607
Epoch 19/300
 - 11s - loss: 2039.1513 - acc: 0.9510 - mDice: 0.7619 - val_loss: 4018.9259 - val_acc: 0.9393 - val_mDice: 0.5733

Epoch 00019: val_mDice did not improve from 0.57607
Epoch 20/300
 - 11s - loss: 1995.6672 - acc: 0.9513 - mDice: 0.7662 - val_loss: 4122.6038 - val_acc: 0.9407 - val_mDice: 0.5646

Epoch 00020: val_mDice did not improve from 0.57607
Epoch 21/300
 - 12s - loss: 1979.5667 - acc: 0.9514 - mDice: 0.7679 - val_loss: 4256.7211 - val_acc: 0.9324 - val_mDice: 0.5541

Epoch 00021: val_mDice did not improve from 0.57607
Epoch 22/300
 - 11s - loss: 1963.2373 - acc: 0.9519 - mDice: 0.7696 - val_loss: 4154.5672 - val_acc: 0.9423 - val_mDice: 0.5659

Epoch 00022: val_mDice did not improve from 0.57607
Epoch 23/300
 - 11s - loss: 1931.4281 - acc: 0.9521 - mDice: 0.7728 - val_loss: 4169.1659 - val_acc: 0.9362 - val_mDice: 0.5610

Epoch 00023: val_mDice did not improve from 0.57607
Epoch 24/300
 - 11s - loss: 1913.2195 - acc: 0.9524 - mDice: 0.7747 - val_loss: 4458.2231 - val_acc: 0.9408 - val_mDice: 0.5404

Epoch 00024: val_mDice did not improve from 0.57607
Epoch 25/300
 - 11s - loss: 1886.2759 - acc: 0.9527 - mDice: 0.7775 - val_loss: 4028.3006 - val_acc: 0.9387 - val_mDice: 0.5705

Epoch 00025: val_mDice did not improve from 0.57607
Epoch 26/300
 - 11s - loss: 1860.6228 - acc: 0.9530 - mDice: 0.7801 - val_loss: 4415.2739 - val_acc: 0.9400 - val_mDice: 0.5475

Epoch 00026: val_mDice did not improve from 0.57607
Epoch 27/300
 - 11s - loss: 1834.4185 - acc: 0.9534 - mDice: 0.7829 - val_loss: 4532.6659 - val_acc: 0.9380 - val_mDice: 0.5362

Epoch 00027: val_mDice did not improve from 0.57607
Epoch 28/300
 - 11s - loss: 1815.8115 - acc: 0.9535 - mDice: 0.7848 - val_loss: 4190.5657 - val_acc: 0.9398 - val_mDice: 0.5624

Epoch 00028: val_mDice did not improve from 0.57607
Epoch 29/300
 - 11s - loss: 1800.1041 - acc: 0.9536 - mDice: 0.7865 - val_loss: 4083.8541 - val_acc: 0.9418 - val_mDice: 0.5667

Epoch 00029: val_mDice did not improve from 0.57607
Epoch 30/300
 - 11s - loss: 1796.2583 - acc: 0.9538 - mDice: 0.7869 - val_loss: 4100.9123 - val_acc: 0.9389 - val_mDice: 0.5674

Epoch 00030: val_mDice did not improve from 0.57607
Epoch 31/300
 - 11s - loss: 1773.7260 - acc: 0.9540 - mDice: 0.7892 - val_loss: 4248.7726 - val_acc: 0.9398 - val_mDice: 0.5582

Epoch 00031: val_mDice did not improve from 0.57607
Epoch 32/300
 - 11s - loss: 1755.4559 - acc: 0.9542 - mDice: 0.7912 - val_loss: 4491.3763 - val_acc: 0.9418 - val_mDice: 0.5422

Epoch 00032: val_mDice did not improve from 0.57607
Epoch 33/300
 - 11s - loss: 1739.2635 - acc: 0.9543 - mDice: 0.7929 - val_loss: 4261.2299 - val_acc: 0.9387 - val_mDice: 0.5558

Epoch 00033: val_mDice did not improve from 0.57607
Epoch 34/300
 - 11s - loss: 1728.6367 - acc: 0.9546 - mDice: 0.7940 - val_loss: 3933.9645 - val_acc: 0.9411 - val_mDice: 0.5794

Epoch 00034: val_mDice improved from 0.57607 to 0.57941, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 11s - loss: 1712.0267 - acc: 0.9547 - mDice: 0.7957 - val_loss: 4018.3400 - val_acc: 0.9410 - val_mDice: 0.5731

Epoch 00035: val_mDice did not improve from 0.57941
Epoch 36/300
 - 11s - loss: 1692.7818 - acc: 0.9550 - mDice: 0.7979 - val_loss: 4138.2524 - val_acc: 0.9392 - val_mDice: 0.5642

Epoch 00036: val_mDice did not improve from 0.57941
Epoch 37/300
 - 11s - loss: 1692.8660 - acc: 0.9549 - mDice: 0.7978 - val_loss: 3967.5262 - val_acc: 0.9430 - val_mDice: 0.5768

Epoch 00037: val_mDice did not improve from 0.57941
Epoch 38/300
 - 11s - loss: 1681.7755 - acc: 0.9550 - mDice: 0.7990 - val_loss: 4200.5557 - val_acc: 0.9422 - val_mDice: 0.5637

Epoch 00038: val_mDice did not improve from 0.57941
Epoch 39/300
 - 11s - loss: 1665.9017 - acc: 0.9551 - mDice: 0.8007 - val_loss: 3973.2718 - val_acc: 0.9427 - val_mDice: 0.5761

Epoch 00039: val_mDice did not improve from 0.57941
Epoch 40/300
 - 11s - loss: 1654.0760 - acc: 0.9554 - mDice: 0.8019 - val_loss: 4277.7865 - val_acc: 0.9398 - val_mDice: 0.5546

Epoch 00040: val_mDice did not improve from 0.57941
Epoch 41/300
 - 11s - loss: 1639.0199 - acc: 0.9555 - mDice: 0.8035 - val_loss: 4689.7096 - val_acc: 0.9371 - val_mDice: 0.5351

Epoch 00041: val_mDice did not improve from 0.57941
Epoch 42/300
 - 12s - loss: 1626.7142 - acc: 0.9556 - mDice: 0.8048 - val_loss: 4410.5341 - val_acc: 0.9407 - val_mDice: 0.5460

Epoch 00042: val_mDice did not improve from 0.57941
Epoch 43/300
 - 11s - loss: 1609.1119 - acc: 0.9559 - mDice: 0.8067 - val_loss: 4452.0188 - val_acc: 0.9340 - val_mDice: 0.5421

Epoch 00043: val_mDice did not improve from 0.57941
Epoch 44/300
 - 11s - loss: 1613.3622 - acc: 0.9558 - mDice: 0.8063 - val_loss: 4106.0938 - val_acc: 0.9414 - val_mDice: 0.5678

Epoch 00044: val_mDice did not improve from 0.57941
Epoch 45/300
 - 11s - loss: 1602.9387 - acc: 0.9560 - mDice: 0.8074 - val_loss: 3994.4007 - val_acc: 0.9444 - val_mDice: 0.5747

Epoch 00045: val_mDice did not improve from 0.57941
Epoch 46/300
 - 11s - loss: 1590.6419 - acc: 0.9561 - mDice: 0.8087 - val_loss: 4072.4658 - val_acc: 0.9446 - val_mDice: 0.5695

Epoch 00046: val_mDice did not improve from 0.57941
Epoch 47/300
 - 10s - loss: 1593.2308 - acc: 0.9561 - mDice: 0.8084 - val_loss: 3968.0555 - val_acc: 0.9456 - val_mDice: 0.5796

Epoch 00047: val_mDice improved from 0.57941 to 0.57956, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 48/300
 - 11s - loss: 1571.2268 - acc: 0.9563 - mDice: 0.8108 - val_loss: 4355.7624 - val_acc: 0.9424 - val_mDice: 0.5503

Epoch 00048: val_mDice did not improve from 0.57956
Epoch 49/300
 - 11s - loss: 1567.3344 - acc: 0.9564 - mDice: 0.8113 - val_loss: 3885.0463 - val_acc: 0.9427 - val_mDice: 0.5821

Epoch 00049: val_mDice improved from 0.57956 to 0.58215, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 50/300
 - 11s - loss: 1557.2471 - acc: 0.9565 - mDice: 0.8123 - val_loss: 4259.3881 - val_acc: 0.9379 - val_mDice: 0.5574

Epoch 00050: val_mDice did not improve from 0.58215
Epoch 51/300
 - 11s - loss: 1551.1837 - acc: 0.9566 - mDice: 0.8130 - val_loss: 3905.9453 - val_acc: 0.9420 - val_mDice: 0.5821

Epoch 00051: val_mDice did not improve from 0.58215
Epoch 52/300
 - 11s - loss: 1542.8216 - acc: 0.9567 - mDice: 0.8139 - val_loss: 3871.7208 - val_acc: 0.9418 - val_mDice: 0.5814

Epoch 00052: val_mDice did not improve from 0.58215
Epoch 53/300
 - 11s - loss: 1541.6182 - acc: 0.9568 - mDice: 0.8140 - val_loss: 4530.6431 - val_acc: 0.9348 - val_mDice: 0.5387

Epoch 00053: val_mDice did not improve from 0.58215
Epoch 54/300
 - 10s - loss: 1526.5070 - acc: 0.9569 - mDice: 0.8157 - val_loss: 4111.3443 - val_acc: 0.9398 - val_mDice: 0.5658

Epoch 00054: val_mDice did not improve from 0.58215
Epoch 55/300
 - 10s - loss: 1527.5666 - acc: 0.9569 - mDice: 0.8156 - val_loss: 4243.7244 - val_acc: 0.9425 - val_mDice: 0.5585

Epoch 00055: val_mDice did not improve from 0.58215
Epoch 56/300
 - 10s - loss: 1522.5588 - acc: 0.9570 - mDice: 0.8161 - val_loss: 4969.1213 - val_acc: 0.9343 - val_mDice: 0.5153

Epoch 00056: val_mDice did not improve from 0.58215
Epoch 57/300
 - 10s - loss: 1515.3073 - acc: 0.9570 - mDice: 0.8169 - val_loss: 4311.8066 - val_acc: 0.9400 - val_mDice: 0.5544

Epoch 00057: val_mDice did not improve from 0.58215
Epoch 58/300
 - 10s - loss: 1507.6304 - acc: 0.9572 - mDice: 0.8177 - val_loss: 3985.2707 - val_acc: 0.9425 - val_mDice: 0.5737

Epoch 00058: val_mDice did not improve from 0.58215
Epoch 59/300
 - 10s - loss: 1500.0991 - acc: 0.9573 - mDice: 0.8185 - val_loss: 4133.5107 - val_acc: 0.9388 - val_mDice: 0.5640

Epoch 00059: val_mDice did not improve from 0.58215
Epoch 60/300
 - 11s - loss: 1487.8845 - acc: 0.9574 - mDice: 0.8199 - val_loss: 4276.7606 - val_acc: 0.9392 - val_mDice: 0.5555

Epoch 00060: val_mDice did not improve from 0.58215
Epoch 61/300
 - 10s - loss: 1492.3533 - acc: 0.9574 - mDice: 0.8194 - val_loss: 4232.5977 - val_acc: 0.9430 - val_mDice: 0.5650

Epoch 00061: val_mDice did not improve from 0.58215
Epoch 62/300
 - 10s - loss: 1486.3831 - acc: 0.9574 - mDice: 0.8201 - val_loss: 4115.2485 - val_acc: 0.9434 - val_mDice: 0.5666

Epoch 00062: val_mDice did not improve from 0.58215
Epoch 63/300
 - 10s - loss: 1482.0513 - acc: 0.9575 - mDice: 0.8205 - val_loss: 4103.9877 - val_acc: 0.9454 - val_mDice: 0.5692

Epoch 00063: val_mDice did not improve from 0.58215
Epoch 64/300
 - 10s - loss: 1482.0996 - acc: 0.9576 - mDice: 0.8205 - val_loss: 3807.8676 - val_acc: 0.9450 - val_mDice: 0.5874

Epoch 00064: val_mDice improved from 0.58215 to 0.58741, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 65/300
 - 10s - loss: 1471.8262 - acc: 0.9577 - mDice: 0.8216 - val_loss: 4012.7583 - val_acc: 0.9421 - val_mDice: 0.5742

Epoch 00065: val_mDice did not improve from 0.58741
Epoch 66/300
 - 10s - loss: 1478.1034 - acc: 0.9576 - mDice: 0.8210 - val_loss: 3937.9165 - val_acc: 0.9424 - val_mDice: 0.5769

Epoch 00066: val_mDice did not improve from 0.58741
Epoch 67/300
 - 11s - loss: 1460.2282 - acc: 0.9578 - mDice: 0.8229 - val_loss: 4522.5437 - val_acc: 0.9360 - val_mDice: 0.5417

Epoch 00067: val_mDice did not improve from 0.58741
Epoch 68/300
 - 11s - loss: 1458.9372 - acc: 0.9579 - mDice: 0.8231 - val_loss: 4098.5054 - val_acc: 0.9371 - val_mDice: 0.5668

Epoch 00068: val_mDice did not improve from 0.58741
Epoch 69/300
 - 10s - loss: 1443.4726 - acc: 0.9580 - mDice: 0.8247 - val_loss: 4037.4523 - val_acc: 0.9408 - val_mDice: 0.5689

Epoch 00069: val_mDice did not improve from 0.58741
Epoch 70/300
 - 10s - loss: 1452.8192 - acc: 0.9580 - mDice: 0.8237 - val_loss: 3906.0118 - val_acc: 0.9451 - val_mDice: 0.5805

Epoch 00070: val_mDice did not improve from 0.58741
Epoch 71/300
 - 10s - loss: 1448.9712 - acc: 0.9580 - mDice: 0.8241 - val_loss: 4046.4230 - val_acc: 0.9441 - val_mDice: 0.5722

Epoch 00071: val_mDice did not improve from 0.58741
Epoch 72/300
 - 10s - loss: 1432.9586 - acc: 0.9582 - mDice: 0.8259 - val_loss: 4302.9684 - val_acc: 0.9401 - val_mDice: 0.5544

Epoch 00072: val_mDice did not improve from 0.58741
Epoch 73/300
 - 10s - loss: 1433.3792 - acc: 0.9582 - mDice: 0.8259 - val_loss: 4207.1122 - val_acc: 0.9420 - val_mDice: 0.5604

Epoch 00073: val_mDice did not improve from 0.58741
Epoch 74/300
 - 11s - loss: 1435.4421 - acc: 0.9582 - mDice: 0.8256 - val_loss: 4187.2567 - val_acc: 0.9386 - val_mDice: 0.5609

Epoch 00074: val_mDice did not improve from 0.58741
Epoch 75/300
 - 11s - loss: 1431.7200 - acc: 0.9581 - mDice: 0.8260 - val_loss: 3907.4596 - val_acc: 0.9410 - val_mDice: 0.5803

Epoch 00075: val_mDice did not improve from 0.58741
Epoch 76/300
 - 10s - loss: 1426.1698 - acc: 0.9582 - mDice: 0.8267 - val_loss: 3853.5878 - val_acc: 0.9428 - val_mDice: 0.5849

Epoch 00076: val_mDice did not improve from 0.58741
Epoch 77/300
 - 10s - loss: 1426.2567 - acc: 0.9583 - mDice: 0.8267 - val_loss: 4159.9369 - val_acc: 0.9414 - val_mDice: 0.5613

Epoch 00077: val_mDice did not improve from 0.58741
Epoch 78/300
 - 10s - loss: 1419.6455 - acc: 0.9584 - mDice: 0.8274 - val_loss: 4012.1974 - val_acc: 0.9422 - val_mDice: 0.5724

Epoch 00078: val_mDice did not improve from 0.58741
Epoch 79/300
 - 11s - loss: 1410.9197 - acc: 0.9585 - mDice: 0.8284 - val_loss: 4079.0190 - val_acc: 0.9416 - val_mDice: 0.5667

Epoch 00079: val_mDice did not improve from 0.58741
Epoch 80/300
 - 11s - loss: 1410.6369 - acc: 0.9585 - mDice: 0.8284 - val_loss: 4351.0400 - val_acc: 0.9409 - val_mDice: 0.5489

Epoch 00080: val_mDice did not improve from 0.58741
Epoch 81/300
 - 10s - loss: 1405.5013 - acc: 0.9586 - mDice: 0.8290 - val_loss: 3803.6234 - val_acc: 0.9439 - val_mDice: 0.5863

Epoch 00081: val_mDice did not improve from 0.58741
Epoch 82/300
 - 10s - loss: 1404.6549 - acc: 0.9585 - mDice: 0.8291 - val_loss: 3966.1314 - val_acc: 0.9426 - val_mDice: 0.5757

Epoch 00082: val_mDice did not improve from 0.58741
Epoch 83/300
 - 10s - loss: 1404.6258 - acc: 0.9586 - mDice: 0.8291 - val_loss: 4098.1095 - val_acc: 0.9409 - val_mDice: 0.5675

Epoch 00083: val_mDice did not improve from 0.58741
Epoch 84/300
 - 11s - loss: 1406.4511 - acc: 0.9585 - mDice: 0.8289 - val_loss: 4212.8065 - val_acc: 0.9418 - val_mDice: 0.5603

Epoch 00084: val_mDice did not improve from 0.58741
Epoch 85/300
 - 11s - loss: 1401.2532 - acc: 0.9587 - mDice: 0.8294 - val_loss: 3838.0805 - val_acc: 0.9427 - val_mDice: 0.5838

Epoch 00085: val_mDice did not improve from 0.58741
Epoch 86/300
 - 10s - loss: 1392.4461 - acc: 0.9586 - mDice: 0.8304 - val_loss: 4086.9186 - val_acc: 0.9426 - val_mDice: 0.5672

Epoch 00086: val_mDice did not improve from 0.58741
Epoch 87/300
 - 10s - loss: 1395.5250 - acc: 0.9587 - mDice: 0.8300 - val_loss: 3982.3164 - val_acc: 0.9441 - val_mDice: 0.5747

Epoch 00087: val_mDice did not improve from 0.58741
Epoch 88/300
 - 10s - loss: 1391.3654 - acc: 0.9588 - mDice: 0.8306 - val_loss: 4219.4272 - val_acc: 0.9422 - val_mDice: 0.5615

Epoch 00088: val_mDice did not improve from 0.58741
Epoch 89/300
 - 11s - loss: 1387.8993 - acc: 0.9588 - mDice: 0.8309 - val_loss: 4067.1132 - val_acc: 0.9417 - val_mDice: 0.5681

Epoch 00089: val_mDice did not improve from 0.58741
Epoch 90/300
 - 11s - loss: 1383.0103 - acc: 0.9588 - mDice: 0.8315 - val_loss: 4173.3922 - val_acc: 0.9402 - val_mDice: 0.5624

Epoch 00090: val_mDice did not improve from 0.58741
Epoch 91/300
 - 10s - loss: 1378.9867 - acc: 0.9589 - mDice: 0.8319 - val_loss: 3989.7274 - val_acc: 0.9424 - val_mDice: 0.5726

Epoch 00091: val_mDice did not improve from 0.58741
Epoch 92/300
 - 10s - loss: 1381.0746 - acc: 0.9589 - mDice: 0.8317 - val_loss: 4093.8574 - val_acc: 0.9416 - val_mDice: 0.5652

Epoch 00092: val_mDice did not improve from 0.58741
Epoch 93/300
 - 10s - loss: 1374.5035 - acc: 0.9589 - mDice: 0.8324 - val_loss: 4118.9285 - val_acc: 0.9439 - val_mDice: 0.5672

Epoch 00093: val_mDice did not improve from 0.58741
Epoch 94/300
 - 10s - loss: 1365.7953 - acc: 0.9590 - mDice: 0.8334 - val_loss: 3984.0750 - val_acc: 0.9391 - val_mDice: 0.5719

Epoch 00094: val_mDice did not improve from 0.58741
Restoring model weights from the end of the best epoch
Epoch 00094: early stopping
{'val_loss': [8750.368586613582, 5645.76939039964, 5263.413057767428, 4812.2081298828125, 4698.372962364783, 4557.927415114183, 4266.419940655048, 4506.733708308293, 4416.296865609976, 4209.405508188101, 4331.460824819712, 4573.787682166467, 4698.544630784255, 4770.29331618089, 4178.541954627404, 3978.1695885291465, 4136.895761343149, 4136.151836688702, 4018.9258845402646, 4122.603797325721, 4256.721074030949, 4154.567232572115, 4169.165902944712, 4458.22305063101, 4028.3006122295674, 4415.273916391226, 4532.665865384615, 4190.565720778245, 4083.8540790264424, 4100.912259615385, 4248.77260178786, 4491.376333383413, 4261.22993351863, 3933.9644681490386, 4018.340040940505, 4138.25239445613, 3967.5262169471152, 4200.555682842548, 3973.2718271108774, 4277.78648024339, 4689.709557166467, 4410.534137432392, 4452.0187753530645, 4106.093834510217, 3994.4006629356973, 4072.465839092548, 3968.0554715670073, 4355.762399526743, 3885.04633976863, 4259.3880615234375, 3905.945321890024, 3871.7207923302285, 4530.643080491286, 4111.344266451322, 4243.724393404447, 4969.1213144155645, 4311.806598369892, 3985.270681527945, 4133.510728102464, 4276.760638897235, 4232.597675030048, 4115.248506986178, 4103.987713153546, 3807.8676100510816, 4012.758310171274, 3937.916508601262, 4522.543654221755, 4098.505361703726, 4037.4523174579326, 3906.0118032602163, 4046.4230111929087, 4302.968360314002, 4207.112196702224, 4187.256671612079, 3907.4596228966348, 3853.5878014197715, 4159.936875563401, 4012.1974252554087, 4079.01897254357, 4351.039973332332, 3803.6234318659854, 3966.13137113131, 4098.109548715444, 4212.8064528245195, 3838.0804537259614, 4086.918644831731, 3982.3164344200723, 4219.427232008714, 4067.1131920447715, 4173.3922119140625, 3989.7274451622598, 4093.8573937049277, 4118.928480881911, 3984.074955866887], 'val_acc': [0.9048076753432934, 0.9071144713805273, 0.9111016186384054, 0.9191406208735245, 0.9382142080710485, 0.9385540118584266, 0.9359582983530484, 0.9351909344012921, 0.9378651701487027, 0.9360415316545047, 0.9388613861340743, 0.9348465502262115, 0.9345067258064563, 0.9399731984505286, 0.9380246951029851, 0.9429895373491141, 0.9383760002943186, 0.939007009451206, 0.9393144295765803, 0.9406920029566839, 0.932417271228937, 0.9423053631415734, 0.9361871503866636, 0.9407868201916034, 0.9387388871266291, 0.9400147726902595, 0.9379877127133883, 0.9398298813746526, 0.9418038083956792, 0.9388706752887139, 0.9397628467816573, 0.9417992096680862, 0.9386764764785767, 0.941147350347959, 0.9410294775779431, 0.9392011853364798, 0.9429617982644302, 0.9421643981566796, 0.9427491632791666, 0.9397512880655435, 0.9370723756460043, 0.9406804488255427, 0.9339935917120713, 0.9414478288247035, 0.9444064314548786, 0.9446190962424645, 0.9456314925964062, 0.9423885666407071, 0.9426520833602319, 0.9378605760060824, 0.9419725628999563, 0.9418385005914248, 0.9348234282090113, 0.9397582228367145, 0.9425018567305344, 0.9343472879666549, 0.939966238462008, 0.9424995619517106, 0.9387596960251148, 0.9391849912129916, 0.9429872540327219, 0.9433755416136521, 0.9454396504622239, 0.9450490199602567, 0.9421204672409937, 0.9424417592011965, 0.9360299545985001, 0.937144045646374, 0.9408330344236814, 0.9450536072254181, 0.9441036261045016, 0.9400864541530609, 0.9419679229076092, 0.9385979015093583, 0.9409555357236129, 0.9427953935586489, 0.9414085333163922, 0.9421574519230769, 0.9416096393878644, 0.9408838588457841, 0.9439395574422983, 0.9426312882166642, 0.9409023706729596, 0.9417529656336858, 0.9426798384923202, 0.9426474915100977, 0.9441429445376763, 0.9421505331993103, 0.9416882349894597, 0.9402135793979352, 0.9424348473548889, 0.9416443361685827, 0.9438909934117243, 0.9391133257975945], 'val_mDice': [0.31379468022630763, 0.45875203150969285, 0.4925766678956839, 0.5171849346504762, 0.5285667762733423, 0.5349829896138265, 0.5526078119874, 0.5389962213543745, 0.5435422550027187, 0.5567491558881906, 0.5514140037389902, 0.534966033238631, 0.5313614389071097, 0.530373310813537, 0.5607426596375612, 0.5760678121676812, 0.563742789798058, 0.5623249858617783, 0.5733440197431124, 0.5645800860455403, 0.5541011370145358, 0.5659393352957872, 0.5609548409970907, 0.5403636519152385, 0.570470905647828, 0.5475037106527731, 0.5361859680941472, 0.5623595674450581, 0.5667362966789649, 0.5674060273628968, 0.558240338586844, 0.5421568155288696, 0.555784978545629, 0.5794084504819833, 0.5730999794143897, 0.5642310564334576, 0.576794198499276, 0.5636878987917533, 0.5760782802334199, 0.5546320181053418, 0.53505026233884, 0.5459601220030051, 0.5421425230227984, 0.5678495913743973, 0.5746698379516602, 0.569451532398279, 0.5795595393731043, 0.5502762301610067, 0.5821497804270341, 0.5574343897975408, 0.5820717525023681, 0.5813863008068159, 0.5386895164847374, 0.5658030039989032, 0.5585300406584373, 0.515262939609014, 0.5543880760669708, 0.5737225178342599, 0.564006123978358, 0.5554504428918545, 0.5650127220612305, 0.5665865953151996, 0.5692073507950857, 0.5874082213984086, 0.5741617467540961, 0.5769077158318117, 0.5416788900127778, 0.5668064992015178, 0.5688956654988803, 0.5805210858010329, 0.5721558363964925, 0.554369986630403, 0.5604072992618268, 0.5608992593792769, 0.5803219343607242, 0.5849002565328891, 0.5612864316656039, 0.5723778284513034, 0.5667127846525266, 0.5489206632169393, 0.5863116412208631, 0.5757130166658988, 0.5674799325374457, 0.5603361313159649, 0.5838208702894357, 0.5672124314766663, 0.5746999377241502, 0.5615322624261563, 0.5681454436137126, 0.5623839463178928, 0.5726171167424092, 0.5651860764393439, 0.5671964413844622, 0.5719361374011407], 'loss': [19431.661599748615, 6572.159692150898, 4579.008042140343, 3744.1086839061813, 3318.33444033458, 3026.8837578103385, 2846.6804685676207, 2723.576342264577, 2578.286298879011, 2519.0330424623207, 2425.99930171233, 2347.667380205151, 2280.715805710896, 2255.3977334595006, 2190.46242975131, 2159.834424038649, 2100.6928983774724, 2071.8765951886803, 2039.1512801914344, 1995.6672226947073, 1979.5666918650354, 1963.2373157540976, 1931.4281377203954, 1913.2194826976956, 1886.2758706372613, 1860.622776537048, 1834.4184729556673, 1815.8115170598526, 1800.1040733004588, 1796.2582645192858, 1773.7259695532796, 1755.4558830032552, 1739.2634622400938, 1728.6366907851695, 1712.0266545024908, 1692.7818155560471, 1692.8660182740034, 1681.7755305673609, 1665.9017258612178, 1654.0760489659679, 1639.0198798928545, 1626.7141775813566, 1609.1118943340102, 1613.3621954738044, 1602.9386771797617, 1590.6418682697524, 1593.2308173140486, 1571.2267851997958, 1567.334444989756, 1557.2471133348831, 1551.1836992035292, 1542.8216238749221, 1541.6182094715755, 1526.5070344889218, 1527.566583135433, 1522.5588199735446, 1515.3073383497706, 1507.6303862582536, 1500.0990582348004, 1487.8844863876122, 1492.3532730661216, 1486.3831431188235, 1482.0513406760751, 1482.0995994060559, 1471.8261606001297, 1478.1033605406517, 1460.2281562983192, 1458.9371984324023, 1443.4725622852427, 1452.819191328705, 1448.9712003394598, 1432.9586234327987, 1433.3791595039625, 1435.4420704991574, 1431.7200207786345, 1426.1697628334705, 1426.256687275831, 1419.6455475362939, 1410.9197116603075, 1410.636922592674, 1405.5013244623278, 1404.6548842602767, 1404.6258445570172, 1406.4511036291055, 1401.2531916889154, 1392.4461109049148, 1395.5250298460394, 1391.3653528427578, 1387.8993004638198, 1383.010252538405, 1378.9866821885735, 1381.074581938169, 1374.5035023923665, 1365.7953004246872], 'acc': [0.7650170011965868, 0.8825982639152582, 0.8900777872644601, 0.9002494321453893, 0.9167345656929097, 0.9327511237653366, 0.940523997654194, 0.9428138256479781, 0.9445434933844213, 0.9452665305540019, 0.9464550200922951, 0.9473658559628654, 0.948040831532083, 0.9484631595472607, 0.9490608085260547, 0.9494161431303239, 0.9502125166993536, 0.9505772263287157, 0.9509717378187122, 0.9512916206434008, 0.9514215130389512, 0.951905540942618, 0.952109834342648, 0.9524345299551806, 0.9526909175179029, 0.952989562822314, 0.9533732541425635, 0.9534758142161543, 0.9536277383255318, 0.9537915945174036, 0.9539605473654083, 0.9542034379254954, 0.9543488274352374, 0.954550947687189, 0.954652834843415, 0.9549517943544009, 0.9548845756244123, 0.9549980185122703, 0.9551186404918202, 0.9553629947711343, 0.9555434552624713, 0.955601227500062, 0.9558541845936711, 0.9558077361831517, 0.956038035986268, 0.9560840823196742, 0.9560910871105199, 0.9562706169767221, 0.9564445401473777, 0.9565178505457229, 0.9565944273698531, 0.9567336092397184, 0.9567511663944378, 0.9569232001423803, 0.9568589119896682, 0.9570170657161768, 0.9569980236290676, 0.9571696398311641, 0.9572804416775055, 0.9573764340041759, 0.9573965883998208, 0.957416650384354, 0.9575398021833622, 0.9576478603085633, 0.9577035504294247, 0.9576060668322517, 0.957791892230857, 0.9578703076463668, 0.9580016845070567, 0.9579511799298231, 0.9579586082857978, 0.9582045557401524, 0.958172855100805, 0.958213604745484, 0.9581047741291345, 0.9582413345050363, 0.9582898674070159, 0.9584086274876428, 0.9584743598505083, 0.9585014295943007, 0.958573814210423, 0.9585394292237035, 0.9585510880582327, 0.9585486290739172, 0.9586612267829743, 0.9586147817971247, 0.9586635784041692, 0.958839248398249, 0.9588106985484873, 0.9587928496591831, 0.95885252706857, 0.9588513544902452, 0.9589080168380076, 0.9590300423439541], 'mDice': [0.14616118651905546, 0.42591432780563354, 0.5478591807464892, 0.6109425999257856, 0.6455867092052883, 0.6700759898480548, 0.6854832422070362, 0.6962635029860773, 0.7095741888237298, 0.7152155608441748, 0.7239493440297612, 0.731498458030797, 0.737837492512632, 0.740415276663556, 0.7467338122158794, 0.7498194219539892, 0.755687178346621, 0.7585452605435014, 0.7618725993564447, 0.7662062909092332, 0.7678770505006624, 0.7695542888965464, 0.7728419882020068, 0.7747083465342569, 0.7775095392667554, 0.780136381173655, 0.7828756654481326, 0.7848247509540078, 0.7864575720268742, 0.7868674293519122, 0.7892238105298803, 0.7911500744655608, 0.792864307754321, 0.7940418068348762, 0.7956796715392142, 0.7978533242644391, 0.7978198460785871, 0.7990256782047733, 0.8006965469843478, 0.8019164623748462, 0.803470317023185, 0.8048427034477614, 0.8066987679429702, 0.8062997933277551, 0.8073922637082175, 0.8087381358396454, 0.8084415766978016, 0.8107907232307677, 0.8112954908957354, 0.8123071813323912, 0.8129912796005556, 0.8138753831644928, 0.8140295758124682, 0.8156839058725286, 0.8155579874186369, 0.8161156463862719, 0.8168773489949185, 0.8177075961369886, 0.8185007922996578, 0.8198714804508628, 0.8194321345482587, 0.82010979805443, 0.8205413230008815, 0.8205356299959623, 0.8216463980128995, 0.8209647365648962, 0.8229289154147548, 0.823065794477337, 0.8247409013983708, 0.8237216671289558, 0.8241443650139595, 0.8259290977673459, 0.8258612264866079, 0.8255930162714074, 0.826020360619646, 0.826697578325072, 0.8266558697838675, 0.8274003973330869, 0.8283530101228176, 0.8283999806717842, 0.8289569726423903, 0.829092566184009, 0.8290739644555536, 0.8288672734294157, 0.8293845628962068, 0.8304164121481454, 0.8300490951962459, 0.8305790575461162, 0.8308752827414351, 0.8314764373341819, 0.8319268934040461, 0.8316833929009382, 0.8323713471438077, 0.8333711989205405]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.89s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.56s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.27s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:38,  1.61s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:01,  1.70s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:54,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:28,  1.81s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:18,  1.78s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:53,  1.91s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:26,  2.04s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:45,  2.11s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:36,  2.09s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<09:49,  2.14s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<09:49,  2.15s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:53,  2.17s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<10:06,  2.23s/it]predicting train subjects:   5%|▍         | 14/285 [00:29<10:15,  2.27s/it]predicting train subjects:   5%|▌         | 15/285 [00:31<10:15,  2.28s/it]predicting train subjects:   6%|▌         | 16/285 [00:33<10:12,  2.28s/it]predicting train subjects:   6%|▌         | 17/285 [00:36<10:17,  2.30s/it]predicting train subjects:   6%|▋         | 18/285 [00:38<10:28,  2.36s/it]predicting train subjects:   7%|▋         | 19/285 [00:40<10:21,  2.34s/it]predicting train subjects:   7%|▋         | 20/285 [00:43<10:10,  2.30s/it]predicting train subjects:   7%|▋         | 21/285 [00:45<10:05,  2.29s/it]predicting train subjects:   8%|▊         | 22/285 [00:47<10:03,  2.30s/it]predicting train subjects:   8%|▊         | 23/285 [00:49<09:54,  2.27s/it]predicting train subjects:   8%|▊         | 24/285 [00:52<09:49,  2.26s/it]predicting train subjects:   9%|▉         | 25/285 [00:54<09:45,  2.25s/it]predicting train subjects:   9%|▉         | 26/285 [00:56<09:48,  2.27s/it]predicting train subjects:   9%|▉         | 27/285 [00:59<09:45,  2.27s/it]predicting train subjects:  10%|▉         | 28/285 [01:01<09:38,  2.25s/it]predicting train subjects:  10%|█         | 29/285 [01:03<09:31,  2.23s/it]predicting train subjects:  11%|█         | 30/285 [01:05<09:27,  2.23s/it]predicting train subjects:  11%|█         | 31/285 [01:07<09:30,  2.25s/it]predicting train subjects:  11%|█         | 32/285 [01:09<09:12,  2.18s/it]predicting train subjects:  12%|█▏        | 33/285 [01:12<09:02,  2.15s/it]predicting train subjects:  12%|█▏        | 34/285 [01:14<09:08,  2.19s/it]predicting train subjects:  12%|█▏        | 35/285 [01:16<09:08,  2.19s/it]predicting train subjects:  13%|█▎        | 36/285 [01:18<08:57,  2.16s/it]predicting train subjects:  13%|█▎        | 37/285 [01:20<08:55,  2.16s/it]predicting train subjects:  13%|█▎        | 38/285 [01:22<08:54,  2.16s/it]predicting train subjects:  14%|█▎        | 39/285 [01:24<08:44,  2.13s/it]predicting train subjects:  14%|█▍        | 40/285 [01:27<08:36,  2.11s/it]predicting train subjects:  14%|█▍        | 41/285 [01:29<08:27,  2.08s/it]predicting train subjects:  15%|█▍        | 42/285 [01:31<08:27,  2.09s/it]predicting train subjects:  15%|█▌        | 43/285 [01:33<08:34,  2.12s/it]predicting train subjects:  15%|█▌        | 44/285 [01:35<08:33,  2.13s/it]predicting train subjects:  16%|█▌        | 45/285 [01:37<08:24,  2.10s/it]predicting train subjects:  16%|█▌        | 46/285 [01:39<08:14,  2.07s/it]predicting train subjects:  16%|█▋        | 47/285 [01:41<07:47,  1.97s/it]predicting train subjects:  17%|█▋        | 48/285 [01:43<07:45,  1.96s/it]predicting train subjects:  17%|█▋        | 49/285 [01:45<07:44,  1.97s/it]predicting train subjects:  18%|█▊        | 50/285 [01:47<07:33,  1.93s/it]predicting train subjects:  18%|█▊        | 51/285 [01:48<07:24,  1.90s/it]predicting train subjects:  18%|█▊        | 52/285 [01:50<07:25,  1.91s/it]predicting train subjects:  19%|█▊        | 53/285 [01:52<07:29,  1.94s/it]predicting train subjects:  19%|█▉        | 54/285 [01:54<07:26,  1.93s/it]predicting train subjects:  19%|█▉        | 55/285 [01:56<07:22,  1.92s/it]predicting train subjects:  20%|█▉        | 56/285 [01:58<07:13,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [02:00<07:05,  1.87s/it]predicting train subjects:  20%|██        | 58/285 [02:02<07:05,  1.87s/it]predicting train subjects:  21%|██        | 59/285 [02:03<06:57,  1.85s/it]predicting train subjects:  21%|██        | 60/285 [02:05<06:43,  1.79s/it]predicting train subjects:  21%|██▏       | 61/285 [02:07<06:47,  1.82s/it]predicting train subjects:  22%|██▏       | 62/285 [02:09<06:55,  1.86s/it]predicting train subjects:  22%|██▏       | 63/285 [02:11<06:57,  1.88s/it]predicting train subjects:  22%|██▏       | 64/285 [02:13<06:55,  1.88s/it]predicting train subjects:  23%|██▎       | 65/285 [02:15<07:15,  1.98s/it]predicting train subjects:  23%|██▎       | 66/285 [02:17<07:21,  2.02s/it]predicting train subjects:  24%|██▎       | 67/285 [02:19<07:07,  1.96s/it]predicting train subjects:  24%|██▍       | 68/285 [02:21<07:05,  1.96s/it]predicting train subjects:  24%|██▍       | 69/285 [02:23<07:02,  1.96s/it]predicting train subjects:  25%|██▍       | 70/285 [02:25<07:03,  1.97s/it]predicting train subjects:  25%|██▍       | 71/285 [02:27<06:50,  1.92s/it]predicting train subjects:  25%|██▌       | 72/285 [02:28<06:36,  1.86s/it]predicting train subjects:  26%|██▌       | 73/285 [02:30<06:46,  1.92s/it]predicting train subjects:  26%|██▌       | 74/285 [02:32<06:32,  1.86s/it]predicting train subjects:  26%|██▋       | 75/285 [02:34<06:32,  1.87s/it]predicting train subjects:  27%|██▋       | 76/285 [02:36<06:29,  1.86s/it]predicting train subjects:  27%|██▋       | 77/285 [02:38<06:26,  1.86s/it]predicting train subjects:  27%|██▋       | 78/285 [02:39<06:21,  1.84s/it]predicting train subjects:  28%|██▊       | 79/285 [02:41<06:18,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:43<06:24,  1.88s/it]predicting train subjects:  28%|██▊       | 81/285 [02:45<06:27,  1.90s/it]predicting train subjects:  29%|██▉       | 82/285 [02:47<06:20,  1.87s/it]predicting train subjects:  29%|██▉       | 83/285 [02:49<06:18,  1.87s/it]predicting train subjects:  29%|██▉       | 84/285 [02:51<06:13,  1.86s/it]predicting train subjects:  30%|██▉       | 85/285 [02:53<06:18,  1.89s/it]predicting train subjects:  30%|███       | 86/285 [02:55<06:30,  1.96s/it]predicting train subjects:  31%|███       | 87/285 [02:57<06:40,  2.02s/it]predicting train subjects:  31%|███       | 88/285 [02:59<06:41,  2.04s/it]predicting train subjects:  31%|███       | 89/285 [03:01<06:39,  2.04s/it]predicting train subjects:  32%|███▏      | 90/285 [03:03<06:34,  2.02s/it]predicting train subjects:  32%|███▏      | 91/285 [03:05<06:35,  2.04s/it]predicting train subjects:  32%|███▏      | 92/285 [03:07<06:32,  2.03s/it]predicting train subjects:  33%|███▎      | 93/285 [03:09<06:26,  2.01s/it]predicting train subjects:  33%|███▎      | 94/285 [03:11<06:37,  2.08s/it]predicting train subjects:  33%|███▎      | 95/285 [03:14<06:38,  2.10s/it]predicting train subjects:  34%|███▎      | 96/285 [03:16<06:36,  2.10s/it]predicting train subjects:  34%|███▍      | 97/285 [03:18<06:33,  2.09s/it]predicting train subjects:  34%|███▍      | 98/285 [03:20<06:33,  2.10s/it]predicting train subjects:  35%|███▍      | 99/285 [03:22<06:32,  2.11s/it]predicting train subjects:  35%|███▌      | 100/285 [03:24<06:29,  2.10s/it]predicting train subjects:  35%|███▌      | 101/285 [03:26<06:28,  2.11s/it]predicting train subjects:  36%|███▌      | 102/285 [03:28<06:26,  2.11s/it]predicting train subjects:  36%|███▌      | 103/285 [03:31<06:32,  2.16s/it]predicting train subjects:  36%|███▋      | 104/285 [03:33<06:23,  2.12s/it]predicting train subjects:  37%|███▋      | 105/285 [03:35<06:16,  2.09s/it]predicting train subjects:  37%|███▋      | 106/285 [03:37<06:14,  2.09s/it]predicting train subjects:  38%|███▊      | 107/285 [03:39<06:14,  2.10s/it]predicting train subjects:  38%|███▊      | 108/285 [03:41<06:09,  2.09s/it]predicting train subjects:  38%|███▊      | 109/285 [03:43<06:12,  2.11s/it]predicting train subjects:  39%|███▊      | 110/285 [03:45<06:14,  2.14s/it]predicting train subjects:  39%|███▉      | 111/285 [03:47<06:15,  2.16s/it]predicting train subjects:  39%|███▉      | 112/285 [03:49<06:02,  2.10s/it]predicting train subjects:  40%|███▉      | 113/285 [03:52<06:05,  2.12s/it]predicting train subjects:  40%|████      | 114/285 [03:54<06:06,  2.14s/it]predicting train subjects:  40%|████      | 115/285 [03:56<06:01,  2.13s/it]predicting train subjects:  41%|████      | 116/285 [03:58<05:52,  2.09s/it]predicting train subjects:  41%|████      | 117/285 [04:00<05:41,  2.03s/it]predicting train subjects:  41%|████▏     | 118/285 [04:02<05:38,  2.03s/it]predicting train subjects:  42%|████▏     | 119/285 [04:04<05:38,  2.04s/it]predicting train subjects:  42%|████▏     | 120/285 [04:06<05:33,  2.02s/it]predicting train subjects:  42%|████▏     | 121/285 [04:08<05:23,  1.97s/it]predicting train subjects:  43%|████▎     | 122/285 [04:10<05:17,  1.95s/it]predicting train subjects:  43%|████▎     | 123/285 [04:11<05:07,  1.90s/it]predicting train subjects:  44%|████▎     | 124/285 [04:13<05:14,  1.95s/it]predicting train subjects:  44%|████▍     | 125/285 [04:15<05:09,  1.94s/it]predicting train subjects:  44%|████▍     | 126/285 [04:17<05:10,  1.95s/it]predicting train subjects:  45%|████▍     | 127/285 [04:19<05:06,  1.94s/it]predicting train subjects:  45%|████▍     | 128/285 [04:21<05:01,  1.92s/it]predicting train subjects:  45%|████▌     | 129/285 [04:23<04:59,  1.92s/it]predicting train subjects:  46%|████▌     | 130/285 [04:25<05:05,  1.97s/it]predicting train subjects:  46%|████▌     | 131/285 [04:27<04:56,  1.93s/it]predicting train subjects:  46%|████▋     | 132/285 [04:29<04:52,  1.91s/it]predicting train subjects:  47%|████▋     | 133/285 [04:31<04:49,  1.91s/it]predicting train subjects:  47%|████▋     | 134/285 [04:33<04:47,  1.90s/it]predicting train subjects:  47%|████▋     | 135/285 [04:34<04:42,  1.88s/it]predicting train subjects:  48%|████▊     | 136/285 [04:36<04:44,  1.91s/it]predicting train subjects:  48%|████▊     | 137/285 [04:38<04:39,  1.89s/it]predicting train subjects:  48%|████▊     | 138/285 [04:40<04:37,  1.89s/it]predicting train subjects:  49%|████▉     | 139/285 [04:42<04:33,  1.87s/it]predicting train subjects:  49%|████▉     | 140/285 [04:44<04:29,  1.86s/it]predicting train subjects:  49%|████▉     | 141/285 [04:46<04:27,  1.86s/it]predicting train subjects:  50%|████▉     | 142/285 [04:48<04:25,  1.86s/it]predicting train subjects:  50%|█████     | 143/285 [04:49<04:22,  1.85s/it]predicting train subjects:  51%|█████     | 144/285 [04:51<04:19,  1.84s/it]predicting train subjects:  51%|█████     | 145/285 [04:53<04:14,  1.81s/it]predicting train subjects:  51%|█████     | 146/285 [04:55<04:06,  1.77s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:56<04:07,  1.80s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:58<04:01,  1.76s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:00<03:57,  1.75s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:02<03:53,  1.73s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:03<03:54,  1.75s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:05<03:56,  1.78s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:07<04:00,  1.82s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:09<04:00,  1.84s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:11<03:57,  1.82s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:12<03:49,  1.78s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:14<03:50,  1.80s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:16<03:47,  1.79s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:18<03:43,  1.77s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:19<03:38,  1.75s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:21<03:36,  1.74s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:23<03:28,  1.69s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:25<03:28,  1.71s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:26<03:23,  1.68s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:28<03:20,  1.67s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:30<03:22,  1.70s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:31<03:22,  1.72s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:33<03:25,  1.75s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:35<03:18,  1.71s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:36<03:15,  1.70s/it]predicting train subjects:  60%|██████    | 171/285 [05:38<03:14,  1.71s/it]predicting train subjects:  60%|██████    | 172/285 [05:40<03:15,  1.73s/it]predicting train subjects:  61%|██████    | 173/285 [05:42<03:11,  1.71s/it]predicting train subjects:  61%|██████    | 174/285 [05:43<03:12,  1.74s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:45<03:13,  1.75s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:47<03:06,  1.71s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:49<03:04,  1.71s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:50<02:59,  1.68s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:52<02:51,  1.62s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:53<02:50,  1.62s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:55<02:48,  1.62s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:56<02:45,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:58<02:41,  1.59s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:00<02:47,  1.66s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:01<02:45,  1.66s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:03<02:43,  1.65s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:05<02:40,  1.64s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:06<02:40,  1.66s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:08<02:38,  1.65s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:10<02:35,  1.64s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:11<02:33,  1.63s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:13<02:32,  1.64s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:15<02:30,  1.64s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:16<02:28,  1.63s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:18<02:27,  1.64s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:20<02:36,  1.76s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:22<02:42,  1.85s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:24<02:45,  1.90s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:26<02:48,  1.96s/it]predicting train subjects:  70%|███████   | 200/285 [06:28<02:49,  2.00s/it]predicting train subjects:  71%|███████   | 201/285 [06:30<02:47,  2.00s/it]predicting train subjects:  71%|███████   | 202/285 [06:32<02:46,  2.01s/it]predicting train subjects:  71%|███████   | 203/285 [06:34<02:40,  1.95s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:36<02:39,  1.97s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:38<02:38,  1.98s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:40<02:35,  1.97s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:42<02:36,  2.00s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:44<02:36,  2.04s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:46<02:33,  2.03s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:48<02:32,  2.04s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:50<02:32,  2.06s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:52<02:28,  2.04s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:54<02:25,  2.02s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:56<02:17,  1.94s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:58<02:14,  1.92s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:00<02:07,  1.85s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:01<02:06,  1.86s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:03<02:01,  1.81s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:05<01:59,  1.80s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:07<01:56,  1.79s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:08<01:52,  1.76s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:10<01:51,  1.77s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:12<01:50,  1.78s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:14<01:45,  1.73s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:15<01:44,  1.73s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:17<01:42,  1.74s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:19<01:39,  1.72s/it]predicting train subjects:  80%|████████  | 228/285 [07:21<01:37,  1.71s/it]predicting train subjects:  80%|████████  | 229/285 [07:22<01:36,  1.72s/it]predicting train subjects:  81%|████████  | 230/285 [07:24<01:33,  1.69s/it]predicting train subjects:  81%|████████  | 231/285 [07:26<01:30,  1.68s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:28<01:36,  1.82s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:30<01:39,  1.92s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:32<01:39,  1.95s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:34<01:41,  2.03s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:36<01:40,  2.04s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:38<01:38,  2.06s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:40<01:38,  2.10s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:43<01:36,  2.11s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:45<01:33,  2.08s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:47<01:32,  2.09s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:49<01:31,  2.13s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:51<01:29,  2.12s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:53<01:26,  2.12s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:55<01:26,  2.15s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:57<01:23,  2.13s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:00<01:23,  2.20s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:02<01:18,  2.11s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:04<01:19,  2.20s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:06<01:12,  2.08s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:07<01:05,  1.92s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:09<01:00,  1.84s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:11<00:57,  1.80s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:13<00:55,  1.80s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:14<00:51,  1.73s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:16<00:51,  1.78s/it]predicting train subjects:  90%|█████████ | 257/285 [08:18<00:48,  1.72s/it]predicting train subjects:  91%|█████████ | 258/285 [08:19<00:45,  1.67s/it]predicting train subjects:  91%|█████████ | 259/285 [08:21<00:43,  1.66s/it]predicting train subjects:  91%|█████████ | 260/285 [08:23<00:42,  1.68s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:24<00:39,  1.64s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:26<00:38,  1.66s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:27<00:36,  1.66s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:29<00:34,  1.65s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:31<00:32,  1.60s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:32<00:30,  1.60s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:34<00:29,  1.65s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:36<00:30,  1.80s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:38<00:30,  1.91s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:40<00:29,  1.99s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:43<00:28,  2.02s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:45<00:27,  2.10s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:47<00:25,  2.12s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:49<00:23,  2.12s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:51<00:21,  2.13s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:54<00:19,  2.16s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:56<00:17,  2.17s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:58<00:15,  2.15s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:00<00:12,  2.14s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:02<00:10,  2.14s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:04<00:08,  2.13s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:06<00:06,  2.15s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:09<00:04,  2.18s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:11<00:02,  2.24s/it]predicting train subjects: 100%|██████████| 285/285 [09:13<00:00,  2.27s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:45,  1.43s/it]Loading train:   1%|          | 2/285 [00:03<07:05,  1.50s/it]Loading train:   1%|          | 3/285 [00:04<07:04,  1.51s/it]Loading train:   1%|▏         | 4/285 [00:06<07:21,  1.57s/it]Loading train:   2%|▏         | 5/285 [00:07<07:06,  1.52s/it]Loading train:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]Loading train:   2%|▏         | 7/285 [00:11<07:24,  1.60s/it]Loading train:   3%|▎         | 8/285 [00:12<07:43,  1.67s/it]Loading train:   3%|▎         | 9/285 [00:14<07:18,  1.59s/it]Loading train:   4%|▎         | 10/285 [00:15<06:41,  1.46s/it]Loading train:   4%|▍         | 11/285 [00:16<06:32,  1.43s/it]Loading train:   4%|▍         | 12/285 [00:18<06:09,  1.35s/it]Loading train:   5%|▍         | 13/285 [00:19<05:48,  1.28s/it]Loading train:   5%|▍         | 14/285 [00:20<05:31,  1.22s/it]Loading train:   5%|▌         | 15/285 [00:21<05:25,  1.21s/it]Loading train:   6%|▌         | 16/285 [00:22<05:21,  1.19s/it]Loading train:   6%|▌         | 17/285 [00:23<05:10,  1.16s/it]Loading train:   6%|▋         | 18/285 [00:24<05:10,  1.16s/it]Loading train:   7%|▋         | 19/285 [00:26<05:20,  1.21s/it]Loading train:   7%|▋         | 20/285 [00:27<05:23,  1.22s/it]Loading train:   7%|▋         | 21/285 [00:28<05:35,  1.27s/it]Loading train:   8%|▊         | 22/285 [00:29<05:23,  1.23s/it]Loading train:   8%|▊         | 23/285 [00:30<05:07,  1.18s/it]Loading train:   8%|▊         | 24/285 [00:31<04:50,  1.11s/it]Loading train:   9%|▉         | 25/285 [00:33<05:01,  1.16s/it]Loading train:   9%|▉         | 26/285 [00:34<04:52,  1.13s/it]Loading train:   9%|▉         | 27/285 [00:35<04:51,  1.13s/it]Loading train:  10%|▉         | 28/285 [00:36<04:57,  1.16s/it]Loading train:  10%|█         | 29/285 [00:37<04:50,  1.13s/it]Loading train:  11%|█         | 30/285 [00:38<04:36,  1.08s/it]Loading train:  11%|█         | 31/285 [00:39<04:47,  1.13s/it]Loading train:  11%|█         | 32/285 [00:40<04:37,  1.10s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:38,  1.11s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:32,  1.09s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:34,  1.10s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:33,  1.10s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:38,  1.12s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:32,  1.10s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:46,  1.17s/it]Loading train:  14%|█▍        | 40/285 [00:50<04:47,  1.17s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:39,  1.14s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:28,  1.11s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:43,  1.17s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:33,  1.14s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:37,  1.16s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:31,  1.14s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:27,  1.12s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:11,  1.06s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:05,  1.04s/it]Loading train:  18%|█▊        | 50/285 [01:00<03:51,  1.01it/s]Loading train:  18%|█▊        | 51/285 [01:01<04:09,  1.06s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:05,  1.06s/it]Loading train:  19%|█▊        | 53/285 [01:03<03:58,  1.03s/it]Loading train:  19%|█▉        | 54/285 [01:04<03:59,  1.04s/it]Loading train:  19%|█▉        | 55/285 [01:05<03:52,  1.01s/it]Loading train:  20%|█▉        | 56/285 [01:06<03:56,  1.03s/it]Loading train:  20%|██        | 57/285 [01:08<03:55,  1.03s/it]Loading train:  20%|██        | 58/285 [01:08<03:45,  1.00it/s]Loading train:  21%|██        | 59/285 [01:09<03:33,  1.06it/s]Loading train:  21%|██        | 60/285 [01:10<03:41,  1.01it/s]Loading train:  21%|██▏       | 61/285 [01:11<03:38,  1.02it/s]Loading train:  22%|██▏       | 62/285 [01:12<03:47,  1.02s/it]Loading train:  22%|██▏       | 63/285 [01:13<03:45,  1.02s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:41,  1.27s/it]Loading train:  23%|██▎       | 65/285 [01:17<05:08,  1.40s/it]Loading train:  23%|██▎       | 66/285 [01:19<05:21,  1.47s/it]Loading train:  24%|██▎       | 67/285 [01:20<05:07,  1.41s/it]Loading train:  24%|██▍       | 68/285 [01:21<04:36,  1.27s/it]Loading train:  24%|██▍       | 69/285 [01:22<04:14,  1.18s/it]Loading train:  25%|██▍       | 70/285 [01:23<04:00,  1.12s/it]Loading train:  25%|██▍       | 71/285 [01:24<03:54,  1.10s/it]Loading train:  25%|██▌       | 72/285 [01:25<03:57,  1.11s/it]Loading train:  26%|██▌       | 73/285 [01:26<03:43,  1.05s/it]Loading train:  26%|██▌       | 74/285 [01:27<03:48,  1.08s/it]Loading train:  26%|██▋       | 75/285 [01:28<03:52,  1.11s/it]Loading train:  27%|██▋       | 76/285 [01:29<03:35,  1.03s/it]Loading train:  27%|██▋       | 77/285 [01:30<03:35,  1.04s/it]Loading train:  27%|██▋       | 78/285 [01:31<03:34,  1.04s/it]Loading train:  28%|██▊       | 79/285 [01:32<03:31,  1.03s/it]Loading train:  28%|██▊       | 80/285 [01:33<03:23,  1.01it/s]Loading train:  28%|██▊       | 81/285 [01:34<03:26,  1.01s/it]Loading train:  29%|██▉       | 82/285 [01:35<03:33,  1.05s/it]Loading train:  29%|██▉       | 83/285 [01:36<03:35,  1.07s/it]Loading train:  29%|██▉       | 84/285 [01:37<03:32,  1.06s/it]Loading train:  30%|██▉       | 85/285 [01:39<03:39,  1.10s/it]Loading train:  30%|███       | 86/285 [01:40<03:56,  1.19s/it]Loading train:  31%|███       | 87/285 [01:41<03:59,  1.21s/it]Loading train:  31%|███       | 88/285 [01:42<03:51,  1.17s/it]Loading train:  31%|███       | 89/285 [01:43<03:40,  1.13s/it]Loading train:  32%|███▏      | 90/285 [01:44<03:38,  1.12s/it]Loading train:  32%|███▏      | 91/285 [01:46<03:35,  1.11s/it]Loading train:  32%|███▏      | 92/285 [01:47<03:30,  1.09s/it]Loading train:  33%|███▎      | 93/285 [01:48<03:39,  1.14s/it]Loading train:  33%|███▎      | 94/285 [01:49<03:44,  1.17s/it]Loading train:  33%|███▎      | 95/285 [01:50<03:37,  1.14s/it]Loading train:  34%|███▎      | 96/285 [01:51<03:31,  1.12s/it]Loading train:  34%|███▍      | 97/285 [01:52<03:24,  1.09s/it]Loading train:  34%|███▍      | 98/285 [01:53<03:27,  1.11s/it]Loading train:  35%|███▍      | 99/285 [01:55<03:27,  1.11s/it]Loading train:  35%|███▌      | 100/285 [01:56<03:22,  1.10s/it]Loading train:  35%|███▌      | 101/285 [01:57<03:26,  1.12s/it]Loading train:  36%|███▌      | 102/285 [01:58<03:21,  1.10s/it]Loading train:  36%|███▌      | 103/285 [01:59<03:23,  1.12s/it]Loading train:  36%|███▋      | 104/285 [02:00<03:23,  1.12s/it]Loading train:  37%|███▋      | 105/285 [02:01<03:13,  1.08s/it]Loading train:  37%|███▋      | 106/285 [02:02<03:11,  1.07s/it]Loading train:  38%|███▊      | 107/285 [02:03<03:03,  1.03s/it]Loading train:  38%|███▊      | 108/285 [02:04<03:00,  1.02s/it]Loading train:  38%|███▊      | 109/285 [02:05<02:59,  1.02s/it]Loading train:  39%|███▊      | 110/285 [02:06<02:50,  1.03it/s]Loading train:  39%|███▉      | 111/285 [02:07<02:54,  1.00s/it]Loading train:  39%|███▉      | 112/285 [02:08<02:59,  1.04s/it]Loading train:  40%|███▉      | 113/285 [02:09<03:08,  1.10s/it]Loading train:  40%|████      | 114/285 [02:11<03:08,  1.11s/it]Loading train:  40%|████      | 115/285 [02:12<03:06,  1.10s/it]Loading train:  41%|████      | 116/285 [02:13<03:08,  1.11s/it]Loading train:  41%|████      | 117/285 [02:14<03:05,  1.11s/it]Loading train:  41%|████▏     | 118/285 [02:15<03:11,  1.15s/it]Loading train:  42%|████▏     | 119/285 [02:16<03:14,  1.17s/it]Loading train:  42%|████▏     | 120/285 [02:17<03:10,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:19<03:24,  1.25s/it]Loading train:  43%|████▎     | 122/285 [02:20<03:26,  1.27s/it]Loading train:  43%|████▎     | 123/285 [02:22<03:32,  1.31s/it]Loading train:  44%|████▎     | 124/285 [02:23<03:16,  1.22s/it]Loading train:  44%|████▍     | 125/285 [02:24<03:15,  1.22s/it]Loading train:  44%|████▍     | 126/285 [02:25<02:58,  1.13s/it]Loading train:  45%|████▍     | 127/285 [02:26<02:48,  1.06s/it]Loading train:  45%|████▍     | 128/285 [02:27<02:38,  1.01s/it]Loading train:  45%|████▌     | 129/285 [02:28<02:38,  1.02s/it]Loading train:  46%|████▌     | 130/285 [02:29<02:43,  1.05s/it]Loading train:  46%|████▌     | 131/285 [02:30<02:47,  1.09s/it]Loading train:  46%|████▋     | 132/285 [02:31<02:42,  1.06s/it]Loading train:  47%|████▋     | 133/285 [02:32<02:40,  1.05s/it]Loading train:  47%|████▋     | 134/285 [02:33<02:37,  1.04s/it]Loading train:  47%|████▋     | 135/285 [02:34<02:34,  1.03s/it]Loading train:  48%|████▊     | 136/285 [02:35<02:37,  1.05s/it]Loading train:  48%|████▊     | 137/285 [02:36<02:31,  1.02s/it]Loading train:  48%|████▊     | 138/285 [02:37<02:32,  1.04s/it]Loading train:  49%|████▉     | 139/285 [02:38<02:28,  1.02s/it]Loading train:  49%|████▉     | 140/285 [02:39<02:30,  1.04s/it]Loading train:  49%|████▉     | 141/285 [02:40<02:25,  1.01s/it]Loading train:  50%|████▉     | 142/285 [02:41<02:16,  1.04it/s]Loading train:  50%|█████     | 143/285 [02:42<02:12,  1.07it/s]Loading train:  51%|█████     | 144/285 [02:43<02:11,  1.07it/s]Loading train:  51%|█████     | 145/285 [02:44<02:07,  1.09it/s]Loading train:  51%|█████     | 146/285 [02:44<02:02,  1.13it/s]Loading train:  52%|█████▏    | 147/285 [02:45<01:58,  1.16it/s]Loading train:  52%|█████▏    | 148/285 [02:46<01:56,  1.18it/s]Loading train:  52%|█████▏    | 149/285 [02:47<02:00,  1.13it/s]Loading train:  53%|█████▎    | 150/285 [02:48<01:56,  1.15it/s]Loading train:  53%|█████▎    | 151/285 [02:49<01:56,  1.15it/s]Loading train:  53%|█████▎    | 152/285 [02:50<01:54,  1.16it/s]Loading train:  54%|█████▎    | 153/285 [02:50<01:56,  1.13it/s]Loading train:  54%|█████▍    | 154/285 [02:51<01:59,  1.10it/s]Loading train:  54%|█████▍    | 155/285 [02:52<02:00,  1.08it/s]Loading train:  55%|█████▍    | 156/285 [02:53<02:01,  1.06it/s]Loading train:  55%|█████▌    | 157/285 [02:54<01:59,  1.07it/s]Loading train:  55%|█████▌    | 158/285 [02:55<01:57,  1.08it/s]Loading train:  56%|█████▌    | 159/285 [02:56<01:54,  1.10it/s]Loading train:  56%|█████▌    | 160/285 [02:57<01:56,  1.07it/s]Loading train:  56%|█████▋    | 161/285 [02:58<02:00,  1.03it/s]Loading train:  57%|█████▋    | 162/285 [02:59<01:58,  1.04it/s]Loading train:  57%|█████▋    | 163/285 [03:00<01:54,  1.06it/s]Loading train:  58%|█████▊    | 164/285 [03:01<01:54,  1.06it/s]Loading train:  58%|█████▊    | 165/285 [03:02<01:48,  1.10it/s]Loading train:  58%|█████▊    | 166/285 [03:03<01:46,  1.12it/s]Loading train:  59%|█████▊    | 167/285 [03:04<01:46,  1.11it/s]Loading train:  59%|█████▉    | 168/285 [03:04<01:47,  1.09it/s]Loading train:  59%|█████▉    | 169/285 [03:05<01:48,  1.07it/s]Loading train:  60%|█████▉    | 170/285 [03:06<01:50,  1.04it/s]Loading train:  60%|██████    | 171/285 [03:08<01:52,  1.01it/s]Loading train:  60%|██████    | 172/285 [03:08<01:44,  1.08it/s]Loading train:  61%|██████    | 173/285 [03:09<01:44,  1.08it/s]Loading train:  61%|██████    | 174/285 [03:10<01:41,  1.09it/s]Loading train:  61%|██████▏   | 175/285 [03:11<01:38,  1.11it/s]Loading train:  62%|██████▏   | 176/285 [03:12<01:33,  1.17it/s]Loading train:  62%|██████▏   | 177/285 [03:13<01:32,  1.17it/s]Loading train:  62%|██████▏   | 178/285 [03:14<01:33,  1.14it/s]Loading train:  63%|██████▎   | 179/285 [03:14<01:28,  1.20it/s]Loading train:  63%|██████▎   | 180/285 [03:15<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [03:16<01:32,  1.13it/s]Loading train:  64%|██████▍   | 182/285 [03:17<01:30,  1.14it/s]Loading train:  64%|██████▍   | 183/285 [03:18<01:29,  1.14it/s]Loading train:  65%|██████▍   | 184/285 [03:19<01:30,  1.11it/s]Loading train:  65%|██████▍   | 185/285 [03:20<01:28,  1.13it/s]Loading train:  65%|██████▌   | 186/285 [03:20<01:25,  1.15it/s]Loading train:  66%|██████▌   | 187/285 [03:21<01:21,  1.20it/s]Loading train:  66%|██████▌   | 188/285 [03:22<01:20,  1.20it/s]Loading train:  66%|██████▋   | 189/285 [03:23<01:23,  1.15it/s]Loading train:  67%|██████▋   | 190/285 [03:24<01:24,  1.13it/s]Loading train:  67%|██████▋   | 191/285 [03:25<01:22,  1.14it/s]Loading train:  67%|██████▋   | 192/285 [03:26<01:20,  1.15it/s]Loading train:  68%|██████▊   | 193/285 [03:27<01:19,  1.15it/s]Loading train:  68%|██████▊   | 194/285 [03:27<01:18,  1.15it/s]Loading train:  68%|██████▊   | 195/285 [03:28<01:17,  1.15it/s]Loading train:  69%|██████▉   | 196/285 [03:29<01:22,  1.08it/s]Loading train:  69%|██████▉   | 197/285 [03:30<01:24,  1.04it/s]Loading train:  69%|██████▉   | 198/285 [03:31<01:23,  1.05it/s]Loading train:  70%|██████▉   | 199/285 [03:33<01:30,  1.05s/it]Loading train:  70%|███████   | 200/285 [03:34<01:28,  1.04s/it]Loading train:  71%|███████   | 201/285 [03:35<01:25,  1.02s/it]Loading train:  71%|███████   | 202/285 [03:36<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [03:37<01:22,  1.01s/it]Loading train:  72%|███████▏  | 204/285 [03:38<01:21,  1.00s/it]Loading train:  72%|███████▏  | 205/285 [03:39<01:21,  1.02s/it]Loading train:  72%|███████▏  | 206/285 [03:40<01:18,  1.01it/s]Loading train:  73%|███████▎  | 207/285 [03:41<01:20,  1.03s/it]Loading train:  73%|███████▎  | 208/285 [03:42<01:17,  1.01s/it]Loading train:  73%|███████▎  | 209/285 [03:43<01:17,  1.02s/it]Loading train:  74%|███████▎  | 210/285 [03:44<01:22,  1.10s/it]Loading train:  74%|███████▍  | 211/285 [03:45<01:18,  1.06s/it]Loading train:  74%|███████▍  | 212/285 [03:46<01:15,  1.03s/it]Loading train:  75%|███████▍  | 213/285 [03:47<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:48<01:13,  1.04s/it]Loading train:  75%|███████▌  | 215/285 [03:49<01:10,  1.01s/it]Loading train:  76%|███████▌  | 216/285 [03:50<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [03:51<01:04,  1.05it/s]Loading train:  76%|███████▋  | 218/285 [03:52<01:06,  1.00it/s]Loading train:  77%|███████▋  | 219/285 [03:53<01:02,  1.06it/s]Loading train:  77%|███████▋  | 220/285 [03:54<01:01,  1.06it/s]Loading train:  78%|███████▊  | 221/285 [03:55<00:59,  1.07it/s]Loading train:  78%|███████▊  | 222/285 [03:55<00:57,  1.10it/s]Loading train:  78%|███████▊  | 223/285 [03:56<00:55,  1.12it/s]Loading train:  79%|███████▊  | 224/285 [03:57<00:54,  1.12it/s]Loading train:  79%|███████▉  | 225/285 [03:58<00:54,  1.10it/s]Loading train:  79%|███████▉  | 226/285 [03:59<00:52,  1.12it/s]Loading train:  80%|███████▉  | 227/285 [04:00<00:52,  1.10it/s]Loading train:  80%|████████  | 228/285 [04:01<00:51,  1.11it/s]Loading train:  80%|████████  | 229/285 [04:02<00:49,  1.12it/s]Loading train:  81%|████████  | 230/285 [04:03<00:53,  1.02it/s]Loading train:  81%|████████  | 231/285 [04:04<00:55,  1.03s/it]Loading train:  81%|████████▏ | 232/285 [04:05<00:56,  1.06s/it]Loading train:  82%|████████▏ | 233/285 [04:06<00:57,  1.11s/it]Loading train:  82%|████████▏ | 234/285 [04:07<00:57,  1.12s/it]Loading train:  82%|████████▏ | 235/285 [04:09<00:58,  1.16s/it]Loading train:  83%|████████▎ | 236/285 [04:10<00:57,  1.18s/it]Loading train:  83%|████████▎ | 237/285 [04:11<00:57,  1.19s/it]Loading train:  84%|████████▎ | 238/285 [04:12<00:53,  1.14s/it]Loading train:  84%|████████▍ | 239/285 [04:13<00:53,  1.17s/it]Loading train:  84%|████████▍ | 240/285 [04:15<00:51,  1.15s/it]Loading train:  85%|████████▍ | 241/285 [04:16<00:51,  1.16s/it]Loading train:  85%|████████▍ | 242/285 [04:17<00:51,  1.19s/it]Loading train:  85%|████████▌ | 243/285 [04:18<00:52,  1.24s/it]Loading train:  86%|████████▌ | 244/285 [04:19<00:48,  1.17s/it]Loading train:  86%|████████▌ | 245/285 [04:21<00:47,  1.18s/it]Loading train:  86%|████████▋ | 246/285 [04:22<00:45,  1.17s/it]Loading train:  87%|████████▋ | 247/285 [04:23<00:43,  1.14s/it]Loading train:  87%|████████▋ | 248/285 [04:24<00:41,  1.12s/it]Loading train:  87%|████████▋ | 249/285 [04:25<00:40,  1.13s/it]Loading train:  88%|████████▊ | 250/285 [04:26<00:38,  1.09s/it]Loading train:  88%|████████▊ | 251/285 [04:27<00:35,  1.03s/it]Loading train:  88%|████████▊ | 252/285 [04:28<00:33,  1.03s/it]Loading train:  89%|████████▉ | 253/285 [04:29<00:31,  1.02it/s]Loading train:  89%|████████▉ | 254/285 [04:30<00:28,  1.08it/s]Loading train:  89%|████████▉ | 255/285 [04:30<00:27,  1.10it/s]Loading train:  90%|████████▉ | 256/285 [04:31<00:26,  1.11it/s]Loading train:  90%|█████████ | 257/285 [04:32<00:25,  1.11it/s]Loading train:  91%|█████████ | 258/285 [04:33<00:24,  1.12it/s]Loading train:  91%|█████████ | 259/285 [04:34<00:23,  1.12it/s]Loading train:  91%|█████████ | 260/285 [04:35<00:21,  1.14it/s]Loading train:  92%|█████████▏| 261/285 [04:36<00:20,  1.18it/s]Loading train:  92%|█████████▏| 262/285 [04:37<00:20,  1.13it/s]Loading train:  92%|█████████▏| 263/285 [04:37<00:19,  1.13it/s]Loading train:  93%|█████████▎| 264/285 [04:38<00:18,  1.12it/s]Loading train:  93%|█████████▎| 265/285 [04:39<00:17,  1.11it/s]Loading train:  93%|█████████▎| 266/285 [04:40<00:16,  1.14it/s]Loading train:  94%|█████████▎| 267/285 [04:41<00:15,  1.13it/s]Loading train:  94%|█████████▍| 268/285 [04:42<00:16,  1.01it/s]Loading train:  94%|█████████▍| 269/285 [04:43<00:16,  1.03s/it]Loading train:  95%|█████████▍| 270/285 [04:44<00:15,  1.05s/it]Loading train:  95%|█████████▌| 271/285 [04:46<00:16,  1.17s/it]Loading train:  95%|█████████▌| 272/285 [04:47<00:14,  1.13s/it]Loading train:  96%|█████████▌| 273/285 [04:48<00:13,  1.14s/it]Loading train:  96%|█████████▌| 274/285 [04:49<00:12,  1.14s/it]Loading train:  96%|█████████▋| 275/285 [04:51<00:11,  1.17s/it]Loading train:  97%|█████████▋| 276/285 [04:52<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [04:53<00:09,  1.17s/it]Loading train:  98%|█████████▊| 278/285 [04:54<00:08,  1.20s/it]Loading train:  98%|█████████▊| 279/285 [04:55<00:07,  1.19s/it]Loading train:  98%|█████████▊| 280/285 [04:56<00:05,  1.18s/it]Loading train:  99%|█████████▊| 281/285 [04:58<00:04,  1.16s/it]Loading train:  99%|█████████▉| 282/285 [04:59<00:03,  1.18s/it]Loading train:  99%|█████████▉| 283/285 [05:00<00:02,  1.21s/it]Loading train: 100%|█████████▉| 284/285 [05:01<00:01,  1.19s/it]Loading train: 100%|██████████| 285/285 [05:02<00:00,  1.18s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 115.70it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:02, 114.57it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:02, 96.02it/s] concatenating: train:  13%|█▎        | 38/285 [00:00<00:03, 78.27it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:03, 72.76it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:03, 69.35it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:03, 70.62it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:03, 63.51it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:02, 70.97it/s]concatenating: train:  30%|███       | 86/285 [00:01<00:02, 71.99it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:02, 81.15it/s]concatenating: train:  38%|███▊      | 109/285 [00:01<00:02, 85.62it/s]concatenating: train:  43%|████▎     | 122/285 [00:01<00:01, 95.36it/s]concatenating: train:  47%|████▋     | 135/285 [00:01<00:01, 101.73it/s]concatenating: train:  51%|█████     | 146/285 [00:01<00:01, 100.66it/s]concatenating: train:  55%|█████▌    | 157/285 [00:01<00:01, 98.17it/s] concatenating: train:  59%|█████▉    | 168/285 [00:01<00:01, 83.18it/s]concatenating: train:  63%|██████▎   | 179/285 [00:02<00:01, 86.82it/s]concatenating: train:  66%|██████▋   | 189/285 [00:02<00:01, 83.11it/s]concatenating: train:  70%|██████▉   | 199/285 [00:02<00:00, 86.62it/s]concatenating: train:  74%|███████▍  | 212/285 [00:02<00:00, 95.41it/s]concatenating: train:  80%|███████▉  | 227/285 [00:02<00:00, 105.23it/s]concatenating: train:  86%|████████▌ | 245/285 [00:02<00:00, 118.38it/s]concatenating: train:  91%|█████████ | 258/285 [00:02<00:00, 108.66it/s]concatenating: train:  96%|█████████▌| 274/285 [00:02<00:00, 119.63it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 97.49it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.49s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.43s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 243.94it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-08 13:51:18.911133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 13:51:18.911256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 13:51:18.911274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 13:51:18.911288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 13:51:18.911768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 28s - loss: 10489.5881 - acc: 0.7997 - mDice: 0.2061 - val_loss: 4891.0054 - val_acc: 0.9051 - val_mDice: 0.3510

Epoch 00001: val_mDice improved from -inf to 0.35098, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 3126.6761 - acc: 0.8750 - mDice: 0.5317 - val_loss: 4346.7254 - val_acc: 0.9067 - val_mDice: 0.4108

Epoch 00002: val_mDice improved from 0.35098 to 0.41084, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 2281.9545 - acc: 0.8821 - mDice: 0.6298 - val_loss: 3529.3734 - val_acc: 0.9101 - val_mDice: 0.4752

Epoch 00003: val_mDice improved from 0.41084 to 0.47522, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 1927.1793 - acc: 0.8954 - mDice: 0.6767 - val_loss: 3324.9530 - val_acc: 0.9181 - val_mDice: 0.4833

Epoch 00004: val_mDice improved from 0.47522 to 0.48334, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 12s - loss: 1739.2259 - acc: 0.9165 - mDice: 0.7030 - val_loss: 2937.7579 - val_acc: 0.9422 - val_mDice: 0.5300

Epoch 00005: val_mDice improved from 0.48334 to 0.53002, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 12s - loss: 1599.4038 - acc: 0.9347 - mDice: 0.7224 - val_loss: 2839.9698 - val_acc: 0.9442 - val_mDice: 0.5362

Epoch 00006: val_mDice improved from 0.53002 to 0.53616, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 13s - loss: 1485.3338 - acc: 0.9442 - mDice: 0.7384 - val_loss: 2886.4353 - val_acc: 0.9459 - val_mDice: 0.5352

Epoch 00007: val_mDice did not improve from 0.53616
Epoch 8/300
 - 12s - loss: 1408.7313 - acc: 0.9469 - mDice: 0.7495 - val_loss: 2908.3022 - val_acc: 0.9462 - val_mDice: 0.5337

Epoch 00008: val_mDice did not improve from 0.53616
Epoch 9/300
 - 12s - loss: 1339.1083 - acc: 0.9486 - mDice: 0.7600 - val_loss: 2852.0110 - val_acc: 0.9398 - val_mDice: 0.5398

Epoch 00009: val_mDice improved from 0.53616 to 0.53975, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 13s - loss: 1270.9978 - acc: 0.9502 - mDice: 0.7706 - val_loss: 2912.4466 - val_acc: 0.9431 - val_mDice: 0.5319

Epoch 00010: val_mDice did not improve from 0.53975
Epoch 11/300
 - 13s - loss: 1236.0280 - acc: 0.9509 - mDice: 0.7761 - val_loss: 2902.1905 - val_acc: 0.9406 - val_mDice: 0.5324

Epoch 00011: val_mDice did not improve from 0.53975
Epoch 12/300
 - 13s - loss: 1197.3511 - acc: 0.9517 - mDice: 0.7821 - val_loss: 3238.3762 - val_acc: 0.9431 - val_mDice: 0.5051

Epoch 00012: val_mDice did not improve from 0.53975
Epoch 13/300
 - 13s - loss: 1150.7506 - acc: 0.9526 - mDice: 0.7896 - val_loss: 3004.3305 - val_acc: 0.9434 - val_mDice: 0.5238

Epoch 00013: val_mDice did not improve from 0.53975
Epoch 14/300
 - 12s - loss: 1127.2562 - acc: 0.9532 - mDice: 0.7933 - val_loss: 2827.5856 - val_acc: 0.9466 - val_mDice: 0.5426

Epoch 00014: val_mDice improved from 0.53975 to 0.54256, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 12s - loss: 1096.9196 - acc: 0.9537 - mDice: 0.7983 - val_loss: 3099.7352 - val_acc: 0.9458 - val_mDice: 0.5202

Epoch 00015: val_mDice did not improve from 0.54256
Epoch 16/300
 - 13s - loss: 1071.7117 - acc: 0.9544 - mDice: 0.8024 - val_loss: 2852.2276 - val_acc: 0.9413 - val_mDice: 0.5396

Epoch 00016: val_mDice did not improve from 0.54256
Epoch 17/300
 - 12s - loss: 1046.5912 - acc: 0.9548 - mDice: 0.8065 - val_loss: 3216.7189 - val_acc: 0.9418 - val_mDice: 0.5041

Epoch 00017: val_mDice did not improve from 0.54256
Epoch 18/300
 - 13s - loss: 1027.0952 - acc: 0.9552 - mDice: 0.8097 - val_loss: 2877.6414 - val_acc: 0.9454 - val_mDice: 0.5370

Epoch 00018: val_mDice did not improve from 0.54256
Epoch 19/300
 - 13s - loss: 1011.3201 - acc: 0.9556 - mDice: 0.8124 - val_loss: 3276.5334 - val_acc: 0.9397 - val_mDice: 0.4980

Epoch 00019: val_mDice did not improve from 0.54256
Epoch 20/300
 - 13s - loss: 994.6541 - acc: 0.9559 - mDice: 0.8151 - val_loss: 2789.2409 - val_acc: 0.9493 - val_mDice: 0.5499

Epoch 00020: val_mDice improved from 0.54256 to 0.54992, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 13s - loss: 974.2656 - acc: 0.9563 - mDice: 0.8185 - val_loss: 3008.0731 - val_acc: 0.9403 - val_mDice: 0.5256

Epoch 00021: val_mDice did not improve from 0.54992
Epoch 22/300
 - 12s - loss: 966.8929 - acc: 0.9565 - mDice: 0.8198 - val_loss: 2821.2471 - val_acc: 0.9469 - val_mDice: 0.5425

Epoch 00022: val_mDice did not improve from 0.54992
Epoch 23/300
 - 13s - loss: 964.0227 - acc: 0.9566 - mDice: 0.8203 - val_loss: 3058.9429 - val_acc: 0.9453 - val_mDice: 0.5182

Epoch 00023: val_mDice did not improve from 0.54992
Epoch 24/300
 - 13s - loss: 931.3592 - acc: 0.9573 - mDice: 0.8258 - val_loss: 2751.2512 - val_acc: 0.9471 - val_mDice: 0.5509

Epoch 00024: val_mDice improved from 0.54992 to 0.55093, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 12s - loss: 920.9974 - acc: 0.9575 - mDice: 0.8275 - val_loss: 2798.0858 - val_acc: 0.9454 - val_mDice: 0.5421

Epoch 00025: val_mDice did not improve from 0.55093
Epoch 26/300
 - 13s - loss: 911.4277 - acc: 0.9577 - mDice: 0.8292 - val_loss: 2804.7444 - val_acc: 0.9475 - val_mDice: 0.5437

Epoch 00026: val_mDice did not improve from 0.55093
Epoch 27/300
 - 12s - loss: 892.2122 - acc: 0.9580 - mDice: 0.8324 - val_loss: 3136.5067 - val_acc: 0.9434 - val_mDice: 0.5114

Epoch 00027: val_mDice did not improve from 0.55093
Epoch 28/300
 - 13s - loss: 887.3594 - acc: 0.9582 - mDice: 0.8333 - val_loss: 3101.7785 - val_acc: 0.9436 - val_mDice: 0.5171

Epoch 00028: val_mDice did not improve from 0.55093
Epoch 29/300
 - 13s - loss: 888.5555 - acc: 0.9581 - mDice: 0.8331 - val_loss: 2982.8854 - val_acc: 0.9473 - val_mDice: 0.5272

Epoch 00029: val_mDice did not improve from 0.55093
Epoch 30/300
 - 13s - loss: 866.3486 - acc: 0.9586 - mDice: 0.8368 - val_loss: 2982.9448 - val_acc: 0.9442 - val_mDice: 0.5214

Epoch 00030: val_mDice did not improve from 0.55093
Epoch 31/300
 - 13s - loss: 858.7913 - acc: 0.9587 - mDice: 0.8382 - val_loss: 2631.9322 - val_acc: 0.9441 - val_mDice: 0.5611

Epoch 00031: val_mDice improved from 0.55093 to 0.56111, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 12s - loss: 851.8579 - acc: 0.9589 - mDice: 0.8393 - val_loss: 2996.0112 - val_acc: 0.9431 - val_mDice: 0.5227

Epoch 00032: val_mDice did not improve from 0.56111
Epoch 33/300
 - 13s - loss: 834.4525 - acc: 0.9592 - mDice: 0.8423 - val_loss: 3087.3454 - val_acc: 0.9438 - val_mDice: 0.5154

Epoch 00033: val_mDice did not improve from 0.56111
Epoch 34/300
 - 12s - loss: 833.1090 - acc: 0.9592 - mDice: 0.8426 - val_loss: 2754.9520 - val_acc: 0.9466 - val_mDice: 0.5485

Epoch 00034: val_mDice did not improve from 0.56111
Epoch 35/300
 - 13s - loss: 834.4425 - acc: 0.9593 - mDice: 0.8423 - val_loss: 2898.6252 - val_acc: 0.9421 - val_mDice: 0.5334

Epoch 00035: val_mDice did not improve from 0.56111
Epoch 36/300
 - 13s - loss: 821.3100 - acc: 0.9595 - mDice: 0.8446 - val_loss: 2765.6082 - val_acc: 0.9483 - val_mDice: 0.5465

Epoch 00036: val_mDice did not improve from 0.56111
Epoch 37/300
 - 13s - loss: 810.2829 - acc: 0.9597 - mDice: 0.8465 - val_loss: 2991.4270 - val_acc: 0.9480 - val_mDice: 0.5242

Epoch 00037: val_mDice did not improve from 0.56111
Epoch 38/300
 - 13s - loss: 810.1559 - acc: 0.9598 - mDice: 0.8465 - val_loss: 3063.5357 - val_acc: 0.9450 - val_mDice: 0.5165

Epoch 00038: val_mDice did not improve from 0.56111
Epoch 39/300
 - 12s - loss: 806.4144 - acc: 0.9598 - mDice: 0.8472 - val_loss: 3028.8244 - val_acc: 0.9434 - val_mDice: 0.5254

Epoch 00039: val_mDice did not improve from 0.56111
Epoch 40/300
 - 13s - loss: 801.7693 - acc: 0.9599 - mDice: 0.8480 - val_loss: 2754.2947 - val_acc: 0.9500 - val_mDice: 0.5469

Epoch 00040: val_mDice did not improve from 0.56111
Epoch 41/300
 - 13s - loss: 790.3315 - acc: 0.9602 - mDice: 0.8500 - val_loss: 3009.0590 - val_acc: 0.9423 - val_mDice: 0.5200

Epoch 00041: val_mDice did not improve from 0.56111
Epoch 42/300
 - 12s - loss: 783.3290 - acc: 0.9603 - mDice: 0.8512 - val_loss: 2941.1702 - val_acc: 0.9455 - val_mDice: 0.5287

Epoch 00042: val_mDice did not improve from 0.56111
Epoch 43/300
 - 13s - loss: 780.6328 - acc: 0.9603 - mDice: 0.8517 - val_loss: 3053.4566 - val_acc: 0.9459 - val_mDice: 0.5189

Epoch 00043: val_mDice did not improve from 0.56111
Epoch 44/300
 - 13s - loss: 777.0527 - acc: 0.9604 - mDice: 0.8523 - val_loss: 2974.0545 - val_acc: 0.9456 - val_mDice: 0.5278

Epoch 00044: val_mDice did not improve from 0.56111
Epoch 45/300
 - 12s - loss: 773.3682 - acc: 0.9605 - mDice: 0.8530 - val_loss: 3230.5934 - val_acc: 0.9434 - val_mDice: 0.5017

Epoch 00045: val_mDice did not improve from 0.56111
Epoch 46/300
 - 13s - loss: 771.9970 - acc: 0.9605 - mDice: 0.8532 - val_loss: 2866.4233 - val_acc: 0.9448 - val_mDice: 0.5381

Epoch 00046: val_mDice did not improve from 0.56111
Epoch 47/300
 - 12s - loss: 764.1772 - acc: 0.9607 - mDice: 0.8546 - val_loss: 2747.3407 - val_acc: 0.9494 - val_mDice: 0.5482

Epoch 00047: val_mDice did not improve from 0.56111
Epoch 48/300
 - 13s - loss: 764.5803 - acc: 0.9607 - mDice: 0.8545 - val_loss: 3028.6574 - val_acc: 0.9466 - val_mDice: 0.5191

Epoch 00048: val_mDice did not improve from 0.56111
Epoch 49/300
 - 13s - loss: 752.1654 - acc: 0.9609 - mDice: 0.8567 - val_loss: 2981.6454 - val_acc: 0.9472 - val_mDice: 0.5246

Epoch 00049: val_mDice did not improve from 0.56111
Epoch 50/300
 - 12s - loss: 755.1505 - acc: 0.9609 - mDice: 0.8562 - val_loss: 3054.6526 - val_acc: 0.9437 - val_mDice: 0.5192

Epoch 00050: val_mDice did not improve from 0.56111
Epoch 51/300
 - 13s - loss: 745.8465 - acc: 0.9611 - mDice: 0.8578 - val_loss: 2899.7794 - val_acc: 0.9460 - val_mDice: 0.5332

Epoch 00051: val_mDice did not improve from 0.56111
Epoch 52/300
 - 12s - loss: 739.6322 - acc: 0.9611 - mDice: 0.8589 - val_loss: 3058.0256 - val_acc: 0.9437 - val_mDice: 0.5165

Epoch 00052: val_mDice did not improve from 0.56111
Epoch 53/300
 - 13s - loss: 741.6119 - acc: 0.9612 - mDice: 0.8586 - val_loss: 3126.7592 - val_acc: 0.9468 - val_mDice: 0.5163

Epoch 00053: val_mDice did not improve from 0.56111
Epoch 54/300
 - 13s - loss: 739.1496 - acc: 0.9612 - mDice: 0.8590 - val_loss: 2739.1922 - val_acc: 0.9469 - val_mDice: 0.5496

Epoch 00054: val_mDice did not improve from 0.56111
Epoch 55/300
 - 12s - loss: 728.6231 - acc: 0.9614 - mDice: 0.8609 - val_loss: 3179.1320 - val_acc: 0.9427 - val_mDice: 0.5018

Epoch 00055: val_mDice did not improve from 0.56111
Epoch 56/300
 - 13s - loss: 729.7106 - acc: 0.9614 - mDice: 0.8607 - val_loss: 3004.5447 - val_acc: 0.9493 - val_mDice: 0.5265

Epoch 00056: val_mDice did not improve from 0.56111
Epoch 57/300
 - 12s - loss: 722.4990 - acc: 0.9615 - mDice: 0.8619 - val_loss: 2995.0629 - val_acc: 0.9456 - val_mDice: 0.5208

Epoch 00057: val_mDice did not improve from 0.56111
Epoch 58/300
 - 13s - loss: 722.3606 - acc: 0.9616 - mDice: 0.8620 - val_loss: 2931.1224 - val_acc: 0.9463 - val_mDice: 0.5287

Epoch 00058: val_mDice did not improve from 0.56111
Epoch 59/300
 - 13s - loss: 718.9830 - acc: 0.9615 - mDice: 0.8626 - val_loss: 3029.8058 - val_acc: 0.9452 - val_mDice: 0.5195

Epoch 00059: val_mDice did not improve from 0.56111
Epoch 60/300
 - 12s - loss: 707.8118 - acc: 0.9618 - mDice: 0.8646 - val_loss: 3222.5715 - val_acc: 0.9435 - val_mDice: 0.4985

Epoch 00060: val_mDice did not improve from 0.56111
Epoch 61/300
 - 13s - loss: 706.3423 - acc: 0.9618 - mDice: 0.8648 - val_loss: 2962.5136 - val_acc: 0.9450 - val_mDice: 0.5272

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.32s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.08s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:18,  1.54s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:32,  1.60s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:35,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:13,  1.76s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:53,  1.69s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:24,  1.81s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:46,  1.90s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<09:13,  2.00s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:57,  1.95s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:16,  2.02s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:26,  2.07s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:24,  2.07s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:37,  2.12s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:37,  2.13s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:44,  2.16s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:42,  2.17s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:45,  2.18s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:49,  2.21s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<09:46,  2.21s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:45,  2.21s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:41,  2.20s/it]predicting train subjects:   8%|▊         | 22/285 [00:45<09:46,  2.23s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:55,  2.27s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<09:48,  2.25s/it]predicting train subjects:   9%|▉         | 25/285 [00:52<09:50,  2.27s/it]predicting train subjects:   9%|▉         | 26/285 [00:54<09:36,  2.23s/it]predicting train subjects:   9%|▉         | 27/285 [00:56<09:36,  2.23s/it]predicting train subjects:  10%|▉         | 28/285 [00:58<09:32,  2.23s/it]predicting train subjects:  10%|█         | 29/285 [01:01<09:22,  2.20s/it]predicting train subjects:  11%|█         | 30/285 [01:03<09:08,  2.15s/it]predicting train subjects:  11%|█         | 31/285 [01:05<08:51,  2.09s/it]predicting train subjects:  11%|█         | 32/285 [01:07<08:52,  2.11s/it]predicting train subjects:  12%|█▏        | 33/285 [01:09<08:51,  2.11s/it]predicting train subjects:  12%|█▏        | 34/285 [01:11<08:52,  2.12s/it]predicting train subjects:  12%|█▏        | 35/285 [01:13<08:57,  2.15s/it]predicting train subjects:  13%|█▎        | 36/285 [01:15<08:49,  2.13s/it]predicting train subjects:  13%|█▎        | 37/285 [01:17<08:44,  2.12s/it]predicting train subjects:  13%|█▎        | 38/285 [01:20<08:46,  2.13s/it]predicting train subjects:  14%|█▎        | 39/285 [01:22<08:54,  2.17s/it]predicting train subjects:  14%|█▍        | 40/285 [01:24<08:49,  2.16s/it]predicting train subjects:  14%|█▍        | 41/285 [01:26<08:38,  2.13s/it]predicting train subjects:  15%|█▍        | 42/285 [01:28<08:37,  2.13s/it]predicting train subjects:  15%|█▌        | 43/285 [01:30<08:38,  2.14s/it]predicting train subjects:  15%|█▌        | 44/285 [01:32<08:34,  2.13s/it]predicting train subjects:  16%|█▌        | 45/285 [01:35<08:34,  2.15s/it]predicting train subjects:  16%|█▌        | 46/285 [01:37<08:21,  2.10s/it]predicting train subjects:  16%|█▋        | 47/285 [01:38<07:57,  2.01s/it]predicting train subjects:  17%|█▋        | 48/285 [01:40<07:35,  1.92s/it]predicting train subjects:  17%|█▋        | 49/285 [01:42<07:27,  1.89s/it]predicting train subjects:  18%|█▊        | 50/285 [01:44<07:13,  1.84s/it]predicting train subjects:  18%|█▊        | 51/285 [01:45<07:07,  1.83s/it]predicting train subjects:  18%|█▊        | 52/285 [01:47<06:54,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:49<06:51,  1.77s/it]predicting train subjects:  19%|█▉        | 54/285 [01:51<06:51,  1.78s/it]predicting train subjects:  19%|█▉        | 55/285 [01:52<06:48,  1.77s/it]predicting train subjects:  20%|█▉        | 56/285 [01:54<06:48,  1.78s/it]predicting train subjects:  20%|██        | 57/285 [01:56<06:48,  1.79s/it]predicting train subjects:  20%|██        | 58/285 [01:58<06:48,  1.80s/it]predicting train subjects:  21%|██        | 59/285 [02:00<06:44,  1.79s/it]predicting train subjects:  21%|██        | 60/285 [02:01<06:41,  1.78s/it]predicting train subjects:  21%|██▏       | 61/285 [02:03<06:45,  1.81s/it]predicting train subjects:  22%|██▏       | 62/285 [02:05<06:44,  1.81s/it]predicting train subjects:  22%|██▏       | 63/285 [02:07<06:36,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [02:09<06:46,  1.84s/it]predicting train subjects:  23%|██▎       | 65/285 [02:11<06:59,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:13<07:05,  1.94s/it]predicting train subjects:  24%|██▎       | 67/285 [02:15<07:06,  1.95s/it]predicting train subjects:  24%|██▍       | 68/285 [02:17<07:02,  1.95s/it]predicting train subjects:  24%|██▍       | 69/285 [02:19<06:56,  1.93s/it]predicting train subjects:  25%|██▍       | 70/285 [02:20<06:49,  1.91s/it]predicting train subjects:  25%|██▍       | 71/285 [02:22<06:46,  1.90s/it]predicting train subjects:  25%|██▌       | 72/285 [02:24<06:49,  1.92s/it]predicting train subjects:  26%|██▌       | 73/285 [02:26<06:59,  1.98s/it]predicting train subjects:  26%|██▌       | 74/285 [02:29<07:04,  2.01s/it]predicting train subjects:  26%|██▋       | 75/285 [02:30<06:55,  1.98s/it]predicting train subjects:  27%|██▋       | 76/285 [02:32<06:45,  1.94s/it]predicting train subjects:  27%|██▋       | 77/285 [02:34<06:49,  1.97s/it]predicting train subjects:  27%|██▋       | 78/285 [02:36<06:53,  2.00s/it]predicting train subjects:  28%|██▊       | 79/285 [02:38<06:42,  1.95s/it]predicting train subjects:  28%|██▊       | 80/285 [02:40<06:32,  1.92s/it]predicting train subjects:  28%|██▊       | 81/285 [02:42<06:38,  1.95s/it]predicting train subjects:  29%|██▉       | 82/285 [02:44<06:35,  1.95s/it]predicting train subjects:  29%|██▉       | 83/285 [02:46<06:21,  1.89s/it]predicting train subjects:  29%|██▉       | 84/285 [02:48<06:13,  1.86s/it]predicting train subjects:  30%|██▉       | 85/285 [02:50<06:25,  1.93s/it]predicting train subjects:  30%|███       | 86/285 [02:52<06:30,  1.96s/it]predicting train subjects:  31%|███       | 87/285 [02:54<06:26,  1.95s/it]predicting train subjects:  31%|███       | 88/285 [02:56<06:21,  1.94s/it]predicting train subjects:  31%|███       | 89/285 [02:58<06:22,  1.95s/it]predicting train subjects:  32%|███▏      | 90/285 [03:00<06:26,  1.98s/it]predicting train subjects:  32%|███▏      | 91/285 [03:02<06:24,  1.98s/it]predicting train subjects:  32%|███▏      | 92/285 [03:04<06:27,  2.01s/it]predicting train subjects:  33%|███▎      | 93/285 [03:06<06:43,  2.10s/it]predicting train subjects:  33%|███▎      | 94/285 [03:08<06:37,  2.08s/it]predicting train subjects:  33%|███▎      | 95/285 [03:10<06:31,  2.06s/it]predicting train subjects:  34%|███▎      | 96/285 [03:12<06:25,  2.04s/it]predicting train subjects:  34%|███▍      | 97/285 [03:14<06:19,  2.02s/it]predicting train subjects:  34%|███▍      | 98/285 [03:16<06:22,  2.05s/it]predicting train subjects:  35%|███▍      | 99/285 [03:18<06:15,  2.02s/it]predicting train subjects:  35%|███▌      | 100/285 [03:20<06:14,  2.02s/it]predicting train subjects:  35%|███▌      | 101/285 [03:22<06:07,  2.00s/it]predicting train subjects:  36%|███▌      | 102/285 [03:24<05:59,  1.96s/it]predicting train subjects:  36%|███▌      | 103/285 [03:26<05:47,  1.91s/it]predicting train subjects:  36%|███▋      | 104/285 [03:28<05:50,  1.94s/it]predicting train subjects:  37%|███▋      | 105/285 [03:30<05:46,  1.92s/it]predicting train subjects:  37%|███▋      | 106/285 [03:32<05:48,  1.95s/it]predicting train subjects:  38%|███▊      | 107/285 [03:34<05:48,  1.96s/it]predicting train subjects:  38%|███▊      | 108/285 [03:35<05:37,  1.90s/it]predicting train subjects:  38%|███▊      | 109/285 [03:37<05:29,  1.87s/it]predicting train subjects:  39%|███▊      | 110/285 [03:39<05:28,  1.88s/it]predicting train subjects:  39%|███▉      | 111/285 [03:41<05:30,  1.90s/it]predicting train subjects:  39%|███▉      | 112/285 [03:43<05:21,  1.86s/it]predicting train subjects:  40%|███▉      | 113/285 [03:45<05:28,  1.91s/it]predicting train subjects:  40%|████      | 114/285 [03:47<05:29,  1.93s/it]predicting train subjects:  40%|████      | 115/285 [03:49<05:27,  1.92s/it]predicting train subjects:  41%|████      | 116/285 [03:51<05:24,  1.92s/it]predicting train subjects:  41%|████      | 117/285 [03:53<05:28,  1.96s/it]predicting train subjects:  41%|████▏     | 118/285 [03:54<05:23,  1.94s/it]predicting train subjects:  42%|████▏     | 119/285 [03:56<05:26,  1.97s/it]predicting train subjects:  42%|████▏     | 120/285 [03:59<05:30,  2.00s/it]predicting train subjects:  42%|████▏     | 121/285 [04:00<05:19,  1.95s/it]predicting train subjects:  43%|████▎     | 122/285 [04:02<04:59,  1.84s/it]predicting train subjects:  43%|████▎     | 123/285 [04:04<04:43,  1.75s/it]predicting train subjects:  44%|████▎     | 124/285 [04:05<04:48,  1.79s/it]predicting train subjects:  44%|████▍     | 125/285 [04:07<04:47,  1.80s/it]predicting train subjects:  44%|████▍     | 126/285 [04:09<04:44,  1.79s/it]predicting train subjects:  45%|████▍     | 127/285 [04:11<04:45,  1.80s/it]predicting train subjects:  45%|████▍     | 128/285 [04:13<04:40,  1.79s/it]predicting train subjects:  45%|████▌     | 129/285 [04:14<04:44,  1.82s/it]predicting train subjects:  46%|████▌     | 130/285 [04:16<04:41,  1.81s/it]predicting train subjects:  46%|████▌     | 131/285 [04:18<04:39,  1.82s/it]predicting train subjects:  46%|████▋     | 132/285 [04:20<04:36,  1.81s/it]predicting train subjects:  47%|████▋     | 133/285 [04:22<04:36,  1.82s/it]predicting train subjects:  47%|████▋     | 134/285 [04:24<04:41,  1.86s/it]predicting train subjects:  47%|████▋     | 135/285 [04:26<04:36,  1.84s/it]predicting train subjects:  48%|████▊     | 136/285 [04:27<04:31,  1.82s/it]predicting train subjects:  48%|████▊     | 137/285 [04:29<04:30,  1.83s/it]predicting train subjects:  48%|████▊     | 138/285 [04:31<04:31,  1.85s/it]predicting train subjects:  49%|████▉     | 139/285 [04:33<04:31,  1.86s/it]predicting train subjects:  49%|████▉     | 140/285 [04:35<04:28,  1.85s/it]predicting train subjects:  49%|████▉     | 141/285 [04:37<04:23,  1.83s/it]predicting train subjects:  50%|████▉     | 142/285 [04:38<04:16,  1.79s/it]predicting train subjects:  50%|█████     | 143/285 [04:40<04:08,  1.75s/it]predicting train subjects:  51%|█████     | 144/285 [04:42<04:04,  1.73s/it]predicting train subjects:  51%|█████     | 145/285 [04:43<03:57,  1.70s/it]predicting train subjects:  51%|█████     | 146/285 [04:45<03:55,  1.69s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:47<03:51,  1.68s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:48<03:50,  1.68s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:50<03:41,  1.63s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:51<03:41,  1.64s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:53<03:36,  1.62s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:54<03:32,  1.60s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:56<03:34,  1.62s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:58<03:32,  1.62s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:59<03:27,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:01<03:20,  1.55s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:02<03:20,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:04<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:06<03:22,  1.61s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:07<03:20,  1.60s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:09<03:19,  1.61s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:10<03:17,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:12<03:15,  1.61s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:14<03:16,  1.62s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:15<03:13,  1.61s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:17<03:12,  1.62s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:19<03:09,  1.61s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:20<03:09,  1.62s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:22<03:08,  1.63s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:23<03:05,  1.62s/it]predicting train subjects:  60%|██████    | 171/285 [05:25<03:04,  1.62s/it]predicting train subjects:  60%|██████    | 172/285 [05:27<03:04,  1.63s/it]predicting train subjects:  61%|██████    | 173/285 [05:28<03:01,  1.62s/it]predicting train subjects:  61%|██████    | 174/285 [05:30<02:58,  1.61s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:32<03:03,  1.67s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:33<03:01,  1.67s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:35<03:02,  1.69s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:37<03:02,  1.71s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:39<02:59,  1.70s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:40<02:58,  1.70s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:42<02:58,  1.71s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:44<02:53,  1.69s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:45<02:55,  1.72s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:47<02:52,  1.71s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:49<02:49,  1.69s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:51<02:52,  1.74s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:52<02:51,  1.75s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:54<02:50,  1.76s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:56<02:47,  1.74s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:58<02:46,  1.75s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:59<02:38,  1.69s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:01<02:33,  1.65s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:02<02:30,  1.64s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:04<02:30,  1.65s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:06<02:25,  1.62s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:07<02:31,  1.70s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:09<02:38,  1.80s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:11<02:41,  1.86s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:13<02:42,  1.89s/it]predicting train subjects:  70%|███████   | 200/285 [06:15<02:39,  1.88s/it]predicting train subjects:  71%|███████   | 201/285 [06:17<02:41,  1.92s/it]predicting train subjects:  71%|███████   | 202/285 [06:19<02:43,  1.97s/it]predicting train subjects:  71%|███████   | 203/285 [06:21<02:44,  2.01s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:23<02:41,  2.00s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:25<02:40,  2.00s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:27<02:36,  1.99s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:29<02:35,  1.99s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:32<02:36,  2.03s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:33<02:31,  2.00s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:36<02:31,  2.02s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:37<02:28,  2.01s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:40<02:27,  2.01s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:42<02:24,  2.01s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:43<02:16,  1.92s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:45<02:13,  1.90s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:47<02:08,  1.87s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:49<02:07,  1.88s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:50<02:02,  1.82s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:52<01:58,  1.80s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:54<01:59,  1.83s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:56<01:56,  1.82s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:58<01:54,  1.82s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:00<01:52,  1.82s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:01<01:50,  1.81s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:03<01:49,  1.82s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:05<01:44,  1.78s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:07<01:42,  1.77s/it]predicting train subjects:  80%|████████  | 228/285 [07:08<01:42,  1.79s/it]predicting train subjects:  80%|████████  | 229/285 [07:10<01:41,  1.81s/it]predicting train subjects:  81%|████████  | 230/285 [07:12<01:40,  1.83s/it]predicting train subjects:  81%|████████  | 231/285 [07:14<01:35,  1.78s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:16<01:40,  1.90s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:18<01:43,  2.00s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:21<01:45,  2.08s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:23<01:46,  2.14s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:25<01:46,  2.18s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:27<01:45,  2.19s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:30<01:43,  2.21s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:32<01:41,  2.21s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:34<01:39,  2.20s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:36<01:36,  2.19s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:38<01:35,  2.23s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:41<01:31,  2.19s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:43<01:29,  2.18s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:45<01:27,  2.19s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:47<01:27,  2.24s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:50<01:25,  2.25s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:52<01:24,  2.27s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:54<01:21,  2.27s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:56<01:13,  2.11s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:58<01:07,  1.98s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:59<01:01,  1.87s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:01<00:57,  1.81s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:02<00:54,  1.76s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:04<00:53,  1.79s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:06<00:52,  1.81s/it]predicting train subjects:  90%|█████████ | 257/285 [08:08<00:49,  1.78s/it]predicting train subjects:  91%|█████████ | 258/285 [08:10<00:48,  1.80s/it]predicting train subjects:  91%|█████████ | 259/285 [08:11<00:46,  1.77s/it]predicting train subjects:  91%|█████████ | 260/285 [08:13<00:44,  1.78s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:15<00:41,  1.73s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:17<00:39,  1.71s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:18<00:37,  1.69s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:20<00:35,  1.67s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:22<00:33,  1.69s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:23<00:32,  1.71s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:25<00:31,  1.75s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:27<00:31,  1.87s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:29<00:31,  1.94s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:32<00:30,  2.01s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:34<00:28,  2.07s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:36<00:27,  2.14s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:38<00:25,  2.13s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:40<00:24,  2.18s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:43<00:21,  2.16s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:45<00:19,  2.20s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:47<00:17,  2.21s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:49<00:15,  2.17s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:51<00:13,  2.17s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:54<00:10,  2.17s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:56<00:08,  2.19s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:58<00:06,  2.20s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:00<00:04,  2.20s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:02<00:02,  2.20s/it]predicting train subjects: 100%|██████████| 285/285 [09:05<00:00,  2.22s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:10,  1.73s/it]Loading train:   1%|          | 2/285 [00:03<08:42,  1.85s/it]Loading train:   1%|          | 3/285 [00:05<08:36,  1.83s/it]Loading train:   1%|▏         | 4/285 [00:08<09:30,  2.03s/it]
Epoch 00061: val_mDice did not improve from 0.56111
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
{'val_loss': [4891.00542922247, 4346.725434802827, 3529.3733956473216, 3324.9530203683034, 2937.757859002976, 2839.9698311941966, 2886.435279482887, 2908.302199590774, 2852.0109514508927, 2912.446602957589, 2902.190452938988, 3238.3761858258927, 3004.3305315290177, 2827.5856003534227, 3099.735194614955, 2852.227585565476, 3216.7188895089284, 2877.641403924851, 3276.5333891369046, 2789.240920293899, 3008.073067801339, 2821.2470819382443, 3058.9429059709823, 2751.251174200149, 2798.0858328683034, 2804.744390578497, 3136.5066731770835, 3101.778517950149, 2982.885428292411, 2982.944830031622, 2631.9322451636904, 2996.011236281622, 3087.3453601655506, 2754.951950799851, 2898.625174386161, 2765.608183361235, 2991.427025204613, 3063.5357491629466, 3028.8243698846727, 2754.294747488839, 3009.0589773995534, 2941.170229957217, 3053.4566359747023, 2974.054472423735, 3230.5934302920386, 2866.4232817150296, 2747.3406982421875, 3028.6574125744046, 2981.6453973679318, 3054.6526402064733, 2899.7794073195682, 3058.0255766369046, 3126.7591610863096, 2739.1922316778273, 3179.131992885045, 3004.544677734375, 2995.0628603980654, 2931.122360956101, 3029.8057570684523, 3222.571539015997, 2962.5135963076636], 'val_acc': [0.9051190728232974, 0.9067009942872184, 0.9101442127000718, 0.9180517622402736, 0.9422092466127305, 0.944205607686724, 0.9458539287249247, 0.9462431357020423, 0.9398054281870524, 0.943070079599108, 0.9406432963552929, 0.943113556929997, 0.943392833073934, 0.9465865237372262, 0.945776085058848, 0.9412614277430943, 0.941783436707088, 0.9453525401297069, 0.9396565982273647, 0.9493360746474493, 0.9402816125324794, 0.946884138243539, 0.9452861831301734, 0.9471405744552612, 0.9454166860807509, 0.9475434905006772, 0.9434226070131574, 0.9435897639819554, 0.947273348058973, 0.9441735063280378, 0.9440979560216268, 0.9430723559288752, 0.9437843419256664, 0.9465750881603786, 0.942133713336218, 0.9482829939751398, 0.9480196833610535, 0.9450205933480036, 0.9434409255073184, 0.9500045577685038, 0.9423420230547587, 0.9455357307479495, 0.9458745632852826, 0.945592965398516, 0.9433562386603582, 0.944771042891911, 0.949352088428679, 0.9466392085665748, 0.9471840461095175, 0.9437133840152195, 0.946009635925293, 0.9436744366373334, 0.9468315130188352, 0.9469391277858189, 0.9427472352981567, 0.949281130518232, 0.9455906408173698, 0.9462729181562152, 0.9451785797164554, 0.9435141938073295, 0.944974802789234], 'val_mDice': [0.35097634561714675, 0.410836157699426, 0.4752203410580045, 0.4833356209454082, 0.5300190652764979, 0.5361585175352437, 0.5351768267296609, 0.5337158072562445, 0.5397526073668685, 0.5319202723247665, 0.5324250406452588, 0.5051403904245013, 0.5237948763228598, 0.5425633245280811, 0.5202011627455553, 0.5395846295924414, 0.5040619078846205, 0.5369537662537325, 0.49802014302639735, 0.5499157568528539, 0.525555764635404, 0.5424651686279547, 0.5181818050997598, 0.5509324511956601, 0.5420541770401455, 0.5436742594909101, 0.5114108946706567, 0.5170539395794982, 0.5271910162908691, 0.5214447882913408, 0.5611053989047096, 0.522702692342656, 0.5154467947071507, 0.5485090987668151, 0.5333539061248302, 0.5465175938748178, 0.524247562424058, 0.5164987322475229, 0.5253774271834464, 0.5469333685579754, 0.5200088205082076, 0.5287228728688899, 0.5188996270298958, 0.5277857509042535, 0.501688149358545, 0.5380605961240473, 0.5482024135334151, 0.519138502223151, 0.5246407662828764, 0.519156567220177, 0.5331714210056123, 0.5164841935038567, 0.5163119078746864, 0.5496499864828019, 0.501769732683897, 0.5265090071729251, 0.5208041126884165, 0.528669797593639, 0.5195160075312569, 0.49850649173770634, 0.5272081742684046], 'loss': [10489.588139425336, 3126.676057137849, 2281.9544843412996, 1927.1792960371934, 1739.2259471827856, 1599.4038145478255, 1485.3338224382696, 1408.7313119929859, 1339.108285627775, 1270.9978397414245, 1236.0279886140193, 1197.3511004590428, 1150.7505640250906, 1127.2562194788918, 1096.9196321609877, 1071.7117286742434, 1046.5911834169633, 1027.0951970521255, 1011.320141973398, 994.6540953189577, 974.26555696351, 966.8928933850552, 964.022660093085, 931.3591741852754, 920.9973728289511, 911.4276636438791, 892.2121841021763, 887.3594206910568, 888.5555012432486, 866.3485926872094, 858.7912757451396, 851.8578963418537, 834.4524755233373, 833.1090187321331, 834.4424856085526, 821.3100373308761, 810.2828979727526, 810.155890602125, 806.4143553675542, 801.769341708011, 790.3315150222498, 783.3290101097847, 780.6327526180046, 777.0527499073706, 773.3681619915172, 771.9969535961486, 764.1771980846046, 764.5803264546582, 752.1653874935799, 755.1505492199173, 745.8465164446385, 739.6321568927577, 741.6118771236987, 739.149645906665, 728.6230965785859, 729.7105585807593, 722.4989547538279, 722.3605919377018, 718.982976168825, 707.8117527753052, 706.3423322475736], 'acc': [0.7997075726824135, 0.8749723783664582, 0.8821332644975, 0.8953899412985272, 0.9165311812871864, 0.9347478113860231, 0.9441697796645457, 0.9469148526422454, 0.9486009526831901, 0.9501987681215108, 0.9509016154633797, 0.9516577378205534, 0.9526497707767755, 0.9531575313808602, 0.9537205871231229, 0.9543900946810545, 0.9547569248081977, 0.9552432060563452, 0.9556016737334135, 0.9559148204724224, 0.9563428257641039, 0.9564645212809428, 0.9566163445957736, 0.9572650162797225, 0.9575027886994294, 0.9576711526536656, 0.9580468824770677, 0.9582026686791582, 0.9580947788138139, 0.9585670191749387, 0.9586708053978096, 0.9588807212816903, 0.9591742187123642, 0.9592179648099848, 0.9592655385209343, 0.9594503997009752, 0.9596963939994017, 0.9597872747767286, 0.9598276854848411, 0.9599146933047235, 0.9601750767527459, 0.9602587512860024, 0.9603115110262203, 0.9604487624360528, 0.9604829187932813, 0.9605032608921367, 0.9607399851112484, 0.9607302746562248, 0.9609060333210401, 0.960856258352069, 0.9610692068678762, 0.9611128429491349, 0.961170284658906, 0.961164353324518, 0.9614023258053133, 0.9613944012718392, 0.9614794649483956, 0.9615885814260788, 0.9615265500437484, 0.9617665189411545, 0.9617781505916582], 'mDice': [0.20611633716180924, 0.5316735522145363, 0.6298354005845774, 0.6767003326625615, 0.7030290979881243, 0.7224035766604137, 0.7384045340892137, 0.7495232549549321, 0.7599967369597519, 0.7705785954690334, 0.7760651980334448, 0.7821487820582834, 0.7895787357479616, 0.7933464777108813, 0.7983032025559137, 0.8024067163398461, 0.8065270133415628, 0.8097466266589609, 0.8123747538987074, 0.8151324634862723, 0.8185199373991521, 0.8197730569244696, 0.8202522207207364, 0.825756744748254, 0.8275183620125612, 0.829153833900409, 0.8324271913711934, 0.8332687744474696, 0.8331085131971367, 0.8368394447241717, 0.8381590336555458, 0.8393151748150512, 0.8423357253845013, 0.8425794121776446, 0.8423378228313871, 0.8446152381338962, 0.8464964270844542, 0.8465419599309877, 0.8472220909280632, 0.847999907422438, 0.8500190439632409, 0.8512422300750221, 0.8517153149099738, 0.8523250438354828, 0.852989286730141, 0.8532304713922313, 0.8545870912633513, 0.8545454676173798, 0.8567274835887893, 0.8562079408459748, 0.8578489409008765, 0.8589333019115021, 0.8585955807646506, 0.8590151027307498, 0.8608558421100935, 0.8606909490031546, 0.8619483706577449, 0.8619662483510241, 0.86258699019704, 0.8645880487076874, 0.8648351914440939]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label valuesLoading train:   2%|▏         | 5/285 [00:10<10:17,  2.20s/it]Loading train:   2%|▏         | 6/285 [00:12<10:01,  2.15s/it]Loading train:   2%|▏         | 7/285 [00:15<10:17,  2.22s/it]Loading train:   3%|▎         | 8/285 [00:17<10:50,  2.35s/it]Loading train:   3%|▎         | 9/285 [00:19<10:06,  2.20s/it]Loading train:   4%|▎         | 10/285 [00:21<09:47,  2.13s/it]Loading train:   4%|▍         | 11/285 [00:23<09:40,  2.12s/it]Loading train:   4%|▍         | 12/285 [00:25<09:39,  2.12s/it]Loading train:   5%|▍         | 13/285 [00:27<09:11,  2.03s/it]Loading train:   5%|▍         | 14/285 [00:29<09:00,  2.00s/it]Loading train:   5%|▌         | 15/285 [00:31<09:05,  2.02s/it]Loading train:   6%|▌         | 16/285 [00:33<09:00,  2.01s/it]Loading train:   6%|▌         | 17/285 [00:35<08:22,  1.87s/it]Loading train:   6%|▋         | 18/285 [00:37<08:19,  1.87s/it]Loading train:   7%|▋         | 19/285 [00:38<07:58,  1.80s/it]Loading train:   7%|▋         | 20/285 [00:40<07:57,  1.80s/it]Loading train:   7%|▋         | 21/285 [00:42<07:53,  1.79s/it]Loading train:   8%|▊         | 22/285 [00:44<08:13,  1.88s/it]Loading train:   8%|▊         | 23/285 [00:46<08:06,  1.86s/it]Loading train:   8%|▊         | 24/285 [00:47<07:50,  1.80s/it]Loading train:   9%|▉         | 25/285 [00:49<07:50,  1.81s/it]Loading train:   9%|▉         | 26/285 [00:51<07:35,  1.76s/it]Loading train:   9%|▉         | 27/285 [00:53<07:28,  1.74s/it]Loading train:  10%|▉         | 28/285 [00:55<07:55,  1.85s/it]Loading train:  10%|█         | 29/285 [00:56<07:48,  1.83s/it]Loading train:  11%|█         | 30/285 [00:58<07:42,  1.81s/it]Loading train:  11%|█         | 31/285 [01:00<07:22,  1.74s/it]Loading train:  11%|█         | 32/285 [01:01<07:16,  1.73s/it]Loading train:  12%|█▏        | 33/285 [01:04<07:40,  1.83s/it]Loading train:  12%|█▏        | 34/285 [01:05<07:34,  1.81s/it]Loading train:  12%|█▏        | 35/285 [01:07<07:26,  1.79s/it]Loading train:  13%|█▎        | 36/285 [01:09<07:22,  1.78s/it]Loading train:  13%|█▎        | 37/285 [01:10<06:54,  1.67s/it]Loading train:  13%|█▎        | 38/285 [01:12<06:44,  1.64s/it]Loading train:  14%|█▎        | 39/285 [01:13<06:24,  1.56s/it]Loading train:  14%|█▍        | 40/285 [01:15<06:20,  1.55s/it]Loading train:  14%|█▍        | 41/285 [01:16<06:31,  1.60s/it]Loading train:  15%|█▍        | 42/285 [01:18<06:24,  1.58s/it]Loading train:  15%|█▌        | 43/285 [01:20<06:59,  1.73s/it]Loading train:  15%|█▌        | 44/285 [01:22<07:06,  1.77s/it]Loading train:  16%|█▌        | 45/285 [01:23<06:44,  1.69s/it]Loading train:  16%|█▌        | 46/285 [01:25<06:29,  1.63s/it]Loading train:  16%|█▋        | 47/285 [01:26<06:03,  1.53s/it]Loading train:  17%|█▋        | 48/285 [01:28<05:52,  1.49s/it]Loading train:  17%|█▋        | 49/285 [01:29<05:46,  1.47s/it]Loading train:  18%|█▊        | 50/285 [01:31<06:01,  1.54s/it]Loading train:  18%|█▊        | 51/285 [01:32<05:52,  1.51s/it]Loading train:  18%|█▊        | 52/285 [01:34<06:03,  1.56s/it]Loading train:  19%|█▊        | 53/285 [01:35<05:59,  1.55s/it]Loading train:  19%|█▉        | 54/285 [01:37<06:17,  1.63s/it]Loading train:  19%|█▉        | 55/285 [01:39<06:05,  1.59s/it]Loading train:  20%|█▉        | 56/285 [01:40<05:52,  1.54s/it]Loading train:  20%|██        | 57/285 [01:42<05:54,  1.56s/it]Loading train:  20%|██        | 58/285 [01:43<05:55,  1.57s/it]Loading train:  21%|██        | 59/285 [01:45<05:43,  1.52s/it]Loading train:  21%|██        | 60/285 [01:46<05:47,  1.54s/it]Loading train:  21%|██▏       | 61/285 [01:48<05:57,  1.60s/it]Loading train:  22%|██▏       | 62/285 [01:50<06:05,  1.64s/it]Loading train:  22%|██▏       | 63/285 [01:51<06:10,  1.67s/it]Loading train:  22%|██▏       | 64/285 [01:53<06:35,  1.79s/it]Loading train:  23%|██▎       | 65/285 [01:56<07:24,  2.02s/it]Loading train:  23%|██▎       | 66/285 [01:58<07:14,  1.98s/it]Loading train:  24%|██▎       | 67/285 [02:00<06:54,  1.90s/it]Loading train:  24%|██▍       | 68/285 [02:01<06:20,  1.76s/it]Loading train:  24%|██▍       | 69/285 [02:03<05:59,  1.66s/it]Loading train:  25%|██▍       | 70/285 [02:04<06:11,  1.73s/it]Loading train:  25%|██▍       | 71/285 [02:06<05:49,  1.63s/it]Loading train:  25%|██▌       | 72/285 [02:08<05:55,  1.67s/it]Loading train:  26%|██▌       | 73/285 [02:09<05:56,  1.68s/it]Loading train:  26%|██▌       | 74/285 [02:11<05:41,  1.62s/it]Loading train:  26%|██▋       | 75/285 [02:13<05:51,  1.68s/it]Loading train:  27%|██▋       | 76/285 [02:14<05:49,  1.67s/it]Loading train:  27%|██▋       | 77/285 [02:16<05:46,  1.67s/it]Loading train:  27%|██▋       | 78/285 [02:18<05:50,  1.69s/it]Loading train:  28%|██▊       | 79/285 [02:19<05:44,  1.67s/it]Loading train:  28%|██▊       | 80/285 [02:21<05:40,  1.66s/it]Loading train:  28%|██▊       | 81/285 [02:22<05:21,  1.58s/it]Loading train:  29%|██▉       | 82/285 [02:24<05:41,  1.68s/it]Loading train:  29%|██▉       | 83/285 [02:26<05:50,  1.73s/it]Loading train:  29%|██▉       | 84/285 [02:28<05:34,  1.67s/it]Loading train:  30%|██▉       | 85/285 [02:29<05:23,  1.62s/it]Loading train:  30%|███       | 86/285 [02:31<05:35,  1.68s/it]Loading train:  31%|███       | 87/285 [02:33<05:40,  1.72s/it]Loading train:  31%|███       | 88/285 [02:34<05:34,  1.70s/it]Loading train:  31%|███       | 89/285 [02:36<05:35,  1.71s/it]Loading train:  32%|███▏      | 90/285 [02:38<05:49,  1.79s/it]Loading train:  32%|███▏      | 91/285 [02:40<05:36,  1.74s/it]Loading train:  32%|███▏      | 92/285 [02:41<05:35,  1.74s/it]Loading train:  33%|███▎      | 93/285 [02:43<05:38,  1.76s/it]Loading train:  33%|███▎      | 94/285 [02:45<05:29,  1.73s/it]Loading train:  33%|███▎      | 95/285 [02:47<05:26,  1.72s/it]Loading train:  34%|███▎      | 96/285 [02:48<05:25,  1.72s/it]Loading train:  34%|███▍      | 97/285 [02:50<05:22,  1.71s/it]Loading train:  34%|███▍      | 98/285 [02:52<05:13,  1.68s/it]Loading train:  35%|███▍      | 99/285 [02:53<05:17,  1.71s/it]Loading train:  35%|███▌      | 100/285 [02:55<05:25,  1.76s/it]Loading train:  35%|███▌      | 101/285 [02:57<05:39,  1.84s/it]Loading train:  36%|███▌      | 102/285 [02:59<05:19,  1.75s/it]Loading train:  36%|███▌      | 103/285 [03:01<05:16,  1.74s/it]Loading train:  36%|███▋      | 104/285 [03:02<05:15,  1.74s/it]Loading train:  37%|███▋      | 105/285 [03:04<04:59,  1.66s/it]Loading train:  37%|███▋      | 106/285 [03:05<04:50,  1.62s/it]Loading train:  38%|███▊      | 107/285 [03:07<04:57,  1.67s/it]Loading train:  38%|███▊      | 108/285 [03:09<04:54,  1.67s/it]Loading train:  38%|███▊      | 109/285 [03:10<04:53,  1.66s/it]Loading train:  39%|███▊      | 110/285 [03:12<04:39,  1.60s/it]Loading train:  39%|███▉      | 111/285 [03:14<04:41,  1.62s/it]Loading train:  39%|███▉      | 112/285 [03:15<04:56,  1.72s/it]Loading train:  40%|███▉      | 113/285 [03:17<05:07,  1.79s/it]Loading train:  40%|████      | 114/285 [03:19<04:53,  1.72s/it]Loading train:  40%|████      | 115/285 [03:21<04:57,  1.75s/it]Loading train:  41%|████      | 116/285 [03:22<04:50,  1.72s/it]Loading train:  41%|████      | 117/285 [03:24<04:40,  1.67s/it]Loading train:  41%|████▏     | 118/285 [03:26<04:31,  1.62s/it]Loading train:  42%|████▏     | 119/285 [03:27<04:28,  1.62s/it]Loading train:  42%|████▏     | 120/285 [03:29<04:26,  1.61s/it]Loading train:  42%|████▏     | 121/285 [03:31<04:47,  1.75s/it]Loading train:  43%|████▎     | 122/285 [03:33<04:48,  1.77s/it]Loading train:  43%|████▎     | 123/285 [03:34<04:43,  1.75s/it]Loading train:  44%|████▎     | 124/285 [03:36<04:26,  1.66s/it]Loading train:  44%|████▍     | 125/285 [03:37<04:15,  1.60s/it]Loading train:  44%|████▍     | 126/285 [03:39<04:09,  1.57s/it]Loading train:  45%|████▍     | 127/285 [03:40<03:53,  1.48s/it]Loading train:  45%|████▍     | 128/285 [03:41<03:42,  1.42s/it]Loading train:  45%|████▌     | 129/285 [03:43<03:57,  1.52s/it]Loading train:  46%|████▌     | 130/285 [03:45<03:55,  1.52s/it]Loading train:  46%|████▌     | 131/285 [03:46<03:59,  1.56s/it]Loading train:  46%|████▋     | 132/285 [03:48<03:57,  1.56s/it]Loading train:  47%|████▋     | 133/285 [03:50<04:12,  1.66s/it]Loading train:  47%|████▋     | 134/285 [03:52<04:23,  1.74s/it]Loading train:  47%|████▋     | 135/285 [03:53<04:14,  1.69s/it]Loading train:  48%|████▊     | 136/285 [03:54<03:56,  1.58s/it]Loading train:  48%|████▊     | 137/285 [03:56<03:45,  1.52s/it]Loading train:  48%|████▊     | 138/285 [03:57<03:40,  1.50s/it]Loading train:  49%|████▉     | 139/285 [03:59<03:39,  1.51s/it]Loading train:  49%|████▉     | 140/285 [04:00<03:40,  1.52s/it]Loading train:  49%|████▉     | 141/285 [04:02<03:34,  1.49s/it]Loading train:  50%|████▉     | 142/285 [04:04<03:44,  1.57s/it]Loading train:  50%|█████     | 143/285 [04:05<03:43,  1.57s/it]Loading train:  51%|█████     | 144/285 [04:06<03:32,  1.51s/it]Loading train:  51%|█████     | 145/285 [04:08<03:29,  1.49s/it]Loading train:  51%|█████     | 146/285 [04:09<03:29,  1.50s/it]Loading train:  52%|█████▏    | 147/285 [04:11<03:40,  1.60s/it]Loading train:  52%|█████▏    | 148/285 [04:13<03:37,  1.59s/it]Loading train:  52%|█████▏    | 149/285 [04:14<03:26,  1.52s/it]Loading train:  53%|█████▎    | 150/285 [04:16<03:30,  1.56s/it]Loading train:  53%|█████▎    | 151/285 [04:17<03:25,  1.53s/it]Loading train:  53%|█████▎    | 152/285 [04:19<03:14,  1.46s/it]Loading train:  54%|█████▎    | 153/285 [04:20<03:06,  1.41s/it]Loading train:  54%|█████▍    | 154/285 [04:21<03:06,  1.42s/it]Loading train:  54%|█████▍    | 155/285 [04:23<03:07,  1.45s/it]Loading train:  55%|█████▍    | 156/285 [04:24<03:05,  1.44s/it]Loading train:  55%|█████▌    | 157/285 [04:26<03:04,  1.44s/it]Loading train:  55%|█████▌    | 158/285 [04:28<03:15,  1.54s/it]Loading train:  56%|█████▌    | 159/285 [04:29<03:12,  1.53s/it]Loading train:  56%|█████▌    | 160/285 [04:31<03:11,  1.53s/it]Loading train:  56%|█████▋    | 161/285 [04:32<03:02,  1.48s/it]Loading train:  57%|█████▋    | 162/285 [04:34<03:11,  1.55s/it]Loading train:  57%|█████▋    | 163/285 [04:35<03:01,  1.49s/it]Loading train:  58%|█████▊    | 164/285 [04:36<02:59,  1.49s/it]Loading train:  58%|█████▊    | 165/285 [04:38<03:01,  1.52s/it]Loading train:  58%|█████▊    | 166/285 [04:39<02:53,  1.46s/it]Loading train:  59%|█████▊    | 167/285 [04:41<02:46,  1.42s/it]Loading train:  59%|█████▉    | 168/285 [04:42<02:36,  1.34s/it]Loading train:  59%|█████▉    | 169/285 [04:43<02:27,  1.27s/it]Loading train:  60%|█████▉    | 170/285 [04:45<02:36,  1.36s/it]Loading train:  60%|██████    | 171/285 [04:46<02:35,  1.36s/it]Loading train:  60%|██████    | 172/285 [04:47<02:32,  1.35s/it]Loading train:  61%|██████    | 173/285 [04:48<02:29,  1.33s/it]Loading train:  61%|██████    | 174/285 [04:50<02:38,  1.42s/it]Loading train:  61%|██████▏   | 175/285 [04:52<02:35,  1.41s/it]Loading train:  62%|██████▏   | 176/285 [04:53<02:35,  1.42s/it]Loading train:  62%|██████▏   | 177/285 [04:55<02:41,  1.50s/it]Loading train:  62%|██████▏   | 178/285 [04:56<02:40,  1.50s/it]Loading train:  63%|██████▎   | 179/285 [04:58<02:40,  1.52s/it]Loading train:  63%|██████▎   | 180/285 [04:59<02:38,  1.51s/it]Loading train:  64%|██████▎   | 181/285 [05:01<02:32,  1.46s/it]Loading train:  64%|██████▍   | 182/285 [05:02<02:30,  1.46s/it]Loading train:  64%|██████▍   | 183/285 [05:03<02:29,  1.46s/it]Loading train:  65%|██████▍   | 184/285 [05:05<02:33,  1.52s/it]Loading train:  65%|██████▍   | 185/285 [05:06<02:23,  1.44s/it]Loading train:  65%|██████▌   | 186/285 [05:08<02:24,  1.46s/it]Loading train:  66%|██████▌   | 187/285 [05:09<02:15,  1.39s/it]Loading train:  66%|██████▌   | 188/285 [05:11<02:16,  1.40s/it]Loading train:  66%|██████▋   | 189/285 [05:12<02:12,  1.38s/it]Loading train:  67%|██████▋   | 190/285 [05:13<02:04,  1.32s/it]Loading train:  67%|██████▋   | 191/285 [05:14<02:03,  1.31s/it]Loading train:  67%|██████▋   | 192/285 [05:16<02:06,  1.36s/it]Loading train:  68%|██████▊   | 193/285 [05:17<02:07,  1.39s/it]Loading train:  68%|██████▊   | 194/285 [05:19<02:03,  1.36s/it]Loading train:  68%|██████▊   | 195/285 [05:20<02:06,  1.40s/it]Loading train:  69%|██████▉   | 196/285 [05:22<02:06,  1.43s/it]Loading train:  69%|██████▉   | 197/285 [05:23<02:07,  1.44s/it]Loading train:  69%|██████▉   | 198/285 [05:25<02:11,  1.51s/it]Loading train:  70%|██████▉   | 199/285 [05:26<02:07,  1.48s/it]Loading train:  70%|███████   | 200/285 [05:28<02:05,  1.48s/it]Loading train:  71%|███████   | 201/285 [05:29<02:09,  1.54s/it]Loading train:  71%|███████   | 202/285 [05:31<02:04,  1.50s/it]Loading train:  71%|███████   | 203/285 [05:32<02:00,  1.47s/it]Loading train:  72%|███████▏  | 204/285 [05:33<01:57,  1.45s/it]Loading train:  72%|███████▏  | 205/285 [05:35<01:58,  1.49s/it]Loading train:  72%|███████▏  | 206/285 [05:37<01:59,  1.51s/it]Loading train:  73%|███████▎  | 207/285 [05:39<02:08,  1.64s/it]Loading train:  73%|███████▎  | 208/285 [05:40<02:03,  1.61s/it]Loading train:  73%|███████▎  | 209/285 [05:42<01:58,  1.56s/it]Loading train:  74%|███████▎  | 210/285 [05:43<01:56,  1.55s/it]Loading train:  74%|███████▍  | 211/285 [05:45<02:00,  1.62s/it]Loading train:  74%|███████▍  | 212/285 [05:46<01:46,  1.45s/it]Loading train:  75%|███████▍  | 213/285 [05:47<01:39,  1.38s/it]Loading train:  75%|███████▌  | 214/285 [05:48<01:30,  1.28s/it]Loading train:  75%|███████▌  | 215/285 [05:50<01:31,  1.31s/it]Loading train:  76%|███████▌  | 216/285 [05:51<01:28,  1.29s/it]Loading train:  76%|███████▌  | 217/285 [05:52<01:32,  1.36s/it]Loading train:  76%|███████▋  | 218/285 [05:54<01:28,  1.32s/it]Loading train:  77%|███████▋  | 219/285 [05:55<01:29,  1.35s/it]Loading train:  77%|███████▋  | 220/285 [05:56<01:21,  1.25s/it]Loading train:  78%|███████▊  | 221/285 [05:57<01:14,  1.16s/it]Loading train:  78%|███████▊  | 222/285 [05:58<01:09,  1.10s/it]Loading train:  78%|███████▊  | 223/285 [05:59<01:06,  1.08s/it]Loading train:  79%|███████▊  | 224/285 [06:00<01:04,  1.05s/it]Loading train:  79%|███████▉  | 225/285 [06:01<01:06,  1.11s/it]Loading train:  79%|███████▉  | 226/285 [06:02<01:05,  1.11s/it]Loading train:  80%|███████▉  | 227/285 [06:03<01:01,  1.06s/it]Loading train:  80%|████████  | 228/285 [06:04<00:58,  1.03s/it]Loading train:  80%|████████  | 229/285 [06:05<00:56,  1.02s/it]Loading train:  81%|████████  | 230/285 [06:06<00:56,  1.02s/it]Loading train:  81%|████████  | 231/285 [06:07<00:56,  1.04s/it]Loading train:  81%|████████▏ | 232/285 [06:09<00:58,  1.11s/it]Loading train:  82%|████████▏ | 233/285 [06:10<00:58,  1.12s/it]Loading train:  82%|████████▏ | 234/285 [06:11<00:58,  1.15s/it]Loading train:  82%|████████▏ | 235/285 [06:12<01:00,  1.22s/it]Loading train:  83%|████████▎ | 236/285 [06:13<00:57,  1.18s/it]Loading train:  83%|████████▎ | 237/285 [06:15<00:58,  1.21s/it]Loading train:  84%|████████▎ | 238/285 [06:16<00:57,  1.22s/it]Loading train:  84%|████████▍ | 239/285 [06:17<00:56,  1.23s/it]Loading train:  84%|████████▍ | 240/285 [06:18<00:55,  1.23s/it]Loading train:  85%|████████▍ | 241/285 [06:20<00:54,  1.25s/it]Loading train:  85%|████████▍ | 242/285 [06:21<00:53,  1.25s/it]Loading train:  85%|████████▌ | 243/285 [06:22<00:52,  1.25s/it]Loading train:  86%|████████▌ | 244/285 [06:23<00:51,  1.25s/it]Loading train:  86%|████████▌ | 245/285 [06:25<00:50,  1.27s/it]Loading train:  86%|████████▋ | 246/285 [06:26<00:48,  1.25s/it]Loading train:  87%|████████▋ | 247/285 [06:27<00:47,  1.24s/it]Loading train:  87%|████████▋ | 248/285 [06:28<00:45,  1.22s/it]Loading train:  87%|████████▋ | 249/285 [06:29<00:42,  1.19s/it]Loading train:  88%|████████▊ | 250/285 [06:30<00:39,  1.13s/it]Loading train:  88%|████████▊ | 251/285 [06:31<00:37,  1.09s/it]Loading train:  88%|████████▊ | 252/285 [06:33<00:36,  1.10s/it]Loading train:  89%|████████▉ | 253/285 [06:33<00:33,  1.05s/it]Loading train:  89%|████████▉ | 254/285 [06:35<00:32,  1.05s/it]Loading train:  89%|████████▉ | 255/285 [06:36<00:31,  1.04s/it]Loading train:  90%|████████▉ | 256/285 [06:37<00:30,  1.07s/it]Loading train:  90%|█████████ | 257/285 [06:38<00:29,  1.06s/it]Loading train:  91%|█████████ | 258/285 [06:39<00:28,  1.04s/it]Loading train:  91%|█████████ | 259/285 [06:40<00:28,  1.09s/it]Loading train:  91%|█████████ | 260/285 [06:41<00:28,  1.13s/it]Loading train:  92%|█████████▏| 261/285 [06:42<00:26,  1.11s/it]Loading train:  92%|█████████▏| 262/285 [06:43<00:25,  1.11s/it]Loading train:  92%|█████████▏| 263/285 [06:44<00:24,  1.09s/it]Loading train:  93%|█████████▎| 264/285 [06:45<00:22,  1.09s/it]Loading train:  93%|█████████▎| 265/285 [06:47<00:21,  1.08s/it]Loading train:  93%|█████████▎| 266/285 [06:48<00:20,  1.08s/it]Loading train:  94%|█████████▎| 267/285 [06:49<00:19,  1.09s/it]Loading train:  94%|█████████▍| 268/285 [06:50<00:20,  1.22s/it]Loading train:  94%|█████████▍| 269/285 [06:52<00:19,  1.24s/it]Loading train:  95%|█████████▍| 270/285 [06:53<00:18,  1.26s/it]Loading train:  95%|█████████▌| 271/285 [06:54<00:17,  1.25s/it]Loading train:  95%|█████████▌| 272/285 [06:55<00:16,  1.27s/it]Loading train:  96%|█████████▌| 273/285 [06:57<00:15,  1.26s/it]Loading train:  96%|█████████▌| 274/285 [06:58<00:14,  1.27s/it]Loading train:  96%|█████████▋| 275/285 [06:59<00:12,  1.27s/it]Loading train:  97%|█████████▋| 276/285 [07:00<00:11,  1.25s/it]Loading train:  97%|█████████▋| 277/285 [07:02<00:10,  1.27s/it]Loading train:  98%|█████████▊| 278/285 [07:03<00:08,  1.25s/it]Loading train:  98%|█████████▊| 279/285 [07:04<00:07,  1.25s/it]Loading train:  98%|█████████▊| 280/285 [07:05<00:06,  1.23s/it]Loading train:  99%|█████████▊| 281/285 [07:06<00:04,  1.21s/it]Loading train:  99%|█████████▉| 282/285 [07:08<00:03,  1.19s/it]Loading train:  99%|█████████▉| 283/285 [07:09<00:02,  1.22s/it]Loading train: 100%|█████████▉| 284/285 [07:10<00:01,  1.25s/it]Loading train: 100%|██████████| 285/285 [07:11<00:00,  1.23s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:02, 124.59it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:02, 110.26it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:02, 90.63it/s] concatenating: train:  15%|█▍        | 42/285 [00:00<00:02, 93.77it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:02, 97.03it/s]concatenating: train:  24%|██▍       | 69/285 [00:00<00:01, 108.67it/s]concatenating: train:  28%|██▊       | 80/285 [00:00<00:01, 105.42it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:01, 111.21it/s]concatenating: train:  36%|███▋      | 104/285 [00:01<00:01, 102.89it/s]concatenating: train:  40%|████      | 115/285 [00:01<00:01, 100.62it/s]concatenating: train:  44%|████▍     | 126/285 [00:01<00:01, 94.26it/s] concatenating: train:  48%|████▊     | 136/285 [00:01<00:01, 94.28it/s]concatenating: train:  51%|█████     | 146/285 [00:01<00:01, 94.36it/s]concatenating: train:  55%|█████▍    | 156/285 [00:01<00:01, 91.78it/s]concatenating: train:  58%|█████▊    | 166/285 [00:01<00:01, 92.45it/s]concatenating: train:  62%|██████▏   | 176/285 [00:01<00:01, 91.49it/s]concatenating: train:  66%|██████▌   | 187/285 [00:01<00:01, 96.34it/s]concatenating: train:  70%|██████▉   | 199/285 [00:02<00:00, 99.57it/s]concatenating: train:  74%|███████▎  | 210/285 [00:02<00:00, 98.92it/s]concatenating: train:  77%|███████▋  | 220/285 [00:02<00:00, 98.08it/s]concatenating: train:  82%|████████▏ | 234/285 [00:02<00:00, 105.81it/s]concatenating: train:  86%|████████▌ | 245/285 [00:02<00:00, 106.25it/s]concatenating: train:  90%|████████▉ | 256/285 [00:02<00:00, 100.98it/s]concatenating: train:  94%|█████████▎| 267/285 [00:02<00:00, 86.86it/s] concatenating: train:  97%|█████████▋| 277/285 [00:02<00:00, 90.37it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 99.00it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.61s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.60s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.53s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 135.12it/s] min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________2019-07-08 14:21:41.283948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 14:21:41.284056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 14:21:41.284074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 14:21:41.284083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 14:21:41.284449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

concatenate_5 (Concatenate)     (None, 26, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 33s - loss: 7275.9097 - acc: 0.8457 - mDice: 0.3443 - val_loss: 3472.6192 - val_acc: 0.9201 - val_mDice: 0.4712

Epoch 00001: val_mDice improved from -inf to 0.47123, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 24s - loss: 2321.7640 - acc: 0.9218 - mDice: 0.6268 - val_loss: 2596.9952 - val_acc: 0.9492 - val_mDice: 0.5652

Epoch 00002: val_mDice improved from 0.47123 to 0.56521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 24s - loss: 1845.2647 - acc: 0.9469 - mDice: 0.6877 - val_loss: 2250.4665 - val_acc: 0.9500 - val_mDice: 0.6051

Epoch 00003: val_mDice improved from 0.56521 to 0.60513, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 24s - loss: 1631.0555 - acc: 0.9516 - mDice: 0.7173 - val_loss: 2404.5351 - val_acc: 0.9498 - val_mDice: 0.5917

Epoch 00004: val_mDice did not improve from 0.60513
Epoch 5/300
 - 23s - loss: 1458.6464 - acc: 0.9544 - mDice: 0.7424 - val_loss: 2269.5107 - val_acc: 0.9490 - val_mDice: 0.6061

Epoch 00005: val_mDice improved from 0.60513 to 0.60614, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 24s - loss: 1366.6058 - acc: 0.9558 - mDice: 0.7564 - val_loss: 2250.4901 - val_acc: 0.9490 - val_mDice: 0.6086

Epoch 00006: val_mDice improved from 0.60614 to 0.60865, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 23s - loss: 1294.0058 - acc: 0.9569 - mDice: 0.7674 - val_loss: 2550.4019 - val_acc: 0.9445 - val_mDice: 0.5751

Epoch 00007: val_mDice did not improve from 0.60865
Epoch 8/300
 - 24s - loss: 1234.8388 - acc: 0.9580 - mDice: 0.7766 - val_loss: 2397.7358 - val_acc: 0.9524 - val_mDice: 0.5972

Epoch 00008: val_mDice did not improve from 0.60865
Epoch 9/300
 - 23s - loss: 1221.4218 - acc: 0.9583 - mDice: 0.7792 - val_loss: 2314.1275 - val_acc: 0.9451 - val_mDice: 0.6032

Epoch 00009: val_mDice did not improve from 0.60865
Epoch 10/300
 - 24s - loss: 1140.3422 - acc: 0.9596 - mDice: 0.7916 - val_loss: 2257.3124 - val_acc: 0.9514 - val_mDice: 0.6084

Epoch 00010: val_mDice did not improve from 0.60865
Epoch 11/300
 - 23s - loss: 1106.5546 - acc: 0.9602 - mDice: 0.7972 - val_loss: 2223.9478 - val_acc: 0.9537 - val_mDice: 0.6123

Epoch 00011: val_mDice improved from 0.60865 to 0.61232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 23s - loss: 1074.6176 - acc: 0.9607 - mDice: 0.8023 - val_loss: 2341.0261 - val_acc: 0.9522 - val_mDice: 0.5975

Epoch 00012: val_mDice did not improve from 0.61232
Epoch 13/300
 - 24s - loss: 1043.4707 - acc: 0.9612 - mDice: 0.8073 - val_loss: 2296.1888 - val_acc: 0.9523 - val_mDice: 0.6056

Epoch 00013: val_mDice did not improve from 0.61232
Epoch 14/300
 - 24s - loss: 1017.2441 - acc: 0.9618 - mDice: 0.8117 - val_loss: 9776.1680 - val_acc: 0.9425 - val_mDice: 0.3735

Epoch 00014: val_mDice did not improve from 0.61232
Epoch 15/300
 - 24s - loss: 1325.8803 - acc: 0.9565 - mDice: 0.7653 - val_loss: 2326.9015 - val_acc: 0.9494 - val_mDice: 0.5975

Epoch 00015: val_mDice did not improve from 0.61232
Epoch 16/300
 - 23s - loss: 1045.4189 - acc: 0.9613 - mDice: 0.8070 - val_loss: 2314.0321 - val_acc: 0.9530 - val_mDice: 0.6004

Epoch 00016: val_mDice did not improve from 0.61232
Epoch 17/300
 - 24s - loss: 1003.0373 - acc: 0.9621 - mDice: 0.8140 - val_loss: 2323.0334 - val_acc: 0.9520 - val_mDice: 0.6055

Epoch 00017: val_mDice did not improve from 0.61232
Epoch 18/300
 - 23s - loss: 967.8371 - acc: 0.9626 - mDice: 0.8198 - val_loss: 2281.3020 - val_acc: 0.9499 - val_mDice: 0.6048

Epoch 00018: val_mDice did not improve from 0.61232
Epoch 19/300
 - 25s - loss: 952.6702 - acc: 0.9630 - mDice: 0.8225 - val_loss: 2248.7960 - val_acc: 0.9516 - val_mDice: 0.6070

Epoch 00019: val_mDice did not improve from 0.61232
Epoch 20/300
 - 23s - loss: 931.2809 - acc: 0.9633 - mDice: 0.8259 - val_loss: 2216.0466 - val_acc: 0.9530 - val_mDice: 0.6117

Epoch 00020: val_mDice did not improve from 0.61232
Epoch 21/300
 - 24s - loss: 913.3365 - acc: 0.9637 - mDice: 0.8290 - val_loss: 2234.8206 - val_acc: 0.9525 - val_mDice: 0.6110

Epoch 00021: val_mDice did not improve from 0.61232
Epoch 22/300
 - 24s - loss: 910.1642 - acc: 0.9638 - mDice: 0.8295 - val_loss: 2570.9841 - val_acc: 0.9528 - val_mDice: 0.5825

Epoch 00022: val_mDice did not improve from 0.61232
Epoch 23/300
 - 24s - loss: 894.2885 - acc: 0.9640 - mDice: 0.8322 - val_loss: 2393.5385 - val_acc: 0.9531 - val_mDice: 0.5935

Epoch 00023: val_mDice did not improve from 0.61232
Epoch 24/300
 - 24s - loss: 884.9861 - acc: 0.9642 - mDice: 0.8338 - val_loss: 2311.4261 - val_acc: 0.9535 - val_mDice: 0.6032

Epoch 00024: val_mDice did not improve from 0.61232
Epoch 25/300
 - 23s - loss: 873.9422 - acc: 0.9644 - mDice: 0.8357 - val_loss: 2457.1673 - val_acc: 0.9511 - val_mDice: 0.5915

Epoch 00025: val_mDice did not improve from 0.61232
Epoch 26/300
 - 24s - loss: 866.9462 - acc: 0.9645 - mDice: 0.8369 - val_loss: 2301.2474 - val_acc: 0.9551 - val_mDice: 0.6013

Epoch 00026: val_mDice did not improve from 0.61232
Epoch 27/300
 - 24s - loss: 859.7595 - acc: 0.9647 - mDice: 0.8381 - val_loss: 2370.4138 - val_acc: 0.9512 - val_mDice: 0.5958

Epoch 00027: val_mDice did not improve from 0.61232
Epoch 28/300
 - 24s - loss: 848.0829 - acc: 0.9648 - mDice: 0.8401 - val_loss: 2435.8782 - val_acc: 0.9552 - val_mDice: 0.5950

Epoch 00028: val_mDice did not improve from 0.61232
Epoch 29/300
 - 24s - loss: 840.4966 - acc: 0.9650 - mDice: 0.8414 - val_loss: 2445.6739 - val_acc: 0.9521 - val_mDice: 0.5878

Epoch 00029: val_mDice did not improve from 0.61232
Epoch 30/300
 - 24s - loss: 837.0970 - acc: 0.9652 - mDice: 0.8420 - val_loss: 2419.7570 - val_acc: 0.9506 - val_mDice: 0.5874

Epoch 00030: val_mDice did not improve from 0.61232
Epoch 31/300
 - 24s - loss: 831.9767 - acc: 0.9652 - mDice: 0.8429 - val_loss: 2451.9703 - val_acc: 0.9542 - val_mDice: 0.5911

Epoch 00031: val_mDice did not improve from 0.61232
Epoch 32/300
 - 24s - loss: 820.3290 - acc: 0.9653 - mDice: 0.8449 - val_loss: 2267.1786 - val_acc: 0.9540 - val_mDice: 0.6073

Epoch 00032: val_mDice did not improve from 0.61232
Epoch 33/300
 - 23s - loss: 816.4140 - acc: 0.9655 - mDice: 0.8456 - val_loss: 2560.9985 - val_acc: 0.9534 - val_mDice: 0.5768

Epoch 00033: val_mDice did not improve from 0.61232
Epoch 34/300
 - 23s - loss: 814.1742 - acc: 0.9655 - mDice: 0.8460 - val_loss: 2337.4074 - val_acc: 0.9536 - val_mDice: 0.6025

Epoch 00034: val_mDice did not improve from 0.61232
Epoch 35/300
 - 24s - loss: 804.5080 - acc: 0.9656 - mDice: 0.8477 - val_loss: 2162.5897 - val_acc: 0.9527 - val_mDice: 0.6182

Epoch 00035: val_mDice improved from 0.61232 to 0.61819, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 36/300
 - 24s - loss: 793.9425 - acc: 0.9658 - mDice: 0.8495 - val_loss: 2260.6011 - val_acc: 0.9533 - val_mDice: 0.6031

Epoch 00036: val_mDice did not improve from 0.61819
Epoch 37/300
 - 24s - loss: 793.9247 - acc: 0.9658 - mDice: 0.8495 - val_loss: 2275.3590 - val_acc: 0.9533 - val_mDice: 0.6039

Epoch 00037: val_mDice did not improve from 0.61819
Epoch 38/300
 - 25s - loss: 789.3063 - acc: 0.9659 - mDice: 0.8503 - val_loss: 2311.4055 - val_acc: 0.9520 - val_mDice: 0.6005

Epoch 00038: val_mDice did not improve from 0.61819
Epoch 39/300
 - 24s - loss: 783.5073 - acc: 0.9660 - mDice: 0.8514 - val_loss: 2383.4971 - val_acc: 0.9492 - val_mDice: 0.5909

Epoch 00039: val_mDice did not improve from 0.61819
Epoch 40/300
 - 24s - loss: 778.4443 - acc: 0.9661 - mDice: 0.8522 - val_loss: 2308.0085 - val_acc: 0.9528 - val_mDice: 0.6023

Epoch 00040: val_mDice did not improve from 0.61819
Epoch 41/300
 - 24s - loss: 775.2207 - acc: 0.9661 - mDice: 0.8528 - val_loss: 2340.8011 - val_acc: 0.9537 - val_mDice: 0.5965

Epoch 00041: val_mDice did not improve from 0.61819
Epoch 42/300
 - 24s - loss: 769.4684 - acc: 0.9662 - mDice: 0.8538 - val_loss: 2321.8296 - val_acc: 0.9532 - val_mDice: 0.6016

Epoch 00042: val_mDice did not improve from 0.61819
Epoch 43/300
 - 24s - loss: 763.4635 - acc: 0.9663 - mDice: 0.8548 - val_loss: 2304.7944 - val_acc: 0.9550 - val_mDice: 0.6020

Epoch 00043: val_mDice did not improve from 0.61819
Epoch 44/300
 - 24s - loss: 766.0722 - acc: 0.9663 - mDice: 0.8544 - val_loss: 2260.0152 - val_acc: 0.9545 - val_mDice: 0.6072

Epoch 00044: val_mDice did not improve from 0.61819
Epoch 45/300
 - 24s - loss: 754.9022 - acc: 0.9665 - mDice: 0.8563 - val_loss: 2234.7618 - val_acc: 0.9546 - val_mDice: 0.6105

Epoch 00045: val_mDice did not improve from 0.61819
Epoch 46/300
 - 24s - loss: 763.1019 - acc: 0.9664 - mDice: 0.8549 - val_loss: 2270.1063 - val_acc: 0.9538 - val_mDice: 0.6051

Epoch 00046: val_mDice did not improve from 0.61819
Epoch 47/300
 - 24s - loss: 748.3983 - acc: 0.9666 - mDice: 0.8575 - val_loss: 2302.6015 - val_acc: 0.9534 - val_mDice: 0.6005

Epoch 00047: val_mDice did not improve from 0.61819
Epoch 48/300
 - 24s - loss: 743.8392 - acc: 0.9667 - mDice: 0.8583 - val_loss: 2435.8933 - val_acc: 0.9515 - val_mDice: 0.5848

Epoch 00048: val_mDice did not improve from 0.61819
Epoch 49/300
 - 25s - loss: 743.3863 - acc: 0.9667 - mDice: 0.8584 - val_loss: 2342.8348 - val_acc: 0.9560 - val_mDice: 0.6002

Epoch 00049: val_mDice did not improve from 0.61819
Epoch 50/300
 - 24s - loss: 738.5864 - acc: 0.9667 - mDice: 0.8592 - val_loss: 2533.6964 - val_acc: 0.9523 - val_mDice: 0.5815

Epoch 00050: val_mDice did not improve from 0.61819
Epoch 51/300
 - 25s - loss: 740.8601 - acc: 0.9668 - mDice: 0.8588 - val_loss: 2466.4519 - val_acc: 0.9517 - val_mDice: 0.5810

Epoch 00051: val_mDice did not improve from 0.61819
Epoch 52/300
 - 23s - loss: 736.5397 - acc: 0.9668 - mDice: 0.8596 - val_loss: 2237.6714 - val_acc: 0.9550 - val_mDice: 0.6093

Epoch 00052: val_mDice did not improve from 0.61819
Epoch 53/300
 - 25s - loss: 729.4329 - acc: 0.9669 - mDice: 0.8608 - val_loss: 2353.2501 - val_acc: 0.9536 - val_mDice: 0.5952

Epoch 00053: val_mDice did not improve from 0.61819
Epoch 54/300
 - 24s - loss: 730.6430 - acc: 0.9669 - mDice: 0.8606 - val_loss: 2279.0410 - val_acc: 0.9535 - val_mDice: 0.6035

Epoch 00054: val_mDice did not improve from 0.61819
Epoch 55/300
 - 24s - loss: 723.9699 - acc: 0.9670 - mDice: 0.8618 - val_loss: 2158.3007 - val_acc: 0.9544 - val_mDice: 0.6168

Epoch 00055: val_mDice did not improve from 0.61819
Epoch 56/300
 - 25s - loss: 719.2908 - acc: 0.9671 - mDice: 0.8626 - val_loss: 2254.1865 - val_acc: 0.9536 - val_mDice: 0.6066

Epoch 00056: val_mDice did not improve from 0.61819
Epoch 57/300
 - 24s - loss: 722.7480 - acc: 0.9670 - mDice: 0.8620 - val_loss: 2374.5217 - val_acc: 0.9535 - val_mDice: 0.5975

Epoch 00057: val_mDice did not improve from 0.61819
Epoch 58/300
 - 24s - loss: 716.5697 - acc: 0.9671 - mDice: 0.8631 - val_loss: 2286.1067 - val_acc: 0.9546 - val_mDice: 0.6018

Epoch 00058: val_mDice did not improve from 0.61819
Epoch 59/300
 - 25s - loss: 713.6313 - acc: 0.9672 - mDice: 0.8636 - val_loss: 2401.4211 - val_acc: 0.9543 - val_mDice: 0.5925

Epoch 00059: val_mDice did not improve from 0.61819
Epoch 60/300
 - 24s - loss: 708.8626 - acc: 0.9673 - mDice: 0.8645 - val_loss: 2345.8070 - val_acc: 0.9531 - val_mDice: 0.5985

Epoch 00060: val_mDice did not improve from 0.61819
Epoch 61/300
 - 24s - loss: 706.4747 - acc: 0.9673 - mDice: 0.8648 - val_loss: 2490.7158 - val_acc: 0.9551 - val_mDice: 0.5900

Epoch 00061: val_mDice did not improve from 0.61819
Epoch 62/300
 - 24s - loss: 707.3062 - acc: 0.9673 - mDice: 0.8647 - val_loss: 2348.9715 - val_acc: 0.9553 - val_mDice: 0.6033

Epoch 00062: val_mDice did not improve from 0.61819
Epoch 63/300
 - 24s - loss: 700.4074 - acc: 0.9674 - mDice: 0.8660 - val_loss: 2474.3041 - val_acc: 0.9565 - val_mDice: 0.5923

Epoch 00063: val_mDice did not improve from 0.61819
Epoch 64/300
 - 23s - loss: 698.5775 - acc: 0.9674 - mDice: 0.8663 - val_loss: 2385.8910 - val_acc: 0.9530 - val_mDice: 0.5928

Epoch 00064: val_mDice did not improve from 0.61819
Epoch 65/300
 - 23s - loss: 700.6081 - acc: 0.9674 - mDice: 0.8659 - val_loss: 2455.8646 - val_acc: 0.9537 - val_mDice: 0.5886

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.67s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:37,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:04<09:07,  1.94s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:54,  1.89s/it]predicting train subjects:   1%|▏         | 4/285 [00:08<09:17,  1.98s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:02,  1.94s/it]predicting train subjects:   2%|▏         | 6/285 [00:12<09:32,  2.05s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<10:04,  2.17s/it]predicting train subjects:   3%|▎         | 8/285 [00:16<10:05,  2.18s/it]predicting train subjects:   3%|▎         | 9/285 [00:18<09:41,  2.11s/it]predicting train subjects:   4%|▎         | 10/285 [00:21<10:07,  2.21s/it]predicting train subjects:   4%|▍         | 11/285 [00:23<10:19,  2.26s/it]predicting train subjects:   4%|▍         | 12/285 [00:26<10:33,  2.32s/it]predicting train subjects:   5%|▍         | 13/285 [00:28<10:38,  2.35s/it]predicting train subjects:   5%|▍         | 14/285 [00:30<10:51,  2.40s/it]predicting train subjects:   5%|▌         | 15/285 [00:33<10:54,  2.42s/it]predicting train subjects:   6%|▌         | 16/285 [00:36<11:12,  2.50s/it]predicting train subjects:   6%|▌         | 17/285 [00:38<11:01,  2.47s/it]predicting train subjects:   6%|▋         | 18/285 [00:41<11:04,  2.49s/it]predicting train subjects:   7%|▋         | 19/285 [00:43<10:54,  2.46s/it]predicting train subjects:   7%|▋         | 20/285 [00:46<10:58,  2.49s/it]predicting train subjects:   7%|▋         | 21/285 [00:48<11:12,  2.55s/it]predicting train subjects:   8%|▊         | 22/285 [00:51<10:52,  2.48s/it]predicting train subjects:   8%|▊         | 23/285 [00:53<10:42,  2.45s/it]predicting train subjects:   8%|▊         | 24/285 [00:55<10:33,  2.43s/it]predicting train subjects:   9%|▉         | 25/285 [00:58<10:31,  2.43s/it]predicting train subjects:   9%|▉         | 26/285 [01:00<10:35,  2.45s/it]predicting train subjects:   9%|▉         | 27/285 [01:03<10:37,  2.47s/it]predicting train subjects:  10%|▉         | 28/285 [01:05<10:19,  2.41s/it]predicting train subjects:  10%|█         | 29/285 [01:07<09:58,  2.34s/it]predicting train subjects:  11%|█         | 30/285 [01:09<09:48,  2.31s/it]predicting train subjects:  11%|█         | 31/285 [01:12<09:39,  2.28s/it]predicting train subjects:  11%|█         | 32/285 [01:14<09:28,  2.25s/it]predicting train subjects:  12%|█▏        | 33/285 [01:16<09:22,  2.23s/it]predicting train subjects:  12%|█▏        | 34/285 [01:18<09:24,  2.25s/it]predicting train subjects:  12%|█▏        | 35/285 [01:21<09:23,  2.25s/it]predicting train subjects:  13%|█▎        | 36/285 [01:23<09:16,  2.24s/it]predicting train subjects:  13%|█▎        | 37/285 [01:25<09:15,  2.24s/it]predicting train subjects:  13%|█▎        | 38/285 [01:27<09:10,  2.23s/it]predicting train subjects:  14%|█▎        | 39/285 [01:30<09:18,  2.27s/it]predicting train subjects:  14%|█▍        | 40/285 [01:32<09:20,  2.29s/it]predicting train subjects:  14%|█▍        | 41/285 [01:34<09:10,  2.26s/it]predicting train subjects:  15%|█▍        | 42/285 [01:36<08:56,  2.21s/it]predicting train subjects:  15%|█▌        | 43/285 [01:38<08:58,  2.22s/it]predicting train subjects:  15%|█▌        | 44/285 [01:41<09:01,  2.25s/it]predicting train subjects:  16%|█▌        | 45/285 [01:43<09:10,  2.29s/it]predicting train subjects:  16%|█▌        | 46/285 [01:45<08:44,  2.19s/it]predicting train subjects:  16%|█▋        | 47/285 [01:47<08:25,  2.13s/it]predicting train subjects:  17%|█▋        | 48/285 [01:49<08:15,  2.09s/it]predicting train subjects:  17%|█▋        | 49/285 [01:51<08:11,  2.08s/it]predicting train subjects:  18%|█▊        | 50/285 [01:53<08:08,  2.08s/it]predicting train subjects:  18%|█▊        | 51/285 [01:55<08:06,  2.08s/it]predicting train subjects:  18%|█▊        | 52/285 [01:57<08:00,  2.06s/it]predicting train subjects:  19%|█▊        | 53/285 [01:59<07:54,  2.05s/it]predicting train subjects:  19%|█▉        | 54/285 [02:01<07:52,  2.04s/it]predicting train subjects:  19%|█▉        | 55/285 [02:03<07:45,  2.02s/it]predicting train subjects:  20%|█▉        | 56/285 [02:05<07:37,  2.00s/it]predicting train subjects:  20%|██        | 57/285 [02:07<07:31,  1.98s/it]predicting train subjects:  20%|██        | 58/285 [02:09<07:33,  2.00s/it]predicting train subjects:  21%|██        | 59/285 [02:11<07:25,  1.97s/it]predicting train subjects:  21%|██        | 60/285 [02:13<07:16,  1.94s/it]predicting train subjects:  21%|██▏       | 61/285 [02:15<07:10,  1.92s/it]predicting train subjects:  22%|██▏       | 62/285 [02:17<07:09,  1.93s/it]predicting train subjects:  22%|██▏       | 63/285 [02:19<07:19,  1.98s/it]predicting train subjects:  22%|██▏       | 64/285 [02:21<07:23,  2.01s/it]predicting train subjects:  23%|██▎       | 65/285 [02:23<07:31,  2.05s/it]predicting train subjects:  23%|██▎       | 66/285 [02:26<07:48,  2.14s/it]predicting train subjects:  24%|██▎       | 67/285 [02:28<07:38,  2.10s/it]predicting train subjects:  24%|██▍       | 68/285 [02:30<07:31,  2.08s/it]predicting train subjects:  24%|██▍       | 69/285 [02:32<07:27,  2.07s/it]predicting train subjects:  25%|██▍       | 70/285 [02:34<07:23,  2.06s/it]predicting train subjects:  25%|██▍       | 71/285 [02:36<07:22,  2.07s/it]predicting train subjects:  25%|██▌       | 72/285 [02:38<07:15,  2.04s/it]predicting train subjects:  26%|██▌       | 73/285 [02:40<07:15,  2.05s/it]predicting train subjects:  26%|██▌       | 74/285 [02:42<07:15,  2.07s/it]predicting train subjects:  26%|██▋       | 75/285 [02:44<07:09,  2.05s/it]predicting train subjects:  27%|██▋       | 76/285 [02:46<07:06,  2.04s/it]predicting train subjects:  27%|██▋       | 77/285 [02:48<07:13,  2.09s/it]predicting train subjects:  27%|██▋       | 78/285 [02:50<07:12,  2.09s/it]predicting train subjects:  28%|██▊       | 79/285 [02:52<07:08,  2.08s/it]predicting train subjects:  28%|██▊       | 80/285 [02:54<07:02,  2.06s/it]predicting train subjects:  28%|██▊       | 81/285 [02:56<06:57,  2.05s/it]predicting train subjects:  29%|██▉       | 82/285 [02:58<06:50,  2.02s/it]predicting train subjects:  29%|██▉       | 83/285 [03:00<06:46,  2.01s/it]predicting train subjects:  29%|██▉       | 84/285 [03:02<06:53,  2.06s/it]predicting train subjects:  30%|██▉       | 85/285 [03:05<07:04,  2.12s/it]predicting train subjects:  30%|███       | 86/285 [03:07<07:12,  2.17s/it]predicting train subjects:  31%|███       | 87/285 [03:09<07:07,  2.16s/it]predicting train subjects:  31%|███       | 88/285 [03:11<07:09,  2.18s/it]predicting train subjects:  31%|███       | 89/285 [03:14<07:08,  2.19s/it]predicting train subjects:  32%|███▏      | 90/285 [03:16<07:03,  2.17s/it]predicting train subjects:  32%|███▏      | 91/285 [03:18<07:00,  2.17s/it]predicting train subjects:  32%|███▏      | 92/285 [03:20<07:06,  2.21s/it]predicting train subjects:  33%|███▎      | 93/285 [03:22<07:06,  2.22s/it]predicting train subjects:  33%|███▎      | 94/285 [03:25<07:02,  2.21s/it]predicting train subjects:  33%|███▎      | 95/285 [03:27<06:58,  2.20s/it]predicting train subjects:  34%|███▎      | 96/285 [03:29<06:58,  2.21s/it]predicting train subjects:  34%|███▍      | 97/285 [03:31<07:03,  2.25s/it]predicting train subjects:  34%|███▍      | 98/285 [03:34<07:02,  2.26s/it]predicting train subjects:  35%|███▍      | 99/285 [03:36<06:56,  2.24s/it]predicting train subjects:  35%|███▌      | 100/285 [03:38<06:48,  2.21s/it]predicting train subjects:  35%|███▌      | 101/285 [03:40<06:50,  2.23s/it]predicting train subjects:  36%|███▌      | 102/285 [03:42<06:42,  2.20s/it]predicting train subjects:  36%|███▌      | 103/285 [03:45<06:38,  2.19s/it]predicting train subjects:  36%|███▋      | 104/285 [03:47<06:33,  2.18s/it]predicting train subjects:  37%|███▋      | 105/285 [03:49<06:30,  2.17s/it]predicting train subjects:  37%|███▋      | 106/285 [03:51<06:34,  2.20s/it]predicting train subjects:  38%|███▊      | 107/285 [03:53<06:33,  2.21s/it]predicting train subjects:  38%|███▊      | 108/285 [03:55<06:27,  2.19s/it]predicting train subjects:  38%|███▊      | 109/285 [03:58<06:22,  2.17s/it]predicting train subjects:  39%|███▊      | 110/285 [04:00<06:22,  2.19s/it]predicting train subjects:  39%|███▉      | 111/285 [04:02<06:17,  2.17s/it]predicting train subjects:  39%|███▉      | 112/285 [04:04<06:13,  2.16s/it]predicting train subjects:  40%|███▉      | 113/285 [04:06<06:15,  2.18s/it]predicting train subjects:  40%|████      | 114/285 [04:09<06:14,  2.19s/it]predicting train subjects:  40%|████      | 115/285 [04:11<06:13,  2.20s/it]predicting train subjects:  41%|████      | 116/285 [04:13<06:13,  2.21s/it]predicting train subjects:  41%|████      | 117/285 [04:15<06:04,  2.17s/it]predicting train subjects:  41%|████▏     | 118/285 [04:17<06:07,  2.20s/it]predicting train subjects:  42%|████▏     | 119/285 [04:20<06:06,  2.21s/it]predicting train subjects:  42%|████▏     | 120/285 [04:22<06:03,  2.20s/it]predicting train subjects:  42%|████▏     | 121/285 [04:24<05:45,  2.11s/it]predicting train subjects:  43%|████▎     | 122/285 [04:25<05:27,  2.01s/it]predicting train subjects:  43%|████▎     | 123/285 [04:27<05:07,  1.90s/it]predicting train subjects:  44%|████▎     | 124/285 [04:29<05:11,  1.93s/it]predicting train subjects:  44%|████▍     | 125/285 [04:31<05:08,  1.93s/it]predicting train subjects:  44%|████▍     | 126/285 [04:33<05:09,  1.95s/it]predicting train subjects:  45%|████▍     | 127/285 [04:35<05:09,  1.96s/it]predicting train subjects:  45%|████▍     | 128/285 [04:37<05:10,  1.98s/it]predicting train subjects:  45%|████▌     | 129/285 [04:39<05:09,  1.99s/it]predicting train subjects:  46%|████▌     | 130/285 [04:41<05:08,  1.99s/it]predicting train subjects:  46%|████▌     | 131/285 [04:43<05:05,  1.99s/it]predicting train subjects:  46%|████▋     | 132/285 [04:45<05:01,  1.97s/it]predicting train subjects:  47%|████▋     | 133/285 [04:47<04:59,  1.97s/it]predicting train subjects:  47%|████▋     | 134/285 [04:49<04:57,  1.97s/it]predicting train subjects:  47%|████▋     | 135/285 [04:51<04:57,  1.98s/it]predicting train subjects:  48%|████▊     | 136/285 [04:53<04:48,  1.94s/it]predicting train subjects:  48%|████▊     | 137/285 [04:55<04:45,  1.93s/it]predicting train subjects:  48%|████▊     | 138/285 [04:56<04:40,  1.91s/it]predicting train subjects:  49%|████▉     | 139/285 [04:58<04:32,  1.87s/it]predicting train subjects:  49%|████▉     | 140/285 [05:00<04:34,  1.89s/it]predicting train subjects:  49%|████▉     | 141/285 [05:02<04:37,  1.93s/it]predicting train subjects:  50%|████▉     | 142/285 [05:04<04:36,  1.93s/it]predicting train subjects:  50%|█████     | 143/285 [05:06<04:29,  1.90s/it]predicting train subjects:  51%|█████     | 144/285 [05:08<04:24,  1.88s/it]predicting train subjects:  51%|█████     | 145/285 [05:10<04:21,  1.87s/it]predicting train subjects:  51%|█████     | 146/285 [05:11<04:12,  1.82s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:13<04:09,  1.81s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:15<04:11,  1.84s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:17<04:11,  1.85s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:19<04:11,  1.86s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:21<04:04,  1.82s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:22<04:05,  1.85s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:24<04:01,  1.83s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:26<04:01,  1.84s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:28<04:03,  1.87s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:30<04:03,  1.89s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:32<04:01,  1.88s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:34<03:54,  1.85s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:36<03:56,  1.88s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:37<03:54,  1.88s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:39<03:47,  1.84s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:41<03:50,  1.87s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:43<03:45,  1.85s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:45<03:38,  1.81s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:46<03:33,  1.78s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:48<03:36,  1.82s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:50<03:34,  1.82s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:52<03:29,  1.79s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:54<03:28,  1.79s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:55<03:27,  1.80s/it]predicting train subjects:  60%|██████    | 171/285 [05:57<03:24,  1.80s/it]predicting train subjects:  60%|██████    | 172/285 [05:59<03:22,  1.79s/it]predicting train subjects:  61%|██████    | 173/285 [06:01<03:24,  1.83s/it]predicting train subjects:  61%|██████    | 174/285 [06:03<03:23,  1.83s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:04<03:17,  1.80s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:06<03:14,  1.79s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:08<03:10,  1.76s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:10<03:07,  1.75s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:11<03:05,  1.75s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:13<03:00,  1.71s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:15<02:59,  1.72s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:16<02:56,  1.72s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:18<02:58,  1.75s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:20<02:59,  1.78s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:22<02:54,  1.75s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:24<02:54,  1.76s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:25<02:54,  1.78s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:27<02:52,  1.78s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:29<02:51,  1.79s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:31<02:49,  1.78s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:33<02:46,  1.77s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:34<02:43,  1.76s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:36<02:39,  1.73s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:37<02:32,  1.68s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:39<02:30,  1.67s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:41<02:36,  1.76s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:43<02:48,  1.91s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:46<02:54,  2.01s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:48<02:51,  1.99s/it]predicting train subjects:  70%|███████   | 200/285 [06:50<02:50,  2.01s/it]predicting train subjects:  71%|███████   | 201/285 [06:52<02:49,  2.02s/it]predicting train subjects:  71%|███████   | 202/285 [06:54<02:48,  2.03s/it]predicting train subjects:  71%|███████   | 203/285 [06:56<02:50,  2.08s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:58<02:49,  2.09s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:00<02:46,  2.08s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:02<02:43,  2.07s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:04<02:40,  2.06s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:06<02:43,  2.12s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:08<02:37,  2.07s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:11<02:37,  2.10s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:13<02:33,  2.07s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:15<02:30,  2.06s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:16<02:23,  2.00s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:18<02:19,  1.97s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:20<02:14,  1.92s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:22<02:08,  1.86s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:24<02:06,  1.86s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:25<02:02,  1.83s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:27<01:56,  1.77s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:29<01:51,  1.71s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:30<01:48,  1.70s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:32<01:46,  1.69s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:34<01:43,  1.67s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:35<01:40,  1.65s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:37<01:38,  1.64s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:38<01:35,  1.62s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:40<01:32,  1.60s/it]predicting train subjects:  80%|████████  | 228/285 [07:42<01:32,  1.62s/it]predicting train subjects:  80%|████████  | 229/285 [07:43<01:30,  1.62s/it]predicting train subjects:  81%|████████  | 230/285 [07:45<01:28,  1.61s/it]predicting train subjects:  81%|████████  | 231/285 [07:47<01:27,  1.62s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:48<01:31,  1.73s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:50<01:33,  1.80s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:52<01:34,  1.85s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:54<01:34,  1.89s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:56<01:32,  1.89s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:58<01:31,  1.91s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:00<01:30,  1.93s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:02<01:30,  1.97s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:04<01:29,  1.99s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:06<01:28,  2.01s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:09<01:27,  2.04s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:11<01:25,  2.04s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:13<01:23,  2.04s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:15<01:22,  2.05s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:17<01:19,  2.05s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:19<01:17,  2.04s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:21<01:15,  2.05s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:23<01:12,  2.02s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:24<01:06,  1.89s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:26<01:01,  1.82s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:28<00:57,  1.75s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:29<00:54,  1.70s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:31<00:51,  1.67s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:32<00:49,  1.64s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:34<00:47,  1.65s/it]predicting train subjects:  90%|█████████ | 257/285 [08:36<00:45,  1.64s/it]predicting train subjects:  91%|█████████ | 258/285 [08:37<00:43,  1.61s/it]predicting train subjects:  91%|█████████ | 259/285 [08:39<00:41,  1.61s/it]predicting train subjects:  91%|█████████ | 260/285 [08:40<00:39,  1.60s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:42<00:38,  1.59s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:44<00:37,  1.63s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:45<00:36,  1.65s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:47<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:49<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:50<00:31,  1.66s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:52<00:29,  1.65s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:54<00:30,  1.79s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:56<00:30,  1.90s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:58<00:29,  1.97s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:00<00:28,  2.01s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:03<00:26,  2.04s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:05<00:24,  2.06s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:07<00:22,  2.07s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:09<00:21,  2.10s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:11<00:18,  2.08s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:13<00:16,  2.10s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:15<00:14,  2.09s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:17<00:12,  2.10s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:19<00:10,  2.10s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:22<00:08,  2.11s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:24<00:06,  2.11s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:26<00:04,  2.10s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:28<00:02,  2.10s/it]predicting train subjects: 100%|██████████| 285/285 [09:30<00:00,  2.10s/it]
Epoch 00065: val_mDice did not improve from 0.61819
Restoring model weights from the end of the best epoch
Epoch 00065: early stopping
{'val_loss': [3472.619150172399, 2596.995154013181, 2250.466541823062, 2404.535100329522, 2269.510743551414, 2250.49008161662, 2550.4019127531424, 2397.735762100646, 2314.1274686845322, 2257.3124318042946, 2223.9477825484464, 2341.026083493366, 2296.1887520731493, 9776.16802876222, 2326.901534948935, 2314.0321324524266, 2323.0334308986558, 2281.3020469622907, 2248.796038920653, 2216.046644498516, 2234.820643931128, 2570.9841267676325, 2393.5384923839038, 2311.426131775925, 2457.1672949764315, 2301.2474249301677, 2370.413806084148, 2435.878172464211, 2445.6739263268155, 2419.756979148481, 2451.9702830394554, 2267.1785609069484, 2560.9985406119063, 2337.407395687849, 2162.5896691689945, 2260.601111044431, 2275.3589685535962, 2311.4054793885302, 2383.497137144291, 2308.0084658148567, 2340.801137231582, 2321.829591207664, 2304.794372217615, 2260.0152103701116, 2234.7617787622207, 2270.1063457467703, 2302.6014670260124, 2435.8932532624826, 2342.8348149986905, 2533.6964445487083, 2466.451863379452, 2237.671362168296, 2353.2501350274965, 2279.0409992580308, 2158.300650314246, 2254.186456605709, 2374.5216807786314, 2286.1066867252966, 2401.421052559794, 2345.806970692214, 2490.715846226868, 2348.971521473464, 2474.304135114787, 2385.89096052287, 2455.8646383445357], 'val_acc': [0.920050179492162, 0.9491566659351967, 0.9499872000523786, 0.9498012565367715, 0.9490347487966442, 0.9489706947816817, 0.9444811820317913, 0.9523693276517218, 0.9450865171475118, 0.9513817789168332, 0.9537308499133786, 0.9522453876181022, 0.9522846167979959, 0.942508094803581, 0.9494210874568151, 0.9530408049428929, 0.9520242946773934, 0.9499169534811095, 0.9516173198236434, 0.9530304567107941, 0.9525490779450486, 0.9528445494907528, 0.9530759217352841, 0.9535139126484621, 0.951109055367262, 0.9550758810016696, 0.9512391966148461, 0.9551626443862915, 0.9521441423027209, 0.9505615370899605, 0.9541936456824148, 0.9540324990309816, 0.953416829335623, 0.9535738253060666, 0.9527453710247018, 0.9533155913459522, 0.9533031942458127, 0.9519974642625734, 0.9492165566156696, 0.9528342082513778, 0.9536957367838428, 0.9532246776133276, 0.9550324755007994, 0.9545035928321284, 0.9546110117235663, 0.9538011004804899, 0.9533899509706977, 0.9515263787860977, 0.9560282992917066, 0.9523094233187883, 0.9517102764305456, 0.9550056047945715, 0.9535862423854167, 0.9535469998860492, 0.9543651492236047, 0.9536399558269778, 0.9534705494369209, 0.9546378644485047, 0.9543320876260043, 0.9531151955354147, 0.955111003454837, 0.9552907357668744, 0.9564559895899043, 0.9530160070797584, 0.9537122722444588], 'val_mDice': [0.4712337914791853, 0.5652113373719114, 0.605132152914335, 0.5916716026860243, 0.6061404720365002, 0.6086458503866995, 0.5750517721948677, 0.5971771525271112, 0.6031978759685708, 0.6083951202850768, 0.6123162028509811, 0.5974504538088538, 0.6056262071572203, 0.37347623722513296, 0.5974695073159714, 0.6004426978819863, 0.6055318090502776, 0.6047817788310557, 0.6069819504322287, 0.6116994186486612, 0.6110072602106872, 0.5824545768386159, 0.5935312399651085, 0.6031765078699123, 0.5915335310238033, 0.601294551148761, 0.5957869044895279, 0.5949680805206299, 0.5877611207562452, 0.5873999555683669, 0.5911128414409786, 0.6072791798154735, 0.5768198976969586, 0.6024627792102665, 0.6181891833603715, 0.6030769291536768, 0.6038586194288798, 0.6005128958371765, 0.5909373960015494, 0.6022540061167498, 0.5964536683519459, 0.6015511055232426, 0.6019765678064783, 0.6071881715145857, 0.6105417765718598, 0.6051336729992701, 0.6004577622067329, 0.5848022619439237, 0.6001789929480527, 0.5814710938730719, 0.5809725486366443, 0.6092774222017, 0.5952468071569944, 0.6035473366689416, 0.6167601620018816, 0.6065789198076259, 0.5975057046506658, 0.601781049920194, 0.5924858357653272, 0.5984639455486276, 0.5900482445455796, 0.603323652091639, 0.5922901320723848, 0.5928291525254702, 0.5886152759610608], 'loss': [7275.909687687749, 2321.7639577406553, 1845.2646958003293, 1631.0555479125412, 1458.6464131313057, 1366.6058091587, 1294.0058063211852, 1234.8387832787034, 1221.4217736924775, 1140.3421537117672, 1106.5545933859896, 1074.6176108368652, 1043.4707170931786, 1017.2440728583916, 1325.8802568751362, 1045.418856311069, 1003.0373096298817, 967.8371049099696, 952.6702306708066, 931.2809466724594, 913.3364503036805, 910.1642167682605, 894.2884556853585, 884.9861328597033, 873.942178020121, 866.9462124037266, 859.7595125988582, 848.0828646519665, 840.4965739169417, 837.0969911991566, 831.9767116390602, 820.3290158370424, 816.4140410358094, 814.1741986141493, 804.5079941345218, 793.9424751846433, 793.9246721443777, 789.3063345600023, 783.5073421426955, 778.4443174152033, 775.2206857030048, 769.4683714513912, 763.4635340055539, 766.0722439397518, 754.9022124202012, 763.1018574971608, 748.3982805325103, 743.8392024686618, 743.3863174623799, 738.5863710886175, 740.8601404907565, 736.5397044245658, 729.4329480308897, 730.6430181176385, 723.9698962449547, 719.2908160233185, 722.7479937912676, 716.5696773451142, 713.6312709908283, 708.8626443565713, 706.4746888759421, 707.3062045565488, 700.4073893838598, 698.5774680352096, 700.6080555871943], 'acc': [0.8457239611262714, 0.9217933504892184, 0.9468857706076802, 0.9516140826354456, 0.9543758174879775, 0.9558476950730005, 0.9569111830735932, 0.958013455999306, 0.9583415634056484, 0.9596418133099337, 0.9602418777716848, 0.9607476554309858, 0.9612492880857066, 0.9617704351537466, 0.956549373313068, 0.9612632636300399, 0.9620991453165634, 0.9626382222187804, 0.9630243986444103, 0.9633170177776708, 0.9636506229390714, 0.9637769556442874, 0.9640437942153456, 0.9642100427562482, 0.9643859398124148, 0.9644586523239743, 0.964685306343389, 0.964848977049142, 0.9649904940254411, 0.96515470874653, 0.9651902185618166, 0.9653292595966859, 0.9654532300446211, 0.9654736351125427, 0.9655784517323736, 0.9657894981971565, 0.965833124729564, 0.9659024509370252, 0.9660179840895768, 0.9660535950162339, 0.966122741659874, 0.9662294747957859, 0.9663260922044472, 0.966333746377708, 0.9664902895158246, 0.9663927618613606, 0.9665777226249076, 0.9666721498282554, 0.9667181734243813, 0.9667482848851991, 0.9667859293654765, 0.9667533824798439, 0.9668629510516559, 0.9668769079429588, 0.9669986858677484, 0.9670523241495854, 0.9670234809779606, 0.9670864447718397, 0.9672022801742504, 0.967289127946309, 0.9672717257338368, 0.9673117489981227, 0.9673710280816206, 0.9674077434845203, 0.9673859312782217], 'mDice': [0.3443254302519822, 0.6267834305211379, 0.6877260301167796, 0.7173160218730237, 0.7424176931153987, 0.7564217214990523, 0.7674306198361328, 0.7766000227622754, 0.7791835517445964, 0.7916315740395278, 0.7972381169821571, 0.8022873586613942, 0.8073303393792771, 0.8117187254783745, 0.7652771526559182, 0.8069676914594771, 0.8140295827728322, 0.819792778629226, 0.8224525505742907, 0.8259248584030072, 0.8289840749085167, 0.8294801309726693, 0.8322398405982468, 0.8338042995903878, 0.8357191065558746, 0.8369273023988146, 0.8381463938838197, 0.8401050128732123, 0.8414101630252896, 0.842042566378076, 0.842882659231277, 0.8449130797495243, 0.8456112738398645, 0.8460167404950999, 0.8476704986914396, 0.8494874507953292, 0.849505871860597, 0.8503156676835714, 0.8513505505935071, 0.8521648288312013, 0.8527631711858555, 0.8537729037826691, 0.8548124012270042, 0.8543685343061538, 0.8562973545992351, 0.8549328154127138, 0.857454695918969, 0.8582721563519414, 0.8583715974515213, 0.8592172405616006, 0.858809426156636, 0.859566129569972, 0.8608228729919218, 0.8605987657636386, 0.8617650261924363, 0.8626097425072614, 0.8619771462095556, 0.863086270189423, 0.8636065697911505, 0.864451948986497, 0.8648478440953771, 0.8647187424929247, 0.8659559572861674, 0.8662868913764833, 0.8659230189855552]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:27,  1.37s/it]Loading train:   1%|          | 2/285 [00:02<06:46,  1.44s/it]Loading train:   1%|          | 3/285 [00:04<06:38,  1.41s/it]Loading train:   1%|▏         | 4/285 [00:06<07:00,  1.50s/it]Loading train:   2%|▏         | 5/285 [00:07<06:47,  1.46s/it]Loading train:   2%|▏         | 6/285 [00:09<07:01,  1.51s/it]Loading train:   2%|▏         | 7/285 [00:10<07:14,  1.56s/it]Loading train:   3%|▎         | 8/285 [00:12<07:19,  1.59s/it]Loading train:   3%|▎         | 9/285 [00:14<07:36,  1.65s/it]Loading train:   4%|▎         | 10/285 [00:15<07:03,  1.54s/it]Loading train:   4%|▍         | 11/285 [00:17<07:16,  1.59s/it]Loading train:   4%|▍         | 12/285 [00:18<06:47,  1.49s/it]Loading train:   5%|▍         | 13/285 [00:19<06:31,  1.44s/it]Loading train:   5%|▍         | 14/285 [00:20<06:10,  1.37s/it]Loading train:   5%|▌         | 15/285 [00:22<05:47,  1.29s/it]Loading train:   6%|▌         | 16/285 [00:23<05:35,  1.25s/it]Loading train:   6%|▌         | 17/285 [00:24<05:30,  1.23s/it]Loading train:   6%|▋         | 18/285 [00:25<05:26,  1.22s/it]Loading train:   7%|▋         | 19/285 [00:26<05:21,  1.21s/it]Loading train:   7%|▋         | 20/285 [00:28<05:25,  1.23s/it]Loading train:   7%|▋         | 21/285 [00:29<05:23,  1.22s/it]Loading train:   8%|▊         | 22/285 [00:30<05:13,  1.19s/it]Loading train:   8%|▊         | 23/285 [00:31<05:19,  1.22s/it]Loading train:   8%|▊         | 24/285 [00:32<05:10,  1.19s/it]Loading train:   9%|▉         | 25/285 [00:33<05:07,  1.18s/it]Loading train:   9%|▉         | 26/285 [00:35<05:05,  1.18s/it]Loading train:   9%|▉         | 27/285 [00:36<04:57,  1.15s/it]Loading train:  10%|▉         | 28/285 [00:37<05:06,  1.19s/it]Loading train:  10%|█         | 29/285 [00:38<05:03,  1.19s/it]Loading train:  11%|█         | 30/285 [00:39<04:58,  1.17s/it]Loading train:  11%|█         | 31/285 [00:40<04:55,  1.16s/it]Loading train:  11%|█         | 32/285 [00:42<05:01,  1.19s/it]Loading train:  12%|█▏        | 33/285 [00:43<04:45,  1.13s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:39,  1.11s/it]Loading train:  12%|█▏        | 35/285 [00:45<04:36,  1.11s/it]Loading train:  13%|█▎        | 36/285 [00:46<04:31,  1.09s/it]Loading train:  13%|█▎        | 37/285 [00:47<04:34,  1.11s/it]Loading train:  13%|█▎        | 38/285 [00:48<04:31,  1.10s/it]Loading train:  14%|█▎        | 39/285 [00:49<04:22,  1.07s/it]Loading train:  14%|█▍        | 40/285 [00:50<04:26,  1.09s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:28,  1.10s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:26,  1.10s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:21,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:55<04:18,  1.07s/it]Loading train:  16%|█▌        | 45/285 [00:56<04:24,  1.10s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:20,  1.09s/it]Loading train:  16%|█▋        | 47/285 [00:58<04:11,  1.06s/it]Loading train:  17%|█▋        | 48/285 [00:59<04:05,  1.04s/it]Loading train:  17%|█▋        | 49/285 [01:00<04:01,  1.02s/it]Loading train:  18%|█▊        | 50/285 [01:01<03:55,  1.00s/it]Loading train:  18%|█▊        | 51/285 [01:02<03:58,  1.02s/it]Loading train:  18%|█▊        | 52/285 [01:03<03:53,  1.00s/it]Loading train:  19%|█▊        | 53/285 [01:04<03:54,  1.01s/it]Loading train:  19%|█▉        | 54/285 [01:05<03:46,  1.02it/s]Loading train:  19%|█▉        | 55/285 [01:06<03:46,  1.02it/s]Loading train:  20%|█▉        | 56/285 [01:07<03:48,  1.00it/s]Loading train:  20%|██        | 57/285 [01:08<03:45,  1.01it/s]Loading train:  20%|██        | 58/285 [01:09<03:45,  1.01it/s]Loading train:  21%|██        | 59/285 [01:10<03:44,  1.01it/s]Loading train:  21%|██        | 60/285 [01:11<03:37,  1.03it/s]Loading train:  21%|██▏       | 61/285 [01:11<03:34,  1.04it/s]Loading train:  22%|██▏       | 62/285 [01:13<03:42,  1.00it/s]Loading train:  22%|██▏       | 63/285 [01:14<03:40,  1.01it/s]Loading train:  22%|██▏       | 64/285 [01:15<04:04,  1.11s/it]Loading train:  23%|██▎       | 65/285 [01:17<04:37,  1.26s/it]Loading train:  23%|██▎       | 66/285 [01:18<05:03,  1.38s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:34,  1.26s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:15,  1.18s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:02,  1.12s/it]Loading train:  25%|██▍       | 70/285 [01:22<03:49,  1.07s/it]Loading train:  25%|██▍       | 71/285 [01:23<03:39,  1.02s/it]Loading train:  25%|██▌       | 72/285 [01:24<03:34,  1.01s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:25,  1.03it/s]Loading train:  26%|██▌       | 74/285 [01:26<03:23,  1.03it/s]Loading train:  26%|██▋       | 75/285 [01:27<03:21,  1.04it/s]Loading train:  27%|██▋       | 76/285 [01:28<03:21,  1.04it/s]Loading train:  27%|██▋       | 77/285 [01:29<03:18,  1.05it/s]Loading train:  27%|██▋       | 78/285 [01:30<03:22,  1.02it/s]Loading train:  28%|██▊       | 79/285 [01:31<03:24,  1.01it/s]Loading train:  28%|██▊       | 80/285 [01:32<03:19,  1.03it/s]Loading train:  28%|██▊       | 81/285 [01:33<03:14,  1.05it/s]Loading train:  29%|██▉       | 82/285 [01:34<03:14,  1.04it/s]Loading train:  29%|██▉       | 83/285 [01:35<03:13,  1.04it/s]Loading train:  29%|██▉       | 84/285 [01:36<03:14,  1.03it/s]Loading train:  30%|██▉       | 85/285 [01:37<03:22,  1.01s/it]Loading train:  30%|███       | 86/285 [01:38<03:24,  1.03s/it]Loading train:  31%|███       | 87/285 [01:39<03:27,  1.05s/it]Loading train:  31%|███       | 88/285 [01:40<03:23,  1.03s/it]Loading train:  31%|███       | 89/285 [01:41<03:20,  1.02s/it]Loading train:  32%|███▏      | 90/285 [01:42<03:27,  1.06s/it]Loading train:  32%|███▏      | 91/285 [01:43<03:37,  1.12s/it]Loading train:  32%|███▏      | 92/285 [01:44<03:41,  1.15s/it]Loading train:  33%|███▎      | 93/285 [01:45<03:31,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:47<03:31,  1.11s/it]Loading train:  33%|███▎      | 95/285 [01:48<03:28,  1.10s/it]Loading train:  34%|███▎      | 96/285 [01:49<03:30,  1.11s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:26,  1.10s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:32,  1.14s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:24,  1.10s/it]Loading train:  35%|███▌      | 100/285 [01:53<03:23,  1.10s/it]Loading train:  35%|███▌      | 101/285 [01:54<03:24,  1.11s/it]Loading train:  36%|███▌      | 102/285 [01:55<03:20,  1.10s/it]Loading train:  36%|███▌      | 103/285 [01:57<03:30,  1.16s/it]Loading train:  36%|███▋      | 104/285 [01:58<03:27,  1.15s/it]Loading train:  37%|███▋      | 105/285 [01:59<03:25,  1.14s/it]Loading train:  37%|███▋      | 106/285 [02:00<03:23,  1.14s/it]Loading train:  38%|███▊      | 107/285 [02:01<03:18,  1.12s/it]Loading train:  38%|███▊      | 108/285 [02:02<03:13,  1.10s/it]Loading train:  38%|███▊      | 109/285 [02:03<03:08,  1.07s/it]Loading train:  39%|███▊      | 110/285 [02:04<03:03,  1.05s/it]Loading train:  39%|███▉      | 111/285 [02:05<03:06,  1.07s/it]Loading train:  39%|███▉      | 112/285 [02:06<03:05,  1.07s/it]Loading train:  40%|███▉      | 113/285 [02:07<03:05,  1.08s/it]Loading train:  40%|████      | 114/285 [02:08<03:00,  1.06s/it]Loading train:  40%|████      | 115/285 [02:09<02:58,  1.05s/it]Loading train:  41%|████      | 116/285 [02:10<02:53,  1.02s/it]Loading train:  41%|████      | 117/285 [02:11<02:53,  1.03s/it]Loading train:  41%|████▏     | 118/285 [02:13<02:52,  1.03s/it]Loading train:  42%|████▏     | 119/285 [02:14<02:56,  1.07s/it]Loading train:  42%|████▏     | 120/285 [02:15<02:56,  1.07s/it]Loading train:  42%|████▏     | 121/285 [02:16<03:12,  1.17s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:17,  1.21s/it]Loading train:  43%|████▎     | 123/285 [02:19<03:24,  1.26s/it]Loading train:  44%|████▎     | 124/285 [02:20<03:12,  1.20s/it]Loading train:  44%|████▍     | 125/285 [02:21<03:00,  1.13s/it]Loading train:  44%|████▍     | 126/285 [02:22<02:53,  1.09s/it]Loading train:  45%|████▍     | 127/285 [02:23<02:46,  1.06s/it]Loading train:  45%|████▍     | 128/285 [02:24<02:41,  1.03s/it]Loading train:  45%|████▌     | 129/285 [02:25<02:36,  1.00s/it]Loading train:  46%|████▌     | 130/285 [02:26<02:35,  1.00s/it]Loading train:  46%|████▌     | 131/285 [02:27<02:26,  1.05it/s]Loading train:  46%|████▋     | 132/285 [02:28<02:29,  1.02it/s]Loading train:  47%|████▋     | 133/285 [02:29<02:28,  1.02it/s]Loading train:  47%|████▋     | 134/285 [02:30<02:30,  1.01it/s]Loading train:  47%|████▋     | 135/285 [02:31<02:34,  1.03s/it]Loading train:  48%|████▊     | 136/285 [02:32<02:37,  1.06s/it]Loading train:  48%|████▊     | 137/285 [02:33<02:33,  1.04s/it]Loading train:  48%|████▊     | 138/285 [02:34<02:26,  1.00it/s]Loading train:  49%|████▉     | 139/285 [02:35<02:27,  1.01s/it]Loading train:  49%|████▉     | 140/285 [02:36<02:23,  1.01it/s]Loading train:  49%|████▉     | 141/285 [02:37<02:20,  1.02it/s]Loading train:  50%|████▉     | 142/285 [02:38<02:24,  1.01s/it]Loading train:  50%|█████     | 143/285 [02:39<02:20,  1.01it/s]Loading train:  51%|█████     | 144/285 [02:40<02:15,  1.04it/s]Loading train:  51%|█████     | 145/285 [02:41<02:12,  1.06it/s]Loading train:  51%|█████     | 146/285 [02:42<02:13,  1.04it/s]Loading train:  52%|█████▏    | 147/285 [02:43<02:20,  1.02s/it]Loading train:  52%|█████▏    | 148/285 [02:44<02:16,  1.00it/s]Loading train:  52%|█████▏    | 149/285 [02:45<02:19,  1.02s/it]Loading train:  53%|█████▎    | 150/285 [02:46<02:15,  1.00s/it]Loading train:  53%|█████▎    | 151/285 [02:47<02:13,  1.00it/s]Loading train:  53%|█████▎    | 152/285 [02:47<02:05,  1.06it/s]Loading train:  54%|█████▎    | 153/285 [02:48<02:03,  1.07it/s]Loading train:  54%|█████▍    | 154/285 [02:49<02:05,  1.05it/s]Loading train:  54%|█████▍    | 155/285 [02:50<02:07,  1.02it/s]Loading train:  55%|█████▍    | 156/285 [02:51<02:09,  1.00s/it]Loading train:  55%|█████▌    | 157/285 [02:52<02:06,  1.01it/s]Loading train:  55%|█████▌    | 158/285 [02:53<02:03,  1.03it/s]Loading train:  56%|█████▌    | 159/285 [02:54<01:58,  1.06it/s]Loading train:  56%|█████▌    | 160/285 [02:55<01:55,  1.08it/s]Loading train:  56%|█████▋    | 161/285 [02:56<01:54,  1.09it/s]Loading train:  57%|█████▋    | 162/285 [02:57<01:50,  1.11it/s]Loading train:  57%|█████▋    | 163/285 [02:58<01:50,  1.10it/s]Loading train:  58%|█████▊    | 164/285 [02:59<01:51,  1.08it/s]Loading train:  58%|█████▊    | 165/285 [03:00<01:51,  1.08it/s]Loading train:  58%|█████▊    | 166/285 [03:01<01:54,  1.04it/s]Loading train:  59%|█████▊    | 167/285 [03:02<01:49,  1.07it/s]Loading train:  59%|█████▉    | 168/285 [03:02<01:46,  1.10it/s]Loading train:  59%|█████▉    | 169/285 [03:03<01:48,  1.07it/s]Loading train:  60%|█████▉    | 170/285 [03:04<01:45,  1.09it/s]Loading train:  60%|██████    | 171/285 [03:05<01:44,  1.09it/s]Loading train:  60%|██████    | 172/285 [03:06<01:42,  1.11it/s]Loading train:  61%|██████    | 173/285 [03:07<01:41,  1.10it/s]Loading train:  61%|██████    | 174/285 [03:08<01:42,  1.09it/s]Loading train:  61%|██████▏   | 175/285 [03:09<01:41,  1.09it/s]Loading train:  62%|██████▏   | 176/285 [03:10<01:39,  1.10it/s]Loading train:  62%|██████▏   | 177/285 [03:11<01:38,  1.10it/s]Loading train:  62%|██████▏   | 178/285 [03:12<01:39,  1.07it/s]Loading train:  63%|██████▎   | 179/285 [03:13<01:42,  1.03it/s]Loading train:  63%|██████▎   | 180/285 [03:14<01:38,  1.07it/s]Loading train:  64%|██████▎   | 181/285 [03:14<01:35,  1.08it/s]Loading train:  64%|██████▍   | 182/285 [03:15<01:33,  1.10it/s]Loading train:  64%|██████▍   | 183/285 [03:16<01:28,  1.16it/s]Loading train:  65%|██████▍   | 184/285 [03:17<01:26,  1.17it/s]Loading train:  65%|██████▍   | 185/285 [03:18<01:23,  1.20it/s]Loading train:  65%|██████▌   | 186/285 [03:19<01:23,  1.19it/s]Loading train:  66%|██████▌   | 187/285 [03:19<01:22,  1.19it/s]Loading train:  66%|██████▌   | 188/285 [03:20<01:22,  1.18it/s]Loading train:  66%|██████▋   | 189/285 [03:21<01:21,  1.18it/s]Loading train:  67%|██████▋   | 190/285 [03:22<01:19,  1.20it/s]Loading train:  67%|██████▋   | 191/285 [03:23<01:17,  1.22it/s]Loading train:  67%|██████▋   | 192/285 [03:24<01:16,  1.21it/s]Loading train:  68%|██████▊   | 193/285 [03:24<01:17,  1.19it/s]Loading train:  68%|██████▊   | 194/285 [03:25<01:18,  1.16it/s]Loading train:  68%|██████▊   | 195/285 [03:26<01:18,  1.15it/s]Loading train:  69%|██████▉   | 196/285 [03:27<01:26,  1.02it/s]Loading train:  69%|██████▉   | 197/285 [03:29<01:30,  1.03s/it]Loading train:  69%|██████▉   | 198/285 [03:30<01:30,  1.04s/it]Loading train:  70%|██████▉   | 199/285 [03:31<01:29,  1.04s/it]Loading train:  70%|███████   | 200/285 [03:32<01:27,  1.03s/it]Loading train:  71%|███████   | 201/285 [03:33<01:26,  1.03s/it]Loading train:  71%|███████   | 202/285 [03:34<01:24,  1.02s/it]Loading train:  71%|███████   | 203/285 [03:35<01:22,  1.00s/it]Loading train:  72%|███████▏  | 204/285 [03:36<01:23,  1.04s/it]Loading train:  72%|███████▏  | 205/285 [03:37<01:24,  1.05s/it]Loading train:  72%|███████▏  | 206/285 [03:38<01:21,  1.03s/it]Loading train:  73%|███████▎  | 207/285 [03:39<01:17,  1.01it/s]Loading train:  73%|███████▎  | 208/285 [03:40<01:18,  1.02s/it]Loading train:  73%|███████▎  | 209/285 [03:41<01:17,  1.02s/it]Loading train:  74%|███████▎  | 210/285 [03:42<01:14,  1.00it/s]Loading train:  74%|███████▍  | 211/285 [03:43<01:14,  1.01s/it]Loading train:  74%|███████▍  | 212/285 [03:44<01:12,  1.00it/s]Loading train:  75%|███████▍  | 213/285 [03:45<01:11,  1.00it/s]Loading train:  75%|███████▌  | 214/285 [03:46<01:09,  1.02it/s]Loading train:  75%|███████▌  | 215/285 [03:47<01:08,  1.03it/s]Loading train:  76%|███████▌  | 216/285 [03:48<01:07,  1.03it/s]Loading train:  76%|███████▌  | 217/285 [03:49<01:03,  1.08it/s]Loading train:  76%|███████▋  | 218/285 [03:50<01:02,  1.07it/s]Loading train:  77%|███████▋  | 219/285 [03:50<01:01,  1.07it/s]Loading train:  77%|███████▋  | 220/285 [03:52<01:03,  1.03it/s]Loading train:  78%|███████▊  | 221/285 [03:52<00:59,  1.08it/s]Loading train:  78%|███████▊  | 222/285 [03:53<00:59,  1.06it/s]Loading train:  78%|███████▊  | 223/285 [03:54<00:59,  1.04it/s]Loading train:  79%|███████▊  | 224/285 [03:55<00:56,  1.08it/s]Loading train:  79%|███████▉  | 225/285 [03:56<00:55,  1.07it/s]Loading train:  79%|███████▉  | 226/285 [03:57<00:53,  1.11it/s]Loading train:  80%|███████▉  | 227/285 [03:58<00:51,  1.14it/s]Loading train:  80%|████████  | 228/285 [03:59<00:50,  1.13it/s]Loading train:  80%|████████  | 229/285 [04:00<00:49,  1.14it/s]Loading train:  81%|████████  | 230/285 [04:00<00:48,  1.14it/s]Loading train:  81%|████████  | 231/285 [04:01<00:47,  1.14it/s]Loading train:  81%|████████▏ | 232/285 [04:02<00:51,  1.02it/s]Loading train:  82%|████████▏ | 233/285 [04:04<00:51,  1.00it/s]Loading train:  82%|████████▏ | 234/285 [04:05<00:53,  1.04s/it]Loading train:  82%|████████▏ | 235/285 [04:06<00:53,  1.07s/it]Loading train:  83%|████████▎ | 236/285 [04:07<00:51,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [04:08<00:51,  1.07s/it]Loading train:  84%|████████▎ | 238/285 [04:09<00:51,  1.09s/it]Loading train:  84%|████████▍ | 239/285 [04:10<00:52,  1.13s/it]Loading train:  84%|████████▍ | 240/285 [04:11<00:50,  1.13s/it]Loading train:  85%|████████▍ | 241/285 [04:13<00:52,  1.19s/it]Loading train:  85%|████████▍ | 242/285 [04:14<00:49,  1.15s/it]Loading train:  85%|████████▌ | 243/285 [04:15<00:48,  1.15s/it]Loading train:  86%|████████▌ | 244/285 [04:16<00:45,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:17<00:44,  1.12s/it]Loading train:  86%|████████▋ | 246/285 [04:18<00:45,  1.18s/it]Loading train:  87%|████████▋ | 247/285 [04:20<00:45,  1.19s/it]Loading train:  87%|████████▋ | 248/285 [04:21<00:44,  1.20s/it]Loading train:  87%|████████▋ | 249/285 [04:22<00:44,  1.24s/it]Loading train:  88%|████████▊ | 250/285 [04:23<00:39,  1.12s/it]Loading train:  88%|████████▊ | 251/285 [04:24<00:35,  1.04s/it]Loading train:  88%|████████▊ | 252/285 [04:25<00:33,  1.01s/it]Loading train:  89%|████████▉ | 253/285 [04:26<00:32,  1.03s/it]Loading train:  89%|████████▉ | 254/285 [04:27<00:29,  1.03it/s]Loading train:  89%|████████▉ | 255/285 [04:28<00:28,  1.06it/s]Loading train:  90%|████████▉ | 256/285 [04:29<00:26,  1.09it/s]Loading train:  90%|█████████ | 257/285 [04:29<00:25,  1.08it/s]Loading train:  91%|█████████ | 258/285 [04:30<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [04:31<00:22,  1.14it/s]Loading train:  91%|█████████ | 260/285 [04:32<00:21,  1.14it/s]Loading train:  92%|█████████▏| 261/285 [04:33<00:22,  1.06it/s]Loading train:  92%|█████████▏| 262/285 [04:34<00:21,  1.09it/s]Loading train:  92%|█████████▏| 263/285 [04:35<00:19,  1.12it/s]Loading train:  93%|█████████▎| 264/285 [04:36<00:20,  1.03it/s]Loading train:  93%|█████████▎| 265/285 [04:37<00:19,  1.01it/s]Loading train:  93%|█████████▎| 266/285 [04:38<00:18,  1.04it/s]Loading train:  94%|█████████▎| 267/285 [04:39<00:17,  1.06it/s]Loading train:  94%|█████████▍| 268/285 [04:40<00:16,  1.01it/s]Loading train:  94%|█████████▍| 269/285 [04:41<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:42<00:15,  1.02s/it]Loading train:  95%|█████████▌| 271/285 [04:43<00:14,  1.06s/it]Loading train:  95%|█████████▌| 272/285 [04:44<00:13,  1.08s/it]Loading train:  96%|█████████▌| 273/285 [04:45<00:13,  1.09s/it]Loading train:  96%|█████████▌| 274/285 [04:46<00:12,  1.10s/it]Loading train:  96%|█████████▋| 275/285 [04:47<00:10,  1.06s/it]Loading train:  97%|█████████▋| 276/285 [04:48<00:09,  1.03s/it]Loading train:  97%|█████████▋| 277/285 [04:49<00:08,  1.03s/it]Loading train:  98%|█████████▊| 278/285 [04:50<00:07,  1.03s/it]Loading train:  98%|█████████▊| 279/285 [04:52<00:06,  1.04s/it]Loading train:  98%|█████████▊| 280/285 [04:53<00:05,  1.03s/it]Loading train:  99%|█████████▊| 281/285 [04:54<00:04,  1.03s/it]Loading train:  99%|█████████▉| 282/285 [04:55<00:03,  1.09s/it]Loading train:  99%|█████████▉| 283/285 [04:56<00:02,  1.08s/it]Loading train: 100%|█████████▉| 284/285 [04:57<00:01,  1.05s/it]Loading train: 100%|██████████| 285/285 [04:58<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 42.58it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:06, 44.97it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:06, 44.31it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:05, 49.79it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:04, 60.36it/s]concatenating: train:  16%|█▌        | 46/285 [00:00<00:03, 66.91it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:03, 62.45it/s]concatenating: train:  21%|██▏       | 61/285 [00:00<00:03, 62.47it/s]concatenating: train:  24%|██▍       | 68/285 [00:01<00:03, 62.48it/s]concatenating: train:  26%|██▋       | 75/285 [00:01<00:03, 62.48it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:03, 63.85it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:02, 66.71it/s]concatenating: train:  37%|███▋      | 105/285 [00:01<00:02, 79.90it/s]concatenating: train:  41%|████      | 116/285 [00:01<00:02, 83.87it/s]concatenating: train:  44%|████▍     | 126/285 [00:01<00:02, 77.09it/s]concatenating: train:  47%|████▋     | 135/285 [00:01<00:02, 73.22it/s]concatenating: train:  51%|█████     | 145/285 [00:01<00:01, 78.77it/s]concatenating: train:  59%|█████▉    | 168/285 [00:02<00:01, 97.42it/s]concatenating: train:  64%|██████▎   | 181/285 [00:02<00:01, 98.22it/s]concatenating: train:  68%|██████▊   | 193/285 [00:02<00:00, 103.77it/s]concatenating: train:  72%|███████▏  | 205/285 [00:02<00:00, 102.59it/s]concatenating: train:  76%|███████▌  | 217/285 [00:02<00:00, 105.97it/s]concatenating: train:  81%|████████▏ | 232/285 [00:02<00:00, 108.30it/s]concatenating: train:  86%|████████▌ | 244/285 [00:02<00:00, 110.34it/s]concatenating: train:  90%|█████████ | 257/285 [00:02<00:00, 115.42it/s]concatenating: train:  95%|█████████▍| 270/285 [00:02<00:00, 119.15it/s]concatenating: train:  99%|█████████▉| 283/285 [00:03<00:00, 118.75it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 91.30it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 292.01it/s]---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________2019-07-08 15:02:56.073378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 15:02:56.073478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 15:02:56.073493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 15:02:56.073503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 15:02:56.073897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

batch_normalization_8 (BatchNor (None, 40, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 27s - loss: 15422.0238 - acc: 0.7748 - mDice: 0.2233 - val_loss: 8895.0180 - val_acc: 0.8971 - val_mDice: 0.3161

Epoch 00001: val_mDice improved from -inf to 0.31612, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 5335.6406 - acc: 0.8873 - mDice: 0.5012 - val_loss: 6171.0978 - val_acc: 0.9181 - val_mDice: 0.4357

Epoch 00002: val_mDice improved from 0.31612 to 0.43570, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 19s - loss: 3673.5031 - acc: 0.8990 - mDice: 0.6175 - val_loss: 6010.9486 - val_acc: 0.9237 - val_mDice: 0.4583

Epoch 00003: val_mDice improved from 0.43570 to 0.45827, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 18s - loss: 3104.5150 - acc: 0.9124 - mDice: 0.6645 - val_loss: 4432.1635 - val_acc: 0.9298 - val_mDice: 0.5416

Epoch 00004: val_mDice improved from 0.45827 to 0.54158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 2778.4923 - acc: 0.9305 - mDice: 0.6929 - val_loss: 4490.0915 - val_acc: 0.9413 - val_mDice: 0.5350

Epoch 00005: val_mDice did not improve from 0.54158
Epoch 6/300
 - 20s - loss: 2576.8072 - acc: 0.9423 - mDice: 0.7107 - val_loss: 4637.7917 - val_acc: 0.9309 - val_mDice: 0.5270

Epoch 00006: val_mDice did not improve from 0.54158
Epoch 7/300
 - 19s - loss: 2409.0767 - acc: 0.9471 - mDice: 0.7260 - val_loss: 4609.2000 - val_acc: 0.9288 - val_mDice: 0.5302

Epoch 00007: val_mDice did not improve from 0.54158
Epoch 8/300
 - 18s - loss: 2248.5411 - acc: 0.9490 - mDice: 0.7411 - val_loss: 4404.5385 - val_acc: 0.9399 - val_mDice: 0.5460

Epoch 00008: val_mDice improved from 0.54158 to 0.54596, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 2199.8703 - acc: 0.9495 - mDice: 0.7460 - val_loss: 4057.8782 - val_acc: 0.9365 - val_mDice: 0.5667

Epoch 00009: val_mDice improved from 0.54596 to 0.56666, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 2096.1433 - acc: 0.9507 - mDice: 0.7562 - val_loss: 4368.5222 - val_acc: 0.9408 - val_mDice: 0.5490

Epoch 00010: val_mDice did not improve from 0.56666
Epoch 11/300
 - 18s - loss: 2026.0835 - acc: 0.9516 - mDice: 0.7632 - val_loss: 4271.9550 - val_acc: 0.9428 - val_mDice: 0.5543

Epoch 00011: val_mDice did not improve from 0.56666
Epoch 12/300
 - 18s - loss: 1959.7480 - acc: 0.9522 - mDice: 0.7699 - val_loss: 4092.0484 - val_acc: 0.9386 - val_mDice: 0.5642

Epoch 00012: val_mDice did not improve from 0.56666
Epoch 13/300
 - 19s - loss: 1894.4057 - acc: 0.9531 - mDice: 0.7766 - val_loss: 4183.1365 - val_acc: 0.9422 - val_mDice: 0.5626

Epoch 00013: val_mDice did not improve from 0.56666
Epoch 14/300
 - 18s - loss: 1847.8463 - acc: 0.9536 - mDice: 0.7814 - val_loss: 4676.3738 - val_acc: 0.9398 - val_mDice: 0.5270

Epoch 00014: val_mDice did not improve from 0.56666
Epoch 15/300
 - 19s - loss: 1801.8194 - acc: 0.9541 - mDice: 0.7862 - val_loss: 4716.2096 - val_acc: 0.9308 - val_mDice: 0.5259

Epoch 00015: val_mDice did not improve from 0.56666
Epoch 16/300
 - 19s - loss: 1758.2653 - acc: 0.9547 - mDice: 0.7907 - val_loss: 4997.2767 - val_acc: 0.9418 - val_mDice: 0.5104

Epoch 00016: val_mDice did not improve from 0.56666
Epoch 17/300
 - 18s - loss: 1740.6394 - acc: 0.9551 - mDice: 0.7926 - val_loss: 4095.6804 - val_acc: 0.9420 - val_mDice: 0.5659

Epoch 00017: val_mDice did not improve from 0.56666
Epoch 18/300
 - 19s - loss: 1698.7582 - acc: 0.9554 - mDice: 0.7970 - val_loss: 4335.9000 - val_acc: 0.9438 - val_mDice: 0.5512

Epoch 00018: val_mDice did not improve from 0.56666
Epoch 19/300
 - 18s - loss: 1667.6701 - acc: 0.9558 - mDice: 0.8004 - val_loss: 4394.4843 - val_acc: 0.9450 - val_mDice: 0.5563

Epoch 00019: val_mDice did not improve from 0.56666
Epoch 20/300
 - 19s - loss: 1628.8823 - acc: 0.9563 - mDice: 0.8044 - val_loss: 4124.1172 - val_acc: 0.9432 - val_mDice: 0.5696

Epoch 00020: val_mDice improved from 0.56666 to 0.56965, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 18s - loss: 1626.7613 - acc: 0.9565 - mDice: 0.8047 - val_loss: 4233.2340 - val_acc: 0.9435 - val_mDice: 0.5592

Epoch 00021: val_mDice did not improve from 0.56965
Epoch 22/300
 - 19s - loss: 1601.0788 - acc: 0.9567 - mDice: 0.8074 - val_loss: 4167.5660 - val_acc: 0.9401 - val_mDice: 0.5638

Epoch 00022: val_mDice did not improve from 0.56965
Epoch 23/300
 - 18s - loss: 1570.1326 - acc: 0.9571 - mDice: 0.8107 - val_loss: 4412.0231 - val_acc: 0.9364 - val_mDice: 0.5513

Epoch 00023: val_mDice did not improve from 0.56965
Epoch 24/300
 - 19s - loss: 1544.6475 - acc: 0.9575 - mDice: 0.8135 - val_loss: 4178.4467 - val_acc: 0.9410 - val_mDice: 0.5600

Epoch 00024: val_mDice did not improve from 0.56965
Epoch 25/300
 - 19s - loss: 1517.1464 - acc: 0.9578 - mDice: 0.8165 - val_loss: 4198.2231 - val_acc: 0.9461 - val_mDice: 0.5612

Epoch 00025: val_mDice did not improve from 0.56965
Epoch 26/300
 - 18s - loss: 1504.8487 - acc: 0.9580 - mDice: 0.8178 - val_loss: 4137.9194 - val_acc: 0.9439 - val_mDice: 0.5658

Epoch 00026: val_mDice did not improve from 0.56965
Epoch 27/300
 - 18s - loss: 1489.0582 - acc: 0.9582 - mDice: 0.8195 - val_loss: 3984.8235 - val_acc: 0.9436 - val_mDice: 0.5757

Epoch 00027: val_mDice improved from 0.56965 to 0.57569, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 18s - loss: 1476.6838 - acc: 0.9584 - mDice: 0.8209 - val_loss: 4533.8844 - val_acc: 0.9407 - val_mDice: 0.5455

Epoch 00028: val_mDice did not improve from 0.57569
Epoch 29/300
 - 19s - loss: 1454.2156 - acc: 0.9586 - mDice: 0.8234 - val_loss: 4195.1970 - val_acc: 0.9442 - val_mDice: 0.5603

Epoch 00029: val_mDice did not improve from 0.57569
Epoch 30/300
 - 19s - loss: 1439.7159 - acc: 0.9588 - mDice: 0.8250 - val_loss: 4968.4033 - val_acc: 0.9430 - val_mDice: 0.5224

Epoch 00030: val_mDice did not improve from 0.57569
Epoch 31/300
 - 19s - loss: 1435.0194 - acc: 0.9588 - mDice: 0.8254 - val_loss: 4175.2445 - val_acc: 0.9437 - val_mDice: 0.5668

Epoch 00031: val_mDice did not improve from 0.57569
Epoch 32/300
 - 19s - loss: 1414.0364 - acc: 0.9592 - mDice: 0.8278 - val_loss: 4419.2198 - val_acc: 0.9403 - val_mDice: 0.5484

Epoch 00032: val_mDice did not improve from 0.57569
Epoch 33/300
 - 19s - loss: 1401.3800 - acc: 0.9593 - mDice: 0.8292 - val_loss: 4205.2224 - val_acc: 0.9431 - val_mDice: 0.5605

Epoch 00033: val_mDice did not improve from 0.57569
Epoch 34/300
 - 19s - loss: 1386.4797 - acc: 0.9595 - mDice: 0.8309 - val_loss: 4229.0883 - val_acc: 0.9404 - val_mDice: 0.5598

Epoch 00034: val_mDice did not improve from 0.57569
Epoch 35/300
 - 19s - loss: 1369.4367 - acc: 0.9597 - mDice: 0.8327 - val_loss: 4289.3620 - val_acc: 0.9450 - val_mDice: 0.5598

Epoch 00035: val_mDice did not improve from 0.57569
Epoch 36/300
 - 19s - loss: 1366.3476 - acc: 0.9597 - mDice: 0.8331 - val_loss: 5030.6855 - val_acc: 0.9427 - val_mDice: 0.5154

Epoch 00036: val_mDice did not improve from 0.57569
Epoch 37/300
 - 18s - loss: 1354.1999 - acc: 0.9599 - mDice: 0.8344 - val_loss: 4228.6692 - val_acc: 0.9420 - val_mDice: 0.5569

Epoch 00037: val_mDice did not improve from 0.57569
Epoch 38/300
 - 19s - loss: 1348.3392 - acc: 0.9601 - mDice: 0.8351 - val_loss: 4146.4735 - val_acc: 0.9446 - val_mDice: 0.5625

Epoch 00038: val_mDice did not improve from 0.57569
Epoch 39/300
 - 19s - loss: 1321.9759 - acc: 0.9604 - mDice: 0.8380 - val_loss: 4630.7432 - val_acc: 0.9398 - val_mDice: 0.5359

Epoch 00039: val_mDice did not improve from 0.57569
Epoch 40/300
 - 20s - loss: 1322.2951 - acc: 0.9603 - mDice: 0.8380 - val_loss: 4729.7634 - val_acc: 0.9356 - val_mDice: 0.5285

Epoch 00040: val_mDice did not improve from 0.57569
Epoch 41/300
 - 19s - loss: 1310.9360 - acc: 0.9604 - mDice: 0.8393 - val_loss: 4429.7765 - val_acc: 0.9443 - val_mDice: 0.5517

Epoch 00041: val_mDice did not improve from 0.57569
Epoch 42/300
 - 20s - loss: 1304.3967 - acc: 0.9606 - mDice: 0.8400 - val_loss: 4111.9157 - val_acc: 0.9451 - val_mDice: 0.5665

Epoch 00042: val_mDice did not improve from 0.57569
Epoch 43/300
 - 20s - loss: 1282.3804 - acc: 0.9609 - mDice: 0.8424 - val_loss: 4090.5850 - val_acc: 0.9431 - val_mDice: 0.5677

Epoch 00043: val_mDice did not improve from 0.57569
Epoch 44/300
 - 20s - loss: 1287.0655 - acc: 0.9608 - mDice: 0.8419 - val_loss: 4301.7487 - val_acc: 0.9451 - val_mDice: 0.5524

Epoch 00044: val_mDice did not improve from 0.57569
Epoch 45/300
 - 20s - loss: 1284.1446 - acc: 0.9609 - mDice: 0.8423 - val_loss: 4428.1662 - val_acc: 0.9449 - val_mDice: 0.5471

Epoch 00045: val_mDice did not improve from 0.57569
Epoch 46/300
 - 19s - loss: 1269.0658 - acc: 0.9611 - mDice: 0.8440 - val_loss: 4054.4611 - val_acc: 0.9471 - val_mDice: 0.5719

Epoch 00046: val_mDice did not improve from 0.57569
Epoch 47/300
 - 20s - loss: 1262.6612 - acc: 0.9613 - mDice: 0.8446 - val_loss: 4044.8933 - val_acc: 0.9453 - val_mDice: 0.5705

Epoch 00047: val_mDice did not improve from 0.57569
Epoch 48/300
 - 19s - loss: 1260.3153 - acc: 0.9612 - mDice: 0.8449 - val_loss: 4323.1868 - val_acc: 0.9417 - val_mDice: 0.5537

Epoch 00048: val_mDice did not improve from 0.57569
Epoch 49/300
 - 19s - loss: 1249.7433 - acc: 0.9613 - mDice: 0.8461 - val_loss: 4323.9209 - val_acc: 0.9440 - val_mDice: 0.5578

Epoch 00049: val_mDice did not improve from 0.57569
Epoch 50/300
 - 19s - loss: 1250.9754 - acc: 0.9613 - mDice: 0.8460 - val_loss: 4393.7932 - val_acc: 0.9447 - val_mDice: 0.5481

Epoch 00050: val_mDice did not improve from 0.57569
Epoch 51/300
 - 19s - loss: 1240.0868 - acc: 0.9615 - mDice: 0.8472 - val_loss: 4214.0799 - val_acc: 0.9439 - val_mDice: 0.5637

Epoch 00051: val_mDice did not improve from 0.57569
Epoch 52/300
 - 20s - loss: 1228.3619 - acc: 0.9616 - mDice: 0.8485 - val_loss: 4251.2710 - val_acc: 0.9408 - val_mDice: 0.5568

Epoch 00052: val_mDice did not improve from 0.57569
Epoch 53/300
 - 19s - loss: 1226.4580 - acc: 0.9617 - mDice: 0.8488 - val_loss: 4168.4474 - val_acc: 0.9436 - val_mDice: 0.5611

Epoch 00053: val_mDice did not improve from 0.57569
Epoch 54/300
 - 18s - loss: 1218.2225 - acc: 0.9617 - mDice: 0.8497 - val_loss: 4230.8509 - val_acc: 0.9388 - val_mDice: 0.5548

Epoch 00054: val_mDice did not improve from 0.57569
Epoch 55/300
 - 20s - loss: 1221.8958 - acc: 0.9617 - mDice: 0.8493 - val_loss: 3901.9319 - val_acc: 0.9431 - val_mDice: 0.5802

Epoch 00055: val_mDice improved from 0.57569 to 0.58022, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_CSFn1_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 56/300
 - 20s - loss: 1204.8816 - acc: 0.9619 - mDice: 0.8512 - val_loss: 4307.3002 - val_acc: 0.9427 - val_mDice: 0.5541

Epoch 00056: val_mDice did not improve from 0.58022
Epoch 57/300
 - 19s - loss: 1194.4488 - acc: 0.9620 - mDice: 0.8524 - val_loss: 4421.6347 - val_acc: 0.9445 - val_mDice: 0.5452

Epoch 00057: val_mDice did not improve from 0.58022
Epoch 58/300
 - 20s - loss: 1193.3679 - acc: 0.9621 - mDice: 0.8526 - val_loss: 4324.2359 - val_acc: 0.9443 - val_mDice: 0.5523

Epoch 00058: val_mDice did not improve from 0.58022
Epoch 59/300
 - 19s - loss: 1184.1869 - acc: 0.9622 - mDice: 0.8536 - val_loss: 4340.7446 - val_acc: 0.9454 - val_mDice: 0.5551

Epoch 00059: val_mDice did not improve from 0.58022
Epoch 60/300
 - 19s - loss: 1188.6216 - acc: 0.9622 - mDice: 0.8531 - val_loss: 4391.6059 - val_acc: 0.9387 - val_mDice: 0.5509

Epoch 00060: val_mDice did not improve from 0.58022
Epoch 61/300
 - 20s - loss: 1189.7480 - acc: 0.9622 - mDice: 0.8530 - val_loss: 4350.7666 - val_acc: 0.9433 - val_mDice: 0.5511

Epoch 00061: val_mDice did not improve from 0.58022
Epoch 62/300
 - 19s - loss: 1183.5347 - acc: 0.9623 - mDice: 0.8537 - val_loss: 4242.5265 - val_acc: 0.9434 - val_mDice: 0.5595

Epoch 00062: val_mDice did not improve from 0.58022
Epoch 63/300
 - 19s - loss: 1172.8089 - acc: 0.9623 - mDice: 0.8549 - val_loss: 4401.7673 - val_acc: 0.9448 - val_mDice: 0.5517

Epoch 00063: val_mDice did not improve from 0.58022
Epoch 64/300
 - 19s - loss: 1174.0538 - acc: 0.9625 - mDice: 0.8548 - val_loss: 4292.6456 - val_acc: 0.9433 - val_mDice: 0.5537

Epoch 00064: val_mDice did not improve from 0.58022
Epoch 65/300
 - 19s - loss: 1160.0538 - acc: 0.9625 - mDice: 0.8563 - val_loss: 4201.6377 - val_acc: 0.9444 - val_mDice: 0.5611

Epoch 00065: val_mDice did not improve from 0.58022
Epoch 66/300
 - 19s - loss: 1165.6200 - acc: 0.9625 - mDice: 0.8557 - val_loss: 4442.2659 - val_acc: 0.9453 - val_mDice: 0.5452

Epoch 00066: val_mDice did not improve from 0.58022
Epoch 67/300
 - 20s - loss: 1161.5627 - acc: 0.9625 - mDice: 0.8562 - val_loss: 3978.7512 - val_acc: 0.9446 - val_mDice: 0.5757

Epoch 00067: val_mDice did not improve from 0.58022
Epoch 68/300
 - 20s - loss: 1159.4798 - acc: 0.9625 - mDice: 0.8564 - val_loss: 4096.8203 - val_acc: 0.9433 - val_mDice: 0.5661

Epoch 00068: val_mDice did not improve from 0.58022
Epoch 69/300
 - 20s - loss: 1155.6353 - acc: 0.9626 - mDice: 0.8569 - val_loss: 4253.7287 - val_acc: 0.9460 - val_mDice: 0.5604

Epoch 00069: val_mDice did not improve from 0.58022
Epoch 70/300
 - 19s - loss: 1148.9487 - acc: 0.9627 - mDice: 0.8576 - val_loss: 4471.3963 - val_acc: 0.9434 - val_mDice: 0.5491

Epoch 00070: val_mDice did not improve from 0.58022
Epoch 71/300
 - 19s - loss: 1149.2572 - acc: 0.9627 - mDice: 0.8576 - val_loss: 5222.7609 - val_acc: 0.9364 - val_mDice: 0.5100

Epoch 00071: val_mDice did not improve from 0.58022
Epoch 72/300
 - 19s - loss: 1143.0416 - acc: 0.9628 - mDice: 0.8583 - val_loss: 4617.0041 - val_acc: 0.9401 - val_mDice: 0.5333

Epoch 00072: val_mDice did not improve from 0.58022
Epoch 73/300
 - 20s - loss: 1144.6912 - acc: 0.9628 - mDice: 0.8581 - val_loss: 4431.6642 - val_acc: 0.9436 - val_mDice: 0.5441

Epoch 00073: val_mDice did not improve from 0.58022
Epoch 74/300
 - 20s - loss: 1130.3459 - acc: 0.9629 - mDice: 0.8598 - val_loss: 4363.4789 - val_acc: 0.9460 - val_mDice: 0.5524

Epoch 00074: val_mDice did not improve from 0.58022
Epoch 75/300
 - 20s - loss: 1136.4560 - acc: 0.9629 - mDice: 0.8591 - val_loss: 4357.3247 - val_acc: 0.9409 - val_mDice: 0.5493

Epoch 00075: val_mDice did not improve from 0.58022
Epoch 76/300
 - 19s - loss: 1133.4097 - acc: 0.9629 - mDice: 0.8594 - val_loss: 4222.7512 - val_acc: 0.9412 - val_mDice: 0.5586

Epoch 00076: val_mDice did not improve from 0.58022
Epoch 77/300
 - 19s - loss: 1132.1786 - acc: 0.9629 - mDice: 0.8596 - val_loss: 4502.6349 - val_acc: 0.9422 - val_mDice: 0.5475

Epoch 00077: val_mDice did not improve from 0.58022
Epoch 78/300
 - 19s - loss: 1125.7429 - acc: 0.9630 - mDice: 0.8603 - val_loss: 4100.2956 - val_acc: 0.9466 - val_mDice: 0.5659

Epoch 00078: val_mDice did not improve from 0.58022
Epoch 79/300
 - 20s - loss: 1122.6028 - acc: 0.9630 - mDice: 0.8607 - val_loss: 4341.2687 - val_acc: 0.9432 - val_mDice: 0.5559

Epoch 00079: val_mDice did not improve from 0.58022
Epoch 80/300
 - 19s - loss: 1110.2995 - acc: 0.9631 - mDice: 0.8620 - val_loss: 4360.2032 - val_acc: 0.9434 - val_mDice: 0.5495

Epoch 00080: val_mDice did not improve from 0.58022
Epoch 81/300
 - 20s - loss: 1110.7134 - acc: 0.9632 - mDice: 0.8621 - val_loss: 4424.9486 - val_acc: 0.9418 - val_mDice: 0.5480

Epoch 00081: val_mDice did not improve from 0.58022
Epoch 82/300
 - 19s - loss: 1114.4828 - acc: 0.9632 - mDice: 0.8616 - val_loss: 4164.6921 - val_acc: 0.9448 - val_mDice: 0.5624

Epoch 00082: val_mDice did not improve from 0.58022
Epoch 83/300
 - 19s - loss: 1105.6775 - acc: 0.9634 - mDice: 0.8626 - val_loss: 4275.4256 - val_acc: 0.9449 - val_mDice: 0.5548

Epoch 00083: val_mDice did not improve from 0.58022
Epoch 84/300
 - 20s - loss: 1100.2677 - acc: 0.9633 - mDice: 0.8633 - val_loss: 4256.2216 - val_acc: 0.9421 - val_mDice: 0.5555

Epoch 00084: val_mDice did not improve from 0.58022
Epoch 85/300
 - 20s - loss: 1110.0677 - acc: 0.9632 - mDice: 0.8621 - val_loss: 4413.0661 - val_acc: 0.9435 - val_mDice: 0.5470

Epoch 00085: val_mDice did not improve from 0.58022
Restoring model weights from the end of the best epoch
Epoch 00085: early stopping
{'val_loss': [8895.018047626201, 6171.09775015024, 6010.948561448317, 4432.16348031851, 4490.091524564303, 4637.791701096755, 4609.200035682092, 4404.5384521484375, 4057.878211388221, 4368.522179236779, 4271.954965444712, 4092.048396183894, 4183.136474609375, 4676.373751126803, 4716.209641676683, 4997.276705228365, 4095.680429311899, 4335.8999586838945, 4394.4843186598555, 4124.11723445012, 4233.234036959135, 4167.566030649038, 4412.023061899038, 4178.446739783654, 4198.2230881911055, 4137.9193772536055, 3984.823542668269, 4533.884380634015, 4195.197040264423, 4968.403282752404, 4175.244497445913, 4419.2198486328125, 4205.222421499399, 4229.0883225661055, 4289.361976036658, 5030.685537484976, 4228.669241098257, 4146.473534217248, 4630.743173452524, 4729.763437124399, 4429.776479867788, 4111.915719839243, 4090.585040752704, 4301.748741736779, 4428.16615647536, 4054.4611299954927, 4044.893277681791, 4323.186795748197, 4323.920884352464, 4393.793212890625, 4214.079932579627, 4251.271010178786, 4168.447397085337, 4230.850938063401, 3901.9319270207334, 4307.300156813401, 4421.634662334735, 4324.2358961838945, 4340.744577261118, 4391.605853740985, 4350.766568697416, 4242.526465782752, 4401.7673105093145, 4292.645550067608, 4201.6376953125, 4442.265920785757, 3978.751164362981, 4096.820331280048, 4253.728712815505, 4471.396287184495, 5222.760892427885, 4617.004079965444, 4431.6641845703125, 4363.4788818359375, 4357.3247305063105, 4222.751192533053, 4502.634892390324, 4100.295621431791, 4341.268657977765, 4360.2032470703125, 4424.948570838342, 4164.692096416767, 4275.4255605844355, 4256.221646822416, 4413.06605881911], 'val_acc': [0.897147719676678, 0.9181166749734145, 0.9237171709537506, 0.9297776199304141, 0.9412675912563617, 0.9309194431855128, 0.9288461437592139, 0.9399362045985001, 0.9365245676957644, 0.9407960428641393, 0.9427699469603025, 0.9386141162652236, 0.9422152386261866, 0.9397697746753693, 0.9308478098649245, 0.9417575574838198, 0.9420326420894036, 0.9437823731165665, 0.9449866207746359, 0.9431929680017325, 0.9434680365599118, 0.9401396123262552, 0.9364390442004571, 0.9410040928767278, 0.9461168669737302, 0.9438956013092628, 0.9435673791628617, 0.9407012668939737, 0.9441614563648517, 0.9429687582529508, 0.9436644980540643, 0.940280597943526, 0.943109753040167, 0.940447027866657, 0.9449796791260059, 0.9427214241944827, 0.941997956771117, 0.9446005981702071, 0.9397766956916223, 0.9356116193991441, 0.9443347660394815, 0.9451391582305615, 0.9431143609377054, 0.945109106027163, 0.9449218763754919, 0.947140803703895, 0.9452801461403186, 0.9417067330617171, 0.9439603457084069, 0.9447184984500592, 0.9438563264333285, 0.940786790389281, 0.9436274698147407, 0.938764329140003, 0.943149032501074, 0.9426544079413781, 0.9445150907223041, 0.9442515717102931, 0.9453933903804193, 0.9386533911411579, 0.9432553396775172, 0.9433732170325059, 0.9448178891952221, 0.9432669259034671, 0.9444295603495377, 0.9452686103490683, 0.944621381851343, 0.9432830695922558, 0.9460382988819709, 0.9434310312454517, 0.9363581561125242, 0.9401326890175159, 0.9435674204276159, 0.9459805190563202, 0.9408907959094415, 0.9412005566633664, 0.9421712939555829, 0.9466091921696296, 0.9431767899256486, 0.9433547487625709, 0.9418176550131577, 0.9447670303858243, 0.9449496154601758, 0.9421343574157128, 0.9435188678594736], 'val_mDice': [0.31611817559370625, 0.43569654914049, 0.4582708440721035, 0.5415824542825038, 0.5350078384463604, 0.5270491924423438, 0.5301597261658082, 0.5459593620437843, 0.5666622806053895, 0.5489715839234682, 0.554339197392647, 0.564177373280892, 0.562563295261218, 0.5269638105080678, 0.5259385366852467, 0.5104303978956662, 0.5659046814991877, 0.5511607883068231, 0.556251843388264, 0.569645972779164, 0.5592322332354692, 0.563827362198096, 0.5513460097404627, 0.5599887881141442, 0.5611944118371377, 0.5658440521130195, 0.5756927281618118, 0.5455337258485647, 0.5603097081184387, 0.5224443324483358, 0.5667558381190667, 0.548363141142405, 0.5605370574272596, 0.5597507283091545, 0.5598298437320269, 0.515432132837864, 0.5569186680592023, 0.5624523993868095, 0.53585284948349, 0.5284827609474843, 0.5517471031500742, 0.5664612352848053, 0.5676723391963885, 0.5524397194385529, 0.5471397566680725, 0.571854558128577, 0.5704715911012429, 0.5537392262082833, 0.5577889612087836, 0.5480676256120205, 0.5636613219976425, 0.5567534176202921, 0.5610761636724839, 0.5548377552857766, 0.5802165384476001, 0.5540596768260002, 0.5451581076933787, 0.5523076854073085, 0.5551126759785873, 0.5508843488418139, 0.5510512108986194, 0.5595200643516504, 0.5516614421055868, 0.5536554914254409, 0.5611104707305248, 0.5451714614262948, 0.5756736455055383, 0.5661301999711074, 0.5603821048369775, 0.5490745157003403, 0.5100153822165269, 0.5333038184505242, 0.5440949717393289, 0.5523618006935487, 0.5492649694474844, 0.5585948337729161, 0.5474542448153863, 0.5658713175127139, 0.5558941306976172, 0.5495270877503432, 0.548003077507019, 0.5623521148585356, 0.5547616390081552, 0.5555288528020565, 0.5469897332099768], 'loss': [15422.023774136216, 5335.640559658666, 3673.5030754220934, 3104.5149794897557, 2778.492315987363, 2576.8072025334604, 2409.0767007919408, 2248.5410509750673, 2199.8703066987614, 2096.1432993170365, 2026.0834605354098, 1959.7480063856633, 1894.4057162815295, 1847.8462503643084, 1801.8193954303126, 1758.2653255995642, 1740.6394220507145, 1698.7582138189582, 1667.6701282113172, 1628.8822612247047, 1626.761287563612, 1601.0788152382117, 1570.1325925190072, 1544.6474621139594, 1517.1464226981386, 1504.8487332393397, 1489.0581710183576, 1476.6838061093383, 1454.2156201342996, 1439.7159105677517, 1435.0193519272136, 1414.0363574880719, 1401.3799663411069, 1386.4796890558532, 1369.4367101680393, 1366.3475698674945, 1354.19987784863, 1348.3391682766332, 1321.975853686116, 1322.2950810910284, 1310.9359647094197, 1304.3967397848662, 1282.3803840066569, 1287.0654675368398, 1284.1446427884691, 1269.0658457150134, 1262.6611869296255, 1260.3153474085293, 1249.7432653505755, 1250.975439268494, 1240.0868243757764, 1228.361909886914, 1226.4580419861081, 1218.222500794138, 1221.8957846237925, 1204.8816262969647, 1194.4488188776925, 1193.367921312236, 1184.1869133296052, 1188.621635754346, 1189.747968806515, 1183.5347437096468, 1172.8089426517881, 1174.0537794479571, 1160.0537931939548, 1165.619982052298, 1161.5626756752, 1159.4797717851434, 1155.6352536473164, 1148.948727465683, 1149.2571851939147, 1143.0416369756122, 1144.6911774568207, 1130.3459335280709, 1136.455978304898, 1133.4097301859945, 1132.1785682256752, 1125.7429393447105, 1122.6027705181923, 1110.2994736070993, 1110.7133542822262, 1114.4827672023785, 1105.6775048810111, 1100.2677031983794, 1110.0677391980325], 'acc': [0.7747975483703007, 0.8872618109364357, 0.8989559436904255, 0.9124224101508729, 0.9304972323975109, 0.9423168239465535, 0.9471224789622524, 0.9490285087619047, 0.9495301164132164, 0.9506757705840283, 0.9515974063896598, 0.9522330744244741, 0.9530910593737956, 0.9536368291745005, 0.9541147190256004, 0.9547187694212085, 0.9550965850251875, 0.9554476369343087, 0.9558253653273969, 0.9562961537712868, 0.956487215132574, 0.9567032583105293, 0.9571105553184083, 0.9574621007537684, 0.9578020010917574, 0.9579510453452508, 0.9581534591128352, 0.9583613648028059, 0.9585966513977712, 0.958847940220974, 0.9588461877685581, 0.9591592011730532, 0.9592695606653072, 0.9595299653710996, 0.9596565306972756, 0.9597262127047852, 0.9599023448588674, 0.9600721847732866, 0.9604422231392481, 0.9603314827775467, 0.9604343068200614, 0.9606062533241306, 0.9608878737543491, 0.9608323613370157, 0.9609444734465974, 0.9611419580700234, 0.961252809120568, 0.9611518270776114, 0.9613372284603287, 0.9613238813790692, 0.9614713534562996, 0.9616027286513797, 0.9617045559061197, 0.9617438631216935, 0.9617334625701848, 0.9619117296677635, 0.9620102973240697, 0.9620536151247183, 0.9621778509168951, 0.9622106909323122, 0.9621561537817551, 0.9622503698152512, 0.9623428805391364, 0.9624667433336588, 0.9624902272338766, 0.9624815563439642, 0.9625499252737376, 0.9625414345280486, 0.9626232644382091, 0.962704735137347, 0.9626798399708691, 0.9627648836504563, 0.9627716004831989, 0.9628957062863472, 0.9629094043110478, 0.9628610976956311, 0.9629165212089787, 0.9629897229853761, 0.9629916082028367, 0.9631239427452013, 0.9631887179266249, 0.9631648436745275, 0.9633547255586766, 0.9633041805615452, 0.9632270290855331], 'mDice': [0.22329377019706603, 0.5012469172180881, 0.6174922824004891, 0.6645319251010177, 0.6929467567315261, 0.7106737819290091, 0.7259567524963977, 0.7410938877917783, 0.7459772146573798, 0.7562012688035973, 0.7632491954806809, 0.7699280251527002, 0.7766376527420195, 0.781405153336543, 0.7861752554816887, 0.7906726180962902, 0.7926191542296571, 0.7970288430238291, 0.8003571173378015, 0.8043634378139377, 0.8047147488600651, 0.8074035544264837, 0.8107209852576684, 0.8135122339971543, 0.8164704084990045, 0.8178160853802823, 0.8195072777220918, 0.8209204164299371, 0.8233830840189849, 0.8250004180812598, 0.8254463998393842, 0.8277967108535028, 0.8291997599291712, 0.8308551245583145, 0.832663679347205, 0.8330764529956374, 0.8344185549615, 0.8350560374720822, 0.8379988166048641, 0.8380210309146042, 0.8392820423471524, 0.8400201190389809, 0.8424483387164389, 0.84193180191839, 0.8422663171199221, 0.8439523430973536, 0.8446350468598003, 0.8449455777305657, 0.8461311489170485, 0.8459870439058167, 0.8472250496330797, 0.8485443568214284, 0.8487649961095295, 0.8497024857612, 0.8493021373422034, 0.8512373963845212, 0.8524243274342361, 0.8525665111178062, 0.8535877808064076, 0.8530675820524618, 0.8529616921224861, 0.8537009693397034, 0.8548505630020856, 0.8547644044248466, 0.8563052065794862, 0.8557278316728767, 0.8562199222550098, 0.8564374832597746, 0.8568684737488627, 0.8576454967686383, 0.8575853894285244, 0.8582857200264502, 0.8581432698837871, 0.8597860830434627, 0.859072916821933, 0.8594115106401811, 0.859575894368615, 0.860301666249651, 0.860662548489031, 0.8620430532498278, 0.8620524967793091, 0.8616277582364187, 0.8626056471995011, 0.8632650896982438, 0.8621281933094054]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.37s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.21s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.00s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:32,  1.59s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:53,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:49,  1.67s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:17,  1.77s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:56,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:17,  1.78s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:39,  1.87s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:51,  1.92s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:38,  1.88s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:57,  1.95s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:19,  2.04s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:29,  2.09s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:36,  2.12s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:40,  2.14s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:44,  2.17s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:39,  2.15s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<09:33,  2.14s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:37,  2.16s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<09:29,  2.14s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:31,  2.16s/it]predicting train subjects:   7%|▋         | 21/285 [00:42<09:37,  2.19s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:36,  2.19s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:29,  2.17s/it]predicting train subjects:   8%|▊         | 24/285 [00:49<09:26,  2.17s/it]predicting train subjects:   9%|▉         | 25/285 [00:51<09:17,  2.15s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:17,  2.15s/it]predicting train subjects:   9%|▉         | 27/285 [00:55<09:11,  2.14s/it]predicting train subjects:  10%|▉         | 28/285 [00:57<09:07,  2.13s/it]predicting train subjects:  10%|█         | 29/285 [00:59<08:48,  2.07s/it]predicting train subjects:  11%|█         | 30/285 [01:01<08:45,  2.06s/it]predicting train subjects:  11%|█         | 31/285 [01:03<08:42,  2.06s/it]predicting train subjects:  11%|█         | 32/285 [01:05<08:44,  2.07s/it]predicting train subjects:  12%|█▏        | 33/285 [01:07<08:29,  2.02s/it]predicting train subjects:  12%|█▏        | 34/285 [01:09<08:32,  2.04s/it]predicting train subjects:  12%|█▏        | 35/285 [01:11<08:15,  1.98s/it]predicting train subjects:  13%|█▎        | 36/285 [01:13<08:18,  2.00s/it]predicting train subjects:  13%|█▎        | 37/285 [01:15<08:11,  1.98s/it]predicting train subjects:  13%|█▎        | 38/285 [01:17<07:56,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:19<07:58,  1.95s/it]predicting train subjects:  14%|█▍        | 40/285 [01:21<07:51,  1.92s/it]predicting train subjects:  14%|█▍        | 41/285 [01:23<08:00,  1.97s/it]predicting train subjects:  15%|█▍        | 42/285 [01:25<07:58,  1.97s/it]predicting train subjects:  15%|█▌        | 43/285 [01:27<08:03,  2.00s/it]predicting train subjects:  15%|█▌        | 44/285 [01:29<07:56,  1.98s/it]predicting train subjects:  16%|█▌        | 45/285 [01:31<08:07,  2.03s/it]predicting train subjects:  16%|█▌        | 46/285 [01:33<07:44,  1.94s/it]predicting train subjects:  16%|█▋        | 47/285 [01:34<07:16,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:36<07:14,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:38<07:12,  1.83s/it]predicting train subjects:  18%|█▊        | 50/285 [01:40<07:04,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:41<06:48,  1.74s/it]predicting train subjects:  18%|█▊        | 52/285 [01:43<06:37,  1.70s/it]predicting train subjects:  19%|█▊        | 53/285 [01:45<06:32,  1.69s/it]predicting train subjects:  19%|█▉        | 54/285 [01:46<06:26,  1.68s/it]predicting train subjects:  19%|█▉        | 55/285 [01:48<06:26,  1.68s/it]predicting train subjects:  20%|█▉        | 56/285 [01:50<06:23,  1.67s/it]predicting train subjects:  20%|██        | 57/285 [01:51<06:16,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:53<06:17,  1.66s/it]predicting train subjects:  21%|██        | 59/285 [01:54<06:10,  1.64s/it]predicting train subjects:  21%|██        | 60/285 [01:56<06:08,  1.64s/it]predicting train subjects:  21%|██▏       | 61/285 [01:58<06:07,  1.64s/it]predicting train subjects:  22%|██▏       | 62/285 [01:59<06:08,  1.65s/it]predicting train subjects:  22%|██▏       | 63/285 [02:01<06:02,  1.63s/it]predicting train subjects:  22%|██▏       | 64/285 [02:03<05:59,  1.62s/it]predicting train subjects:  23%|██▎       | 65/285 [02:04<06:11,  1.69s/it]predicting train subjects:  23%|██▎       | 66/285 [02:06<06:20,  1.74s/it]predicting train subjects:  24%|██▎       | 67/285 [02:08<06:10,  1.70s/it]predicting train subjects:  24%|██▍       | 68/285 [02:10<06:08,  1.70s/it]predicting train subjects:  24%|██▍       | 69/285 [02:11<06:00,  1.67s/it]predicting train subjects:  25%|██▍       | 70/285 [02:13<05:59,  1.67s/it]predicting train subjects:  25%|██▍       | 71/285 [02:15<05:59,  1.68s/it]predicting train subjects:  25%|██▌       | 72/285 [02:16<05:52,  1.65s/it]predicting train subjects:  26%|██▌       | 73/285 [02:18<05:52,  1.66s/it]predicting train subjects:  26%|██▌       | 74/285 [02:20<05:53,  1.68s/it]predicting train subjects:  26%|██▋       | 75/285 [02:21<05:49,  1.66s/it]predicting train subjects:  27%|██▋       | 76/285 [02:23<05:47,  1.66s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<05:44,  1.66s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<05:44,  1.66s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<05:47,  1.69s/it]predicting train subjects:  28%|██▊       | 80/285 [02:30<05:44,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<05:41,  1.67s/it]predicting train subjects:  29%|██▉       | 82/285 [02:33<05:38,  1.67s/it]predicting train subjects:  29%|██▉       | 83/285 [02:35<05:37,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:36<05:29,  1.64s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<05:40,  1.70s/it]predicting train subjects:  30%|███       | 86/285 [02:40<05:46,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:42<05:47,  1.76s/it]predicting train subjects:  31%|███       | 88/285 [02:43<05:47,  1.76s/it]predicting train subjects:  31%|███       | 89/285 [02:45<05:42,  1.75s/it]predicting train subjects:  32%|███▏      | 90/285 [02:47<05:43,  1.76s/it]predicting train subjects:  32%|███▏      | 91/285 [02:49<05:44,  1.77s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<05:42,  1.78s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:44,  1.79s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:42,  1.79s/it]predicting train subjects:  33%|███▎      | 95/285 [02:56<05:41,  1.80s/it]predicting train subjects:  34%|███▎      | 96/285 [02:58<05:42,  1.81s/it]predicting train subjects:  34%|███▍      | 97/285 [03:00<05:40,  1.81s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:38,  1.81s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:36,  1.81s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:36,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:31,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:28,  1.80s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:25,  1.79s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:22,  1.78s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:18,  1.77s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:18,  1.79s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:15,  1.78s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:14,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:10,  1.77s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:16,  1.82s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:16,  1.83s/it]predicting train subjects:  40%|███▉      | 113/285 [03:28<05:08,  1.79s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:09,  1.82s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:04,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:35<05:00,  1.79s/it]predicting train subjects:  41%|████▏     | 118/285 [03:37<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:39<04:58,  1.80s/it]predicting train subjects:  42%|████▏     | 120/285 [03:41<05:00,  1.82s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:48,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [03:44<04:32,  1.67s/it]predicting train subjects:  43%|████▎     | 123/285 [03:45<04:20,  1.61s/it]predicting train subjects:  44%|████▎     | 124/285 [03:47<04:20,  1.62s/it]predicting train subjects:  44%|████▍     | 125/285 [03:49<04:21,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:50<04:16,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:52<04:15,  1.62s/it]predicting train subjects:  45%|████▍     | 128/285 [03:54<04:19,  1.65s/it]predicting train subjects:  45%|████▌     | 129/285 [03:55<04:17,  1.65s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<04:19,  1.67s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<04:14,  1.65s/it]predicting train subjects:  46%|████▋     | 132/285 [04:00<04:12,  1.65s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<04:10,  1.65s/it]predicting train subjects:  47%|████▋     | 134/285 [04:04<04:06,  1.63s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<04:05,  1.64s/it]predicting train subjects:  48%|████▊     | 136/285 [04:07<04:06,  1.66s/it]predicting train subjects:  48%|████▊     | 137/285 [04:09<04:07,  1.67s/it]predicting train subjects:  48%|████▊     | 138/285 [04:10<04:09,  1.70s/it]predicting train subjects:  49%|████▉     | 139/285 [04:12<04:09,  1.71s/it]predicting train subjects:  49%|████▉     | 140/285 [04:14<04:02,  1.67s/it]predicting train subjects:  49%|████▉     | 141/285 [04:15<03:59,  1.66s/it]predicting train subjects:  50%|████▉     | 142/285 [04:17<03:52,  1.63s/it]predicting train subjects:  50%|█████     | 143/285 [04:18<03:47,  1.60s/it]predicting train subjects:  51%|█████     | 144/285 [04:20<03:39,  1.55s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<03:37,  1.55s/it]predicting train subjects:  51%|█████     | 146/285 [04:23<03:29,  1.51s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:25,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:26<03:26,  1.50s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:23,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:29<03:21,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:30<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:32<03:18,  1.49s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:33<03:17,  1.50s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:35<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:36<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:38<03:10,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:39<03:08,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:41<03:10,  1.50s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:42<03:08,  1.50s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:44<03:09,  1.52s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:45<03:06,  1.50s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:47<03:03,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:48<03:03,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:50<02:59,  1.48s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:51<02:57,  1.48s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:53<02:57,  1.49s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:54<02:54,  1.48s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:56<02:51,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:57<02:51,  1.48s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:59<02:51,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [05:00<02:50,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [05:02<02:47,  1.49s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:47,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:05<02:46,  1.50s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:44,  1.49s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:43,  1.50s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:42,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:11<02:38,  1.48s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:12<02:34,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:13<02:32,  1.45s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:15<02:31,  1.46s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:16<02:27,  1.43s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:18<02:24,  1.42s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:19<02:25,  1.44s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:21<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:22<02:20,  1.42s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:23<02:17,  1.41s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:25<02:15,  1.40s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:26<02:11,  1.37s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:27<02:13,  1.40s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:29<02:10,  1.39s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:30<02:08,  1.38s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:32<02:08,  1.40s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:33<02:07,  1.41s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:34<02:05,  1.39s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:36<02:10,  1.47s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:38<02:14,  1.53s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:39<02:19,  1.60s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:41<02:19,  1.62s/it]predicting train subjects:  70%|███████   | 200/285 [05:43<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [05:45<02:19,  1.66s/it]predicting train subjects:  71%|███████   | 202/285 [05:46<02:19,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [05:48<02:18,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:50<02:18,  1.72s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:51<02:17,  1.72s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:53<02:14,  1.70s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:55<02:11,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:57<02:11,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:58<02:09,  1.71s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:00<02:08,  1.71s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:02<02:05,  1.70s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:03<02:05,  1.71s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:05<02:02,  1.70s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:07<01:55,  1.63s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:08<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:09<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:11<01:42,  1.51s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:12<01:40,  1.51s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:14<01:38,  1.49s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:15<01:36,  1.48s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:17<01:34,  1.48s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:18<01:34,  1.50s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:20<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:21<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:23<01:28,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:24<01:27,  1.48s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:26<01:26,  1.49s/it]predicting train subjects:  80%|████████  | 228/285 [06:27<01:24,  1.48s/it]predicting train subjects:  80%|████████  | 229/285 [06:29<01:23,  1.49s/it]predicting train subjects:  81%|████████  | 230/285 [06:30<01:21,  1.47s/it]predicting train subjects:  81%|████████  | 231/285 [06:32<01:18,  1.46s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:33<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:35<01:27,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:37<01:26,  1.70s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:39<01:27,  1.74s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:41<01:26,  1.77s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:43<01:26,  1.81s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:44<01:24,  1.80s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:46<01:22,  1.80s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:48<01:20,  1.79s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:50<01:18,  1.79s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:52<01:16,  1.77s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:53<01:14,  1.78s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:55<01:13,  1.80s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:57<01:11,  1.80s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:59<01:10,  1.81s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:01<01:08,  1.81s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:02<01:06,  1.79s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:04<01:04,  1.79s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:06<00:58,  1.68s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:07<00:53,  1.58s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:08<00:49,  1.51s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:10<00:47,  1.47s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:11<00:45,  1.45s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:12<00:42,  1.41s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:14<00:40,  1.41s/it]predicting train subjects:  90%|█████████ | 257/285 [07:15<00:39,  1.40s/it]predicting train subjects:  91%|█████████ | 258/285 [07:17<00:38,  1.41s/it]predicting train subjects:  91%|█████████ | 259/285 [07:18<00:36,  1.42s/it]predicting train subjects:  91%|█████████ | 260/285 [07:19<00:35,  1.40s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:21<00:33,  1.39s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:22<00:32,  1.41s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:24<00:31,  1.42s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:25<00:29,  1.40s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:26<00:27,  1.37s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:28<00:26,  1.39s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:29<00:25,  1.39s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:31<00:27,  1.59s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:33<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:35<00:26,  1.74s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:37<00:24,  1.78s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:39<00:23,  1.80s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:40<00:21,  1.80s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:42<00:19,  1.78s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:44<00:17,  1.79s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:46<00:16,  1.83s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:48<00:14,  1.82s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:50<00:12,  1.84s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:51<00:10,  1.82s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:53<00:09,  1.83s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:55<00:07,  1.83s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:57<00:05,  1.83s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:59<00:03,  1.80s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:00<00:01,  1.80s/it]predicting train subjects: 100%|██████████| 285/285 [08:02<00:00,  1.79s/it]

