*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/532) train vimp2_1448_08132015_SRI
(1/532) train vimp2_1452_10162014_SRI
(2/532) train vimp2_1510_04202015_SRI
(3/532) train vimp2_1519_04212015_SRI
(4/532) train vimp2_1530_04232015_SRI
(5/532) train vimp2_1557_05062015_SRI
(6/532) train vimp2_1559_05062015_SRI
(7/532) train vimp2_1564_05072015_SRI
(8/532) train vimp2_1604_10092015_SRI
(9/532) train vimp2_1620_05292015_SRI
(10/532) train vimp2_1621_05292015_SRI
(11/532) train vimp2_1621_10162015_SRI
(12/532) train vimp2_1622_05292015_SRI
(13/532) train vimp2_1623_05292015_SRI
(14/532) train vimp2_1632_10232015_SRI
(15/532) train vimp2_1648_10282015_SRI
(16/532) train vimp2_1689_06262015_SRI
(17/532) train vimp2_1709_07072015_SRI
(18/532) train vimp2_1712_11162015_SRI
(19/532) train vimp2_1724_11202015_SRI
(20/532) train vimp2_1751_12022015_SRI
(21/532) train vimp2_1756_12032015_SRI
(22/532) train vimp2_1761_12042015_SRI
(23/532) train vimp2_1844_01142016_SRI
(24/532) train vimp2_1847_01152016_SRI
(25/532) train vimp2_1888_01292016_SRI
(26/532) train vimp2_1907_02052016_SRI
(27/532) train vimp2_2039_03182016_SRI
(28/532) train vimp2_2119_04142016_SRI
(29/532) train vimp2_2309_07072016_SRI
(30/532) train vimp2_2390_07272016_SRI
(31/532) train vimp2_2398_07292016_SRI
(32/532) train vimp2_2450_08172016_SRI
(33/532) train vimp2_2459_08192016_SRI
(34/532) train vimp2_2460_08192016_SRI
(35/532) train vimp2_2476_08242016_SRI
(36/532) train vimp2_2484_08252016_SRI
(37/532) train vimp2_2485_08252016_SRI
(38/532) train vimp2_2499_08302016_SRI
(39/532) train vimp2_2617_10262016_SRI
(40/532) train vimp2_2618_10262016_SRI
(41/532) train vimp2_2628_10282016_SRI
(42/532) train vimp2_2878_01262017_SRI
(43/532) train vimp2_2914_02162017_Test_NewCases_SRI
(44/532) train vimp2_2926_02222017_Test_NewCases_SRI
(45/532) train vimp2_2946_03032017_Test_NewCases_SRI
(46/532) train vimp2_2948_03042017_Test_NewCases_SRI
(47/532) train vimp2_2966_03092017_Test_NewCases_SRI
(48/532) train vimp2_2972_03102017_Test_NewCases_SRI
(49/532) train vimp2_2998_03222017_Test_NewCases_SRI
(50/532) train vimp2_3131_05182017_SRI
(51/532) train vimp2_3187_06092017_SRI
(52/532) train vimp2_3349_08012017_SRI
(53/532) train vimp2_676_04252014_SRI
(54/532) train vimp2_804_06042014_SRI
(55/532) train vimp2_1082_12092014_SRI
(56/532) train vimp2_1116_12152014_SRI
(57/532) train vimp2_1278_02062015_SRI
(58/532) train vimp2_1443_08122015_SRI
(59/532) train vimp2_1662_10302015_SRI
(60/532) train vimp2_2438_08122016_SRI
(61/532) train vimp2_2846_01112017_SRI
(62/532) train vimp2_1139_12192014_SRI
(63/532) train vimp2_1220_01212015_SRI
(64/532) train vimp2_1400_03132015_SRI
(65/532) train vimp2_1510_09022015_SRI
(66/532) train vimp2_1739_11242015_SRI
(67/532) train vimp2_2462_08192016_Test_NewCases_SRI
(68/532) train vimp2_702_04302014_SRI
(69/532) train vimp2_969_07142014_SRI
(70/532) train vimp2_1100_08062014_SRI
(71/532) train vimp2_1276_02052015_SRI
(72/532) train vimp2_1410_03172015_SRI
(73/532) train vimp2_1595_05202015_SRI
(74/532) train vimp2_1875_01262016_SRI
(75/532) train vimp2_2951_03062017_Test_NewCases_SRI
(76/532) train vimp2_1082_12092014_SRI_Aug0_Rot_-3_sd1
(77/532) train vimp2_1082_12092014_SRI_Aug0_Rot_-6_sd2
(78/532) train vimp2_1082_12092014_SRI_Aug0_Rot_7_sd0
(79/532) train vimp2_1082_12092014_SRI_Aug1_Rot_-2_sd2
(80/532) train vimp2_1082_12092014_SRI_Aug1_Rot_-3_sd0
(81/532) train vimp2_1082_12092014_SRI_Aug1_Rot_-7_sd1
(82/532) train vimp2_1100_08062014_SRI_Aug0_Rot_2_sd1
(83/532) train vimp2_1100_08062014_SRI_Aug0_Rot_-2_sd2
(84/532) train vimp2_1100_08062014_SRI_Aug0_Rot_4_sd0
(85/532) train vimp2_1100_08062014_SRI_Aug1_Rot_-2_sd2
(86/532) train vimp2_1100_08062014_SRI_Aug1_Rot_-3_sd0
(87/532) train vimp2_1100_08062014_SRI_Aug1_Rot_5_sd1
(88/532) train vimp2_1116_12152014_SRI_Aug0_Rot_3_sd0
(89/532) train vimp2_1116_12152014_SRI_Aug0_Rot_3_sd2
(90/532) train vimp2_1116_12152014_SRI_Aug0_Rot_-7_sd1
(91/532) train vimp2_1116_12152014_SRI_Aug1_Rot_3_sd1
(92/532) train vimp2_1116_12152014_SRI_Aug1_Rot_6_sd2
(93/532) train vimp2_1116_12152014_SRI_Aug1_Rot_-7_sd0
(94/532) train vimp2_1139_12192014_SRI_Aug0_Rot_-2_sd1
(95/532) train vimp2_1139_12192014_SRI_Aug0_Rot_3_sd0
(96/532) train vimp2_1139_12192014_SRI_Aug0_Rot_-5_sd2
(97/532) train vimp2_1139_12192014_SRI_Aug1_Rot_-1_sd0
(98/532) train vimp2_1139_12192014_SRI_Aug1_Rot_3_sd2
(99/532) train vimp2_1139_12192014_SRI_Aug1_Rot_-6_sd1
(100/532) train vimp2_1220_01212015_SRI_Aug0_Rot_1_sd2
(101/532) train vimp2_1220_01212015_SRI_Aug0_Rot_6_sd1
(102/532) train vimp2_1220_01212015_SRI_Aug0_Rot_-7_sd0
(103/532) train vimp2_1220_01212015_SRI_Aug1_Rot_-1_sd0
(104/532) train vimp2_1220_01212015_SRI_Aug1_Rot_-1_sd2
(105/532) train vimp2_1220_01212015_SRI_Aug1_Rot_-4_sd1
(106/532) train vimp2_1276_02052015_SRI_Aug0_Rot_-1_sd0
(107/532) train vimp2_1276_02052015_SRI_Aug0_Rot_2_sd2
(108/532) train vimp2_1276_02052015_SRI_Aug0_Rot_7_sd1
(109/532) train vimp2_1276_02052015_SRI_Aug1_Rot_-2_sd1
(110/532) train vimp2_1276_02052015_SRI_Aug1_Rot_-4_sd2
(111/532) train vimp2_1276_02052015_SRI_Aug1_Rot_-6_sd0
(112/532) train vimp2_1278_02062015_SRI_Aug0_Rot_3_sd1
(113/532) train vimp2_1278_02062015_SRI_Aug0_Rot_3_sd2
(114/532) train vimp2_1278_02062015_SRI_Aug0_Rot_-5_sd0
(115/532) train vimp2_1278_02062015_SRI_Aug1_Rot_1_sd1
(116/532) train vimp2_1278_02062015_SRI_Aug1_Rot_-4_sd0
(117/532) train vimp2_1278_02062015_SRI_Aug1_Rot_5_sd2
(118/532) train vimp2_1400_03132015_SRI_Aug0_Rot_2_sd2
(119/532) train vimp2_1400_03132015_SRI_Aug0_Rot_-4_sd0
(120/532) train vimp2_1400_03132015_SRI_Aug0_Rot_-4_sd1
(121/532) train vimp2_1400_03132015_SRI_Aug1_Rot_1_sd1
(122/532) train vimp2_1400_03132015_SRI_Aug1_Rot_-2_sd2
(123/532) train vimp2_1400_03132015_SRI_Aug1_Rot_-6_sd0
(124/532) train vimp2_1410_03172015_SRI_Aug0_Rot_2_sd1
(125/532) train vimp2_1410_03172015_SRI_Aug0_Rot_-3_sd0
(126/532) train vimp2_1410_03172015_SRI_Aug0_Rot_-5_sd2
(127/532) train vimp2_1410_03172015_SRI_Aug1_Rot_-3_sd1
(128/532) train vimp2_1410_03172015_SRI_Aug1_Rot_5_sd2
(129/532) train vimp2_1410_03172015_SRI_Aug1_Rot_6_sd0
(130/532) train vimp2_1443_08122015_SRI_Aug0_Rot_1_sd2
(131/532) train vimp2_1443_08122015_SRI_Aug0_Rot_-5_sd0
(132/532) train vimp2_1443_08122015_SRI_Aug0_Rot_-7_sd1
(133/532) train vimp2_1443_08122015_SRI_Aug1_Rot_-1_sd1
(134/532) train vimp2_1443_08122015_SRI_Aug1_Rot_2_sd0
(135/532) train vimp2_1443_08122015_SRI_Aug1_Rot_7_sd2
(136/532) train vimp2_1448_08132015_SRI_Aug0_Rot_-1_sd0
(137/532) train vimp2_1448_08132015_SRI_Aug0_Rot_2_sd2
(138/532) train vimp2_1448_08132015_SRI_Aug0_Rot_-6_sd1
(139/532) train vimp2_1448_08132015_SRI_Aug1_Rot_1_sd1
(140/532) train vimp2_1448_08132015_SRI_Aug1_Rot_-3_sd0
(141/532) train vimp2_1448_08132015_SRI_Aug1_Rot_5_sd2
(142/532) train vimp2_1452_10162014_SRI_Aug0_Rot_-4_sd1
(143/532) train vimp2_1452_10162014_SRI_Aug0_Rot_-5_sd0
(144/532) train vimp2_1452_10162014_SRI_Aug0_Rot_6_sd2
(145/532) train vimp2_1452_10162014_SRI_Aug1_Rot_-4_sd1
(146/532) train vimp2_1452_10162014_SRI_Aug1_Rot_-4_sd2
(147/532) train vimp2_1452_10162014_SRI_Aug1_Rot_7_sd0
(148/532) train vimp2_1510_04202015_SRI_Aug0_Rot_1_sd2
(149/532) train vimp2_1510_04202015_SRI_Aug0_Rot_3_sd0
(150/532) train vimp2_1510_04202015_SRI_Aug0_Rot_-7_sd1
(151/532) train vimp2_1510_04202015_SRI_Aug1_Rot_-1_sd2
(152/532) train vimp2_1510_04202015_SRI_Aug1_Rot_3_sd0
(153/532) train vimp2_1510_04202015_SRI_Aug1_Rot_4_sd1
(154/532) train vimp2_1510_09022015_SRI_Aug0_Rot_-2_sd1
(155/532) train vimp2_1510_09022015_SRI_Aug0_Rot_3_sd0
(156/532) train vimp2_1510_09022015_SRI_Aug0_Rot_3_sd2
(157/532) train vimp2_1510_09022015_SRI_Aug1_Rot_3_sd0
(158/532) train vimp2_1510_09022015_SRI_Aug1_Rot_-5_sd2
(159/532) train vimp2_1510_09022015_SRI_Aug1_Rot_7_sd1
(160/532) train vimp2_1519_04212015_SRI_Aug0_Rot_1_sd0
(161/532) train vimp2_1519_04212015_SRI_Aug0_Rot_2_sd2
(162/532) train vimp2_1519_04212015_SRI_Aug0_Rot_5_sd1
(163/532) train vimp2_1519_04212015_SRI_Aug1_Rot_1_sd1
(164/532) train vimp2_1519_04212015_SRI_Aug1_Rot_2_sd2
(165/532) train vimp2_1519_04212015_SRI_Aug1_Rot_-6_sd0
(166/532) train vimp2_1530_04232015_SRI_Aug0_Rot_1_sd0
(167/532) train vimp2_1530_04232015_SRI_Aug0_Rot_1_sd2
(168/532) train vimp2_1530_04232015_SRI_Aug0_Rot_-5_sd1
(169/532) train vimp2_1530_04232015_SRI_Aug1_Rot_3_sd0
(170/532) train vimp2_1530_04232015_SRI_Aug1_Rot_-3_sd2
(171/532) train vimp2_1530_04232015_SRI_Aug1_Rot_-4_sd1
(172/532) train vimp2_1557_05062015_SRI_Aug0_Rot_-2_sd2
(173/532) train vimp2_1557_05062015_SRI_Aug0_Rot_4_sd1
(174/532) train vimp2_1557_05062015_SRI_Aug0_Rot_5_sd0
(175/532) train vimp2_1557_05062015_SRI_Aug1_Rot_-1_sd0
(176/532) train vimp2_1557_05062015_SRI_Aug1_Rot_-2_sd2
(177/532) train vimp2_1557_05062015_SRI_Aug1_Rot_3_sd1
(178/532) train vimp2_1559_05062015_SRI_Aug0_Rot_4_sd1
(179/532) train vimp2_1559_05062015_SRI_Aug0_Rot_-7_sd0
(180/532) train vimp2_1559_05062015_SRI_Aug0_Rot_7_sd2
(181/532) train vimp2_1559_05062015_SRI_Aug1_Rot_3_sd0
(182/532) train vimp2_1559_05062015_SRI_Aug1_Rot_-6_sd1
(183/532) train vimp2_1559_05062015_SRI_Aug1_Rot_-7_sd2
(184/532) train vimp2_1564_05072015_SRI_Aug0_Rot_-2_sd1
(185/532) train vimp2_1564_05072015_SRI_Aug0_Rot_6_sd2
(186/532) train vimp2_1564_05072015_SRI_Aug0_Rot_-7_sd0
(187/532) train vimp2_1564_05072015_SRI_Aug1_Rot_-1_sd0
(188/532) train vimp2_1564_05072015_SRI_Aug1_Rot_-4_sd1
(189/532) train vimp2_1564_05072015_SRI_Aug1_Rot_6_sd2
(190/532) train vimp2_1595_05202015_SRI_Aug0_Rot_3_sd0
(191/532) train vimp2_1595_05202015_SRI_Aug0_Rot_-6_sd2
(192/532) train vimp2_1595_05202015_SRI_Aug0_Rot_-7_sd1
(193/532) train vimp2_1595_05202015_SRI_Aug1_Rot_1_sd0
(194/532) train vimp2_1595_05202015_SRI_Aug1_Rot_2_sd1
(195/532) train vimp2_1595_05202015_SRI_Aug1_Rot_-2_sd2
(196/532) train vimp2_1604_10092015_SRI_Aug0_Rot_-1_sd2
(197/532) train vimp2_1604_10092015_SRI_Aug0_Rot_-4_sd1
(198/532) train vimp2_1604_10092015_SRI_Aug0_Rot_7_sd0
(199/532) train vimp2_1604_10092015_SRI_Aug1_Rot_1_sd2
(200/532) train vimp2_1604_10092015_SRI_Aug1_Rot_2_sd1
(201/532) train vimp2_1604_10092015_SRI_Aug1_Rot_5_sd0
(202/532) train vimp2_1620_05292015_SRI_Aug0_Rot_-6_sd1
(203/532) train vimp2_1620_05292015_SRI_Aug0_Rot_7_sd0
(204/532) train vimp2_1620_05292015_SRI_Aug0_Rot_7_sd2
(205/532) train vimp2_1620_05292015_SRI_Aug1_Rot_1_sd1
(206/532) train vimp2_1620_05292015_SRI_Aug1_Rot_3_sd2
(207/532) train vimp2_1620_05292015_SRI_Aug1_Rot_-4_sd0
(208/532) train vimp2_1621_05292015_SRI_Aug0_Rot_0_sd1
(209/532) train vimp2_1621_05292015_SRI_Aug0_Rot_4_sd2
(210/532) train vimp2_1621_05292015_SRI_Aug0_Rot_-7_sd0
(211/532) train vimp2_1621_05292015_SRI_Aug1_Rot_1_sd0
(212/532) train vimp2_1621_05292015_SRI_Aug1_Rot_2_sd1
(213/532) train vimp2_1621_05292015_SRI_Aug1_Rot_6_sd2
(214/532) train vimp2_1621_10162015_SRI_Aug0_Rot_1_sd1
(215/532) train vimp2_1621_10162015_SRI_Aug0_Rot_-2_sd0
(216/532) train vimp2_1621_10162015_SRI_Aug0_Rot_3_sd2
(217/532) train vimp2_1621_10162015_SRI_Aug1_Rot_-1_sd1
(218/532) train vimp2_1621_10162015_SRI_Aug1_Rot_2_sd0
(219/532) train vimp2_1621_10162015_SRI_Aug1_Rot_-4_sd2
(220/532) train vimp2_1622_05292015_SRI_Aug0_Rot_-1_sd0
(221/532) train vimp2_1622_05292015_SRI_Aug0_Rot_-1_sd1
(222/532) train vimp2_1622_05292015_SRI_Aug0_Rot_-5_sd2
(223/532) train vimp2_1622_05292015_SRI_Aug1_Rot_3_sd0
(224/532) train vimp2_1622_05292015_SRI_Aug1_Rot_3_sd2
(225/532) train vimp2_1622_05292015_SRI_Aug1_Rot_-5_sd1
(226/532) train vimp2_1623_05292015_SRI_Aug0_Rot_-3_sd0
(227/532) train vimp2_1623_05292015_SRI_Aug0_Rot_-3_sd2
(228/532) train vimp2_1623_05292015_SRI_Aug0_Rot_-4_sd1
(229/532) train vimp2_1623_05292015_SRI_Aug1_Rot_6_sd2
(230/532) train vimp2_1623_05292015_SRI_Aug1_Rot_7_sd0
(231/532) train vimp2_1623_05292015_SRI_Aug1_Rot_7_sd1
(232/532) train vimp2_1632_10232015_SRI_Aug0_Rot_0_sd2
(233/532) train vimp2_1632_10232015_SRI_Aug0_Rot_1_sd1
(234/532) train vimp2_1632_10232015_SRI_Aug0_Rot_-6_sd0
(235/532) train vimp2_1632_10232015_SRI_Aug1_Rot_-3_sd1
(236/532) train vimp2_1632_10232015_SRI_Aug1_Rot_4_sd2
(237/532) train vimp2_1632_10232015_SRI_Aug1_Rot_7_sd0
(238/532) train vimp2_1648_10282015_SRI_Aug0_Rot_-1_sd2
(239/532) train vimp2_1648_10282015_SRI_Aug0_Rot_3_sd0
(240/532) train vimp2_1648_10282015_SRI_Aug0_Rot_-4_sd1
(241/532) train vimp2_1648_10282015_SRI_Aug1_Rot_1_sd0
(242/532) train vimp2_1648_10282015_SRI_Aug1_Rot_2_sd2
(243/532) train vimp2_1648_10282015_SRI_Aug1_Rot_-3_sd1
(244/532) train vimp2_1662_10302015_SRI_Aug0_Rot_-3_sd0
(245/532) train vimp2_1662_10302015_SRI_Aug0_Rot_3_sd2
(246/532) train vimp2_1662_10302015_SRI_Aug0_Rot_-6_sd1
(247/532) train vimp2_1662_10302015_SRI_Aug1_Rot_-3_sd1
(248/532) train vimp2_1662_10302015_SRI_Aug1_Rot_-7_sd0
(249/532) train vimp2_1662_10302015_SRI_Aug1_Rot_-7_sd2
(250/532) train vimp2_1689_06262015_SRI_Aug0_Rot_-4_sd2
(251/532) train vimp2_1689_06262015_SRI_Aug0_Rot_5_sd0
(252/532) train vimp2_1689_06262015_SRI_Aug0_Rot_-7_sd1
(253/532) train vimp2_1689_06262015_SRI_Aug1_Rot_-1_sd0
(254/532) train vimp2_1689_06262015_SRI_Aug1_Rot_-2_sd1
(255/532) train vimp2_1689_06262015_SRI_Aug1_Rot_6_sd2
(256/532) train vimp2_1709_07072015_SRI_Aug0_Rot_5_sd1
(257/532) train vimp2_1709_07072015_SRI_Aug0_Rot_6_sd0
(258/532) train vimp2_1709_07072015_SRI_Aug0_Rot_-6_sd2
(259/532) train vimp2_1709_07072015_SRI_Aug1_Rot_0_sd2
(260/532) train vimp2_1709_07072015_SRI_Aug1_Rot_1_sd0
(261/532) train vimp2_1709_07072015_SRI_Aug1_Rot_-1_sd1
(262/532) train vimp2_1712_11162015_SRI_Aug0_Rot_3_sd0
(263/532) train vimp2_1712_11162015_SRI_Aug0_Rot_-3_sd1
(264/532) train vimp2_1712_11162015_SRI_Aug0_Rot_-3_sd2
(265/532) train vimp2_1712_11162015_SRI_Aug1_Rot_-4_sd0
(266/532) train vimp2_1712_11162015_SRI_Aug1_Rot_7_sd1
(267/532) train vimp2_1712_11162015_SRI_Aug1_Rot_7_sd2
(268/532) train vimp2_1724_11202015_SRI_Aug0_Rot_4_sd0
(269/532) train vimp2_1724_11202015_SRI_Aug0_Rot_4_sd1
(270/532) train vimp2_1724_11202015_SRI_Aug0_Rot_-4_sd2
(271/532) train vimp2_1724_11202015_SRI_Aug1_Rot_2_sd1
(272/532) train vimp2_1724_11202015_SRI_Aug1_Rot_-3_sd2
(273/532) train vimp2_1724_11202015_SRI_Aug1_Rot_4_sd0
(274/532) train vimp2_1739_11242015_SRI_Aug0_Rot_-3_sd0
(275/532) train vimp2_1739_11242015_SRI_Aug0_Rot_-4_sd2
(276/532) train vimp2_1739_11242015_SRI_Aug0_Rot_-5_sd1
(277/532) train vimp2_1739_11242015_SRI_Aug1_Rot_5_sd0
(278/532) train vimp2_1739_11242015_SRI_Aug1_Rot_-5_sd1
(279/532) train vimp2_1739_11242015_SRI_Aug1_Rot_7_sd2
(280/532) train vimp2_1751_12022015_SRI_Aug0_Rot_-1_sd1
(281/532) train vimp2_1751_12022015_SRI_Aug0_Rot_5_sd2
(282/532) train vimp2_1751_12022015_SRI_Aug0_Rot_6_sd0
(283/532) train vimp2_1751_12022015_SRI_Aug1_Rot_-4_sd2
(284/532) train vimp2_1751_12022015_SRI_Aug1_Rot_5_sd0
(285/532) train vimp2_1751_12022015_SRI_Aug1_Rot_-6_sd1
(286/532) train vimp2_1756_12032015_SRI_Aug0_Rot_-3_sd0
(287/532) train vimp2_1756_12032015_SRI_Aug0_Rot_5_sd2
(288/532) train vimp2_1756_12032015_SRI_Aug0_Rot_6_sd1
(289/532) train vimp2_1756_12032015_SRI_Aug1_Rot_-1_sd0
(290/532) train vimp2_1756_12032015_SRI_Aug1_Rot_5_sd1
(291/532) train vimp2_1756_12032015_SRI_Aug1_Rot_-7_sd2
(292/532) train vimp2_1761_12042015_SRI_Aug0_Rot_2_sd1
(293/532) train vimp2_1761_12042015_SRI_Aug0_Rot_7_sd0
(294/532) train vimp2_1761_12042015_SRI_Aug0_Rot_7_sd2
(295/532) train vimp2_1761_12042015_SRI_Aug1_Rot_1_sd2
(296/532) train vimp2_1761_12042015_SRI_Aug1_Rot_4_sd0
(297/532) train vimp2_1761_12042015_SRI_Aug1_Rot_-5_sd1
(298/532) train vimp2_1844_01142016_SRI_Aug0_Rot_1_sd1
(299/532) train vimp2_1844_01142016_SRI_Aug0_Rot_-1_sd2
(300/532) train vimp2_1844_01142016_SRI_Aug0_Rot_-2_sd0
(301/532) train vimp2_1844_01142016_SRI_Aug1_Rot_-2_sd1
(302/532) train vimp2_1844_01142016_SRI_Aug1_Rot_-2_sd2
(303/532) train vimp2_1844_01142016_SRI_Aug1_Rot_6_sd0
(304/532) train vimp2_1847_01152016_SRI_Aug0_Rot_-3_sd1
(305/532) train vimp2_1847_01152016_SRI_Aug0_Rot_4_sd2
(306/532) train vimp2_1847_01152016_SRI_Aug0_Rot_-5_sd0
(307/532) train vimp2_1847_01152016_SRI_Aug1_Rot_-2_sd2
(308/532) train vimp2_1847_01152016_SRI_Aug1_Rot_5_sd0
(309/532) train vimp2_1847_01152016_SRI_Aug1_Rot_-6_sd1
(310/532) train vimp2_1875_01262016_SRI_Aug0_Rot_3_sd0
(311/532) train vimp2_1875_01262016_SRI_Aug0_Rot_-3_sd1
(312/532) train vimp2_1875_01262016_SRI_Aug0_Rot_-3_sd2
(313/532) train vimp2_1875_01262016_SRI_Aug1_Rot_-2_sd1
(314/532) train vimp2_1875_01262016_SRI_Aug1_Rot_-4_sd2
(315/532) train vimp2_1875_01262016_SRI_Aug1_Rot_6_sd0
(316/532) train vimp2_1888_01292016_SRI_Aug0_Rot_2_sd0
(317/532) train vimp2_1888_01292016_SRI_Aug0_Rot_4_sd2
(318/532) train vimp2_1888_01292016_SRI_Aug0_Rot_-6_sd1
(319/532) train vimp2_1888_01292016_SRI_Aug1_Rot_-1_sd2
(320/532) train vimp2_1888_01292016_SRI_Aug1_Rot_-2_sd1
(321/532) train vimp2_1888_01292016_SRI_Aug1_Rot_4_sd0
(322/532) train vimp2_1907_02052016_SRI_Aug0_Rot_0_sd2
(323/532) train vimp2_1907_02052016_SRI_Aug0_Rot_-2_sd0
(324/532) train vimp2_1907_02052016_SRI_Aug0_Rot_-7_sd1
(325/532) train vimp2_1907_02052016_SRI_Aug1_Rot_-1_sd1
(326/532) train vimp2_1907_02052016_SRI_Aug1_Rot_2_sd0
(327/532) train vimp2_1907_02052016_SRI_Aug1_Rot_5_sd2
(328/532) train vimp2_2039_03182016_SRI_Aug0_Rot_-1_sd0
(329/532) train vimp2_2039_03182016_SRI_Aug0_Rot_2_sd2
(330/532) train vimp2_2039_03182016_SRI_Aug0_Rot_5_sd1
(331/532) train vimp2_2039_03182016_SRI_Aug1_Rot_-1_sd1
(332/532) train vimp2_2039_03182016_SRI_Aug1_Rot_-5_sd0
(333/532) train vimp2_2039_03182016_SRI_Aug1_Rot_5_sd2
(334/532) train vimp2_2119_04142016_SRI_Aug0_Rot_-2_sd2
(335/532) train vimp2_2119_04142016_SRI_Aug0_Rot_-3_sd0
(336/532) train vimp2_2119_04142016_SRI_Aug0_Rot_-4_sd1
(337/532) train vimp2_2119_04142016_SRI_Aug1_Rot_2_sd2
(338/532) train vimp2_2119_04142016_SRI_Aug1_Rot_-3_sd0
(339/532) train vimp2_2119_04142016_SRI_Aug1_Rot_3_sd1
(340/532) train vimp2_2309_07072016_SRI_Aug0_Rot_-1_sd1
(341/532) train vimp2_2309_07072016_SRI_Aug0_Rot_-6_sd2
(342/532) train vimp2_2309_07072016_SRI_Aug0_Rot_7_sd0
(343/532) train vimp2_2309_07072016_SRI_Aug1_Rot_-5_sd0
(344/532) train vimp2_2309_07072016_SRI_Aug1_Rot_5_sd1
(345/532) train vimp2_2309_07072016_SRI_Aug1_Rot_-6_sd2
(346/532) train vimp2_2390_07272016_SRI_Aug0_Rot_1_sd0
(347/532) train vimp2_2390_07272016_SRI_Aug0_Rot_-5_sd1
(348/532) train vimp2_2390_07272016_SRI_Aug0_Rot_-5_sd2
(349/532) train vimp2_2390_07272016_SRI_Aug1_Rot_-3_sd1
(350/532) train vimp2_2390_07272016_SRI_Aug1_Rot_5_sd0
(351/532) train vimp2_2390_07272016_SRI_Aug1_Rot_5_sd2
(352/532) train vimp2_2398_07292016_SRI_Aug0_Rot_-2_sd1
(353/532) train vimp2_2398_07292016_SRI_Aug0_Rot_-6_sd0
(354/532) train vimp2_2398_07292016_SRI_Aug0_Rot_6_sd2
(355/532) train vimp2_2398_07292016_SRI_Aug1_Rot_-2_sd0
(356/532) train vimp2_2398_07292016_SRI_Aug1_Rot_-3_sd2
(357/532) train vimp2_2398_07292016_SRI_Aug1_Rot_-4_sd1
(358/532) train vimp2_2438_08122016_SRI_Aug0_Rot_-1_sd1
(359/532) train vimp2_2438_08122016_SRI_Aug0_Rot_-5_sd2
(360/532) train vimp2_2438_08122016_SRI_Aug0_Rot_6_sd0
(361/532) train vimp2_2438_08122016_SRI_Aug1_Rot_4_sd0
(362/532) train vimp2_2438_08122016_SRI_Aug1_Rot_-4_sd2
(363/532) train vimp2_2438_08122016_SRI_Aug1_Rot_-6_sd1
(364/532) train vimp2_2450_08172016_SRI_Aug0_Rot_2_sd2
(365/532) train vimp2_2450_08172016_SRI_Aug0_Rot_5_sd1
(366/532) train vimp2_2450_08172016_SRI_Aug0_Rot_-7_sd0
(367/532) train vimp2_2450_08172016_SRI_Aug1_Rot_2_sd0
(368/532) train vimp2_2450_08172016_SRI_Aug1_Rot_-4_sd2
(369/532) train vimp2_2450_08172016_SRI_Aug1_Rot_6_sd1
(370/532) train vimp2_2459_08192016_SRI_Aug0_Rot_-2_sd1
(371/532) train vimp2_2459_08192016_SRI_Aug0_Rot_-5_sd0
(372/532) train vimp2_2459_08192016_SRI_Aug0_Rot_6_sd2
(373/532) train vimp2_2459_08192016_SRI_Aug1_Rot_-2_sd0
(374/532) train vimp2_2459_08192016_SRI_Aug1_Rot_-4_sd2
(375/532) train vimp2_2459_08192016_SRI_Aug1_Rot_-5_sd1
(376/532) train vimp2_2460_08192016_SRI_Aug0_Rot_2_sd1
(377/532) train vimp2_2460_08192016_SRI_Aug0_Rot_5_sd2
(378/532) train vimp2_2460_08192016_SRI_Aug0_Rot_6_sd0
(379/532) train vimp2_2460_08192016_SRI_Aug1_Rot_-4_sd0
(380/532) train vimp2_2460_08192016_SRI_Aug1_Rot_5_sd1
(381/532) train vimp2_2460_08192016_SRI_Aug1_Rot_-6_sd2
(382/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug0_Rot_-1_sd0
(383/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug0_Rot_-2_sd2
(384/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug0_Rot_3_sd1
(385/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug1_Rot_5_sd1
(386/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug1_Rot_5_sd2
(387/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug1_Rot_-6_sd0
(388/532) train vimp2_2476_08242016_SRI_Aug0_Rot_3_sd1
(389/532) train vimp2_2476_08242016_SRI_Aug0_Rot_3_sd2
(390/532) train vimp2_2476_08242016_SRI_Aug0_Rot_6_sd0
(391/532) train vimp2_2476_08242016_SRI_Aug1_Rot_5_sd1
(392/532) train vimp2_2476_08242016_SRI_Aug1_Rot_6_sd0
(393/532) train vimp2_2476_08242016_SRI_Aug1_Rot_7_sd2
(394/532) train vimp2_2484_08252016_SRI_Aug0_Rot_5_sd1
(395/532) train vimp2_2484_08252016_SRI_Aug0_Rot_6_sd0
(396/532) train vimp2_2484_08252016_SRI_Aug0_Rot_-7_sd2
(397/532) train vimp2_2484_08252016_SRI_Aug1_Rot_-1_sd0
(398/532) train vimp2_2484_08252016_SRI_Aug1_Rot_-1_sd1
(399/532) train vimp2_2484_08252016_SRI_Aug1_Rot_-5_sd2
(400/532) train vimp2_2485_08252016_SRI_Aug0_Rot_-1_sd0
(401/532) train vimp2_2485_08252016_SRI_Aug0_Rot_3_sd1
(402/532) train vimp2_2485_08252016_SRI_Aug0_Rot_-7_sd2
(403/532) train vimp2_2485_08252016_SRI_Aug1_Rot_4_sd2
(404/532) train vimp2_2485_08252016_SRI_Aug1_Rot_7_sd0
(405/532) train vimp2_2485_08252016_SRI_Aug1_Rot_7_sd1
(406/532) train vimp2_2499_08302016_SRI_Aug0_Rot_3_sd1
(407/532) train vimp2_2499_08302016_SRI_Aug0_Rot_-6_sd0
(408/532) train vimp2_2499_08302016_SRI_Aug0_Rot_7_sd2
(409/532) train vimp2_2499_08302016_SRI_Aug1_Rot_1_sd0
(410/532) train vimp2_2499_08302016_SRI_Aug1_Rot_2_sd1
(411/532) train vimp2_2499_08302016_SRI_Aug1_Rot_4_sd2
(412/532) train vimp2_2617_10262016_SRI_Aug0_Rot_-3_sd2
(413/532) train vimp2_2617_10262016_SRI_Aug0_Rot_4_sd0
(414/532) train vimp2_2617_10262016_SRI_Aug0_Rot_-7_sd1
(415/532) train vimp2_2617_10262016_SRI_Aug1_Rot_-4_sd2
(416/532) train vimp2_2617_10262016_SRI_Aug1_Rot_5_sd0
(417/532) train vimp2_2617_10262016_SRI_Aug1_Rot_5_sd1
(418/532) train vimp2_2618_10262016_SRI_Aug0_Rot_-1_sd1
(419/532) train vimp2_2618_10262016_SRI_Aug0_Rot_-2_sd0
(420/532) train vimp2_2618_10262016_SRI_Aug0_Rot_-3_sd2
(421/532) train vimp2_2618_10262016_SRI_Aug1_Rot_5_sd0
(422/532) train vimp2_2618_10262016_SRI_Aug1_Rot_-5_sd1
(423/532) train vimp2_2618_10262016_SRI_Aug1_Rot_7_sd2
(424/532) train vimp2_2628_10282016_SRI_Aug0_Rot_3_sd1
(425/532) train vimp2_2628_10282016_SRI_Aug0_Rot_4_sd2
(426/532) train vimp2_2628_10282016_SRI_Aug0_Rot_6_sd0
(427/532) train vimp2_2628_10282016_SRI_Aug1_Rot_-7_sd0
(428/532) train vimp2_2628_10282016_SRI_Aug1_Rot_-7_sd1
(429/532) train vimp2_2628_10282016_SRI_Aug1_Rot_-7_sd2
(430/532) train vimp2_2846_01112017_SRI_Aug0_Rot_1_sd1
(431/532) train vimp2_2846_01112017_SRI_Aug0_Rot_-3_sd0
(432/532) train vimp2_2846_01112017_SRI_Aug0_Rot_7_sd2
(433/532) train vimp2_2846_01112017_SRI_Aug1_Rot_1_sd2
(434/532) train vimp2_2846_01112017_SRI_Aug1_Rot_3_sd1
(435/532) train vimp2_2846_01112017_SRI_Aug1_Rot_5_sd0
(436/532) train vimp2_2878_01262017_SRI_Aug0_Rot_-3_sd0
(437/532) train vimp2_2878_01262017_SRI_Aug0_Rot_4_sd2
(438/532) train vimp2_2878_01262017_SRI_Aug0_Rot_-6_sd1
(439/532) train vimp2_2878_01262017_SRI_Aug1_Rot_3_sd1
(440/532) train vimp2_2878_01262017_SRI_Aug1_Rot_-5_sd2
(441/532) train vimp2_2878_01262017_SRI_Aug1_Rot_7_sd0
(442/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug0_Rot_-3_sd2
(443/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug0_Rot_6_sd0
(444/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug0_Rot_7_sd1
(445/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug1_Rot_-3_sd2
(446/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug1_Rot_6_sd1
(447/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug1_Rot_-7_sd0
(448/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug0_Rot_-1_sd0
(449/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug0_Rot_3_sd2
(450/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug0_Rot_-7_sd1
(451/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug1_Rot_1_sd0
(452/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug1_Rot_-5_sd2
(453/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug1_Rot_7_sd1
(454/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug0_Rot_0_sd1
(455/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug0_Rot_1_sd2
(456/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug0_Rot_-5_sd0
(457/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug1_Rot_0_sd0
(458/532)2019-06-30 18:31:55.681839: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-30 18:31:56.847390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-06-30 18:31:56.847456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 18:31:57.245253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 18:31:57.245315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 18:31:57.245327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 18:31:57.245817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:02,  1.91s/it]Loading train:   1%|          | 2/285 [00:04<09:22,  1.99s/it]Loading train:   1%|          | 3/285 [00:06<09:14,  1.97s/it]Loading train:   1%|▏         | 4/285 [00:08<09:31,  2.03s/it]Loading train:   2%|▏         | 5/285 [00:09<09:00,  1.93s/it]Loading train:   2%|▏         | 6/285 [00:12<09:20,  2.01s/it]Loading train:   2%|▏         | 7/285 [00:14<09:16,  2.00s/it]Loading train:   3%|▎         | 8/285 [00:16<09:24,  2.04s/it]Loading train:   3%|▎         | 9/285 [00:17<08:48,  1.91s/it]Loading train:   4%|▎         | 10/285 [00:19<08:51,  1.93s/it]Loading train:   4%|▍         | 11/285 [00:22<09:29,  2.08s/it]Loading train:   4%|▍         | 12/285 [00:24<09:19,  2.05s/it]Loading train:   5%|▍         | 13/285 [00:25<08:53,  1.96s/it]Loading train:   5%|▍         | 14/285 [00:28<09:27,  2.10s/it]Loading train:   5%|▌         | 15/285 [00:29<08:49,  1.96s/it]Loading train:   6%|▌         | 16/285 [00:32<08:51,  1.98s/it]Loading train:   6%|▌         | 17/285 [00:34<09:10,  2.05s/it]Loading train:   6%|▋         | 18/285 [00:36<08:45,  1.97s/it]Loading train:   7%|▋         | 19/285 [00:37<08:43,  1.97s/it]Loading train:   7%|▋         | 20/285 [00:39<08:37,  1.95s/it]Loading train:   7%|▋         | 21/285 [00:41<08:19,  1.89s/it]Loading train:   8%|▊         | 22/285 [00:43<08:04,  1.84s/it]Loading train:   8%|▊         | 23/285 [00:45<08:15,  1.89s/it]Loading train:   8%|▊         | 24/285 [00:47<08:02,  1.85s/it]Loading train:   9%|▉         | 25/285 [00:48<07:38,  1.77s/it]Loading train:   9%|▉         | 26/285 [00:50<07:47,  1.81s/it]Loading train:   9%|▉         | 27/285 [00:52<08:04,  1.88s/it]Loading train:  10%|▉         | 28/285 [00:54<08:26,  1.97s/it]Loading train:  10%|█         | 29/285 [00:56<08:06,  1.90s/it]Loading train:  11%|█         | 30/285 [00:58<08:00,  1.88s/it]Loading train:  11%|█         | 31/285 [01:00<08:23,  1.98s/it]Loading train:  11%|█         | 32/285 [01:02<07:57,  1.89s/it]Loading train:  12%|█▏        | 33/285 [01:04<08:06,  1.93s/it]Loading train:  12%|█▏        | 34/285 [01:06<08:08,  1.95s/it]Loading train:  12%|█▏        | 35/285 [01:08<08:30,  2.04s/it]Loading train:  13%|█▎        | 36/285 [01:10<08:17,  2.00s/it]Loading train:  13%|█▎        | 37/285 [01:12<08:24,  2.03s/it]Loading train:  13%|█▎        | 38/285 [01:14<08:18,  2.02s/it]Loading train:  14%|█▎        | 39/285 [01:16<08:29,  2.07s/it]Loading train:  14%|█▍        | 40/285 [01:18<08:40,  2.12s/it]Loading train:  14%|█▍        | 41/285 [01:20<08:04,  1.99s/it]Loading train:  15%|█▍        | 42/285 [01:22<07:42,  1.90s/it]Loading train:  15%|█▌        | 43/285 [01:24<07:59,  1.98s/it]Loading train:  15%|█▌        | 44/285 [01:26<07:48,  1.94s/it]Loading train:  16%|█▌        | 45/285 [01:28<07:50,  1.96s/it]Loading train:  16%|█▌        | 46/285 [01:30<07:59,  2.00s/it]Loading train:  16%|█▋        | 47/285 [01:32<07:23,  1.87s/it]Loading train:  17%|█▋        | 48/285 [01:33<07:09,  1.81s/it]Loading train:  17%|█▋        | 49/285 [01:35<07:08,  1.81s/it]Loading train:  18%|█▊        | 50/285 [01:37<07:06,  1.81s/it]Loading train:  18%|█▊        | 51/285 [01:38<06:36,  1.70s/it]Loading train:  18%|█▊        | 52/285 [01:40<06:38,  1.71s/it]Loading train:  19%|█▊        | 53/285 [01:42<06:46,  1.75s/it]Loading train:  19%|█▉        | 54/285 [01:43<06:28,  1.68s/it]Loading train:  19%|█▉        | 55/285 [01:45<06:37,  1.73s/it]Loading train:  20%|█▉        | 56/285 [01:47<06:48,  1.78s/it]Loading train:  20%|██        | 57/285 [01:49<06:36,  1.74s/it]Loading train:  20%|██        | 58/285 [01:51<06:46,  1.79s/it]Loading train:  21%|██        | 59/285 [01:52<06:21,  1.69s/it]Loading train:  21%|██        | 60/285 [01:54<06:25,  1.71s/it]Loading train:  21%|██▏       | 61/285 [01:56<06:26,  1.73s/it]Loading train:  22%|██▏       | 62/285 [01:57<06:23,  1.72s/it]Loading train:  22%|██▏       | 63/285 [01:59<06:22,  1.72s/it]Loading train:  22%|██▏       | 64/285 [02:01<06:32,  1.77s/it]Loading train:  23%|██▎       | 65/285 [02:03<06:58,  1.90s/it]Loading train:  23%|██▎       | 66/285 [02:06<07:45,  2.13s/it]Loading train:  24%|██▎       | 67/285 [02:08<07:16,  2.00s/it]Loading train:  24%|██▍       | 68/285 [02:10<07:12,  2.00s/it]Loading train:  24%|██▍       | 69/285 [02:11<06:33,  1.82s/it]Loading train:  25%|██▍       | 70/285 [02:13<06:37,  1.85s/it]Loading train:  25%|██▍       | 71/285 [02:15<06:40,  1.87s/it]Loading train:  25%|██▌       | 72/285 [02:17<06:55,  1.95s/it]Loading train:  26%|██▌       | 73/285 [02:19<07:16,  2.06s/it]Loading train:  26%|██▌       | 74/285 [02:21<07:08,  2.03s/it]Loading train:  26%|██▋       | 75/285 [02:23<06:36,  1.89s/it]Loading train:  27%|██▋       | 76/285 [02:24<06:16,  1.80s/it]Loading train:  27%|██▋       | 77/285 [02:26<06:07,  1.77s/it]Loading train:  27%|██▋       | 78/285 [02:27<05:42,  1.65s/it]Loading train:  28%|██▊       | 79/285 [02:29<06:01,  1.76s/it]Loading train:  28%|██▊       | 80/285 [02:31<05:49,  1.70s/it]Loading train:  28%|██▊       | 81/285 [02:33<05:44,  1.69s/it]Loading train:  29%|██▉       | 82/285 [02:34<05:32,  1.64s/it]Loading train:  29%|██▉       | 83/285 [02:36<05:51,  1.74s/it]Loading train:  29%|██▉       | 84/285 [02:38<05:30,  1.64s/it]Loading train:  30%|██▉       | 85/285 [02:40<06:06,  1.83s/it]Loading train:  30%|███       | 86/285 [02:42<06:20,  1.91s/it]Loading train:  31%|███       | 87/285 [02:44<06:27,  1.96s/it]Loading train:  31%|███       | 88/285 [02:46<06:40,  2.03s/it]Loading train:  31%|███       | 89/285 [02:48<06:27,  1.98s/it]Loading train:  32%|███▏      | 90/285 [02:50<06:07,  1.88s/it]Loading train:  32%|███▏      | 91/285 [02:52<05:58,  1.85s/it]Loading train:  32%|███▏      | 92/285 [02:54<06:13,  1.94s/it]Loading train:  33%|███▎      | 93/285 [02:56<06:41,  2.09s/it]Loading train:  33%|███▎      | 94/285 [02:58<06:14,  1.96s/it]Loading train:  33%|███▎      | 95/285 [02:59<05:56,  1.88s/it]Loading train:  34%|███▎      | 96/285 [03:01<05:41,  1.81s/it]Loading train:  34%|███▍      | 97/285 [03:02<05:17,  1.69s/it]Loading train:  34%|███▍      | 98/285 [03:04<05:13,  1.68s/it]Loading train:  35%|███▍      | 99/285 [03:06<05:05,  1.64s/it]Loading train:  35%|███▌      | 100/285 [03:07<05:00,  1.62s/it]Loading train:  35%|███▌      | 101/285 [03:09<04:46,  1.56s/it]Loading train:  36%|███▌      | 102/285 [03:10<04:48,  1.58s/it]Loading train:  36%|███▌      | 103/285 [03:12<04:36,  1.52s/it]Loading train:  36%|███▋      | 104/285 [03:13<04:13,  1.40s/it]Loading train:  37%|███▋      | 105/285 [03:14<03:58,  1.33s/it]Loading train:  37%|███▋      | 106/285 [03:15<04:04,  1.37s/it]Loading train:  38%|███▊      | 107/285 [03:17<04:09,  1.40s/it]Loading train:  38%|███▊      | 108/285 [03:19<04:59,  1.69s/it]Loading train:  38%|███▊      | 109/285 [03:21<05:10,  1.76s/it]Loading train:  39%|███▊      | 110/285 [03:23<04:54,  1.68s/it]Loading train:  39%|███▉      | 111/285 [03:24<04:41,  1.62s/it]Loading train:  39%|███▉      | 112/285 [03:26<04:25,  1.53s/it]Loading train:  40%|███▉      | 113/285 [03:27<04:21,  1.52s/it]Loading train:  40%|████      | 114/285 [03:28<04:09,  1.46s/it]Loading train:  40%|████      | 115/285 [03:30<03:56,  1.39s/it]Loading train:  41%|████      | 116/285 [03:31<04:13,  1.50s/it]Loading train:  41%|████      | 117/285 [03:33<04:12,  1.50s/it]Loading train:  41%|████▏     | 118/285 [03:34<03:54,  1.40s/it]Loading train:  42%|████▏     | 119/285 [03:35<03:44,  1.35s/it]Loading train:  42%|████▏     | 120/285 [03:37<04:10,  1.52s/it]Loading train:  42%|████▏     | 121/285 [03:39<04:10,  1.53s/it]Loading train:  43%|████▎     | 122/285 [03:40<04:10,  1.54s/it]Loading train:  43%|████▎     | 123/285 [03:42<03:57,  1.46s/it]Loading train:  44%|████▎     | 124/285 [03:43<04:04,  1.52s/it]Loading train:  44%|████▍     | 125/285 [03:45<03:56,  1.48s/it]Loading train:  44%|████▍     | 126/285 [03:46<03:46,  1.42s/it]Loading train:  45%|████▍     | 127/285 [03:47<03:37,  1.38s/it]Loading train:  45%|████▍     | 128/285 [03:49<03:39,  1.40s/it]Loading train:  45%|████▌     | 129/285 [03:50<03:26,  1.32s/it]Loading train:  46%|████▌     | 130/285 [03:51<03:21,  1.30s/it]Loading train:  46%|████▌     | 131/285 [03:52<03:17,  1.28s/it]Loading train:  46%|████▋     | 132/285 [03:53<03:12,  1.26s/it]Loading train:  47%|████▋     | 133/285 [03:55<03:28,  1.37s/it]Loading train:  47%|████▋     | 134/285 [03:56<03:27,  1.38s/it]Loading train:  47%|████▋     | 135/285 [03:58<03:34,  1.43s/it]Loading train:  48%|████▊     | 136/285 [03:59<03:32,  1.43s/it]Loading train:  48%|████▊     | 137/285 [04:01<03:40,  1.49s/it]Loading train:  48%|████▊     | 138/285 [04:03<03:49,  1.56s/it]Loading train:  49%|████▉     | 139/285 [04:05<03:59,  1.64s/it]Loading train:  49%|████▉     | 140/285 [04:06<04:00,  1.66s/it]Loading train:  49%|████▉     | 141/285 [04:08<03:48,  1.58s/it]Loading train:  50%|████▉     | 142/285 [04:09<03:47,  1.59s/it]Loading train:  50%|█████     | 143/285 [04:11<03:51,  1.63s/it]Loading train:  51%|█████     | 144/285 [04:13<03:48,  1.62s/it]Loading train:  51%|█████     | 145/285 [04:14<03:38,  1.56s/it]Loading train:  51%|█████     | 146/285 [04:15<03:24,  1.47s/it]Loading train:  52%|█████▏    | 147/285 [04:17<03:17,  1.43s/it]Loading train:  52%|█████▏    | 148/285 [04:18<03:23,  1.49s/it]Loading train:  52%|█████▏    | 149/285 [04:20<03:20,  1.47s/it]Loading train:  53%|█████▎    | 150/285 [04:22<03:32,  1.57s/it]Loading train:  53%|█████▎    | 151/285 [04:23<03:19,  1.49s/it]Loading train:  53%|█████▎    | 152/285 [04:24<03:24,  1.53s/it]Loading train:  54%|█████▎    | 153/285 [04:26<03:25,  1.55s/it]Loading train:  54%|█████▍    | 154/285 [04:28<03:27,  1.58s/it]Loading train:  54%|█████▍    | 155/285 [04:29<03:28,  1.60s/it]Loading train:  55%|█████▍    | 156/285 [04:30<03:07,  1.46s/it]Loading train:  55%|█████▌    | 157/285 [04:32<03:10,  1.49s/it]Loading train:  55%|█████▌    | 158/285 [04:33<03:02,  1.43s/it]Loading train:  56%|█████▌    | 159/285 [04:35<03:00,  1.43s/it]Loading train:  56%|█████▌    | 160/285 [04:36<02:55,  1.41s/it]Loading train:  56%|█████▋    | 161/285 [04:38<02:54,  1.40s/it]Loading train:  57%|█████▋    | 162/285 [04:39<02:50,  1.39s/it]Loading train:  57%|█████▋    | 163/285 [04:41<02:59,  1.47s/it]Loading train:  58%|█████▊    | 164/285 [04:42<03:01,  1.50s/it]Loading train:  58%|█████▊    | 165/285 [04:43<02:56,  1.47s/it]Loading train:  58%|█████▊    | 166/285 [04:45<02:56,  1.48s/it]Loading train:  59%|█████▊    | 167/285 [04:46<02:52,  1.47s/it]Loading train:  59%|█████▉    | 168/285 [04:48<02:58,  1.53s/it]Loading train:  59%|█████▉    | 169/285 [04:50<03:02,  1.57s/it]Loading train:  60%|█████▉    | 170/285 [04:51<02:55,  1.52s/it]Loading train:  60%|██████    | 171/285 [04:53<02:51,  1.50s/it]Loading train:  60%|██████    | 172/285 [04:54<02:45,  1.47s/it]Loading train:  61%|██████    | 173/285 [04:55<02:41,  1.44s/it]Loading train:  61%|██████    | 174/285 [04:57<02:48,  1.52s/it]Loading train:  61%|██████▏   | 175/285 [04:58<02:40,  1.46s/it]Loading train:  62%|██████▏   | 176/285 [05:00<02:32,  1.40s/it]Loading train:  62%|██████▏   | 177/285 [05:01<02:32,  1.42s/it]Loading train:  62%|██████▏   | 178/285 [05:03<02:37,  1.47s/it]Loading train:  63%|██████▎   | 179/285 [05:05<02:47,  1.58s/it]Loading train:  63%|██████▎   | 180/285 [05:06<02:38,  1.51s/it]Loading train:  64%|██████▎   | 181/285 [05:08<02:43,  1.57s/it]Loading train:  64%|██████▍   | 182/285 [05:09<02:42,  1.58s/it]Loading train:  64%|██████▍   | 183/285 [05:11<02:41,  1.59s/it]Loading train:  65%|██████▍   | 184/285 [05:12<02:36,  1.55s/it]Loading train:  65%|██████▍   | 185/285 [05:13<02:24,  1.44s/it]Loading train:  65%|██████▌   | 186/285 [05:15<02:16,  1.38s/it]Loading train:  66%|██████▌   | 187/285 [05:16<02:21,  1.44s/it]Loading train:  66%|██████▌   | 188/285 [05:18<02:15,  1.40s/it]Loading train:  66%|██████▋   | 189/285 [05:19<02:14,  1.40s/it]Loading train:  67%|██████▋   | 190/285 [05:21<02:24,  1.52s/it]Loading train:  67%|██████▋   | 191/285 [05:22<02:16,  1.45s/it]Loading train:  67%|██████▋   | 192/285 [05:23<02:13,  1.43s/it]Loading train:  68%|██████▊   | 193/285 [05:25<02:15,  1.47s/it]Loading train:  68%|██████▊   | 194/285 [05:26<02:05,  1.37s/it]Loading train:  68%|██████▊   | 195/285 [05:28<02:07,  1.41s/it]Loading train:  69%|██████▉   | 196/285 [05:29<02:09,  1.46s/it]Loading train:  69%|██████▉   | 197/285 [05:31<02:16,  1.55s/it]Loading train:  69%|██████▉   | 198/285 [05:33<02:12,  1.53s/it]Loading train:  70%|██████▉   | 199/285 [05:34<02:16,  1.59s/it]Loading train:  70%|███████   | 200/285 [05:36<02:17,  1.62s/it]Loading train:  71%|███████   | 201/285 [05:37<02:13,  1.59s/it]Loading train:  71%|███████   | 202/285 [05:39<02:13,  1.60s/it]Loading train:  71%|███████   | 203/285 [05:40<02:06,  1.54s/it]Loading train:  72%|███████▏  | 204/285 [05:42<02:03,  1.52s/it]Loading train:  72%|███████▏  | 205/285 [05:44<02:13,  1.67s/it]Loading train:  72%|███████▏  | 206/285 [05:46<02:08,  1.63s/it]Loading train:  73%|███████▎  | 207/285 [05:47<02:00,  1.55s/it]Loading train:  73%|███████▎  | 208/285 [05:49<02:02,  1.59s/it]Loading train:  73%|███████▎  | 209/285 [05:50<01:58,  1.56s/it]Loading train:  74%|███████▎  | 210/285 [05:52<01:54,  1.53s/it]Loading train:  74%|███████▍  | 211/285 [05:53<01:58,  1.60s/it]Loading train:  74%|███████▍  | 212/285 [05:55<01:53,  1.55s/it]Loading train:  75%|███████▍  | 213/285 [05:56<01:51,  1.54s/it]Loading train:  75%|███████▌  | 214/285 [05:57<01:42,  1.44s/it]Loading train:  75%|███████▌  | 215/285 [05:59<01:35,  1.36s/it]Loading train:  76%|███████▌  | 216/285 [06:00<01:40,  1.45s/it]Loading train:  76%|███████▌  | 217/285 [06:02<01:41,  1.50s/it]Loading train:  76%|███████▋  | 218/285 [06:04<01:43,  1.54s/it]Loading train:  77%|███████▋  | 219/285 [06:05<01:37,  1.48s/it]Loading train:  77%|███████▋  | 220/285 [06:06<01:34,  1.45s/it]Loading train:  78%|███████▊  | 221/285 [06:08<01:36,  1.50s/it]Loading train:  78%|███████▊  | 222/285 [06:09<01:29,  1.42s/it]Loading train:  78%|███████▊  | 223/285 [06:11<01:35,  1.53s/it]Loading train:  79%|███████▊  | 224/285 [06:12<01:33,  1.54s/it]Loading train:  79%|███████▉  | 225/285 [06:14<01:27,  1.45s/it]Loading train:  79%|███████▉  | 226/285 [06:15<01:25,  1.45s/it]Loading train:  80%|███████▉  | 227/285 [06:17<01:26,  1.49s/it]Loading train:  80%|████████  | 228/285 [06:18<01:26,  1.52s/it]Loading train:  80%|████████  | 229/285 [06:20<01:27,  1.56s/it]Loading train:  81%|████████  | 230/285 [06:22<01:25,  1.56s/it]Loading train:  81%|████████  | 231/285 [06:23<01:22,  1.52s/it]Loading train:  81%|████████▏ | 232/285 [06:25<01:23,  1.57s/it]Loading train:  82%|████████▏ | 233/285 [06:26<01:19,  1.53s/it]Loading train:  82%|████████▏ | 234/285 [06:28<01:19,  1.55s/it]Loading train:  82%|████████▏ | 235/285 [06:29<01:18,  1.58s/it]Loading train:  83%|████████▎ | 236/285 [06:31<01:22,  1.68s/it]Loading train:  83%|████████▎ | 237/285 [06:33<01:21,  1.71s/it]Loading train:  84%|████████▎ | 238/285 [06:35<01:21,  1.74s/it]Loading train:  84%|████████▍ | 239/285 [06:36<01:17,  1.69s/it]Loading train:  84%|████████▍ | 240/285 [06:38<01:15,  1.67s/it]Loading train:  85%|████████▍ | 241/285 [06:40<01:15,  1.71s/it]Loading train:  85%|████████▍ | 242/285 [06:41<01:10,  1.64s/it]Loading train:  85%|████████▌ | 243/285 [06:43<01:12,  1.74s/it]Loading train:  86%|████████▌ | 244/285 [06:45<01:15,  1.84s/it]Loading train:  86%|████████▌ | 245/285 [06:47<01:11,  1.78s/it]Loading train:  86%|████████▋ | 246/285 [06:49<01:07,  1.74s/it]Loading train:  87%|████████▋ | 247/285 [06:50<01:07,  1.77s/it]Loading train:  87%|████████▋ | 248/285 [06:52<01:08,  1.84s/it]Loading train:  87%|████████▋ | 249/285 [06:54<01:05,  1.82s/it]Loading train:  88%|████████▊ | 250/285 [06:56<01:01,  1.75s/it]Loading train:  88%|████████▊ | 251/285 [06:57<00:53,  1.59s/it]Loading train:  88%|████████▊ | 252/285 [06:59<00:51,  1.57s/it]Loading train:  89%|████████▉ | 253/285 [07:00<00:48,  1.50s/it]Loading train:  89%|████████▉ | 254/285 [07:01<00:45,  1.45s/it]Loading train:  89%|████████▉ | 255/285 [07:03<00:46,  1.56s/it]Loading train:  90%|████████▉ | 256/285 [07:05<00:44,  1.53s/it]Loading train:  90%|█████████ | 257/285 [07:06<00:42,  1.52s/it]Loading train:  91%|█████████ | 258/285 [07:08<00:41,  1.52s/it]Loading train:  91%|█████████ | 259/285 [07:09<00:38,  1.50s/it]Loading train:  91%|█████████ | 260/285 [07:10<00:35,  1.42s/it]Loading train:  92%|█████████▏| 261/285 [07:12<00:34,  1.43s/it]Loading train:  92%|█████████▏| 262/285 [07:13<00:34,  1.49s/it]Loading train:  92%|█████████▏| 263/285 [07:15<00:32,  1.46s/it]Loading train:  93%|█████████▎| 264/285 [07:16<00:30,  1.45s/it]Loading train:  93%|█████████▎| 265/285 [07:18<00:28,  1.43s/it]Loading train:  93%|█████████▎| 266/285 [07:19<00:26,  1.41s/it]Loading train:  94%|█████████▎| 267/285 [07:20<00:24,  1.38s/it]Loading train:  94%|█████████▍| 268/285 [07:22<00:25,  1.49s/it]Loading train:  94%|█████████▍| 269/285 [07:24<00:24,  1.52s/it]Loading train:  95%|█████████▍| 270/285 [07:25<00:22,  1.52s/it]Loading train:  95%|█████████▌| 271/285 [07:27<00:22,  1.63s/it]Loading train:  95%|█████████▌| 272/285 [07:29<00:20,  1.61s/it]Loading train:  96%|█████████▌| 273/285 [07:30<00:20,  1.68s/it]Loading train:  96%|█████████▌| 274/285 [07:32<00:18,  1.64s/it]Loading train:  96%|█████████▋| 275/285 [07:34<00:16,  1.63s/it]Loading train:  97%|█████████▋| 276/285 [07:35<00:15,  1.67s/it]Loading train:  97%|█████████▋| 277/285 [07:37<00:13,  1.72s/it]Loading train:  98%|█████████▊| 278/285 [07:39<00:12,  1.75s/it]Loading train:  98%|█████████▊| 279/285 [07:40<00:09,  1.65s/it]Loading train:  98%|█████████▊| 280/285 [07:42<00:08,  1.62s/it]Loading train:  99%|█████████▊| 281/285 [07:43<00:06,  1.59s/it]Loading train:  99%|█████████▉| 282/285 [07:45<00:04,  1.66s/it]Loading train:  99%|█████████▉| 283/285 [07:47<00:03,  1.63s/it]Loading train: 100%|█████████▉| 284/285 [07:49<00:01,  1.71s/it]Loading train: 100%|██████████| 285/285 [07:50<00:00,  1.70s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:19, 14.85it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:18, 15.35it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:17, 16.34it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:14, 18.65it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:12, 21.02it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:11, 24.33it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:09, 27.98it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:08, 30.69it/s]concatenating: train:  11%|█         | 31/285 [00:01<00:07, 33.62it/s]concatenating: train:  12%|█▏        | 35/285 [00:01<00:07, 32.87it/s]concatenating: train:  14%|█▎        | 39/285 [00:01<00:07, 34.02it/s]concatenating: train:  15%|█▌        | 43/285 [00:01<00:07, 31.87it/s]concatenating: train:  17%|█▋        | 48/285 [00:01<00:07, 32.94it/s]concatenating: train:  18%|█▊        | 52/285 [00:01<00:07, 32.73it/s]concatenating: train:  20%|█▉        | 56/285 [00:01<00:07, 32.27it/s]concatenating: train:  21%|██        | 60/285 [00:01<00:06, 32.87it/s]concatenating: train:  23%|██▎       | 66/285 [00:02<00:05, 37.46it/s]concatenating: train:  25%|██▍       | 71/285 [00:02<00:05, 39.40it/s]concatenating: train:  27%|██▋       | 76/285 [00:02<00:05, 40.44it/s]concatenating: train:  29%|██▉       | 82/285 [00:02<00:04, 43.62it/s]concatenating: train:  31%|███       | 87/285 [00:02<00:04, 44.66it/s]concatenating: train:  33%|███▎      | 93/285 [00:02<00:04, 46.79it/s]concatenating: train:  34%|███▍      | 98/285 [00:02<00:04, 44.12it/s]concatenating: train:  36%|███▌      | 103/285 [00:02<00:04, 43.12it/s]concatenating: train:  39%|███▊      | 110/285 [00:02<00:03, 47.37it/s]concatenating: train:  41%|████      | 116/285 [00:03<00:03, 48.64it/s]concatenating: train:  43%|████▎     | 122/285 [00:03<00:03, 51.52it/s]concatenating: train:  45%|████▍     | 128/285 [00:03<00:03, 45.07it/s]concatenating: train:  47%|████▋     | 133/285 [00:03<00:03, 45.93it/s]concatenating: train:  48%|████▊     | 138/285 [00:03<00:03, 42.34it/s]concatenating: train:  51%|█████     | 144/285 [00:03<00:03, 46.33it/s]concatenating: train:  53%|█████▎    | 151/285 [00:03<00:02, 50.30it/s]concatenating: train:  55%|█████▌    | 157/285 [00:03<00:02, 51.24it/s]concatenating: train:  58%|█████▊    | 164/285 [00:04<00:02, 53.67it/s]concatenating: train:  60%|█████▉    | 170/285 [00:04<00:02, 53.70it/s]concatenating: train:  62%|██████▏   | 176/285 [00:04<00:02, 51.93it/s]concatenating: train:  64%|██████▍   | 183/285 [00:04<00:01, 54.71it/s]concatenating: train:  67%|██████▋   | 190/285 [00:04<00:01, 56.84it/s]concatenating: train:  69%|██████▉   | 196/285 [00:04<00:01, 57.09it/s]concatenating: train:  71%|███████   | 202/285 [00:04<00:01, 52.51it/s]concatenating: train:  73%|███████▎  | 208/285 [00:04<00:01, 52.78it/s]concatenating: train:  75%|███████▌  | 214/285 [00:04<00:01, 53.00it/s]concatenating: train:  77%|███████▋  | 220/285 [00:05<00:01, 53.18it/s]concatenating: train:  79%|███████▉  | 226/285 [00:05<00:01, 54.75it/s]concatenating: train:  82%|████████▏ | 233/285 [00:05<00:00, 55.04it/s]concatenating: train:  84%|████████▍ | 239/285 [00:05<00:00, 52.86it/s]concatenating: train:  86%|████████▌ | 245/285 [00:05<00:00, 53.58it/s]concatenating: train:  88%|████████▊ | 251/285 [00:05<00:00, 52.47it/s]concatenating: train:  91%|█████████ | 258/285 [00:05<00:00, 55.12it/s]concatenating: train:  93%|█████████▎| 265/285 [00:05<00:00, 56.59it/s]concatenating: train:  95%|█████████▌| 271/285 [00:05<00:00, 57.57it/s]concatenating: train:  98%|█████████▊| 278/285 [00:06<00:00, 58.98it/s]concatenating: train: 100%|█████████▉| 284/285 [00:06<00:00, 58.59it/s]concatenating: train: 100%|██████████| 285/285 [00:06<00:00, 46.00it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.66s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.69s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.61s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00, 15.55it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 16.23it/s] train vimp2_2946_03032017_Test_NewCases_SRI_Aug1_Rot_-6_sd1
(459/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug1_Rot_-6_sd2
(460/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug0_Rot_2_sd1
(461/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug0_Rot_-2_sd2
(462/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug0_Rot_-6_sd0
(463/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug1_Rot_1_sd2
(464/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug1_Rot_-6_sd1
(465/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug1_Rot_7_sd0
(466/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug0_Rot_-1_sd2
(467/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug0_Rot_7_sd0
(468/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug0_Rot_-7_sd1
(469/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug1_Rot_-3_sd0
(470/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug1_Rot_4_sd2
(471/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug1_Rot_-7_sd1
(472/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug0_Rot_-1_sd2
(473/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug0_Rot_5_sd1
(474/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug0_Rot_-6_sd0
(475/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug1_Rot_1_sd2
(476/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug1_Rot_5_sd1
(477/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug1_Rot_7_sd0
(478/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug0_Rot_2_sd0
(479/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug0_Rot_-3_sd1
(480/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug0_Rot_-3_sd2
(481/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug1_Rot_1_sd2
(482/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug1_Rot_4_sd0
(483/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug1_Rot_-7_sd1
(484/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug0_Rot_1_sd2
(485/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug0_Rot_4_sd0
(486/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug0_Rot_5_sd1
(487/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug1_Rot_5_sd1
(488/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug1_Rot_6_sd0
(489/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug1_Rot_6_sd2
(490/532) train vimp2_3131_05182017_SRI_Aug0_Rot_2_sd2
(491/532) train vimp2_3131_05182017_SRI_Aug0_Rot_-5_sd1
(492/532) train vimp2_3131_05182017_SRI_Aug0_Rot_-7_sd0
(493/532) train vimp2_3131_05182017_SRI_Aug1_Rot_-4_sd0
(494/532) train vimp2_3131_05182017_SRI_Aug1_Rot_-4_sd2
(495/532) train vimp2_3131_05182017_SRI_Aug1_Rot_-7_sd1
(496/532) train vimp2_3187_06092017_SRI_Aug0_Rot_-1_sd0
(497/532) train vimp2_3187_06092017_SRI_Aug0_Rot_4_sd1
(498/532) train vimp2_3187_06092017_SRI_Aug0_Rot_-7_sd2
(499/532) train vimp2_3187_06092017_SRI_Aug1_Rot_-4_sd2
(500/532) train vimp2_3187_06092017_SRI_Aug1_Rot_-6_sd0
(501/532) train vimp2_3187_06092017_SRI_Aug1_Rot_-6_sd1
(502/532) train vimp2_3349_08012017_SRI_Aug0_Rot_4_sd0
(503/532) train vimp2_3349_08012017_SRI_Aug0_Rot_-4_sd1
(504/532) train vimp2_3349_08012017_SRI_Aug0_Rot_5_sd2
(505/532) train vimp2_3349_08012017_SRI_Aug1_Rot_-2_sd1
(506/532) train vimp2_3349_08012017_SRI_Aug1_Rot_-4_sd2
(507/532) train vimp2_3349_08012017_SRI_Aug1_Rot_-7_sd0
(508/532) train vimp2_676_04252014_SRI_Aug0_Rot_6_sd1
(509/532) train vimp2_676_04252014_SRI_Aug0_Rot_-6_sd2
(510/532) train vimp2_676_04252014_SRI_Aug0_Rot_7_sd0
(511/532) train vimp2_676_04252014_SRI_Aug1_Rot_2_sd0
(512/532) train vimp2_676_04252014_SRI_Aug1_Rot_-3_sd1
(513/532) train vimp2_676_04252014_SRI_Aug1_Rot_5_sd2
(514/532) train vimp2_702_04302014_SRI_Aug0_Rot_2_sd1
(515/532) train vimp2_702_04302014_SRI_Aug0_Rot_-3_sd0
(516/532) train vimp2_702_04302014_SRI_Aug0_Rot_-3_sd2
(517/532) train vimp2_702_04302014_SRI_Aug1_Rot_3_sd2
(518/532) train vimp2_702_04302014_SRI_Aug1_Rot_-4_sd1
(519/532) train vimp2_702_04302014_SRI_Aug1_Rot_-7_sd0
(520/532) train vimp2_804_06042014_SRI_Aug0_Rot_-2_sd2
(521/532) train vimp2_804_06042014_SRI_Aug0_Rot_3_sd1
(522/532) train vimp2_804_06042014_SRI_Aug0_Rot_-6_sd0
(523/532) train vimp2_804_06042014_SRI_Aug1_Rot_-3_sd1
(524/532) train vimp2_804_06042014_SRI_Aug1_Rot_5_sd0
(525/532) train vimp2_804_06042014_SRI_Aug1_Rot_7_sd2
(526/532) train vimp2_969_07142014_SRI_Aug0_Rot_1_sd2
(527/532) train vimp2_969_07142014_SRI_Aug0_Rot_-6_sd0
(528/532) train vimp2_969_07142014_SRI_Aug0_Rot_-6_sd1
(529/532) train vimp2_969_07142014_SRI_Aug1_Rot_-2_sd2
(530/532) train vimp2_969_07142014_SRI_Aug1_Rot_4_sd1
(531/532) train vimp2_969_07142014_SRI_Aug1_Rot_-6_sd0
(0/15) test vimp2_0699_04302014_SRI
(1/15) test vimp2_0781_05292014_SRI
(2/15) test vimp2_0837_06122014_SRI
(3/15) test vimp2_0892_06262014_SRI
(4/15) test vimp2_2456_08182016_SRI
(5/15) test vimp2_2520_09092016_SRI
(6/15) test vimp2_2530_09142016_SRI
(7/15) test vimp2_2551_09232016_Test_NewCases_SRI
(8/15) test vimp2_2553_09232016_Test_NewCases_SRI
(9/15) test vimp2_2554_09282016_SRI
(10/15) test vimp2_2594_10172016_SRI
(11/15) test vimp2_2597_10182016_Test_NewCases_SRI
(12/15) test vimp2_2598_10192016_Test_NewCases_SRI
(13/15) test vimp2_1876_01262016_SRI
(14/15) test vimp2_2475_08242016_SRI
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 40)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 80)   28880       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 80)   0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 40)   12840       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 80)   0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 40)   28840       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 40)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 20)   3220        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 80, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 20)   7220        concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 20)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   273         dropout_5[0][0]                  
==================================================================================================
Total params: 184,113
Trainable params: 183,313
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [2.13273029e+01 1.05010629e+01 2.46462697e+01 3.06320970e+00
 8.90359853e+00 2.32172244e+00 2.79665044e+01 3.70132346e+01
 2.82684742e+01 4.35344460e+00 9.66596785e+01 6.42825607e+01
 8.84946717e-02]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 17s - loss: 1653.4167 - acc: 0.8748 - mDice: 0.1587 - val_loss: 1175.8132 - val_acc: 0.9108 - val_mDice: 0.2384

Epoch 00001: val_mDice improved from -inf to 0.23841, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 9s - loss: 994.8643 - acc: 0.8929 - mDice: 0.3253 - val_loss: 1217.7178 - val_acc: 0.9172 - val_mDice: 0.3136

Epoch 00002: val_mDice improved from 0.23841 to 0.31358, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 8s - loss: 841.7966 - acc: 0.9041 - mDice: 0.4113 - val_loss: 1386.1720 - val_acc: 0.9244 - val_mDice: 0.3427

Epoch 00003: val_mDice improved from 0.31358 to 0.34272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 754.7646 - acc: 0.9092 - mDice: 0.4619 - val_loss: 1235.3806 - val_acc: 0.9282 - val_mDice: 0.3912

Epoch 00004: val_mDice improved from 0.34272 to 0.39118, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 8s - loss: 692.4224 - acc: 0.9133 - mDice: 0.5027 - val_loss: 1215.6724 - val_acc: 0.9309 - val_mDice: 0.4110

Epoch 00005: val_mDice improved from 0.39118 to 0.41101, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 655.0090 - acc: 0.9159 - mDice: 0.5254 - val_loss: 1286.7908 - val_acc: 0.9341 - val_mDice: 0.4208

Epoch 00006: val_mDice improved from 0.41101 to 0.42076, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 8s - loss: 626.5155 - acc: 0.9178 - mDice: 0.5430 - val_loss: 1421.8443 - val_acc: 0.9338 - val_mDice: 0.4173

Epoch 00007: val_mDice did not improve from 0.42076
Epoch 8/300
 - 9s - loss: 603.8847 - acc: 0.9193 - mDice: 0.5583 - val_loss: 1329.7695 - val_acc: 0.9357 - val_mDice: 0.4278

Epoch 00008: val_mDice improved from 0.42076 to 0.42778, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 8s - loss: 583.9043 - acc: 0.9203 - mDice: 0.5708 - val_loss: 1436.4233 - val_acc: 0.9362 - val_mDice: 0.4198

Epoch 00009: val_mDice did not improve from 0.42778
Epoch 10/300
 - 9s - loss: 568.3429 - acc: 0.9215 - mDice: 0.5815 - val_loss: 1628.3690 - val_acc: 0.9357 - val_mDice: 0.4118

Epoch 00010: val_mDice did not improve from 0.42778
Epoch 11/300
 - 9s - loss: 550.9361 - acc: 0.9222 - mDice: 0.5929 - val_loss: 1421.0744 - val_acc: 0.9375 - val_mDice: 0.4303

Epoch 00011: val_mDice improved from 0.42778 to 0.43035, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 8s - loss: 537.5871 - acc: 0.9231 - mDice: 0.6026 - val_loss: 1466.4606 - val_acc: 0.9361 - val_mDice: 0.4256

Epoch 00012: val_mDice did not improve from 0.43035
Epoch 13/300
 - 9s - loss: 529.0394 - acc: 0.9233 - mDice: 0.6079 - val_loss: 1491.0333 - val_acc: 0.9366 - val_mDice: 0.4233

Epoch 00013: val_mDice did not improve from 0.43035
Epoch 14/300
 - 9s - loss: 516.3512 - acc: 0.9240 - mDice: 0.6165 - val_loss: 1479.9870 - val_acc: 0.9335 - val_mDice: 0.4292

Epoch 00014: val_mDice did not improve from 0.43035
Epoch 15/300
 - 8s - loss: 507.2521 - acc: 0.9243 - mDice: 0.6225 - val_loss: 1502.1488 - val_acc: 0.9378 - val_mDice: 0.4381

Epoch 00015: val_mDice improved from 0.43035 to 0.43810, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 8s - loss: 498.4942 - acc: 0.9247 - mDice: 0.6296 - val_loss: 1398.0360 - val_acc: 0.9343 - val_mDice: 0.4309

Epoch 00016: val_mDice did not improve from 0.43810
Epoch 17/300
 - 9s - loss: 492.3305 - acc: 0.9249 - mDice: 0.6335 - val_loss: 1387.9087 - val_acc: 0.9352 - val_mDice: 0.4447

Epoch 00017: val_mDice improved from 0.43810 to 0.44467, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 8s - loss: 484.9380 - acc: 0.9252 - mDice: 0.6382 - val_loss: 1753.6506 - val_acc: 0.9357 - val_mDice: 0.4156

Epoch 00018: val_mDice did not improve from 0.44467
Epoch 19/300
 - 8s - loss: 477.6789 - acc: 0.9257 - mDice: 0.6437 - val_loss: 1687.3413 - val_acc: 0.9349 - val_mDice: 0.4180

Epoch 00019: val_mDice did not improve from 0.44467
Epoch 20/300
 - 9s - loss: 471.1539 - acc: 0.9259 - mDice: 0.6479 - val_loss: 1453.6808 - val_acc: 0.9353 - val_mDice: 0.4449

Epoch 00020: val_mDice improved from 0.44467 to 0.44486, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 8s - loss: 466.4729 - acc: 0.9259 - mDice: 0.6517 - val_loss: 1660.4698 - val_acc: 0.9356 - val_mDice: 0.4252

Epoch 00021: val_mDice did not improve from 0.44486
Epoch 22/300
 - 8s - loss: 459.8434 - acc: 0.9262 - mDice: 0.6563 - val_loss: 1473.9921 - val_acc: 0.9345 - val_mDice: 0.4423

Epoch 00022: val_mDice did not improve from 0.44486
Epoch 23/300
 - 9s - loss: 454.7162 - acc: 0.9265 - mDice: 0.6594 - val_loss: 1611.9836 - val_acc: 0.9341 - val_mDice: 0.4331

Epoch 00023: val_mDice did not improve from 0.44486
Epoch 24/300
 - 8s - loss: 451.6432 - acc: 0.9268 - mDice: 0.6620 - val_loss: 1846.3066 - val_acc: 0.9344 - val_mDice: 0.4198

Epoch 00024: val_mDice did not improve from 0.44486
Epoch 25/300
 - 8s - loss: 446.6332 - acc: 0.9268 - mDice: 0.6655 - val_loss: 1788.8174 - val_acc: 0.9353 - val_mDice: 0.4257

Epoch 00025: val_mDice did not improve from 0.44486
Epoch 26/300
 - 9s - loss: 442.3692 - acc: 0.9270 - mDice: 0.6684 - val_loss: 1704.5014 - val_acc: 0.9353 - val_mDice: 0.4347

Epoch 00026: val_mDice did not improve from 0.44486
Epoch 27/300
 - 8s - loss: 437.7423 - acc: 0.9273 - mDice: 0.6720 - val_loss: 1545.7972 - val_acc: 0.9327 - val_mDice: 0.4393

Epoch 00027: val_mDice did not improve from 0.44486
Epoch 28/300
 - 8s - loss: 434.3801 - acc: 0.9273 - mDice: 0.6747 - val_loss: 1734.4490 - val_acc: 0.9333 - val_mDice: 0.4324

Epoch 00028: val_mDice did not improve from 0.44486
Epoch 29/300
 - 8s - loss: 427.5614 - acc: 0.9276 - mDice: 0.6792 - val_loss: 1724.3422 - val_acc: 0.9345 - val_mDice: 0.4264

Epoch 00029: val_mDice did not improve from 0.44486
Epoch 30/300
 - 8s - loss: 426.2206 - acc: 0.9277 - mDice: 0.6800 - val_loss: 1593.9877 - val_acc: 0.9346 - val_mDice: 0.4440

Epoch 00030: val_mDice did not improve from 0.44486
Epoch 31/300
 - 8s - loss: 424.0156 - acc: 0.9277 - mDice: 0.6815 - val_loss: 1732.5761 - val_acc: 0.9345 - val_mDice: 0.4282

Epoch 00031: val_mDice did not improve from 0.44486
Epoch 32/300
 - 8s - loss: 420.6861 - acc: 0.9280 - mDice: 0.6838 - val_loss: 1782.3288 - val_acc: 0.9336 - val_mDice: 0.4241

Epoch 00032: val_mDice did not improve from 0.44486
Epoch 33/300
 - 9s - loss: 415.9149 - acc: 0.9281 - mDice: 0.6875 - val_loss: 1877.6449 - val_acc: 0.9331 - val_mDice: 0.4170

Epoch 00033: val_mDice did not improve from 0.44486
Epoch 34/300
 - 8s - loss: 413.3966 - acc: 0.9282 - mDice: 0.6894 - val_loss: 1714.8667 - val_acc: 0.9361 - val_mDice: 0.4376

Epoch 00034: val_mDice did not improve from 0.44486
Epoch 35/300
 - 8s - loss: 409.7023 - acc: 0.9284 - mDice: 0.6919 - val_loss: 1765.5338 - val_acc: 0.9343 - val_mDice: 0.4271

Epoch 00035: val_mDice did not improve from 0.44486
Epoch 36/300
 - 9s - loss: 409.1124 - acc: 0.9284 - mDice: 0.6929 - val_loss: 1886.9899 - val_acc: 0.9328 - val_mDice: 0.4255

Epoch 00036: val_mDice did not improve from 0.44486
Epoch 37/300
 - 8s - loss: 405.9477 - acc: 0.9285 - mDice: 0.6948 - val_loss: 1761.9372 - val_acc: 0.9326 - val_mDice: 0.4373

Epoch 00037: val_mDice did not improve from 0.44486
Epoch 38/300
 - 9s - loss: 403.8139 - acc: 0.9285 - mDice: 0.6964 - val_loss: 2033.2862 - val_acc: 0.9333 - val_mDice: 0.4150

Epoch 00038: val_mDice did not improve from 0.44486
Epoch 39/300
 - 8s - loss: 403.1187 - acc: 0.9286 - mDice: 0.6970 - val_loss: 1630.3406 - val_acc: 0.9332 - val_mDice: 0.4439

Epoch 00039: val_mDice did not improve from 0.44486
Epoch 40/300
 - 8s - loss: 397.7278 - acc: 0.9288 - mDice: 0.7004 - val_loss: 1829.2428 - val_acc: 0.9363 - val_mDice: 0.4373

Epoch 00040: val_mDice did not improve from 0.44486
Epoch 41/300
 - 9s - loss: 396.8257 - acc: 0.9289 - mDice: 0.7018 - val_loss: 1718.1300 - val_acc: 0.9339 - val_mDice: 0.4456

Epoch 00041: val_mDice improved from 0.44486 to 0.44555, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 42/300
 - 8s - loss: 393.9930 - acc: 0.9288 - mDice: 0.7034 - val_loss: 1927.0878 - val_acc: 0.9337 - val_mDice: 0.4275

Epoch 00042: val_mDice did not improve from 0.44555
Epoch 43/300
 - 8s - loss: 391.2193 - acc: 0.9291 - mDice: 0.7053 - val_loss: 2019.6454 - val_acc: 0.9349 - val_mDice: 0.4243

Epoch 00043: val_mDice did not improve from 0.44555
Epoch 44/300
 - 9s - loss: 391.2985 - acc: 0.9292 - mDice: 0.7058 - val_loss: 1811.4567 - val_acc: 0.9339 - val_mDice: 0.4435

Epoch 00044: val_mDice did not improve from 0.44555
Epoch 45/300
 - 9s - loss: 388.0101 - acc: 0.9291 - mDice: 0.7082 - val_loss: 1925.1707 - val_acc: 0.9344 - val_mDice: 0.4278

Epoch 00045: val_mDice did not improve from 0.44555
Epoch 46/300
 - 8s - loss: 385.9990 - acc: 0.9291 - mDice: 0.7092 - val_loss: 1830.3604 - val_acc: 0.9344 - val_mDice: 0.4365

Epoch 00046: val_mDice did not improve from 0.44555
Epoch 47/300
 - 8s - loss: 384.7078 - acc: 0.9293 - mDice: 0.7102 - val_loss: 1943.1964 - val_acc: 0.9355 - val_mDice: 0.4226

Epoch 00047: val_mDice did not improve from 0.44555
Epoch 48/300
 - 9s - loss: 383.5363 - acc: 0.9295 - mDice: 0.7115 - val_loss: 1831.9699 - val_acc: 0.9339 - val_mDice: 0.4375

Epoch 00048: val_mDice did not improve from 0.44555
Epoch 49/300
 - 8s - loss: 380.7651 - acc: 0.9296 - mDice: 0.7132 - val_loss: 1928.3918 - val_acc: 0.9343 - val_mDice: 0.4242

Epoch 00049: val_mDice did not improve from 0.44555
Epoch 50/300
 - 8s - loss: 381.0835 - acc: 0.9296 - mDice: 0.7130 - val_loss: 1865.1068 - val_acc: 0.9342 - val_mDice: 0.4312

Epoch 00050: val_mDice did not improve from 0.44555
Epoch 51/300
 - 8s - loss: 380.2145 - acc: 0.9296 - mDice: 0.7139 - val_loss: 1931.9418 - val_acc: 0.9339 - val_mDice: 0.4235

Epoch 00051: val_mDice did not improve from 0.44555
Epoch 52/300
 - 8s - loss: 376.3615 - acc: 0.9295 - mDice: 0.7165 - val_loss: 1998.1265 - val_acc: 0.9344 - val_mDice: 0.4279

Epoch 00052: val_mDice did not improve from 0.44555
Epoch 53/300
 - 8s - loss: 374.0640 - acc: 0.9296 - mDice: 0.7179 - val_loss: 1968.6826 - val_acc: 0.9319 - val_mDice: 0.4251

Epoch 00053: val_mDice did not improve from 0.44555
Epoch 54/300
 - 8s - loss: 373.5090 - acc: 0.9298 - mDice: 0.7185 - val_loss: 2031.1099 - val_acc: 0.9325 - val_mDice: 0.4197

Epoch 00054: val_mDice did not improve from 0.44555
Epoch 55/300
 - 8s - loss: 371.6291 - acc: 0.9298 - mDice: 0.7197 - val_loss: 1804.4671 - val_acc: 0.9334 - val_mDice: 0.4368

Epoch 00055: val_mDice did not improve from 0.44555
Epoch 56/300
 - 9s - loss: 370.0248 - acc: 0.9301 - mDice: 0.7214 - val_loss: 1770.8852 - val_acc: 0.9323 - val_mDice: 0.4417

Epoch 00056: val_mDice did not improve from 0.44555
Epoch 57/300
 - 9s - loss: 370.1007 - acc: 0.9299 - mDice: 0.7211 - val_loss: 2129.7583 - val_acc: 0.9341 - val_mDice: 0.4139

Epoch 00057: val_mDice did not improve from 0.44555
Epoch 58/300
 - 8s - loss: 368.4960 - acc: 0.9301 - mDice: 0.7227 - val_loss: 1848.1234 - val_acc: 0.9319 - val_mDice: 0.4295

Epoch 00058: val_mDice did not improve from 0.44555
Epoch 59/300
 - 8s - loss: 365.8899 - acc: 0.9301 - mDice: 0.7240 - val_loss: 2030.7411 - val_acc: 0.9328 - val_mDice: 0.4224

Epoch 00059: val_mDice did not improve from 0.44555
Epoch 60/300
 - 8s - loss: 363.8659 - acc: 0.9303 - mDice: 0.7253 - val_loss: 1814.2948 - val_acc: 0.9315 - val_mDice: 0.4364

Epoch 00060: val_mDice did not improve from 0.44555
Epoch 61/300
 - 8s - loss: 362.5865 - acc: 0.9300 - mDice: 0.7268 - val_loss: 1824.1429 - val_acc: 0.9317 - val_mDice: 0.4394

Epoch 00061: val_mDice did not improve from 0.44555
Epoch 62/300
 - 8s - loss: 361.8273 - acc: 0.9300 - mDice: 0.7274 - val_loss: 1902.3199 - val_acc: 0.9332 - val_mDice: 0.4372

Epoch 00062: val_mDice did not improve from 0.44555
Epoch 63/300
 - 9s - loss: 362.4184 - acc: 0.9300 - mDice: 0.7269 - val_loss: 1826.4598 - val_acc: 0.9324 - val_mDice: 0.4369

Epoch 00063: val_mDice did not improve from 0.44555
Epoch 64/300
 - 8s - loss: 360.5917 - acc: 0.9302 - mDice: 0.7275 - val_loss: 1843.6767 - val_acc: 0.9325 - val_mDice: 0.4335

Epoch 00064: val_mDice did not improve from 0.44555
Epoch 65/300
 - 9s - loss: 359.9120 - acc: 0.9302 - mDice: 0.7291 - val_loss: 1853.8249 - val_acc: 0.9323 - val_mDice: 0.4316

Epoch 00065: val_mDice did not improve from 0.44555
Epoch 66/300
 - 8s - loss: 357.3968 - acc: 0.9303 - mDice: 0.7307 - val_loss: 2118.3417 - val_acc: 0.9336 - val_mDice: 0.4161

Epoch 00066: val_mDice did not improve from 0.44555
Epoch 67/300
 - 8s - loss: 356.4552 - acc: 0.9306 - mDice: 0.7312 - val_loss: 2085.4059 - val_acc: 0.9321 - val_mDice: 0.4178

Epoch 00067: val_mDice did not improve from 0.44555
Epoch 68/300
 - 9s - loss: 355.2769 - acc: 0.9308 - mDice: 0.7322 - val_loss: 1898.4887 - val_acc: 0.9332 - val_mDice: 0.4339

Epoch 00068: val_mDice did not improve from 0.44555
Epoch 69/300
 - 8s - loss: 353.8285 - acc: 0.9308 - mDice: 0.7329 - val_loss: 1915.2867 - val_acc: 0.9335 - val_mDice: 0.4345

Epoch 00069: val_mDice did not improve from 0.44555
Epoch 70/300
 - 8s - loss: 353.3266 - acc: 0.9308 - mDice: 0.7338 - val_loss: 2141.2498 - val_acc: 0.9353 - val_mDice: 0.4212

Epoch 00070: val_mDice did not improve from 0.44555
Epoch 71/300
 - 8s - loss: 352.9896 - acc: 0.9309 - mDice: 0.7339 - val_loss: 2021.7256 - val_acc: 0.9345 - val_mDice: 0.4247

Epoch 00071: val_mDice did not improve from 0.44555
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
{'val_loss': [1175.8131941159565, 1217.7177558172316, 1386.1719912517638, 1235.3806320372082, 1215.672389688946, 1286.7907529217857, 1421.8442836943127, 1329.7695014363244, 1436.4232802958716, 1628.3689756393433, 1421.0743811244056, 1466.4606384209224, 1491.0332855383556, 1479.986993897529, 1502.1488276606515, 1398.0359580630347, 1387.908697605133, 1753.6505851461775, 1687.3412547963005, 1453.6808271635146, 1660.4698499611445, 1473.9921123811177, 1611.9836152337846, 1846.3066200244994, 1788.8174343676794, 1704.5013578846342, 1545.797182219369, 1734.449011450722, 1724.3422117857706, 1593.9877257744472, 1732.5761400745027, 1782.3287937527612, 1877.6448778595243, 1714.8666674182527, 1765.5337903499603, 1886.9899439073745, 1761.93719124794, 2033.2862195060366, 1630.3405906813484, 1829.2427716822851, 1718.129970045317, 1927.0878290846235, 2019.6453686611992, 1811.4567460219066, 1925.170695021039, 1830.3603887444451, 1943.1963501998357, 1831.969923870904, 1928.3918246314638, 1865.1068329811096, 1931.9417911597661, 1998.1265433004924, 1968.6825875668299, 2031.1099107322239, 1804.467108658382, 1770.8852285771143, 2129.758314632234, 1848.1233803374428, 2030.7410540807814, 1814.2948009797506, 1824.1428667136602, 1902.3199000358582, 1826.4598225411914, 1843.6767072337013, 1853.824936174211, 2118.341711611975, 2085.405884617851, 1898.4886608521144, 1915.286657367434, 2141.249836439178, 2021.7256206046968], 'val_acc': [0.9108378972326007, 0.9171611467997233, 0.9243658185005188, 0.9281776632581439, 0.9308745208240691, 0.9341483286448887, 0.9338278429848808, 0.9357028177806309, 0.9362362907046363, 0.9356867869695028, 0.9375160251344953, 0.936144681203933, 0.9366025811149961, 0.9334912896156311, 0.9378159386771066, 0.9342765353974842, 0.935187748500279, 0.9356708157630194, 0.9349381866909209, 0.9353204908825102, 0.9355631640979222, 0.9344940242313203, 0.9341186114719936, 0.9344253596805391, 0.9353159325463432, 0.935309058143979, 0.9327105993316287, 0.9332623907497951, 0.9345489967437017, 0.9345535550798688, 0.9345260830152602, 0.9335599740346273, 0.9330677730696542, 0.9361011953580947, 0.9342559292202904, 0.9328021804491679, 0.9325709910619826, 0.9333218591553825, 0.9331776329449245, 0.9362728964714777, 0.9339056781360081, 0.9336813035465422, 0.9348626477377755, 0.9339285776728675, 0.9343979216757274, 0.93435670932134, 0.9355082142920721, 0.9338965245655605, 0.934260524454571, 0.9342330325217474, 0.9339469103586107, 0.934361267657507, 0.9319459739185515, 0.9324725554102943, 0.9333722648166475, 0.9322504316057477, 0.9340910996709552, 0.9318887534595671, 0.9327884429977054, 0.9314812279882885, 0.9316506357420058, 0.93321426709493, 0.9323946918760028, 0.9324610914502826, 0.9323282951400393, 0.9336401252519517, 0.9321268286023822, 0.9332005268051511, 0.9334730080195835, 0.9353296643211728, 0.9344803066480727], 'val_mDice': [0.23840985624563127, 0.313577062494698, 0.3427239008957431, 0.39118089828462826, 0.4110098747270448, 0.4207582129609017, 0.4173466314872106, 0.4277810404698054, 0.419827568034331, 0.411839858407066, 0.43034876067013966, 0.4256442150189763, 0.42326754260630833, 0.4292306685376735, 0.438100119077024, 0.43092408119922593, 0.4446683054169019, 0.41560892335006167, 0.4180314487644604, 0.4448649902783689, 0.4251957450594221, 0.4422762088832401, 0.433087119389148, 0.41978614245142254, 0.4256628366808097, 0.43468141750920386, 0.43929084532317664, 0.43242272699163076, 0.42638202508290607, 0.44398085418201627, 0.4281807199475311, 0.42411585702073007, 0.41696145403243245, 0.43755035084627925, 0.427118492800565, 0.4254809795390992, 0.4373063840681598, 0.41502302210955394, 0.4438778335849444, 0.43731920119552387, 0.4455533435656911, 0.4274744325805278, 0.4242807467068945, 0.4435000751344931, 0.4277959324064709, 0.43647512545188266, 0.4226248070952438, 0.4375355389146578, 0.4241818845981643, 0.43123939633369446, 0.4234872960618564, 0.42791185066813514, 0.4250696698824565, 0.41971064784697126, 0.4368480376544453, 0.4416913361776443, 0.41392833544384866, 0.42948855583866435, 0.4224003700628167, 0.43640835902520586, 0.4394419360018912, 0.437167144070069, 0.4369363309372039, 0.4335463031062058, 0.4316119933057399, 0.41614003603657085, 0.41783490493184045, 0.43393262351552647, 0.4345297398311751, 0.4211568378266834, 0.4246562573881376], 'loss': [1653.4167065801523, 994.8643004794513, 841.7965680121089, 754.7645651157453, 692.4224383014232, 655.0090237836836, 626.5154955400445, 603.8847357840214, 583.9042831312054, 568.3429276904137, 550.9360742990006, 537.587122408071, 529.0393558441157, 516.3512305426465, 507.2520952050066, 498.4942047783973, 492.33050664780757, 484.9379553867485, 477.6788935134561, 471.15387695971447, 466.4728724911927, 459.84344672458076, 454.71624338132744, 451.643227854652, 446.63324837126623, 442.3692057844713, 437.74227272800016, 434.3801221816278, 427.56143935089375, 426.2205724177481, 424.01564785141187, 420.68612186100205, 415.9149275765567, 413.3965670613395, 409.70231418966307, 409.1124210743769, 405.94765449319476, 403.8138860993379, 403.11868046087085, 397.72779037507945, 396.8257018913532, 393.99304495745827, 391.21926107382717, 391.2985157125461, 388.0101399374808, 385.99901758932714, 384.70778698219783, 383.5362678352799, 380.76507688382236, 381.0835487979075, 380.2144800160049, 376.3614663042635, 374.064011829171, 373.508975027337, 371.6290624621104, 370.0248492483415, 370.1007062839547, 368.49599413690663, 365.8899492683359, 363.8658578996601, 362.5864897993274, 361.82731911707225, 362.4184462291923, 360.59171287076236, 359.9119652151855, 357.39676155132986, 356.455157060625, 355.27687425468156, 353.82852040473404, 353.3265662236505, 352.9896134273014], 'acc': [0.8748379826936414, 0.8929145873707568, 0.9040607027357568, 0.9092465121667463, 0.9133268157847934, 0.9158803975281055, 0.9178228048844354, 0.919258552719592, 0.9203091192755691, 0.9214848057369242, 0.922176283001555, 0.9231007889283744, 0.9232902924104855, 0.9240152669913603, 0.9242628586643896, 0.9246843090653994, 0.924882982309002, 0.9252330397672452, 0.9256650044413828, 0.9259342178343256, 0.9259343339869667, 0.9262424942751668, 0.9264829018131165, 0.9268429262895035, 0.9267890302919344, 0.9270468388124079, 0.927312667162542, 0.927297578844832, 0.9276029150196875, 0.9276766485507856, 0.9277409030013584, 0.9279576319707756, 0.9280545135695327, 0.9281794056971454, 0.9283727744491155, 0.9283689036060442, 0.9284841421713644, 0.9285138462328465, 0.9286484742109454, 0.9287932271072119, 0.9289271395882591, 0.9288415674623645, 0.9290545369150645, 0.9291569572872157, 0.9291039616564737, 0.9290570662112188, 0.9293303048309619, 0.9295259443969425, 0.9296139772282599, 0.9296075582435326, 0.9295593107139671, 0.9295445060900049, 0.9296200921224311, 0.9297606776922177, 0.9297697329557951, 0.9301050326969896, 0.9298962797414413, 0.930123617786053, 0.930068745752371, 0.9302737963482298, 0.930019323194282, 0.9300364923541523, 0.9299570094856519, 0.9302464271409906, 0.9301586276836332, 0.9303283887100697, 0.9305867289494797, 0.9308195363723728, 0.9308103375612299, 0.9307547958917142, 0.930865186635575], 'mDice': [0.15871728310608924, 0.3252540214088856, 0.4113223937083146, 0.4618673750447335, 0.5026546306225843, 0.5253622589001933, 0.5429851407717022, 0.5583081677489964, 0.5707888015322725, 0.581542972277786, 0.5928751103607289, 0.6026348375460535, 0.6079098994110921, 0.6165015724368561, 0.6224743677215215, 0.6295612751001196, 0.6335251763626769, 0.6381674258493379, 0.6436533548249568, 0.6479017824158633, 0.651687786922488, 0.6562802121890678, 0.6593604700078572, 0.6619548710734255, 0.6655173679066458, 0.6683665949507258, 0.671955326227685, 0.6746516190720634, 0.6792070320490493, 0.6800073012925076, 0.6815280576581461, 0.6837963847863966, 0.6874649088024657, 0.689366664664925, 0.6919464660168889, 0.692856308580571, 0.6948102077629746, 0.6963945841867385, 0.6970079143842062, 0.7003523039638548, 0.7017721118484822, 0.7034148408287818, 0.7053207291420517, 0.7057824067948112, 0.7081751802741205, 0.709196902192441, 0.7102361026701036, 0.711516957614425, 0.7131590033073932, 0.7130086943435375, 0.7139169092189376, 0.7164749820751332, 0.7178752640664796, 0.7184947544332871, 0.7197200797163547, 0.7214156279151142, 0.7210751995429934, 0.7227371945784734, 0.7240293138583823, 0.725317636045482, 0.726760982099654, 0.727433183920827, 0.7268685364461207, 0.7274751330424026, 0.7291068860117998, 0.7307004303469785, 0.731170506968718, 0.7322019150957152, 0.7328821191420922, 0.7337856190338378, 0.7339416539505862]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.14s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:02,  1.49s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:23,  1.57s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:21,  1.57s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:45,  1.66s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:29,  1.60s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:59,  1.72s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:33,  1.85s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:49,  1.91s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:32,  1.86s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:40,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:55,  1.96s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<08:58,  1.97s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<09:11,  2.03s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<09:07,  2.02s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:12,  2.05s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:10,  2.04s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<09:03,  2.03s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:56,  2.01s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<09:05,  2.05s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<09:11,  2.08s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<09:12,  2.09s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<09:05,  2.07s/it]predicting train subjects:   8%|▊         | 23/285 [00:45<09:12,  2.11s/it]predicting train subjects:   8%|▊         | 24/285 [00:47<09:20,  2.15s/it]predicting train subjects:   9%|▉         | 25/285 [00:49<09:08,  2.11s/it]predicting train subjects:   9%|▉         | 26/285 [00:51<09:01,  2.09s/it]predicting train subjects:   9%|▉         | 27/285 [00:53<08:47,  2.05s/it]predicting train subjects:  10%|▉         | 28/285 [00:55<08:36,  2.01s/it]predicting train subjects:  10%|█         | 29/285 [00:57<08:43,  2.05s/it]predicting train subjects:  11%|█         | 30/285 [00:59<08:42,  2.05s/it]predicting train subjects:  11%|█         | 31/285 [01:01<08:28,  2.00s/it]predicting train subjects:  11%|█         | 32/285 [01:03<08:07,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:05<08:18,  1.98s/it]predicting train subjects:  12%|█▏        | 34/285 [01:07<08:10,  1.95s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<08:00,  1.92s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<07:45,  1.87s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<07:46,  1.89s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<08:03,  1.97s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<08:04,  1.98s/it]predicting train subjects:  14%|█▍        | 41/285 [01:20<08:01,  1.97s/it]predicting train subjects:  15%|█▍        | 42/285 [01:22<07:56,  1.96s/it]predicting train subjects:  15%|█▌        | 43/285 [01:24<07:53,  1.96s/it]predicting train subjects:  15%|█▌        | 44/285 [01:26<07:47,  1.94s/it]predicting train subjects:  16%|█▌        | 45/285 [01:28<07:40,  1.92s/it]predicting train subjects:  16%|█▌        | 46/285 [01:29<07:14,  1.82s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<06:52,  1.73s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<06:45,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<06:45,  1.72s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<06:44,  1.72s/it]predicting train subjects:  18%|█▊        | 51/285 [01:38<06:39,  1.71s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<06:30,  1.68s/it]predicting train subjects:  19%|█▊        | 53/285 [01:41<06:21,  1.65s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<06:20,  1.65s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<06:21,  1.66s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<06:21,  1.67s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:15,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:49<06:16,  1.66s/it]predicting train subjects:  21%|██        | 59/285 [01:51<06:11,  1.65s/it]predicting train subjects:  21%|██        | 60/285 [01:52<06:11,  1.65s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:07,  1.64s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<06:05,  1.64s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:10,  1.67s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:18,  1.71s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:36,  1.80s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:36,  1.81s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:35,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:15,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:17,  1.76s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:32,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:14<06:19,  1.78s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:12,  1.77s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:11,  1.77s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:18,  1.81s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:09,  1.78s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:03,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<05:55,  1.74s/it]predicting train subjects:  28%|██▊       | 81/285 [02:30<06:01,  1.77s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<05:56,  1.76s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:55,  1.76s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:56,  1.77s/it]predicting train subjects:  30%|██▉       | 85/285 [02:37<06:14,  1.87s/it]predicting train subjects:  30%|███       | 86/285 [02:39<06:11,  1.87s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:06,  1.85s/it]predicting train subjects:  31%|███       | 88/285 [02:42<06:01,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:44<05:58,  1.83s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<05:58,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<05:58,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<05:55,  1.84s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:59,  1.87s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:56,  1.87s/it]predicting train subjects:  33%|███▎      | 95/285 [02:56<05:58,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:59,  1.90s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:57,  1.90s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:57,  1.91s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:54,  1.90s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:57,  1.93s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:57,  1.94s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<06:00,  1.97s/it]predicting train subjects:  36%|███▌      | 103/285 [03:11<05:50,  1.93s/it]predicting train subjects:  36%|███▋      | 104/285 [03:13<05:49,  1.93s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<06:02,  2.01s/it]predicting train subjects:  37%|███▋      | 106/285 [03:17<06:05,  2.04s/it]predicting train subjects:  38%|███▊      | 107/285 [03:19<05:59,  2.02s/it]predicting train subjects:  38%|███▊      | 108/285 [03:21<05:48,  1.97s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:35,  1.91s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:30,  1.89s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:35,  1.93s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:33,  1.93s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:30,  1.92s/it]predicting train subjects:  40%|████      | 114/285 [03:33<05:32,  1.94s/it]predicting train subjects:  40%|████      | 115/285 [03:34<05:29,  1.94s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:22,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:38<05:30,  1.96s/it]predicting train subjects:  41%|████▏     | 118/285 [03:40<05:30,  1.98s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<05:38,  2.04s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:40,  2.07s/it]predicting train subjects:  42%|████▏     | 121/285 [03:47<05:25,  1.98s/it]predicting train subjects:  43%|████▎     | 122/285 [03:48<05:08,  1.89s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:48,  1.78s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:51,  1.81s/it]predicting train subjects:  44%|████▍     | 125/285 [03:53<04:48,  1.80s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:49,  1.82s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:50,  1.84s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:52,  1.86s/it]predicting train subjects:  45%|████▌     | 129/285 [04:01<04:50,  1.86s/it]predicting train subjects:  46%|████▌     | 130/285 [04:03<04:47,  1.86s/it]predicting train subjects:  46%|████▌     | 131/285 [04:05<04:46,  1.86s/it]predicting train subjects:  46%|████▋     | 132/285 [04:06<04:42,  1.85s/it]predicting train subjects:  47%|████▋     | 133/285 [04:08<04:39,  1.84s/it]predicting train subjects:  47%|████▋     | 134/285 [04:10<04:39,  1.85s/it]predicting train subjects:  47%|████▋     | 135/285 [04:12<04:39,  1.86s/it]predicting train subjects:  48%|████▊     | 136/285 [04:14<04:39,  1.88s/it]predicting train subjects:  48%|████▊     | 137/285 [04:16<04:34,  1.85s/it]predicting train subjects:  48%|████▊     | 138/285 [04:18<04:31,  1.85s/it]predicting train subjects:  49%|████▉     | 139/285 [04:20<04:33,  1.88s/it]predicting train subjects:  49%|████▉     | 140/285 [04:21<04:31,  1.87s/it]predicting train subjects:  49%|████▉     | 141/285 [04:23<04:30,  1.88s/it]predicting train subjects:  50%|████▉     | 142/285 [04:25<04:21,  1.83s/it]predicting train subjects:  50%|█████     | 143/285 [04:27<04:17,  1.81s/it]predicting train subjects:  51%|█████     | 144/285 [04:28<04:11,  1.78s/it]predicting train subjects:  51%|█████     | 145/285 [04:30<04:03,  1.74s/it]predicting train subjects:  51%|█████     | 146/285 [04:32<03:57,  1.71s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:33<03:54,  1.70s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:35<03:50,  1.68s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:37<03:44,  1.65s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:38<03:41,  1.64s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:40<03:41,  1.65s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:42<03:40,  1.66s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:43<03:45,  1.71s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:45<03:41,  1.69s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:47<03:43,  1.72s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:48<03:33,  1.65s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:50<03:31,  1.65s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:52<03:30,  1.65s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:53<03:29,  1.67s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:55<03:27,  1.66s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:57<03:24,  1.65s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:58<03:22,  1.64s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:00<03:22,  1.66s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:02<03:20,  1.66s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:03<03:15,  1.63s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:05<03:15,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:07<03:14,  1.65s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:08<03:14,  1.67s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:10<03:15,  1.68s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:12<03:07,  1.63s/it]predicting train subjects:  60%|██████    | 171/285 [05:13<03:06,  1.64s/it]predicting train subjects:  60%|██████    | 172/285 [05:15<03:08,  1.67s/it]predicting train subjects:  61%|██████    | 173/285 [05:17<03:06,  1.66s/it]predicting train subjects:  61%|██████    | 174/285 [05:18<03:02,  1.64s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:20<03:04,  1.68s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:22<03:00,  1.66s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:23<03:00,  1.67s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:25<02:58,  1.67s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:26<02:53,  1.64s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:28<02:49,  1.62s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:30<02:51,  1.65s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:31<02:47,  1.62s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:33<02:44,  1.61s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:34<02:38,  1.57s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:36<02:38,  1.59s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:38<02:41,  1.63s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:39<02:40,  1.64s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:41<02:38,  1.63s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:43<02:37,  1.64s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:44<02:28,  1.57s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:46<02:31,  1.61s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:47<02:30,  1.62s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:49<02:25,  1.58s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:50<02:24,  1.59s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:52<02:20,  1.56s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:54<02:27,  1.66s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:56<02:34,  1.75s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:58<02:36,  1.79s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:00<02:38,  1.84s/it]predicting train subjects:  70%|███████   | 200/285 [06:02<02:41,  1.90s/it]predicting train subjects:  71%|███████   | 201/285 [06:04<02:37,  1.87s/it]predicting train subjects:  71%|███████   | 202/285 [06:05<02:34,  1.86s/it]predicting train subjects:  71%|███████   | 203/285 [06:07<02:28,  1.81s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:09<02:25,  1.79s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:11<02:21,  1.77s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:12<02:20,  1.78s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:14<02:18,  1.77s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:16<02:16,  1.77s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:18<02:14,  1.77s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:19<02:12,  1.77s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:21<02:07,  1.73s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:23<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:24<02:02,  1.71s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:26<01:59,  1.69s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:28<01:55,  1.65s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:29<01:53,  1.64s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:31<01:50,  1.62s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:32<01:45,  1.57s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:34<01:40,  1.52s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:35<01:38,  1.51s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:37<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:38<01:34,  1.50s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:40<01:32,  1.50s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:41<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:42<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:44<01:25,  1.45s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:45<01:25,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:47<01:23,  1.47s/it]predicting train subjects:  80%|████████  | 229/285 [06:48<01:21,  1.45s/it]predicting train subjects:  81%|████████  | 230/285 [06:50<01:19,  1.45s/it]predicting train subjects:  81%|████████  | 231/285 [06:51<01:18,  1.46s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:53<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:55<01:26,  1.66s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:57<01:28,  1.73s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:59<01:28,  1.76s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:00<01:27,  1.78s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:02<01:26,  1.80s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:04<01:25,  1.82s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:06<01:23,  1.83s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:08<01:22,  1.83s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:10<01:20,  1.83s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:12<01:19,  1.84s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:13<01:17,  1.85s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:15<01:15,  1.85s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:17<01:14,  1.87s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:19<01:13,  1.87s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:21<01:11,  1.89s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:23<01:08,  1.86s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:25<01:06,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:26<01:01,  1.75s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:28<00:57,  1.68s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:29<00:52,  1.61s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:30<00:49,  1.55s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:32<00:46,  1.50s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:33<00:44,  1.48s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:35<00:43,  1.49s/it]predicting train subjects:  90%|█████████ | 257/285 [07:36<00:42,  1.51s/it]predicting train subjects:  91%|█████████ | 258/285 [07:38<00:41,  1.54s/it]predicting train subjects:  91%|█████████ | 259/285 [07:40<00:40,  1.55s/it]predicting train subjects:  91%|█████████ | 260/285 [07:41<00:38,  1.55s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:43<00:36,  1.52s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:44<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:46<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:47<00:32,  1.53s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:49<00:30,  1.51s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:50<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:52<00:27,  1.54s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:54<00:28,  1.70s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:56<00:28,  1.78s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:58<00:26,  1.79s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:00<00:25,  1.85s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:02<00:24,  1.89s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:04<00:23,  1.94s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:05<00:20,  1.90s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:07<00:18,  1.87s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:09<00:16,  1.88s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:11<00:15,  1.93s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:13<00:13,  1.90s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:15<00:11,  1.88s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:17<00:09,  1.85s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:18<00:07,  1.84s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:20<00:05,  1.87s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:22<00:03,  1.89s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:24<00:01,  1.88s/it]predicting train subjects: 100%|██████████| 285/285 [08:26<00:00,  1.87s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:32,  1.38s/it]Loading train:   1%|          | 2/285 [00:02<06:49,  1.45s/it]Loading train:   1%|          | 3/285 [00:04<06:51,  1.46s/it]Loading train:   1%|▏         | 4/285 [00:06<07:12,  1.54s/it]Loading train:   2%|▏         | 5/285 [00:08<07:34,  1.62s/it]Loading train:   2%|▏         | 6/285 [00:10<08:13,  1.77s/it]Loading train:   2%|▏         | 7/285 [00:12<08:54,  1.92s/it]Loading train:   3%|▎         | 8/285 [00:14<09:11,  1.99s/it]Loading train:   3%|▎         | 9/285 [00:16<08:33,  1.86s/it]Loading train:   4%|▎         | 10/285 [00:17<07:44,  1.69s/it]Loading train:   4%|▍         | 11/285 [00:18<06:51,  1.50s/it]Loading train:   4%|▍         | 12/285 [00:20<06:59,  1.54s/it]Loading train:   5%|▍         | 13/285 [00:21<07:06,  1.57s/it]Loading train:   5%|▍         | 14/285 [00:23<07:29,  1.66s/it]Loading train:   5%|▌         | 15/285 [00:25<07:52,  1.75s/it]Loading train:   6%|▌         | 16/285 [00:27<07:33,  1.69s/it]Loading train:   6%|▌         | 17/285 [00:28<07:19,  1.64s/it]Loading train:   6%|▋         | 18/285 [00:30<07:13,  1.62s/it]Loading train:   7%|▋         | 19/285 [00:31<07:08,  1.61s/it]Loading train:   7%|▋         | 20/285 [00:33<07:01,  1.59s/it]Loading train:   7%|▋         | 21/285 [00:34<06:58,  1.58s/it]Loading train:   8%|▊         | 22/285 [00:36<06:48,  1.55s/it]Loading train:   8%|▊         | 23/285 [00:37<06:42,  1.54s/it]Loading train:   8%|▊         | 24/285 [00:39<06:58,  1.60s/it]Loading train:   9%|▉         | 25/285 [00:41<07:06,  1.64s/it]Loading train:   9%|▉         | 26/285 [00:42<07:03,  1.64s/it]Loading train:   9%|▉         | 27/285 [00:44<06:50,  1.59s/it]Loading train:  10%|▉         | 28/285 [00:45<06:40,  1.56s/it]Loading train:  10%|█         | 29/285 [00:47<06:45,  1.58s/it]Loading train:  11%|█         | 30/285 [00:49<06:30,  1.53s/it]Loading train:  11%|█         | 31/285 [00:50<06:37,  1.57s/it]Loading train:  11%|█         | 32/285 [00:52<06:46,  1.61s/it]Loading train:  12%|█▏        | 33/285 [00:53<06:38,  1.58s/it]Loading train:  12%|█▏        | 34/285 [00:55<06:32,  1.57s/it]Loading train:  12%|█▏        | 35/285 [00:56<06:24,  1.54s/it]Loading train:  13%|█▎        | 36/285 [00:58<06:07,  1.48s/it]Loading train:  13%|█▎        | 37/285 [00:59<06:06,  1.48s/it]Loading train:  13%|█▎        | 38/285 [01:01<06:01,  1.46s/it]Loading train:  14%|█▎        | 39/285 [01:02<06:08,  1.50s/it]Loading train:  14%|█▍        | 40/285 [01:04<06:08,  1.50s/it]Loading train:  14%|█▍        | 41/285 [01:05<05:58,  1.47s/it]Loading train:  15%|█▍        | 42/285 [01:07<05:57,  1.47s/it]Loading train:  15%|█▌        | 43/285 [01:08<06:02,  1.50s/it]Loading train:  15%|█▌        | 44/285 [01:10<05:52,  1.46s/it]Loading train:  16%|█▌        | 45/285 [01:11<06:12,  1.55s/it]Loading train:  16%|█▌        | 46/285 [01:13<06:13,  1.56s/it]Loading train:  16%|█▋        | 47/285 [01:14<05:53,  1.48s/it]Loading train:  17%|█▋        | 48/285 [01:15<05:26,  1.38s/it]Loading train:  17%|█▋        | 49/285 [01:16<05:02,  1.28s/it]Loading train:  18%|█▊        | 50/285 [01:18<05:11,  1.32s/it]Loading train:  18%|█▊        | 51/285 [01:19<05:23,  1.38s/it]Loading train:  18%|█▊        | 52/285 [01:21<05:20,  1.38s/it]Loading train:  19%|█▊        | 53/285 [01:22<05:15,  1.36s/it]Loading train:  19%|█▉        | 54/285 [01:23<05:14,  1.36s/it]Loading train:  19%|█▉        | 55/285 [01:25<05:08,  1.34s/it]Loading train:  20%|█▉        | 56/285 [01:26<05:18,  1.39s/it]Loading train:  20%|██        | 57/285 [01:28<05:24,  1.43s/it]Loading train:  20%|██        | 58/285 [01:29<05:26,  1.44s/it]Loading train:  21%|██        | 59/285 [01:31<05:21,  1.42s/it]Loading train:  21%|██        | 60/285 [01:32<05:12,  1.39s/it]Loading train:  21%|██▏       | 61/285 [01:33<05:22,  1.44s/it]Loading train:  22%|██▏       | 62/285 [01:35<05:16,  1.42s/it]Loading train:  22%|██▏       | 63/285 [01:36<04:53,  1.32s/it]Loading train:  22%|██▏       | 64/285 [01:38<05:21,  1.45s/it]Loading train:  23%|██▎       | 65/285 [01:39<05:44,  1.57s/it]Loading train:  23%|██▎       | 66/285 [01:41<06:10,  1.69s/it]Loading train:  24%|██▎       | 67/285 [01:43<05:52,  1.62s/it]Loading train:  24%|██▍       | 68/285 [01:44<05:32,  1.53s/it]Loading train:  24%|██▍       | 69/285 [01:46<05:39,  1.57s/it]Loading train:  25%|██▍       | 70/285 [01:47<05:38,  1.57s/it]Loading train:  25%|██▍       | 71/285 [01:49<05:35,  1.57s/it]Loading train:  25%|██▌       | 72/285 [01:50<05:26,  1.53s/it]Loading train:  26%|██▌       | 73/285 [01:52<05:34,  1.58s/it]Loading train:  26%|██▌       | 74/285 [01:54<05:30,  1.57s/it]Loading train:  26%|██▋       | 75/285 [01:55<05:13,  1.49s/it]Loading train:  27%|██▋       | 76/285 [01:56<05:00,  1.44s/it]Loading train:  27%|██▋       | 77/285 [01:58<05:21,  1.54s/it]Loading train:  27%|██▋       | 78/285 [02:00<05:12,  1.51s/it]Loading train:  28%|██▊       | 79/285 [02:01<04:45,  1.38s/it]Loading train:  28%|██▊       | 80/285 [02:02<04:19,  1.27s/it]Loading train:  28%|██▊       | 81/285 [02:03<04:18,  1.27s/it]Loading train:  29%|██▉       | 82/285 [02:04<04:08,  1.23s/it]Loading train:  29%|██▉       | 83/285 [02:05<04:12,  1.25s/it]Loading train:  29%|██▉       | 84/285 [02:06<03:59,  1.19s/it]Loading train:  30%|██▉       | 85/285 [02:08<03:59,  1.20s/it]Loading train:  30%|███       | 86/285 [02:09<03:58,  1.20s/it]Loading train:  31%|███       | 87/285 [02:10<03:58,  1.21s/it]Loading train:  31%|███       | 88/285 [02:11<03:57,  1.21s/it]Loading train:  31%|███       | 89/285 [02:12<03:53,  1.19s/it]Loading train:  32%|███▏      | 90/285 [02:14<03:50,  1.18s/it]Loading train:  32%|███▏      | 91/285 [02:15<03:45,  1.16s/it]Loading train:  32%|███▏      | 92/285 [02:16<03:45,  1.17s/it]Loading train:  33%|███▎      | 93/285 [02:17<03:45,  1.17s/it]Loading train:  33%|███▎      | 94/285 [02:18<03:48,  1.20s/it]Loading train:  33%|███▎      | 95/285 [02:19<03:48,  1.20s/it]Loading train:  34%|███▎      | 96/285 [02:21<03:54,  1.24s/it]Loading train:  34%|███▍      | 97/285 [02:22<04:00,  1.28s/it]Loading train:  34%|███▍      | 98/285 [02:23<03:55,  1.26s/it]Loading train:  35%|███▍      | 99/285 [02:25<03:59,  1.29s/it]Loading train:  35%|███▌      | 100/285 [02:26<03:49,  1.24s/it]Loading train:  35%|███▌      | 101/285 [02:27<03:45,  1.23s/it]Loading train:  36%|███▌      | 102/285 [02:28<03:43,  1.22s/it]Loading train:  36%|███▌      | 103/285 [02:30<03:58,  1.31s/it]Loading train:  36%|███▋      | 104/285 [02:31<04:13,  1.40s/it]Loading train:  37%|███▋      | 105/285 [02:33<04:29,  1.50s/it]Loading train:  37%|███▋      | 106/285 [02:35<04:21,  1.46s/it]Loading train:  38%|███▊      | 107/285 [02:36<04:15,  1.44s/it]Loading train:  38%|███▊      | 108/285 [02:38<04:23,  1.49s/it]Loading train:  38%|███▊      | 109/285 [02:39<04:26,  1.51s/it]Loading train:  39%|███▊      | 110/285 [02:40<04:17,  1.47s/it]Loading train:  39%|███▉      | 111/285 [02:42<04:36,  1.59s/it]Loading train:  39%|███▉      | 112/285 [02:44<04:39,  1.61s/it]Loading train:  40%|███▉      | 113/285 [02:45<04:27,  1.55s/it]Loading train:  40%|████      | 114/285 [02:47<04:25,  1.55s/it]Loading train:  40%|████      | 115/285 [02:48<04:18,  1.52s/it]Loading train:  41%|████      | 116/285 [02:50<04:12,  1.50s/it]Loading train:  41%|████      | 117/285 [02:52<04:31,  1.62s/it]Loading train:  41%|████▏     | 118/285 [02:53<04:29,  1.61s/it]Loading train:  42%|████▏     | 119/285 [02:55<04:12,  1.52s/it]Loading train:  42%|████▏     | 120/285 [02:56<04:18,  1.57s/it]Loading train:  42%|████▏     | 121/285 [02:58<04:26,  1.63s/it]Loading train:  43%|████▎     | 122/285 [03:00<04:27,  1.64s/it]Loading train:  43%|████▎     | 123/285 [03:01<04:17,  1.59s/it]Loading train:  44%|████▎     | 124/285 [03:02<03:58,  1.48s/it]Loading train:  44%|████▍     | 125/285 [03:03<03:35,  1.34s/it]Loading train:  44%|████▍     | 126/285 [03:04<03:13,  1.22s/it]Loading train:  45%|████▍     | 127/285 [03:05<03:04,  1.17s/it]Loading train:  45%|████▍     | 128/285 [03:06<02:52,  1.10s/it]Loading train:  45%|████▌     | 129/285 [03:07<02:49,  1.09s/it]Loading train:  46%|████▌     | 130/285 [03:09<02:50,  1.10s/it]Loading train:  46%|████▌     | 131/285 [03:10<02:50,  1.10s/it]Loading train:  46%|████▋     | 132/285 [03:11<02:50,  1.11s/it]Loading train:  47%|████▋     | 133/285 [03:12<03:03,  1.21s/it]Loading train:  47%|████▋     | 134/285 [03:14<03:10,  1.26s/it]Loading train:  47%|████▋     | 135/285 [03:15<03:04,  1.23s/it]Loading train:  48%|████▊     | 136/285 [03:16<03:02,  1.23s/it]Loading train:  48%|████▊     | 137/285 [03:17<03:07,  1.27s/it]Loading train:  48%|████▊     | 138/285 [03:19<03:07,  1.27s/it]Loading train:  49%|████▉     | 139/285 [03:20<03:00,  1.24s/it]Loading train:  49%|████▉     | 140/285 [03:21<03:06,  1.29s/it]Loading train:  49%|████▉     | 141/285 [03:23<03:11,  1.33s/it]Loading train:  50%|████▉     | 142/285 [03:24<03:05,  1.30s/it]Loading train:  50%|█████     | 143/285 [03:25<03:01,  1.28s/it]Loading train:  51%|█████     | 144/285 [03:26<02:57,  1.26s/it]Loading train:  51%|█████     | 145/285 [03:27<02:51,  1.23s/it]Loading train:  51%|█████     | 146/285 [03:29<02:49,  1.22s/it]Loading train:  52%|█████▏    | 147/285 [03:30<02:43,  1.19s/it]Loading train:  52%|█████▏    | 148/285 [03:31<02:42,  1.19s/it]Loading train:  52%|█████▏    | 149/285 [03:32<02:47,  1.23s/it]Loading train:  53%|█████▎    | 150/285 [03:34<02:53,  1.29s/it]Loading train:  53%|█████▎    | 151/285 [03:35<02:50,  1.27s/it]Loading train:  53%|█████▎    | 152/285 [03:36<02:57,  1.34s/it]Loading train:  54%|█████▎    | 153/285 [03:38<02:57,  1.35s/it]Loading train:  54%|█████▍    | 154/285 [03:39<03:03,  1.40s/it]Loading train:  54%|█████▍    | 155/285 [03:41<02:54,  1.34s/it]Loading train:  55%|█████▍    | 156/285 [03:42<02:52,  1.34s/it]Loading train:  55%|█████▌    | 157/285 [03:43<02:53,  1.35s/it]Loading train:  55%|█████▌    | 158/285 [03:44<02:43,  1.29s/it]Loading train:  56%|█████▌    | 159/285 [03:46<02:49,  1.35s/it]Loading train:  56%|█████▌    | 160/285 [03:47<02:36,  1.25s/it]Loading train:  56%|█████▋    | 161/285 [03:48<02:39,  1.29s/it]Loading train:  57%|█████▋    | 162/285 [03:50<02:45,  1.34s/it]Loading train:  57%|█████▋    | 163/285 [03:51<02:35,  1.27s/it]Loading train:  58%|█████▊    | 164/285 [03:52<02:34,  1.28s/it]Loading train:  58%|█████▊    | 165/285 [03:53<02:26,  1.22s/it]Loading train:  58%|█████▊    | 166/285 [03:54<02:18,  1.16s/it]Loading train:  59%|█████▊    | 167/285 [03:56<02:26,  1.25s/it]Loading train:  59%|█████▉    | 168/285 [03:57<02:32,  1.30s/it]Loading train:  59%|█████▉    | 169/285 [03:59<02:35,  1.34s/it]Loading train:  60%|█████▉    | 170/285 [04:00<02:25,  1.27s/it]Loading train:  60%|██████    | 171/285 [04:01<02:26,  1.29s/it]Loading train:  60%|██████    | 172/285 [04:03<02:36,  1.39s/it]Loading train:  61%|██████    | 173/285 [04:04<02:31,  1.35s/it]Loading train:  61%|██████    | 174/285 [04:05<02:35,  1.40s/it]Loading train:  61%|██████▏   | 175/285 [04:07<02:31,  1.38s/it]Loading train:  62%|██████▏   | 176/285 [04:08<02:26,  1.34s/it]Loading train:  62%|██████▏   | 177/285 [04:09<02:27,  1.36s/it]Loading train:  62%|██████▏   | 178/285 [04:11<02:21,  1.33s/it]Loading train:  63%|██████▎   | 179/285 [04:12<02:17,  1.30s/it]Loading train:  63%|██████▎   | 180/285 [04:13<02:16,  1.30s/it]Loading train:  64%|██████▎   | 181/285 [04:15<02:21,  1.36s/it]Loading train:  64%|██████▍   | 182/285 [04:16<02:21,  1.37s/it]Loading train:  64%|██████▍   | 183/285 [04:18<02:21,  1.38s/it]Loading train:  65%|██████▍   | 184/285 [04:19<02:13,  1.32s/it]Loading train:  65%|██████▍   | 185/285 [04:20<02:14,  1.35s/it]Loading train:  65%|██████▌   | 186/285 [04:21<02:05,  1.27s/it]Loading train:  66%|██████▌   | 187/285 [04:22<02:05,  1.29s/it]Loading train:  66%|██████▌   | 188/285 [04:24<02:05,  1.29s/it]Loading train:  66%|██████▋   | 189/285 [04:25<02:06,  1.32s/it]Loading train:  67%|██████▋   | 190/285 [04:27<02:05,  1.32s/it]Loading train:  67%|██████▋   | 191/285 [04:28<02:07,  1.36s/it]Loading train:  67%|██████▋   | 192/285 [04:30<02:17,  1.48s/it]Loading train:  68%|██████▊   | 193/285 [04:31<02:12,  1.44s/it]Loading train:  68%|██████▊   | 194/285 [04:32<02:08,  1.41s/it]Loading train:  68%|██████▊   | 195/285 [04:34<02:05,  1.40s/it]Loading train:  69%|██████▉   | 196/285 [04:35<02:02,  1.38s/it]Loading train:  69%|██████▉   | 197/285 [04:36<02:01,  1.38s/it]Loading train:  69%|██████▉   | 198/285 [04:38<02:12,  1.52s/it]Loading train:  70%|██████▉   | 199/285 [04:40<02:14,  1.56s/it]Loading train:  70%|███████   | 200/285 [04:42<02:12,  1.56s/it]Loading train:  71%|███████   | 201/285 [04:43<02:08,  1.53s/it]Loading train:  71%|███████   | 202/285 [04:44<02:04,  1.50s/it]Loading train:  71%|███████   | 203/285 [04:46<02:05,  1.53s/it]Loading train:  72%|███████▏  | 204/285 [04:48<02:05,  1.55s/it]Loading train:  72%|███████▏  | 205/285 [04:49<01:54,  1.43s/it]Loading train:  72%|███████▏  | 206/285 [04:50<01:51,  1.41s/it]Loading train:  73%|███████▎  | 207/285 [04:51<01:45,  1.35s/it]Loading train:  73%|███████▎  | 208/285 [04:53<01:44,  1.35s/it]Loading train:  73%|███████▎  | 209/285 [04:54<01:44,  1.37s/it]Loading train:  74%|███████▎  | 210/285 [04:55<01:42,  1.37s/it]Loading train:  74%|███████▍  | 211/285 [04:57<01:36,  1.31s/it]Loading train:  74%|███████▍  | 212/285 [04:58<01:33,  1.29s/it]Loading train:  75%|███████▍  | 213/285 [04:59<01:32,  1.28s/it]Loading train:  75%|███████▌  | 214/285 [05:00<01:22,  1.16s/it]Loading train:  75%|███████▌  | 215/285 [05:01<01:20,  1.14s/it]Loading train:  76%|███████▌  | 216/285 [05:02<01:13,  1.07s/it]Loading train:  76%|███████▌  | 217/285 [05:03<01:15,  1.12s/it]Loading train:  76%|███████▋  | 218/285 [05:04<01:09,  1.04s/it]Loading train:  77%|███████▋  | 219/285 [05:05<01:09,  1.06s/it]Loading train:  77%|███████▋  | 220/285 [05:06<01:06,  1.02s/it]Loading train:  78%|███████▊  | 221/285 [05:07<01:06,  1.04s/it]Loading train:  78%|███████▊  | 222/285 [05:08<01:05,  1.04s/it]Loading train:  78%|███████▊  | 223/285 [05:09<01:04,  1.04s/it]Loading train:  79%|███████▊  | 224/285 [05:10<01:02,  1.02s/it]Loading train:  79%|███████▉  | 225/285 [05:11<00:58,  1.02it/s]Loading train:  79%|███████▉  | 226/285 [05:12<00:57,  1.03it/s]Loading train:  80%|███████▉  | 227/285 [05:13<00:54,  1.06it/s]Loading train:  80%|████████  | 228/285 [05:14<00:54,  1.05it/s]Loading train:  80%|████████  | 229/285 [05:15<00:52,  1.07it/s]Loading train:  81%|████████  | 230/285 [05:16<00:53,  1.02it/s]Loading train:  81%|████████  | 231/285 [05:17<00:52,  1.03it/s]Loading train:  81%|████████▏ | 232/285 [05:18<00:54,  1.02s/it]Loading train:  82%|████████▏ | 233/285 [05:19<00:56,  1.10s/it]Loading train:  82%|████████▏ | 234/285 [05:20<00:56,  1.10s/it]Loading train:  82%|████████▏ | 235/285 [05:22<00:55,  1.10s/it]Loading train:  83%|████████▎ | 236/285 [05:23<00:55,  1.14s/it]Loading train:  83%|████████▎ | 237/285 [05:24<00:54,  1.13s/it]Loading train:  84%|████████▎ | 238/285 [05:25<00:54,  1.17s/it]Loading train:  84%|████████▍ | 239/285 [05:26<00:54,  1.18s/it]Loading train:  84%|████████▍ | 240/285 [05:28<00:56,  1.25s/it]Loading train:  85%|████████▍ | 241/285 [05:29<00:56,  1.29s/it]Loading train:  85%|████████▍ | 242/285 [05:30<00:54,  1.28s/it]Loading train:  85%|████████▌ | 243/285 [05:32<00:52,  1.25s/it]Loading train:  86%|████████▌ | 244/285 [05:33<00:51,  1.25s/it]Loading train:  86%|████████▌ | 245/285 [05:34<00:52,  1.31s/it]Loading train:  86%|████████▋ | 246/285 [05:36<00:50,  1.29s/it]Loading train:  87%|████████▋ | 247/285 [05:37<00:50,  1.33s/it]Loading train:  87%|████████▋ | 248/285 [05:38<00:48,  1.30s/it]Loading train:  87%|████████▋ | 249/285 [05:40<00:49,  1.38s/it]Loading train:  88%|████████▊ | 250/285 [05:41<00:49,  1.40s/it]Loading train:  88%|████████▊ | 251/285 [05:43<00:47,  1.41s/it]Loading train:  88%|████████▊ | 252/285 [05:44<00:48,  1.46s/it]Loading train:  89%|████████▉ | 253/285 [05:46<00:53,  1.67s/it]Loading train:  89%|████████▉ | 254/285 [05:48<00:52,  1.71s/it]Loading train:  89%|████████▉ | 255/285 [05:50<00:54,  1.82s/it]Loading train:  90%|████████▉ | 256/285 [05:52<00:52,  1.80s/it]Loading train:  90%|█████████ | 257/285 [05:54<00:50,  1.81s/it]Loading train:  91%|█████████ | 258/285 [05:56<00:49,  1.84s/it]Loading train:  91%|█████████ | 259/285 [05:58<00:48,  1.86s/it]Loading train:  91%|█████████ | 260/285 [06:00<00:46,  1.87s/it]Loading train:  92%|█████████▏| 261/285 [06:01<00:41,  1.74s/it]Loading train:  92%|█████████▏| 262/285 [06:03<00:41,  1.80s/it]Loading train:  92%|█████████▏| 263/285 [06:05<00:39,  1.78s/it]Loading train:  93%|█████████▎| 264/285 [06:06<00:36,  1.74s/it]Loading train:  93%|█████████▎| 265/285 [06:07<00:31,  1.58s/it]Loading train:  93%|█████████▎| 266/285 [06:09<00:30,  1.62s/it]Loading train:  94%|█████████▎| 267/285 [06:11<00:29,  1.63s/it]Loading train:  94%|█████████▍| 268/285 [06:13<00:30,  1.77s/it]Loading train:  94%|█████████▍| 269/285 [06:15<00:29,  1.82s/it]Loading train:  95%|█████████▍| 270/285 [06:17<00:28,  1.93s/it]Loading train:  95%|█████████▌| 271/285 [06:19<00:27,  1.98s/it]Loading train:  95%|█████████▌| 272/285 [06:21<00:25,  1.98s/it]Loading train:  96%|█████████▌| 273/285 [06:24<00:26,  2.18s/it]Loading train:  96%|█████████▌| 274/285 [06:26<00:25,  2.32s/it]Loading train:  96%|█████████▋| 275/285 [06:29<00:22,  2.29s/it]Loading train:  97%|█████████▋| 276/285 [06:31<00:19,  2.18s/it]Loading train:  97%|█████████▋| 277/285 [06:33<00:16,  2.12s/it]Loading train:  98%|█████████▊| 278/285 [06:35<00:15,  2.15s/it]Loading train:  98%|█████████▊| 279/285 [06:37<00:12,  2.16s/it]Loading train:  98%|█████████▊| 280/285 [06:39<00:11,  2.21s/it]Loading train:  99%|█████████▊| 281/285 [06:42<00:09,  2.33s/it]Loading train:  99%|█████████▉| 282/285 [06:43<00:06,  2.03s/it]Loading train:  99%|█████████▉| 283/285 [06:45<00:03,  1.82s/it]Loading train: 100%|█████████▉| 284/285 [06:46<00:01,  1.80s/it]Loading train: 100%|██████████| 285/285 [06:48<00:00,  1.76s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:09, 28.24it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:10, 26.99it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:09, 27.76it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:10, 25.73it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:10, 25.51it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:11, 22.81it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:12, 20.71it/s]concatenating: train:   9%|▉         | 25/285 [00:01<00:11, 22.42it/s]concatenating: train:  11%|█         | 31/285 [00:01<00:09, 27.58it/s]concatenating: train:  15%|█▍        | 42/285 [00:01<00:06, 35.45it/s]concatenating: train:  17%|█▋        | 48/285 [00:01<00:06, 37.11it/s]concatenating: train:  19%|█▉        | 54/285 [00:01<00:06, 33.29it/s]concatenating: train:  21%|██        | 59/285 [00:01<00:07, 31.90it/s]concatenating: train:  22%|██▏       | 63/285 [00:01<00:07, 29.46it/s]concatenating: train:  24%|██▎       | 67/285 [00:02<00:08, 26.21it/s]concatenating: train:  25%|██▍       | 71/285 [00:02<00:10, 20.96it/s]concatenating: train:  26%|██▋       | 75/285 [00:02<00:08, 23.82it/s]concatenating: train:  29%|██▉       | 82/285 [00:02<00:06, 29.47it/s]concatenating: train:  31%|███       | 89/285 [00:02<00:05, 34.81it/s]concatenating: train:  34%|███▎      | 96/285 [00:02<00:04, 39.37it/s]concatenating: train:  35%|███▌      | 101/285 [00:03<00:04, 39.28it/s]concatenating: train:  37%|███▋      | 106/285 [00:03<00:05, 34.08it/s]concatenating: train:  39%|███▉      | 111/285 [00:03<00:05, 32.66it/s]concatenating: train:  40%|████      | 115/285 [00:03<00:05, 32.22it/s]concatenating: train:  42%|████▏     | 119/285 [00:03<00:05, 28.85it/s]concatenating: train:  43%|████▎     | 123/285 [00:03<00:05, 28.77it/s]concatenating: train:  45%|████▍     | 127/285 [00:04<00:05, 26.46it/s]concatenating: train:  46%|████▌     | 131/285 [00:04<00:05, 27.73it/s]concatenating: train:  48%|████▊     | 136/285 [00:04<00:04, 31.98it/s]concatenating: train:  49%|████▉     | 141/285 [00:04<00:04, 33.85it/s]concatenating: train:  51%|█████     | 145/285 [00:04<00:04, 31.77it/s]concatenating: train:  53%|█████▎    | 150/285 [00:04<00:03, 33.90it/s]concatenating: train:  54%|█████▍    | 154/285 [00:04<00:04, 28.78it/s]concatenating: train:  55%|█████▌    | 158/285 [00:05<00:04, 25.65it/s]concatenating: train:  56%|█████▋    | 161/285 [00:05<00:04, 24.94it/s]concatenating: train:  58%|█████▊    | 164/285 [00:05<00:04, 25.11it/s]concatenating: train:  59%|█████▊    | 167/285 [00:05<00:04, 25.96it/s]concatenating: train:  60%|█████▉    | 170/285 [00:05<00:04, 25.67it/s]concatenating: train:  61%|██████    | 173/285 [00:05<00:04, 25.72it/s]concatenating: train:  62%|██████▏   | 176/285 [00:05<00:04, 22.32it/s]concatenating: train:  63%|██████▎   | 179/285 [00:05<00:05, 21.11it/s]concatenating: train:  64%|██████▍   | 183/285 [00:06<00:04, 23.39it/s]concatenating: train:  65%|██████▌   | 186/285 [00:06<00:03, 24.80it/s]concatenating: train:  66%|██████▋   | 189/285 [00:06<00:03, 24.14it/s]concatenating: train:  68%|██████▊   | 194/285 [00:06<00:03, 28.16it/s]concatenating: train:  71%|███████   | 201/285 [00:06<00:02, 33.36it/s]concatenating: train:  73%|███████▎  | 207/285 [00:06<00:02, 37.58it/s]concatenating: train:  74%|███████▍  | 212/285 [00:06<00:01, 39.47it/s]concatenating: train:  76%|███████▌  | 217/285 [00:06<00:01, 34.49it/s]concatenating: train:  78%|███████▊  | 221/285 [00:07<00:02, 29.77it/s]concatenating: train:  79%|███████▉  | 225/285 [00:07<00:02, 27.76it/s]concatenating: train:  80%|████████  | 229/285 [00:07<00:02, 24.15it/s]concatenating: train:  81%|████████▏ | 232/285 [00:07<00:02, 23.26it/s]concatenating: train:  83%|████████▎ | 236/285 [00:07<00:01, 25.00it/s]concatenating: train:  84%|████████▍ | 240/285 [00:07<00:01, 23.10it/s]concatenating: train:  85%|████████▌ | 243/285 [00:08<00:02, 20.53it/s]concatenating: train:  86%|████████▋ | 246/285 [00:08<00:02, 19.50it/s]concatenating: train:  87%|████████▋ | 249/285 [00:08<00:01, 21.21it/s]concatenating: train:  89%|████████▉ | 253/285 [00:08<00:01, 23.83it/s]concatenating: train:  91%|█████████ | 259/285 [00:08<00:00, 28.90it/s]concatenating: train:  93%|█████████▎| 265/285 [00:08<00:00, 34.22it/s]concatenating: train:  95%|█████████▌| 271/285 [00:08<00:00, 35.93it/s]concatenating: train:  97%|█████████▋| 276/285 [00:09<00:00, 30.37it/s]concatenating: train:  98%|█████████▊| 280/285 [00:09<00:00, 31.17it/s]concatenating: train: 100%|██████████| 285/285 [00:09<00:00, 33.46it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.91s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.91s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00, 14.08it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 14.55it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 40)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   28880       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 80)   0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   12840       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 80)   0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   28840       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 40)   0           activation_8[0][0]               
__________________________________________________________________________________________________2019-06-30 19:06:26.741420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 19:06:26.741532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 19:06:26.741552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 19:06:26.741567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 19:06:26.742165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   3220        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 20)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   273         dropout_5[0][0]                  
==================================================================================================
Total params: 184,113
Trainable params: 183,313
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [2.45357524e+01 1.20808280e+01 2.83540199e+01 3.52403467e+00
 1.02430434e+01 2.67099910e+00 3.19605001e+01 4.25814537e+01
 3.25211438e+01 5.00837070e+00 1.11201025e+02 7.27972247e+01
 8.67943023e-02]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 20s - loss: 1254.7722 - acc: 0.9045 - mDice: 0.2963 - val_loss: 1070.2930 - val_acc: 0.9360 - val_mDice: 0.3653

Epoch 00001: val_mDice improved from -inf to 0.36526, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 12s - loss: 724.8430 - acc: 0.9198 - mDice: 0.4787 - val_loss: 840.1758 - val_acc: 0.9403 - val_mDice: 0.4588

Epoch 00002: val_mDice improved from 0.36526 to 0.45882, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 632.8313 - acc: 0.9247 - mDice: 0.5345 - val_loss: 780.0135 - val_acc: 0.9430 - val_mDice: 0.4926

Epoch 00003: val_mDice improved from 0.45882 to 0.49261, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 12s - loss: 581.9922 - acc: 0.9272 - mDice: 0.5669 - val_loss: 838.9614 - val_acc: 0.9436 - val_mDice: 0.4919

Epoch 00004: val_mDice did not improve from 0.49261
Epoch 5/300
 - 12s - loss: 549.7267 - acc: 0.9290 - mDice: 0.5886 - val_loss: 844.7846 - val_acc: 0.9435 - val_mDice: 0.5064

Epoch 00005: val_mDice improved from 0.49261 to 0.50636, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 526.6783 - acc: 0.9298 - mDice: 0.6042 - val_loss: 956.8468 - val_acc: 0.9432 - val_mDice: 0.5023

Epoch 00006: val_mDice did not improve from 0.50636
Epoch 7/300
 - 12s - loss: 506.7817 - acc: 0.9307 - mDice: 0.6182 - val_loss: 969.3173 - val_acc: 0.9444 - val_mDice: 0.5068

Epoch 00007: val_mDice improved from 0.50636 to 0.50681, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 490.5599 - acc: 0.9308 - mDice: 0.6304 - val_loss: 933.8165 - val_acc: 0.9446 - val_mDice: 0.5109

Epoch 00008: val_mDice improved from 0.50681 to 0.51093, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 476.3105 - acc: 0.9315 - mDice: 0.6396 - val_loss: 1002.4182 - val_acc: 0.9438 - val_mDice: 0.5114

Epoch 00009: val_mDice improved from 0.51093 to 0.51145, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 12s - loss: 464.4492 - acc: 0.9320 - mDice: 0.6482 - val_loss: 990.0458 - val_acc: 0.9438 - val_mDice: 0.5094

Epoch 00010: val_mDice did not improve from 0.51145
Epoch 11/300
 - 11s - loss: 455.1385 - acc: 0.9326 - mDice: 0.6546 - val_loss: 1120.1619 - val_acc: 0.9432 - val_mDice: 0.4977

Epoch 00011: val_mDice did not improve from 0.51145
Epoch 12/300
 - 11s - loss: 448.5078 - acc: 0.9327 - mDice: 0.6593 - val_loss: 1103.1312 - val_acc: 0.9442 - val_mDice: 0.5070

Epoch 00012: val_mDice did not improve from 0.51145
Epoch 13/300
 - 11s - loss: 437.9963 - acc: 0.9334 - mDice: 0.6671 - val_loss: 1182.8350 - val_acc: 0.9443 - val_mDice: 0.4982

Epoch 00013: val_mDice did not improve from 0.51145
Epoch 14/300
 - 12s - loss: 431.4344 - acc: 0.9338 - mDice: 0.6725 - val_loss: 1097.4394 - val_acc: 0.9442 - val_mDice: 0.5154

Epoch 00014: val_mDice improved from 0.51145 to 0.51541, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 11s - loss: 425.5564 - acc: 0.9343 - mDice: 0.6768 - val_loss: 1124.0810 - val_acc: 0.9450 - val_mDice: 0.5157

Epoch 00015: val_mDice improved from 0.51541 to 0.51572, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 12s - loss: 419.6221 - acc: 0.9343 - mDice: 0.6810 - val_loss: 1129.4533 - val_acc: 0.9444 - val_mDice: 0.5138

Epoch 00016: val_mDice did not improve from 0.51572
Epoch 17/300
 - 11s - loss: 416.2792 - acc: 0.9347 - mDice: 0.6832 - val_loss: 1142.1104 - val_acc: 0.9441 - val_mDice: 0.5035

Epoch 00017: val_mDice did not improve from 0.51572
Epoch 18/300
 - 12s - loss: 409.7452 - acc: 0.9351 - mDice: 0.6885 - val_loss: 1315.5893 - val_acc: 0.9445 - val_mDice: 0.5034

Epoch 00018: val_mDice did not improve from 0.51572
Epoch 19/300
 - 11s - loss: 405.5626 - acc: 0.9353 - mDice: 0.6910 - val_loss: 1190.5924 - val_acc: 0.9436 - val_mDice: 0.5055

Epoch 00019: val_mDice did not improve from 0.51572
Epoch 20/300
 - 11s - loss: 402.1538 - acc: 0.9354 - mDice: 0.6940 - val_loss: 1187.0482 - val_acc: 0.9442 - val_mDice: 0.5223

Epoch 00020: val_mDice improved from 0.51572 to 0.52233, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 11s - loss: 396.6456 - acc: 0.9360 - mDice: 0.6980 - val_loss: 1214.3125 - val_acc: 0.9439 - val_mDice: 0.5097

Epoch 00021: val_mDice did not improve from 0.52233
Epoch 22/300
 - 12s - loss: 393.2083 - acc: 0.9363 - mDice: 0.7004 - val_loss: 1263.0480 - val_acc: 0.9446 - val_mDice: 0.5144

Epoch 00022: val_mDice did not improve from 0.52233
Epoch 23/300
 - 12s - loss: 390.5663 - acc: 0.9362 - mDice: 0.7028 - val_loss: 1239.0664 - val_acc: 0.9439 - val_mDice: 0.5062

Epoch 00023: val_mDice did not improve from 0.52233
Epoch 24/300
 - 11s - loss: 385.9059 - acc: 0.9364 - mDice: 0.7061 - val_loss: 1208.9107 - val_acc: 0.9445 - val_mDice: 0.5245

Epoch 00024: val_mDice improved from 0.52233 to 0.52454, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 11s - loss: 385.4604 - acc: 0.9365 - mDice: 0.7062 - val_loss: 1266.1950 - val_acc: 0.9446 - val_mDice: 0.5160

Epoch 00025: val_mDice did not improve from 0.52454
Epoch 26/300
 - 11s - loss: 381.5830 - acc: 0.9370 - mDice: 0.7093 - val_loss: 1234.9252 - val_acc: 0.9448 - val_mDice: 0.5157

Epoch 00026: val_mDice did not improve from 0.52454
Epoch 27/300
 - 11s - loss: 379.5841 - acc: 0.9373 - mDice: 0.7103 - val_loss: 1108.1133 - val_acc: 0.9441 - val_mDice: 0.5303

Epoch 00027: val_mDice improved from 0.52454 to 0.53033, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 12s - loss: 376.0710 - acc: 0.9373 - mDice: 0.7134 - val_loss: 1297.1482 - val_acc: 0.9445 - val_mDice: 0.5120

Epoch 00028: val_mDice did not improve from 0.53033
Epoch 29/300
 - 11s - loss: 373.6414 - acc: 0.9373 - mDice: 0.7153 - val_loss: 1138.1356 - val_acc: 0.9439 - val_mDice: 0.5295

Epoch 00029: val_mDice did not improve from 0.53033
Epoch 30/300
 - 11s - loss: 371.7733 - acc: 0.9378 - mDice: 0.7166 - val_loss: 1412.0436 - val_acc: 0.9435 - val_mDice: 0.4944

Epoch 00030: val_mDice did not improve from 0.53033
Epoch 31/300
 - 11s - loss: 369.3912 - acc: 0.9380 - mDice: 0.7185 - val_loss: 1331.8719 - val_acc: 0.9442 - val_mDice: 0.5079

Epoch 00031: val_mDice did not improve from 0.53033
Epoch 32/300
 - 11s - loss: 367.3799 - acc: 0.9384 - mDice: 0.7199 - val_loss: 1307.7426 - val_acc: 0.9448 - val_mDice: 0.5170

Epoch 00032: val_mDice did not improve from 0.53033
Epoch 33/300
 - 11s - loss: 364.7248 - acc: 0.9386 - mDice: 0.7218 - val_loss: 1373.6878 - val_acc: 0.9444 - val_mDice: 0.5137

Epoch 00033: val_mDice did not improve from 0.53033
Epoch 34/300
 - 11s - loss: 362.6419 - acc: 0.9388 - mDice: 0.7231 - val_loss: 1198.4726 - val_acc: 0.9441 - val_mDice: 0.5249

Epoch 00034: val_mDice did not improve from 0.53033
Epoch 35/300
 - 12s - loss: 361.2281 - acc: 0.9385 - mDice: 0.7245 - val_loss: 1387.2123 - val_acc: 0.9451 - val_mDice: 0.5145

Epoch 00035: val_mDice did not improve from 0.53033
Epoch 36/300
 - 11s - loss: 359.6423 - acc: 0.9386 - mDice: 0.7257 - val_loss: 1406.4757 - val_acc: 0.9447 - val_mDice: 0.5091

Epoch 00036: val_mDice did not improve from 0.53033
Epoch 37/300
 - 11s - loss: 357.9956 - acc: 0.9387 - mDice: 0.7272 - val_loss: 1380.9835 - val_acc: 0.9445 - val_mDice: 0.5129

Epoch 00037: val_mDice did not improve from 0.53033
Epoch 38/300
 - 11s - loss: 355.7894 - acc: 0.9393 - mDice: 0.7284 - val_loss: 1357.8617 - val_acc: 0.9441 - val_mDice: 0.5091

Epoch 00038: val_mDice did not improve from 0.53033
Epoch 39/300
 - 11s - loss: 355.7188 - acc: 0.9390 - mDice: 0.7285 - val_loss: 1479.0829 - val_acc: 0.9452 - val_mDice: 0.5059

Epoch 00039: val_mDice did not improve from 0.53033
Epoch 40/300
 - 11s - loss: 352.4300 - acc: 0.9394 - mDice: 0.7305 - val_loss: 1399.9696 - val_acc: 0.9446 - val_mDice: 0.5119

Epoch 00040: val_mDice did not improve from 0.53033
Epoch 41/300
 - 11s - loss: 351.3369 - acc: 0.9394 - mDice: 0.7322 - val_loss: 1400.3092 - val_acc: 0.9447 - val_mDice: 0.5159

Epoch 00041: val_mDice did not improve from 0.53033
Epoch 42/300
 - 11s - loss: 348.7720 - acc: 0.9398 - mDice: 0.7337 - val_loss: 1357.7595 - val_acc: 0.9448 - val_mDice: 0.5230

Epoch 00042: val_mDice did not improve from 0.53033
Epoch 43/300
 - 11s - loss: 351.1219 - acc: 0.9397 - mDice: 0.7321 - val_loss: 1276.4326 - val_acc: 0.9451 - val_mDice: 0.5218

Epoch 00043: val_mDice did not improve from 0.53033
Epoch 44/300
 - 11s - loss: 346.1786 - acc: 0.9400 - mDice: 0.7355 - val_loss: 1382.1994 - val_acc: 0.9439 - val_mDice: 0.5099

Epoch 00044: val_mDice did not improve from 0.53033
Epoch 45/300
 - 11s - loss: 344.7782 - acc: 0.9399 - mDice: 0.7370 - val_loss: 1293.0597 - val_acc: 0.9445 - val_mDice: 0.5208

Epoch 00045: val_mDice did not improve from 0.53033
Epoch 46/300
 - 11s - loss: 344.9701 - acc: 0.9397 - mDice: 0.7369 - val_loss: 1365.8648 - val_acc: 0.9434 - val_mDice: 0.5197

Epoch 00046: val_mDice did not improve from 0.53033
Epoch 47/300
 - 11s - loss: 343.1016 - acc: 0.9400 - mDice: 0.7376 - val_loss: 1334.8401 - val_acc: 0.9443 - val_mDice: 0.5213

Epoch 00047: val_mDice did not improve from 0.53033
Epoch 48/300
 - 11s - loss: 341.0642 - acc: 0.9402 - mDice: 0.7396 - val_loss: 1362.6604 - val_acc: 0.9445 - val_mDice: 0.5123

Epoch 00048: val_mDice did not improve from 0.53033
Epoch 49/300
 - 12s - loss: 340.4536 - acc: 0.9405 - mDice: 0.7397 - val_loss: 1521.7303 - val_acc: 0.9444 - val_mDice: 0.5038

Epoch 00049: val_mDice did not improve from 0.53033
Epoch 50/300
 - 11s - loss: 340.6992 - acc: 0.9405 - mDice: 0.7401 - val_loss: 1416.2315 - val_acc: 0.9450 - val_mDice: 0.5136

Epoch 00050: val_mDice did not improve from 0.53033
Epoch 51/300
 - 11s - loss: 337.7598 - acc: 0.9405 - mDice: 0.7419 - val_loss: 1321.0907 - val_acc: 0.9437 - val_mDice: 0.5144

Epoch 00051: val_mDice did not improve from 0.53033
Epoch 52/300
 - 11s - loss: 337.5111 - acc: 0.9404 - mDice: 0.7425 - val_loss: 1433.7851 - val_acc: 0.9442 - val_mDice: 0.5056

Epoch 00052: val_mDice did not improve from 0.53033
Epoch 53/300
 - 11s - loss: 336.2698 - acc: 0.9405 - mDice: 0.7433 - val_loss: 1458.1196 - val_acc: 0.9444 - val_mDice: 0.5011

Epoch 00053: val_mDice did not improve from 0.53033
Epoch 54/300
 - 11s - loss: 335.6465 - acc: 0.9403 - mDice: 0.7433 - val_loss: 1421.3719 - val_acc: 0.9451 - val_mDice: 0.5185

Epoch 00054: val_mDice did not improve from 0.53033
Epoch 55/300
 - 11s - loss: 334.2765 - acc: 0.9408 - mDice: 0.7443 - val_loss: 1536.9791 - val_acc: 0.9438 - val_mDice: 0.5027

Epoch 00055: val_mDice did not improve from 0.53033
Epoch 56/300
 - 11s - loss: 332.8052 - acc: 0.9406 - mDice: 0.7455 - val_loss: 1434.8096 - val_acc: 0.9444 - val_mDice: 0.5101

Epoch 00056: val_mDice did not improve from 0.53033
Epoch 57/300
 - 11s - loss: 333.6247 - acc: 0.9408 - mDice: 0.7453 - val_loss: 1414.6813 - val_acc: 0.9447 - val_mDice: 0.5124

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.62s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.42s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.25s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:53,  1.88s/it]predicting train subjects:   1%|          | 2/285 [00:04<10:25,  2.21s/it]predicting train subjects:   1%|          | 3/285 [00:06<10:01,  2.13s/it]predicting train subjects:   1%|▏         | 4/285 [00:09<10:05,  2.15s/it]predicting train subjects:   2%|▏         | 5/285 [00:10<09:40,  2.07s/it]predicting train subjects:   2%|▏         | 6/285 [00:13<10:12,  2.20s/it]predicting train subjects:   2%|▏         | 7/285 [00:15<10:32,  2.27s/it]predicting train subjects:   3%|▎         | 8/285 [00:18<10:43,  2.32s/it]predicting train subjects:   3%|▎         | 9/285 [00:20<10:24,  2.26s/it]predicting train subjects:   4%|▎         | 10/285 [00:23<10:55,  2.38s/it]predicting train subjects:   4%|▍         | 11/285 [00:25<11:12,  2.45s/it]predicting train subjects:   4%|▍         | 12/285 [00:28<11:15,  2.48s/it]predicting train subjects:   5%|▍         | 13/285 [00:30<11:32,  2.55s/it]predicting train subjects:   5%|▍         | 14/285 [00:33<11:27,  2.54s/it]predicting train subjects:   5%|▌         | 15/285 [00:35<11:21,  2.52s/it]predicting train subjects:   6%|▌         | 16/285 [00:38<11:16,  2.51s/it]predicting train subjects:   6%|▌         | 17/285 [00:41<11:19,  2.53s/it]predicting train subjects:   6%|▋         | 18/285 [00:43<11:08,  2.50s/it]predicting train subjects:   7%|▋         | 19/285 [00:46<11:17,  2.55s/it]predicting train subjects:   7%|▋         | 20/285 [00:48<11:15,  2.55s/it]predicting train subjects:   7%|▋         | 21/285 [00:50<10:57,  2.49s/it]predicting train subjects:   8%|▊         | 22/285 [00:53<10:50,  2.47s/it]predicting train subjects:   8%|▊         | 23/285 [00:56<11:01,  2.52s/it]predicting train subjects:   8%|▊         | 24/285 [00:58<11:08,  2.56s/it]predicting train subjects:   9%|▉         | 25/285 [01:01<11:25,  2.64s/it]predicting train subjects:   9%|▉         | 26/285 [01:04<11:14,  2.60s/it]predicting train subjects:   9%|▉         | 27/285 [01:06<11:32,  2.68s/it]predicting train subjects:  10%|▉         | 28/285 [01:09<11:09,  2.60s/it]predicting train subjects:  10%|█         | 29/285 [01:11<10:37,  2.49s/it]predicting train subjects:  11%|█         | 30/285 [01:13<10:13,  2.40s/it]predicting train subjects:  11%|█         | 31/285 [01:16<10:24,  2.46s/it]predicting train subjects:  11%|█         | 32/285 [01:18<10:02,  2.38s/it]predicting train subjects:  12%|█▏        | 33/285 [01:20<09:52,  2.35s/it]predicting train subjects:  12%|█▏        | 34/285 [01:23<09:46,  2.33s/it]predicting train subjects:  12%|█▏        | 35/285 [01:25<09:33,  2.29s/it]predicting train subjects:  13%|█▎        | 36/285 [01:27<09:25,  2.27s/it]predicting train subjects:  13%|█▎        | 37/285 [01:29<09:20,  2.26s/it]predicting train subjects:  13%|█▎        | 38/285 [01:32<09:17,  2.26s/it]predicting train subjects:  14%|█▎        | 39/285 [01:34<09:18,  2.27s/it]predicting train subjects:  14%|█▍        | 40/285 [01:36<09:25,  2.31s/it]predicting train subjects:  14%|█▍        | 41/285 [01:39<09:23,  2.31s/it]predicting train subjects:  15%|█▍        | 42/285 [01:41<09:26,  2.33s/it]predicting train subjects:  15%|█▌        | 43/285 [01:43<09:23,  2.33s/it]predicting train subjects:  15%|█▌        | 44/285 [01:45<09:14,  2.30s/it]predicting train subjects:  16%|█▌        | 45/285 [01:48<09:13,  2.31s/it]predicting train subjects:  16%|█▌        | 46/285 [01:50<08:53,  2.23s/it]predicting train subjects:  16%|█▋        | 47/285 [01:52<08:43,  2.20s/it]predicting train subjects:  17%|█▋        | 48/285 [01:54<08:36,  2.18s/it]predicting train subjects:  17%|█▋        | 49/285 [01:56<08:46,  2.23s/it]predicting train subjects:  18%|█▊        | 50/285 [01:59<08:32,  2.18s/it]predicting train subjects:  18%|█▊        | 51/285 [02:01<08:55,  2.29s/it]predicting train subjects:  18%|█▊        | 52/285 [02:03<08:35,  2.21s/it]predicting train subjects:  19%|█▊        | 53/285 [02:05<08:38,  2.23s/it]predicting train subjects:  19%|█▉        | 54/285 [02:07<08:20,  2.17s/it]predicting train subjects:  19%|█▉        | 55/285 [02:09<08:01,  2.10s/it]predicting train subjects:  20%|█▉        | 56/285 [02:11<07:57,  2.08s/it]predicting train subjects:  20%|██        | 57/285 [02:14<08:03,  2.12s/it]predicting train subjects:  20%|██        | 58/285 [02:16<08:09,  2.16s/it]predicting train subjects:  21%|██        | 59/285 [02:18<08:06,  2.15s/it]predicting train subjects:  21%|██        | 60/285 [02:20<07:56,  2.12s/it]predicting train subjects:  21%|██▏       | 61/285 [02:22<07:57,  2.13s/it]predicting train subjects:  22%|██▏       | 62/285 [02:24<07:48,  2.10s/it]predicting train subjects:  22%|██▏       | 63/285 [02:26<07:40,  2.08s/it]predicting train subjects:  22%|██▏       | 64/285 [02:28<07:37,  2.07s/it]predicting train subjects:  23%|██▎       | 65/285 [02:31<07:54,  2.16s/it]predicting train subjects:  23%|██▎       | 66/285 [02:33<07:56,  2.18s/it]predicting train subjects:  24%|██▎       | 67/285 [02:35<07:46,  2.14s/it]predicting train subjects:  24%|██▍       | 68/285 [02:37<07:45,  2.15s/it]predicting train subjects:  24%|██▍       | 69/285 [02:39<07:38,  2.12s/it]predicting train subjects:  25%|██▍       | 70/285 [02:41<07:30,  2.10s/it]predicting train subjects:  25%|██▍       | 71/285 [02:43<07:17,  2.04s/it]predicting train subjects:  25%|██▌       | 72/285 [02:45<07:21,  2.08s/it]predicting train subjects:  26%|██▌       | 73/285 [02:47<07:17,  2.06s/it]predicting train subjects:  26%|██▌       | 74/285 [02:49<07:14,  2.06s/it]predicting train subjects:  26%|██▋       | 75/285 [02:52<07:21,  2.10s/it]predicting train subjects:  27%|██▋       | 76/285 [02:54<07:25,  2.13s/it]predicting train subjects:  27%|██▋       | 77/285 [02:56<07:18,  2.11s/it]predicting train subjects:  27%|██▋       | 78/285 [02:58<07:16,  2.11s/it]predicting train subjects:  28%|██▊       | 79/285 [03:00<07:11,  2.09s/it]predicting train subjects:  28%|██▊       | 80/285 [03:02<07:01,  2.06s/it]predicting train subjects:  28%|██▊       | 81/285 [03:04<06:51,  2.02s/it]predicting train subjects:  29%|██▉       | 82/285 [03:06<07:03,  2.08s/it]predicting train subjects:  29%|██▉       | 83/285 [03:08<07:15,  2.15s/it]predicting train subjects:  29%|██▉       | 84/285 [03:11<07:10,  2.14s/it]predicting train subjects:  30%|██▉       | 85/285 [03:13<07:14,  2.17s/it]predicting train subjects:  30%|███       | 86/285 [03:15<07:21,  2.22s/it]predicting train subjects:  31%|███       | 87/285 [03:18<07:54,  2.40s/it]predicting train subjects:  31%|███       | 88/285 [03:21<08:09,  2.48s/it]predicting train subjects:  31%|███       | 89/285 [03:23<07:41,  2.35s/it]predicting train subjects:  32%|███▏      | 90/285 [03:25<07:26,  2.29s/it]predicting train subjects:  32%|███▏      | 91/285 [03:27<07:20,  2.27s/it]predicting train subjects:  32%|███▏      | 92/285 [03:29<07:30,  2.33s/it]predicting train subjects:  33%|███▎      | 93/285 [03:32<07:30,  2.35s/it]predicting train subjects:  33%|███▎      | 94/285 [03:34<07:28,  2.35s/it]predicting train subjects:  33%|███▎      | 95/285 [03:37<07:35,  2.40s/it]predicting train subjects:  34%|███▎      | 96/285 [03:39<07:41,  2.44s/it]predicting train subjects:  34%|███▍      | 97/285 [03:42<07:34,  2.42s/it]predicting train subjects:  34%|███▍      | 98/285 [03:44<07:23,  2.37s/it]predicting train subjects:  35%|███▍      | 99/285 [03:46<07:25,  2.39s/it]predicting train subjects:  35%|███▌      | 100/285 [03:49<07:20,  2.38s/it]predicting train subjects:  35%|███▌      | 101/285 [03:51<07:10,  2.34s/it]predicting train subjects:  36%|███▌      | 102/285 [03:53<06:59,  2.29s/it]predicting train subjects:  36%|███▌      | 103/285 [03:55<06:55,  2.28s/it]predicting train subjects:  36%|███▋      | 104/285 [03:58<06:54,  2.29s/it]predicting train subjects:  37%|███▋      | 105/285 [04:00<06:52,  2.29s/it]predicting train subjects:  37%|███▋      | 106/285 [04:02<06:58,  2.34s/it]predicting train subjects:  38%|███▊      | 107/285 [04:05<06:51,  2.31s/it]predicting train subjects:  38%|███▊      | 108/285 [04:07<06:53,  2.33s/it]predicting train subjects:  38%|███▊      | 109/285 [04:09<06:44,  2.30s/it]predicting train subjects:  39%|███▊      | 110/285 [04:11<06:30,  2.23s/it]predicting train subjects:  39%|███▉      | 111/285 [04:14<06:27,  2.23s/it]predicting train subjects:  39%|███▉      | 112/285 [04:16<06:24,  2.22s/it]predicting train subjects:  40%|███▉      | 113/285 [04:18<06:20,  2.21s/it]predicting train subjects:  40%|████      | 114/285 [04:20<06:24,  2.25s/it]predicting train subjects:  40%|████      | 115/285 [04:23<06:20,  2.24s/it]predicting train subjects:  41%|████      | 116/285 [04:25<06:24,  2.28s/it]predicting train subjects:  41%|████      | 117/285 [04:27<06:22,  2.28s/it]predicting train subjects:  41%|████▏     | 118/285 [04:30<06:24,  2.31s/it]predicting train subjects:  42%|████▏     | 119/285 [04:32<06:26,  2.33s/it]predicting train subjects:  42%|████▏     | 120/285 [04:34<06:19,  2.30s/it]predicting train subjects:  42%|████▏     | 121/285 [04:36<06:04,  2.22s/it]predicting train subjects:  43%|████▎     | 122/285 [04:38<05:40,  2.09s/it]predicting train subjects:  43%|████▎     | 123/285 [04:40<05:24,  2.00s/it]predicting train subjects:  44%|████▎     | 124/285 [04:42<05:29,  2.05s/it]predicting train subjects:  44%|████▍     | 125/285 [04:44<05:34,  2.09s/it]predicting train subjects:  44%|████▍     | 126/285 [04:46<05:30,  2.08s/it]predicting train subjects:  45%|████▍     | 127/285 [04:48<05:32,  2.10s/it]predicting train subjects:  45%|████▍     | 128/285 [04:50<05:25,  2.07s/it]predicting train subjects:  45%|████▌     | 129/285 [04:53<05:35,  2.15s/it]predicting train subjects:  46%|████▌     | 130/285 [04:55<05:29,  2.13s/it]predicting train subjects:  46%|████▌     | 131/285 [04:57<05:29,  2.14s/it]predicting train subjects:  46%|████▋     | 132/285 [04:59<05:31,  2.17s/it]predicting train subjects:  47%|████▋     | 133/285 [05:01<05:18,  2.09s/it]predicting train subjects:  47%|████▋     | 134/285 [05:03<05:13,  2.08s/it]predicting train subjects:  47%|████▋     | 135/285 [05:05<05:08,  2.06s/it]predicting train subjects:  48%|████▊     | 136/285 [05:07<05:04,  2.04s/it]predicting train subjects:  48%|████▊     | 137/285 [05:09<05:04,  2.05s/it]predicting train subjects:  48%|████▊     | 138/285 [05:11<04:59,  2.04s/it]predicting train subjects:  49%|████▉     | 139/285 [05:13<04:56,  2.03s/it]predicting train subjects:  49%|████▉     | 140/285 [05:15<04:58,  2.06s/it]predicting train subjects:  49%|████▉     | 141/285 [05:17<04:56,  2.06s/it]predicting train subjects:  50%|████▉     | 142/285 [05:19<04:48,  2.02s/it]predicting train subjects:  50%|█████     | 143/285 [05:21<04:39,  1.97s/it]predicting train subjects:  51%|█████     | 144/285 [05:23<04:38,  1.98s/it]predicting train subjects:  51%|█████     | 145/285 [05:25<04:28,  1.92s/it]predicting train subjects:  51%|█████     | 146/285 [05:27<04:28,  1.93s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:29<04:23,  1.91s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:31<04:20,  1.90s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:33<04:19,  1.91s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:35<04:20,  1.93s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:36<04:14,  1.90s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:38<04:11,  1.89s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:40<04:05,  1.86s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:42<04:00,  1.83s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:44<04:00,  1.85s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:46<03:58,  1.85s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:47<03:53,  1.82s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:49<03:46,  1.78s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:51<03:45,  1.79s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:53<03:45,  1.80s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:54<03:43,  1.81s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:57<03:52,  1.89s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:59<03:55,  1.93s/it]predicting train subjects:  58%|█████▊    | 164/285 [06:01<03:57,  1.96s/it]predicting train subjects:  58%|█████▊    | 165/285 [06:02<03:49,  1.91s/it]predicting train subjects:  58%|█████▊    | 166/285 [06:04<03:46,  1.90s/it]predicting train subjects:  59%|█████▊    | 167/285 [06:06<03:45,  1.91s/it]predicting train subjects:  59%|█████▉    | 168/285 [06:08<03:48,  1.95s/it]predicting train subjects:  59%|█████▉    | 169/285 [06:10<03:47,  1.96s/it]predicting train subjects:  60%|█████▉    | 170/285 [06:12<03:41,  1.92s/it]predicting train subjects:  60%|██████    | 171/285 [06:14<03:36,  1.90s/it]predicting train subjects:  60%|██████    | 172/285 [06:16<03:31,  1.87s/it]predicting train subjects:  61%|██████    | 173/285 [06:18<03:29,  1.87s/it]predicting train subjects:  61%|██████    | 174/285 [06:19<03:27,  1.87s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:21<03:19,  1.82s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:23<03:17,  1.81s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:25<03:25,  1.90s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:27<03:20,  1.88s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:29<03:13,  1.83s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:30<03:06,  1.78s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:32<03:05,  1.79s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:34<03:04,  1.79s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:36<02:59,  1.76s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:37<03:01,  1.80s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:39<02:57,  1.78s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:41<02:53,  1.76s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:43<02:54,  1.78s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:45<02:52,  1.78s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:46<02:55,  1.83s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:49<03:11,  2.02s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:51<03:06,  1.98s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:53<02:59,  1.93s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:55<03:14,  2.11s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:57<03:03,  2.02s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:59<02:58,  1.98s/it]predicting train subjects:  69%|██████▉   | 196/285 [07:01<02:57,  1.99s/it]predicting train subjects:  69%|██████▉   | 197/285 [07:03<02:57,  2.02s/it]predicting train subjects:  69%|██████▉   | 198/285 [07:05<02:58,  2.06s/it]predicting train subjects:  70%|██████▉   | 199/285 [07:07<02:54,  2.03s/it]predicting train subjects:  70%|███████   | 200/285 [07:09<02:54,  2.06s/it]predicting train subjects:  71%|███████   | 201/285 [07:11<02:55,  2.09s/it]predicting train subjects:  71%|███████   | 202/285 [07:13<02:53,  2.09s/it]predicting train subjects:  71%|███████   | 203/285 [07:15<02:49,  2.07s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:18<02:46,  2.06s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:20<02:44,  2.05s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:22<02:41,  2.04s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:24<02:42,  2.08s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:26<02:42,  2.11s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:28<02:40,  2.11s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:30<02:37,  2.10s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:32<02:32,  2.05s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:34<02:27,  2.03s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:36<02:25,  2.02s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:38<02:18,  1.95s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:39<02:10,  1.87s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:41<02:07,  1.85s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:43<02:06,  1.86s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:45<02:10,  1.95s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:47<02:05,  1.90s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:49<01:59,  1.83s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:51<01:57,  1.84s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:52<01:56,  1.84s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:54<01:54,  1.84s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:56<01:53,  1.87s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:58<01:51,  1.86s/it]predicting train subjects:  79%|███████▉  | 226/285 [08:00<01:50,  1.87s/it]predicting train subjects:  80%|███████▉  | 227/285 [08:02<01:49,  1.88s/it]predicting train subjects:  80%|████████  | 228/285 [08:04<01:47,  1.88s/it]predicting train subjects:  80%|████████  | 229/285 [08:06<01:43,  1.86s/it]predicting train subjects:  81%|████████  | 230/285 [08:07<01:41,  1.85s/it]predicting train subjects:  81%|████████  | 231/285 [08:09<01:40,  1.86s/it]predicting train subjects:  81%|████████▏ | 232/285 [08:12<01:44,  1.98s/it]predicting train subjects:  82%|████████▏ | 233/285 [08:14<01:48,  2.08s/it]predicting train subjects:  82%|████████▏ | 234/285 [08:16<01:46,  2.09s/it]predicting train subjects:  82%|████████▏ | 235/285 [08:18<01:45,  2.11s/it]predicting train subjects:  83%|████████▎ | 236/285 [08:20<01:45,  2.16s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:23<01:42,  2.15s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:25<01:43,  2.19s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:27<01:40,  2.19s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:29<01:40,  2.24s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:32<01:37,  2.22s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:34<01:36,  2.25s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:36<01:34,  2.26s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:38<01:31,  2.24s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:41<01:31,  2.29s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:43<01:28,  2.28s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:45<01:28,  2.34s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:48<01:31,  2.46s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:51<01:28,  2.45s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:52<01:18,  2.25s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:55<01:14,  2.20s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:57<01:12,  2.19s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:59<01:12,  2.27s/it]predicting train subjects:  89%|████████▉ | 254/285 [09:01<01:07,  2.19s/it]predicting train subjects:  89%|████████▉ | 255/285 [09:03<01:04,  2.13s/it]predicting train subjects:  90%|████████▉ | 256/285 [09:05<00:59,  2.05s/it]predicting train subjects:  90%|█████████ | 257/285 [09:07<00:58,  2.07s/it]predicting train subjects:  91%|█████████ | 258/285 [09:09<00:56,  2.10s/it]predicting train subjects:  91%|█████████ | 259/285 [09:11<00:54,  2.08s/it]predicting train subjects:  91%|█████████ | 260/285 [09:13<00:50,  2.02s/it]predicting train subjects:  92%|█████████▏| 261/285 [09:16<00:52,  2.19s/it]predicting train subjects:  92%|█████████▏| 262/285 [09:18<00:48,  2.13s/it]predicting train subjects:  92%|█████████▏| 263/285 [09:20<00:46,  2.11s/it]predicting train subjects:  93%|█████████▎| 264/285 [09:22<00:44,  2.11s/it]predicting train subjects:  93%|█████████▎| 265/285 [09:24<00:42,  2.10s/it]predicting train subjects:  93%|█████████▎| 266/285 [09:26<00:40,  2.15s/it]predicting train subjects:  94%|█████████▎| 267/285 [09:28<00:38,  2.16s/it]predicting train subjects:  94%|█████████▍| 268/285 [09:31<00:39,  2.31s/it]predicting train subjects:  94%|█████████▍| 269/285 [09:34<00:37,  2.36s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:36<00:36,  2.46s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:39<00:35,  2.53s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:42<00:36,  2.77s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:45<00:32,  2.70s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:47<00:29,  2.67s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:50<00:27,  2.75s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:53<00:24,  2.71s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:56<00:21,  2.67s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:58<00:18,  2.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [10:01<00:15,  2.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [10:04<00:14,  2.81s/it]predicting train subjects:  99%|█████████▊| 281/285 [10:07<00:11,  2.78s/it]predicting train subjects:  99%|█████████▉| 282/285 [10:10<00:08,  2.84s/it]predicting train subjects:  99%|█████████▉| 283/285 [10:12<00:05,  2.82s/it]predicting train subjects: 100%|█████████▉| 284/285 [10:15<00:02,  2.78s/it]predicting train subjects: 100%|██████████| 285/285 [10:18<00:00,  2.72s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:03<14:30,  3.07s/it]Loading train:   1%|          | 2/285 [00:06<14:17,  3.03s/it]Loading train:   1%|          | 3/285 [00:08<13:10,  2.80s/it]Loading train:   1%|▏         | 4/285 [00:11<13:13,  2.83s/it]Loading train:   2%|▏         | 5/285 [00:13<12:38,  2.71s/it]Loading train:   2%|▏         | 6/285 [00:16<12:14,  2.63s/it]Loading train:   2%|▏         | 7/285 [00:18<12:27,  2.69s/it]Loading train:   3%|▎         | 8/285 [00:21<12:18,  2.67s/it]Loading train:   3%|▎         | 9/285 [00:24<12:08,  2.64s/it]Loading train:   4%|▎         | 10/285 [00:26<12:05,  2.64s/it]Loading train:   4%|▍         | 11/285 [00:29<12:34,  2.76s/it]Loading train:   4%|▍         | 12/285 [00:32<12:37,  2.78s/it]Loading train:   5%|▍         | 13/285 [00:34<11:39,  2.57s/it]Loading train:   5%|▍         | 14/285 [00:37<11:41,  2.59s/it]Loading train:   5%|▌         | 15/285 [00:40<12:21,  2.75s/it]Loading train:   6%|▌         | 16/285 [00:42<11:52,  2.65s/it]Loading train:   6%|▌         | 17/285 [00:45<11:38,  2.61s/it]Loading train:   6%|▋         | 18/285 [00:48<12:01,  2.70s/it]Loading train:   7%|▋         | 19/285 [00:50<11:43,  2.65s/it]Loading train:   7%|▋         | 20/285 [00:53<11:55,  2.70s/it]Loading train:   7%|▋         | 21/285 [00:56<11:42,  2.66s/it]Loading train:   8%|▊         | 22/285 [00:59<12:04,  2.76s/it]Loading train:   8%|▊         | 23/285 [01:01<12:00,  2.75s/it]Loading train:   8%|▊         | 24/285 [01:04<11:36,  2.67s/it]Loading train:   9%|▉         | 25/285 [01:06<10:59,  2.53s/it]Loading train:   9%|▉         | 26/285 [01:08<10:33,  2.45s/it]Loading train:   9%|▉         | 27/285 [01:11<11:01,  2.56s/it]Loading train:  10%|▉         | 28/285 [01:14<11:05,  2.59s/it]Loading train:  10%|█         | 29/285 [01:16<10:56,  2.56s/it]Loading train:  11%|█         | 30/285 [01:19<11:21,  2.67s/it]Loading train:  11%|█         | 31/285 [01:22<10:59,  2.60s/it]Loading train:  11%|█         | 32/285 [01:24<10:54,  2.59s/it]Loading train:  12%|█▏        | 33/285 [01:27<11:25,  2.72s/it]Loading train:  12%|█▏        | 34/285 [01:29<10:41,  2.56s/it]Loading train:  12%|█▏        | 35/285 [01:32<11:00,  2.64s/it]Loading train:  13%|█▎        | 36/285 [01:34<09:59,  2.41s/it]Loading train:  13%|█▎        | 37/285 [01:37<09:55,  2.40s/it]Loading train:  13%|█▎        | 38/285 [01:39<09:41,  2.35s/it]Loading train:  14%|█▎        | 39/285 [01:41<09:27,  2.31s/it]Loading train:  14%|█▍        | 40/285 [01:43<09:28,  2.32s/it]Loading train:  14%|█▍        | 41/285 [01:46<09:27,  2.32s/it]Loading train:  15%|█▍        | 42/285 [01:48<09:18,  2.30s/it]Loading train:  15%|█▌        | 43/285 [01:50<08:54,  2.21s/it]Loading train:  15%|█▌        | 44/285 [01:52<08:43,  2.17s/it]Loading train:  16%|█▌        | 45/285 [01:54<08:13,  2.06s/it]Loading train:  16%|█▌        | 46/285 [01:56<08:42,  2.19s/it]Loading train:  16%|█▋        | 47/285 [01:58<08:37,  2.17s/it]Loading train:  17%|█▋        | 48/285 [02:00<08:10,  2.07s/it]Loading train:  17%|█▋        | 49/285 [02:02<08:12,  2.09s/it]Loading train:  18%|█▊        | 50/285 [02:05<08:27,  2.16s/it]Loading train:  18%|█▊        | 51/285 [02:07<08:43,  2.24s/it]Loading train:  18%|█▊        | 52/285 [02:09<08:35,  2.21s/it]Loading train:  19%|█▊        | 53/285 [02:11<08:33,  2.21s/it]Loading train:  19%|█▉        | 54/285 [02:14<09:18,  2.42s/it]Loading train:  19%|█▉        | 55/285 [02:17<09:15,  2.41s/it]Loading train:  20%|█▉        | 56/285 [02:20<09:49,  2.57s/it]Loading train:  20%|██        | 57/285 [02:21<08:53,  2.34s/it]Loading train:  20%|██        | 58/285 [02:23<08:25,  2.23s/it]Loading train:  21%|██        | 59/285 [02:26<09:15,  2.46s/it]Loading train:  21%|██        | 60/285 [02:29<09:40,  2.58s/it]Loading train:  21%|██▏       | 61/285 [02:32<09:46,  2.62s/it]Loading train:  22%|██▏       | 62/285 [02:35<10:24,  2.80s/it]Loading train:  22%|██▏       | 63/285 [02:38<10:33,  2.86s/it]Loading train:  22%|██▏       | 64/285 [02:41<10:13,  2.78s/it]Loading train:  23%|██▎       | 65/285 [02:44<10:27,  2.85s/it]
Epoch 00057: val_mDice did not improve from 0.53033
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [1070.292962953365, 840.1757734074939, 780.0135184346631, 838.9613719066429, 844.7846311430691, 956.846839606429, 969.3173330296352, 933.8165433233677, 1002.4181596979748, 990.0457920521998, 1120.1619109254975, 1103.131230359637, 1182.835025041463, 1097.4394333482455, 1124.081044458144, 1129.4533166299318, 1142.1103972536225, 1315.5893159152408, 1190.5923669910965, 1187.048212999738, 1214.3125450091654, 1263.048005002837, 1239.0663762438896, 1208.9107168186977, 1266.1949606101607, 1234.9251743082227, 1108.1132798860858, 1297.14817835632, 1138.135601704347, 1412.043612517458, 1331.8718691351694, 1307.7425803072626, 1373.68783552287, 1198.4726385191166, 1387.212286411051, 1406.4757421056652, 1380.9834843640888, 1357.8616581922138, 1479.082853690206, 1399.9696174493715, 1400.3092197865747, 1357.759468291725, 1276.432604230316, 1382.1993749181652, 1293.0597285265362, 1365.8648142894554, 1334.8401035756372, 1362.6603669747294, 1521.7302668907123, 1416.2315066886347, 1321.0907146091567, 1433.7850512286138, 1458.1195586646736, 1421.3719093706354, 1536.9791000621944, 1434.8095764501136, 1414.6812757779767], 'val_acc': [0.9359938548929865, 0.9402726562329511, 0.9429853591839028, 0.9435638578910401, 0.9434626215663036, 0.9432291475088237, 0.9444006145333445, 0.9446195966704598, 0.9438468937101311, 0.9438468930441574, 0.9431940323813668, 0.9441919523244463, 0.9443076159701002, 0.9441795332471752, 0.9449976809197964, 0.9444150654963275, 0.9440783089099649, 0.9444956529739849, 0.9435514414776637, 0.9442291289734441, 0.9438902695751723, 0.9446175358148926, 0.9438923710551341, 0.9444522508029831, 0.944576226133208, 0.9447621536654467, 0.9440886208464979, 0.9444894371085992, 0.9439047202051685, 0.9434874101058065, 0.9442311651879849, 0.9448096608982406, 0.9444109387903906, 0.9441196329100838, 0.9450762012151367, 0.9446712472585327, 0.9444667200802425, 0.944127876998326, 0.9452084189686696, 0.9445514312669552, 0.9446526662597443, 0.9448220603292881, 0.945119608380941, 0.9439006238010342, 0.944508029761927, 0.9434026885965017, 0.9442539148490522, 0.944497690520473, 0.9444026590725563, 0.9450059656324333, 0.9437064195478428, 0.9441691876789711, 0.9443820142213193, 0.9450947981972934, 0.9438035121843136, 0.944415036859459, 0.9447249587021727], 'val_mDice': [0.36526332720697924, 0.4588213846004209, 0.49261052398708277, 0.49190781935633227, 0.5063636023239051, 0.5022735472497993, 0.5068117182015041, 0.5109322174301361, 0.5114472518420087, 0.5094125187596795, 0.4976851127667134, 0.5069620198044698, 0.4982295722268813, 0.515410295744848, 0.515717885347718, 0.5137739289739278, 0.5035499484179407, 0.5034104715512452, 0.5054963156164691, 0.5223261590776497, 0.5097385318585614, 0.5143925813989266, 0.5062026273271891, 0.5245427088031556, 0.5159538108543311, 0.5157101254223445, 0.5303272290269756, 0.5120467576900674, 0.529538927963992, 0.4944104104401679, 0.507854082231415, 0.516986792313986, 0.5136922479674803, 0.5249222412122695, 0.5145266284156778, 0.5090933149087362, 0.5128845277778263, 0.5090769682516599, 0.5058883481851503, 0.5118578808933663, 0.5158600187834415, 0.5229727898896074, 0.5217834697755356, 0.5099483555255655, 0.5207894009917808, 0.519746839001192, 0.521257086506103, 0.5123094263689478, 0.5038353997235857, 0.513568636591874, 0.5143555519301132, 0.5055958773503756, 0.5011153081275898, 0.518497029163318, 0.5027425330777407, 0.5101203995044005, 0.5124295933286571], 'loss': [1254.7722037295475, 724.842951463631, 632.8313026476008, 581.9922487329446, 549.7267448043428, 526.6783328875173, 506.7816522300234, 490.55989772866644, 476.310452844094, 464.44920539014527, 455.1384780141667, 448.507778218626, 437.9962561824315, 431.43439063674765, 425.55643700605435, 419.62208826137675, 416.27917130516346, 409.7451610466499, 405.5626289230969, 402.15383605641233, 396.6456454515808, 393.2083024656089, 390.56631551750553, 385.9058716134447, 385.4603651030236, 381.58303609290914, 379.58407235590954, 376.071017045353, 373.6414232529831, 371.7732564222773, 369.39123462523054, 367.37989649396854, 364.7248361717479, 362.6418825881582, 361.22814796638477, 359.6423093937989, 357.9955950092369, 355.78943639642745, 355.7188309170401, 352.43001198424514, 351.3368757480721, 348.7720002219617, 351.121936646638, 346.17855186747033, 344.778203929849, 344.9701097159206, 343.10161675550364, 341.0642447657824, 340.45358222349364, 340.6992230539741, 337.7597769122323, 337.51114052657783, 336.2698281020499, 335.64647470082303, 334.27654553441386, 332.80524372653264, 333.6247226957545], 'acc': [0.9045075694594428, 0.9198020778088767, 0.924749110997564, 0.9272374815913847, 0.9290133184853232, 0.9298207007957617, 0.9306869166822295, 0.9307884516964537, 0.9314944136442036, 0.9319806180516591, 0.9326288622160972, 0.9327259660805955, 0.9334183566405762, 0.9338201853738268, 0.9342885412595142, 0.9342573401513855, 0.934668013358855, 0.9351486917200655, 0.9352692025373018, 0.9353771197738084, 0.9360149296746327, 0.9363056753372667, 0.9362014424378209, 0.9363624741877744, 0.9364683797180143, 0.936968217841499, 0.9372753401602751, 0.9372677467635603, 0.937276305456215, 0.9377507432783152, 0.9379791320198066, 0.9384012627910668, 0.9386057793675318, 0.9387646600231548, 0.9384502276805002, 0.938641591549543, 0.9386972873489177, 0.9393206103474842, 0.9390083519074075, 0.9393737860302748, 0.9394464568922731, 0.9397503348108691, 0.9396638281659216, 0.9399805347109587, 0.9398919708568685, 0.9397170818791489, 0.9399893989776462, 0.9401907964499647, 0.9405338090493602, 0.9404561230640422, 0.9405260754789858, 0.9404012376846205, 0.9405043229812124, 0.9403123307102134, 0.9408013904271942, 0.9405815041822894, 0.9408251585040267], 'mDice': [0.2962737672777972, 0.4786526188307108, 0.5344626973880466, 0.5668737366012379, 0.5886430496756829, 0.604153738897173, 0.6182176724646802, 0.6303515454327046, 0.6396411669701638, 0.6481649636780799, 0.6546391651369532, 0.6593395576914127, 0.6670654570833672, 0.6724661383926982, 0.6767842250967278, 0.6809560179379269, 0.6832198732026905, 0.6884576309078511, 0.6910358520188069, 0.6939705125413347, 0.6980471155052773, 0.7004388374321653, 0.702822215695649, 0.7061080761474174, 0.7061559568302778, 0.7093145311427372, 0.7102651806784303, 0.7133854707207635, 0.7152780132657023, 0.7166172889581233, 0.7184778849684227, 0.7199101605308088, 0.7217681709928363, 0.7231444274929248, 0.7244672873273251, 0.7257080580386894, 0.7272393411167125, 0.7284468943358156, 0.7284656680784002, 0.7305200983707854, 0.732224481774275, 0.7337221823371799, 0.7320601040550478, 0.7354514221728, 0.7369774816751831, 0.7369398929429894, 0.7375803410951741, 0.7396137752951597, 0.7396909709486019, 0.7400876199664792, 0.7419096913565465, 0.7424808600572036, 0.7432525901192966, 0.7433007972594031, 0.7443353070567931, 0.7455344350728442, 0.7452757511125412]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 maxLoading train:  23%|██▎       | 66/285 [02:48<11:48,  3.24s/it]Loading train:  24%|██▎       | 67/285 [02:50<10:43,  2.95s/it]Loading train:  24%|██▍       | 68/285 [02:52<09:35,  2.65s/it]Loading train:  24%|██▍       | 69/285 [02:54<08:55,  2.48s/it]Loading train:  25%|██▍       | 70/285 [02:57<08:37,  2.41s/it]Loading train:  25%|██▍       | 71/285 [02:59<08:26,  2.37s/it]Loading train:  25%|██▌       | 72/285 [03:01<07:54,  2.23s/it]Loading train:  26%|██▌       | 73/285 [03:03<07:34,  2.15s/it]Loading train:  26%|██▌       | 74/285 [03:05<07:31,  2.14s/it]Loading train:  26%|██▋       | 75/285 [03:06<06:52,  1.97s/it]Loading train:  27%|██▋       | 76/285 [03:08<06:54,  1.98s/it]Loading train:  27%|██▋       | 77/285 [03:11<07:02,  2.03s/it]Loading train:  27%|██▋       | 78/285 [03:13<07:06,  2.06s/it]Loading train:  28%|██▊       | 79/285 [03:15<06:56,  2.02s/it]Loading train:  28%|██▊       | 80/285 [03:17<07:35,  2.22s/it]Loading train:  28%|██▊       | 81/285 [03:20<07:59,  2.35s/it]Loading train:  29%|██▉       | 82/285 [03:22<07:58,  2.36s/it]Loading train:  29%|██▉       | 83/285 [03:25<08:00,  2.38s/it]Loading train:  29%|██▉       | 84/285 [03:27<07:37,  2.27s/it]Loading train:  30%|██▉       | 85/285 [03:29<08:00,  2.40s/it]Loading train:  30%|███       | 86/285 [03:31<07:35,  2.29s/it]Loading train:  31%|███       | 87/285 [03:34<07:30,  2.27s/it]Loading train:  31%|███       | 88/285 [03:36<07:45,  2.37s/it]Loading train:  31%|███       | 89/285 [03:39<07:47,  2.39s/it]Loading train:  32%|███▏      | 90/285 [03:42<08:38,  2.66s/it]Loading train:  32%|███▏      | 91/285 [03:44<07:51,  2.43s/it]Loading train:  32%|███▏      | 92/285 [03:46<07:33,  2.35s/it]Loading train:  33%|███▎      | 93/285 [03:48<07:19,  2.29s/it]Loading train:  33%|███▎      | 94/285 [03:50<06:41,  2.10s/it]Loading train:  33%|███▎      | 95/285 [03:52<06:37,  2.09s/it]Loading train:  34%|███▎      | 96/285 [03:54<06:05,  1.93s/it]Loading train:  34%|███▍      | 97/285 [03:56<06:27,  2.06s/it]Loading train:  34%|███▍      | 98/285 [03:58<06:18,  2.02s/it]Loading train:  35%|███▍      | 99/285 [04:00<06:26,  2.08s/it]Loading train:  35%|███▌      | 100/285 [04:02<06:22,  2.07s/it]Loading train:  35%|███▌      | 101/285 [04:04<06:27,  2.11s/it]Loading train:  36%|███▌      | 102/285 [04:06<06:17,  2.07s/it]Loading train:  36%|███▌      | 103/285 [04:08<06:23,  2.11s/it]Loading train:  36%|███▋      | 104/285 [04:10<06:04,  2.01s/it]Loading train:  37%|███▋      | 105/285 [04:12<05:56,  1.98s/it]Loading train:  37%|███▋      | 106/285 [04:15<06:45,  2.26s/it]Loading train:  38%|███▊      | 107/285 [04:17<06:23,  2.15s/it]Loading train:  38%|███▊      | 108/285 [04:19<05:50,  1.98s/it]Loading train:  38%|███▊      | 109/285 [04:20<05:40,  1.94s/it]Loading train:  39%|███▊      | 110/285 [04:22<05:22,  1.84s/it]Loading train:  39%|███▉      | 111/285 [04:24<05:35,  1.93s/it]Loading train:  39%|███▉      | 112/285 [04:26<05:34,  1.93s/it]Loading train:  40%|███▉      | 113/285 [04:28<05:46,  2.02s/it]Loading train:  40%|████      | 114/285 [04:31<06:00,  2.11s/it]Loading train:  40%|████      | 115/285 [04:33<06:07,  2.16s/it]Loading train:  41%|████      | 116/285 [04:35<06:09,  2.19s/it]Loading train:  41%|████      | 117/285 [04:37<06:13,  2.22s/it]Loading train:  41%|████▏     | 118/285 [04:40<06:07,  2.20s/it]Loading train:  42%|████▏     | 119/285 [04:41<05:40,  2.05s/it]Loading train:  42%|████▏     | 120/285 [04:44<05:56,  2.16s/it]Loading train:  42%|████▏     | 121/285 [04:46<05:54,  2.16s/it]Loading train:  43%|████▎     | 122/285 [04:48<05:56,  2.19s/it]Loading train:  43%|████▎     | 123/285 [04:50<05:40,  2.10s/it]Loading train:  44%|████▎     | 124/285 [04:52<05:47,  2.16s/it]Loading train:  44%|████▍     | 125/285 [04:54<05:27,  2.05s/it]Loading train:  44%|████▍     | 126/285 [04:56<05:13,  1.97s/it]Loading train:  45%|████▍     | 127/285 [04:58<05:00,  1.90s/it]Loading train:  45%|████▍     | 128/285 [05:00<05:02,  1.93s/it]Loading train:  45%|████▌     | 129/285 [05:01<04:41,  1.81s/it]Loading train:  46%|████▌     | 130/285 [05:03<04:25,  1.72s/it]Loading train:  46%|████▌     | 131/285 [05:04<04:18,  1.68s/it]Loading train:  46%|████▋     | 132/285 [05:06<04:11,  1.64s/it]Loading train:  47%|████▋     | 133/285 [05:08<04:16,  1.69s/it]Loading train:  47%|████▋     | 134/285 [05:11<05:15,  2.09s/it]Loading train:  47%|████▋     | 135/285 [05:13<05:10,  2.07s/it]Loading train:  48%|████▊     | 136/285 [05:15<05:00,  2.02s/it]Loading train:  48%|████▊     | 137/285 [05:16<04:45,  1.93s/it]Loading train:  48%|████▊     | 138/285 [05:18<04:31,  1.84s/it]Loading train:  49%|████▉     | 139/285 [05:20<04:37,  1.90s/it]Loading train:  49%|████▉     | 140/285 [05:22<04:27,  1.85s/it]Loading train:  49%|████▉     | 141/285 [05:23<04:19,  1.80s/it]Loading train:  50%|████▉     | 142/285 [05:25<04:25,  1.86s/it]Loading train:  50%|█████     | 143/285 [05:27<04:14,  1.80s/it]Loading train:  51%|█████     | 144/285 [05:29<04:11,  1.78s/it]Loading train:  51%|█████     | 145/285 [05:31<04:28,  1.92s/it]Loading train:  51%|█████     | 146/285 [05:33<04:21,  1.88s/it]Loading train:  52%|█████▏    | 147/285 [05:34<04:03,  1.77s/it]Loading train:  52%|█████▏    | 148/285 [05:36<04:04,  1.78s/it]Loading train:  52%|█████▏    | 149/285 [05:38<04:04,  1.80s/it]Loading train:  53%|█████▎    | 150/285 [05:40<04:09,  1.85s/it]Loading train:  53%|█████▎    | 151/285 [05:42<03:58,  1.78s/it]Loading train:  53%|█████▎    | 152/285 [05:43<03:59,  1.80s/it]Loading train:  54%|█████▎    | 153/285 [05:45<04:06,  1.87s/it]Loading train:  54%|█████▍    | 154/285 [05:47<04:04,  1.86s/it]Loading train:  54%|█████▍    | 155/285 [05:49<03:57,  1.82s/it]Loading train:  55%|█████▍    | 156/285 [05:50<03:36,  1.68s/it]Loading train:  55%|█████▌    | 157/285 [05:52<03:47,  1.78s/it]Loading train:  55%|█████▌    | 158/285 [05:54<03:48,  1.80s/it]Loading train:  56%|█████▌    | 159/285 [05:56<03:46,  1.80s/it]Loading train:  56%|█████▌    | 160/285 [05:58<03:48,  1.83s/it]Loading train:  56%|█████▋    | 161/285 [06:00<03:53,  1.89s/it]Loading train:  57%|█████▋    | 162/285 [06:02<03:52,  1.89s/it]Loading train:  57%|█████▋    | 163/285 [06:04<03:44,  1.84s/it]Loading train:  58%|█████▊    | 164/285 [06:05<03:25,  1.69s/it]Loading train:  58%|█████▊    | 165/285 [06:07<03:24,  1.71s/it]Loading train:  58%|█████▊    | 166/285 [06:08<03:11,  1.61s/it]Loading train:  59%|█████▊    | 167/285 [06:09<03:04,  1.57s/it]Loading train:  59%|█████▉    | 168/285 [06:11<02:59,  1.53s/it]Loading train:  59%|█████▉    | 169/285 [06:13<03:04,  1.59s/it]Loading train:  60%|█████▉    | 170/285 [06:14<03:07,  1.63s/it]Loading train:  60%|██████    | 171/285 [06:16<02:56,  1.55s/it]Loading train:  60%|██████    | 172/285 [06:17<02:58,  1.58s/it]Loading train:  61%|██████    | 173/285 [06:19<02:53,  1.55s/it]Loading train:  61%|██████    | 174/285 [06:21<03:04,  1.66s/it]Loading train:  61%|██████▏   | 175/285 [06:22<02:52,  1.57s/it]Loading train:  62%|██████▏   | 176/285 [06:24<02:52,  1.58s/it]Loading train:  62%|██████▏   | 177/285 [06:26<02:58,  1.65s/it]Loading train:  62%|██████▏   | 178/285 [06:27<02:57,  1.66s/it]Loading train:  63%|██████▎   | 179/285 [06:29<02:54,  1.65s/it]Loading train:  63%|██████▎   | 180/285 [06:30<02:48,  1.60s/it]Loading train:  64%|██████▎   | 181/285 [06:32<02:51,  1.65s/it]Loading train:  64%|██████▍   | 182/285 [06:34<02:56,  1.71s/it]Loading train:  64%|██████▍   | 183/285 [06:36<02:50,  1.67s/it]Loading train:  65%|██████▍   | 184/285 [06:37<02:48,  1.67s/it]Loading train:  65%|██████▍   | 185/285 [06:39<02:47,  1.68s/it]Loading train:  65%|██████▌   | 186/285 [06:41<02:49,  1.71s/it]Loading train:  66%|██████▌   | 187/285 [06:42<02:46,  1.70s/it]Loading train:  66%|██████▌   | 188/285 [06:44<02:50,  1.76s/it]Loading train:  66%|██████▋   | 189/285 [06:46<02:44,  1.71s/it]Loading train:  67%|██████▋   | 190/285 [06:48<02:40,  1.69s/it]Loading train:  67%|██████▋   | 191/285 [06:49<02:39,  1.70s/it]Loading train:  67%|██████▋   | 192/285 [06:51<02:41,  1.74s/it]Loading train:  68%|██████▊   | 193/285 [06:52<02:21,  1.54s/it]Loading train:  68%|██████▊   | 194/285 [06:54<02:20,  1.54s/it]Loading train:  68%|██████▊   | 195/285 [06:55<02:22,  1.59s/it]Loading train:  69%|██████▉   | 196/285 [06:57<02:30,  1.69s/it]Loading train:  69%|██████▉   | 197/285 [06:58<02:12,  1.51s/it]Loading train:  69%|██████▉   | 198/285 [07:00<02:05,  1.44s/it]Loading train:  70%|██████▉   | 199/285 [07:01<01:57,  1.36s/it]Loading train:  70%|███████   | 200/285 [07:03<02:04,  1.47s/it]Loading train:  71%|███████   | 201/285 [07:04<02:01,  1.45s/it]Loading train:  71%|███████   | 202/285 [07:05<01:50,  1.34s/it]Loading train:  71%|███████   | 203/285 [07:06<01:40,  1.22s/it]Loading train:  72%|███████▏  | 204/285 [07:07<01:33,  1.15s/it]Loading train:  72%|███████▏  | 205/285 [07:08<01:35,  1.20s/it]Loading train:  72%|███████▏  | 206/285 [07:10<01:45,  1.34s/it]Loading train:  73%|███████▎  | 207/285 [07:12<01:49,  1.41s/it]Loading train:  73%|███████▎  | 208/285 [07:13<01:56,  1.52s/it]Loading train:  73%|███████▎  | 209/285 [07:14<01:42,  1.34s/it]Loading train:  74%|███████▎  | 210/285 [07:15<01:31,  1.21s/it]Loading train:  74%|███████▍  | 211/285 [07:16<01:25,  1.16s/it]Loading train:  74%|███████▍  | 212/285 [07:17<01:25,  1.17s/it]Loading train:  75%|███████▍  | 213/285 [07:19<01:35,  1.32s/it]Loading train:  75%|███████▌  | 214/285 [07:21<01:37,  1.37s/it]Loading train:  75%|███████▌  | 215/285 [07:22<01:31,  1.31s/it]Loading train:  76%|███████▌  | 216/285 [07:23<01:21,  1.17s/it]Loading train:  76%|███████▌  | 217/285 [07:24<01:17,  1.15s/it]Loading train:  76%|███████▋  | 218/285 [07:25<01:11,  1.07s/it]Loading train:  77%|███████▋  | 219/285 [07:26<01:11,  1.09s/it]Loading train:  77%|███████▋  | 220/285 [07:27<01:20,  1.24s/it]Loading train:  78%|███████▊  | 221/285 [07:28<01:15,  1.18s/it]Loading train:  78%|███████▊  | 222/285 [07:29<01:08,  1.09s/it]Loading train:  78%|███████▊  | 223/285 [07:30<01:05,  1.05s/it]Loading train:  79%|███████▊  | 224/285 [07:31<01:02,  1.02s/it]Loading train:  79%|███████▉  | 225/285 [07:32<01:03,  1.06s/it]Loading train:  79%|███████▉  | 226/285 [07:34<01:17,  1.31s/it]Loading train:  80%|███████▉  | 227/285 [07:35<01:11,  1.23s/it]Loading train:  80%|████████  | 228/285 [07:36<01:04,  1.13s/it]Loading train:  80%|████████  | 229/285 [07:37<01:05,  1.17s/it]Loading train:  81%|████████  | 230/285 [07:38<00:58,  1.06s/it]Loading train:  81%|████████  | 231/285 [07:39<00:56,  1.04s/it]Loading train:  81%|████████▏ | 232/285 [07:41<01:05,  1.24s/it]Loading train:  82%|████████▏ | 233/285 [07:42<01:04,  1.24s/it]Loading train:  82%|████████▏ | 234/285 [07:43<01:03,  1.25s/it]Loading train:  82%|████████▏ | 235/285 [07:45<01:03,  1.26s/it]Loading train:  83%|████████▎ | 236/285 [07:46<01:08,  1.39s/it]Loading train:  83%|████████▎ | 237/285 [07:48<01:15,  1.57s/it]Loading train:  84%|████████▎ | 238/285 [07:50<01:18,  1.66s/it]Loading train:  84%|████████▍ | 239/285 [07:52<01:14,  1.62s/it]Loading train:  84%|████████▍ | 240/285 [07:53<01:06,  1.48s/it]Loading train:  85%|████████▍ | 241/285 [07:54<01:00,  1.38s/it]Loading train:  85%|████████▍ | 242/285 [07:55<00:59,  1.39s/it]Loading train:  85%|████████▌ | 243/285 [07:57<01:02,  1.48s/it]Loading train:  86%|████████▌ | 244/285 [07:58<00:56,  1.37s/it]Loading train:  86%|████████▌ | 245/285 [07:59<00:52,  1.31s/it]Loading train:  86%|████████▋ | 246/285 [08:00<00:47,  1.22s/it]Loading train:  87%|████████▋ | 247/285 [08:02<00:49,  1.29s/it]Loading train:  87%|████████▋ | 248/285 [08:04<00:54,  1.48s/it]Loading train:  87%|████████▋ | 249/285 [08:05<00:50,  1.41s/it]Loading train:  88%|████████▊ | 250/285 [08:06<00:46,  1.32s/it]Loading train:  88%|████████▊ | 251/285 [08:07<00:41,  1.23s/it]Loading train:  88%|████████▊ | 252/285 [08:08<00:36,  1.10s/it]Loading train:  89%|████████▉ | 253/285 [08:10<00:39,  1.23s/it]Loading train:  89%|████████▉ | 254/285 [08:11<00:39,  1.27s/it]Loading train:  89%|████████▉ | 255/285 [08:12<00:34,  1.14s/it]Loading train:  90%|████████▉ | 256/285 [08:13<00:30,  1.07s/it]Loading train:  90%|█████████ | 257/285 [08:13<00:28,  1.02s/it]Loading train:  91%|█████████ | 258/285 [08:14<00:26,  1.02it/s]Loading train:  91%|█████████ | 259/285 [08:15<00:24,  1.04it/s]Loading train:  91%|█████████ | 260/285 [08:17<00:30,  1.21s/it]Loading train:  92%|█████████▏| 261/285 [08:18<00:28,  1.21s/it]Loading train:  92%|█████████▏| 262/285 [08:19<00:26,  1.15s/it]Loading train:  92%|█████████▏| 263/285 [08:20<00:23,  1.08s/it]Loading train:  93%|█████████▎| 264/285 [08:21<00:22,  1.07s/it]Loading train:  93%|█████████▎| 265/285 [08:22<00:20,  1.02s/it]Loading train:  93%|█████████▎| 266/285 [08:23<00:20,  1.06s/it]Loading train:  94%|█████████▎| 267/285 [08:25<00:21,  1.19s/it]Loading train:  94%|█████████▍| 268/285 [08:26<00:20,  1.23s/it]Loading train:  94%|█████████▍| 269/285 [08:27<00:19,  1.24s/it]Loading train:  95%|█████████▍| 270/285 [08:28<00:17,  1.17s/it]Loading train:  95%|█████████▌| 271/285 [08:30<00:16,  1.18s/it]Loading train:  95%|█████████▌| 272/285 [08:31<00:16,  1.26s/it]Loading train:  96%|█████████▌| 273/285 [08:33<00:15,  1.33s/it]Loading train:  96%|█████████▌| 274/285 [08:34<00:13,  1.26s/it]Loading train:  96%|█████████▋| 275/285 [08:35<00:11,  1.16s/it]Loading train:  97%|█████████▋| 276/285 [08:36<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [08:37<00:09,  1.14s/it]Loading train:  98%|█████████▊| 278/285 [08:38<00:08,  1.26s/it]Loading train:  98%|█████████▊| 279/285 [08:40<00:07,  1.27s/it]Loading train:  98%|█████████▊| 280/285 [08:41<00:05,  1.18s/it]Loading train:  99%|█████████▊| 281/285 [08:42<00:04,  1.17s/it]Loading train:  99%|█████████▉| 282/285 [08:43<00:03,  1.10s/it]Loading train:  99%|█████████▉| 283/285 [08:44<00:02,  1.15s/it]Loading train: 100%|█████████▉| 284/285 [08:46<00:01,  1.25s/it]Loading train: 100%|██████████| 285/285 [08:46<00:00,  1.16s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:00, 331.40it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:00, 250.55it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:01, 160.91it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:01, 170.61it/s]concatenating: train:  39%|███▊      | 110/285 [00:00<00:00, 193.23it/s]concatenating: train:  50%|█████     | 143/285 [00:00<00:00, 219.90it/s]concatenating: train:  60%|█████▉    | 170/285 [00:00<00:00, 232.49it/s]concatenating: train:  72%|███████▏  | 206/285 [00:00<00:00, 259.83it/s]concatenating: train:  83%|████████▎ | 237/285 [00:00<00:00, 272.05it/s]concatenating: train:  95%|█████████▍| 270/285 [00:01<00:00, 285.67it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 261.65it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 111.94it/s] 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 40)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   28880       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 80)   0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   12840       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 80)   0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   28840       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 40)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   3220        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               2019-06-30 19:37:06.334837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 19:37:06.334940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 19:37:06.334955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 19:37:06.334963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 19:37:06.335430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 20)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   273         dropout_5[0][0]                  
==================================================================================================
Total params: 184,113
Trainable params: 183,313
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [2.22914927e+01 1.09758073e+01 2.57605072e+01 3.20169489e+00
 9.30612289e+00 2.42668560e+00 2.90680004e+01 3.86865725e+01
 2.95464687e+01 4.55026025e+00 1.01029583e+02 6.65891339e+01
 8.79274619e-02]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 15s - loss: 2524.4260 - acc: 0.8824 - mDice: 0.1991 - val_loss: 1743.2867 - val_acc: 0.9219 - val_mDice: 0.3127

Epoch 00001: val_mDice improved from -inf to 0.31273, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 1361.6929 - acc: 0.9082 - mDice: 0.3937 - val_loss: 1604.5646 - val_acc: 0.9288 - val_mDice: 0.3956

Epoch 00002: val_mDice improved from 0.31273 to 0.39565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 8s - loss: 1163.7440 - acc: 0.9154 - mDice: 0.4626 - val_loss: 1550.2375 - val_acc: 0.9333 - val_mDice: 0.4185

Epoch 00003: val_mDice improved from 0.39565 to 0.41852, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 1063.7722 - acc: 0.9192 - mDice: 0.5001 - val_loss: 1561.7197 - val_acc: 0.9336 - val_mDice: 0.4352

Epoch 00004: val_mDice improved from 0.41852 to 0.43520, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 995.9261 - acc: 0.9221 - mDice: 0.5282 - val_loss: 1554.3954 - val_acc: 0.9372 - val_mDice: 0.4545

Epoch 00005: val_mDice improved from 0.43520 to 0.45448, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 949.3741 - acc: 0.9241 - mDice: 0.5484 - val_loss: 1613.7178 - val_acc: 0.9366 - val_mDice: 0.4531

Epoch 00006: val_mDice did not improve from 0.45448
Epoch 7/300
 - 10s - loss: 911.4377 - acc: 0.9260 - mDice: 0.5628 - val_loss: 1731.5833 - val_acc: 0.9354 - val_mDice: 0.4405

Epoch 00007: val_mDice did not improve from 0.45448
Epoch 8/300
 - 9s - loss: 881.2599 - acc: 0.9269 - mDice: 0.5767 - val_loss: 1657.4985 - val_acc: 0.9393 - val_mDice: 0.4597

Epoch 00008: val_mDice improved from 0.45448 to 0.45970, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 10s - loss: 853.0240 - acc: 0.9285 - mDice: 0.5901 - val_loss: 1623.4071 - val_acc: 0.9402 - val_mDice: 0.4750

Epoch 00009: val_mDice improved from 0.45970 to 0.47504, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 833.1740 - acc: 0.9293 - mDice: 0.5981 - val_loss: 1590.2333 - val_acc: 0.9411 - val_mDice: 0.4804

Epoch 00010: val_mDice improved from 0.47504 to 0.48040, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 9s - loss: 809.8299 - acc: 0.9303 - mDice: 0.6081 - val_loss: 1703.7223 - val_acc: 0.9381 - val_mDice: 0.4643

Epoch 00011: val_mDice did not improve from 0.48040
Epoch 12/300
 - 9s - loss: 796.7441 - acc: 0.9307 - mDice: 0.6144 - val_loss: 1681.4684 - val_acc: 0.9385 - val_mDice: 0.4760

Epoch 00012: val_mDice did not improve from 0.48040
Epoch 13/300
 - 8s - loss: 781.1278 - acc: 0.9317 - mDice: 0.6216 - val_loss: 1919.5126 - val_acc: 0.9394 - val_mDice: 0.4467

Epoch 00013: val_mDice did not improve from 0.48040
Epoch 14/300
 - 8s - loss: 769.8288 - acc: 0.9321 - mDice: 0.6268 - val_loss: 1829.5812 - val_acc: 0.9426 - val_mDice: 0.4680

Epoch 00014: val_mDice did not improve from 0.48040
Epoch 15/300
 - 8s - loss: 757.7303 - acc: 0.9328 - mDice: 0.6315 - val_loss: 1660.8435 - val_acc: 0.9397 - val_mDice: 0.4913

Epoch 00015: val_mDice improved from 0.48040 to 0.49134, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 9s - loss: 743.7618 - acc: 0.9335 - mDice: 0.6386 - val_loss: 1647.3002 - val_acc: 0.9402 - val_mDice: 0.4912

Epoch 00016: val_mDice did not improve from 0.49134
Epoch 17/300
 - 8s - loss: 729.7213 - acc: 0.9343 - mDice: 0.6442 - val_loss: 1783.1184 - val_acc: 0.9419 - val_mDice: 0.4848

Epoch 00017: val_mDice did not improve from 0.49134
Epoch 18/300
 - 8s - loss: 726.5658 - acc: 0.9346 - mDice: 0.6464 - val_loss: 1762.7526 - val_acc: 0.9429 - val_mDice: 0.4897

Epoch 00018: val_mDice did not improve from 0.49134
Epoch 19/300
 - 8s - loss: 715.1032 - acc: 0.9349 - mDice: 0.6516 - val_loss: 1777.0302 - val_acc: 0.9433 - val_mDice: 0.4783

Epoch 00019: val_mDice did not improve from 0.49134
Epoch 20/300
 - 9s - loss: 706.9872 - acc: 0.9353 - mDice: 0.6553 - val_loss: 1782.9936 - val_acc: 0.9421 - val_mDice: 0.4855

Epoch 00020: val_mDice did not improve from 0.49134
Epoch 21/300
 - 10s - loss: 699.1560 - acc: 0.9359 - mDice: 0.6586 - val_loss: 1751.4139 - val_acc: 0.9409 - val_mDice: 0.4872

Epoch 00021: val_mDice did not improve from 0.49134
Epoch 22/300
 - 8s - loss: 694.4582 - acc: 0.9361 - mDice: 0.6615 - val_loss: 1725.6150 - val_acc: 0.9409 - val_mDice: 0.4867

Epoch 00022: val_mDice did not improve from 0.49134
Epoch 23/300
 - 9s - loss: 686.3497 - acc: 0.9364 - mDice: 0.6651 - val_loss: 1796.8244 - val_acc: 0.9424 - val_mDice: 0.4961

Epoch 00023: val_mDice improved from 0.49134 to 0.49613, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 10s - loss: 681.7257 - acc: 0.9371 - mDice: 0.6673 - val_loss: 1868.1313 - val_acc: 0.9430 - val_mDice: 0.4800

Epoch 00024: val_mDice did not improve from 0.49613
Epoch 25/300
 - 9s - loss: 673.2137 - acc: 0.9372 - mDice: 0.6710 - val_loss: 1803.4764 - val_acc: 0.9446 - val_mDice: 0.4902

Epoch 00025: val_mDice did not improve from 0.49613
Epoch 26/300
 - 9s - loss: 668.4227 - acc: 0.9375 - mDice: 0.6732 - val_loss: 1732.6557 - val_acc: 0.9423 - val_mDice: 0.4961

Epoch 00026: val_mDice did not improve from 0.49613
Epoch 27/300
 - 9s - loss: 663.7172 - acc: 0.9379 - mDice: 0.6753 - val_loss: 1890.1636 - val_acc: 0.9422 - val_mDice: 0.4814

Epoch 00027: val_mDice did not improve from 0.49613
Epoch 28/300
 - 9s - loss: 659.0926 - acc: 0.9381 - mDice: 0.6776 - val_loss: 1860.5587 - val_acc: 0.9419 - val_mDice: 0.4894

Epoch 00028: val_mDice did not improve from 0.49613
Epoch 29/300
 - 9s - loss: 654.1438 - acc: 0.9383 - mDice: 0.6797 - val_loss: 1814.0908 - val_acc: 0.9425 - val_mDice: 0.5068

Epoch 00029: val_mDice improved from 0.49613 to 0.50683, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 9s - loss: 647.7017 - acc: 0.9384 - mDice: 0.6833 - val_loss: 1829.1357 - val_acc: 0.9407 - val_mDice: 0.4977

Epoch 00030: val_mDice did not improve from 0.50683
Epoch 31/300
 - 8s - loss: 648.1497 - acc: 0.9384 - mDice: 0.6832 - val_loss: 1833.8136 - val_acc: 0.9412 - val_mDice: 0.4909

Epoch 00031: val_mDice did not improve from 0.50683
Epoch 32/300
 - 9s - loss: 642.4902 - acc: 0.9386 - mDice: 0.6855 - val_loss: 1838.5410 - val_acc: 0.9419 - val_mDice: 0.4868

Epoch 00032: val_mDice did not improve from 0.50683
Epoch 33/300
 - 9s - loss: 639.1736 - acc: 0.9391 - mDice: 0.6866 - val_loss: 1922.8489 - val_acc: 0.9417 - val_mDice: 0.4911

Epoch 00033: val_mDice did not improve from 0.50683
Epoch 34/300
 - 9s - loss: 632.1995 - acc: 0.9391 - mDice: 0.6899 - val_loss: 1873.3039 - val_acc: 0.9441 - val_mDice: 0.4949

Epoch 00034: val_mDice did not improve from 0.50683
Epoch 35/300
 - 9s - loss: 628.8546 - acc: 0.9396 - mDice: 0.6916 - val_loss: 1940.1351 - val_acc: 0.9437 - val_mDice: 0.4900

Epoch 00035: val_mDice did not improve from 0.50683
Epoch 36/300
 - 9s - loss: 627.7889 - acc: 0.9396 - mDice: 0.6929 - val_loss: 1986.1866 - val_acc: 0.9418 - val_mDice: 0.4832

Epoch 00036: val_mDice did not improve from 0.50683
Epoch 37/300
 - 9s - loss: 623.4537 - acc: 0.9399 - mDice: 0.6943 - val_loss: 1990.5643 - val_acc: 0.9435 - val_mDice: 0.4827

Epoch 00037: val_mDice did not improve from 0.50683
Epoch 38/300
 - 9s - loss: 617.4608 - acc: 0.9403 - mDice: 0.6968 - val_loss: 1882.5752 - val_acc: 0.9422 - val_mDice: 0.4941

Epoch 00038: val_mDice did not improve from 0.50683
Epoch 39/300
 - 9s - loss: 615.5448 - acc: 0.9402 - mDice: 0.6985 - val_loss: 1831.8458 - val_acc: 0.9435 - val_mDice: 0.5037

Epoch 00039: val_mDice did not improve from 0.50683
Epoch 40/300
 - 9s - loss: 612.9503 - acc: 0.9405 - mDice: 0.6996 - val_loss: 1919.5219 - val_acc: 0.9433 - val_mDice: 0.4958

Epoch 00040: val_mDice did not improve from 0.50683
Epoch 41/300
 - 9s - loss: 608.4517 - acc: 0.9407 - mDice: 0.7012 - val_loss: 1972.9479 - val_acc: 0.9418 - val_mDice: 0.4856

Epoch 00041: val_mDice did not improve from 0.50683
Epoch 42/300
 - 10s - loss: 606.5833 - acc: 0.9406 - mDice: 0.7023 - val_loss: 1956.5280 - val_acc: 0.9430 - val_mDice: 0.4938

Epoch 00042: val_mDice did not improve from 0.50683
Epoch 43/300
 - 9s - loss: 605.4889 - acc: 0.9410 - mDice: 0.7030 - val_loss: 2147.8122 - val_acc: 0.9434 - val_mDice: 0.4773

Epoch 00043: val_mDice did not improve from 0.50683
Epoch 44/300
 - 9s - loss: 600.2159 - acc: 0.9411 - mDice: 0.7056 - val_loss: 1925.5271 - val_acc: 0.9427 - val_mDice: 0.4957

Epoch 00044: val_mDice did not improve from 0.50683
Epoch 45/300
 - 9s - loss: 600.4160 - acc: 0.9413 - mDice: 0.7052 - val_loss: 2040.5903 - val_acc: 0.9428 - val_mDice: 0.4881

Epoch 00045: val_mDice did not improve from 0.50683
Epoch 46/300
 - 9s - loss: 599.9760 - acc: 0.9413 - mDice: 0.7054 - val_loss: 2160.1852 - val_acc: 0.9414 - val_mDice: 0.4806

Epoch 00046: val_mDice did not improve from 0.50683
Epoch 47/300
 - 9s - loss: 596.3295 - acc: 0.9413 - mDice: 0.7075 - val_loss: 1908.1001 - val_acc: 0.9423 - val_mDice: 0.4989

Epoch 00047: val_mDice did not improve from 0.50683
Epoch 48/300
 - 9s - loss: 594.5441 - acc: 0.9413 - mDice: 0.7080 - val_loss: 2096.3411 - val_acc: 0.9425 - val_mDice: 0.4809

Epoch 00048: val_mDice did not improve from 0.50683
Epoch 49/300
 - 9s - loss: 593.7211 - acc: 0.9417 - mDice: 0.7078 - val_loss: 2145.7395 - val_acc: 0.9428 - val_mDice: 0.4821

Epoch 00049: val_mDice did not improve from 0.50683
Epoch 50/300
 - 9s - loss: 590.6604 - acc: 0.9421 - mDice: 0.7097 - val_loss: 2051.8400 - val_acc: 0.9420 - val_mDice: 0.4873

Epoch 00050: val_mDice did not improve from 0.50683
Epoch 51/300
 - 9s - loss: 585.9708 - acc: 0.9422 - mDice: 0.7121 - val_loss: 2078.3350 - val_acc: 0.9423 - val_mDice: 0.4854

Epoch 00051: val_mDice did not improve from 0.50683
Epoch 52/300
 - 9s - loss: 586.7333 - acc: 0.9421 - mDice: 0.7119 - val_loss: 2025.2470 - val_acc: 0.9428 - val_mDice: 0.4875

Epoch 00052: val_mDice did not improve from 0.50683
Epoch 53/300
 - 9s - loss: 580.5041 - acc: 0.9426 - mDice: 0.7145 - val_loss: 2122.3600 - val_acc: 0.9437 - val_mDice: 0.4873

Epoch 00053: val_mDice did not improve from 0.50683
Epoch 54/300
 - 9s - loss: 580.4992 - acc: 0.9426 - mDice: 0.7149 - val_loss: 2097.0642 - val_acc: 0.9427 - val_mDice: 0.4877

Epoch 00054: val_mDice did not improve from 0.50683
Epoch 55/300
 - 9s - loss: 576.4692 - acc: 0.9428 - mDice: 0.7162 - val_loss: 2078.8771 - val_acc: 0.9418 - val_mDice: 0.4927

Epoch 00055: val_mDice did not improve from 0.50683
Epoch 56/300
 - 9s - loss: 576.1739 - acc: 0.9429 - mDice: 0.7167 - val_loss: 2120.3453 - val_acc: 0.9431 - val_mDice: 0.4851

Epoch 00056: val_mDice did not improve from 0.50683
Epoch 57/300
 - 9s - loss: 574.3991 - acc: 0.9429 - mDice: 0.7173 - val_loss: 2110.1875 - val_acc: 0.9423 - val_mDice: 0.4857

Epoch 00057: val_mDice did not improve from 0.50683
Epoch 58/300
 - 9s - loss: 571.9730 - acc: 0.9431 - mDice: 0.7185 - val_loss: 1945.2663 - val_acc: 0.9417 - val_mDice: 0.4956

Epoch 00058: val_mDice did not improve from 0.50683
Epoch 59/300
 - 9s - loss: 572.2901 - acc: 0.9431 - mDice: 0.7188 - val_loss: 2079.2953 - val_acc: 0.9430 - val_mDice: 0.4889

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.57s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.35s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.11s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:01,  1.70s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:28,  1.80s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:21,  1.78s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:51,  1.89s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:36,  1.85s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<09:00,  1.94s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:31,  2.06s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:29,  2.05s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:22,  2.04s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<09:36,  2.10s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<09:41,  2.12s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:38,  2.12s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<09:55,  2.19s/it]predicting train subjects:   5%|▍         | 14/285 [00:29<09:57,  2.21s/it]predicting train subjects:   5%|▌         | 15/285 [00:31<10:01,  2.23s/it]predicting train subjects:   6%|▌         | 16/285 [00:33<09:55,  2.21s/it]predicting train subjects:   6%|▌         | 17/285 [00:35<09:54,  2.22s/it]predicting train subjects:   6%|▋         | 18/285 [00:37<09:46,  2.20s/it]predicting train subjects:   7%|▋         | 19/285 [00:40<09:47,  2.21s/it]predicting train subjects:   7%|▋         | 20/285 [00:42<09:56,  2.25s/it]predicting train subjects:   7%|▋         | 21/285 [00:44<09:43,  2.21s/it]predicting train subjects:   8%|▊         | 22/285 [00:46<09:56,  2.27s/it]predicting train subjects:   8%|▊         | 23/285 [00:49<09:52,  2.26s/it]predicting train subjects:   8%|▊         | 24/285 [00:51<09:41,  2.23s/it]predicting train subjects:   9%|▉         | 25/285 [00:53<09:36,  2.22s/it]predicting train subjects:   9%|▉         | 26/285 [00:55<09:31,  2.21s/it]predicting train subjects:   9%|▉         | 27/285 [00:57<09:34,  2.23s/it]predicting train subjects:  10%|▉         | 28/285 [01:00<09:35,  2.24s/it]predicting train subjects:  10%|█         | 29/285 [01:02<09:22,  2.20s/it]predicting train subjects:  11%|█         | 30/285 [01:04<09:01,  2.12s/it]predicting train subjects:  11%|█         | 31/285 [01:06<08:50,  2.09s/it]predicting train subjects:  11%|█         | 32/285 [01:08<08:38,  2.05s/it]predicting train subjects:  12%|█▏        | 33/285 [01:10<08:55,  2.12s/it]predicting train subjects:  12%|█▏        | 34/285 [01:12<09:03,  2.16s/it]predicting train subjects:  12%|█▏        | 35/285 [01:14<08:48,  2.11s/it]predicting train subjects:  13%|█▎        | 36/285 [01:17<09:02,  2.18s/it]predicting train subjects:  13%|█▎        | 37/285 [01:19<08:55,  2.16s/it]predicting train subjects:  13%|█▎        | 38/285 [01:21<09:13,  2.24s/it]predicting train subjects:  14%|█▎        | 39/285 [01:24<09:20,  2.28s/it]predicting train subjects:  14%|█▍        | 40/285 [01:26<09:00,  2.21s/it]predicting train subjects:  14%|█▍        | 41/285 [01:28<08:55,  2.20s/it]predicting train subjects:  15%|█▍        | 42/285 [01:30<08:52,  2.19s/it]predicting train subjects:  15%|█▌        | 43/285 [01:32<08:49,  2.19s/it]predicting train subjects:  15%|█▌        | 44/285 [01:34<08:50,  2.20s/it]predicting train subjects:  16%|█▌        | 45/285 [01:37<08:45,  2.19s/it]predicting train subjects:  16%|█▌        | 46/285 [01:39<08:29,  2.13s/it]predicting train subjects:  16%|█▋        | 47/285 [01:41<08:16,  2.08s/it]predicting train subjects:  17%|█▋        | 48/285 [01:42<07:52,  1.99s/it]predicting train subjects:  17%|█▋        | 49/285 [01:44<07:41,  1.96s/it]predicting train subjects:  18%|█▊        | 50/285 [01:46<07:49,  2.00s/it]predicting train subjects:  18%|█▊        | 51/285 [01:48<07:27,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:50<07:32,  1.94s/it]predicting train subjects:  19%|█▊        | 53/285 [01:52<07:27,  1.93s/it]predicting train subjects:  19%|█▉        | 54/285 [01:54<07:16,  1.89s/it]predicting train subjects:  19%|█▉        | 55/285 [01:56<07:26,  1.94s/it]predicting train subjects:  20%|█▉        | 56/285 [01:58<07:13,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:59<06:57,  1.83s/it]predicting train subjects:  20%|██        | 58/285 [02:01<06:56,  1.84s/it]predicting train subjects:  21%|██        | 59/285 [02:03<06:55,  1.84s/it]predicting train subjects:  21%|██        | 60/285 [02:05<07:04,  1.89s/it]predicting train subjects:  21%|██▏       | 61/285 [02:07<07:09,  1.92s/it]predicting train subjects:  22%|██▏       | 62/285 [02:09<07:19,  1.97s/it]predicting train subjects:  22%|██▏       | 63/285 [02:11<07:06,  1.92s/it]predicting train subjects:  22%|██▏       | 64/285 [02:13<06:57,  1.89s/it]predicting train subjects:  23%|██▎       | 65/285 [02:15<07:20,  2.00s/it]predicting train subjects:  23%|██▎       | 66/285 [02:17<07:17,  2.00s/it]predicting train subjects:  24%|██▎       | 67/285 [02:19<07:19,  2.02s/it]predicting train subjects:  24%|██▍       | 68/285 [02:21<07:08,  1.97s/it]predicting train subjects:  24%|██▍       | 69/285 [02:23<06:52,  1.91s/it]predicting train subjects:  25%|██▍       | 70/285 [02:24<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 71/285 [02:26<06:42,  1.88s/it]predicting train subjects:  25%|██▌       | 72/285 [02:28<06:34,  1.85s/it]predicting train subjects:  26%|██▌       | 73/285 [02:30<06:35,  1.87s/it]predicting train subjects:  26%|██▌       | 74/285 [02:32<06:27,  1.84s/it]predicting train subjects:  26%|██▋       | 75/285 [02:33<06:18,  1.80s/it]predicting train subjects:  27%|██▋       | 76/285 [02:35<06:15,  1.80s/it]predicting train subjects:  27%|██▋       | 77/285 [02:37<06:04,  1.75s/it]predicting train subjects:  27%|██▋       | 78/285 [02:39<05:57,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:40<06:03,  1.77s/it]predicting train subjects:  28%|██▊       | 80/285 [02:42<06:08,  1.80s/it]predicting train subjects:  28%|██▊       | 81/285 [02:44<06:21,  1.87s/it]predicting train subjects:  29%|██▉       | 82/285 [02:46<06:17,  1.86s/it]predicting train subjects:  29%|██▉       | 83/285 [02:48<06:18,  1.87s/it]predicting train subjects:  29%|██▉       | 84/285 [02:50<06:09,  1.84s/it]predicting train subjects:  30%|██▉       | 85/285 [02:52<06:19,  1.90s/it]predicting train subjects:  30%|███       | 86/285 [02:54<06:31,  1.97s/it]predicting train subjects:  31%|███       | 87/285 [02:56<06:40,  2.02s/it]predicting train subjects:  31%|███       | 88/285 [02:58<06:41,  2.04s/it]predicting train subjects:  31%|███       | 89/285 [03:00<06:45,  2.07s/it]predicting train subjects:  32%|███▏      | 90/285 [03:02<06:42,  2.06s/it]predicting train subjects:  32%|███▏      | 91/285 [03:04<06:36,  2.04s/it]predicting train subjects:  32%|███▏      | 92/285 [03:06<06:35,  2.05s/it]predicting train subjects:  33%|███▎      | 93/285 [03:09<06:38,  2.08s/it]predicting train subjects:  33%|███▎      | 94/285 [03:11<06:32,  2.06s/it]predicting train subjects:  33%|███▎      | 95/285 [03:13<06:30,  2.06s/it]predicting train subjects:  34%|███▎      | 96/285 [03:15<06:38,  2.11s/it]predicting train subjects:  34%|███▍      | 97/285 [03:17<06:30,  2.08s/it]predicting train subjects:  34%|███▍      | 98/285 [03:19<06:24,  2.06s/it]predicting train subjects:  35%|███▍      | 99/285 [03:21<06:27,  2.09s/it]predicting train subjects:  35%|███▌      | 100/285 [03:23<06:19,  2.05s/it]predicting train subjects:  35%|███▌      | 101/285 [03:25<06:17,  2.05s/it]predicting train subjects:  36%|███▌      | 102/285 [03:27<06:14,  2.04s/it]predicting train subjects:  36%|███▌      | 103/285 [03:29<06:12,  2.05s/it]predicting train subjects:  36%|███▋      | 104/285 [03:31<06:10,  2.04s/it]predicting train subjects:  37%|███▋      | 105/285 [03:33<06:02,  2.01s/it]predicting train subjects:  37%|███▋      | 106/285 [03:35<05:54,  1.98s/it]predicting train subjects:  38%|███▊      | 107/285 [03:37<05:48,  1.96s/it]predicting train subjects:  38%|███▊      | 108/285 [03:39<05:38,  1.91s/it]predicting train subjects:  38%|███▊      | 109/285 [03:41<05:35,  1.91s/it]predicting train subjects:  39%|███▊      | 110/285 [03:43<05:46,  1.98s/it]predicting train subjects:  39%|███▉      | 111/285 [03:45<05:53,  2.03s/it]predicting train subjects:  39%|███▉      | 112/285 [03:47<05:51,  2.03s/it]predicting train subjects:  40%|███▉      | 113/285 [03:49<05:41,  1.98s/it]predicting train subjects:  40%|████      | 114/285 [03:51<05:33,  1.95s/it]predicting train subjects:  40%|████      | 115/285 [03:53<05:27,  1.93s/it]predicting train subjects:  41%|████      | 116/285 [03:55<05:26,  1.93s/it]predicting train subjects:  41%|████      | 117/285 [03:56<05:22,  1.92s/it]predicting train subjects:  41%|████▏     | 118/285 [03:58<05:22,  1.93s/it]predicting train subjects:  42%|████▏     | 119/285 [04:00<05:12,  1.88s/it]predicting train subjects:  42%|████▏     | 120/285 [04:02<05:13,  1.90s/it]predicting train subjects:  42%|████▏     | 121/285 [04:04<05:12,  1.90s/it]predicting train subjects:  43%|████▎     | 122/285 [04:06<04:54,  1.81s/it]predicting train subjects:  43%|████▎     | 123/285 [04:07<04:39,  1.73s/it]predicting train subjects:  44%|████▎     | 124/285 [04:09<04:45,  1.77s/it]predicting train subjects:  44%|████▍     | 125/285 [04:11<04:44,  1.78s/it]predicting train subjects:  44%|████▍     | 126/285 [04:13<04:47,  1.81s/it]predicting train subjects:  45%|████▍     | 127/285 [04:14<04:43,  1.80s/it]predicting train subjects:  45%|████▍     | 128/285 [04:16<04:48,  1.84s/it]predicting train subjects:  45%|████▌     | 129/285 [04:18<04:48,  1.85s/it]predicting train subjects:  46%|████▌     | 130/285 [04:20<04:41,  1.82s/it]predicting train subjects:  46%|████▌     | 131/285 [04:22<04:39,  1.81s/it]predicting train subjects:  46%|████▋     | 132/285 [04:24<04:41,  1.84s/it]predicting train subjects:  47%|████▋     | 133/285 [04:26<04:40,  1.84s/it]predicting train subjects:  47%|████▋     | 134/285 [04:27<04:40,  1.86s/it]predicting train subjects:  47%|████▋     | 135/285 [04:29<04:36,  1.84s/it]predicting train subjects:  48%|████▊     | 136/285 [04:31<04:34,  1.85s/it]predicting train subjects:  48%|████▊     | 137/285 [04:33<04:32,  1.84s/it]predicting train subjects:  48%|████▊     | 138/285 [04:35<04:34,  1.87s/it]predicting train subjects:  49%|████▉     | 139/285 [04:37<04:48,  1.98s/it]predicting train subjects:  49%|████▉     | 140/285 [04:39<04:44,  1.96s/it]predicting train subjects:  49%|████▉     | 141/285 [04:41<04:38,  1.94s/it]predicting train subjects:  50%|████▉     | 142/285 [04:43<04:30,  1.89s/it]predicting train subjects:  50%|█████     | 143/285 [04:45<04:26,  1.88s/it]predicting train subjects:  51%|█████     | 144/285 [04:46<04:15,  1.81s/it]predicting train subjects:  51%|█████     | 145/285 [04:48<04:20,  1.86s/it]predicting train subjects:  51%|█████     | 146/285 [04:50<04:01,  1.74s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:51<03:58,  1.73s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:53<03:51,  1.69s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:55<03:45,  1.66s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:56<03:47,  1.68s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:58<03:38,  1.63s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:00<03:41,  1.66s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:01<03:38,  1.65s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:03<03:32,  1.62s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:04<03:35,  1.66s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:06<03:28,  1.61s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:08<03:30,  1.65s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:09<03:27,  1.64s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:11<03:28,  1.65s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:13<03:24,  1.64s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:14<03:21,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:16<03:19,  1.62s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:17<03:18,  1.63s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:19<03:11,  1.59s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:21<03:14,  1.62s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:22<03:06,  1.57s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:23<03:00,  1.53s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:25<02:59,  1.53s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:27<02:57,  1.53s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:28<02:56,  1.53s/it]predicting train subjects:  60%|██████    | 171/285 [05:30<02:54,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [05:31<02:49,  1.50s/it]predicting train subjects:  61%|██████    | 173/285 [05:33<02:54,  1.55s/it]predicting train subjects:  61%|██████    | 174/285 [05:34<02:57,  1.60s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:36<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:38<02:55,  1.61s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:39<02:54,  1.62s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:41<02:49,  1.59s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:42<02:45,  1.57s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:44<02:36,  1.49s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:45<02:28,  1.43s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:46<02:23,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:48<02:26,  1.43s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:49<02:22,  1.41s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:51<02:23,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:52<02:24,  1.46s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:54<02:23,  1.46s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:55<02:27,  1.52s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:57<02:24,  1.50s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:58<02:18,  1.46s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:59<02:15,  1.45s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:01<02:12,  1.42s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:02<02:08,  1.39s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:03<02:03,  1.36s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:05<02:01,  1.35s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:06<02:07,  1.44s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:08<02:10,  1.48s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:10<02:14,  1.55s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:12<02:20,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [06:13<02:18,  1.63s/it]predicting train subjects:  71%|███████   | 201/285 [06:15<02:18,  1.64s/it]predicting train subjects:  71%|███████   | 202/285 [06:17<02:16,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [06:18<02:14,  1.64s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:20<02:16,  1.69s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:21<02:11,  1.65s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:23<02:08,  1.63s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:25<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:26<02:04,  1.62s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:28<02:02,  1.61s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:30<02:02,  1.63s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:31<01:59,  1.62s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:33<01:58,  1.62s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:34<01:58,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:36<01:53,  1.60s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:37<01:48,  1.55s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:39<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:40<01:44,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:42<01:40,  1.50s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:43<01:38,  1.50s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:45<01:35,  1.47s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:46<01:32,  1.45s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:48<01:30,  1.43s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:49<01:30,  1.45s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:51<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:52<01:28,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:53<01:26,  1.47s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:55<01:26,  1.50s/it]predicting train subjects:  80%|████████  | 228/285 [06:57<01:26,  1.52s/it]predicting train subjects:  80%|████████  | 229/285 [06:58<01:23,  1.49s/it]predicting train subjects:  81%|████████  | 230/285 [07:00<01:22,  1.50s/it]predicting train subjects:  81%|████████  | 231/285 [07:01<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:03<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:05<01:25,  1.64s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:06<01:24,  1.65s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:08<01:24,  1.69s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:10<01:25,  1.74s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:12<01:25,  1.78s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:14<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:15<01:21,  1.78s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:17<01:19,  1.77s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:19<01:19,  1.81s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:21<01:17,  1.81s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:23<01:16,  1.81s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:24<01:13,  1.80s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:26<01:12,  1.82s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:28<01:11,  1.84s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:30<01:10,  1.87s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:32<01:10,  1.90s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:34<01:07,  1.88s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:35<01:00,  1.73s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:37<00:55,  1.63s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:38<00:50,  1.54s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:39<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:41<00:46,  1.50s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:42<00:43,  1.45s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:44<00:41,  1.42s/it]predicting train subjects:  90%|█████████ | 257/285 [07:45<00:38,  1.38s/it]predicting train subjects:  91%|█████████ | 258/285 [07:46<00:36,  1.36s/it]predicting train subjects:  91%|█████████ | 259/285 [07:48<00:36,  1.41s/it]predicting train subjects:  91%|█████████ | 260/285 [07:49<00:35,  1.43s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:51<00:35,  1.46s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:52<00:34,  1.49s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:54<00:32,  1.47s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:55<00:30,  1.45s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:57<00:29,  1.47s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:58<00:28,  1.49s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:00<00:27,  1.51s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:02<00:27,  1.64s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:04<00:27,  1.73s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:05<00:26,  1.76s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:07<00:24,  1.78s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:09<00:23,  1.78s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:11<00:21,  1.77s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:13<00:19,  1.81s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:15<00:18,  1.88s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:17<00:16,  1.86s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:18<00:14,  1.87s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:20<00:13,  1.86s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:22<00:11,  1.88s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:24<00:09,  1.86s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:26<00:07,  1.88s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:28<00:05,  1.90s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:30<00:03,  1.97s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:32<00:02,  2.00s/it]predicting train subjects: 100%|██████████| 285/285 [08:34<00:00,  1.98s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a’: File exists

Epoch 00059: val_mDice did not improve from 0.50683
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
{'val_loss': [1743.2866656963643, 1604.5645869328425, 1550.237539438101, 1561.7196549635667, 1554.3953904371995, 1613.717774611253, 1731.583253126878, 1657.4985275268555, 1623.4071080134465, 1590.2332728459285, 1703.7223182091345, 1681.4683732252854, 1919.5125556358923, 1829.5811767578125, 1660.843530508188, 1647.3002260648286, 1783.1184140718901, 1762.7525834303635, 1777.0302194448618, 1782.9936065673828, 1751.4139228233923, 1725.6149990375225, 1796.8243807279146, 1868.1312719491812, 1803.4763899583083, 1732.655745286208, 1890.163584782527, 1860.558743403508, 1814.0907757098857, 1829.1357081486628, 1833.8136162391077, 1838.5410009530874, 1922.8489098182092, 1873.3039022592397, 1940.1350743220403, 1986.1866255540115, 1990.5642641507661, 1882.5752135056716, 1831.8457735501802, 1919.5219151423528, 1972.9478659996619, 1956.5279705341045, 2147.8121866079478, 1925.5271271925706, 2040.5902563241812, 2160.1852287879356, 1908.1001088069036, 2096.341059758113, 2145.7395436213565, 2051.8400362454927, 2078.334971501277, 2025.246959392841, 2122.359975374662, 2097.064204289363, 2078.8770787165713, 2120.3453333928037, 2110.187541081355, 1945.2663280780498, 2079.2953373835635], 'val_acc': [0.9219004122110513, 0.9288438214705541, 0.9332978656658759, 0.9336168467998505, 0.9372249268568479, 0.9366378417381873, 0.9354359071988326, 0.9392520189285278, 0.9401719936957726, 0.941117314191965, 0.9380686030938075, 0.9385331731576186, 0.9393745546157544, 0.9426012612306155, 0.9396796616224142, 0.9401581218609443, 0.9419031808009515, 0.942897074497663, 0.943340892975147, 0.9420511034818796, 0.940932395366522, 0.9409046562818381, 0.9424255444453313, 0.9430103645874903, 0.944561284322005, 0.9423423707485199, 0.9422337046036353, 0.9418708452811608, 0.9425249512378986, 0.9407359338723696, 0.941175089432643, 0.9419262890632336, 0.9417483325187976, 0.9440666620547955, 0.9436691242914933, 0.941808452972999, 0.9434772363075843, 0.9421944274352148, 0.9434518424364237, 0.9432830993945782, 0.9418200139815991, 0.9430426978147947, 0.9434125262957352, 0.9427168094194852, 0.9427653298928187, 0.941410862482511, 0.9423354199299445, 0.9424625795621139, 0.9428115693422464, 0.9419517540014707, 0.9422915165240948, 0.9427560728329879, 0.9436945273325994, 0.9426682866536654, 0.9417644922549908, 0.9431259150688465, 0.9423123254225805, 0.9416582171733563, 0.9430219301810632], 'val_mDice': [0.31273473913852984, 0.3956470243059672, 0.4185223619525249, 0.4351956815673755, 0.4544809346015637, 0.4530589715219461, 0.4404951503070501, 0.45969768040455306, 0.4750404079946188, 0.48040060756298214, 0.46434145220197165, 0.4759640366985248, 0.4466763316438748, 0.46800750809220165, 0.4913383378432347, 0.491242664364668, 0.484800045306866, 0.4897179016127036, 0.4783145303909595, 0.48545190634635776, 0.48719239922670216, 0.486721060023858, 0.4961312304322536, 0.4799959115110911, 0.4901709539385942, 0.49605492187234074, 0.4813699911420162, 0.4894201649496189, 0.5068314579816965, 0.49773432543644536, 0.49092221603943753, 0.4867849000371419, 0.49109394962971026, 0.4948646964935156, 0.49002747667523533, 0.48324137926101685, 0.4827138480658715, 0.4941019370005681, 0.5037213687140208, 0.49583205351462734, 0.4855546375306753, 0.4937678690140064, 0.4773495879310828, 0.49572576926304746, 0.4881278809446555, 0.48058289604691357, 0.4989236934253803, 0.4808635147145161, 0.4820653587006606, 0.48732177769908536, 0.48544897998754793, 0.4874597177482568, 0.48734058181826884, 0.4877495960547374, 0.49266441710866415, 0.48507526173041415, 0.4857024189371329, 0.495610281251944, 0.4888537239569884], 'loss': [2524.426046251668, 1361.6928631230978, 1163.743993125718, 1063.7722317587347, 995.9261143033623, 949.374055770428, 911.4376635841257, 881.2599226738665, 853.0239634110591, 833.1740377767933, 809.8298569788058, 796.7440862714568, 781.1277896494462, 769.8287749796635, 757.7303063535915, 743.7617841532538, 729.7212532125781, 726.5657817809265, 715.1031571989579, 706.9872322114182, 699.1559973145658, 694.4582492455801, 686.3496692646564, 681.725677771684, 673.2136626693471, 668.4227270970515, 663.7171732701906, 659.0925704729488, 654.1438403813412, 647.7016617900648, 648.1496899618958, 642.4901683525571, 639.173624031836, 632.1995468498496, 628.8545671881844, 627.7889025296869, 623.4537485796928, 617.4607567193048, 615.5448427398212, 612.9503451703297, 608.4516818166098, 606.5833400946905, 605.4889301784494, 600.215869391678, 600.4160098651344, 599.9760273855396, 596.3295473898951, 594.5441056824716, 593.7211264279852, 590.6603619052092, 585.9708292707024, 586.7333247680721, 580.5040975850545, 580.4992013136356, 576.4692129507877, 576.1738565204482, 574.3990723658211, 571.9729946143159, 572.2901315763847], 'acc': [0.8823944811703127, 0.9081797941379922, 0.915375855728059, 0.9192429828344759, 0.9221489742586536, 0.9240851267824575, 0.9259532250942895, 0.9269217263670477, 0.9285322524442957, 0.9292857983527254, 0.9302602181748624, 0.9306762982402067, 0.9317241192006938, 0.9321090447598143, 0.9327767719633628, 0.9334566271427119, 0.9342741292032887, 0.9345790262175235, 0.9348716424046479, 0.9353392651619138, 0.9358602041832297, 0.936066559432321, 0.936433956943666, 0.9370825472302865, 0.9372306422181074, 0.9375062527817509, 0.9378697901406235, 0.9381448014695234, 0.9382577554101952, 0.9384298571073227, 0.93840278786926, 0.9385936453445123, 0.9391046770547112, 0.9391032806580042, 0.9396005450365432, 0.9396003675199155, 0.9399396505543175, 0.9402670712584468, 0.9402381178803476, 0.9404563349924613, 0.9406891817108991, 0.9405868917464506, 0.9409840603678646, 0.9411163226458503, 0.9412952528045614, 0.9412602899776639, 0.9413004824731069, 0.941310928182981, 0.9417401277622064, 0.9421387843668796, 0.9422209626588502, 0.9420898079784178, 0.9426121684135705, 0.9426248698923669, 0.942840425348981, 0.9429158930473747, 0.9429329827539179, 0.9431404951565778, 0.9431080805423085], 'mDice': [0.1991114175144865, 0.39366029489747295, 0.46264393881195576, 0.5000670873886829, 0.5281757641177242, 0.548448544366327, 0.5627984830641191, 0.5766655562340218, 0.5900862370317497, 0.5980943973726489, 0.6080811773566405, 0.6143613447620124, 0.6215639835484494, 0.6268213370525121, 0.6314946972531146, 0.6385911671721516, 0.6442432105678656, 0.6463715801223182, 0.6515813068711185, 0.6553289132684202, 0.6585737774427731, 0.6615473003852722, 0.665091026151443, 0.6672702201186956, 0.6709893077960987, 0.6732319379044142, 0.6753361590243041, 0.677622000922425, 0.6797194795602803, 0.6832547695129041, 0.6832021432400938, 0.68546828175453, 0.6865726819252117, 0.6898950761362579, 0.6915662070377434, 0.6928643355793501, 0.6943420812914999, 0.6967721843888792, 0.6985294160000306, 0.6996253050529109, 0.7011642632235529, 0.7023430767176304, 0.7030126193809211, 0.7056368545534689, 0.7051557782038677, 0.7054454747088927, 0.7074582083390382, 0.7079789121190769, 0.7078005595696673, 0.709703424083981, 0.7121494904464212, 0.7119134434923237, 0.7145014573955386, 0.714938335710925, 0.7162282337157762, 0.7167322612343091, 0.7172964527346843, 0.7185479669424482, 0.7187641713877154]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:04,  1.71s/it]Loading train:   1%|          | 2/285 [00:03<08:08,  1.73s/it]Loading train:   1%|          | 3/285 [00:05<07:55,  1.69s/it]Loading train:   1%|▏         | 4/285 [00:07<08:19,  1.78s/it]Loading train:   2%|▏         | 5/285 [00:08<07:53,  1.69s/it]Loading train:   2%|▏         | 6/285 [00:10<08:05,  1.74s/it]Loading train:   2%|▏         | 7/285 [00:12<08:08,  1.76s/it]Loading train:   3%|▎         | 8/285 [00:14<08:10,  1.77s/it]Loading train:   3%|▎         | 9/285 [00:15<07:57,  1.73s/it]Loading train:   4%|▎         | 10/285 [00:17<07:28,  1.63s/it]Loading train:   4%|▍         | 11/285 [00:18<07:25,  1.63s/it]Loading train:   4%|▍         | 12/285 [00:20<07:30,  1.65s/it]Loading train:   5%|▍         | 13/285 [00:21<07:10,  1.58s/it]Loading train:   5%|▍         | 14/285 [00:23<06:56,  1.54s/it]Loading train:   5%|▌         | 15/285 [00:24<06:26,  1.43s/it]Loading train:   6%|▌         | 16/285 [00:25<06:17,  1.40s/it]Loading train:   6%|▌         | 17/285 [00:26<05:56,  1.33s/it]Loading train:   6%|▋         | 18/285 [00:28<06:07,  1.38s/it]Loading train:   7%|▋         | 19/285 [00:29<05:47,  1.31s/it]Loading train:   7%|▋         | 20/285 [00:30<05:35,  1.27s/it]Loading train:   7%|▋         | 21/285 [00:31<05:26,  1.24s/it]Loading train:   8%|▊         | 22/285 [00:33<05:18,  1.21s/it]Loading train:   8%|▊         | 23/285 [00:34<05:25,  1.24s/it]Loading train:   8%|▊         | 24/285 [00:35<05:09,  1.18s/it]Loading train:   9%|▉         | 25/285 [00:37<06:02,  1.39s/it]Loading train:   9%|▉         | 26/285 [00:38<06:07,  1.42s/it]Loading train:   9%|▉         | 27/285 [00:39<05:50,  1.36s/it]Loading train:  10%|▉         | 28/285 [00:40<05:23,  1.26s/it]Loading train:  10%|█         | 29/285 [00:42<05:04,  1.19s/it]Loading train:  11%|█         | 30/285 [00:43<05:01,  1.18s/it]Loading train:  11%|█         | 31/285 [00:44<04:49,  1.14s/it]Loading train:  11%|█         | 32/285 [00:45<04:48,  1.14s/it]Loading train:  12%|█▏        | 33/285 [00:46<04:32,  1.08s/it]Loading train:  12%|█▏        | 34/285 [00:47<04:18,  1.03s/it]Loading train:  12%|█▏        | 35/285 [00:48<04:13,  1.01s/it]Loading train:  13%|█▎        | 36/285 [00:49<04:16,  1.03s/it]Loading train:  13%|█▎        | 37/285 [00:50<04:06,  1.01it/s]Loading train:  13%|█▎        | 38/285 [00:51<03:59,  1.03it/s]Loading train:  14%|█▎        | 39/285 [00:52<04:08,  1.01s/it]Loading train:  14%|█▍        | 40/285 [00:53<04:12,  1.03s/it]Loading train:  14%|█▍        | 41/285 [00:54<04:13,  1.04s/it]Loading train:  15%|█▍        | 42/285 [00:55<04:19,  1.07s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:16,  1.06s/it]Loading train:  15%|█▌        | 44/285 [00:57<04:04,  1.02s/it]Loading train:  16%|█▌        | 45/285 [00:58<04:03,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:59<03:49,  1.04it/s]Loading train:  16%|█▋        | 47/285 [01:00<03:38,  1.09it/s]Loading train:  17%|█▋        | 48/285 [01:00<03:33,  1.11it/s]Loading train:  17%|█▋        | 49/285 [01:01<03:22,  1.16it/s]Loading train:  18%|█▊        | 50/285 [01:02<03:32,  1.11it/s]Loading train:  18%|█▊        | 51/285 [01:03<03:25,  1.14it/s]Loading train:  18%|█▊        | 52/285 [01:04<03:39,  1.06it/s]Loading train:  19%|█▊        | 53/285 [01:05<03:30,  1.10it/s]Loading train:  19%|█▉        | 54/285 [01:06<03:27,  1.11it/s]Loading train:  19%|█▉        | 55/285 [01:07<03:25,  1.12it/s]Loading train:  20%|█▉        | 56/285 [01:08<03:24,  1.12it/s]Loading train:  20%|██        | 57/285 [01:09<03:24,  1.12it/s]Loading train:  20%|██        | 58/285 [01:09<03:22,  1.12it/s]Loading train:  21%|██        | 59/285 [01:11<03:46,  1.00s/it]Loading train:  21%|██        | 60/285 [01:12<03:39,  1.03it/s]Loading train:  21%|██▏       | 61/285 [01:13<03:48,  1.02s/it]Loading train:  22%|██▏       | 62/285 [01:14<03:35,  1.03it/s]Loading train:  22%|██▏       | 63/285 [01:14<03:31,  1.05it/s]Loading train:  22%|██▏       | 64/285 [01:16<04:03,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:18<04:59,  1.36s/it]Loading train:  23%|██▎       | 66/285 [01:19<05:03,  1.39s/it]Loading train:  24%|██▎       | 67/285 [01:20<04:29,  1.24s/it]Loading train:  24%|██▍       | 68/285 [01:21<04:15,  1.18s/it]Loading train:  24%|██▍       | 69/285 [01:22<03:54,  1.09s/it]Loading train:  25%|██▍       | 70/285 [01:23<03:44,  1.04s/it]Loading train:  25%|██▍       | 71/285 [01:24<03:36,  1.01s/it]Loading train:  25%|██▌       | 72/285 [01:25<03:26,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:26<03:20,  1.06it/s]Loading train:  26%|██▌       | 74/285 [01:27<03:46,  1.07s/it]Loading train:  26%|██▋       | 75/285 [01:29<04:11,  1.20s/it]Loading train:  27%|██▋       | 76/285 [01:30<04:14,  1.22s/it]Loading train:  27%|██▋       | 77/285 [01:31<04:16,  1.23s/it]Loading train:  27%|██▋       | 78/285 [01:33<04:49,  1.40s/it]Loading train:  28%|██▊       | 79/285 [01:34<04:48,  1.40s/it]Loading train:  28%|██▊       | 80/285 [01:36<04:41,  1.37s/it]Loading train:  28%|██▊       | 81/285 [01:37<04:38,  1.37s/it]Loading train:  29%|██▉       | 82/285 [01:38<04:28,  1.32s/it]Loading train:  29%|██▉       | 83/285 [01:40<04:46,  1.42s/it]Loading train:  29%|██▉       | 84/285 [01:41<04:29,  1.34s/it]Loading train:  30%|██▉       | 85/285 [01:42<04:36,  1.38s/it]Loading train:  30%|███       | 86/285 [01:44<04:41,  1.41s/it]Loading train:  31%|███       | 87/285 [01:46<05:07,  1.55s/it]Loading train:  31%|███       | 88/285 [01:47<05:01,  1.53s/it]Loading train:  31%|███       | 89/285 [01:49<04:55,  1.51s/it]Loading train:  32%|███▏      | 90/285 [01:50<04:49,  1.48s/it]Loading train:  32%|███▏      | 91/285 [01:52<04:40,  1.45s/it]Loading train:  32%|███▏      | 92/285 [01:53<05:02,  1.57s/it]Loading train:  33%|███▎      | 93/285 [01:55<04:43,  1.48s/it]Loading train:  33%|███▎      | 94/285 [01:56<04:43,  1.49s/it]Loading train:  33%|███▎      | 95/285 [01:57<04:31,  1.43s/it]Loading train:  34%|███▎      | 96/285 [01:59<04:12,  1.34s/it]Loading train:  34%|███▍      | 97/285 [02:00<04:12,  1.34s/it]Loading train:  34%|███▍      | 98/285 [02:02<04:31,  1.45s/it]Loading train:  35%|███▍      | 99/285 [02:03<04:49,  1.56s/it]Loading train:  35%|███▌      | 100/285 [02:05<04:54,  1.59s/it]Loading train:  35%|███▌      | 101/285 [02:07<04:49,  1.58s/it]Loading train:  36%|███▌      | 102/285 [02:08<04:46,  1.56s/it]Loading train:  36%|███▌      | 103/285 [02:10<05:02,  1.66s/it]Loading train:  36%|███▋      | 104/285 [02:12<04:49,  1.60s/it]Loading train:  37%|███▋      | 105/285 [02:13<04:27,  1.48s/it]Loading train:  37%|███▋      | 106/285 [02:14<04:23,  1.47s/it]Loading train:  38%|███▊      | 107/285 [02:16<04:18,  1.45s/it]Loading train:  38%|███▊      | 108/285 [02:17<04:31,  1.53s/it]Loading train:  38%|███▊      | 109/285 [02:19<04:40,  1.59s/it]Loading train:  39%|███▊      | 110/285 [02:21<04:36,  1.58s/it]Loading train:  39%|███▉      | 111/285 [02:22<04:22,  1.51s/it]Loading train:  39%|███▉      | 112/285 [02:24<04:23,  1.53s/it]Loading train:  40%|███▉      | 113/285 [02:25<04:24,  1.54s/it]Loading train:  40%|████      | 114/285 [02:27<04:46,  1.68s/it]Loading train:  40%|████      | 115/285 [02:28<04:29,  1.58s/it]Loading train:  41%|████      | 116/285 [02:30<04:29,  1.60s/it]Loading train:  41%|████      | 117/285 [02:32<04:20,  1.55s/it]Loading train:  41%|████▏     | 118/285 [02:33<04:20,  1.56s/it]Loading train:  42%|████▏     | 119/285 [02:35<04:20,  1.57s/it]Loading train:  42%|████▏     | 120/285 [02:36<04:26,  1.62s/it]Loading train:  42%|████▏     | 121/285 [02:38<04:29,  1.64s/it]Loading train:  43%|████▎     | 122/285 [02:40<04:22,  1.61s/it]Loading train:  43%|████▎     | 123/285 [02:41<04:21,  1.62s/it]Loading train:  44%|████▎     | 124/285 [02:43<04:07,  1.54s/it]Loading train:  44%|████▍     | 125/285 [02:44<04:01,  1.51s/it]Loading train:  44%|████▍     | 126/285 [02:45<03:47,  1.43s/it]Loading train:  45%|████▍     | 127/285 [02:47<03:59,  1.52s/it]Loading train:  45%|████▍     | 128/285 [02:49<03:54,  1.49s/it]Loading train:  45%|████▌     | 129/285 [02:50<03:44,  1.44s/it]Loading train:  46%|████▌     | 130/285 [02:51<03:48,  1.48s/it]Loading train:  46%|████▌     | 131/285 [02:53<03:35,  1.40s/it]Loading train:  46%|████▋     | 132/285 [02:54<03:34,  1.40s/it]Loading train:  47%|████▋     | 133/285 [02:55<03:31,  1.39s/it]Loading train:  47%|████▋     | 134/285 [02:57<03:44,  1.49s/it]Loading train:  47%|████▋     | 135/285 [02:59<03:53,  1.56s/it]Loading train:  48%|████▊     | 136/285 [03:01<04:04,  1.64s/it]Loading train:  48%|████▊     | 137/285 [03:02<03:55,  1.59s/it]Loading train:  48%|████▊     | 138/285 [03:04<04:08,  1.69s/it]Loading train:  49%|████▉     | 139/285 [03:06<03:56,  1.62s/it]Loading train:  49%|████▉     | 140/285 [03:07<03:54,  1.62s/it]Loading train:  49%|████▉     | 141/285 [03:09<03:51,  1.61s/it]Loading train:  50%|████▉     | 142/285 [03:10<03:45,  1.58s/it]Loading train:  50%|█████     | 143/285 [03:11<03:23,  1.43s/it]Loading train:  51%|█████     | 144/285 [03:13<03:22,  1.44s/it]Loading train:  51%|█████     | 145/285 [03:14<03:20,  1.43s/it]Loading train:  51%|█████     | 146/285 [03:16<03:23,  1.46s/it]Loading train:  52%|█████▏    | 147/285 [03:17<03:23,  1.47s/it]Loading train:  52%|█████▏    | 148/285 [03:19<03:28,  1.52s/it]Loading train:  52%|█████▏    | 149/285 [03:20<03:23,  1.50s/it]Loading train:  53%|█████▎    | 150/285 [03:22<03:22,  1.50s/it]Loading train:  53%|█████▎    | 151/285 [03:23<03:08,  1.41s/it]Loading train:  53%|█████▎    | 152/285 [03:24<03:01,  1.36s/it]Loading train:  54%|█████▎    | 153/285 [03:26<02:56,  1.34s/it]Loading train:  54%|█████▍    | 154/285 [03:27<03:01,  1.39s/it]Loading train:  54%|█████▍    | 155/285 [03:28<03:00,  1.39s/it]Loading train:  55%|█████▍    | 156/285 [03:30<02:51,  1.33s/it]Loading train:  55%|█████▌    | 157/285 [03:31<02:40,  1.26s/it]Loading train:  55%|█████▌    | 158/285 [03:32<02:44,  1.29s/it]Loading train:  56%|█████▌    | 159/285 [03:33<02:40,  1.27s/it]Loading train:  56%|█████▌    | 160/285 [03:35<02:50,  1.36s/it]Loading train:  56%|█████▋    | 161/285 [03:36<02:42,  1.31s/it]Loading train:  57%|█████▋    | 162/285 [03:37<02:36,  1.27s/it]Loading train:  57%|█████▋    | 163/285 [03:38<02:34,  1.27s/it]Loading train:  58%|█████▊    | 164/285 [03:40<02:26,  1.21s/it]Loading train:  58%|█████▊    | 165/285 [03:41<02:22,  1.19s/it]Loading train:  58%|█████▊    | 166/285 [03:42<02:30,  1.27s/it]Loading train:  59%|█████▊    | 167/285 [03:44<02:37,  1.34s/it]Loading train:  59%|█████▉    | 168/285 [03:45<02:44,  1.40s/it]Loading train:  59%|█████▉    | 169/285 [03:47<02:47,  1.44s/it]Loading train:  60%|█████▉    | 170/285 [03:48<02:36,  1.36s/it]Loading train:  60%|██████    | 171/285 [03:49<02:20,  1.23s/it]Loading train:  60%|██████    | 172/285 [03:50<02:12,  1.18s/it]Loading train:  61%|██████    | 173/285 [03:51<02:03,  1.10s/it]Loading train:  61%|██████    | 174/285 [03:52<02:02,  1.11s/it]Loading train:  61%|██████▏   | 175/285 [03:53<01:53,  1.03s/it]Loading train:  62%|██████▏   | 176/285 [03:54<01:51,  1.03s/it]Loading train:  62%|██████▏   | 177/285 [03:55<01:55,  1.07s/it]Loading train:  62%|██████▏   | 178/285 [03:56<02:07,  1.19s/it]Loading train:  63%|██████▎   | 179/285 [03:57<01:58,  1.12s/it]Loading train:  63%|██████▎   | 180/285 [03:59<02:01,  1.16s/it]Loading train:  64%|██████▎   | 181/285 [04:00<02:00,  1.15s/it]Loading train:  64%|██████▍   | 182/285 [04:01<01:53,  1.11s/it]Loading train:  64%|██████▍   | 183/285 [04:02<01:48,  1.06s/it]Loading train:  65%|██████▍   | 184/285 [04:03<01:45,  1.04s/it]Loading train:  65%|██████▍   | 185/285 [04:04<01:37,  1.02it/s]Loading train:  65%|██████▌   | 186/285 [04:04<01:31,  1.08it/s]Loading train:  66%|██████▌   | 187/285 [04:05<01:33,  1.05it/s]Loading train:  66%|██████▌   | 188/285 [04:06<01:34,  1.03it/s]Loading train:  66%|██████▋   | 189/285 [04:07<01:35,  1.00it/s]Loading train:  67%|██████▋   | 190/285 [04:09<01:36,  1.01s/it]Loading train:  67%|██████▋   | 191/285 [04:10<01:41,  1.08s/it]Loading train:  67%|██████▋   | 192/285 [04:11<01:37,  1.04s/it]Loading train:  68%|██████▊   | 193/285 [04:12<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [04:13<01:32,  1.02s/it]Loading train:  68%|██████▊   | 195/285 [04:14<01:31,  1.02s/it]Loading train:  69%|██████▉   | 196/285 [04:15<01:43,  1.16s/it]Loading train:  69%|██████▉   | 197/285 [04:16<01:40,  1.14s/it]Loading train:  69%|██████▉   | 198/285 [04:18<01:45,  1.21s/it]Loading train:  70%|██████▉   | 199/285 [04:19<01:53,  1.32s/it]Loading train:  70%|███████   | 200/285 [04:21<01:54,  1.35s/it]Loading train:  71%|███████   | 201/285 [04:22<01:52,  1.34s/it]Loading train:  71%|███████   | 202/285 [04:23<01:51,  1.34s/it]Loading train:  71%|███████   | 203/285 [04:25<01:48,  1.32s/it]Loading train:  72%|███████▏  | 204/285 [04:26<01:51,  1.37s/it]Loading train:  72%|███████▏  | 205/285 [04:28<01:54,  1.44s/it]Loading train:  72%|███████▏  | 206/285 [04:29<01:54,  1.45s/it]Loading train:  73%|███████▎  | 207/285 [04:31<01:50,  1.41s/it]Loading train:  73%|███████▎  | 208/285 [04:32<01:57,  1.52s/it]Loading train:  73%|███████▎  | 209/285 [04:34<01:49,  1.44s/it]Loading train:  74%|███████▎  | 210/285 [04:35<01:51,  1.49s/it]Loading train:  74%|███████▍  | 211/285 [04:36<01:45,  1.42s/it]Loading train:  74%|███████▍  | 212/285 [04:38<01:53,  1.55s/it]Loading train:  75%|███████▍  | 213/285 [04:39<01:43,  1.44s/it]Loading train:  75%|███████▌  | 214/285 [04:41<01:40,  1.41s/it]Loading train:  75%|███████▌  | 215/285 [04:43<01:44,  1.50s/it]Loading train:  76%|███████▌  | 216/285 [04:44<01:50,  1.60s/it]Loading train:  76%|███████▌  | 217/285 [04:46<01:52,  1.65s/it]Loading train:  76%|███████▋  | 218/285 [04:47<01:41,  1.51s/it]Loading train:  77%|███████▋  | 219/285 [04:49<01:35,  1.45s/it]Loading train:  77%|███████▋  | 220/285 [04:51<01:44,  1.61s/it]Loading train:  78%|███████▊  | 221/285 [04:52<01:37,  1.53s/it]Loading train:  78%|███████▊  | 222/285 [04:53<01:31,  1.46s/it]Loading train:  78%|███████▊  | 223/285 [04:55<01:31,  1.47s/it]Loading train:  79%|███████▊  | 224/285 [04:56<01:32,  1.51s/it]Loading train:  79%|███████▉  | 225/285 [04:58<01:31,  1.53s/it]Loading train:  79%|███████▉  | 226/285 [04:59<01:30,  1.53s/it]Loading train:  80%|███████▉  | 227/285 [05:01<01:30,  1.55s/it]Loading train:  80%|████████  | 228/285 [05:02<01:23,  1.47s/it]Loading train:  80%|████████  | 229/285 [05:04<01:26,  1.55s/it]Loading train:  81%|████████  | 230/285 [05:06<01:25,  1.56s/it]Loading train:  81%|████████  | 231/285 [05:08<01:33,  1.72s/it]Loading train:  81%|████████▏ | 232/285 [05:10<01:36,  1.82s/it]Loading train:  82%|████████▏ | 233/285 [05:14<02:04,  2.39s/it]Loading train:  82%|████████▏ | 234/285 [05:15<01:45,  2.08s/it]Loading train:  82%|████████▏ | 235/285 [05:17<01:39,  1.99s/it]Loading train:  83%|████████▎ | 236/285 [05:19<01:35,  1.96s/it]Loading train:  83%|████████▎ | 237/285 [05:21<01:35,  2.00s/it]Loading train:  84%|████████▎ | 238/285 [05:22<01:28,  1.87s/it]Loading train:  84%|████████▍ | 239/285 [05:24<01:19,  1.74s/it]Loading train:  84%|████████▍ | 240/285 [05:25<01:18,  1.74s/it]Loading train:  85%|████████▍ | 241/285 [05:27<01:17,  1.76s/it]Loading train:  85%|████████▍ | 242/285 [05:29<01:17,  1.81s/it]Loading train:  85%|████████▌ | 243/285 [05:30<01:09,  1.66s/it]Loading train:  86%|████████▌ | 244/285 [05:32<01:05,  1.61s/it]Loading train:  86%|████████▌ | 245/285 [05:34<01:08,  1.71s/it]Loading train:  86%|████████▋ | 246/285 [05:35<01:03,  1.63s/it]Loading train:  87%|████████▋ | 247/285 [05:37<01:03,  1.67s/it]Loading train:  87%|████████▋ | 248/285 [05:39<01:04,  1.74s/it]Loading train:  87%|████████▋ | 249/285 [05:41<01:08,  1.90s/it]Loading train:  88%|████████▊ | 250/285 [05:43<01:01,  1.77s/it]Loading train:  88%|████████▊ | 251/285 [05:44<00:51,  1.51s/it]Loading train:  88%|████████▊ | 252/285 [05:45<00:51,  1.55s/it]Loading train:  89%|████████▉ | 253/285 [05:47<00:48,  1.52s/it]Loading train:  89%|████████▉ | 254/285 [05:48<00:45,  1.47s/it]Loading train:  89%|████████▉ | 255/285 [05:50<00:44,  1.48s/it]Loading train:  90%|████████▉ | 256/285 [05:51<00:43,  1.49s/it]Loading train:  90%|█████████ | 257/285 [05:53<00:41,  1.48s/it]Loading train:  91%|█████████ | 258/285 [05:54<00:40,  1.49s/it]Loading train:  91%|█████████ | 259/285 [05:56<00:40,  1.56s/it]Loading train:  91%|█████████ | 260/285 [05:57<00:36,  1.47s/it]Loading train:  92%|█████████▏| 261/285 [05:58<00:32,  1.37s/it]Loading train:  92%|█████████▏| 262/285 [05:59<00:30,  1.34s/it]Loading train:  92%|█████████▏| 263/285 [06:01<00:29,  1.32s/it]Loading train:  93%|█████████▎| 264/285 [06:02<00:26,  1.24s/it]Loading train:  93%|█████████▎| 265/285 [06:03<00:24,  1.20s/it]Loading train:  93%|█████████▎| 266/285 [06:04<00:23,  1.25s/it]Loading train:  94%|█████████▎| 267/285 [06:05<00:22,  1.24s/it]Loading train:  94%|█████████▍| 268/285 [06:07<00:22,  1.32s/it]Loading train:  94%|█████████▍| 269/285 [06:09<00:22,  1.42s/it]Loading train:  95%|█████████▍| 270/285 [06:10<00:21,  1.45s/it]Loading train:  95%|█████████▌| 271/285 [06:11<00:19,  1.38s/it]Loading train:  95%|█████████▌| 272/285 [06:13<00:18,  1.40s/it]Loading train:  96%|█████████▌| 273/285 [06:14<00:16,  1.39s/it]Loading train:  96%|█████████▌| 274/285 [06:15<00:14,  1.36s/it]Loading train:  96%|█████████▋| 275/285 [06:17<00:14,  1.48s/it]Loading train:  97%|█████████▋| 276/285 [06:19<00:12,  1.44s/it]Loading train:  97%|█████████▋| 277/285 [06:20<00:11,  1.45s/it]Loading train:  98%|█████████▊| 278/285 [06:21<00:10,  1.45s/it]Loading train:  98%|█████████▊| 279/285 [06:23<00:08,  1.48s/it]Loading train:  98%|█████████▊| 280/285 [06:25<00:07,  1.50s/it]Loading train:  99%|█████████▊| 281/285 [06:26<00:05,  1.43s/it]Loading train:  99%|█████████▉| 282/285 [06:27<00:04,  1.50s/it]Loading train:  99%|█████████▉| 283/285 [06:29<00:03,  1.51s/it]Loading train: 100%|█████████▉| 284/285 [06:31<00:01,  1.54s/it]Loading train: 100%|██████████| 285/285 [06:32<00:00,  1.57s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:08, 35.01it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:08, 31.30it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:07, 34.64it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:07, 36.24it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:06, 39.09it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:05, 43.23it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:05, 45.93it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:05, 48.87it/s]concatenating: train:  18%|█▊        | 52/285 [00:01<00:03, 58.37it/s]concatenating: train:  24%|██▎       | 67/285 [00:01<00:03, 71.10it/s]concatenating: train:  27%|██▋       | 77/285 [00:01<00:02, 75.04it/s]concatenating: train:  30%|███       | 86/285 [00:01<00:02, 71.45it/s]concatenating: train:  33%|███▎      | 95/285 [00:01<00:02, 69.79it/s]concatenating: train:  36%|███▌      | 103/285 [00:01<00:03, 50.95it/s]concatenating: train:  39%|███▊      | 110/285 [00:01<00:03, 53.44it/s]concatenating: train:  41%|████      | 117/285 [00:01<00:03, 54.82it/s]concatenating: train:  44%|████▎     | 124/285 [00:02<00:02, 55.30it/s]concatenating: train:  46%|████▌     | 130/285 [00:02<00:02, 52.74it/s]concatenating: train:  48%|████▊     | 137/285 [00:02<00:02, 55.60it/s]concatenating: train:  50%|█████     | 143/285 [00:02<00:02, 53.23it/s]concatenating: train:  52%|█████▏    | 149/285 [00:02<00:02, 46.88it/s]concatenating: train:  54%|█████▍    | 154/285 [00:02<00:02, 47.72it/s]concatenating: train:  56%|█████▌    | 160/285 [00:02<00:02, 49.83it/s]concatenating: train:  59%|█████▊    | 167/285 [00:02<00:02, 53.06it/s]concatenating: train:  61%|██████    | 174/285 [00:03<00:01, 55.58it/s]concatenating: train:  64%|██████▎   | 181/285 [00:03<00:01, 57.49it/s]concatenating: train:  66%|██████▌   | 187/285 [00:03<00:01, 58.22it/s]concatenating: train:  68%|██████▊   | 193/285 [00:03<00:01, 53.18it/s]concatenating: train:  70%|██████▉   | 199/285 [00:03<00:01, 51.07it/s]concatenating: train:  72%|███████▏  | 205/285 [00:03<00:01, 46.11it/s]concatenating: train:  74%|███████▎  | 210/285 [00:03<00:01, 43.69it/s]concatenating: train:  75%|███████▌  | 215/285 [00:03<00:01, 43.98it/s]concatenating: train:  77%|███████▋  | 220/285 [00:04<00:01, 39.60it/s]concatenating: train:  79%|███████▉  | 225/285 [00:04<00:01, 38.31it/s]concatenating: train:  80%|████████  | 229/285 [00:04<00:01, 29.29it/s]concatenating: train:  82%|████████▏ | 235/285 [00:04<00:01, 34.11it/s]concatenating: train:  85%|████████▍ | 241/285 [00:04<00:01, 38.87it/s]concatenating: train:  87%|████████▋ | 247/285 [00:04<00:00, 42.72it/s]concatenating: train:  89%|████████▉ | 254/285 [00:04<00:00, 47.20it/s]concatenating: train:  91%|█████████ | 260/285 [00:05<00:00, 48.48it/s]concatenating: train:  93%|█████████▎| 266/285 [00:05<00:00, 48.45it/s]concatenating: train:  95%|█████████▌| 272/285 [00:05<00:00, 50.89it/s]concatenating: train:  98%|█████████▊| 279/285 [00:05<00:00, 54.93it/s]concatenating: train: 100%|██████████| 285/285 [00:05<00:00, 52.52it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.69s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.78s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.73s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 27.92it/s] 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 60)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 120)  64920       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 120)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   28860       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 120)  0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 60)   64860       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 60)   0           activation_8[0][0]               2019-06-30 20:02:10.753855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 20:02:10.753951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 20:02:10.753965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 20:02:10.753973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 20:02:10.754445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   7230        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 30)   16230       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 30)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   403         dropout_5[0][0]                  
==================================================================================================
Total params: 412,363
Trainable params: 411,163
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [2.13273029e+01 1.05010629e+01 2.46462697e+01 3.06320970e+00
 8.90359853e+00 2.32172244e+00 2.79665044e+01 3.70132346e+01
 2.82684742e+01 4.35344460e+00 9.66596785e+01 6.42825607e+01
 8.84946717e-02]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 18s - loss: 1316.8270 - acc: 0.8859 - mDice: 0.2872 - val_loss: 1032.5751 - val_acc: 0.9246 - val_mDice: 0.3695

Epoch 00001: val_mDice improved from -inf to 0.36951, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 708.1746 - acc: 0.9101 - mDice: 0.4963 - val_loss: 1471.5117 - val_acc: 0.9264 - val_mDice: 0.3524

Epoch 00002: val_mDice did not improve from 0.36951
Epoch 3/300
 - 10s - loss: 602.4134 - acc: 0.9171 - mDice: 0.5602 - val_loss: 1182.3751 - val_acc: 0.9365 - val_mDice: 0.4232

Epoch 00003: val_mDice improved from 0.36951 to 0.42316, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 546.4008 - acc: 0.9200 - mDice: 0.5955 - val_loss: 1357.8424 - val_acc: 0.9372 - val_mDice: 0.4269

Epoch 00004: val_mDice improved from 0.42316 to 0.42690, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 10s - loss: 507.4925 - acc: 0.9222 - mDice: 0.6213 - val_loss: 1485.6855 - val_acc: 0.9372 - val_mDice: 0.4198

Epoch 00005: val_mDice did not improve from 0.42690
Epoch 6/300
 - 10s - loss: 477.6810 - acc: 0.9239 - mDice: 0.6424 - val_loss: 1335.9912 - val_acc: 0.9411 - val_mDice: 0.4382

Epoch 00006: val_mDice improved from 0.42690 to 0.43824, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 455.1460 - acc: 0.9251 - mDice: 0.6576 - val_loss: 1465.8564 - val_acc: 0.9401 - val_mDice: 0.4395

Epoch 00007: val_mDice improved from 0.43824 to 0.43949, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 438.9262 - acc: 0.9266 - mDice: 0.6695 - val_loss: 1553.9000 - val_acc: 0.9407 - val_mDice: 0.4251

Epoch 00008: val_mDice did not improve from 0.43949
Epoch 9/300
 - 11s - loss: 424.7039 - acc: 0.9274 - mDice: 0.6801 - val_loss: 1672.7782 - val_acc: 0.9385 - val_mDice: 0.4119

Epoch 00009: val_mDice did not improve from 0.43949
Epoch 10/300
 - 10s - loss: 409.7942 - acc: 0.9282 - mDice: 0.6904 - val_loss: 1459.9246 - val_acc: 0.9413 - val_mDice: 0.4411

Epoch 00010: val_mDice improved from 0.43949 to 0.44114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 397.5145 - acc: 0.9288 - mDice: 0.6998 - val_loss: 1627.6380 - val_acc: 0.9407 - val_mDice: 0.4413

Epoch 00011: val_mDice improved from 0.44114 to 0.44125, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 10s - loss: 390.1241 - acc: 0.9294 - mDice: 0.7052 - val_loss: 1701.0349 - val_acc: 0.9382 - val_mDice: 0.4153

Epoch 00012: val_mDice did not improve from 0.44125
Epoch 13/300
 - 10s - loss: 380.5845 - acc: 0.9300 - mDice: 0.7120 - val_loss: 1756.8533 - val_acc: 0.9385 - val_mDice: 0.4116

Epoch 00013: val_mDice did not improve from 0.44125
Epoch 14/300
 - 10s - loss: 375.1481 - acc: 0.9305 - mDice: 0.7163 - val_loss: 1527.3821 - val_acc: 0.9416 - val_mDice: 0.4371

Epoch 00014: val_mDice did not improve from 0.44125
Epoch 15/300
 - 10s - loss: 365.3374 - acc: 0.9313 - mDice: 0.7232 - val_loss: 1568.4659 - val_acc: 0.9423 - val_mDice: 0.4461

Epoch 00015: val_mDice improved from 0.44125 to 0.44607, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 10s - loss: 360.5065 - acc: 0.9323 - mDice: 0.7273 - val_loss: 1754.2643 - val_acc: 0.9413 - val_mDice: 0.4356

Epoch 00016: val_mDice did not improve from 0.44607
Epoch 17/300
 - 10s - loss: 353.1453 - acc: 0.9325 - mDice: 0.7327 - val_loss: 1730.1077 - val_acc: 0.9413 - val_mDice: 0.4329

Epoch 00017: val_mDice did not improve from 0.44607
Epoch 18/300
 - 10s - loss: 347.5514 - acc: 0.9329 - mDice: 0.7368 - val_loss: 1853.3997 - val_acc: 0.9400 - val_mDice: 0.4227

Epoch 00018: val_mDice did not improve from 0.44607
Epoch 19/300
 - 10s - loss: 341.7595 - acc: 0.9332 - mDice: 0.7411 - val_loss: 2074.2988 - val_acc: 0.9377 - val_mDice: 0.4049

Epoch 00019: val_mDice did not improve from 0.44607
Epoch 20/300
 - 10s - loss: 337.2915 - acc: 0.9339 - mDice: 0.7444 - val_loss: 2043.9217 - val_acc: 0.9386 - val_mDice: 0.4126

Epoch 00020: val_mDice did not improve from 0.44607
Epoch 21/300
 - 10s - loss: 331.1639 - acc: 0.9342 - mDice: 0.7484 - val_loss: 1916.0230 - val_acc: 0.9394 - val_mDice: 0.4262

Epoch 00021: val_mDice did not improve from 0.44607
Epoch 22/300
 - 10s - loss: 328.7306 - acc: 0.9346 - mDice: 0.7511 - val_loss: 1930.4567 - val_acc: 0.9411 - val_mDice: 0.4271

Epoch 00022: val_mDice did not improve from 0.44607
Epoch 23/300
 - 10s - loss: 324.4969 - acc: 0.9349 - mDice: 0.7541 - val_loss: 1591.4723 - val_acc: 0.9420 - val_mDice: 0.4650

Epoch 00023: val_mDice improved from 0.44607 to 0.46501, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 10s - loss: 322.6043 - acc: 0.9350 - mDice: 0.7554 - val_loss: 1642.4722 - val_acc: 0.9446 - val_mDice: 0.4581

Epoch 00024: val_mDice did not improve from 0.46501
Epoch 25/300
 - 10s - loss: 318.8741 - acc: 0.9353 - mDice: 0.7580 - val_loss: 1837.6577 - val_acc: 0.9411 - val_mDice: 0.4337

Epoch 00025: val_mDice did not improve from 0.46501
Epoch 26/300
 - 10s - loss: 313.9847 - acc: 0.9357 - mDice: 0.7619 - val_loss: 1890.4710 - val_acc: 0.9425 - val_mDice: 0.4380

Epoch 00026: val_mDice did not improve from 0.46501
Epoch 27/300
 - 10s - loss: 310.8261 - acc: 0.9360 - mDice: 0.7642 - val_loss: 1969.0830 - val_acc: 0.9428 - val_mDice: 0.4361

Epoch 00027: val_mDice did not improve from 0.46501
Epoch 28/300
 - 10s - loss: 307.7692 - acc: 0.9365 - mDice: 0.7666 - val_loss: 1734.8311 - val_acc: 0.9434 - val_mDice: 0.4530

Epoch 00028: val_mDice did not improve from 0.46501
Epoch 29/300
 - 10s - loss: 305.3224 - acc: 0.9365 - mDice: 0.7681 - val_loss: 1739.1696 - val_acc: 0.9454 - val_mDice: 0.4588

Epoch 00029: val_mDice did not improve from 0.46501
Epoch 30/300
 - 10s - loss: 301.5553 - acc: 0.9371 - mDice: 0.7715 - val_loss: 1971.4044 - val_acc: 0.9418 - val_mDice: 0.4287

Epoch 00030: val_mDice did not improve from 0.46501
Epoch 31/300
 - 11s - loss: 299.2209 - acc: 0.9373 - mDice: 0.7727 - val_loss: 1770.6344 - val_acc: 0.9437 - val_mDice: 0.4521

Epoch 00031: val_mDice did not improve from 0.46501
Epoch 32/300
 - 10s - loss: 297.3372 - acc: 0.9373 - mDice: 0.7745 - val_loss: 2055.5516 - val_acc: 0.9423 - val_mDice: 0.4179

Epoch 00032: val_mDice did not improve from 0.46501
Epoch 33/300
 - 10s - loss: 296.1991 - acc: 0.9372 - mDice: 0.7751 - val_loss: 1852.6025 - val_acc: 0.9420 - val_mDice: 0.4422

Epoch 00033: val_mDice did not improve from 0.46501
Epoch 34/300
 - 10s - loss: 293.0255 - acc: 0.9374 - mDice: 0.7776 - val_loss: 1962.9187 - val_acc: 0.9431 - val_mDice: 0.4426

Epoch 00034: val_mDice did not improve from 0.46501
Epoch 35/300
 - 10s - loss: 290.3211 - acc: 0.9378 - mDice: 0.7797 - val_loss: 1840.7440 - val_acc: 0.9451 - val_mDice: 0.4574

Epoch 00035: val_mDice did not improve from 0.46501
Epoch 36/300
 - 10s - loss: 289.9699 - acc: 0.9381 - mDice: 0.7802 - val_loss: 2024.4926 - val_acc: 0.9423 - val_mDice: 0.4255

Epoch 00036: val_mDice did not improve from 0.46501
Epoch 37/300
 - 10s - loss: 285.7147 - acc: 0.9382 - mDice: 0.7832 - val_loss: 1776.8184 - val_acc: 0.9427 - val_mDice: 0.4578

Epoch 00037: val_mDice did not improve from 0.46501
Epoch 38/300
 - 10s - loss: 283.6603 - acc: 0.9383 - mDice: 0.7846 - val_loss: 1926.3770 - val_acc: 0.9433 - val_mDice: 0.4424

Epoch 00038: val_mDice did not improve from 0.46501
Epoch 39/300
 - 10s - loss: 284.1714 - acc: 0.9384 - mDice: 0.7845 - val_loss: 1923.6996 - val_acc: 0.9435 - val_mDice: 0.4449

Epoch 00039: val_mDice did not improve from 0.46501
Epoch 40/300
 - 10s - loss: 280.5758 - acc: 0.9390 - mDice: 0.7875 - val_loss: 1927.2649 - val_acc: 0.9415 - val_mDice: 0.4313

Epoch 00040: val_mDice did not improve from 0.46501
Epoch 41/300
 - 10s - loss: 279.6740 - acc: 0.9388 - mDice: 0.7876 - val_loss: 1927.9418 - val_acc: 0.9446 - val_mDice: 0.4472

Epoch 00041: val_mDice did not improve from 0.46501
Epoch 42/300
 - 10s - loss: 277.3312 - acc: 0.9391 - mDice: 0.7897 - val_loss: 2039.0677 - val_acc: 0.9431 - val_mDice: 0.4317

Epoch 00042: val_mDice did not improve from 0.46501
Epoch 43/300
 - 10s - loss: 274.0562 - acc: 0.9393 - mDice: 0.7920 - val_loss: 1916.3711 - val_acc: 0.9431 - val_mDice: 0.4501

Epoch 00043: val_mDice did not improve from 0.46501
Epoch 44/300
 - 10s - loss: 274.0284 - acc: 0.9397 - mDice: 0.7925 - val_loss: 1889.2260 - val_acc: 0.9433 - val_mDice: 0.4491

Epoch 00044: val_mDice did not improve from 0.46501
Epoch 45/300
 - 10s - loss: 272.8530 - acc: 0.9392 - mDice: 0.7928 - val_loss: 1930.0818 - val_acc: 0.9430 - val_mDice: 0.4399

Epoch 00045: val_mDice did not improve from 0.46501
Epoch 46/300
 - 10s - loss: 271.1041 - acc: 0.9394 - mDice: 0.7942 - val_loss: 2133.4318 - val_acc: 0.9426 - val_mDice: 0.4215

Epoch 00046: val_mDice did not improve from 0.46501
Epoch 47/300
 - 10s - loss: 268.7326 - acc: 0.9397 - mDice: 0.7960 - val_loss: 2155.8242 - val_acc: 0.9422 - val_mDice: 0.4224

Epoch 00047: val_mDice did not improve from 0.46501
Epoch 48/300
 - 10s - loss: 268.7140 - acc: 0.9397 - mDice: 0.7963 - val_loss: 2007.1192 - val_acc: 0.9446 - val_mDice: 0.4484

Epoch 00048: val_mDice did not improve from 0.46501
Epoch 49/300
 - 10s - loss: 266.6207 - acc: 0.9398 - mDice: 0.7974 - val_loss: 2135.7996 - val_acc: 0.9433 - val_mDice: 0.4304

Epoch 00049: val_mDice did not improve from 0.46501
Epoch 50/300
 - 10s - loss: 264.8310 - acc: 0.9403 - mDice: 0.7990 - val_loss: 2041.4160 - val_acc: 0.9430 - val_mDice: 0.4341

Epoch 00050: val_mDice did not improve from 0.46501
Epoch 51/300
 - 10s - loss: 264.2666 - acc: 0.9402 - mDice: 0.7994 - val_loss: 2000.0089 - val_acc: 0.9421 - val_mDice: 0.4347

Epoch 00051: val_mDice did not improve from 0.46501
Epoch 52/300
 - 10s - loss: 263.0055 - acc: 0.9402 - mDice: 0.8003 - val_loss: 2156.8631 - val_acc: 0.9393 - val_mDice: 0.4185

Epoch 00052: val_mDice did not improve from 0.46501
Epoch 53/300
 - 10s - loss: 261.2271 - acc: 0.9406 - mDice: 0.8016 - val_loss: 2213.8596 - val_acc: 0.9413 - val_mDice: 0.4179

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.71s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.46s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.22s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:42,  1.63s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:07,  1.72s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:27,  1.80s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:59,  1.92s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:34,  1.84s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:57,  1.93s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:16,  2.00s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:31,  2.06s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:06,  1.98s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<09:41,  2.12s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<09:47,  2.15s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:59,  2.20s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<09:55,  2.19s/it]predicting train subjects:   5%|▍         | 14/285 [00:29<09:59,  2.21s/it]predicting train subjects:   5%|▌         | 15/285 [00:31<09:51,  2.19s/it]predicting train subjects:   6%|▌         | 16/285 [00:33<10:26,  2.33s/it]predicting train subjects:   6%|▌         | 17/285 [00:36<10:15,  2.29s/it]predicting train subjects:   6%|▋         | 18/285 [00:38<10:13,  2.30s/it]predicting train subjects:   7%|▋         | 19/285 [00:40<09:57,  2.24s/it]predicting train subjects:   7%|▋         | 20/285 [00:42<09:33,  2.16s/it]predicting train subjects:   7%|▋         | 21/285 [00:44<09:14,  2.10s/it]predicting train subjects:   8%|▊         | 22/285 [00:46<09:13,  2.10s/it]predicting train subjects:   8%|▊         | 23/285 [00:48<09:17,  2.13s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<09:03,  2.08s/it]predicting train subjects:   9%|▉         | 25/285 [00:52<08:56,  2.06s/it]predicting train subjects:   9%|▉         | 26/285 [00:55<09:12,  2.13s/it]predicting train subjects:   9%|▉         | 27/285 [00:57<09:13,  2.15s/it]predicting train subjects:  10%|▉         | 28/285 [00:59<09:01,  2.11s/it]predicting train subjects:  10%|█         | 29/285 [01:01<08:44,  2.05s/it]predicting train subjects:  11%|█         | 30/285 [01:03<08:33,  2.01s/it]predicting train subjects:  11%|█         | 31/285 [01:05<08:29,  2.01s/it]predicting train subjects:  11%|█         | 32/285 [01:07<08:33,  2.03s/it]predicting train subjects:  12%|█▏        | 33/285 [01:09<08:34,  2.04s/it]predicting train subjects:  12%|█▏        | 34/285 [01:11<08:29,  2.03s/it]predicting train subjects:  12%|█▏        | 35/285 [01:13<08:23,  2.02s/it]predicting train subjects:  13%|█▎        | 36/285 [01:15<08:24,  2.03s/it]predicting train subjects:  13%|█▎        | 37/285 [01:17<08:19,  2.01s/it]predicting train subjects:  13%|█▎        | 38/285 [01:19<08:09,  1.98s/it]predicting train subjects:  14%|█▎        | 39/285 [01:21<08:04,  1.97s/it]predicting train subjects:  14%|█▍        | 40/285 [01:23<08:15,  2.02s/it]predicting train subjects:  14%|█▍        | 41/285 [01:25<08:31,  2.10s/it]predicting train subjects:  15%|█▍        | 42/285 [01:27<08:36,  2.12s/it]predicting train subjects:  15%|█▌        | 43/285 [01:29<08:34,  2.12s/it]predicting train subjects:  15%|█▌        | 44/285 [01:31<08:30,  2.12s/it]predicting train subjects:  16%|█▌        | 45/285 [01:34<08:34,  2.14s/it]predicting train subjects:  16%|█▌        | 46/285 [01:35<08:06,  2.04s/it]predicting train subjects:  16%|█▋        | 47/285 [01:37<07:49,  1.97s/it]predicting train subjects:  17%|█▋        | 48/285 [01:39<07:34,  1.92s/it]predicting train subjects:  17%|█▋        | 49/285 [01:41<07:23,  1.88s/it]predicting train subjects:  18%|█▊        | 50/285 [01:43<07:16,  1.86s/it]predicting train subjects:  18%|█▊        | 51/285 [01:45<07:15,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:47<07:25,  1.91s/it]predicting train subjects:  19%|█▊        | 53/285 [01:48<07:19,  1.89s/it]predicting train subjects:  19%|█▉        | 54/285 [01:50<07:30,  1.95s/it]predicting train subjects:  19%|█▉        | 55/285 [01:53<07:45,  2.02s/it]predicting train subjects:  20%|█▉        | 56/285 [01:55<08:00,  2.10s/it]predicting train subjects:  20%|██        | 57/285 [01:57<08:07,  2.14s/it]predicting train subjects:  20%|██        | 58/285 [01:59<07:39,  2.03s/it]predicting train subjects:  21%|██        | 59/285 [02:01<07:21,  1.95s/it]predicting train subjects:  21%|██        | 60/285 [02:02<06:59,  1.86s/it]predicting train subjects:  21%|██▏       | 61/285 [02:04<06:51,  1.84s/it]predicting train subjects:  22%|██▏       | 62/285 [02:06<06:51,  1.84s/it]predicting train subjects:  22%|██▏       | 63/285 [02:08<06:50,  1.85s/it]predicting train subjects:  22%|██▏       | 64/285 [02:10<06:58,  1.90s/it]predicting train subjects:  23%|██▎       | 65/285 [02:12<07:09,  1.95s/it]predicting train subjects:  23%|██▎       | 66/285 [02:14<07:21,  2.01s/it]predicting train subjects:  24%|██▎       | 67/285 [02:16<07:08,  1.97s/it]predicting train subjects:  24%|██▍       | 68/285 [02:18<07:03,  1.95s/it]predicting train subjects:  24%|██▍       | 69/285 [02:20<06:53,  1.91s/it]predicting train subjects:  25%|██▍       | 70/285 [02:22<06:59,  1.95s/it]predicting train subjects:  25%|██▍       | 71/285 [02:24<06:52,  1.93s/it]predicting train subjects:  25%|██▌       | 72/285 [02:25<06:46,  1.91s/it]predicting train subjects:  26%|██▌       | 73/285 [02:28<07:05,  2.01s/it]predicting train subjects:  26%|██▌       | 74/285 [02:30<06:59,  1.99s/it]predicting train subjects:  26%|██▋       | 75/285 [02:32<06:48,  1.94s/it]predicting train subjects:  27%|██▋       | 76/285 [02:33<06:47,  1.95s/it]predicting train subjects:  27%|██▋       | 77/285 [02:35<06:41,  1.93s/it]predicting train subjects:  27%|██▋       | 78/285 [02:37<06:31,  1.89s/it]predicting train subjects:  28%|██▊       | 79/285 [02:39<06:33,  1.91s/it]predicting train subjects:  28%|██▊       | 80/285 [02:41<06:31,  1.91s/it]predicting train subjects:  28%|██▊       | 81/285 [02:43<06:41,  1.97s/it]predicting train subjects:  29%|██▉       | 82/285 [02:45<06:31,  1.93s/it]predicting train subjects:  29%|██▉       | 83/285 [02:47<06:24,  1.90s/it]predicting train subjects:  29%|██▉       | 84/285 [02:49<06:18,  1.89s/it]predicting train subjects:  30%|██▉       | 85/285 [02:51<06:22,  1.91s/it]predicting train subjects:  30%|███       | 86/285 [02:53<06:34,  1.98s/it]predicting train subjects:  31%|███       | 87/285 [02:55<07:15,  2.20s/it]predicting train subjects:  31%|███       | 88/285 [02:58<07:07,  2.17s/it]predicting train subjects:  31%|███       | 89/285 [03:00<06:59,  2.14s/it]predicting train subjects:  32%|███▏      | 90/285 [03:02<06:47,  2.09s/it]predicting train subjects:  32%|███▏      | 91/285 [03:04<06:47,  2.10s/it]predicting train subjects:  32%|███▏      | 92/285 [03:06<06:45,  2.10s/it]predicting train subjects:  33%|███▎      | 93/285 [03:08<06:46,  2.12s/it]predicting train subjects:  33%|███▎      | 94/285 [03:10<06:40,  2.10s/it]predicting train subjects:  33%|███▎      | 95/285 [03:12<06:36,  2.09s/it]predicting train subjects:  34%|███▎      | 96/285 [03:14<06:32,  2.08s/it]predicting train subjects:  34%|███▍      | 97/285 [03:16<06:25,  2.05s/it]predicting train subjects:  34%|███▍      | 98/285 [03:18<06:20,  2.03s/it]predicting train subjects:  35%|███▍      | 99/285 [03:20<06:10,  1.99s/it]predicting train subjects:  35%|███▌      | 100/285 [03:22<06:04,  1.97s/it]predicting train subjects:  35%|███▌      | 101/285 [03:24<05:56,  1.94s/it]predicting train subjects:  36%|███▌      | 102/285 [03:26<05:55,  1.94s/it]predicting train subjects:  36%|███▌      | 103/285 [03:28<05:53,  1.94s/it]predicting train subjects:  36%|███▋      | 104/285 [03:30<05:44,  1.91s/it]predicting train subjects:  37%|███▋      | 105/285 [03:31<05:32,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:33<05:38,  1.89s/it]predicting train subjects:  38%|███▊      | 107/285 [03:35<05:41,  1.92s/it]predicting train subjects:  38%|███▊      | 108/285 [03:37<05:47,  1.96s/it]predicting train subjects:  38%|███▊      | 109/285 [03:39<05:43,  1.95s/it]predicting train subjects:  39%|███▊      | 110/285 [03:41<05:44,  1.97s/it]predicting train subjects:  39%|███▉      | 111/285 [03:43<05:32,  1.91s/it]predicting train subjects:  39%|███▉      | 112/285 [03:45<05:19,  1.85s/it]predicting train subjects:  40%|███▉      | 113/285 [03:47<05:20,  1.86s/it]predicting train subjects:  40%|████      | 114/285 [03:49<05:25,  1.91s/it]predicting train subjects:  40%|████      | 115/285 [03:51<05:36,  1.98s/it]predicting train subjects:  41%|████      | 116/285 [03:53<05:39,  2.01s/it]predicting train subjects:  41%|████      | 117/285 [03:55<05:45,  2.06s/it]predicting train subjects:  41%|████▏     | 118/285 [03:57<05:41,  2.05s/it]predicting train subjects:  42%|████▏     | 119/285 [03:59<05:42,  2.06s/it]predicting train subjects:  42%|████▏     | 120/285 [04:01<05:40,  2.06s/it]predicting train subjects:  42%|████▏     | 121/285 [04:03<05:26,  1.99s/it]predicting train subjects:  43%|████▎     | 122/285 [04:05<05:09,  1.90s/it]predicting train subjects:  43%|████▎     | 123/285 [04:06<05:01,  1.86s/it]predicting train subjects:  44%|████▎     | 124/285 [04:08<05:05,  1.90s/it]predicting train subjects:  44%|████▍     | 125/285 [04:10<05:05,  1.91s/it]predicting train subjects:  44%|████▍     | 126/285 [04:12<05:01,  1.90s/it]predicting train subjects:  45%|████▍     | 127/285 [04:14<05:00,  1.90s/it]predicting train subjects:  45%|████▍     | 128/285 [04:16<05:02,  1.93s/it]predicting train subjects:  45%|████▌     | 129/285 [04:18<04:55,  1.89s/it]predicting train subjects:  46%|████▌     | 130/285 [04:20<04:56,  1.91s/it]predicting train subjects:  46%|████▌     | 131/285 [04:22<04:53,  1.90s/it]predicting train subjects:  46%|████▋     | 132/285 [04:24<04:49,  1.89s/it]predicting train subjects:  47%|████▋     | 133/285 [04:26<04:50,  1.91s/it]predicting train subjects:  47%|████▋     | 134/285 [04:28<04:53,  1.94s/it]predicting train subjects:  47%|████▋     | 135/285 [04:30<04:53,  1.96s/it]predicting train subjects:  48%|████▊     | 136/285 [04:32<04:53,  1.97s/it]predicting train subjects:  48%|████▊     | 137/285 [04:34<04:52,  1.98s/it]predicting train subjects:  48%|████▊     | 138/285 [04:36<04:47,  1.96s/it]predicting train subjects:  49%|████▉     | 139/285 [04:38<04:47,  1.97s/it]predicting train subjects:  49%|████▉     | 140/285 [04:40<04:47,  1.98s/it]predicting train subjects:  49%|████▉     | 141/285 [04:41<04:39,  1.94s/it]predicting train subjects:  50%|████▉     | 142/285 [04:43<04:28,  1.88s/it]predicting train subjects:  50%|█████     | 143/285 [04:45<04:24,  1.86s/it]predicting train subjects:  51%|█████     | 144/285 [04:47<04:17,  1.83s/it]predicting train subjects:  51%|█████     | 145/285 [04:49<04:18,  1.85s/it]predicting train subjects:  51%|█████     | 146/285 [04:50<04:10,  1.80s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:52<04:01,  1.75s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:54<03:59,  1.75s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:55<03:57,  1.75s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:57<03:52,  1.72s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:59<03:51,  1.73s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:00<03:47,  1.71s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:02<03:45,  1.71s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:04<03:43,  1.71s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:06<03:40,  1.70s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:07<03:40,  1.71s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:09<03:41,  1.73s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:11<03:39,  1.73s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:12<03:36,  1.72s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:14<03:37,  1.74s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:16<03:33,  1.73s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:18<03:29,  1.70s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:19<03:28,  1.71s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:21<03:25,  1.70s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:23<03:22,  1.68s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:24<03:19,  1.68s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:26<03:17,  1.67s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:28<03:15,  1.67s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:29<03:19,  1.72s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:31<03:11,  1.67s/it]predicting train subjects:  60%|██████    | 171/285 [05:33<03:11,  1.68s/it]predicting train subjects:  60%|██████    | 172/285 [05:34<03:07,  1.66s/it]predicting train subjects:  61%|██████    | 173/285 [05:36<03:07,  1.67s/it]predicting train subjects:  61%|██████    | 174/285 [05:38<03:08,  1.70s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:40<03:05,  1.69s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:41<03:08,  1.73s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:43<03:04,  1.70s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:45<02:59,  1.68s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:46<02:57,  1.67s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:48<02:54,  1.67s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:50<02:54,  1.68s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:51<02:50,  1.65s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:53<02:46,  1.63s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:54<02:44,  1.62s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:56<02:46,  1.67s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:58<02:46,  1.68s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:59<02:40,  1.63s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:01<02:42,  1.68s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:03<02:40,  1.67s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:04<02:33,  1.61s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:06<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:07<02:18,  1.49s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:09<02:20,  1.52s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:10<02:21,  1.55s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:12<02:17,  1.53s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:14<02:26,  1.65s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:16<02:34,  1.75s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:18<02:41,  1.86s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:20<02:51,  1.99s/it]predicting train subjects:  70%|███████   | 200/285 [06:22<02:55,  2.07s/it]predicting train subjects:  71%|███████   | 201/285 [06:24<02:53,  2.07s/it]predicting train subjects:  71%|███████   | 202/285 [06:27<02:56,  2.12s/it]predicting train subjects:  71%|███████   | 203/285 [06:28<02:46,  2.03s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:30<02:43,  2.02s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:32<02:38,  1.98s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:34<02:37,  2.00s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:36<02:33,  1.97s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:38<02:32,  1.98s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:40<02:29,  1.97s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:42<02:25,  1.94s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:44<02:17,  1.86s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:46<02:16,  1.87s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:48<02:15,  1.88s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:49<02:09,  1.83s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:51<02:05,  1.79s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:53<02:01,  1.76s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:54<01:58,  1.74s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:56<01:56,  1.74s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:58<01:55,  1.75s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:00<01:52,  1.72s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:01<01:51,  1.74s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:03<01:48,  1.72s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:05<01:44,  1.69s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:06<01:40,  1.65s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:08<01:39,  1.66s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:10<01:37,  1.66s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:11<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [07:13<01:34,  1.65s/it]predicting train subjects:  80%|████████  | 229/285 [07:15<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [07:16<01:33,  1.69s/it]predicting train subjects:  81%|████████  | 231/285 [07:18<01:29,  1.67s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:20<01:36,  1.82s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:22<01:39,  1.91s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:24<01:40,  1.97s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:26<01:40,  2.01s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:29<01:40,  2.05s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:31<01:39,  2.06s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:33<01:40,  2.14s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:35<01:37,  2.13s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:37<01:35,  2.11s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:39<01:34,  2.14s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:42<01:33,  2.17s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:44<01:30,  2.15s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:46<01:33,  2.27s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:48<01:29,  2.24s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:51<01:28,  2.26s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:53<01:23,  2.21s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:55<01:20,  2.18s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:57<01:16,  2.12s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:59<01:09,  1.98s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:00<01:03,  1.86s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:02<01:00,  1.83s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:04<00:56,  1.77s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:05<00:53,  1.73s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:07<00:50,  1.70s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:09<00:49,  1.72s/it]predicting train subjects:  90%|█████████ | 257/285 [08:10<00:47,  1.70s/it]predicting train subjects:  91%|█████████ | 258/285 [08:12<00:45,  1.68s/it]predicting train subjects:  91%|█████████ | 259/285 [08:14<00:44,  1.71s/it]predicting train subjects:  91%|█████████ | 260/285 [08:15<00:42,  1.70s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:17<00:40,  1.68s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:19<00:38,  1.68s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:20<00:36,  1.67s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:22<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:23<00:32,  1.64s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:25<00:31,  1.63s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:27<00:29,  1.66s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:29<00:30,  1.77s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:31<00:29,  1.85s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:33<00:29,  1.94s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:35<00:27,  2.00s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:37<00:26,  2.05s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:39<00:24,  2.08s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:42<00:22,  2.07s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:44<00:20,  2.06s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:46<00:18,  2.10s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:48<00:17,  2.13s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:50<00:14,  2.10s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:52<00:12,  2.06s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:54<00:10,  2.09s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:56<00:08,  2.11s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:58<00:06,  2.13s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:01<00:04,  2.12s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:03<00:02,  2.10s/it]predicting train subjects: 100%|██████████| 285/285 [09:05<00:00,  2.14s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:30,  2.01s/it]Loading train:   1%|          | 2/285 [00:04<09:29,  2.01s/it]Loading train:   1%|          | 3/285 [00:06<09:45,  2.08s/it]Loading train:   1%|▏         | 4/285 [00:09<11:03,  2.36s/it]Loading train:   2%|▏         | 5/285 [00:11<10:32,  2.26s/it]Loading train:   2%|▏         | 6/285 [00:13<10:35,  2.28s/it]Loading train:   2%|▏         | 7/285 [00:16<11:19,  2.44s/it]Loading train:   3%|▎         | 8/285 [00:19<11:49,  2.56s/it]Loading train:   3%|▎         | 9/285 [00:21<11:40,  2.54s/it]Loading train:   4%|▎         | 10/285 [00:24<11:33,  2.52s/it]Loading train:   4%|▍         | 11/285 [00:26<11:28,  2.51s/it]Loading train:   4%|▍         | 12/285 [00:29<11:26,  2.51s/it]Loading train:   5%|▍         | 13/285 [00:31<11:09,  2.46s/it]Loading train:   5%|▍         | 14/285 [00:34<11:24,  2.53s/it]Loading train:   5%|▌         | 15/285 [00:37<11:59,  2.66s/it]Loading train:   6%|▌         | 16/285 [00:39<11:53,  2.65s/it]Loading train:   6%|▌         | 17/285 [00:42<11:45,  2.63s/it]Loading train:   6%|▋         | 18/285 [00:45<11:40,  2.62s/it]Loading train:   7%|▋         | 19/285 [00:48<12:37,  2.85s/it]Loading train:   7%|▋         | 20/285 [00:50<11:58,  2.71s/it]Loading train:   7%|▋         | 21/285 [00:53<11:47,  2.68s/it]Loading train:   8%|▊         | 22/285 [00:56<11:55,  2.72s/it]Loading train:   8%|▊         | 23/285 [00:58<11:26,  2.62s/it]Loading train:   8%|▊         | 24/285 [01:01<11:07,  2.56s/it]Loading train:   9%|▉         | 25/285 [01:03<10:49,  2.50s/it]Loading train:   9%|▉         | 26/285 [01:06<11:26,  2.65s/it]Loading train:   9%|▉         | 27/285 [01:09<11:33,  2.69s/it]Loading train:  10%|▉         | 28/285 [01:11<11:33,  2.70s/it]Loading train:  10%|█         | 29/285 [01:14<10:56,  2.56s/it]Loading train:  11%|█         | 30/285 [01:17<11:27,  2.70s/it]Loading train:  11%|█         | 31/285 [01:20<12:06,  2.86s/it]Loading train:  11%|█         | 32/285 [01:23<11:43,  2.78s/it]Loading train:  12%|█▏        | 33/285 [01:26<11:59,  2.86s/it]Loading train:  12%|█▏        | 34/285 [01:28<11:50,  2.83s/it]Loading train:  12%|█▏        | 35/285 [01:31<11:59,  2.88s/it]Loading train:  13%|█▎        | 36/285 [01:35<12:49,  3.09s/it]Loading train:  13%|█▎        | 37/285 [01:39<13:42,  3.32s/it]Loading train:  13%|█▎        | 38/285 [01:42<13:36,  3.30s/it]Loading train:  14%|█▎        | 39/285 [01:45<13:40,  3.34s/it]Loading train:  14%|█▍        | 40/285 [01:48<13:00,  3.19s/it]Loading train:  14%|█▍        | 41/285 [01:51<12:44,  3.13s/it]Loading train:  15%|█▍        | 42/285 [01:54<12:29,  3.08s/it]Loading train:  15%|█▌        | 43/285 [01:57<12:13,  3.03s/it]Loading train:  15%|█▌        | 44/285 [02:00<12:16,  3.05s/it]Loading train:  16%|█▌        | 45/285 [02:03<12:13,  3.06s/it]Loading train:  16%|█▌        | 46/285 [02:06<11:55,  2.99s/it]Loading train:  16%|█▋        | 47/285 [02:09<11:48,  2.98s/it]Loading train:  17%|█▋        | 48/285 [02:12<12:10,  3.08s/it]Loading train:  17%|█▋        | 49/285 [02:16<12:33,  3.19s/it]Loading train:  18%|█▊        | 50/285 [02:19<12:55,  3.30s/it]Loading train:  18%|█▊        | 51/285 [02:23<13:07,  3.37s/it]Loading train:  18%|█▊        | 52/285 [02:26<12:59,  3.35s/it]Loading train:  19%|█▊        | 53/285 [02:30<12:50,  3.32s/it]Loading train:  19%|█▉        | 54/285 [02:33<12:35,  3.27s/it]Loading train:  19%|█▉        | 55/285 [02:36<12:53,  3.36s/it]Loading train:  20%|█▉        | 56/285 [02:40<13:22,  3.51s/it]Loading train:  20%|██        | 57/285 [02:43<12:37,  3.32s/it]Loading train:  20%|██        | 58/285 [02:47<12:52,  3.40s/it]Loading train:  21%|██        | 59/285 [02:49<12:05,  3.21s/it]Loading train:  21%|██        | 60/285 [02:53<12:02,  3.21s/it]Loading train:  21%|██▏       | 61/285 [02:56<11:56,  3.20s/it]Loading train:  22%|██▏       | 62/285 [02:59<12:02,  3.24s/it]Loading train:  22%|██▏       | 63/285 [03:02<12:09,  3.28s/it]Loading train:  22%|██▏       | 64/285 [03:06<12:41,  3.45s/it]Loading train:  23%|██▎       | 65/285 [03:10<13:01,  3.55s/it]Loading train:  23%|██▎       | 66/285 [03:14<12:59,  3.56s/it]Loading train:  24%|██▎       | 67/285 [03:17<12:14,  3.37s/it]Loading train:  24%|██▍       | 68/285 [03:20<12:10,  3.37s/it]Loading train:  24%|██▍       | 69/285 [03:23<11:25,  3.17s/it]Loading train:  25%|██▍       | 70/285 [03:27<12:05,  3.38s/it]Loading train:  25%|██▍       | 71/285 [03:30<12:02,  3.38s/it]Loading train:  25%|██▌       | 72/285 [03:33<11:11,  3.15s/it]Loading train:  26%|██▌       | 73/285 [03:35<10:54,  3.09s/it]Loading train:  26%|██▌       | 74/285 [03:39<10:51,  3.09s/it]Loading train:  26%|██▋       | 75/285 [03:41<10:14,  2.93s/it]Loading train:  27%|██▋       | 76/285 [03:44<10:40,  3.07s/it]Loading train:  27%|██▋       | 77/285 [03:47<10:33,  3.04s/it]Loading train:  27%|██▋       | 78/285 [03:50<10:21,  3.00s/it]Loading train:  28%|██▊       | 79/285 [03:54<11:17,  3.29s/it]Loading train:  28%|██▊       | 80/285 [03:58<11:39,  3.41s/it]Loading train:  28%|██▊       | 81/285 [04:02<12:22,  3.64s/it]Loading train:  29%|██▉       | 82/285 [04:05<11:00,  3.26s/it]Loading train:  29%|██▉       | 83/285 [04:07<10:20,  3.07s/it]Loading train:  29%|██▉       | 84/285 [04:10<09:58,  2.98s/it]Loading train:  30%|██▉       | 85/285 [04:14<10:46,  3.23s/it]Loading train:  30%|███       | 86/285 [04:18<11:24,  3.44s/it]Loading train:  31%|███       | 87/285 [04:21<11:14,  3.40s/it]Loading train:  31%|███       | 88/285 [04:24<11:09,  3.40s/it]Loading train:  31%|███       | 89/285 [04:28<11:01,  3.37s/it]Loading train:  32%|███▏      | 90/285 [04:31<10:58,  3.37s/it]Loading train:  32%|███▏      | 91/285 [04:35<11:18,  3.50s/it]Loading train:  32%|███▏      | 92/285 [04:38<11:06,  3.45s/it]Loading train:  33%|███▎      | 93/285 [04:41<10:32,  3.30s/it]Loading train:  33%|███▎      | 94/285 [04:44<10:25,  3.28s/it]Loading train:  33%|███▎      | 95/285 [04:48<10:37,  3.35s/it]Loading train:  34%|███▎      | 96/285 [04:51<10:20,  3.28s/it]Loading train:  34%|███▍      | 97/285 [04:54<09:49,  3.14s/it]Loading train:  34%|███▍      | 98/285 [04:57<09:57,  3.20s/it]Loading train:  35%|███▍      | 99/285 [05:01<10:33,  3.40s/it]Loading train:  35%|███▌      | 100/285 [05:04<10:19,  3.35s/it]Loading train:  35%|███▌      | 101/285 [05:08<10:09,  3.31s/it]Loading train:  36%|███▌      | 102/285 [05:11<10:37,  3.48s/it]Loading train:  36%|███▌      | 103/285 [05:15<10:49,  3.57s/it]Loading train:  36%|███▋      | 104/285 [05:19<11:22,  3.77s/it]Loading train:  37%|███▋      | 105/285 [05:23<11:03,  3.68s/it]Loading train:  37%|███▋      | 106/285 [05:27<10:56,  3.67s/it]Loading train:  38%|███▊      | 107/285 [05:30<10:41,  3.60s/it]Loading train:  38%|███▊      | 108/285 [05:32<09:33,  3.24s/it]Loading train:  38%|███▊      | 109/285 [05:35<08:59,  3.07s/it]Loading train:  39%|███▊      | 110/285 [05:38<08:40,  2.98s/it]Loading train:  39%|███▉      | 111/285 [05:41<09:04,  3.13s/it]Loading train:  39%|███▉      | 112/285 [05:45<09:21,  3.25s/it]Loading train:  40%|███▉      | 113/285 [05:48<09:01,  3.15s/it]Loading train:  40%|████      | 114/285 [05:51<09:05,  3.19s/it]Loading train:  40%|████      | 115/285 [05:54<09:11,  3.25s/it]Loading train:  41%|████      | 116/285 [05:58<09:13,  3.28s/it]Loading train:  41%|████      | 117/285 [06:01<09:00,  3.22s/it]Loading train:  41%|████▏     | 118/285 [06:04<09:10,  3.30s/it]Loading train:  42%|████▏     | 119/285 [06:07<08:56,  3.23s/it]Loading train:  42%|████▏     | 120/285 [06:11<08:56,  3.25s/it]Loading train:  42%|████▏     | 121/285 [06:14<08:44,  3.20s/it]Loading train:  43%|████▎     | 122/285 [06:17<08:30,  3.13s/it]Loading train:  43%|████▎     | 123/285 [06:20<08:14,  3.05s/it]Loading train:  44%|████▎     | 124/285 [06:23<08:26,  3.15s/it]Loading train:  44%|████▍     | 125/285 [06:25<07:46,  2.92s/it]Loading train:  44%|████▍     | 126/285 [06:28<07:26,  2.81s/it]Loading train:  45%|████▍     | 127/285 [06:30<07:02,  2.68s/it]Loading train:  45%|████▍     | 128/285 [06:33<06:48,  2.60s/it]Loading train:  45%|████▌     | 129/285 [06:36<07:13,  2.78s/it]Loading train:  46%|████▌     | 130/285 [06:39<07:18,  2.83s/it]Loading train:  46%|████▌     | 131/285 [06:42<07:22,  2.87s/it]Loading train:  46%|████▋     | 132/285 [06:44<07:06,  2.79s/it]Loading train:  47%|████▋     | 133/285 [06:47<07:08,  2.82s/it]Loading train:  47%|████▋     | 134/285 [06:50<07:00,  2.78s/it]Loading train:  47%|████▋     | 135/285 [06:52<06:45,  2.70s/it]Loading train:  48%|████▊     | 136/285 [06:55<06:51,  2.76s/it]Loading train:  48%|████▊     | 137/285 [06:58<06:48,  2.76s/it]Loading train:  48%|████▊     | 138/285 [07:01<06:48,  2.78s/it]Loading train:  49%|████▉     | 139/285 [07:04<07:03,  2.90s/it]Loading train:  49%|████▉     | 140/285 [07:07<06:47,  2.81s/it]Loading train:  49%|████▉     | 141/285 [07:10<06:52,  2.86s/it]Loading train:  50%|████▉     | 142/285 [07:12<06:36,  2.77s/it]Loading train:  50%|█████     | 143/285 [07:16<06:52,  2.90s/it]Loading train:  51%|█████     | 144/285 [07:18<06:48,  2.90s/it]Loading train:  51%|█████     | 145/285 [07:21<06:31,  2.80s/it]Loading train:  51%|█████     | 146/285 [07:23<06:14,  2.69s/it]Loading train:  52%|█████▏    | 147/285 [07:26<06:23,  2.78s/it]Loading train:  52%|█████▏    | 148/285 [07:29<06:12,  2.72s/it]Loading train:  52%|█████▏    | 149/285 [07:31<06:00,  2.65s/it]Loading train:  53%|█████▎    | 150/285 [07:35<06:13,  2.77s/it]Loading train:  53%|█████▎    | 151/285 [07:37<05:52,  2.63s/it]Loading train:  53%|█████▎    | 152/285 [07:40<06:09,  2.78s/it]Loading train:  54%|█████▎    | 153/285 [07:43<06:03,  2.75s/it]Loading train:  54%|█████▍    | 154/285 [07:45<05:48,  2.66s/it]Loading train:  54%|█████▍    | 155/285 [07:48<05:40,  2.62s/it]Loading train:  55%|█████▍    | 156/285 [07:50<05:47,  2.69s/it]Loading train:  55%|█████▌    | 157/285 [07:53<05:51,  2.74s/it]Loading train:  55%|█████▌    | 158/285 [07:56<05:41,  2.69s/it]Loading train:  56%|█████▌    | 159/285 [07:59<05:35,  2.66s/it]Loading train:  56%|█████▌    | 160/285 [08:01<05:28,  2.63s/it]Loading train:  56%|█████▋    | 161/285 [08:03<05:18,  2.57s/it]Loading train:  57%|█████▋    | 162/285 [08:06<05:16,  2.57s/it]Loading train:  57%|█████▋    | 163/285 [08:09<05:35,  2.75s/it]Loading train:  58%|█████▊    | 164/285 [08:12<05:18,  2.63s/it]Loading train:  58%|█████▊    | 165/285 [08:14<05:19,  2.66s/it]Loading train:  58%|█████▊    | 166/285 [08:17<05:18,  2.68s/it]Loading train:  59%|█████▊    | 167/285 [08:20<05:11,  2.64s/it]Loading train:  59%|█████▉    | 168/285 [08:22<04:59,  2.56s/it]Loading train:  59%|█████▉    | 169/285 [08:25<05:12,  2.69s/it]Loading train:  60%|█████▉    | 170/285 [08:27<05:02,  2.63s/it]Loading train:  60%|██████    | 171/285 [08:30<05:14,  2.76s/it]Loading train:  60%|██████    | 172/285 [08:33<05:13,  2.78s/it]Loading train:  61%|██████    | 173/285 [08:36<04:53,  2.62s/it]Loading train:  61%|██████    | 174/285 [08:38<04:50,  2.62s/it]Loading train:  61%|██████▏   | 175/285 [08:41<04:46,  2.61s/it]Loading train:  62%|██████▏   | 176/285 [08:43<04:35,  2.53s/it]Loading train:  62%|██████▏   | 177/285 [08:46<04:29,  2.50s/it]Loading train:  62%|██████▏   | 178/285 [08:49<04:43,  2.65s/it]Loading train:  63%|██████▎   | 179/285 [08:51<04:33,  2.58s/it]Loading train:  63%|██████▎   | 180/285 [08:52<03:50,  2.19s/it]Loading train:  64%|██████▎   | 181/285 [08:54<03:20,  1.92s/it]Loading train:  64%|██████▍   | 182/285 [08:55<03:04,  1.79s/it]Loading train:  64%|██████▍   | 183/285 [08:57<03:11,  1.87s/it]Loading train:  65%|██████▍   | 184/285 [08:59<03:11,  1.89s/it]Loading train:  65%|██████▍   | 185/285 [09:00<02:50,  1.70s/it]Loading train:  65%|██████▌   | 186/285 [09:02<02:43,  1.65s/it]Loading train:  66%|██████▌   | 187/285 [09:03<02:34,  1.58s/it]Loading train:  66%|██████▌   | 188/285 [09:05<02:26,  1.51s/it]Loading train:  66%|██████▋   | 189/285 [09:06<02:16,  1.43s/it]Loading train:  67%|██████▋   | 190/285 [09:07<02:09,  1.36s/it]Loading train:  67%|██████▋   | 191/285 [09:08<02:03,  1.31s/it]Loading train:  67%|██████▋   | 192/285 [09:10<02:05,  1.34s/it]Loading train:  68%|██████▊   | 193/285 [09:11<02:03,  1.34s/it]Loading train:  68%|██████▊   | 194/285 [09:12<01:55,  1.27s/it]Loading train:  68%|██████▊   | 195/285 [09:13<01:55,  1.28s/it]Loading train:  69%|██████▉   | 196/285 [09:15<02:10,  1.47s/it]Loading train:  69%|██████▉   | 197/285 [09:17<02:05,  1.43s/it]Loading train:  69%|██████▉   | 198/285 [09:18<02:06,  1.45s/it]Loading train:  70%|██████▉   | 199/285 [09:19<02:01,  1.41s/it]Loading train:  70%|███████   | 200/285 [09:21<02:08,  1.51s/it]Loading train:  71%|███████   | 201/285 [09:23<02:10,  1.55s/it]Loading train:  71%|███████   | 202/285 [09:24<02:09,  1.56s/it]Loading train:  71%|███████   | 203/285 [09:26<02:05,  1.53s/it]Loading train:  72%|███████▏  | 204/285 [09:27<02:05,  1.55s/it]Loading train:  72%|███████▏  | 205/285 [09:29<02:09,  1.62s/it]Loading train:  72%|███████▏  | 206/285 [09:31<02:13,  1.69s/it]Loading train:  73%|███████▎  | 207/285 [09:33<02:10,  1.67s/it]Loading train:  73%|███████▎  | 208/285 [09:35<02:11,  1.70s/it]Loading train:  73%|███████▎  | 209/285 [09:36<02:14,  1.77s/it]Loading train:  74%|███████▎  | 210/285 [09:39<02:21,  1.89s/it]Loading train:  74%|███████▍  | 211/285 [09:40<02:13,  1.81s/it]Loading train:  74%|███████▍  | 212/285 [09:41<01:59,  1.64s/it]Loading train:  75%|███████▍  | 213/285 [09:43<01:54,  1.59s/it]Loading train:  75%|███████▌  | 214/285 [09:45<01:56,  1.64s/it]Loading train:  75%|███████▌  | 215/285 [09:47<01:58,  1.70s/it]Loading train:  76%|███████▌  | 216/285 [09:48<02:02,  1.77s/it]Loading train:  76%|███████▌  | 217/285 [09:51<02:06,  1.87s/it]Loading train:  76%|███████▋  | 218/285 [09:52<02:04,  1.85s/it]Loading train:  77%|███████▋  | 219/285 [09:54<02:01,  1.84s/it]Loading train:  77%|███████▋  | 220/285 [09:56<02:01,  1.87s/it]Loading train:  78%|███████▊  | 221/285 [09:58<02:01,  1.89s/it]Loading train:  78%|███████▊  | 222/285 [10:00<02:06,  2.01s/it]Loading train:  78%|███████▊  | 223/285 [10:02<01:53,  1.83s/it]Loading train:  79%|███████▊  | 224/285 [10:04<01:50,  1.81s/it]Loading train:  79%|███████▉  | 225/285 [10:06<01:54,  1.91s/it]Loading train:  79%|███████▉  | 226/285 [10:08<01:58,  2.00s/it]Loading train:  80%|███████▉  | 227/285 [10:10<01:54,  1.97s/it]Loading train:  80%|████████  | 228/285 [10:12<01:54,  2.01s/it]Loading train:  80%|████████  | 229/285 [10:14<01:47,  1.91s/it]Loading train:  81%|████████  | 230/285 [10:16<01:48,  1.98s/it]Loading train:  81%|████████  | 231/285 [10:18<01:50,  2.05s/it]Loading train:  81%|████████▏ | 232/285 [10:20<01:52,  2.12s/it]Loading train:  82%|████████▏ | 233/285 [10:23<01:55,  2.21s/it]Loading train:  82%|████████▏ | 234/285 [10:24<01:44,  2.04s/it]Loading train:  82%|████████▏ | 235/285 [10:27<01:45,  2.11s/it]Loading train:  83%|████████▎ | 236/285 [10:28<01:38,  2.01s/it]Loading train:  83%|████████▎ | 237/285 [10:30<01:33,  1.94s/it]Loading train:  84%|████████▎ | 238/285 [10:32<01:36,  2.06s/it]Loading train:  84%|████████▍ | 239/285 [10:35<01:37,  2.11s/it]Loading train:  84%|████████▍ | 240/285 [10:37<01:35,  2.12s/it]Loading train:  85%|████████▍ | 241/285 [10:39<01:34,  2.15s/it]Loading train:  85%|████████▍ | 242/285 [10:41<01:28,  2.06s/it]Loading train:  85%|████████▌ | 243/285 [10:43<01:27,  2.08s/it]Loading train:  86%|████████▌ | 244/285 [10:45<01:27,  2.13s/it]Loading train:  86%|████████▌ | 245/285 [10:47<01:24,  2.12s/it]Loading train:  86%|████████▋ | 246/285 [10:50<01:29,  2.29s/it]Loading train:  87%|████████▋ | 247/285 [10:52<01:27,  2.31s/it]Loading train:  87%|████████▋ | 248/285 [10:55<01:23,  2.26s/it]Loading train:  87%|████████▋ | 249/285 [10:57<01:19,  2.21s/it]Loading train:  88%|████████▊ | 250/285 [10:59<01:13,  2.10s/it]Loading train:  88%|████████▊ | 251/285 [11:00<01:10,  2.06s/it]Loading train:  88%|████████▊ | 252/285 [11:02<01:06,  2.02s/it]Loading train:  89%|████████▉ | 253/285 [11:04<01:00,  1.91s/it]Loading train:  89%|████████▉ | 254/285 [11:06<01:03,  2.06s/it]Loading train:  89%|████████▉ | 255/285 [11:08<00:58,  1.94s/it]Loading train:  90%|████████▉ | 256/285 [11:10<00:55,  1.92s/it]Loading train:  90%|█████████ | 257/285 [11:12<00:53,  1.91s/it]Loading train:  91%|█████████ | 258/285 [11:13<00:47,  1.77s/it]Loading train:  91%|█████████ | 259/285 [11:15<00:46,  1.78s/it]Loading train:  91%|█████████ | 260/285 [11:16<00:41,  1.65s/it]Loading train:  92%|█████████▏| 261/285 [11:18<00:38,  1.61s/it]Loading train:  92%|█████████▏| 262/285 [11:20<00:39,  1.70s/it]Loading train:  92%|█████████▏| 263/285 [11:22<00:39,  1.81s/it]Loading train:  93%|█████████▎| 264/285 [11:24<00:39,  1.86s/it]Loading train:  93%|█████████▎| 265/285 [11:26<00:39,  1.95s/it]Loading train:  93%|█████████▎| 266/285 [11:28<00:36,  1.94s/it]Loading train:  94%|█████████▎| 267/285 [11:30<00:33,  1.86s/it]Loading train:  94%|█████████▍| 268/285 [11:32<00:33,  1.96s/it]Loading train:  94%|█████████▍| 269/285 [11:34<00:33,  2.11s/it]Loading train:  95%|█████████▍| 270/285 [11:36<00:30,  2.03s/it]Loading train:  95%|█████████▌| 271/285 [11:38<00:28,  2.01s/it]Loading train:  95%|█████████▌| 272/285 [11:40<00:24,  1.86s/it]Loading train:  96%|█████████▌| 273/285 [11:42<00:22,  1.91s/it]Loading train:  96%|█████████▌| 274/285 [11:44<00:20,  1.89s/it]Loading train:  96%|█████████▋| 275/285 [11:46<00:19,  1.95s/it]Loading train:  97%|█████████▋| 276/285 [11:48<00:17,  1.97s/it]Loading train:  97%|█████████▋| 277/285 [11:50<00:16,  2.05s/it]Loading train:  98%|█████████▊| 278/285 [11:52<00:14,  2.10s/it]Loading train:  98%|█████████▊| 279/285 [11:54<00:12,  2.12s/it]Loading train:  98%|█████████▊| 280/285 [11:56<00:09,  1.89s/it]Loading train:  99%|█████████▊| 281/285 [11:57<00:07,  1.80s/it]Loading train:  99%|█████████▉| 282/285 [11:59<00:05,  1.71s/it]Loading train:  99%|█████████▉| 283/285 [12:00<00:03,  1.66s/it]Loading train: 100%|█████████▉| 284/285 [12:02<00:01,  1.57s/it]Loading train: 100%|██████████| 285/285 [12:03<00:00,  1.58s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:15, 17.93it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:13, 20.21it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:11, 24.85it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:11, 23.75it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:09, 26.91it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:09, 27.62it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:09, 27.02it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:08, 30.44it/s]concatenating: train:  18%|█▊        | 50/285 [00:01<00:05, 40.67it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:04, 52.22it/s]concatenating: train:  27%|██▋       | 77/285 [00:01<00:04, 47.56it/s]concatenating: train:  35%|███▌      | 101/285 [00:01<00:02, 62.62it/s]concatenating: train:  41%|████      | 117/285 [00:01<00:02, 76.12it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:02, 68.32it/s]concatenating: train:  54%|█████▍    | 155/285 [00:02<00:01, 86.80it/s]concatenating: train:  60%|█████▉    | 170/285 [00:02<00:01, 60.44it/s]concatenating: train:  64%|██████▍   | 182/285 [00:02<00:01, 69.99it/s]concatenating: train:  74%|███████▍  | 211/285 [00:02<00:00, 89.63it/s]concatenating: train:  85%|████████▍ | 241/285 [00:02<00:00, 111.48it/s]concatenating: train:  91%|█████████ | 260/285 [00:03<00:00, 86.24it/s] concatenating: train:  99%|█████████▊| 281/285 [00:03<00:00, 104.31it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 88.09it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.89s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.81s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 61.56it/s]
Epoch 00053: val_mDice did not improve from 0.46501
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
{'val_loss': [1032.575056984311, 1471.5117351895287, 1182.3750531673431, 1357.8424482629412, 1485.6854619582493, 1335.9912110737391, 1465.8563616616386, 1553.9000316347394, 1672.7781857706252, 1459.9245603538695, 1627.6380437612534, 1701.0348782766432, 1756.8533000832513, 1527.3821074962616, 1568.4658601511092, 1754.2643041553952, 1730.1076894147056, 1853.399734270005, 2074.2988419703074, 2043.9216905945823, 1916.0230423155285, 1930.45667215756, 1591.472287200746, 1642.4721884727478, 1837.657696695555, 1890.4709601969946, 1969.0830266759508, 1734.8311176186517, 1739.1695955991745, 1971.4043840680804, 1770.6343859490894, 2055.5516158399128, 1852.6024843397595, 1962.9187350273132, 1840.744011311304, 2024.4925647008986, 1776.8184209891729, 1926.3770427930922, 1923.6996143886022, 1927.2648972102575, 1927.9418134348732, 2039.0677432900384, 1916.3711244492304, 1889.226006996064, 1930.0818397771745, 2133.4317649829954, 2155.824193653606, 2007.1192292485919, 2135.799648915018, 2041.4160401480538, 2000.0088587715513, 2156.8631016186305, 2213.8595939477286], 'val_acc': [0.9245741906620207, 0.926423986752828, 0.9365338825044178, 0.9372436148779733, 0.9371680588949294, 0.9411492659932091, 0.9400938465481713, 0.9407394698687962, 0.9385371066275097, 0.9413026486124311, 0.9407211343447367, 0.9382073907625108, 0.9385118910244533, 0.9416254304704212, 0.9422710424377805, 0.9413072097869146, 0.9412980732463655, 0.9400366516340346, 0.9376579835301354, 0.9386103351910909, 0.9394368188721793, 0.9410920285043263, 0.9420261042458671, 0.9445787724994478, 0.9410851824851263, 0.9424862861633301, 0.9428250676109677, 0.9433676969437372, 0.9454349960599627, 0.9417903139477685, 0.9437019001869928, 0.9423259922436306, 0.9420283748990014, 0.9431089957555135, 0.945087024143764, 0.9423008334069025, 0.942671693506695, 0.9433379230045137, 0.9434706739016941, 0.9414652217002142, 0.9446222555069697, 0.943086062158857, 0.9430883555185228, 0.9433310315722511, 0.9429990819522313, 0.94255721001398, 0.9421932214782351, 0.9445718839055016, 0.9432761158261981, 0.9430425819896516, 0.9421084920565287, 0.9392856927145095, 0.9413186623936608], 'val_mDice': [0.3695128758748372, 0.35237393333088785, 0.423155885721956, 0.42690340163452284, 0.41983165308123543, 0.43823889093030066, 0.43948657704251154, 0.4251397589132899, 0.41193700226999463, 0.4411407464316913, 0.44125346041151453, 0.4153336582794076, 0.41163589237701326, 0.4370543896442368, 0.4460738803304377, 0.43561624948467526, 0.4329144347991262, 0.4227460154465267, 0.4048692284240609, 0.4125766860587256, 0.42617244220205713, 0.42707551057849613, 0.46500560854162487, 0.458090287234102, 0.43368341667311533, 0.43800664427024977, 0.4361436945341882, 0.4530427908258779, 0.45880858564660665, 0.4287485015534219, 0.45206003494205926, 0.4178912568660009, 0.4421879415001188, 0.44259420888764517, 0.45740597003272604, 0.42552322344410987, 0.4577509019346464, 0.442366150873048, 0.44485377342928023, 0.4313332810997963, 0.4471844243151801, 0.4316614220539729, 0.4500553696638062, 0.4490916934751329, 0.4399306767043613, 0.4214716835745743, 0.42244134346644086, 0.44838330362524303, 0.4304104032261031, 0.43412618339061737, 0.4346533087747438, 0.41849085901464733, 0.4179169940096991], 'loss': [1316.8270232960142, 708.1746255474925, 602.4134312326885, 546.4008382867476, 507.4924718600513, 477.680971756408, 455.1459693474785, 438.9262337008951, 424.7039145739386, 409.7941687315306, 397.5145221634455, 390.1240889440963, 380.58450230307403, 375.1480743308184, 365.3373975899032, 360.5065459822652, 353.1452775039217, 347.55136487294146, 341.7594804059616, 337.29153410317883, 331.16391375990116, 328.7305980422765, 324.49685044120406, 322.60425011785776, 318.8741280338956, 313.9846913543813, 310.8260667432083, 307.76922263238663, 305.3223935523106, 301.55526089158064, 299.2209442591699, 297.33721576703175, 296.19912246695276, 293.0254959509463, 290.32110668364027, 289.96991774597814, 285.71472759846205, 283.66026548845633, 284.17141290609146, 280.5757981920509, 279.6740091565443, 277.33117656071613, 274.0562274874762, 274.02839830971095, 272.85300381573865, 271.1041187957828, 268.7326168533187, 268.7139726134654, 266.62070861192757, 264.8310294738734, 264.2665738807562, 263.005522928556, 261.227098225582], 'acc': [0.8859438945131539, 0.9100626945518587, 0.9170540772422973, 0.91998369322132, 0.9221548721214377, 0.9239386851465355, 0.9251436647799793, 0.9266189006176072, 0.9273573144658444, 0.9282164816362725, 0.9287975672607319, 0.9294204219058227, 0.9300293778325175, 0.9305336666355387, 0.9313435191153928, 0.9323093711766798, 0.9325447500338094, 0.9329214334166163, 0.9331574573529716, 0.9339277829212882, 0.9342038524111779, 0.9345735365401717, 0.9349400912357108, 0.9350171373923298, 0.9353292375969615, 0.9356711427439655, 0.9359532798993604, 0.9365055593585655, 0.9365479637943575, 0.9371386382054427, 0.9373336731755529, 0.9372692327060888, 0.9371677402106006, 0.9373967910240398, 0.9377627219679453, 0.9381430873710893, 0.9382132526098568, 0.9382924114506392, 0.9384484707861018, 0.9389840629327405, 0.9387878441778432, 0.9390502183543525, 0.939347188953538, 0.9396546094293927, 0.9392286895073882, 0.9394353804547869, 0.9396535684912104, 0.9397005140034477, 0.9398369940462107, 0.9403356290033655, 0.9401736348402024, 0.9402324223486196, 0.9405643102840948], 'mDice': [0.28723223726454555, 0.4963001491294009, 0.5601899088038078, 0.5955330914607139, 0.6212644591849963, 0.6423849096550104, 0.657586820924905, 0.6695466865366172, 0.6801302782115344, 0.6903829658470426, 0.699779737678272, 0.705204752844286, 0.711960412356489, 0.7163035740667578, 0.7231521758703177, 0.7272737234664235, 0.7326733703348525, 0.7368082564323423, 0.7410602313786866, 0.7444320690064203, 0.7484252827577056, 0.7510754127182527, 0.7541196239185352, 0.755422494603141, 0.7579955534827441, 0.7618954124215345, 0.7641548012547211, 0.7666128799592182, 0.7681376082786412, 0.7714730938988107, 0.7727448836167193, 0.7744746979822285, 0.7751185858160033, 0.7776422037746443, 0.7796634948733963, 0.7802089583283103, 0.7831696146068164, 0.7846422576941069, 0.7845031183212278, 0.787460026493738, 0.7875696553852095, 0.7896955055792437, 0.7919966463686897, 0.7924616418869389, 0.7928268499794506, 0.7942020271195367, 0.7960362859330289, 0.7962859807180858, 0.7973873448183432, 0.7990227062991296, 0.7994449339966473, 0.8002883931311289, 0.8016341529371469]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  64920       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 120)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   28860       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 120)  0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   64860       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 60)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   7230        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16230       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________2019-06-30 20:33:07.022758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 20:33:07.022891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 20:33:07.022914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 20:33:07.022927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 20:33:07.023503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

dropout_5 (Dropout)             (None, 52, 52, 30)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   403         dropout_5[0][0]                  
==================================================================================================
Total params: 412,363
Trainable params: 411,163
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [2.45357524e+01 1.20808280e+01 2.83540199e+01 3.52403467e+00
 1.02430434e+01 2.67099910e+00 3.19605001e+01 4.25814537e+01
 3.25211438e+01 5.00837070e+00 1.11201025e+02 7.27972247e+01
 8.67943023e-02]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 24s - loss: 1108.5252 - acc: 0.9114 - mDice: 0.3507 - val_loss: 870.1433 - val_acc: 0.9437 - val_mDice: 0.4321

Epoch 00001: val_mDice improved from -inf to 0.43209, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 606.9794 - acc: 0.9316 - mDice: 0.5521 - val_loss: 874.6825 - val_acc: 0.9475 - val_mDice: 0.4826

Epoch 00002: val_mDice improved from 0.43209 to 0.48264, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 517.7241 - acc: 0.9364 - mDice: 0.6122 - val_loss: 924.4262 - val_acc: 0.9482 - val_mDice: 0.5077

Epoch 00003: val_mDice improved from 0.48264 to 0.50768, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 15s - loss: 470.1758 - acc: 0.9385 - mDice: 0.6446 - val_loss: 1064.4143 - val_acc: 0.9473 - val_mDice: 0.4906

Epoch 00004: val_mDice did not improve from 0.50768
Epoch 5/300
 - 15s - loss: 435.6492 - acc: 0.9400 - mDice: 0.6691 - val_loss: 1034.1658 - val_acc: 0.9482 - val_mDice: 0.5088

Epoch 00005: val_mDice improved from 0.50768 to 0.50877, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 15s - loss: 412.4012 - acc: 0.9407 - mDice: 0.6860 - val_loss: 1194.7813 - val_acc: 0.9453 - val_mDice: 0.4853

Epoch 00006: val_mDice did not improve from 0.50877
Epoch 7/300
 - 14s - loss: 394.0802 - acc: 0.9416 - mDice: 0.6994 - val_loss: 1081.3871 - val_acc: 0.9466 - val_mDice: 0.5183

Epoch 00007: val_mDice improved from 0.50877 to 0.51831, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 15s - loss: 381.0237 - acc: 0.9423 - mDice: 0.7091 - val_loss: 1048.6893 - val_acc: 0.9476 - val_mDice: 0.5260

Epoch 00008: val_mDice improved from 0.51831 to 0.52603, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 15s - loss: 367.2144 - acc: 0.9429 - mDice: 0.7195 - val_loss: 1178.0802 - val_acc: 0.9464 - val_mDice: 0.5085

Epoch 00009: val_mDice did not improve from 0.52603
Epoch 10/300
 - 15s - loss: 360.1389 - acc: 0.9438 - mDice: 0.7244 - val_loss: 1094.9103 - val_acc: 0.9454 - val_mDice: 0.5362

Epoch 00010: val_mDice improved from 0.52603 to 0.53624, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 350.8214 - acc: 0.9443 - mDice: 0.7317 - val_loss: 1048.7892 - val_acc: 0.9455 - val_mDice: 0.5459

Epoch 00011: val_mDice improved from 0.53624 to 0.54587, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 15s - loss: 340.9707 - acc: 0.9450 - mDice: 0.7390 - val_loss: 1103.2716 - val_acc: 0.9468 - val_mDice: 0.5439

Epoch 00012: val_mDice did not improve from 0.54587
Epoch 13/300
 - 15s - loss: 333.5788 - acc: 0.9452 - mDice: 0.7449 - val_loss: 1083.9511 - val_acc: 0.9502 - val_mDice: 0.5417

Epoch 00013: val_mDice did not improve from 0.54587
Epoch 14/300
 - 15s - loss: 329.3744 - acc: 0.9455 - mDice: 0.7478 - val_loss: 1183.6142 - val_acc: 0.9486 - val_mDice: 0.5348

Epoch 00014: val_mDice did not improve from 0.54587
Epoch 15/300
 - 15s - loss: 322.9324 - acc: 0.9457 - mDice: 0.7528 - val_loss: 1040.4696 - val_acc: 0.9484 - val_mDice: 0.5602

Epoch 00015: val_mDice improved from 0.54587 to 0.56018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 14s - loss: 318.8756 - acc: 0.9458 - mDice: 0.7557 - val_loss: 1159.7295 - val_acc: 0.9474 - val_mDice: 0.5462

Epoch 00016: val_mDice did not improve from 0.56018
Epoch 17/300
 - 14s - loss: 313.0620 - acc: 0.9462 - mDice: 0.7602 - val_loss: 1115.4275 - val_acc: 0.9492 - val_mDice: 0.5405

Epoch 00017: val_mDice did not improve from 0.56018
Epoch 18/300
 - 15s - loss: 309.3243 - acc: 0.9460 - mDice: 0.7630 - val_loss: 1144.2273 - val_acc: 0.9457 - val_mDice: 0.5463

Epoch 00018: val_mDice did not improve from 0.56018
Epoch 19/300
 - 16s - loss: 306.0438 - acc: 0.9466 - mDice: 0.7656 - val_loss: 1127.0349 - val_acc: 0.9475 - val_mDice: 0.5477

Epoch 00019: val_mDice did not improve from 0.56018
Epoch 20/300
 - 16s - loss: 300.6680 - acc: 0.9469 - mDice: 0.7696 - val_loss: 1322.0917 - val_acc: 0.9462 - val_mDice: 0.5233

Epoch 00020: val_mDice did not improve from 0.56018
Epoch 21/300
 - 15s - loss: 298.2375 - acc: 0.9471 - mDice: 0.7713 - val_loss: 1395.9773 - val_acc: 0.9443 - val_mDice: 0.5128

Epoch 00021: val_mDice did not improve from 0.56018
Epoch 22/300
 - 17s - loss: 294.9103 - acc: 0.9471 - mDice: 0.7740 - val_loss: 1237.6765 - val_acc: 0.9487 - val_mDice: 0.5415

Epoch 00022: val_mDice did not improve from 0.56018
Epoch 23/300
 - 16s - loss: 291.5133 - acc: 0.9478 - mDice: 0.7762 - val_loss: 1164.0175 - val_acc: 0.9486 - val_mDice: 0.5471

Epoch 00023: val_mDice did not improve from 0.56018
Epoch 24/300
 - 15s - loss: 287.7797 - acc: 0.9477 - mDice: 0.7793 - val_loss: 1168.8839 - val_acc: 0.9487 - val_mDice: 0.5487

Epoch 00024: val_mDice did not improve from 0.56018
Epoch 25/300
 - 16s - loss: 286.3952 - acc: 0.9481 - mDice: 0.7804 - val_loss: 1417.7889 - val_acc: 0.9483 - val_mDice: 0.5167

Epoch 00025: val_mDice did not improve from 0.56018
Epoch 26/300
 - 15s - loss: 283.9893 - acc: 0.9485 - mDice: 0.7821 - val_loss: 1359.4820 - val_acc: 0.9475 - val_mDice: 0.5310

Epoch 00026: val_mDice did not improve from 0.56018
Epoch 27/300
 - 16s - loss: 281.5133 - acc: 0.9489 - mDice: 0.7842 - val_loss: 1212.8285 - val_acc: 0.9501 - val_mDice: 0.5476

Epoch 00027: val_mDice did not improve from 0.56018
Epoch 28/300
 - 15s - loss: 278.9283 - acc: 0.9491 - mDice: 0.7860 - val_loss: 1254.8347 - val_acc: 0.9465 - val_mDice: 0.5430

Epoch 00028: val_mDice did not improve from 0.56018
Epoch 29/300
 - 16s - loss: 276.0528 - acc: 0.9492 - mDice: 0.7882 - val_loss: 1262.2628 - val_acc: 0.9499 - val_mDice: 0.5327

Epoch 00029: val_mDice did not improve from 0.56018
Epoch 30/300
 - 18s - loss: 274.5667 - acc: 0.9496 - mDice: 0.7895 - val_loss: 1318.4550 - val_acc: 0.9506 - val_mDice: 0.5343

Epoch 00030: val_mDice did not improve from 0.56018
Epoch 31/300
 - 16s - loss: 273.1655 - acc: 0.9493 - mDice: 0.7903 - val_loss: 1279.7748 - val_acc: 0.9488 - val_mDice: 0.5457

Epoch 00031: val_mDice did not improve from 0.56018
Epoch 32/300
 - 15s - loss: 270.9109 - acc: 0.9495 - mDice: 0.7922 - val_loss: 1266.7157 - val_acc: 0.9490 - val_mDice: 0.5394

Epoch 00032: val_mDice did not improve from 0.56018
Epoch 33/300
 - 15s - loss: 270.0350 - acc: 0.9498 - mDice: 0.7927 - val_loss: 1258.0444 - val_acc: 0.9509 - val_mDice: 0.5458

Epoch 00033: val_mDice did not improve from 0.56018
Epoch 34/300
 - 14s - loss: 266.9962 - acc: 0.9503 - mDice: 0.7952 - val_loss: 1280.0643 - val_acc: 0.9491 - val_mDice: 0.5424

Epoch 00034: val_mDice did not improve from 0.56018
Epoch 35/300
 - 14s - loss: 266.8669 - acc: 0.9502 - mDice: 0.7950 - val_loss: 1302.4989 - val_acc: 0.9487 - val_mDice: 0.5454

Epoch 00035: val_mDice did not improve from 0.56018
Epoch 36/300
 - 14s - loss: 263.0964 - acc: 0.9504 - mDice: 0.7978 - val_loss: 1373.0742 - val_acc: 0.9488 - val_mDice: 0.5292

Epoch 00036: val_mDice did not improve from 0.56018
Epoch 37/300
 - 14s - loss: 263.1591 - acc: 0.9506 - mDice: 0.7982 - val_loss: 1289.0112 - val_acc: 0.9501 - val_mDice: 0.5460

Epoch 00037: val_mDice did not improve from 0.56018
Epoch 38/300
 - 14s - loss: 261.1987 - acc: 0.9509 - mDice: 0.7995 - val_loss: 1351.5541 - val_acc: 0.9499 - val_mDice: 0.5355

Epoch 00038: val_mDice did not improve from 0.56018
Epoch 39/300
 - 14s - loss: 259.4063 - acc: 0.9515 - mDice: 0.8007 - val_loss: 1355.5110 - val_acc: 0.9506 - val_mDice: 0.5353

Epoch 00039: val_mDice did not improve from 0.56018
Epoch 40/300
 - 14s - loss: 257.6389 - acc: 0.9513 - mDice: 0.8021 - val_loss: 1323.1275 - val_acc: 0.9512 - val_mDice: 0.5440

Epoch 00040: val_mDice did not improve from 0.56018
Epoch 41/300
 - 13s - loss: 257.3630 - acc: 0.9513 - mDice: 0.8026 - val_loss: 1280.9331 - val_acc: 0.9507 - val_mDice: 0.5475

Epoch 00041: val_mDice did not improve from 0.56018
Epoch 42/300
 - 14s - loss: 256.2498 - acc: 0.9514 - mDice: 0.8037 - val_loss: 1289.4298 - val_acc: 0.9498 - val_mDice: 0.5492

Epoch 00042: val_mDice did not improve from 0.56018
Epoch 43/300
 - 13s - loss: 254.6565 - acc: 0.9513 - mDice: 0.8047 - val_loss: 1393.9539 - val_acc: 0.9518 - val_mDice: 0.5345

Epoch 00043: val_mDice did not improve from 0.56018
Epoch 44/300
 - 13s - loss: 252.8358 - acc: 0.9518 - mDice: 0.8058 - val_loss: 1264.0226 - val_acc: 0.9510 - val_mDice: 0.5518

Epoch 00044: val_mDice did not improve from 0.56018
Epoch 45/300
 - 14s - loss: 251.1012 - acc: 0.9519 - mDice: 0.8074 - val_loss: 1334.3230 - val_acc: 0.9520 - val_mDice: 0.5429

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.49s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.22s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.04s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:14,  1.53s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:44,  1.64s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:52,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:00,  1.71s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:48,  1.67s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:26,  1.81s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:55,  1.93s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:47,  1.91s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:24,  1.83s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:39,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:05,  1.99s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:32,  2.10s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:42,  2.14s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:48,  2.17s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:49,  2.18s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:43,  2.17s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:49,  2.20s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:45,  2.19s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<09:36,  2.17s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:35,  2.17s/it]predicting train subjects:   7%|▋         | 21/285 [00:42<09:34,  2.18s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:34,  2.18s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:31,  2.18s/it]predicting train subjects:   8%|▊         | 24/285 [00:49<09:32,  2.19s/it]predicting train subjects:   9%|▉         | 25/285 [00:51<09:32,  2.20s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:24,  2.18s/it]predicting train subjects:   9%|▉         | 27/285 [00:55<09:22,  2.18s/it]predicting train subjects:  10%|▉         | 28/285 [00:57<09:02,  2.11s/it]predicting train subjects:  10%|█         | 29/285 [00:59<08:46,  2.05s/it]predicting train subjects:  11%|█         | 30/285 [01:01<08:36,  2.03s/it]predicting train subjects:  11%|█         | 31/285 [01:03<08:25,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [01:05<08:20,  1.98s/it]predicting train subjects:  12%|█▏        | 33/285 [01:07<08:18,  1.98s/it]predicting train subjects:  12%|█▏        | 34/285 [01:09<08:15,  1.97s/it]predicting train subjects:  12%|█▏        | 35/285 [01:11<08:12,  1.97s/it]predicting train subjects:  13%|█▎        | 36/285 [01:13<08:00,  1.93s/it]predicting train subjects:  13%|█▎        | 37/285 [01:15<07:57,  1.92s/it]predicting train subjects:  13%|█▎        | 38/285 [01:17<07:57,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:19<07:54,  1.93s/it]predicting train subjects:  14%|█▍        | 40/285 [01:21<08:02,  1.97s/it]predicting train subjects:  14%|█▍        | 41/285 [01:23<07:55,  1.95s/it]predicting train subjects:  15%|█▍        | 42/285 [01:25<07:55,  1.96s/it]predicting train subjects:  15%|█▌        | 43/285 [01:27<07:55,  1.96s/it]predicting train subjects:  15%|█▌        | 44/285 [01:28<07:51,  1.96s/it]predicting train subjects:  16%|█▌        | 45/285 [01:30<07:42,  1.93s/it]predicting train subjects:  16%|█▌        | 46/285 [01:32<07:26,  1.87s/it]predicting train subjects:  16%|█▋        | 47/285 [01:34<07:21,  1.85s/it]predicting train subjects:  17%|█▋        | 48/285 [01:36<07:07,  1.80s/it]predicting train subjects:  17%|█▋        | 49/285 [01:37<07:06,  1.81s/it]predicting train subjects:  18%|█▊        | 50/285 [01:39<06:56,  1.77s/it]predicting train subjects:  18%|█▊        | 51/285 [01:41<06:57,  1.79s/it]predicting train subjects:  18%|█▊        | 52/285 [01:43<06:50,  1.76s/it]predicting train subjects:  19%|█▊        | 53/285 [01:44<06:52,  1.78s/it]predicting train subjects:  19%|█▉        | 54/285 [01:46<06:46,  1.76s/it]predicting train subjects:  19%|█▉        | 55/285 [01:48<06:45,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:50<06:43,  1.76s/it]predicting train subjects:  20%|██        | 57/285 [01:51<06:39,  1.75s/it]predicting train subjects:  20%|██        | 58/285 [01:53<06:36,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:55<06:42,  1.78s/it]predicting train subjects:  21%|██        | 60/285 [01:57<06:35,  1.76s/it]predicting train subjects:  21%|██▏       | 61/285 [01:58<06:28,  1.73s/it]predicting train subjects:  22%|██▏       | 62/285 [02:00<06:30,  1.75s/it]predicting train subjects:  22%|██▏       | 63/285 [02:02<06:32,  1.77s/it]predicting train subjects:  22%|██▏       | 64/285 [02:04<06:39,  1.81s/it]predicting train subjects:  23%|██▎       | 65/285 [02:06<07:00,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:08<07:06,  1.95s/it]predicting train subjects:  24%|██▎       | 67/285 [02:10<06:50,  1.88s/it]predicting train subjects:  24%|██▍       | 68/285 [02:12<06:45,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:13<06:37,  1.84s/it]predicting train subjects:  25%|██▍       | 70/285 [02:15<06:34,  1.83s/it]predicting train subjects:  25%|██▍       | 71/285 [02:17<06:38,  1.86s/it]predicting train subjects:  25%|██▌       | 72/285 [02:19<06:43,  1.90s/it]predicting train subjects:  26%|██▌       | 73/285 [02:21<06:37,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:23<06:37,  1.88s/it]predicting train subjects:  26%|██▋       | 75/285 [02:25<06:30,  1.86s/it]predicting train subjects:  27%|██▋       | 76/285 [02:26<06:20,  1.82s/it]predicting train subjects:  27%|██▋       | 77/285 [02:28<06:06,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:30<06:02,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:32<06:03,  1.76s/it]predicting train subjects:  28%|██▊       | 80/285 [02:33<06:14,  1.82s/it]predicting train subjects:  28%|██▊       | 81/285 [02:35<06:10,  1.82s/it]predicting train subjects:  29%|██▉       | 82/285 [02:37<06:11,  1.83s/it]predicting train subjects:  29%|██▉       | 83/285 [02:39<06:05,  1.81s/it]predicting train subjects:  29%|██▉       | 84/285 [02:41<05:59,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:43<06:05,  1.83s/it]predicting train subjects:  30%|███       | 86/285 [02:45<06:13,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:46<06:14,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:48<06:19,  1.92s/it]predicting train subjects:  31%|███       | 89/285 [02:51<06:23,  1.96s/it]predicting train subjects:  32%|███▏      | 90/285 [02:53<06:26,  1.98s/it]predicting train subjects:  32%|███▏      | 91/285 [02:55<06:28,  2.00s/it]predicting train subjects:  32%|███▏      | 92/285 [02:57<06:30,  2.02s/it]predicting train subjects:  33%|███▎      | 93/285 [02:59<06:34,  2.05s/it]predicting train subjects:  33%|███▎      | 94/285 [03:01<06:28,  2.03s/it]predicting train subjects:  33%|███▎      | 95/285 [03:03<06:39,  2.10s/it]predicting train subjects:  34%|███▎      | 96/285 [03:05<06:48,  2.16s/it]predicting train subjects:  34%|███▍      | 97/285 [03:08<06:46,  2.16s/it]predicting train subjects:  34%|███▍      | 98/285 [03:10<06:43,  2.16s/it]predicting train subjects:  35%|███▍      | 99/285 [03:12<06:46,  2.19s/it]predicting train subjects:  35%|███▌      | 100/285 [03:14<06:35,  2.14s/it]predicting train subjects:  35%|███▌      | 101/285 [03:16<06:32,  2.13s/it]predicting train subjects:  36%|███▌      | 102/285 [03:18<06:29,  2.13s/it]predicting train subjects:  36%|███▌      | 103/285 [03:20<06:22,  2.10s/it]predicting train subjects:  36%|███▋      | 104/285 [03:22<06:15,  2.08s/it]predicting train subjects:  37%|███▋      | 105/285 [03:24<06:17,  2.10s/it]predicting train subjects:  37%|███▋      | 106/285 [03:26<06:05,  2.04s/it]predicting train subjects:  38%|███▊      | 107/285 [03:28<06:06,  2.06s/it]predicting train subjects:  38%|███▊      | 108/285 [03:30<06:02,  2.05s/it]predicting train subjects:  38%|███▊      | 109/285 [03:32<06:01,  2.05s/it]predicting train subjects:  39%|███▊      | 110/285 [03:35<06:02,  2.07s/it]predicting train subjects:  39%|███▉      | 111/285 [03:37<05:58,  2.06s/it]predicting train subjects:  39%|███▉      | 112/285 [03:39<06:05,  2.11s/it]predicting train subjects:  40%|███▉      | 113/285 [03:41<06:13,  2.17s/it]predicting train subjects:  40%|████      | 114/285 [03:43<06:14,  2.19s/it]predicting train subjects:  40%|████      | 115/285 [03:46<06:10,  2.18s/it]predicting train subjects:  41%|████      | 116/285 [03:48<06:07,  2.17s/it]predicting train subjects:  41%|████      | 117/285 [03:50<06:00,  2.15s/it]predicting train subjects:  41%|████▏     | 118/285 [03:52<06:06,  2.19s/it]predicting train subjects:  42%|████▏     | 119/285 [03:54<06:02,  2.19s/it]predicting train subjects:  42%|████▏     | 120/285 [03:56<05:57,  2.17s/it]predicting train subjects:  42%|████▏     | 121/285 [03:58<05:49,  2.13s/it]predicting train subjects:  43%|████▎     | 122/285 [04:00<05:29,  2.02s/it]predicting train subjects:  43%|████▎     | 123/285 [04:02<05:17,  1.96s/it]predicting train subjects:  44%|████▎     | 124/285 [04:04<05:15,  1.96s/it]predicting train subjects:  44%|████▍     | 125/285 [04:06<05:19,  2.00s/it]predicting train subjects:  44%|████▍     | 126/285 [04:08<05:13,  1.97s/it]predicting train subjects:  45%|████▍     | 127/285 [04:10<05:09,  1.96s/it]predicting train subjects:  45%|████▍     | 128/285 [04:12<05:07,  1.96s/it]predicting train subjects:  45%|████▌     | 129/285 [04:14<05:01,  1.93s/it]predicting train subjects:  46%|████▌     | 130/285 [04:16<04:52,  1.88s/it]predicting train subjects:  46%|████▌     | 131/285 [04:17<04:46,  1.86s/it]predicting train subjects:  46%|████▋     | 132/285 [04:19<04:46,  1.87s/it]predicting train subjects:  47%|████▋     | 133/285 [04:21<04:42,  1.86s/it]predicting train subjects:  47%|████▋     | 134/285 [04:23<04:31,  1.80s/it]predicting train subjects:  47%|████▋     | 135/285 [04:25<04:30,  1.80s/it]predicting train subjects:  48%|████▊     | 136/285 [04:26<04:25,  1.78s/it]predicting train subjects:  48%|████▊     | 137/285 [04:28<04:38,  1.88s/it]predicting train subjects:  48%|████▊     | 138/285 [04:30<04:34,  1.86s/it]predicting train subjects:  49%|████▉     | 139/285 [04:32<04:31,  1.86s/it]predicting train subjects:  49%|████▉     | 140/285 [04:34<04:31,  1.87s/it]predicting train subjects:  49%|████▉     | 141/285 [04:36<04:28,  1.86s/it]predicting train subjects:  50%|████▉     | 142/285 [04:37<04:19,  1.82s/it]predicting train subjects:  50%|█████     | 143/285 [04:39<04:13,  1.78s/it]predicting train subjects:  51%|█████     | 144/285 [04:41<04:05,  1.74s/it]predicting train subjects:  51%|█████     | 145/285 [04:42<03:58,  1.70s/it]predicting train subjects:  51%|█████     | 146/285 [04:44<03:55,  1.69s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:46<03:52,  1.68s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:47<03:46,  1.65s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:49<03:47,  1.67s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:51<03:47,  1.68s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:53<03:48,  1.70s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:54<03:48,  1.72s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:56<03:47,  1.72s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:58<03:43,  1.70s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:59<03:36,  1.67s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:01<03:32,  1.65s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:03<03:40,  1.72s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:05<03:39,  1.73s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:06<03:47,  1.80s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:08<03:48,  1.83s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:10<03:39,  1.77s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:12<03:37,  1.77s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:14<03:37,  1.79s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:15<03:36,  1.79s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:17<03:27,  1.73s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:19<03:45,  1.89s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:21<03:44,  1.90s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:23<03:48,  1.95s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:25<03:39,  1.89s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:27<03:27,  1.81s/it]predicting train subjects:  60%|██████    | 171/285 [05:28<03:24,  1.79s/it]predicting train subjects:  60%|██████    | 172/285 [05:30<03:28,  1.84s/it]predicting train subjects:  61%|██████    | 173/285 [05:32<03:23,  1.82s/it]predicting train subjects:  61%|██████    | 174/285 [05:34<03:19,  1.80s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:35<03:13,  1.76s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:37<03:11,  1.76s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:39<03:06,  1.73s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:41<03:09,  1.77s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:43<03:06,  1.76s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:44<03:05,  1.77s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:46<03:03,  1.76s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:48<02:58,  1.73s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:49<02:57,  1.74s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:52<03:07,  1.85s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:53<02:59,  1.79s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:55<02:53,  1.75s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:56<02:45,  1.68s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:58<02:47,  1.72s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:00<02:44,  1.72s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:02<02:41,  1.70s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:03<02:43,  1.74s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:05<02:48,  1.81s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:07<02:44,  1.79s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:09<02:40,  1.76s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:11<02:38,  1.76s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:13<02:41,  1.82s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:15<02:48,  1.91s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:17<02:55,  2.01s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:19<02:56,  2.05s/it]predicting train subjects:  70%|███████   | 200/285 [06:21<02:53,  2.04s/it]predicting train subjects:  71%|███████   | 201/285 [06:23<02:53,  2.07s/it]predicting train subjects:  71%|███████   | 202/285 [06:25<02:51,  2.06s/it]predicting train subjects:  71%|███████   | 203/285 [06:27<02:47,  2.05s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:29<02:44,  2.03s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:31<02:40,  2.01s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:33<02:40,  2.03s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:35<02:40,  2.06s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:37<02:36,  2.03s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:39<02:34,  2.04s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:42<02:35,  2.07s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:44<02:33,  2.08s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:46<02:29,  2.04s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:48<02:25,  2.02s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:49<02:17,  1.94s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:51<02:08,  1.83s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:53<02:02,  1.78s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:54<01:59,  1.75s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:56<01:55,  1.73s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:57<01:50,  1.67s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:59<01:47,  1.65s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:01<01:44,  1.64s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:02<01:43,  1.64s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:04<01:43,  1.66s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:06<01:42,  1.67s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:07<01:39,  1.65s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:09<01:36,  1.63s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:11<01:34,  1.62s/it]predicting train subjects:  80%|████████  | 228/285 [07:12<01:32,  1.63s/it]predicting train subjects:  80%|████████  | 229/285 [07:14<01:30,  1.62s/it]predicting train subjects:  81%|████████  | 230/285 [07:15<01:29,  1.63s/it]predicting train subjects:  81%|████████  | 231/285 [07:17<01:29,  1.65s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:19<01:34,  1.79s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:21<01:35,  1.84s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:23<01:38,  1.93s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:25<01:38,  1.96s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:27<01:35,  1.95s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:29<01:35,  1.99s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:31<01:31,  1.95s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:33<01:30,  1.97s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:36<01:33,  2.08s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:38<01:31,  2.07s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:40<01:26,  2.01s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:42<01:27,  2.08s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:44<01:25,  2.07s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:46<01:23,  2.10s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:48<01:21,  2.09s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:50<01:20,  2.11s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:52<01:19,  2.15s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:55<01:16,  2.11s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:56<01:10,  2.00s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:58<01:06,  1.95s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:00<01:02,  1.89s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:02<00:58,  1.84s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:03<00:56,  1.83s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:05<00:54,  1.81s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:07<00:51,  1.78s/it]predicting train subjects:  90%|█████████ | 257/285 [08:09<00:49,  1.77s/it]predicting train subjects:  91%|█████████ | 258/285 [08:10<00:47,  1.76s/it]predicting train subjects:  91%|█████████ | 259/285 [08:12<00:45,  1.76s/it]predicting train subjects:  91%|█████████ | 260/285 [08:14<00:44,  1.77s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:16<00:43,  1.80s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:17<00:40,  1.76s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:19<00:39,  1.80s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:21<00:37,  1.79s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:23<00:35,  1.79s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:25<00:33,  1.78s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:26<00:31,  1.74s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:29<00:32,  1.91s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:31<00:32,  2.01s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:33<00:30,  2.05s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:35<00:29,  2.07s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:37<00:27,  2.10s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:39<00:25,  2.11s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:42<00:23,  2.15s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:44<00:21,  2.19s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:46<00:19,  2.19s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:48<00:17,  2.21s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:51<00:15,  2.21s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:53<00:13,  2.23s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:55<00:11,  2.25s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:57<00:08,  2.24s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:00<00:06,  2.23s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:02<00:04,  2.18s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:04<00:02,  2.19s/it]predicting train subjects: 100%|██████████| 285/285 [09:06<00:00,  2.19s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:19,  1.76s/it]Loading train:   1%|          | 2/285 [00:03<08:28,  1.80s/it]Loading train:   1%|          | 3/285 [00:05<08:28,  1.80s/it]Loading train:   1%|▏         | 4/285 [00:07<08:50,  1.89s/it]Loading train:   2%|▏         | 5/285 [00:09<08:35,  1.84s/it]Loading train:   2%|▏         | 6/285 [00:11<08:43,  1.88s/it]Loading train:   2%|▏         | 7/285 [00:13<08:57,  1.93s/it]Loading train:   3%|▎         | 8/285 [00:15<09:08,  1.98s/it]Loading train:   3%|▎         | 9/285 [00:17<08:55,  1.94s/it]Loading train:   4%|▎         | 10/285 [00:19<08:55,  1.95s/it]Loading train:   4%|▍         | 11/285 [00:20<08:35,  1.88s/it]Loading train:   4%|▍         | 12/285 [00:22<08:32,  1.88s/it]Loading train:   5%|▍         | 13/285 [00:24<08:05,  1.79s/it]Loading train:   5%|▍         | 14/285 [00:26<08:19,  1.84s/it]Loading train:   5%|▌         | 15/285 [00:27<07:55,  1.76s/it]Loading train:   6%|▌         | 16/285 [00:29<07:53,  1.76s/it]Loading train:   6%|▌         | 17/285 [00:31<08:01,  1.80s/it]Loading train:   6%|▋         | 18/285 [00:33<08:07,  1.83s/it]Loading train:   7%|▋         | 19/285 [00:35<08:02,  1.81s/it]Loading train:   7%|▋         | 20/285 [00:36<07:43,  1.75s/it]Loading train:   7%|▋         | 21/285 [00:38<07:35,  1.73s/it]Loading train:   8%|▊         | 22/285 [00:40<07:20,  1.68s/it]Loading train:   8%|▊         | 23/285 [00:41<07:19,  1.68s/it]Loading train:   8%|▊         | 24/285 [00:43<07:35,  1.74s/it]Loading train:   9%|▉         | 25/285 [00:45<07:33,  1.74s/it]Loading train:   9%|▉         | 26/285 [00:47<07:45,  1.80s/it]Loading train:   9%|▉         | 27/285 [00:48<07:31,  1.75s/it]Loading train:  10%|▉         | 28/285 [00:51<08:13,  1.92s/it]Loading train:  10%|█         | 29/285 [00:52<07:31,  1.77s/it]Loading train:  11%|█         | 30/285 [00:54<07:18,  1.72s/it]Loading train:  11%|█         | 31/285 [00:55<07:08,  1.69s/it]Loading train:  11%|█         | 32/285 [00:57<07:13,  1.71s/it]Loading train:  12%|█▏        | 33/285 [00:59<06:55,  1.65s/it]Loading train:  12%|█▏        | 34/285 [01:00<06:51,  1.64s/it]Loading train:  12%|█▏        | 35/285 [01:02<06:30,  1.56s/it]Loading train:  13%|█▎        | 36/285 [01:03<06:20,  1.53s/it]Loading train:  13%|█▎        | 37/285 [01:05<06:19,  1.53s/it]Loading train:  13%|█▎        | 38/285 [01:06<06:08,  1.49s/it]Loading train:  14%|█▎        | 39/285 [01:08<06:05,  1.49s/it]Loading train:  14%|█▍        | 40/285 [01:09<06:07,  1.50s/it]Loading train:  14%|█▍        | 41/285 [01:11<06:12,  1.53s/it]Loading train:  15%|█▍        | 42/285 [01:12<06:19,  1.56s/it]Loading train:  15%|█▌        | 43/285 [01:14<06:32,  1.62s/it]Loading train:  15%|█▌        | 44/285 [01:16<06:33,  1.63s/it]Loading train:  16%|█▌        | 45/285 [01:17<06:26,  1.61s/it]Loading train:  16%|█▌        | 46/285 [01:19<06:30,  1.63s/it]Loading train:  16%|█▋        | 47/285 [01:20<06:14,  1.57s/it]Loading train:  17%|█▋        | 48/285 [01:22<05:57,  1.51s/it]Loading train:  17%|█▋        | 49/285 [01:24<06:19,  1.61s/it]Loading train:  18%|█▊        | 50/285 [01:25<06:25,  1.64s/it]Loading train:  18%|█▊        | 51/285 [01:27<06:23,  1.64s/it]Loading train:  18%|█▊        | 52/285 [01:29<06:25,  1.65s/it]Loading train:  19%|█▊        | 53/285 [01:30<06:21,  1.65s/it]Loading train:  19%|█▉        | 54/285 [01:32<06:19,  1.64s/it]Loading train:  19%|█▉        | 55/285 [01:34<06:19,  1.65s/it]Loading train:  20%|█▉        | 56/285 [01:35<06:19,  1.66s/it]Loading train:  20%|██        | 57/285 [01:37<06:06,  1.61s/it]Loading train:  20%|██        | 58/285 [01:38<06:01,  1.59s/it]Loading train:  21%|██        | 59/285 [01:40<05:42,  1.52s/it]Loading train:  21%|██        | 60/285 [01:41<05:55,  1.58s/it]Loading train:  21%|██▏       | 61/285 [01:43<05:47,  1.55s/it]Loading train:  22%|██▏       | 62/285 [01:45<05:53,  1.58s/it]Loading train:  22%|██▏       | 63/285 [01:46<05:48,  1.57s/it]Loading train:  22%|██▏       | 64/285 [01:48<06:11,  1.68s/it]Loading train:  23%|██▎       | 65/285 [01:50<06:34,  1.79s/it]Loading train:  23%|██▎       | 66/285 [01:53<08:01,  2.20s/it]Loading train:  24%|██▎       | 67/285 [01:55<07:47,  2.14s/it]Loading train:  24%|██▍       | 68/285 [01:57<07:08,  1.97s/it]Loading train:  24%|██▍       | 69/285 [01:58<06:34,  1.83s/it]Loading train:  25%|██▍       | 70/285 [02:00<05:57,  1.66s/it]Loading train:  25%|██▍       | 71/285 [02:01<05:54,  1.66s/it]Loading train:  25%|██▌       | 72/285 [02:02<05:13,  1.47s/it]Loading train:  26%|██▌       | 73/285 [02:04<05:15,  1.49s/it]Loading train:  26%|██▌       | 74/285 [02:06<05:33,  1.58s/it]Loading train:  26%|██▋       | 75/285 [02:07<05:20,  1.53s/it]Loading train:  27%|██▋       | 76/285 [02:08<05:11,  1.49s/it]Loading train:  27%|██▋       | 77/285 [02:10<05:33,  1.60s/it]Loading train:  27%|██▋       | 78/285 [02:12<05:28,  1.59s/it]Loading train:  28%|██▊       | 79/285 [02:13<05:18,  1.55s/it]Loading train:  28%|██▊       | 80/285 [02:15<05:03,  1.48s/it]Loading train:  28%|██▊       | 81/285 [02:16<04:54,  1.44s/it]Loading train:  29%|██▉       | 82/285 [02:17<04:37,  1.37s/it]Loading train:  29%|██▉       | 83/285 [02:18<04:08,  1.23s/it]Loading train:  29%|██▉       | 84/285 [02:19<04:08,  1.24s/it]Loading train:  30%|██▉       | 85/285 [02:21<04:24,  1.32s/it]Loading train:  30%|███       | 86/285 [02:22<04:27,  1.34s/it]Loading train:  31%|███       | 87/285 [02:23<04:19,  1.31s/it]Loading train:  31%|███       | 88/285 [02:25<04:09,  1.27s/it]Loading train:  31%|███       | 89/285 [02:26<04:08,  1.27s/it]Loading train:  32%|███▏      | 90/285 [02:27<04:06,  1.27s/it]Loading train:  32%|███▏      | 91/285 [02:28<04:06,  1.27s/it]Loading train:  32%|███▏      | 92/285 [02:30<04:12,  1.31s/it]Loading train:  33%|███▎      | 93/285 [02:31<04:30,  1.41s/it]Loading train:  33%|███▎      | 94/285 [02:32<04:06,  1.29s/it]Loading train:  33%|███▎      | 95/285 [02:34<04:24,  1.39s/it]Loading train:  34%|███▎      | 96/285 [02:35<04:22,  1.39s/it]Loading train:  34%|███▍      | 97/285 [02:37<04:17,  1.37s/it]Loading train:  34%|███▍      | 98/285 [02:38<03:54,  1.26s/it]Loading train:  35%|███▍      | 99/285 [02:39<03:45,  1.21s/it]Loading train:  35%|███▌      | 100/285 [02:40<03:52,  1.26s/it]Loading train:  35%|███▌      | 101/285 [02:42<04:05,  1.34s/it]Loading train:  36%|███▌      | 102/285 [02:43<03:57,  1.30s/it]Loading train:  36%|███▌      | 103/285 [02:45<04:09,  1.37s/it]Loading train:  36%|███▋      | 104/285 [02:46<04:14,  1.41s/it]Loading train:  37%|███▋      | 105/285 [02:47<04:09,  1.38s/it]Loading train:  37%|███▋      | 106/285 [02:48<03:52,  1.30s/it]Loading train:  38%|███▊      | 107/285 [02:50<04:19,  1.46s/it]Loading train:  38%|███▊      | 108/285 [02:52<04:11,  1.42s/it]Loading train:  38%|███▊      | 109/285 [02:53<04:15,  1.45s/it]Loading train:  39%|███▊      | 110/285 [02:54<04:09,  1.43s/it]Loading train:  39%|███▉      | 111/285 [02:56<04:29,  1.55s/it]Loading train:  39%|███▉      | 112/285 [02:58<04:15,  1.48s/it]Loading train:  40%|███▉      | 113/285 [02:59<04:06,  1.43s/it]Loading train:  40%|████      | 114/285 [03:00<03:55,  1.38s/it]Loading train:  40%|████      | 115/285 [03:01<03:42,  1.31s/it]Loading train:  41%|████      | 116/285 [03:02<03:29,  1.24s/it]Loading train:  41%|████      | 117/285 [03:04<03:33,  1.27s/it]Loading train:  41%|████▏     | 118/285 [03:05<03:48,  1.37s/it]Loading train:  42%|████▏     | 119/285 [03:07<03:56,  1.43s/it]Loading train:  42%|████▏     | 120/285 [03:09<04:05,  1.49s/it]Loading train:  42%|████▏     | 121/285 [03:10<04:05,  1.50s/it]Loading train:  43%|████▎     | 122/285 [03:11<03:57,  1.46s/it]Loading train:  43%|████▎     | 123/285 [03:13<03:58,  1.47s/it]Loading train:  44%|████▎     | 124/285 [03:14<03:56,  1.47s/it]Loading train:  44%|████▍     | 125/285 [03:16<03:49,  1.43s/it]Loading train:  44%|████▍     | 126/285 [03:17<03:44,  1.41s/it]Loading train:  45%|████▍     | 127/285 [03:19<03:42,  1.41s/it]Loading train:  45%|████▍     | 128/285 [03:20<03:32,  1.35s/it]Loading train:  45%|████▌     | 129/285 [03:21<03:22,  1.30s/it]Loading train:  46%|████▌     | 130/285 [03:22<03:25,  1.33s/it]Loading train:  46%|████▌     | 131/285 [03:23<03:10,  1.24s/it]Loading train:  46%|████▋     | 132/285 [03:25<03:07,  1.23s/it]Loading train:  47%|████▋     | 133/285 [03:26<02:59,  1.18s/it]Loading train:  47%|████▋     | 134/285 [03:27<02:58,  1.18s/it]Loading train:  47%|████▋     | 135/285 [03:28<02:49,  1.13s/it]Loading train:  48%|████▊     | 136/285 [03:29<02:45,  1.11s/it]Loading train:  48%|████▊     | 137/285 [03:30<02:38,  1.07s/it]Loading train:  48%|████▊     | 138/285 [03:31<02:44,  1.12s/it]Loading train:  49%|████▉     | 139/285 [03:32<02:55,  1.20s/it]Loading train:  49%|████▉     | 140/285 [03:34<02:48,  1.16s/it]Loading train:  49%|████▉     | 141/285 [03:35<02:48,  1.17s/it]Loading train:  50%|████▉     | 142/285 [03:36<02:48,  1.18s/it]Loading train:  50%|█████     | 143/285 [03:37<02:33,  1.08s/it]Loading train:  51%|█████     | 144/285 [03:38<02:24,  1.02s/it]Loading train:  51%|█████     | 145/285 [03:39<02:22,  1.02s/it]Loading train:  51%|█████     | 146/285 [03:40<02:19,  1.00s/it]Loading train:  52%|█████▏    | 147/285 [03:41<02:16,  1.01it/s]Loading train:  52%|█████▏    | 148/285 [03:42<02:18,  1.01s/it]Loading train:  52%|█████▏    | 149/285 [03:43<02:21,  1.04s/it]Loading train:  53%|█████▎    | 150/285 [03:44<02:25,  1.07s/it]Loading train:  53%|█████▎    | 151/285 [03:45<02:18,  1.03s/it]Loading train:  53%|█████▎    | 152/285 [03:46<02:34,  1.16s/it]Loading train:  54%|█████▎    | 153/285 [03:47<02:23,  1.09s/it]Loading train:  54%|█████▍    | 154/285 [03:48<02:22,  1.09s/it]Loading train:  54%|█████▍    | 155/285 [03:49<02:16,  1.05s/it]Loading train:  55%|█████▍    | 156/285 [03:50<02:09,  1.00s/it]Loading train:  55%|█████▌    | 157/285 [03:51<01:59,  1.07it/s]Loading train:  55%|█████▌    | 158/285 [03:52<02:00,  1.05it/s]Loading train:  56%|█████▌    | 159/285 [03:54<02:24,  1.14s/it]Loading train:  56%|█████▌    | 160/285 [03:55<02:28,  1.19s/it]Loading train:  56%|█████▋    | 161/285 [03:56<02:29,  1.21s/it]Loading train:  57%|█████▋    | 162/285 [03:57<02:26,  1.19s/it]Loading train:  57%|█████▋    | 163/285 [03:58<02:23,  1.17s/it]Loading train:  58%|█████▊    | 164/285 [03:59<02:15,  1.12s/it]Loading train:  58%|█████▊    | 165/285 [04:00<02:09,  1.08s/it]Loading train:  58%|█████▊    | 166/285 [04:01<02:08,  1.08s/it]Loading train:  59%|█████▊    | 167/285 [04:02<02:00,  1.02s/it]Loading train:  59%|█████▉    | 168/285 [04:03<01:53,  1.03it/s]Loading train:  59%|█████▉    | 169/285 [04:04<01:49,  1.06it/s]Loading train:  60%|█████▉    | 170/285 [04:05<01:45,  1.09it/s]Loading train:  60%|██████    | 171/285 [04:06<01:46,  1.07it/s]Loading train:  60%|██████    | 172/285 [04:07<01:44,  1.08it/s]Loading train:  61%|██████    | 173/285 [04:08<01:50,  1.01it/s]Loading train:  61%|██████    | 174/285 [04:09<02:00,  1.08s/it]Loading train:  61%|██████▏   | 175/285 [04:11<02:09,  1.18s/it]Loading train:  62%|██████▏   | 176/285 [04:12<02:09,  1.19s/it]Loading train:  62%|██████▏   | 177/285 [04:13<02:04,  1.16s/it]Loading train:  62%|██████▏   | 178/285 [04:14<02:08,  1.20s/it]Loading train:  63%|██████▎   | 179/285 [04:15<02:07,  1.21s/it]Loading train:  63%|██████▎   | 180/285 [04:17<02:02,  1.17s/it]Loading train:  64%|██████▎   | 181/285 [04:18<02:02,  1.18s/it]Loading train:  64%|██████▍   | 182/285 [04:19<01:56,  1.13s/it]Loading train:  64%|██████▍   | 183/285 [04:20<01:56,  1.14s/it]Loading train:  65%|██████▍   | 184/285 [04:21<01:52,  1.11s/it]Loading train:  65%|██████▍   | 185/285 [04:22<01:57,  1.18s/it]Loading train:  65%|██████▌   | 186/285 [04:23<01:53,  1.14s/it]Loading train:  66%|██████▌   | 187/285 [04:25<01:56,  1.18s/it]Loading train:  66%|██████▌   | 188/285 [04:26<01:51,  1.15s/it]Loading train:  66%|██████▋   | 189/285 [04:27<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [04:28<01:46,  1.12s/it]Loading train:  67%|██████▋   | 191/285 [04:29<01:46,  1.13s/it]Loading train:  67%|██████▋   | 192/285 [04:30<01:48,  1.17s/it]Loading train:  68%|██████▊   | 193/285 [04:32<01:50,  1.20s/it]Loading train:  68%|██████▊   | 194/285 [04:33<01:51,  1.23s/it]Loading train:  68%|██████▊   | 195/285 [04:34<01:46,  1.19s/it]Loading train:  69%|██████▉   | 196/285 [04:35<01:47,  1.21s/it]Loading train:  69%|██████▉   | 197/285 [04:36<01:49,  1.24s/it]Loading train:  69%|██████▉   | 198/285 [04:38<01:52,  1.29s/it]Loading train:  70%|██████▉   | 199/285 [04:39<01:43,  1.21s/it]Loading train:  70%|███████   | 200/285 [04:40<01:39,  1.17s/it]Loading train:  71%|███████   | 201/285 [04:41<01:34,  1.12s/it]Loading train:  71%|███████   | 202/285 [04:42<01:39,  1.20s/it]Loading train:  71%|███████   | 203/285 [04:44<01:36,  1.17s/it]Loading train:  72%|███████▏  | 204/285 [04:44<01:27,  1.08s/it]Loading train:  72%|███████▏  | 205/285 [04:46<01:36,  1.20s/it]Loading train:  72%|███████▏  | 206/285 [04:47<01:31,  1.16s/it]Loading train:  73%|███████▎  | 207/285 [04:48<01:29,  1.14s/it]Loading train:  73%|███████▎  | 208/285 [04:49<01:27,  1.14s/it]Loading train:  73%|███████▎  | 209/285 [04:50<01:24,  1.11s/it]Loading train:  74%|███████▎  | 210/285 [04:51<01:21,  1.09s/it]Loading train:  74%|███████▍  | 211/285 [04:52<01:22,  1.11s/it]Loading train:  74%|███████▍  | 212/285 [04:54<01:20,  1.11s/it]Loading train:  75%|███████▍  | 213/285 [04:55<01:24,  1.17s/it]Loading train:  75%|███████▌  | 214/285 [04:56<01:17,  1.08s/it]Loading train:  75%|███████▌  | 215/285 [04:57<01:09,  1.00it/s]Loading train:  76%|███████▌  | 216/285 [04:58<01:09,  1.01s/it]Loading train:  76%|███████▌  | 217/285 [04:59<01:09,  1.02s/it]Loading train:  76%|███████▋  | 218/285 [05:00<01:12,  1.08s/it]Loading train:  77%|███████▋  | 219/285 [05:01<01:05,  1.01it/s]Loading train:  77%|███████▋  | 220/285 [05:02<01:04,  1.00it/s]Loading train:  78%|███████▊  | 221/285 [05:03<01:02,  1.02it/s]Loading train:  78%|███████▊  | 222/285 [05:03<00:57,  1.09it/s]Loading train:  78%|███████▊  | 223/285 [05:04<00:57,  1.07it/s]Loading train:  79%|███████▊  | 224/285 [05:05<00:53,  1.14it/s]Loading train:  79%|███████▉  | 225/285 [05:06<00:53,  1.12it/s]Loading train:  79%|███████▉  | 226/285 [05:07<00:50,  1.16it/s]Loading train:  80%|███████▉  | 227/285 [05:07<00:47,  1.21it/s]Loading train:  80%|████████  | 228/285 [05:08<00:46,  1.23it/s]Loading train:  80%|████████  | 229/285 [05:09<00:45,  1.24it/s]Loading train:  81%|████████  | 230/285 [05:10<00:44,  1.24it/s]Loading train:  81%|████████  | 231/285 [05:11<00:42,  1.26it/s]Loading train:  81%|████████▏ | 232/285 [05:12<00:44,  1.18it/s]Loading train:  82%|████████▏ | 233/285 [05:13<00:46,  1.13it/s]Loading train:  82%|████████▏ | 234/285 [05:14<00:45,  1.11it/s]Loading train:  82%|████████▏ | 235/285 [05:14<00:45,  1.09it/s]Loading train:  83%|████████▎ | 236/285 [05:15<00:44,  1.10it/s]Loading train:  83%|████████▎ | 237/285 [05:16<00:43,  1.10it/s]Loading train:  84%|████████▎ | 238/285 [05:17<00:44,  1.06it/s]Loading train:  84%|████████▍ | 239/285 [05:18<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [05:19<00:43,  1.02it/s]Loading train:  85%|████████▍ | 241/285 [05:20<00:44,  1.00s/it]Loading train:  85%|████████▍ | 242/285 [05:21<00:42,  1.00it/s]Loading train:  85%|████████▌ | 243/285 [05:22<00:42,  1.00s/it]Loading train:  86%|████████▌ | 244/285 [05:23<00:40,  1.02it/s]Loading train:  86%|████████▌ | 245/285 [05:24<00:38,  1.05it/s]Loading train:  86%|████████▋ | 246/285 [05:25<00:37,  1.05it/s]Loading train:  87%|████████▋ | 247/285 [05:26<00:35,  1.07it/s]Loading train:  87%|████████▋ | 248/285 [05:27<00:34,  1.09it/s]Loading train:  87%|████████▋ | 249/285 [05:28<00:32,  1.09it/s]Loading train:  88%|████████▊ | 250/285 [05:29<00:30,  1.13it/s]Loading train:  88%|████████▊ | 251/285 [05:29<00:28,  1.18it/s]Loading train:  88%|████████▊ | 252/285 [05:30<00:27,  1.20it/s]Loading train:  89%|████████▉ | 253/285 [05:31<00:25,  1.23it/s]Loading train:  89%|████████▉ | 254/285 [05:32<00:23,  1.29it/s]Loading train:  89%|████████▉ | 255/285 [05:32<00:22,  1.31it/s]Loading train:  90%|████████▉ | 256/285 [05:33<00:22,  1.30it/s]Loading train:  90%|█████████ | 257/285 [05:34<00:21,  1.28it/s]Loading train:  91%|█████████ | 258/285 [05:35<00:21,  1.26it/s]Loading train:  91%|█████████ | 259/285 [05:36<00:20,  1.27it/s]Loading train:  91%|█████████ | 260/285 [05:37<00:20,  1.20it/s]Loading train:  92%|█████████▏| 261/285 [05:37<00:19,  1.21it/s]Loading train:  92%|█████████▏| 262/285 [05:38<00:18,  1.22it/s]Loading train:  92%|█████████▏| 263/285 [05:39<00:17,  1.24it/s]Loading train:  93%|█████████▎| 264/285 [05:40<00:16,  1.26it/s]Loading train:  93%|█████████▎| 265/285 [05:41<00:16,  1.21it/s]Loading train:  93%|█████████▎| 266/285 [05:41<00:15,  1.21it/s]Loading train:  94%|█████████▎| 267/285 [05:42<00:14,  1.20it/s]Loading train:  94%|█████████▍| 268/285 [05:43<00:14,  1.16it/s]Loading train:  94%|█████████▍| 269/285 [05:44<00:13,  1.16it/s]Loading train:  95%|█████████▍| 270/285 [05:45<00:13,  1.12it/s]Loading train:  95%|█████████▌| 271/285 [05:46<00:13,  1.04it/s]Loading train:  95%|█████████▌| 272/285 [05:47<00:12,  1.02it/s]Loading train:  96%|█████████▌| 273/285 [05:48<00:12,  1.01s/it]Loading train:  96%|█████████▌| 274/285 [05:49<00:11,  1.03s/it]Loading train:  96%|█████████▋| 275/285 [05:50<00:10,  1.07s/it]Loading train:  97%|█████████▋| 276/285 [05:52<00:09,  1.10s/it]Loading train:  97%|█████████▋| 277/285 [05:53<00:09,  1.20s/it]Loading train:  98%|█████████▊| 278/285 [05:54<00:08,  1.18s/it]Loading train:  98%|█████████▊| 279/285 [05:56<00:07,  1.22s/it]Loading train:  98%|█████████▊| 280/285 [05:57<00:06,  1.21s/it]Loading train:  99%|█████████▊| 281/285 [05:58<00:04,  1.18s/it]Loading train:  99%|█████████▉| 282/285 [05:59<00:03,  1.14s/it]Loading train:  99%|█████████▉| 283/285 [06:00<00:02,  1.12s/it]Loading train: 100%|█████████▉| 284/285 [06:01<00:01,  1.11s/it]Loading train: 100%|██████████| 285/285 [06:02<00:00,  1.07s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:07, 35.38it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:07, 35.42it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:06, 43.06it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:04, 54.61it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:03, 68.29it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:03, 68.13it/s]concatenating: train:  25%|██▍       | 71/285 [00:00<00:03, 67.55it/s]concatenating: train:  28%|██▊       | 80/285 [00:00<00:03, 65.95it/s]concatenating: train:  33%|███▎      | 95/285 [00:01<00:02, 78.76it/s]concatenating: train:  41%|████      | 117/285 [00:01<00:01, 97.54it/s]concatenating: train:  51%|█████     | 145/285 [00:01<00:01, 120.88it/s]concatenating: train:  57%|█████▋    | 163/285 [00:01<00:00, 130.39it/s]concatenating: train:  68%|██████▊   | 194/285 [00:01<00:00, 157.82it/s]concatenating: train:  78%|███████▊  | 222/285 [00:01<00:00, 181.05it/s]concatenating: train:  89%|████████▉ | 253/285 [00:01<00:00, 205.66it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 158.77it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.55s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.47s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 69.82it/s]
Epoch 00045: val_mDice did not improve from 0.56018
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
{'val_loss': [870.1432628098813, 874.6824910254452, 924.4261740572625, 1064.4142616314596, 1034.1657960348289, 1194.7812554556565, 1081.3871477009864, 1048.6893215072887, 1178.0801517763618, 1094.9102742285702, 1048.7892343531773, 1103.2715648459323, 1083.9511023153807, 1183.614206665721, 1040.4695935808747, 1159.7294676370461, 1115.4274868245898, 1144.22725673228, 1127.034901880019, 1322.0916632114177, 1395.9773160625437, 1237.6765211734025, 1164.0174819690556, 1168.883930909567, 1417.7889383838162, 1359.4819560983328, 1212.8285164433485, 1254.8347242984025, 1262.2628132910702, 1318.4550167488653, 1279.7748246006458, 1266.7156825571753, 1258.0444015417686, 1280.064262177025, 1302.498947740267, 1373.0742303432698, 1289.0111847776275, 1351.5541064725908, 1355.5109590498428, 1323.1275402900228, 1280.933120471805, 1289.4297945672574, 1393.9538928836419, 1264.0225707325856, 1334.322970086636], 'val_acc': [0.9436650858911056, 0.9474769424459788, 0.9482248651914756, 0.9472889424036335, 0.9482000683273017, 0.9453199995296627, 0.9465637653233618, 0.9475781910912284, 0.9464294614072618, 0.9453737173000527, 0.9455121392644318, 0.9468467751694791, 0.950249587690364, 0.9485864016596831, 0.948437638455929, 0.9474294225596849, 0.9492268772098605, 0.9457249261813456, 0.9475265534896424, 0.946245570089564, 0.9442766458628564, 0.9487082998179857, 0.9486194795736388, 0.9487165708781621, 0.9483178008202068, 0.9474666175229589, 0.950127694859851, 0.9465203691461233, 0.9499355174975688, 0.9506235049423559, 0.9487558246990822, 0.9490223546933861, 0.9509417061699169, 0.9490905227607855, 0.9486566392403075, 0.948811589339592, 0.9500512480735779, 0.9498591093377694, 0.9505966761924701, 0.9511855091462588, 0.9507020292335382, 0.9498219113776137, 0.951774311465258, 0.950958241297546, 0.9519974675924419], 'val_mDice': [0.43209006533276434, 0.48263870004835074, 0.5076804817055857, 0.49059249136035005, 0.5087722163626601, 0.4853462853245229, 0.5183094340329729, 0.5260347740610218, 0.5084728750103679, 0.5362396050431875, 0.545873902696471, 0.5438524592855123, 0.5416524023983066, 0.5348089660346175, 0.5601765759830368, 0.5462496696903719, 0.5405436727587737, 0.5463492472411534, 0.5477190885130919, 0.5232902880154509, 0.5127715951237599, 0.5414927059045717, 0.5471419137616397, 0.5486630574284985, 0.516667938432214, 0.5309777436309686, 0.5475567719123883, 0.5430349611037271, 0.5327258692773361, 0.5343051770878904, 0.5456857408225203, 0.5394184446201644, 0.5458203231156206, 0.542358898916724, 0.5454063290657278, 0.5291520573573405, 0.5459806789233032, 0.5355189102988004, 0.5352819255610418, 0.5440330082477804, 0.5474893047822921, 0.5492133032010255, 0.5344692242212136, 0.5517701972796264, 0.5429454352602613], 'loss': [1108.5252456062533, 606.9794388710754, 517.724129237976, 470.17575894977966, 435.649190398786, 412.4012475022822, 394.08018574180454, 381.0237453974486, 367.2143831508078, 360.1389393122665, 350.8214255190059, 340.97067531662356, 333.5788089836756, 329.3743636226493, 322.9323886630128, 318.8755969177449, 313.0620380619968, 309.32429842878537, 306.0437596557278, 300.6680155419023, 298.2375012567039, 294.9103457943935, 291.5132641816969, 287.7797309015774, 286.3951537663767, 283.9892828335567, 281.51329515634893, 278.9283039605564, 276.05277846601103, 274.56669698224584, 273.16551288193165, 270.9109079670422, 270.0349599109951, 266.9961554657809, 266.8669415202758, 263.09638765134696, 263.15914712223076, 261.1987381509158, 259.4063262897901, 257.6388589121354, 257.3629639750569, 256.24975960073266, 254.6564744166394, 252.83579578465103, 251.10123020810153], 'acc': [0.9114226122825962, 0.9315944020118753, 0.9363672097071695, 0.9385392138053049, 0.9399985822708828, 0.9407262430654088, 0.9416341727143909, 0.9422842282127253, 0.9429257012005693, 0.9438193496110736, 0.9443178373603454, 0.9449534511314253, 0.9452101392045038, 0.9455417908554041, 0.9457015562022435, 0.9457708428052898, 0.9461963767547258, 0.946000622470072, 0.9466058375444438, 0.9468887885972102, 0.9470999346476197, 0.947082492382748, 0.9478261065466212, 0.9477365749261847, 0.9480831133930403, 0.94846325016484, 0.9488765389517654, 0.9491245438769378, 0.9491543141002716, 0.9495935825654659, 0.9493054166565235, 0.9494962198504059, 0.9498423931320913, 0.9503472456517326, 0.9502024104552204, 0.950386341984421, 0.9505711645545293, 0.9509349629858351, 0.951514097754261, 0.951270947038371, 0.9513160633655177, 0.9514160299312834, 0.9513214640605424, 0.9518456913002903, 0.9519248473755278], 'mDice': [0.35065572138192586, 0.5521444207306203, 0.6121854201477797, 0.6445999238253561, 0.6691392531459105, 0.6859611629835953, 0.6994293366315533, 0.7090881728092366, 0.7195224886035083, 0.7243968193213292, 0.7317244846974964, 0.7389776429432188, 0.7449443254048291, 0.7477861066690672, 0.7528162499955976, 0.755708650977554, 0.7601890159318094, 0.7630049398662049, 0.7656131556763718, 0.7695817661164639, 0.7713470638307973, 0.7739606398323589, 0.7762489089758838, 0.7792784293345472, 0.780444349908769, 0.7820671578422558, 0.7842133229584302, 0.785987173103376, 0.7881799617543939, 0.7895022738532403, 0.790297612129918, 0.7921505559861326, 0.7926741592453349, 0.7952094811005346, 0.7949563860666011, 0.7978492649861991, 0.7982175750875518, 0.7995005675172709, 0.8007175696129231, 0.8021349620308779, 0.8025991866339409, 0.803653562736371, 0.8047327617175516, 0.8057891336585122, 0.8074285325567211]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   2019-06-30 21:00:14.134054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 21:00:14.134152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 21:00:14.134166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 21:00:14.134174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 21:00:14.134602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 120)  64920       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 120)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 60)   28860       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 120)  0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 60)   64860       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 60)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 30)   7230        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 80, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 30)   16230       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 30)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   403         dropout_5[0][0]                  
==================================================================================================
Total params: 412,363
Trainable params: 411,163
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [2.22914927e+01 1.09758073e+01 2.57605072e+01 3.20169489e+00
 9.30612289e+00 2.42668560e+00 2.90680004e+01 3.86865725e+01
 2.95464687e+01 4.55026025e+00 1.01029583e+02 6.65891339e+01
 8.79274619e-02]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 17s - loss: 2269.6226 - acc: 0.8903 - mDice: 0.2441 - val_loss: 2067.6536 - val_acc: 0.9209 - val_mDice: 0.3065

Epoch 00001: val_mDice improved from -inf to 0.30645, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 1205.9777 - acc: 0.9257 - mDice: 0.4461 - val_loss: 1680.4257 - val_acc: 0.9285 - val_mDice: 0.3839

Epoch 00002: val_mDice improved from 0.30645 to 0.38391, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 1009.3280 - acc: 0.9339 - mDice: 0.5219 - val_loss: 1705.6140 - val_acc: 0.9278 - val_mDice: 0.4077

Epoch 00003: val_mDice improved from 0.38391 to 0.40773, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 901.5820 - acc: 0.9382 - mDice: 0.5663 - val_loss: 1680.8212 - val_acc: 0.9414 - val_mDice: 0.4328

Epoch 00004: val_mDice improved from 0.40773 to 0.43283, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 10s - loss: 833.5371 - acc: 0.9409 - mDice: 0.5965 - val_loss: 1934.8186 - val_acc: 0.9381 - val_mDice: 0.4215

Epoch 00005: val_mDice did not improve from 0.43283
Epoch 6/300
 - 10s - loss: 783.9867 - acc: 0.9432 - mDice: 0.6185 - val_loss: 1850.0798 - val_acc: 0.9423 - val_mDice: 0.4439

Epoch 00006: val_mDice improved from 0.43283 to 0.44391, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 746.4532 - acc: 0.9448 - mDice: 0.6355 - val_loss: 1837.2378 - val_acc: 0.9434 - val_mDice: 0.4586

Epoch 00007: val_mDice improved from 0.44391 to 0.45861, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 715.0419 - acc: 0.9461 - mDice: 0.6498 - val_loss: 1937.1637 - val_acc: 0.9420 - val_mDice: 0.4367

Epoch 00008: val_mDice did not improve from 0.45861
Epoch 9/300
 - 11s - loss: 691.1870 - acc: 0.9472 - mDice: 0.6609 - val_loss: 1877.6829 - val_acc: 0.9445 - val_mDice: 0.4577

Epoch 00009: val_mDice did not improve from 0.45861
Epoch 10/300
 - 10s - loss: 670.3258 - acc: 0.9480 - mDice: 0.6711 - val_loss: 1888.9538 - val_acc: 0.9451 - val_mDice: 0.4601

Epoch 00010: val_mDice improved from 0.45861 to 0.46011, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 650.1834 - acc: 0.9489 - mDice: 0.6803 - val_loss: 2044.9664 - val_acc: 0.9451 - val_mDice: 0.4433

Epoch 00011: val_mDice did not improve from 0.46011
Epoch 12/300
 - 10s - loss: 635.5750 - acc: 0.9494 - mDice: 0.6869 - val_loss: 1925.6736 - val_acc: 0.9470 - val_mDice: 0.4609

Epoch 00012: val_mDice improved from 0.46011 to 0.46092, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 622.3017 - acc: 0.9500 - mDice: 0.6934 - val_loss: 2068.3889 - val_acc: 0.9459 - val_mDice: 0.4623

Epoch 00013: val_mDice improved from 0.46092 to 0.46231, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 11s - loss: 606.2671 - acc: 0.9507 - mDice: 0.7012 - val_loss: 2128.1797 - val_acc: 0.9454 - val_mDice: 0.4588

Epoch 00014: val_mDice did not improve from 0.46231
Epoch 15/300
 - 11s - loss: 598.2244 - acc: 0.9512 - mDice: 0.7054 - val_loss: 2159.1771 - val_acc: 0.9423 - val_mDice: 0.4449

Epoch 00015: val_mDice did not improve from 0.46231
Epoch 16/300
 - 11s - loss: 585.4028 - acc: 0.9517 - mDice: 0.7109 - val_loss: 2080.2276 - val_acc: 0.9461 - val_mDice: 0.4657

Epoch 00016: val_mDice improved from 0.46231 to 0.46566, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 575.4884 - acc: 0.9522 - mDice: 0.7158 - val_loss: 2080.6709 - val_acc: 0.9453 - val_mDice: 0.4659

Epoch 00017: val_mDice improved from 0.46566 to 0.46588, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 10s - loss: 565.5889 - acc: 0.9525 - mDice: 0.7203 - val_loss: 2131.5113 - val_acc: 0.9470 - val_mDice: 0.4696

Epoch 00018: val_mDice improved from 0.46588 to 0.46958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 11s - loss: 559.2559 - acc: 0.9529 - mDice: 0.7234 - val_loss: 2173.1229 - val_acc: 0.9474 - val_mDice: 0.4645

Epoch 00019: val_mDice did not improve from 0.46958
Epoch 20/300
 - 11s - loss: 551.2095 - acc: 0.9531 - mDice: 0.7277 - val_loss: 2065.8927 - val_acc: 0.9455 - val_mDice: 0.4725

Epoch 00020: val_mDice improved from 0.46958 to 0.47252, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 11s - loss: 542.9511 - acc: 0.9536 - mDice: 0.7315 - val_loss: 2579.8287 - val_acc: 0.9407 - val_mDice: 0.4184

Epoch 00021: val_mDice did not improve from 0.47252
Epoch 22/300
 - 11s - loss: 538.8838 - acc: 0.9537 - mDice: 0.7334 - val_loss: 2114.4135 - val_acc: 0.9477 - val_mDice: 0.4681

Epoch 00022: val_mDice did not improve from 0.47252
Epoch 23/300
 - 11s - loss: 532.4561 - acc: 0.9540 - mDice: 0.7367 - val_loss: 2333.2813 - val_acc: 0.9446 - val_mDice: 0.4526

Epoch 00023: val_mDice did not improve from 0.47252
Epoch 24/300
 - 11s - loss: 523.8826 - acc: 0.9544 - mDice: 0.7404 - val_loss: 2411.3585 - val_acc: 0.9440 - val_mDice: 0.4398

Epoch 00024: val_mDice did not improve from 0.47252
Epoch 25/300
 - 11s - loss: 519.5377 - acc: 0.9546 - mDice: 0.7425 - val_loss: 2383.0087 - val_acc: 0.9454 - val_mDice: 0.4520

Epoch 00025: val_mDice did not improve from 0.47252
Epoch 26/300
 - 11s - loss: 516.3496 - acc: 0.9547 - mDice: 0.7447 - val_loss: 2326.5839 - val_acc: 0.9434 - val_mDice: 0.4535

Epoch 00026: val_mDice did not improve from 0.47252
Epoch 27/300
 - 11s - loss: 509.7821 - acc: 0.9550 - mDice: 0.7473 - val_loss: 2208.0601 - val_acc: 0.9472 - val_mDice: 0.4685

Epoch 00027: val_mDice did not improve from 0.47252
Epoch 28/300
 - 11s - loss: 505.8041 - acc: 0.9551 - mDice: 0.7493 - val_loss: 2251.0855 - val_acc: 0.9472 - val_mDice: 0.4663

Epoch 00028: val_mDice did not improve from 0.47252
Epoch 29/300
 - 11s - loss: 499.9901 - acc: 0.9554 - mDice: 0.7518 - val_loss: 2323.1411 - val_acc: 0.9458 - val_mDice: 0.4652

Epoch 00029: val_mDice did not improve from 0.47252
Epoch 30/300
 - 11s - loss: 494.6391 - acc: 0.9556 - mDice: 0.7549 - val_loss: 2378.5484 - val_acc: 0.9438 - val_mDice: 0.4563

Epoch 00030: val_mDice did not improve from 0.47252
Epoch 31/300
 - 11s - loss: 490.6727 - acc: 0.9559 - mDice: 0.7568 - val_loss: 2660.0567 - val_acc: 0.9421 - val_mDice: 0.4303

Epoch 00031: val_mDice did not improve from 0.47252
Epoch 32/300
 - 11s - loss: 486.7206 - acc: 0.9561 - mDice: 0.7583 - val_loss: 2327.5165 - val_acc: 0.9469 - val_mDice: 0.4700

Epoch 00032: val_mDice did not improve from 0.47252
Epoch 33/300
 - 11s - loss: 483.4383 - acc: 0.9562 - mDice: 0.7604 - val_loss: 2439.5322 - val_acc: 0.9442 - val_mDice: 0.4652

Epoch 00033: val_mDice did not improve from 0.47252
Epoch 34/300
 - 11s - loss: 480.9754 - acc: 0.9564 - mDice: 0.7621 - val_loss: 2347.5191 - val_acc: 0.9471 - val_mDice: 0.4685

Epoch 00034: val_mDice did not improve from 0.47252
Epoch 35/300
 - 11s - loss: 477.6828 - acc: 0.9565 - mDice: 0.7634 - val_loss: 2435.7661 - val_acc: 0.9465 - val_mDice: 0.4698

Epoch 00035: val_mDice did not improve from 0.47252
Epoch 36/300
 - 11s - loss: 473.1587 - acc: 0.9568 - mDice: 0.7653 - val_loss: 2380.2645 - val_acc: 0.9466 - val_mDice: 0.4683

Epoch 00036: val_mDice did not improve from 0.47252
Epoch 37/300
 - 11s - loss: 470.5399 - acc: 0.9570 - mDice: 0.7666 - val_loss: 2300.2855 - val_acc: 0.9476 - val_mDice: 0.4787

Epoch 00037: val_mDice improved from 0.47252 to 0.47865, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 10s - loss: 467.4585 - acc: 0.9571 - mDice: 0.7680 - val_loss: 2249.7888 - val_acc: 0.9467 - val_mDice: 0.4823

Epoch 00038: val_mDice improved from 0.47865 to 0.48235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 10s - loss: 463.4133 - acc: 0.9572 - mDice: 0.7703 - val_loss: 2449.5231 - val_acc: 0.9437 - val_mDice: 0.4666

Epoch 00039: val_mDice did not improve from 0.48235
Epoch 40/300
 - 11s - loss: 461.4902 - acc: 0.9573 - mDice: 0.7711 - val_loss: 2601.4243 - val_acc: 0.9430 - val_mDice: 0.4529

Epoch 00040: val_mDice did not improve from 0.48235
Epoch 41/300
 - 10s - loss: 460.6532 - acc: 0.9572 - mDice: 0.7715 - val_loss: 2346.0203 - val_acc: 0.9469 - val_mDice: 0.4759

Epoch 00041: val_mDice did not improve from 0.48235
Epoch 42/300
 - 10s - loss: 458.3956 - acc: 0.9574 - mDice: 0.7726 - val_loss: 2248.5569 - val_acc: 0.9479 - val_mDice: 0.4787

Epoch 00042: val_mDice did not improve from 0.48235
Epoch 43/300
 - 11s - loss: 455.4592 - acc: 0.9575 - mDice: 0.7740 - val_loss: 2572.9146 - val_acc: 0.9464 - val_mDice: 0.4636

Epoch 00043: val_mDice did not improve from 0.48235
Epoch 44/300
 - 11s - loss: 452.1223 - acc: 0.9576 - mDice: 0.7755 - val_loss: 2508.1349 - val_acc: 0.9461 - val_mDice: 0.4717

Epoch 00044: val_mDice did not improve from 0.48235
Epoch 45/300
 - 11s - loss: 447.8811 - acc: 0.9578 - mDice: 0.7777 - val_loss: 2526.8648 - val_acc: 0.9450 - val_mDice: 0.4660

Epoch 00045: val_mDice did not improve from 0.48235
Epoch 46/300
 - 11s - loss: 446.5681 - acc: 0.9579 - mDice: 0.7783 - val_loss: 2422.3277 - val_acc: 0.9470 - val_mDice: 0.4771

Epoch 00046: val_mDice did not improve from 0.48235
Epoch 47/300
 - 11s - loss: 445.1848 - acc: 0.9580 - mDice: 0.7791 - val_loss: 2530.4526 - val_acc: 0.9453 - val_mDice: 0.4614

Epoch 00047: val_mDice did not improve from 0.48235
Epoch 48/300
 - 10s - loss: 440.9042 - acc: 0.9582 - mDice: 0.7814 - val_loss: 2569.6021 - val_acc: 0.9463 - val_mDice: 0.4624

Epoch 00048: val_mDice did not improve from 0.48235
Epoch 49/300
 - 11s - loss: 438.1996 - acc: 0.9583 - mDice: 0.7825 - val_loss: 2413.9136 - val_acc: 0.9471 - val_mDice: 0.4807

Epoch 00049: val_mDice did not improve from 0.48235
Epoch 50/300
 - 11s - loss: 437.1893 - acc: 0.9583 - mDice: 0.7830 - val_loss: 2503.4506 - val_acc: 0.9477 - val_mDice: 0.4748

Epoch 00050: val_mDice did not improve from 0.48235
Epoch 51/300
 - 11s - loss: 433.7525 - acc: 0.9585 - mDice: 0.7845 - val_loss: 2400.4969 - val_acc: 0.9471 - val_mDice: 0.4804

Epoch 00051: val_mDice did not improve from 0.48235
Epoch 52/300
 - 10s - loss: 434.0377 - acc: 0.9585 - mDice: 0.7848 - val_loss: 2561.1427 - val_acc: 0.9472 - val_mDice: 0.4640

Epoch 00052: val_mDice did not improve from 0.48235
Epoch 53/300
 - 11s - loss: 431.0980 - acc: 0.9586 - mDice: 0.7860 - val_loss: 2621.6730 - val_acc: 0.9467 - val_mDice: 0.4699

Epoch 00053: val_mDice did not improve from 0.48235
Epoch 54/300
 - 11s - loss: 430.5412 - acc: 0.9586 - mDice: 0.7862 - val_loss: 2578.2798 - val_acc: 0.9475 - val_mDice: 0.4745

Epoch 00054: val_mDice did not improve from 0.48235
Epoch 55/300
 - 11s - loss: 427.0558 - acc: 0.9589 - mDice: 0.7882 - val_loss: 2541.6981 - val_acc: 0.9472 - val_mDice: 0.4741

Epoch 00055: val_mDice did not improve from 0.48235
Epoch 56/300
 - 10s - loss: 428.1465 - acc: 0.9587 - mDice: 0.7876 - val_loss: 2525.7571 - val_acc: 0.9450 - val_mDice: 0.4744

Epoch 00056: val_mDice did not improve from 0.48235
Epoch 57/300
 - 10s - loss: 423.7287 - acc: 0.9588 - mDice: 0.7896 - val_loss: 2669.3472 - val_acc: 0.9449 - val_mDice: 0.4655

Epoch 00057: val_mDice did not improve from 0.48235
Epoch 58/300
 - 11s - loss: 424.9829 - acc: 0.9588 - mDice: 0.7892 - val_loss: 2509.3722 - val_acc: 0.9470 - val_mDice: 0.4784

Epoch 00058: val_mDice did not improve from 0.48235
Epoch 59/300
 - 11s - loss: 420.3410 - acc: 0.9590 - mDice: 0.7909 - val_loss: 2570.1254 - val_acc: 0.9470 - val_mDice: 0.4740

Epoch 00059: val_mDice did not improve from 0.48235
Epoch 60/300
 - 10s - loss: 418.9195 - acc: 0.9591 - mDice: 0.7919 - val_loss: 2460.1125 - val_acc: 0.9465 - val_mDice: 0.4773

Epoch 00060: val_mDice did not improve from 0.48235
Epoch 61/300
 - 10s - loss: 418.4113 - acc: 0.9592 - mDice: 0.7924 - val_loss: 2583.8337 - val_acc: 0.9482 - val_mDice: 0.4747

Epoch 00061: val_mDice did not improve from 0.48235
Epoch 62/300
 - 10s - loss: 417.3172 - acc: 0.9591 - mDice: 0.7930 - val_loss: 2693.9837 - val_acc: 0.9454 - val_mDice: 0.4548

Epoch 00062: val_mDice did not improve from 0.48235
Epoch 63/300
 - 11s - loss: 415.3330 - acc: 0.9593 - mDice: 0.7938 - val_loss: 2570.8660 - val_acc: 0.9471 - val_mDice: 0.4740

Epoch 00063: val_mDice did not improve from 0.48235
Epoch 64/300
 - 11s - loss: 411.7421 - acc: 0.9594 - mDice: 0.7955 - val_loss: 2759.7156 - val_acc: 0.9476 - val_mDice: 0.4610

Epoch 00064: val_mDice did not improve from 0.48235
Epoch 65/300
 - 11s - loss: 412.6142 - acc: 0.9593 - mDice: 0.7952 - val_loss: 2646.2999 - val_acc: 0.9433 - val_mDice: 0.4609

Epoch 00065: val_mDice did not improve from 0.48235
Epoch 66/300
 - 11s - loss: 411.1229 - acc: 0.9593 - mDice: 0.7958 - val_loss: 2712.7200 - val_acc: 0.9446 - val_mDice: 0.4602

Epoch 00066: val_mDice did not improve from 0.48235
Epoch 67/300
 - 11s - loss: 408.3606 - acc: 0.9596 - mDice: 0.7975 - val_loss: 2573.6869 - val_acc: 0.9471 - val_mDice: 0.4783

Epoch 00067: val_mDice did not improve from 0.48235
Epoch 68/300
 - 11s - loss: 407.3446 - acc: 0.9596 - mDice: 0.7977 - val_loss: 2541.4061 - val_acc: 0.9450 - val_mDice: 0.4748

Epoch 00068: val_mDice did not improve from 0.48235
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
{'val_loss': [2067.6536419208232, 1680.4256720909705, 1705.6139960655798, 1680.821173447829, 1934.8185911912185, 1850.079842200646, 1837.2378228994517, 1937.1636775090144, 1877.6829458383413, 1888.9537623478816, 2044.9664189265325, 1925.673587505634, 2068.388878455529, 2128.179695716271, 2159.1771463247446, 2080.227597163274, 2080.6708931556113, 2131.5112727238584, 2173.1229201096753, 2065.8926849365234, 2579.82874415471, 2114.4135131835938, 2333.281305166391, 2411.358465928298, 2383.008708660419, 2326.583938598633, 2208.060145451472, 2251.0855243389424, 2323.1410962618315, 2378.548357450045, 2660.056688748873, 2327.5164630596455, 2439.5321860680215, 2347.519101069524, 2435.766092153696, 2380.264488220215, 2300.2855212871846, 2249.788782559908, 2449.523122934195, 2601.424329317533, 2346.020260150616, 2248.556946974534, 2572.914608882024, 2508.134860698993, 2526.864834712102, 2422.327687777006, 2530.452574509841, 2569.602051955003, 2413.913558959961, 2503.4506249060996, 2400.4969083345854, 2561.1427213228667, 2621.6730440579927, 2578.279849712665, 2541.6981236384463, 2525.7570583636943, 2669.347207876352, 2509.372234637921, 2570.1254049447866, 2460.112527700571, 2583.8336651141826, 2693.9837458683896, 2570.8660278320312, 2759.7155644343447, 2646.2999185415415, 2712.72001178448, 2573.6868591308594, 2541.4060786320615], 'val_acc': [0.920934273646428, 0.9284856021404266, 0.927755193068431, 0.9413993266912607, 0.938089384482457, 0.9423077152325556, 0.9434379660166227, 0.9419795022560999, 0.9445266356834998, 0.945109106027163, 0.9450906285872827, 0.9469767052393693, 0.9459204192344959, 0.9453864762416253, 0.9423377307561728, 0.9460983482690958, 0.9452939881728246, 0.9470414083737594, 0.9474135339260101, 0.9455251602026132, 0.9406550664168137, 0.9477255734113547, 0.9445682076307443, 0.9439927224929516, 0.9453864487317892, 0.9433524516912607, 0.9472471085878519, 0.9472101307832278, 0.9457886471198156, 0.9437546042295603, 0.9421181609997382, 0.9469327697387109, 0.9441845256548661, 0.9471084773540497, 0.9464774338098673, 0.9466392397880554, 0.94763311285239, 0.9466946927400736, 0.9437245703660525, 0.9429641457704397, 0.946865744315661, 0.9478712104834043, 0.9464404353728662, 0.946054431108328, 0.9450004788545462, 0.9470460437811338, 0.9453194256012256, 0.9463272163501153, 0.9471292541577265, 0.9477348442261035, 0.9471177229514489, 0.9472309740690085, 0.946745576766821, 0.9475452945782588, 0.9471523807598994, 0.944956525013997, 0.9448548303200648, 0.946988236445647, 0.9469743898281684, 0.9464612488563244, 0.9481693552090571, 0.9454095569940714, 0.9471477293051206, 0.9475707090817965, 0.943308548285411, 0.944563592855747, 0.9471385158025302, 0.9449819693198571], 'val_mDice': [0.3064508300561171, 0.38391326339198995, 0.407728528460631, 0.4328349908957115, 0.42145684648018616, 0.4439141071186616, 0.45861091120884967, 0.4366644351528241, 0.4577348576142238, 0.4601086111595997, 0.4432828538119793, 0.4609172811301855, 0.46231309238534707, 0.4588333422747942, 0.44489756885629433, 0.465660047932313, 0.4658847391032256, 0.46957524636617076, 0.4645348580983969, 0.47251816065265584, 0.4184296985085194, 0.46810501928512865, 0.45255379378795624, 0.4398326011231312, 0.4520247449668554, 0.45354969570269954, 0.4684971817410909, 0.4662642596432796, 0.46523223186914736, 0.4562813616715945, 0.43026092877754796, 0.47004961566283154, 0.465166161266657, 0.4684688105032994, 0.46983476957449544, 0.46828703868847626, 0.47865280279746425, 0.48234991929852045, 0.46660439842022383, 0.45287272735283923, 0.47588703895990664, 0.47870840332829034, 0.46361480481349504, 0.4717207198532728, 0.46597549949701017, 0.47706338190115416, 0.46141455609064835, 0.4624214329971717, 0.4806565928917665, 0.4748489767886125, 0.48038887748351466, 0.46402428299188614, 0.46990141387169176, 0.47454731137706685, 0.474087230861187, 0.47444293103539026, 0.4654611727366081, 0.47840628371788907, 0.4739529372980961, 0.4773096522459617, 0.4747365386440204, 0.4547761586996225, 0.47397868077342326, 0.46103406153046167, 0.46089119693407643, 0.4602339594410016, 0.47833799513486713, 0.4748198971725427], 'loss': [2269.6226399326792, 1205.977680282642, 1009.3279751365413, 901.5820323701694, 833.5371424199953, 783.9866584398578, 746.4532262711884, 715.0419256443754, 691.1870029656681, 670.3257743218371, 650.1834468670924, 635.5750072000432, 622.3017124709725, 606.2670986883031, 598.2243933737042, 585.4027561637008, 575.4884369929405, 565.5888753607959, 559.2558877479323, 551.2095307755886, 542.9511368429706, 538.8838408815897, 532.4561320157725, 523.8825900281782, 519.5377237752148, 516.3495809894025, 509.7820516711373, 505.80414163838736, 499.99008328160664, 494.63911021583624, 490.67271694235063, 486.72062746150175, 483.4382616194546, 480.9754395400929, 477.6828365563401, 473.158666821629, 470.5399383232513, 467.4584819312071, 463.41333159513823, 461.49015427726357, 460.6531811202022, 458.39563578199574, 455.45919881987965, 452.1223493556876, 447.8811120956155, 446.5680792214938, 445.18482726470995, 440.90421799312577, 438.1995917297999, 437.1892672444384, 433.752529834894, 434.03769831387837, 431.098007994429, 430.54116471869406, 427.0557781199429, 428.1464614453026, 423.7286712469171, 424.98290091626023, 420.3409924456568, 418.9194856619226, 418.41134418395023, 417.3171899913917, 415.3329720881046, 411.74208446271547, 412.61419519700434, 411.1229483634247, 408.3605675215784, 407.34455471079275], 'acc': [0.8903142246254078, 0.9256761967888466, 0.9338664507817531, 0.938209649201173, 0.9409266843805011, 0.9431986410569674, 0.9447561457655609, 0.9460782231489011, 0.9471923763831361, 0.9480017240962386, 0.9489008562872465, 0.949391869423212, 0.9500397716700497, 0.9507490874579128, 0.9511950750759054, 0.9517258770250586, 0.9521605116705564, 0.9524994622096578, 0.9528558605614156, 0.9531451962722641, 0.95357541676587, 0.9536860245549238, 0.9540497343841211, 0.9544392794213985, 0.9545970151952785, 0.9546939641976614, 0.9550407416792162, 0.9551358028475367, 0.9554483725951407, 0.9556142629418747, 0.9558928708281231, 0.9561170047305557, 0.9562018701898912, 0.9563873858620273, 0.9565314422572416, 0.9567650222782718, 0.9569854778545562, 0.9570566177214246, 0.9572075055851154, 0.957274942817827, 0.9572316008905726, 0.9574338098541129, 0.9575482277998589, 0.9576263980518944, 0.9578022457165196, 0.957855654369693, 0.9580119250006071, 0.9581674665836548, 0.9582579658500473, 0.9583191294561483, 0.9584576896302739, 0.9585288117251405, 0.9585819935365476, 0.9586272854531459, 0.9588749423618962, 0.9586574601959964, 0.9588410011420091, 0.9588363259401332, 0.9590056096837934, 0.9591002292676154, 0.9591874671875084, 0.9591368320660432, 0.9592795169552478, 0.9594178077953169, 0.959313232064478, 0.9593384231982784, 0.9595516494232318, 0.9596031687306509], 'mDice': [0.24413242694675885, 0.44611840648349005, 0.5219128066341474, 0.566259108642519, 0.5964768581984943, 0.618486404210057, 0.6355394544630465, 0.6498444192108056, 0.660850358434811, 0.6710719604900289, 0.6802971372742457, 0.6868857537085067, 0.6934389709096042, 0.7011585758751107, 0.7053538469945901, 0.7108661218134996, 0.715820805767877, 0.7203033755738764, 0.7233849963688448, 0.7276624442246263, 0.731464907998343, 0.7334081515399092, 0.7367084848092489, 0.7403917476654405, 0.742487252434714, 0.7446835827565793, 0.7472660644769251, 0.7492697110180924, 0.7517601162714678, 0.7548809639754291, 0.7567853638576777, 0.7582715870181232, 0.760358727650043, 0.7620711291307982, 0.7634071017459432, 0.7653090907211817, 0.7665854643810106, 0.7679713332245164, 0.7703240312774012, 0.7710947947540395, 0.7714543316974023, 0.7726241274424434, 0.7739626940057736, 0.7755421288699712, 0.7776726537840092, 0.778336853346877, 0.7791241842486878, 0.7814084333675567, 0.7825161568806047, 0.7830301492809865, 0.7844656804143795, 0.7847973870074497, 0.7860349381056855, 0.7861564816512119, 0.7882491582369855, 0.7876160232593991, 0.7895754083412485, 0.7891728512026843, 0.7909288225738609, 0.7919157117008778, 0.7923557837983729, 0.7929585209128537, 0.7937528686055967, 0.7954995258481347, 0.7951903937213218, 0.7957967945672506, 0.797526812719417, 0.797744800653513]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.65s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.39s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.14s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:27,  1.58s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:02,  1.70s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:07,  1.73s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:44,  1.87s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:21,  1.79s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:49,  1.90s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:44,  2.10s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:42,  2.10s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:14,  2.01s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<09:45,  2.13s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<10:05,  2.21s/it]predicting train subjects:   4%|▍         | 12/285 [00:25<10:19,  2.27s/it]predicting train subjects:   5%|▍         | 13/285 [00:27<10:22,  2.29s/it]predicting train subjects:   5%|▍         | 14/285 [00:29<10:16,  2.28s/it]predicting train subjects:   5%|▌         | 15/285 [00:32<10:29,  2.33s/it]predicting train subjects:   6%|▌         | 16/285 [00:34<10:32,  2.35s/it]predicting train subjects:   6%|▌         | 17/285 [00:36<10:22,  2.32s/it]predicting train subjects:   6%|▋         | 18/285 [00:38<10:17,  2.31s/it]predicting train subjects:   7%|▋         | 19/285 [00:41<10:15,  2.32s/it]predicting train subjects:   7%|▋         | 20/285 [00:43<10:17,  2.33s/it]predicting train subjects:   7%|▋         | 21/285 [00:45<10:04,  2.29s/it]predicting train subjects:   8%|▊         | 22/285 [00:48<09:59,  2.28s/it]predicting train subjects:   8%|▊         | 23/285 [00:50<09:51,  2.26s/it]predicting train subjects:   8%|▊         | 24/285 [00:52<09:48,  2.25s/it]predicting train subjects:   9%|▉         | 25/285 [00:54<09:32,  2.20s/it]predicting train subjects:   9%|▉         | 26/285 [00:56<09:09,  2.12s/it]predicting train subjects:   9%|▉         | 27/285 [00:58<09:03,  2.10s/it]predicting train subjects:  10%|▉         | 28/285 [01:00<08:52,  2.07s/it]predicting train subjects:  10%|█         | 29/285 [01:02<08:45,  2.05s/it]predicting train subjects:  11%|█         | 30/285 [01:04<08:31,  2.00s/it]predicting train subjects:  11%|█         | 31/285 [01:06<08:11,  1.94s/it]predicting train subjects:  11%|█         | 32/285 [01:08<07:52,  1.87s/it]predicting train subjects:  12%|█▏        | 33/285 [01:10<08:06,  1.93s/it]predicting train subjects:  12%|█▏        | 34/285 [01:12<08:05,  1.93s/it]predicting train subjects:  12%|█▏        | 35/285 [01:14<08:16,  1.99s/it]predicting train subjects:  13%|█▎        | 36/285 [01:16<08:19,  2.01s/it]predicting train subjects:  13%|█▎        | 37/285 [01:18<08:12,  1.98s/it]predicting train subjects:  13%|█▎        | 38/285 [01:20<08:12,  1.99s/it]predicting train subjects:  14%|█▎        | 39/285 [01:22<08:04,  1.97s/it]predicting train subjects:  14%|█▍        | 40/285 [01:24<08:01,  1.97s/it]predicting train subjects:  14%|█▍        | 41/285 [01:26<08:07,  2.00s/it]predicting train subjects:  15%|█▍        | 42/285 [01:28<07:59,  1.97s/it]predicting train subjects:  15%|█▌        | 43/285 [01:29<07:44,  1.92s/it]predicting train subjects:  15%|█▌        | 44/285 [01:31<07:51,  1.96s/it]predicting train subjects:  16%|█▌        | 45/285 [01:33<08:01,  2.01s/it]predicting train subjects:  16%|█▌        | 46/285 [01:35<07:55,  1.99s/it]predicting train subjects:  16%|█▋        | 47/285 [01:37<07:37,  1.92s/it]predicting train subjects:  17%|█▋        | 48/285 [01:39<07:28,  1.89s/it]predicting train subjects:  17%|█▋        | 49/285 [01:41<07:32,  1.92s/it]predicting train subjects:  18%|█▊        | 50/285 [01:43<07:11,  1.84s/it]predicting train subjects:  18%|█▊        | 51/285 [01:44<06:48,  1.75s/it]predicting train subjects:  18%|█▊        | 52/285 [01:46<06:57,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:48<07:12,  1.87s/it]predicting train subjects:  19%|█▉        | 54/285 [01:50<07:16,  1.89s/it]predicting train subjects:  19%|█▉        | 55/285 [01:52<07:15,  1.89s/it]predicting train subjects:  20%|█▉        | 56/285 [01:54<07:11,  1.88s/it]predicting train subjects:  20%|██        | 57/285 [01:56<07:13,  1.90s/it]predicting train subjects:  20%|██        | 58/285 [01:58<07:23,  1.95s/it]predicting train subjects:  21%|██        | 59/285 [02:00<07:13,  1.92s/it]predicting train subjects:  21%|██        | 60/285 [02:02<07:05,  1.89s/it]predicting train subjects:  21%|██▏       | 61/285 [02:03<07:02,  1.89s/it]predicting train subjects:  22%|██▏       | 62/285 [02:05<07:08,  1.92s/it]predicting train subjects:  22%|██▏       | 63/285 [02:07<07:03,  1.91s/it]predicting train subjects:  22%|██▏       | 64/285 [02:09<06:56,  1.89s/it]predicting train subjects:  23%|██▎       | 65/285 [02:11<07:01,  1.92s/it]predicting train subjects:  23%|██▎       | 66/285 [02:13<07:02,  1.93s/it]predicting train subjects:  24%|██▎       | 67/285 [02:15<06:59,  1.92s/it]predicting train subjects:  24%|██▍       | 68/285 [02:17<06:56,  1.92s/it]predicting train subjects:  24%|██▍       | 69/285 [02:19<06:48,  1.89s/it]predicting train subjects:  25%|██▍       | 70/285 [02:21<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 71/285 [02:22<06:44,  1.89s/it]predicting train subjects:  25%|██▌       | 72/285 [02:24<06:41,  1.89s/it]predicting train subjects:  26%|██▌       | 73/285 [02:26<06:33,  1.86s/it]predicting train subjects:  26%|██▌       | 74/285 [02:28<06:34,  1.87s/it]predicting train subjects:  26%|██▋       | 75/285 [02:30<06:35,  1.88s/it]predicting train subjects:  27%|██▋       | 76/285 [02:32<06:34,  1.89s/it]predicting train subjects:  27%|██▋       | 77/285 [02:34<06:25,  1.86s/it]predicting train subjects:  27%|██▋       | 78/285 [02:36<06:30,  1.88s/it]predicting train subjects:  28%|██▊       | 79/285 [02:37<06:28,  1.89s/it]predicting train subjects:  28%|██▊       | 80/285 [02:39<06:15,  1.83s/it]predicting train subjects:  28%|██▊       | 81/285 [02:41<06:18,  1.86s/it]predicting train subjects:  29%|██▉       | 82/285 [02:43<06:19,  1.87s/it]predicting train subjects:  29%|██▉       | 83/285 [02:45<06:29,  1.93s/it]predicting train subjects:  29%|██▉       | 84/285 [02:47<06:31,  1.95s/it]predicting train subjects:  30%|██▉       | 85/285 [02:49<06:32,  1.96s/it]predicting train subjects:  30%|███       | 86/285 [02:51<06:37,  2.00s/it]predicting train subjects:  31%|███       | 87/285 [02:53<06:34,  1.99s/it]predicting train subjects:  31%|███       | 88/285 [02:55<06:38,  2.02s/it]predicting train subjects:  31%|███       | 89/285 [02:57<06:43,  2.06s/it]predicting train subjects:  32%|███▏      | 90/285 [02:59<06:39,  2.05s/it]predicting train subjects:  32%|███▏      | 91/285 [03:01<06:39,  2.06s/it]predicting train subjects:  32%|███▏      | 92/285 [03:04<06:46,  2.11s/it]predicting train subjects:  33%|███▎      | 93/285 [03:06<06:49,  2.13s/it]predicting train subjects:  33%|███▎      | 94/285 [03:08<07:00,  2.20s/it]predicting train subjects:  33%|███▎      | 95/285 [03:10<06:51,  2.16s/it]predicting train subjects:  34%|███▎      | 96/285 [03:12<06:46,  2.15s/it]predicting train subjects:  34%|███▍      | 97/285 [03:15<06:39,  2.13s/it]predicting train subjects:  34%|███▍      | 98/285 [03:17<06:39,  2.14s/it]predicting train subjects:  35%|███▍      | 99/285 [03:19<06:30,  2.10s/it]predicting train subjects:  35%|███▌      | 100/285 [03:21<06:24,  2.08s/it]predicting train subjects:  35%|███▌      | 101/285 [03:23<06:19,  2.06s/it]predicting train subjects:  36%|███▌      | 102/285 [03:25<06:33,  2.15s/it]predicting train subjects:  36%|███▌      | 103/285 [03:27<06:28,  2.14s/it]predicting train subjects:  36%|███▋      | 104/285 [03:29<06:15,  2.08s/it]predicting train subjects:  37%|███▋      | 105/285 [03:31<06:17,  2.10s/it]predicting train subjects:  37%|███▋      | 106/285 [03:34<06:26,  2.16s/it]predicting train subjects:  38%|███▊      | 107/285 [03:36<06:25,  2.17s/it]predicting train subjects:  38%|███▊      | 108/285 [03:38<06:13,  2.11s/it]predicting train subjects:  38%|███▊      | 109/285 [03:40<06:09,  2.10s/it]predicting train subjects:  39%|███▊      | 110/285 [03:42<06:09,  2.11s/it]predicting train subjects:  39%|███▉      | 111/285 [03:44<06:16,  2.16s/it]predicting train subjects:  39%|███▉      | 112/285 [03:46<06:13,  2.16s/it]predicting train subjects:  40%|███▉      | 113/285 [03:49<06:08,  2.14s/it]predicting train subjects:  40%|████      | 114/285 [03:51<06:06,  2.14s/it]predicting train subjects:  40%|████      | 115/285 [03:53<05:59,  2.11s/it]predicting train subjects:  41%|████      | 116/285 [03:55<05:44,  2.04s/it]predicting train subjects:  41%|████      | 117/285 [03:56<05:27,  1.95s/it]predicting train subjects:  41%|████▏     | 118/285 [03:58<05:23,  1.93s/it]predicting train subjects:  42%|████▏     | 119/285 [04:00<05:20,  1.93s/it]predicting train subjects:  42%|████▏     | 120/285 [04:02<05:15,  1.91s/it]predicting train subjects:  42%|████▏     | 121/285 [04:04<05:03,  1.85s/it]predicting train subjects:  43%|████▎     | 122/285 [04:05<04:50,  1.78s/it]predicting train subjects:  43%|████▎     | 123/285 [04:07<04:42,  1.74s/it]predicting train subjects:  44%|████▎     | 124/285 [04:09<04:43,  1.76s/it]predicting train subjects:  44%|████▍     | 125/285 [04:11<04:42,  1.76s/it]predicting train subjects:  44%|████▍     | 126/285 [04:12<04:46,  1.80s/it]predicting train subjects:  45%|████▍     | 127/285 [04:14<04:48,  1.82s/it]predicting train subjects:  45%|████▍     | 128/285 [04:16<04:49,  1.84s/it]predicting train subjects:  45%|████▌     | 129/285 [04:18<04:38,  1.79s/it]predicting train subjects:  46%|████▌     | 130/285 [04:20<04:38,  1.79s/it]predicting train subjects:  46%|████▌     | 131/285 [04:22<04:38,  1.81s/it]predicting train subjects:  46%|████▋     | 132/285 [04:23<04:35,  1.80s/it]predicting train subjects:  47%|████▋     | 133/285 [04:25<04:29,  1.77s/it]predicting train subjects:  47%|████▋     | 134/285 [04:27<04:19,  1.72s/it]predicting train subjects:  47%|████▋     | 135/285 [04:29<04:33,  1.82s/it]predicting train subjects:  48%|████▊     | 136/285 [04:31<04:34,  1.84s/it]predicting train subjects:  48%|████▊     | 137/285 [04:33<04:44,  1.92s/it]predicting train subjects:  48%|████▊     | 138/285 [04:35<04:41,  1.92s/it]predicting train subjects:  49%|████▉     | 139/285 [04:37<04:44,  1.95s/it]predicting train subjects:  49%|████▉     | 140/285 [04:39<04:44,  1.96s/it]predicting train subjects:  49%|████▉     | 141/285 [04:40<04:33,  1.90s/it]predicting train subjects:  50%|████▉     | 142/285 [04:42<04:28,  1.88s/it]predicting train subjects:  50%|█████     | 143/285 [04:44<04:22,  1.85s/it]predicting train subjects:  51%|█████     | 144/285 [04:45<04:03,  1.73s/it]predicting train subjects:  51%|█████     | 145/285 [04:47<03:51,  1.66s/it]predicting train subjects:  51%|█████     | 146/285 [04:49<03:52,  1.67s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:50<03:54,  1.70s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:52<03:53,  1.70s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:53<03:41,  1.63s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:55<03:34,  1.59s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:56<03:28,  1.55s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:58<03:24,  1.53s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:59<03:17,  1.49s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:01<03:22,  1.54s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:03<03:20,  1.54s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:04<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:06<03:20,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:07<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:09<03:25,  1.63s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:11<03:22,  1.62s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:12<03:20,  1.61s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:14<03:14,  1.58s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:15<03:11,  1.57s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:17<03:07,  1.55s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:19<03:12,  1.60s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:20<03:10,  1.60s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:22<03:04,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:23<03:02,  1.56s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:25<03:00,  1.56s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:26<02:57,  1.54s/it]predicting train subjects:  60%|██████    | 171/285 [05:28<02:52,  1.52s/it]predicting train subjects:  60%|██████    | 172/285 [05:29<02:52,  1.52s/it]predicting train subjects:  61%|██████    | 173/285 [05:31<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:32<02:48,  1.52s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:34<02:47,  1.52s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:35<02:45,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:37<02:42,  1.50s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:38<02:42,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:40<02:41,  1.53s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:41<02:36,  1.49s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:43<02:34,  1.49s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:44<02:36,  1.52s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:46<02:32,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:47<02:28,  1.47s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:49<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:50<02:17,  1.39s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:51<02:19,  1.42s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:53<02:19,  1.43s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:54<02:21,  1.48s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:56<02:19,  1.47s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:57<02:21,  1.51s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:59<02:15,  1.45s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:00<02:10,  1.42s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:01<02:05,  1.38s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:03<02:06,  1.40s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:04<02:11,  1.47s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:06<02:16,  1.56s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:08<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:10<02:27,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [06:12<02:24,  1.70s/it]predicting train subjects:  71%|███████   | 201/285 [06:13<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [06:15<02:16,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [06:16<02:13,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:18<02:11,  1.63s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:20<02:10,  1.63s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:21<02:08,  1.63s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:23<02:09,  1.66s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:25<02:10,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:27<02:14,  1.77s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:29<02:15,  1.81s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:30<02:13,  1.81s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:32<02:09,  1.77s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:34<02:05,  1.74s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:35<01:57,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:37<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:38<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:40<01:43,  1.52s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:41<01:40,  1.50s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:43<01:40,  1.52s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:44<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:46<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:47<01:33,  1.48s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:49<01:31,  1.48s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:50<01:30,  1.48s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:52<01:29,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:53<01:27,  1.49s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:54<01:25,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:56<01:26,  1.51s/it]predicting train subjects:  80%|████████  | 229/285 [06:58<01:24,  1.51s/it]predicting train subjects:  81%|████████  | 230/285 [06:59<01:22,  1.50s/it]predicting train subjects:  81%|████████  | 231/285 [07:01<01:20,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:02<01:25,  1.61s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:04<01:28,  1.71s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:06<01:28,  1.73s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:08<01:26,  1.74s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:10<01:27,  1.79s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:12<01:26,  1.80s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:14<01:26,  1.84s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:16<01:26,  1.88s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:17<01:23,  1.87s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:19<01:22,  1.87s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:21<01:20,  1.88s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:23<01:18,  1.88s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:25<01:17,  1.88s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:27<01:16,  1.92s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:29<01:15,  1.95s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:31<01:13,  1.93s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:33<01:12,  1.97s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:35<01:10,  1.95s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:36<01:02,  1.80s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:38<00:57,  1.69s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:39<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:41<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:42<00:46,  1.51s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:43<00:44,  1.47s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:45<00:42,  1.48s/it]predicting train subjects:  90%|█████████ | 257/285 [07:46<00:41,  1.49s/it]predicting train subjects:  91%|█████████ | 258/285 [07:48<00:40,  1.50s/it]predicting train subjects:  91%|█████████ | 259/285 [07:49<00:37,  1.45s/it]predicting train subjects:  91%|█████████ | 260/285 [07:51<00:36,  1.47s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:52<00:34,  1.44s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:54<00:33,  1.48s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:55<00:32,  1.49s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:57<00:31,  1.52s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:58<00:30,  1.51s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:00<00:29,  1.56s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:01<00:28,  1.57s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:04<00:29,  1.75s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:06<00:29,  1.87s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:08<00:29,  1.94s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:10<00:27,  1.99s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:12<00:26,  2.03s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:14<00:24,  2.01s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:16<00:22,  2.05s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:18<00:19,  1.99s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:20<00:18,  2.01s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:22<00:16,  2.04s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:25<00:14,  2.11s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:26<00:12,  2.06s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:28<00:10,  2.01s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:30<00:08,  2.01s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:32<00:05,  2.00s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:34<00:04,  2.04s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:36<00:02,  2.02s/it]predicting train subjects: 100%|██████████| 285/285 [08:38<00:00,  1.94s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:11,  1.73s/it]Loading train:   1%|          | 2/285 [00:03<08:24,  1.78s/it]Loading train:   1%|          | 3/285 [00:05<08:11,  1.74s/it]Loading train:   1%|▏         | 4/285 [00:07<08:56,  1.91s/it]Loading train:   2%|▏         | 5/285 [00:09<08:54,  1.91s/it]Loading train:   2%|▏         | 6/285 [00:11<09:14,  1.99s/it]Loading train:   2%|▏         | 7/285 [00:13<09:24,  2.03s/it]Loading train:   3%|▎         | 8/285 [00:16<09:39,  2.09s/it]Loading train:   3%|▎         | 9/285 [00:18<09:40,  2.10s/it]Loading train:   4%|▎         | 10/285 [00:20<09:17,  2.03s/it]Loading train:   4%|▍         | 11/285 [00:22<09:40,  2.12s/it]Loading train:   4%|▍         | 12/285 [00:24<09:45,  2.15s/it]Loading train:   5%|▍         | 13/285 [00:26<09:32,  2.10s/it]Loading train:   5%|▍         | 14/285 [00:28<08:50,  1.96s/it]Loading train:   5%|▌         | 15/285 [00:29<08:15,  1.83s/it]Loading train:   6%|▌         | 16/285 [00:31<08:17,  1.85s/it]Loading train:   6%|▌         | 17/285 [00:33<08:09,  1.83s/it]Loading train:   6%|▋         | 18/285 [00:35<08:11,  1.84s/it]Loading train:   7%|▋         | 19/285 [00:37<08:22,  1.89s/it]Loading train:   7%|▋         | 20/285 [00:39<08:30,  1.93s/it]Loading train:   7%|▋         | 21/285 [00:41<08:35,  1.95s/it]Loading train:   8%|▊         | 22/285 [00:43<08:21,  1.91s/it]Loading train:   8%|▊         | 23/285 [00:45<08:35,  1.97s/it]Loading train:   8%|▊         | 24/285 [00:47<08:22,  1.93s/it]Loading train:   9%|▉         | 25/285 [00:48<08:22,  1.93s/it]Loading train:   9%|▉         | 26/285 [00:50<08:23,  1.94s/it]Loading train:   9%|▉         | 27/285 [00:52<08:25,  1.96s/it]Loading train:  10%|▉         | 28/285 [00:54<08:08,  1.90s/it]Loading train:  10%|█         | 29/285 [00:56<07:45,  1.82s/it]Loading train:  11%|█         | 30/285 [00:58<07:39,  1.80s/it]Loading train:  11%|█         | 31/285 [01:00<07:46,  1.84s/it]Loading train:  11%|█         | 32/285 [01:01<07:37,  1.81s/it]Loading train:  12%|█▏        | 33/285 [01:05<10:23,  2.47s/it]Loading train:  12%|█▏        | 34/285 [01:07<09:40,  2.31s/it]Loading train:  12%|█▏        | 35/285 [01:09<09:20,  2.24s/it]Loading train:  13%|█▎        | 36/285 [01:16<14:30,  3.50s/it]Loading train:  13%|█▎        | 37/285 [01:18<12:26,  3.01s/it]Loading train:  13%|█▎        | 38/285 [01:20<11:33,  2.81s/it]Loading train:  14%|█▎        | 39/285 [01:22<10:02,  2.45s/it]Loading train:  14%|█▍        | 40/285 [01:23<09:09,  2.24s/it]Loading train:  14%|█▍        | 41/285 [01:25<08:27,  2.08s/it]Loading train:  15%|█▍        | 42/285 [01:27<08:17,  2.05s/it]Loading train:  15%|█▌        | 43/285 [01:29<07:50,  1.94s/it]Loading train:  15%|█▌        | 44/285 [01:30<07:27,  1.86s/it]Loading train:  16%|█▌        | 45/285 [01:32<07:25,  1.86s/it]Loading train:  16%|█▌        | 46/285 [01:34<07:25,  1.86s/it]Loading train:  16%|█▋        | 47/285 [01:36<07:00,  1.77s/it]Loading train:  17%|█▋        | 48/285 [01:39<08:18,  2.10s/it]Loading train:  17%|█▋        | 49/285 [01:43<10:49,  2.75s/it]Loading train:  18%|█▊        | 50/285 [01:54<20:23,  5.21s/it]Loading train:  18%|█▊        | 51/285 [02:16<40:51, 10.48s/it]Loading train:  18%|█▊        | 52/285 [02:24<37:34,  9.67s/it]Loading train:  19%|█▊        | 53/285 [02:28<30:00,  7.76s/it]Loading train:  19%|█▉        | 54/285 [02:31<24:33,  6.38s/it]Loading train:  19%|█▉        | 55/285 [02:42<30:02,  7.84s/it]Loading train:  20%|█▉        | 56/285 [02:50<29:45,  7.80s/it]Loading train:  20%|██        | 57/285 [02:54<25:11,  6.63s/it]Loading train:  20%|██        | 58/285 [03:22<49:22, 13.05s/it]Loading train:  21%|██        | 59/285 [03:23<36:11,  9.61s/it]Loading train:  21%|██        | 60/285 [03:25<26:53,  7.17s/it]Loading train:  21%|██▏       | 61/285 [03:26<20:23,  5.46s/it]Loading train:  22%|██▏       | 62/285 [03:28<15:58,  4.30s/it]Loading train:  22%|██▏       | 63/285 [03:29<12:52,  3.48s/it]Loading train:  22%|██▏       | 64/285 [03:31<10:36,  2.88s/it]Loading train:  23%|██▎       | 65/285 [03:37<13:47,  3.76s/it]Loading train:  23%|██▎       | 66/285 [03:39<12:09,  3.33s/it]Loading train:  24%|██▎       | 67/285 [03:40<10:04,  2.77s/it]Loading train:  24%|██▍       | 68/285 [03:42<09:10,  2.54s/it]Loading train:  24%|██▍       | 69/285 [03:44<08:37,  2.40s/it]Loading train:  25%|██▍       | 70/285 [03:46<07:54,  2.20s/it]Loading train:  25%|██▍       | 71/285 [03:48<06:59,  1.96s/it]Loading train:  25%|██▌       | 72/285 [03:49<06:21,  1.79s/it]Loading train:  26%|██▌       | 73/285 [03:51<06:15,  1.77s/it]Loading train:  26%|██▌       | 74/285 [03:52<06:02,  1.72s/it]Loading train:  26%|██▋       | 75/285 [03:54<05:44,  1.64s/it]Loading train:  27%|██▋       | 76/285 [03:55<05:35,  1.61s/it]Loading train:  27%|██▋       | 77/285 [03:57<05:45,  1.66s/it]Loading train:  27%|██▋       | 78/285 [03:59<05:43,  1.66s/it]Loading train:  28%|██▊       | 79/285 [04:00<05:33,  1.62s/it]Loading train:  28%|██▊       | 80/285 [04:02<05:15,  1.54s/it]Loading train:  28%|██▊       | 81/285 [04:04<05:39,  1.66s/it]Loading train:  29%|██▉       | 82/285 [04:06<05:58,  1.77s/it]Loading train:  29%|██▉       | 83/285 [04:07<05:58,  1.78s/it]Loading train:  29%|██▉       | 84/285 [04:09<05:50,  1.74s/it]Loading train:  30%|██▉       | 85/285 [04:11<06:02,  1.81s/it]Loading train:  30%|███       | 86/285 [04:13<06:25,  1.94s/it]Loading train:  31%|███       | 87/285 [04:15<06:21,  1.93s/it]Loading train:  31%|███       | 88/285 [04:17<06:24,  1.95s/it]Loading train:  31%|███       | 89/285 [04:19<06:28,  1.98s/it]Loading train:  32%|███▏      | 90/285 [04:21<05:52,  1.81s/it]Loading train:  32%|███▏      | 91/285 [04:23<05:57,  1.84s/it]Loading train:  32%|███▏      | 92/285 [04:25<06:15,  1.95s/it]Loading train:  33%|███▎      | 93/285 [04:27<06:34,  2.05s/it]Loading train:  33%|███▎      | 94/285 [04:29<06:13,  1.95s/it]Loading train:  33%|███▎      | 95/285 [04:31<06:02,  1.91s/it]Loading train:  34%|███▎      | 96/285 [04:33<06:05,  1.94s/it]Loading train:  34%|███▍      | 97/285 [04:35<06:16,  2.00s/it]Loading train:  34%|███▍      | 98/285 [04:37<06:21,  2.04s/it]Loading train:  35%|███▍      | 99/285 [04:39<06:06,  1.97s/it]Loading train:  35%|███▌      | 100/285 [04:41<06:13,  2.02s/it]Loading train:  35%|███▌      | 101/285 [04:42<05:48,  1.89s/it]Loading train:  36%|███▌      | 102/285 [04:44<05:46,  1.89s/it]Loading train:  36%|███▌      | 103/285 [04:46<05:41,  1.88s/it]Loading train:  36%|███▋      | 104/285 [04:48<05:13,  1.73s/it]Loading train:  37%|███▋      | 105/285 [04:49<05:07,  1.71s/it]Loading train:  37%|███▋      | 106/285 [04:51<05:09,  1.73s/it]Loading train:  38%|███▊      | 107/285 [04:52<04:53,  1.65s/it]Loading train:  38%|███▊      | 108/285 [04:54<05:06,  1.73s/it]Loading train:  38%|███▊      | 109/285 [04:56<05:01,  1.71s/it]Loading train:  39%|███▊      | 110/285 [04:58<05:11,  1.78s/it]Loading train:  39%|███▉      | 111/285 [05:00<05:08,  1.78s/it]Loading train:  39%|███▉      | 112/285 [05:02<05:22,  1.86s/it]Loading train:  40%|███▉      | 113/285 [05:04<05:25,  1.89s/it]Loading train:  40%|████      | 114/285 [05:06<05:34,  1.96s/it]Loading train:  40%|████      | 115/285 [05:07<05:10,  1.83s/it]Loading train:  41%|████      | 116/285 [05:09<04:43,  1.68s/it]Loading train:  41%|████      | 117/285 [05:11<04:59,  1.78s/it]Loading train:  41%|████▏     | 118/285 [05:12<04:56,  1.77s/it]Loading train:  42%|████▏     | 119/285 [05:14<04:59,  1.81s/it]Loading train:  42%|████▏     | 120/285 [05:16<04:56,  1.80s/it]Loading train:  42%|████▏     | 121/285 [05:18<04:46,  1.75s/it]Loading train:  43%|████▎     | 122/285 [05:19<04:38,  1.71s/it]Loading train:  43%|████▎     | 123/285 [05:21<04:31,  1.68s/it]Loading train:  44%|████▎     | 124/285 [05:22<04:16,  1.59s/it]Loading train:  44%|████▍     | 125/285 [05:24<04:22,  1.64s/it]Loading train:  44%|████▍     | 126/285 [05:26<04:30,  1.70s/it]Loading train:  45%|████▍     | 127/285 [05:27<04:10,  1.58s/it]Loading train:  45%|████▍     | 128/285 [05:29<04:14,  1.62s/it]Loading train:  45%|████▌     | 129/285 [05:31<04:14,  1.63s/it]Loading train:  46%|████▌     | 130/285 [05:32<04:01,  1.56s/it]Loading train:  46%|████▌     | 131/285 [05:33<03:48,  1.49s/it]Loading train:  46%|████▋     | 132/285 [05:34<03:31,  1.38s/it]Loading train:  47%|████▋     | 133/285 [05:36<03:32,  1.40s/it]Loading train:  47%|████▋     | 134/285 [05:37<03:22,  1.34s/it]Loading train:  47%|████▋     | 135/285 [05:39<03:39,  1.46s/it]Loading train:  48%|████▊     | 136/285 [05:40<03:30,  1.41s/it]Loading train:  48%|████▊     | 137/285 [05:42<03:36,  1.46s/it]Loading train:  48%|████▊     | 138/285 [05:43<03:35,  1.46s/it]Loading train:  49%|████▉     | 139/285 [05:45<03:33,  1.46s/it]Loading train:  49%|████▉     | 140/285 [05:46<03:43,  1.54s/it]Loading train:  49%|████▉     | 141/285 [05:48<03:31,  1.47s/it]Loading train:  50%|████▉     | 142/285 [05:49<03:34,  1.50s/it]Loading train:  50%|█████     | 143/285 [05:51<03:50,  1.62s/it]Loading train:  51%|█████     | 144/285 [05:52<03:32,  1.51s/it]Loading train:  51%|█████     | 145/285 [05:54<03:37,  1.55s/it]Loading train:  51%|█████     | 146/285 [05:55<03:25,  1.48s/it]Loading train:  52%|█████▏    | 147/285 [05:57<03:27,  1.50s/it]Loading train:  52%|█████▏    | 148/285 [05:59<03:29,  1.53s/it]Loading train:  52%|█████▏    | 149/285 [06:00<03:24,  1.50s/it]Loading train:  53%|█████▎    | 150/285 [06:02<03:41,  1.64s/it]Loading train:  53%|█████▎    | 151/285 [06:03<03:23,  1.52s/it]Loading train:  53%|█████▎    | 152/285 [06:05<03:45,  1.69s/it]Loading train:  54%|█████▎    | 153/285 [06:07<03:45,  1.71s/it]Loading train:  54%|█████▍    | 154/285 [06:09<04:08,  1.90s/it]Loading train:  54%|█████▍    | 155/285 [06:11<04:07,  1.90s/it]Loading train:  55%|█████▍    | 156/285 [06:13<03:53,  1.81s/it]Loading train:  55%|█████▌    | 157/285 [06:14<03:31,  1.66s/it]Loading train:  55%|█████▌    | 158/285 [06:16<03:23,  1.61s/it]Loading train:  56%|█████▌    | 159/285 [06:17<03:20,  1.59s/it]Loading train:  56%|█████▌    | 160/285 [06:19<03:21,  1.61s/it]Loading train:  56%|█████▋    | 161/285 [06:21<03:25,  1.66s/it]Loading train:  57%|█████▋    | 162/285 [06:22<03:20,  1.63s/it]Loading train:  57%|█████▋    | 163/285 [06:24<03:17,  1.62s/it]Loading train:  58%|█████▊    | 164/285 [06:25<02:52,  1.42s/it]Loading train:  58%|█████▊    | 165/285 [06:26<02:51,  1.43s/it]Loading train:  58%|█████▊    | 166/285 [06:28<02:46,  1.40s/it]Loading train:  59%|█████▊    | 167/285 [06:29<02:51,  1.46s/it]Loading train:  59%|█████▉    | 168/285 [06:31<02:49,  1.45s/it]Loading train:  59%|█████▉    | 169/285 [06:32<02:38,  1.37s/it]Loading train:  60%|█████▉    | 170/285 [06:33<02:35,  1.35s/it]Loading train:  60%|██████    | 171/285 [06:35<02:42,  1.42s/it]Loading train:  60%|██████    | 172/285 [06:36<02:50,  1.51s/it]Loading train:  61%|██████    | 173/285 [06:38<02:55,  1.57s/it]Loading train:  61%|██████    | 174/285 [06:39<02:48,  1.52s/it]Loading train:  61%|██████▏   | 175/285 [06:41<02:39,  1.45s/it]Loading train:  62%|██████▏   | 176/285 [06:42<02:39,  1.46s/it]Loading train:  62%|██████▏   | 177/285 [06:44<02:36,  1.45s/it]Loading train:  62%|██████▏   | 178/285 [06:45<02:34,  1.45s/it]Loading train:  63%|██████▎   | 179/285 [06:46<02:26,  1.38s/it]Loading train:  63%|██████▎   | 180/285 [06:48<02:24,  1.38s/it]Loading train:  64%|██████▎   | 181/285 [06:49<02:27,  1.42s/it]Loading train:  64%|██████▍   | 182/285 [06:50<02:15,  1.32s/it]Loading train:  64%|██████▍   | 183/285 [06:51<02:09,  1.27s/it]Loading train:  65%|██████▍   | 184/285 [06:53<02:09,  1.28s/it]Loading train:  65%|██████▍   | 185/285 [06:54<02:11,  1.32s/it]Loading train:  65%|██████▌   | 186/285 [06:55<02:07,  1.29s/it]Loading train:  66%|██████▌   | 187/285 [06:57<02:07,  1.30s/it]Loading train:  66%|██████▌   | 188/285 [06:58<02:02,  1.26s/it]Loading train:  66%|██████▋   | 189/285 [06:59<01:53,  1.18s/it]Loading train:  67%|██████▋   | 190/285 [07:00<01:57,  1.23s/it]Loading train:  67%|██████▋   | 191/285 [07:02<02:02,  1.31s/it]Loading train:  67%|██████▋   | 192/285 [07:03<02:05,  1.35s/it]Loading train:  68%|██████▊   | 193/285 [07:05<02:15,  1.47s/it]Loading train:  68%|██████▊   | 194/285 [07:06<02:05,  1.38s/it]Loading train:  68%|██████▊   | 195/285 [07:07<01:59,  1.33s/it]Loading train:  69%|██████▉   | 196/285 [07:09<02:01,  1.37s/it]Loading train:  69%|██████▉   | 197/285 [07:10<02:07,  1.45s/it]Loading train:  69%|██████▉   | 198/285 [07:12<02:05,  1.44s/it]Loading train:  70%|██████▉   | 199/285 [07:13<02:05,  1.46s/it]Loading train:  70%|███████   | 200/285 [07:15<02:11,  1.55s/it]Loading train:  71%|███████   | 201/285 [07:17<02:11,  1.56s/it]Loading train:  71%|███████   | 202/285 [07:18<02:12,  1.59s/it]Loading train:  71%|███████   | 203/285 [07:20<02:20,  1.71s/it]Loading train:  72%|███████▏  | 204/285 [07:22<02:08,  1.59s/it]Loading train:  72%|███████▏  | 205/285 [07:24<02:18,  1.73s/it]Loading train:  72%|███████▏  | 206/285 [07:25<02:17,  1.74s/it]Loading train:  73%|███████▎  | 207/285 [07:27<02:10,  1.67s/it]Loading train:  73%|███████▎  | 208/285 [07:29<02:11,  1.70s/it]Loading train:  73%|███████▎  | 209/285 [07:31<02:16,  1.79s/it]Loading train:  74%|███████▎  | 210/285 [07:32<02:12,  1.77s/it]Loading train:  74%|███████▍  | 211/285 [07:35<02:20,  1.90s/it]Loading train:  74%|███████▍  | 212/285 [07:36<02:14,  1.84s/it]Loading train:  75%|███████▍  | 213/285 [07:38<02:13,  1.86s/it]Loading train:  75%|███████▌  | 214/285 [07:40<02:05,  1.77s/it]Loading train:  75%|███████▌  | 215/285 [07:41<01:58,  1.70s/it]Loading train:  76%|███████▌  | 216/285 [07:43<02:00,  1.74s/it]Loading train:  76%|███████▌  | 217/285 [07:45<02:04,  1.83s/it]Loading train:  76%|███████▋  | 218/285 [07:47<02:04,  1.85s/it]Loading train:  77%|███████▋  | 219/285 [07:49<01:56,  1.76s/it]Loading train:  77%|███████▋  | 220/285 [07:50<01:54,  1.77s/it]Loading train:  78%|███████▊  | 221/285 [07:52<01:56,  1.82s/it]Loading train:  78%|███████▊  | 222/285 [07:54<01:49,  1.74s/it]Loading train:  78%|███████▊  | 223/285 [07:56<01:47,  1.74s/it]Loading train:  79%|███████▊  | 224/285 [07:57<01:39,  1.63s/it]Loading train:  79%|███████▉  | 225/285 [07:58<01:32,  1.53s/it]Loading train:  79%|███████▉  | 226/285 [08:00<01:26,  1.46s/it]Loading train:  80%|███████▉  | 227/285 [08:01<01:23,  1.44s/it]Loading train:  80%|████████  | 228/285 [08:03<01:29,  1.58s/it]Loading train:  80%|████████  | 229/285 [08:04<01:23,  1.49s/it]Loading train:  81%|████████  | 230/285 [08:06<01:30,  1.65s/it]Loading train:  81%|████████  | 231/285 [08:08<01:23,  1.54s/it]Loading train:  81%|████████▏ | 232/285 [08:10<01:30,  1.71s/it]Loading train:  82%|████████▏ | 233/285 [08:11<01:30,  1.74s/it]Loading train:  82%|████████▏ | 234/285 [08:13<01:28,  1.74s/it]Loading train:  82%|████████▏ | 235/285 [08:15<01:30,  1.81s/it]Loading train:  83%|████████▎ | 236/285 [08:17<01:27,  1.79s/it]Loading train:  83%|████████▎ | 237/285 [08:19<01:27,  1.81s/it]Loading train:  84%|████████▎ | 238/285 [08:21<01:26,  1.85s/it]Loading train:  84%|████████▍ | 239/285 [08:22<01:22,  1.80s/it]Loading train:  84%|████████▍ | 240/285 [08:24<01:19,  1.76s/it]Loading train:  85%|████████▍ | 241/285 [08:26<01:17,  1.77s/it]Loading train:  85%|████████▍ | 242/285 [08:28<01:17,  1.81s/it]Loading train:  85%|████████▌ | 243/285 [08:30<01:21,  1.93s/it]Loading train:  86%|████████▌ | 244/285 [08:32<01:20,  1.97s/it]Loading train:  86%|████████▌ | 245/285 [08:34<01:15,  1.88s/it]Loading train:  86%|████████▋ | 246/285 [08:36<01:14,  1.91s/it]Loading train:  87%|████████▋ | 247/285 [08:38<01:15,  1.98s/it]Loading train:  87%|████████▋ | 248/285 [08:40<01:11,  1.93s/it]Loading train:  87%|████████▋ | 249/285 [08:41<01:07,  1.87s/it]Loading train:  88%|████████▊ | 250/285 [08:43<01:04,  1.85s/it]Loading train:  88%|████████▊ | 251/285 [08:45<00:58,  1.73s/it]Loading train:  88%|████████▊ | 252/285 [08:46<00:57,  1.74s/it]Loading train:  89%|████████▉ | 253/285 [08:48<00:55,  1.75s/it]Loading train:  89%|████████▉ | 254/285 [08:50<00:52,  1.69s/it]Loading train:  89%|████████▉ | 255/285 [08:51<00:50,  1.68s/it]Loading train:  90%|████████▉ | 256/285 [08:53<00:47,  1.65s/it]Loading train:  90%|█████████ | 257/285 [08:55<00:48,  1.74s/it]Loading train:  91%|█████████ | 258/285 [08:56<00:41,  1.55s/it]Loading train:  91%|█████████ | 259/285 [08:58<00:41,  1.60s/it]Loading train:  91%|█████████ | 260/285 [08:59<00:40,  1.62s/it]Loading train:  92%|█████████▏| 261/285 [09:01<00:38,  1.62s/it]Loading train:  92%|█████████▏| 262/285 [09:02<00:35,  1.53s/it]Loading train:  92%|█████████▏| 263/285 [09:04<00:35,  1.59s/it]Loading train:  93%|█████████▎| 264/285 [09:06<00:34,  1.63s/it]Loading train:  93%|█████████▎| 265/285 [09:08<00:33,  1.69s/it]Loading train:  93%|█████████▎| 266/285 [09:09<00:30,  1.60s/it]Loading train:  94%|█████████▎| 267/285 [09:10<00:27,  1.55s/it]Loading train:  94%|█████████▍| 268/285 [09:13<00:29,  1.72s/it]Loading train:  94%|█████████▍| 269/285 [09:15<00:29,  1.83s/it]Loading train:  95%|█████████▍| 270/285 [09:16<00:26,  1.80s/it]Loading train:  95%|█████████▌| 271/285 [09:18<00:25,  1.82s/it]Loading train:  95%|█████████▌| 272/285 [09:20<00:24,  1.92s/it]Loading train:  96%|█████████▌| 273/285 [09:22<00:21,  1.80s/it]Loading train:  96%|█████████▌| 274/285 [09:24<00:20,  1.85s/it]Loading train:  96%|█████████▋| 275/285 [09:26<00:18,  1.88s/it]Loading train:  97%|█████████▋| 276/285 [09:27<00:16,  1.80s/it]Loading train:  97%|█████████▋| 277/285 [09:30<00:15,  1.88s/it]Loading train:  98%|█████████▊| 278/285 [09:31<00:13,  1.87s/it]Loading train:  98%|█████████▊| 279/285 [09:33<00:10,  1.75s/it]Loading train:  98%|█████████▊| 280/285 [09:35<00:09,  1.82s/it]Loading train:  99%|█████████▊| 281/285 [09:37<00:07,  1.84s/it]Loading train:  99%|█████████▉| 282/285 [09:39<00:05,  1.96s/it]Loading train:  99%|█████████▉| 283/285 [09:41<00:04,  2.00s/it]Loading train: 100%|█████████▉| 284/285 [09:43<00:01,  1.95s/it]Loading train: 100%|██████████| 285/285 [09:45<00:00,  1.97s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:10, 27.74it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:09, 29.71it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:08, 33.15it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:08, 32.27it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:07, 33.76it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:08, 32.43it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:08, 31.31it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:08, 30.67it/s]concatenating: train:  12%|█▏        | 35/285 [00:01<00:08, 30.89it/s]concatenating: train:  14%|█▎        | 39/285 [00:01<00:07, 31.09it/s]concatenating: train:  15%|█▌        | 43/285 [00:01<00:08, 29.17it/s]concatenating: train:  16%|█▋        | 47/285 [00:01<00:08, 29.57it/s]concatenating: train:  18%|█▊        | 52/285 [00:01<00:07, 33.16it/s]concatenating: train:  20%|█▉        | 56/285 [00:01<00:06, 33.55it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:06, 36.89it/s]concatenating: train:  24%|██▎       | 67/285 [00:01<00:05, 40.04it/s]concatenating: train:  25%|██▌       | 72/285 [00:02<00:05, 42.16it/s]concatenating: train:  27%|██▋       | 77/285 [00:02<00:04, 44.24it/s]concatenating: train:  29%|██▉       | 82/285 [00:02<00:05, 40.52it/s]concatenating: train:  31%|███       | 87/285 [00:02<00:04, 41.63it/s]concatenating: train:  32%|███▏      | 92/285 [00:02<00:04, 42.98it/s]concatenating: train:  34%|███▍      | 97/285 [00:02<00:04, 42.97it/s]concatenating: train:  36%|███▌      | 102/285 [00:02<00:04, 41.76it/s]concatenating: train:  38%|███▊      | 107/285 [00:05<00:31,  5.64it/s]concatenating: train:  39%|███▉      | 111/285 [00:05<00:23,  7.46it/s]concatenating: train:  40%|████      | 115/285 [00:05<00:17,  9.64it/s]concatenating: train:  42%|████▏     | 119/285 [00:05<00:13, 12.04it/s]concatenating: train:  44%|████▎     | 124/285 [00:05<00:10, 15.52it/s]concatenating: train:  45%|████▍     | 128/285 [00:06<00:08, 18.28it/s]concatenating: train:  47%|████▋     | 133/285 [00:06<00:06, 22.10it/s]concatenating: train:  48%|████▊     | 138/285 [00:06<00:05, 25.41it/s]concatenating: train:  50%|█████     | 143/285 [00:06<00:04, 28.78it/s]concatenating: train:  52%|█████▏    | 147/285 [00:06<00:04, 30.59it/s]concatenating: train:  53%|█████▎    | 151/285 [00:06<00:05, 26.40it/s]concatenating: train:  54%|█████▍    | 155/285 [00:06<00:05, 22.46it/s]concatenating: train:  55%|█████▌    | 158/285 [00:07<00:05, 22.96it/s]concatenating: train:  56%|█████▋    | 161/285 [00:07<00:05, 21.88it/s]concatenating: train:  58%|█████▊    | 164/285 [00:07<00:05, 20.84it/s]concatenating: train:  59%|█████▊    | 167/285 [00:07<00:05, 22.13it/s]concatenating: train:  60%|█████▉    | 170/285 [00:07<00:04, 23.57it/s]concatenating: train:  61%|██████    | 174/285 [00:07<00:04, 26.64it/s]concatenating: train:  63%|██████▎   | 179/285 [00:07<00:03, 28.66it/s]concatenating: train:  64%|██████▍   | 183/285 [00:08<00:03, 29.14it/s]concatenating: train:  66%|██████▌   | 187/285 [00:08<00:03, 31.39it/s]concatenating: train:  67%|██████▋   | 192/285 [00:08<00:02, 35.04it/s]concatenating: train:  69%|██████▉   | 196/285 [00:08<00:02, 35.24it/s]concatenating: train:  70%|███████   | 200/285 [00:08<00:02, 33.97it/s]concatenating: train:  72%|███████▏  | 204/285 [00:08<00:02, 33.11it/s]concatenating: train:  73%|███████▎  | 208/285 [00:08<00:02, 32.53it/s]concatenating: train:  74%|███████▍  | 212/285 [00:08<00:02, 31.20it/s]concatenating: train:  76%|███████▌  | 217/285 [00:08<00:01, 34.05it/s]concatenating: train:  78%|███████▊  | 221/285 [00:09<00:01, 33.16it/s]concatenating: train:  79%|███████▉  | 225/285 [00:09<00:01, 32.56it/s]concatenating: train:  80%|████████  | 229/285 [00:09<00:01, 32.16it/s]concatenating: train:  82%|████████▏ | 233/285 [00:09<00:01, 31.88it/s]concatenating: train:  83%|████████▎ | 237/285 [00:09<00:01, 32.30it/s]concatenating: train:  85%|████████▍ | 241/285 [00:09<00:01, 28.64it/s]concatenating: train:  86%|████████▋ | 246/285 [00:09<00:01, 31.40it/s]concatenating: train:  88%|████████▊ | 250/285 [00:10<00:01, 31.36it/s]concatenating: train:  89%|████████▉ | 255/285 [00:10<00:00, 34.98it/s]concatenating: train:  91%|█████████ | 259/285 [00:10<00:00, 33.94it/s]concatenating: train:  92%|█████████▏| 263/285 [00:10<00:00, 33.97it/s]concatenating: train:  94%|█████████▎| 267/285 [00:10<00:00, 33.10it/s]concatenating: train:  95%|█████████▌| 271/285 [00:10<00:00, 27.41it/s]concatenating: train:  96%|█████████▌| 274/285 [00:10<00:00, 26.96it/s]concatenating: train:  97%|█████████▋| 277/285 [00:10<00:00, 25.80it/s]concatenating: train:  98%|█████████▊| 280/285 [00:11<00:00, 24.79it/s]concatenating: train: 100%|█████████▉| 284/285 [00:11<00:00, 26.86it/s]concatenating: train: 100%|██████████| 285/285 [00:11<00:00, 25.37it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.10s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.97s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  33%|███▎      | 1/3 [00:00<00:00,  9.74it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 11.27it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 80)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 80)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 160)  115360      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 160)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 80)   51280       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 160)  0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 80)   115280      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 80)   320         conv2d_7[0][0]                   2019-06-30 21:32:06.258586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 21:32:06.258689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 21:32:06.258712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 21:32:06.258721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 21:32:06.259152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 80)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 40)   12840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 80, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 40)   28840       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 40)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   533         dropout_5[0][0]                  
==================================================================================================
Total params: 731,413
Trainable params: 729,813
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [2.13273029e+01 1.05010629e+01 2.46462697e+01 3.06320970e+00
 8.90359853e+00 2.32172244e+00 2.79665044e+01 3.70132346e+01
 2.82684742e+01 4.35344460e+00 9.66596785e+01 6.42825607e+01
 8.84946717e-02]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 22s - loss: 1300.5747 - acc: 0.8794 - mDice: 0.2932 - val_loss: 1195.7941 - val_acc: 0.9274 - val_mDice: 0.3643

Epoch 00001: val_mDice improved from -inf to 0.36430, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 13s - loss: 679.1990 - acc: 0.9099 - mDice: 0.5150 - val_loss: 1364.5843 - val_acc: 0.9353 - val_mDice: 0.3884

Epoch 00002: val_mDice improved from 0.36430 to 0.38835, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 564.8941 - acc: 0.9204 - mDice: 0.5851 - val_loss: 1535.1765 - val_acc: 0.9349 - val_mDice: 0.3906

Epoch 00003: val_mDice improved from 0.38835 to 0.39061, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 504.3199 - acc: 0.9251 - mDice: 0.6238 - val_loss: 1502.6303 - val_acc: 0.9389 - val_mDice: 0.4280

Epoch 00004: val_mDice improved from 0.39061 to 0.42804, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 459.9824 - acc: 0.9285 - mDice: 0.6553 - val_loss: 1670.6309 - val_acc: 0.9391 - val_mDice: 0.4177

Epoch 00005: val_mDice did not improve from 0.42804
Epoch 6/300
 - 13s - loss: 432.0000 - acc: 0.9306 - mDice: 0.6750 - val_loss: 1676.8718 - val_acc: 0.9396 - val_mDice: 0.4321

Epoch 00006: val_mDice improved from 0.42804 to 0.43213, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 13s - loss: 406.3944 - acc: 0.9325 - mDice: 0.6931 - val_loss: 1519.3837 - val_acc: 0.9414 - val_mDice: 0.4393

Epoch 00007: val_mDice improved from 0.43213 to 0.43932, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 387.7189 - acc: 0.9338 - mDice: 0.7060 - val_loss: 1562.3578 - val_acc: 0.9413 - val_mDice: 0.4470

Epoch 00008: val_mDice improved from 0.43932 to 0.44696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 371.8394 - acc: 0.9353 - mDice: 0.7185 - val_loss: 1579.4093 - val_acc: 0.9430 - val_mDice: 0.4453

Epoch 00009: val_mDice did not improve from 0.44696
Epoch 10/300
 - 13s - loss: 357.7020 - acc: 0.9362 - mDice: 0.7279 - val_loss: 1725.7127 - val_acc: 0.9383 - val_mDice: 0.4262

Epoch 00010: val_mDice did not improve from 0.44696
Epoch 11/300
 - 13s - loss: 346.3189 - acc: 0.9370 - mDice: 0.7365 - val_loss: 1772.7510 - val_acc: 0.9387 - val_mDice: 0.4252

Epoch 00011: val_mDice did not improve from 0.44696
Epoch 12/300
 - 13s - loss: 336.6984 - acc: 0.9382 - mDice: 0.7440 - val_loss: 1693.1222 - val_acc: 0.9402 - val_mDice: 0.4356

Epoch 00012: val_mDice did not improve from 0.44696
Epoch 13/300
 - 13s - loss: 329.1971 - acc: 0.9386 - mDice: 0.7496 - val_loss: 1632.0369 - val_acc: 0.9427 - val_mDice: 0.4558

Epoch 00013: val_mDice improved from 0.44696 to 0.45581, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 14s - loss: 320.1907 - acc: 0.9391 - mDice: 0.7564 - val_loss: 1801.4865 - val_acc: 0.9443 - val_mDice: 0.4459

Epoch 00014: val_mDice did not improve from 0.45581
Epoch 15/300
 - 14s - loss: 312.6929 - acc: 0.9394 - mDice: 0.7617 - val_loss: 1731.4482 - val_acc: 0.9439 - val_mDice: 0.4568

Epoch 00015: val_mDice improved from 0.45581 to 0.45675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 13s - loss: 305.1800 - acc: 0.9405 - mDice: 0.7672 - val_loss: 1971.2999 - val_acc: 0.9434 - val_mDice: 0.4381

Epoch 00016: val_mDice did not improve from 0.45675
Epoch 17/300
 - 13s - loss: 300.6960 - acc: 0.9409 - mDice: 0.7707 - val_loss: 1731.5264 - val_acc: 0.9441 - val_mDice: 0.4523

Epoch 00017: val_mDice did not improve from 0.45675
Epoch 18/300
 - 13s - loss: 295.9406 - acc: 0.9412 - mDice: 0.7745 - val_loss: 1668.0896 - val_acc: 0.9414 - val_mDice: 0.4568

Epoch 00018: val_mDice improved from 0.45675 to 0.45680, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 14s - loss: 290.2348 - acc: 0.9417 - mDice: 0.7787 - val_loss: 1789.2027 - val_acc: 0.9428 - val_mDice: 0.4539

Epoch 00019: val_mDice did not improve from 0.45680
Epoch 20/300
 - 14s - loss: 284.9657 - acc: 0.9422 - mDice: 0.7828 - val_loss: 1852.6700 - val_acc: 0.9426 - val_mDice: 0.4421

Epoch 00020: val_mDice did not improve from 0.45680
Epoch 21/300
 - 13s - loss: 281.0000 - acc: 0.9426 - mDice: 0.7857 - val_loss: 1857.2402 - val_acc: 0.9446 - val_mDice: 0.4492

Epoch 00021: val_mDice did not improve from 0.45680
Epoch 22/300
 - 14s - loss: 277.4277 - acc: 0.9429 - mDice: 0.7882 - val_loss: 1902.9632 - val_acc: 0.9416 - val_mDice: 0.4466

Epoch 00022: val_mDice did not improve from 0.45680
Epoch 23/300
 - 14s - loss: 272.9786 - acc: 0.9429 - mDice: 0.7914 - val_loss: 1754.4442 - val_acc: 0.9425 - val_mDice: 0.4567

Epoch 00023: val_mDice did not improve from 0.45680
Epoch 24/300
 - 14s - loss: 269.0109 - acc: 0.9437 - mDice: 0.7945 - val_loss: 1843.3793 - val_acc: 0.9421 - val_mDice: 0.4456

Epoch 00024: val_mDice did not improve from 0.45680
Epoch 25/300
 - 14s - loss: 265.5876 - acc: 0.9437 - mDice: 0.7972 - val_loss: 1829.0957 - val_acc: 0.9428 - val_mDice: 0.4504

Epoch 00025: val_mDice did not improve from 0.45680
Epoch 26/300
 - 14s - loss: 263.3126 - acc: 0.9439 - mDice: 0.7991 - val_loss: 1882.4716 - val_acc: 0.9427 - val_mDice: 0.4554

Epoch 00026: val_mDice did not improve from 0.45680
Epoch 27/300
 - 13s - loss: 258.7705 - acc: 0.9445 - mDice: 0.8024 - val_loss: 1850.2487 - val_acc: 0.9440 - val_mDice: 0.4640

Epoch 00027: val_mDice improved from 0.45680 to 0.46398, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 14s - loss: 256.6288 - acc: 0.9447 - mDice: 0.8039 - val_loss: 2087.3238 - val_acc: 0.9426 - val_mDice: 0.4396

Epoch 00028: val_mDice did not improve from 0.46398
Epoch 29/300
 - 13s - loss: 254.8346 - acc: 0.9448 - mDice: 0.8056 - val_loss: 1957.8990 - val_acc: 0.9415 - val_mDice: 0.4481

Epoch 00029: val_mDice did not improve from 0.46398
Epoch 30/300
 - 14s - loss: 251.5536 - acc: 0.9452 - mDice: 0.8080 - val_loss: 1959.4513 - val_acc: 0.9425 - val_mDice: 0.4563

Epoch 00030: val_mDice did not improve from 0.46398
Epoch 31/300
 - 13s - loss: 248.2976 - acc: 0.9453 - mDice: 0.8103 - val_loss: 1966.6153 - val_acc: 0.9422 - val_mDice: 0.4498

Epoch 00031: val_mDice did not improve from 0.46398
Epoch 32/300
 - 13s - loss: 245.9201 - acc: 0.9456 - mDice: 0.8121 - val_loss: 1948.5221 - val_acc: 0.9432 - val_mDice: 0.4569

Epoch 00032: val_mDice did not improve from 0.46398
Epoch 33/300
 - 13s - loss: 244.4218 - acc: 0.9459 - mDice: 0.8132 - val_loss: 2002.6970 - val_acc: 0.9393 - val_mDice: 0.4363

Epoch 00033: val_mDice did not improve from 0.46398
Epoch 34/300
 - 13s - loss: 242.5450 - acc: 0.9458 - mDice: 0.8148 - val_loss: 2070.1600 - val_acc: 0.9416 - val_mDice: 0.4505

Epoch 00034: val_mDice did not improve from 0.46398
Epoch 35/300
 - 13s - loss: 239.9057 - acc: 0.9462 - mDice: 0.8170 - val_loss: 2168.3019 - val_acc: 0.9399 - val_mDice: 0.4310

Epoch 00035: val_mDice did not improve from 0.46398
Epoch 36/300
 - 14s - loss: 237.5656 - acc: 0.9466 - mDice: 0.8186 - val_loss: 1949.6189 - val_acc: 0.9425 - val_mDice: 0.4442

Epoch 00036: val_mDice did not improve from 0.46398
Epoch 37/300
 - 13s - loss: 236.4829 - acc: 0.9469 - mDice: 0.8196 - val_loss: 2072.7995 - val_acc: 0.9427 - val_mDice: 0.4472

Epoch 00037: val_mDice did not improve from 0.46398
Epoch 38/300
 - 13s - loss: 234.0239 - acc: 0.9467 - mDice: 0.8210 - val_loss: 2109.7261 - val_acc: 0.9422 - val_mDice: 0.4455

Epoch 00038: val_mDice did not improve from 0.46398
Epoch 39/300
 - 13s - loss: 232.2045 - acc: 0.9468 - mDice: 0.8228 - val_loss: 2057.9883 - val_acc: 0.9394 - val_mDice: 0.4387

Epoch 00039: val_mDice did not improve from 0.46398
Epoch 40/300
 - 14s - loss: 231.4689 - acc: 0.9469 - mDice: 0.8232 - val_loss: 1867.1569 - val_acc: 0.9438 - val_mDice: 0.4668

Epoch 00040: val_mDice improved from 0.46398 to 0.46676, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 41/300
 - 14s - loss: 229.0317 - acc: 0.9474 - mDice: 0.8251 - val_loss: 2067.7309 - val_acc: 0.9418 - val_mDice: 0.4496

Epoch 00041: val_mDice did not improve from 0.46676
Epoch 42/300
 - 13s - loss: 227.5705 - acc: 0.9473 - mDice: 0.8261 - val_loss: 2012.7712 - val_acc: 0.9420 - val_mDice: 0.4563

Epoch 00042: val_mDice did not improve from 0.46676
Epoch 43/300
 - 13s - loss: 225.3566 - acc: 0.9475 - mDice: 0.8280 - val_loss: 2095.0835 - val_acc: 0.9430 - val_mDice: 0.4557

Epoch 00043: val_mDice did not improve from 0.46676
Epoch 44/300
 - 14s - loss: 223.9951 - acc: 0.9477 - mDice: 0.8286 - val_loss: 1991.8007 - val_acc: 0.9430 - val_mDice: 0.4640

Epoch 00044: val_mDice did not improve from 0.46676
Epoch 45/300
 - 14s - loss: 223.0592 - acc: 0.9476 - mDice: 0.8297 - val_loss: 2065.1546 - val_acc: 0.9424 - val_mDice: 0.4556

Epoch 00045: val_mDice did not improve from 0.46676
Epoch 46/300
 - 14s - loss: 222.0793 - acc: 0.9476 - mDice: 0.8306 - val_loss: 2081.6167 - val_acc: 0.9393 - val_mDice: 0.4398

Epoch 00046: val_mDice did not improve from 0.46676
Epoch 47/300
 - 13s - loss: 219.4541 - acc: 0.9480 - mDice: 0.8324 - val_loss: 2014.2171 - val_acc: 0.9414 - val_mDice: 0.4531

Epoch 00047: val_mDice did not improve from 0.46676
Epoch 48/300
 - 13s - loss: 218.5472 - acc: 0.9482 - mDice: 0.8329 - val_loss: 2203.1668 - val_acc: 0.9427 - val_mDice: 0.4404

Epoch 00048: val_mDice did not improve from 0.46676
Epoch 49/300
 - 14s - loss: 216.8858 - acc: 0.9486 - mDice: 0.8343 - val_loss: 2189.3048 - val_acc: 0.9421 - val_mDice: 0.4466

Epoch 00049: val_mDice did not improve from 0.46676
Epoch 50/300
 - 14s - loss: 215.4866 - acc: 0.9486 - mDice: 0.8354 - val_loss: 2210.0831 - val_acc: 0.9408 - val_mDice: 0.4387

Epoch 00050: val_mDice did not improve from 0.46676
Epoch 51/300
 - 13s - loss: 213.8263 - acc: 0.9488 - mDice: 0.8368 - val_loss: 2089.6766 - val_acc: 0.9395 - val_mDice: 0.4382

Epoch 00051: val_mDice did not improve from 0.46676
Epoch 52/300
 - 13s - loss: 213.7302 - acc: 0.9488 - mDice: 0.8370 - val_loss: 2029.0049 - val_acc: 0.9394 - val_mDice: 0.4456

Epoch 00052: val_mDice did not improve from 0.46676
Epoch 53/300
 - 13s - loss: 211.7338 - acc: 0.9489 - mDice: 0.8382 - val_loss: 2107.3779 - val_acc: 0.9415 - val_mDice: 0.4484

Epoch 00053: val_mDice did not improve from 0.46676
Epoch 54/300
 - 13s - loss: 212.0456 - acc: 0.9492 - mDice: 0.8382 - val_loss: 2080.9540 - val_acc: 0.9439 - val_mDice: 0.4550

Epoch 00054: val_mDice did not improve from 0.46676
Epoch 55/300
 - 14s - loss: 209.8083 - acc: 0.9493 - mDice: 0.8397 - val_loss: 2249.5592 - val_acc: 0.9432 - val_mDice: 0.4430

Epoch 00055: val_mDice did not improve from 0.46676
Epoch 56/300
 - 14s - loss: 208.8586 - acc: 0.9493 - mDice: 0.8405 - val_loss: 2181.0248 - val_acc: 0.9417 - val_mDice: 0.4436

Epoch 00056: val_mDice did not improve from 0.46676
Epoch 57/300
 - 13s - loss: 208.0273 - acc: 0.9493 - mDice: 0.8411 - val_loss: 2147.5782 - val_acc: 0.9444 - val_mDice: 0.4602

Epoch 00057: val_mDice did not improve from 0.46676
Epoch 58/300
 - 13s - loss: 206.9037 - acc: 0.9493 - mDice: 0.8420 - val_loss: 2263.3550 - val_acc: 0.9428 - val_mDice: 0.4545

Epoch 00058: val_mDice did not improve from 0.46676
Epoch 59/300
 - 13s - loss: 205.4198 - acc: 0.9494 - mDice: 0.8433 - val_loss: 2279.6251 - val_acc: 0.9433 - val_mDice: 0.4494

Epoch 00059: val_mDice did not improve from 0.46676
Epoch 60/300
 - 13s - loss: 203.7514 - acc: 0.9494 - mDice: 0.8445 - val_loss: 2108.4510 - val_acc: 0.9443 - val_mDice: 0.4560

Epoch 00060: val_mDice did not improve from 0.46676
Epoch 61/300
 - 13s - loss: 204.0147 - acc: 0.9495 - mDice: 0.8443 - val_loss: 2206.4320 - val_acc: 0.9429 - val_mDice: 0.4523

Epoch 00061: val_mDice did not improve from 0.46676
Epoch 62/300
 - 14s - loss: 202.5632 - acc: 0.9497 - mDice: 0.8454 - val_loss: 2181.5437 - val_acc: 0.9422 - val_mDice: 0.4427

Epoch 00062: val_mDice did not improve from 0.46676
Epoch 63/300
 - 14s - loss: 202.0991 - acc: 0.9500 - mDice: 0.8457 - val_loss: 2036.9586 - val_acc: 0.9421 - val_mDice: 0.4617

Epoch 00063: val_mDice did not improve from 0.46676
Epoch 64/300
 - 13s - loss: 200.7491 - acc: 0.9499 - mDice: 0.8467 - val_loss: 2235.0816 - val_acc: 0.9391 - val_mDice: 0.4367

Epoch 00064: val_mDice did not improve from 0.46676
Epoch 65/300
 - 13s - loss: 201.0022 - acc: 0.9498 - mDice: 0.8466 - val_loss: 2283.0533 - val_acc: 0.9405 - val_mDice: 0.4380

Epoch 00065: val_mDice did not improve from 0.46676
Epoch 66/300
 - 13s - loss: 199.1710 - acc: 0.9504 - mDice: 0.8481 - val_loss: 2250.5040 - val_acc: 0.9439 - val_mDice: 0.4440

Epoch 00066: val_mDice did not improve from 0.46676
Epoch 67/300
 - 13s - loss: 198.8463 - acc: 0.9501 - mDice: 0.8481 - val_loss: 2181.3523 - val_acc: 0.9428 - val_mDice: 0.4547

Epoch 00067: val_mDice did not improve from 0.46676
Epoch 68/300
 - 13s - loss: 198.0134 - acc: 0.9500 - mDice: 0.8490 - val_loss: 2126.6162 - val_acc: 0.9415 - val_mDice: 0.4623

Epoch 00068: val_mDice did not improve from 0.46676
Epoch 69/300
 - 14s - loss: 196.4121 - acc: 0.9503 - mDice: 0.8500 - val_loss: 2337.9180 - val_acc: 0.9425 - val_mDice: 0.4403

Epoch 00069: val_mDice did not improve from 0.46676
Epoch 70/300
 - 14s - loss: 196.4023 - acc: 0.9502 - mDice: 0.8501 - val_loss: 2363.4088 - val_acc: 0.9403 - val_mDice: 0.4272

Epoch 00070: val_mDice did not improve from 0.46676
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
{'val_loss': [1195.794127191816, 1364.5842859177362, 1535.1765134788695, 1502.6303398609161, 1670.6308815081914, 1676.8717886095956, 1519.383705065364, 1562.3577909639903, 1579.4093342849187, 1725.712654352188, 1772.7509664297104, 1693.1221966686703, 1632.0369304134733, 1801.4864686670758, 1731.448216937837, 1971.2999221710932, 1731.5264369589943, 1668.0895850204286, 1789.2027442114693, 1852.6700148355394, 1857.2402275516874, 1902.9631941545576, 1754.4442127488908, 1843.3793077752703, 1829.0957234530222, 1882.4716099500656, 1850.2486655257997, 2087.3237514382317, 1957.898971716563, 1959.4512734867278, 1966.6152913116273, 1948.5221489667892, 2002.697036635308, 2070.160025085722, 2168.301884214083, 1949.6188960756574, 2072.799530863762, 2109.7260590962, 2057.9882519585744, 1867.156854391098, 2067.730903012412, 2012.7712089447748, 2095.0834955260866, 1991.800717830658, 2065.1546478441783, 2081.6167088122593, 2014.2171333857946, 2203.1668391454787, 2189.304783684867, 2210.0830670197806, 2089.6765670776367, 2029.0048639887855, 2107.377921910513, 2080.9539846238636, 2249.559167668933, 2181.0247689542316, 2147.5781833728156, 2263.3550199781143, 2279.6251193795883, 2108.4510131449924, 2206.432038057418, 2181.5436578364597, 2036.9586321058728, 2235.0815945012228, 2283.0533387888045, 2250.5040188914254, 2181.352302051726, 2126.616233121781, 2337.918002826827, 2363.4088105587734], 'val_acc': [0.9274198980558486, 0.9352747116770063, 0.9348718041465396, 0.938898830186753, 0.9391208574885413, 0.9395993635767982, 0.9414240008308774, 0.941330109323774, 0.9430242634954906, 0.9383173187573751, 0.9387339977991014, 0.9402083499091012, 0.9426923309053693, 0.9443086215427944, 0.9439239956083751, 0.94343406245822, 0.9441254734992981, 0.9414125567390805, 0.9427907466888428, 0.9425663891292754, 0.9446130792299906, 0.9416254475003197, 0.9425435094606309, 0.9421268502871195, 0.9427724537395296, 0.9427495542026701, 0.944013272012983, 0.9425915735108512, 0.9414674895150321, 0.9425160203661237, 0.9421520346686953, 0.9432234423501151, 0.9392582206499009, 0.9415636516752697, 0.9398718078931173, 0.9425343388602847, 0.9427060342970348, 0.9421680399349758, 0.9394482374191284, 0.9438072443008423, 0.941783396970658, 0.9420283607074192, 0.9429532913934617, 0.9429716098876226, 0.9424221657571339, 0.9393498415038699, 0.9414491738591876, 0.9426785593941098, 0.9420993356477647, 0.9407669390950885, 0.9394825782094683, 0.9393796040898278, 0.9414949644179571, 0.9438598695255461, 0.9432463560785566, 0.9417009892917815, 0.9443933396112352, 0.9428342552412123, 0.9433241827147347, 0.9443017159189496, 0.9429395340737843, 0.9422115286191305, 0.942076441787538, 0.9390636455445063, 0.9404624445097787, 0.9439469093368167, 0.9428228253409976, 0.9414835174878439, 0.9425228862535386, 0.9402541092463902], 'val_mDice': [0.36429681487026666, 0.3883539814324606, 0.3906106370545569, 0.42803801720341045, 0.4176994367014794, 0.4321325135727723, 0.43932386877990903, 0.4469600930100396, 0.4453155446265425, 0.4261926742536681, 0.42524579220584463, 0.43563414152179447, 0.4558100856485821, 0.44585008617667926, 0.45675176062754225, 0.43810688101110007, 0.4523298421076366, 0.456803572142408, 0.45386831320467447, 0.44206511530847775, 0.44924823354397503, 0.4465754482717741, 0.4566659402279627, 0.44558468070768176, 0.4504079400073914, 0.4553748842860971, 0.46397694218016805, 0.43956038675137926, 0.4481035460318838, 0.45632679015398026, 0.4497746005654335, 0.4569369362933295, 0.4363260318835576, 0.45047396119861377, 0.43100890588192714, 0.4441905672706309, 0.44718565029047785, 0.4455080142333394, 0.4386974246728988, 0.4667635198150362, 0.44955567980096456, 0.45634614268229123, 0.4556668744910331, 0.46400080248713493, 0.4555704387880507, 0.4397776387631893, 0.4531477099018438, 0.44039936274999664, 0.44655415539940196, 0.43869732817014057, 0.4382351812507425, 0.4456303813272998, 0.4484192989766598, 0.4549630686995529, 0.4430499749169463, 0.4436256903268042, 0.4602250041706221, 0.45445932714002474, 0.4494307793322064, 0.4559749952029614, 0.4522905484551475, 0.44270535930991173, 0.4617326021904037, 0.4366973203917344, 0.43795709170046304, 0.44399539807013105, 0.45474368262858617, 0.46230350009032656, 0.4402865680555503, 0.42721832508132573], 'loss': [1300.5747304827762, 679.1989775746457, 564.8940802582064, 504.31991758947777, 459.9823857975392, 432.0000463970737, 406.39436550666215, 387.71885132518423, 371.83938124424833, 357.7020387872005, 346.31892360012864, 336.6984429786907, 329.1970561909864, 320.1907246495709, 312.6929305756692, 305.1800362958553, 300.6959931973159, 295.94056325412015, 290.2347632180709, 284.96566315020857, 280.99995362646024, 277.4276728632824, 272.9786227689397, 269.0108946430125, 265.5876400331461, 263.31257455537883, 258.77049052685425, 256.628759277885, 254.83455570736487, 251.55358047147053, 248.2975673201182, 245.92008188195098, 244.42183778408705, 242.54503098990338, 239.90568869307432, 237.56558191061526, 236.48285756682026, 234.02391406137036, 232.2044831940221, 231.4688598268037, 229.03170229204133, 227.5705391431742, 225.356626011628, 223.9951228856443, 223.05923022124404, 222.07927766663505, 219.45411495328617, 218.54719952358454, 216.88576614500494, 215.48664364686977, 213.826302391039, 213.7302482050463, 211.73382746628627, 212.0455920438397, 209.80829186896403, 208.8586050768636, 208.02729037218478, 206.90370740094394, 205.41984836687948, 203.75140943613636, 204.0146879979772, 202.5631510063658, 202.09906229431377, 200.74909627196277, 201.00221877266313, 199.17097603463475, 198.84627910236736, 198.0133950722707, 196.41211082527627, 196.402281594042], 'acc': [0.8794364327522103, 0.9099123084478487, 0.920380718105442, 0.9251250595124397, 0.9284939401775328, 0.9306026690264118, 0.932547761786299, 0.9337717683668745, 0.9353164967507877, 0.9362166045211703, 0.9370210147188972, 0.938183500182084, 0.9385672508118951, 0.9391165399381323, 0.9394496551983982, 0.9404885421512627, 0.9409489153046036, 0.941179342816417, 0.9417081212799788, 0.9422021202322189, 0.9425634381765112, 0.9428501459980875, 0.942892017267057, 0.9436938092500368, 0.9436994626477478, 0.9439133156327262, 0.9444731902428071, 0.9446980510232351, 0.9448479500169903, 0.9452057942067219, 0.9453333757023419, 0.9456104886354866, 0.945933062997608, 0.9457583290224754, 0.9461512506663144, 0.946564610980714, 0.9469298682438976, 0.9466585298597594, 0.9468234412721156, 0.9469359193736242, 0.9473502769023439, 0.94733609716764, 0.9475381557987861, 0.9476804279950122, 0.9475771068538432, 0.9476338540838936, 0.9479866907135562, 0.9481826084805105, 0.9486428497957774, 0.9486192813010627, 0.948847338439459, 0.9488290815723869, 0.9488753569201971, 0.9491844915323274, 0.9492723103637798, 0.9492579901726323, 0.9492648737449418, 0.949349913933568, 0.9494027210748194, 0.9494028852030517, 0.9494635695916553, 0.949689196774972, 0.950044930004214, 0.9499346320055021, 0.9498146489587206, 0.950437485206465, 0.9500602959138662, 0.9500344122722472, 0.9502588735395299, 0.9502423097224555], 'mDice': [0.2932284946099329, 0.5150345869438483, 0.5850753768436799, 0.6238023627349033, 0.6553118090328969, 0.6749507269579849, 0.6930590292748767, 0.7060414294137508, 0.7184667386989362, 0.7279024843377186, 0.7364964211678859, 0.7439917220139931, 0.7496047794232829, 0.7563774941720001, 0.7616944459561601, 0.7671689632680344, 0.7707186858847533, 0.7745428406390147, 0.7786517427770623, 0.7828245848066802, 0.7857353906078055, 0.7881907227183207, 0.7914394080374589, 0.7945282867769756, 0.7971763221979004, 0.7990522825559349, 0.802417347133332, 0.8039415172466957, 0.8055688067394482, 0.8079775261102164, 0.8102503248508528, 0.8120915986840289, 0.813203016066565, 0.8148484353571469, 0.8169647192757369, 0.8185930864554001, 0.8196445625136761, 0.8210378799085468, 0.8228213604829067, 0.8232154312082308, 0.8250943070343286, 0.8261220663849136, 0.8280006998739469, 0.8286480042018343, 0.8297355565832648, 0.8306446026831849, 0.8323851806225289, 0.8329050574018612, 0.8342723766227252, 0.8354429732358177, 0.8368190103972696, 0.8369983062363553, 0.8381935481922186, 0.8381534055958416, 0.839691691495606, 0.8404886237178116, 0.8410754610583436, 0.8420298124798373, 0.8432854881446578, 0.8445430497156073, 0.8443142518915375, 0.8453771625499126, 0.8456944782356548, 0.8467406141107565, 0.846600624461015, 0.8481151196959852, 0.8481410950715311, 0.8489569928895676, 0.850012474375376, 0.8501229620586591]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.57s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.32s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:32,  1.59s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:04,  1.71s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:09,  1.74s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:48,  1.88s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:23,  1.80s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:57,  1.93s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:26,  2.04s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:33,  2.07s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:29,  2.06s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<09:35,  2.09s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<09:48,  2.15s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:45,  2.14s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<09:48,  2.17s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<09:36,  2.13s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:43,  2.16s/it]predicting train subjects:   6%|▌         | 16/285 [00:33<09:54,  2.21s/it]predicting train subjects:   6%|▌         | 17/285 [00:35<09:53,  2.22s/it]predicting train subjects:   6%|▋         | 18/285 [00:37<09:55,  2.23s/it]predicting train subjects:   7%|▋         | 19/285 [00:40<09:59,  2.25s/it]predicting train subjects:   7%|▋         | 20/285 [00:42<10:07,  2.29s/it]predicting train subjects:   7%|▋         | 21/285 [00:44<10:00,  2.28s/it]predicting train subjects:   8%|▊         | 22/285 [00:47<09:59,  2.28s/it]predicting train subjects:   8%|▊         | 23/285 [00:49<09:51,  2.26s/it]predicting train subjects:   8%|▊         | 24/285 [00:51<09:52,  2.27s/it]predicting train subjects:   9%|▉         | 25/285 [00:53<09:53,  2.28s/it]predicting train subjects:   9%|▉         | 26/285 [00:56<09:46,  2.26s/it]predicting train subjects:   9%|▉         | 27/285 [00:58<09:30,  2.21s/it]predicting train subjects:  10%|▉         | 28/285 [01:00<09:19,  2.18s/it]predicting train subjects:  10%|█         | 29/285 [01:02<09:08,  2.14s/it]predicting train subjects:  11%|█         | 30/285 [01:04<08:59,  2.11s/it]predicting train subjects:  11%|█         | 31/285 [01:06<08:58,  2.12s/it]predicting train subjects:  11%|█         | 32/285 [01:08<09:00,  2.14s/it]predicting train subjects:  12%|█▏        | 33/285 [01:10<08:57,  2.13s/it]predicting train subjects:  12%|█▏        | 34/285 [01:13<09:02,  2.16s/it]predicting train subjects:  12%|█▏        | 35/285 [01:15<08:59,  2.16s/it]predicting train subjects:  13%|█▎        | 36/285 [01:17<08:50,  2.13s/it]predicting train subjects:  13%|█▎        | 37/285 [01:19<08:41,  2.10s/it]predicting train subjects:  13%|█▎        | 38/285 [01:21<08:40,  2.11s/it]predicting train subjects:  14%|█▎        | 39/285 [01:23<08:45,  2.14s/it]predicting train subjects:  14%|█▍        | 40/285 [01:25<08:49,  2.16s/it]predicting train subjects:  14%|█▍        | 41/285 [01:28<09:03,  2.23s/it]predicting train subjects:  15%|█▍        | 42/285 [01:30<08:51,  2.19s/it]predicting train subjects:  15%|█▌        | 43/285 [01:32<08:42,  2.16s/it]predicting train subjects:  15%|█▌        | 44/285 [01:34<08:38,  2.15s/it]predicting train subjects:  16%|█▌        | 45/285 [01:36<08:37,  2.16s/it]predicting train subjects:  16%|█▌        | 46/285 [01:38<08:17,  2.08s/it]predicting train subjects:  16%|█▋        | 47/285 [01:40<07:59,  2.01s/it]predicting train subjects:  17%|█▋        | 48/285 [01:42<07:35,  1.92s/it]predicting train subjects:  17%|█▋        | 49/285 [01:43<07:24,  1.88s/it]predicting train subjects:  18%|█▊        | 50/285 [01:45<07:18,  1.86s/it]predicting train subjects:  18%|█▊        | 51/285 [01:47<07:05,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:49<07:12,  1.85s/it]predicting train subjects:  19%|█▊        | 53/285 [01:51<07:05,  1.84s/it]predicting train subjects:  19%|█▉        | 54/285 [01:52<06:54,  1.79s/it]predicting train subjects:  19%|█▉        | 55/285 [01:54<06:53,  1.80s/it]predicting train subjects:  20%|█▉        | 56/285 [01:56<06:53,  1.81s/it]predicting train subjects:  20%|██        | 57/285 [01:58<07:14,  1.91s/it]predicting train subjects:  20%|██        | 58/285 [02:00<07:31,  1.99s/it]predicting train subjects:  21%|██        | 59/285 [02:02<07:29,  1.99s/it]predicting train subjects:  21%|██        | 60/285 [02:04<07:14,  1.93s/it]predicting train subjects:  21%|██▏       | 61/285 [02:06<07:05,  1.90s/it]predicting train subjects:  22%|██▏       | 62/285 [02:08<06:56,  1.87s/it]predicting train subjects:  22%|██▏       | 63/285 [02:10<06:59,  1.89s/it]predicting train subjects:  22%|██▏       | 64/285 [02:12<06:56,  1.89s/it]predicting train subjects:  23%|██▎       | 65/285 [02:13<06:55,  1.89s/it]predicting train subjects:  23%|██▎       | 66/285 [02:16<07:25,  2.04s/it]predicting train subjects:  24%|██▎       | 67/285 [02:18<07:22,  2.03s/it]predicting train subjects:  24%|██▍       | 68/285 [02:20<07:13,  2.00s/it]predicting train subjects:  24%|██▍       | 69/285 [02:22<07:05,  1.97s/it]predicting train subjects:  25%|██▍       | 70/285 [02:24<07:05,  1.98s/it]predicting train subjects:  25%|██▍       | 71/285 [02:26<07:01,  1.97s/it]predicting train subjects:  25%|██▌       | 72/285 [02:28<07:05,  2.00s/it]predicting train subjects:  26%|██▌       | 73/285 [02:30<06:59,  1.98s/it]predicting train subjects:  26%|██▌       | 74/285 [02:31<06:49,  1.94s/it]predicting train subjects:  26%|██▋       | 75/285 [02:34<06:58,  1.99s/it]predicting train subjects:  27%|██▋       | 76/285 [02:36<06:58,  2.00s/it]predicting train subjects:  27%|██▋       | 77/285 [02:38<06:54,  1.99s/it]predicting train subjects:  27%|██▋       | 78/285 [02:39<06:44,  1.95s/it]predicting train subjects:  28%|██▊       | 79/285 [02:41<06:31,  1.90s/it]predicting train subjects:  28%|██▊       | 80/285 [02:43<06:37,  1.94s/it]predicting train subjects:  28%|██▊       | 81/285 [02:45<06:41,  1.97s/it]predicting train subjects:  29%|██▉       | 82/285 [02:47<06:35,  1.95s/it]predicting train subjects:  29%|██▉       | 83/285 [02:49<06:30,  1.93s/it]predicting train subjects:  29%|██▉       | 84/285 [02:51<06:26,  1.93s/it]predicting train subjects:  30%|██▉       | 85/285 [02:53<06:42,  2.01s/it]predicting train subjects:  30%|███       | 86/285 [02:55<06:39,  2.01s/it]predicting train subjects:  31%|███       | 87/285 [02:57<06:43,  2.04s/it]predicting train subjects:  31%|███       | 88/285 [03:00<06:55,  2.11s/it]predicting train subjects:  31%|███       | 89/285 [03:02<06:53,  2.11s/it]predicting train subjects:  32%|███▏      | 90/285 [03:04<06:54,  2.13s/it]predicting train subjects:  32%|███▏      | 91/285 [03:06<07:02,  2.18s/it]predicting train subjects:  32%|███▏      | 92/285 [03:08<06:55,  2.15s/it]predicting train subjects:  33%|███▎      | 93/285 [03:11<07:02,  2.20s/it]predicting train subjects:  33%|███▎      | 94/285 [03:13<07:09,  2.25s/it]predicting train subjects:  33%|███▎      | 95/285 [03:15<07:04,  2.23s/it]predicting train subjects:  34%|███▎      | 96/285 [03:17<07:00,  2.23s/it]predicting train subjects:  34%|███▍      | 97/285 [03:20<06:57,  2.22s/it]predicting train subjects:  34%|███▍      | 98/285 [03:22<07:01,  2.25s/it]predicting train subjects:  35%|███▍      | 99/285 [03:24<06:52,  2.22s/it]predicting train subjects:  35%|███▌      | 100/285 [03:26<06:42,  2.17s/it]predicting train subjects:  35%|███▌      | 101/285 [03:28<06:34,  2.15s/it]predicting train subjects:  36%|███▌      | 102/285 [03:30<06:31,  2.14s/it]predicting train subjects:  36%|███▌      | 103/285 [03:32<06:29,  2.14s/it]predicting train subjects:  36%|███▋      | 104/285 [03:35<06:26,  2.13s/it]predicting train subjects:  37%|███▋      | 105/285 [03:37<06:21,  2.12s/it]predicting train subjects:  37%|███▋      | 106/285 [03:39<06:33,  2.20s/it]predicting train subjects:  38%|███▊      | 107/285 [03:41<06:25,  2.17s/it]predicting train subjects:  38%|███▊      | 108/285 [03:43<06:22,  2.16s/it]predicting train subjects:  38%|███▊      | 109/285 [03:45<06:07,  2.09s/it]predicting train subjects:  39%|███▊      | 110/285 [03:47<06:03,  2.08s/it]predicting train subjects:  39%|███▉      | 111/285 [03:49<06:03,  2.09s/it]predicting train subjects:  39%|███▉      | 112/285 [03:52<06:04,  2.11s/it]predicting train subjects:  40%|███▉      | 113/285 [03:54<06:05,  2.12s/it]predicting train subjects:  40%|████      | 114/285 [03:56<06:06,  2.14s/it]predicting train subjects:  40%|████      | 115/285 [03:58<06:27,  2.28s/it]predicting train subjects:  41%|████      | 116/285 [04:01<06:45,  2.40s/it]predicting train subjects:  41%|████      | 117/285 [04:04<06:44,  2.41s/it]predicting train subjects:  41%|████▏     | 118/285 [04:06<06:33,  2.36s/it]predicting train subjects:  42%|████▏     | 119/285 [04:08<06:15,  2.26s/it]predicting train subjects:  42%|████▏     | 120/285 [04:10<06:03,  2.20s/it]predicting train subjects:  42%|████▏     | 121/285 [04:12<05:46,  2.11s/it]predicting train subjects:  43%|████▎     | 122/285 [04:13<05:22,  1.98s/it]predicting train subjects:  43%|████▎     | 123/285 [04:15<05:07,  1.90s/it]predicting train subjects:  44%|████▎     | 124/285 [04:18<05:35,  2.09s/it]predicting train subjects:  44%|████▍     | 125/285 [04:20<05:21,  2.01s/it]predicting train subjects:  44%|████▍     | 126/285 [04:21<05:04,  1.92s/it]predicting train subjects:  45%|████▍     | 127/285 [04:23<05:02,  1.91s/it]predicting train subjects:  45%|████▍     | 128/285 [04:25<04:48,  1.84s/it]predicting train subjects:  45%|████▌     | 129/285 [04:27<04:43,  1.82s/it]predicting train subjects:  46%|████▌     | 130/285 [04:29<04:49,  1.87s/it]predicting train subjects:  46%|████▌     | 131/285 [04:30<04:45,  1.86s/it]predicting train subjects:  46%|████▋     | 132/285 [04:32<04:34,  1.79s/it]predicting train subjects:  47%|████▋     | 133/285 [04:34<04:43,  1.87s/it]predicting train subjects:  47%|████▋     | 134/285 [04:36<04:39,  1.85s/it]predicting train subjects:  47%|████▋     | 135/285 [04:38<04:37,  1.85s/it]predicting train subjects:  48%|████▊     | 136/285 [04:40<04:40,  1.89s/it]predicting train subjects:  48%|████▊     | 137/285 [04:41<04:25,  1.80s/it]predicting train subjects:  48%|████▊     | 138/285 [04:43<04:14,  1.73s/it]predicting train subjects:  49%|████▉     | 139/285 [04:45<04:09,  1.71s/it]predicting train subjects:  49%|████▉     | 140/285 [04:46<04:04,  1.68s/it]predicting train subjects:  49%|████▉     | 141/285 [04:48<04:08,  1.73s/it]predicting train subjects:  50%|████▉     | 142/285 [04:50<04:03,  1.71s/it]predicting train subjects:  50%|█████     | 143/285 [04:51<04:01,  1.70s/it]predicting train subjects:  51%|█████     | 144/285 [04:53<03:54,  1.66s/it]predicting train subjects:  51%|█████     | 145/285 [04:54<03:49,  1.64s/it]predicting train subjects:  51%|█████     | 146/285 [04:56<03:47,  1.64s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:58<03:48,  1.66s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:59<03:43,  1.63s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:01<03:35,  1.59s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:02<03:33,  1.58s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:04<03:27,  1.55s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:05<03:22,  1.53s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:07<03:28,  1.58s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:09<03:28,  1.59s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:10<03:26,  1.59s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:12<03:30,  1.63s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:14<03:26,  1.61s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:15<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:17<03:24,  1.62s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:18<03:23,  1.63s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:20<03:26,  1.66s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:22<03:23,  1.65s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:23<03:21,  1.65s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:25<03:20,  1.65s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:27<03:29,  1.74s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:29<03:24,  1.72s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:31<03:26,  1.75s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:32<03:25,  1.76s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:34<03:20,  1.73s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:36<03:18,  1.72s/it]predicting train subjects:  60%|██████    | 171/285 [05:37<03:16,  1.73s/it]predicting train subjects:  60%|██████    | 172/285 [05:39<03:13,  1.71s/it]predicting train subjects:  61%|██████    | 173/285 [05:41<03:08,  1.68s/it]predicting train subjects:  61%|██████    | 174/285 [05:42<03:06,  1.68s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:44<03:08,  1.71s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:46<03:06,  1.71s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:47<02:58,  1.65s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:49<02:51,  1.60s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:50<02:48,  1.59s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:52<02:44,  1.57s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:54<02:45,  1.59s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:55<02:46,  1.62s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:57<02:48,  1.65s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:59<02:50,  1.69s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:00<02:45,  1.66s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:02<02:54,  1.77s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:04<03:01,  1.85s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:06<02:56,  1.82s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:08<02:52,  1.80s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:09<02:41,  1.70s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:11<02:34,  1.64s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:13<02:42,  1.75s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:15<02:36,  1.70s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:16<02:29,  1.64s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:18<02:24,  1.60s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:19<02:31,  1.71s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:22<02:39,  1.82s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:23<02:38,  1.82s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:25<02:36,  1.82s/it]predicting train subjects:  70%|███████   | 200/285 [06:27<02:38,  1.86s/it]predicting train subjects:  71%|███████   | 201/285 [06:29<02:34,  1.83s/it]predicting train subjects:  71%|███████   | 202/285 [06:31<02:35,  1.87s/it]predicting train subjects:  71%|███████   | 203/285 [06:33<02:33,  1.87s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:35<02:32,  1.88s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:37<02:30,  1.88s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:38<02:26,  1.86s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:40<02:24,  1.85s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:42<02:23,  1.86s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:44<02:21,  1.86s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:46<02:19,  1.86s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:48<02:15,  1.83s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:49<02:13,  1.82s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:51<02:13,  1.85s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:53<02:05,  1.77s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:55<02:02,  1.74s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:56<01:59,  1.73s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:58<01:56,  1.72s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:00<01:52,  1.68s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:01<01:48,  1.65s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:03<01:47,  1.66s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:04<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:06<01:45,  1.68s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:08<01:43,  1.67s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:09<01:40,  1.64s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:11<01:34,  1.58s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:12<01:33,  1.58s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:14<01:30,  1.56s/it]predicting train subjects:  80%|████████  | 228/285 [07:15<01:29,  1.56s/it]predicting train subjects:  80%|████████  | 229/285 [07:17<01:26,  1.54s/it]predicting train subjects:  81%|████████  | 230/285 [07:19<01:26,  1.57s/it]predicting train subjects:  81%|████████  | 231/285 [07:20<01:22,  1.52s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:22<01:29,  1.69s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:24<01:34,  1.82s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:26<01:37,  1.91s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:28<01:38,  1.97s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:30<01:37,  2.00s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:32<01:33,  1.95s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:34<01:30,  1.93s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:36<01:28,  1.92s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:38<01:27,  1.94s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:40<01:26,  1.96s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:42<01:26,  2.00s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:44<01:24,  2.00s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:46<01:22,  2.02s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:48<01:23,  2.08s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:51<01:21,  2.09s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:53<01:17,  2.04s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:55<01:15,  2.04s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:57<01:13,  2.04s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:58<01:07,  1.94s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:00<01:01,  1.82s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:01<00:57,  1.76s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:03<00:55,  1.72s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:05<00:54,  1.76s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:07<00:51,  1.70s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:08<00:50,  1.73s/it]predicting train subjects:  90%|█████████ | 257/285 [08:10<00:49,  1.77s/it]predicting train subjects:  91%|█████████ | 258/285 [08:12<00:46,  1.74s/it]predicting train subjects:  91%|█████████ | 259/285 [08:14<00:45,  1.73s/it]predicting train subjects:  91%|█████████ | 260/285 [08:15<00:44,  1.76s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:17<00:42,  1.78s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:19<00:41,  1.81s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:21<00:39,  1.78s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:22<00:36,  1.73s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:24<00:34,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:26<00:31,  1.68s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:27<00:29,  1.65s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:29<00:30,  1.82s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:32<00:30,  1.90s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:34<00:29,  1.98s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:36<00:28,  2.06s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:38<00:27,  2.10s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:40<00:25,  2.13s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:43<00:23,  2.18s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:45<00:21,  2.17s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:47<00:19,  2.14s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:49<00:17,  2.13s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:52<00:16,  2.43s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:54<00:14,  2.34s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:57<00:11,  2.36s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:59<00:09,  2.30s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:01<00:06,  2.31s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:03<00:04,  2.31s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:06<00:02,  2.30s/it]predicting train subjects: 100%|██████████| 285/285 [09:08<00:00,  2.27s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:53,  1.88s/it]Loading train:   1%|          | 2/285 [00:03<09:02,  1.92s/it]Loading train:   1%|          | 3/285 [00:05<08:38,  1.84s/it]Loading train:   1%|▏         | 4/285 [00:08<09:32,  2.04s/it]Loading train:   2%|▏         | 5/285 [00:10<09:30,  2.04s/it]Loading train:   2%|▏         | 6/285 [00:12<09:59,  2.15s/it]Loading train:   2%|▏         | 7/285 [00:14<10:25,  2.25s/it]Loading train:   3%|▎         | 8/285 [00:17<10:21,  2.24s/it]Loading train:   3%|▎         | 9/285 [00:19<10:49,  2.35s/it]Loading train:   4%|▎         | 10/285 [00:21<10:27,  2.28s/it]Loading train:   4%|▍         | 11/285 [00:23<09:48,  2.15s/it]Loading train:   4%|▍         | 12/285 [00:25<09:38,  2.12s/it]Loading train:   5%|▍         | 13/285 [00:28<10:08,  2.24s/it]Loading train:   5%|▍         | 14/285 [00:30<10:06,  2.24s/it]Loading train:   5%|▌         | 15/285 [00:34<12:29,  2.78s/it]Loading train:   6%|▌         | 16/285 [00:37<12:12,  2.72s/it]Loading train:   6%|▌         | 17/285 [00:39<11:16,  2.52s/it]Loading train:   6%|▋         | 18/285 [00:41<11:07,  2.50s/it]Loading train:   7%|▋         | 19/285 [00:43<10:17,  2.32s/it]Loading train:   7%|▋         | 20/285 [00:45<09:57,  2.26s/it]Loading train:   7%|▋         | 21/285 [00:47<09:23,  2.14s/it]Loading train:   8%|▊         | 22/285 [00:49<08:52,  2.02s/it]Loading train:   8%|▊         | 23/285 [00:52<09:51,  2.26s/it]Loading train:   8%|▊         | 24/285 [00:54<10:02,  2.31s/it]Loading train:   9%|▉         | 25/285 [00:56<09:28,  2.19s/it]Loading train:   9%|▉         | 26/285 [00:58<09:40,  2.24s/it]Loading train:   9%|▉         | 27/285 [01:01<09:49,  2.28s/it]Loading train:  10%|▉         | 28/285 [01:03<09:30,  2.22s/it]Loading train:  10%|█         | 29/285 [01:05<09:07,  2.14s/it]Loading train:  11%|█         | 30/285 [01:07<08:55,  2.10s/it]Loading train:  11%|█         | 31/285 [01:09<08:27,  2.00s/it]Loading train:  11%|█         | 32/285 [01:10<07:49,  1.86s/it]Loading train:  12%|█▏        | 33/285 [01:13<08:37,  2.05s/it]Loading train:  12%|█▏        | 34/285 [01:15<09:21,  2.24s/it]Loading train:  12%|█▏        | 35/285 [01:18<10:05,  2.42s/it]Loading train:  13%|█▎        | 36/285 [01:20<09:04,  2.19s/it]Loading train:  13%|█▎        | 37/285 [01:21<08:32,  2.07s/it]Loading train:  13%|█▎        | 38/285 [01:24<08:39,  2.10s/it]Loading train:  14%|█▎        | 39/285 [01:25<08:07,  1.98s/it]Loading train:  14%|█▍        | 40/285 [01:28<08:21,  2.05s/it]Loading train:  14%|█▍        | 41/285 [01:29<07:56,  1.95s/it]Loading train:  15%|█▍        | 42/285 [01:32<08:59,  2.22s/it]Loading train:  15%|█▌        | 43/285 [01:34<08:46,  2.17s/it]Loading train:  15%|█▌        | 44/285 [01:37<09:01,  2.25s/it]Loading train:  16%|█▌        | 45/285 [01:38<08:25,  2.11s/it]Loading train:  16%|█▌        | 46/285 [01:40<07:53,  1.98s/it]Loading train:  16%|█▋        | 47/285 [01:42<07:27,  1.88s/it]Loading train:  17%|█▋        | 48/285 [01:43<06:58,  1.76s/it]Loading train:  17%|█▋        | 49/285 [01:45<06:49,  1.74s/it]Loading train:  18%|█▊        | 50/285 [01:46<06:30,  1.66s/it]Loading train:  18%|█▊        | 51/285 [01:48<06:17,  1.61s/it]Loading train:  18%|█▊        | 52/285 [01:49<05:53,  1.52s/it]Loading train:  19%|█▊        | 53/285 [01:51<05:52,  1.52s/it]Loading train:  19%|█▉        | 54/285 [01:52<05:37,  1.46s/it]Loading train:  19%|█▉        | 55/285 [01:54<05:39,  1.48s/it]Loading train:  20%|█▉        | 56/285 [01:56<06:26,  1.69s/it]Loading train:  20%|██        | 57/285 [01:58<06:39,  1.75s/it]Loading train:  20%|██        | 58/285 [01:59<06:16,  1.66s/it]Loading train:  21%|██        | 59/285 [02:00<05:48,  1.54s/it]Loading train:  21%|██        | 60/285 [02:02<05:44,  1.53s/it]Loading train:  21%|██▏       | 61/285 [02:03<05:45,  1.54s/it]Loading train:  22%|██▏       | 62/285 [02:05<05:43,  1.54s/it]Loading train:  22%|██▏       | 63/285 [02:07<05:53,  1.59s/it]Loading train:  22%|██▏       | 64/285 [02:09<06:33,  1.78s/it]Loading train:  23%|██▎       | 65/285 [02:11<06:54,  1.88s/it]Loading train:  23%|██▎       | 66/285 [02:13<07:15,  1.99s/it]Loading train:  24%|██▎       | 67/285 [02:15<07:00,  1.93s/it]Loading train:  24%|██▍       | 68/285 [02:17<07:02,  1.95s/it]Loading train:  24%|██▍       | 69/285 [02:19<06:42,  1.86s/it]Loading train:  25%|██▍       | 70/285 [02:20<06:08,  1.72s/it]Loading train:  25%|██▍       | 71/285 [02:22<05:58,  1.68s/it]Loading train:  25%|██▌       | 72/285 [02:23<05:52,  1.66s/it]Loading train:  26%|██▌       | 73/285 [02:25<05:43,  1.62s/it]Loading train:  26%|██▌       | 74/285 [02:26<05:38,  1.61s/it]Loading train:  26%|██▋       | 75/285 [02:28<05:39,  1.62s/it]Loading train:  27%|██▋       | 76/285 [02:30<05:36,  1.61s/it]Loading train:  27%|██▋       | 77/285 [02:31<05:46,  1.67s/it]Loading train:  27%|██▋       | 78/285 [02:33<05:49,  1.69s/it]Loading train:  28%|██▊       | 79/285 [02:35<05:51,  1.71s/it]Loading train:  28%|██▊       | 80/285 [02:37<05:44,  1.68s/it]Loading train:  28%|██▊       | 81/285 [02:38<05:42,  1.68s/it]Loading train:  29%|██▉       | 82/285 [02:40<05:31,  1.63s/it]Loading train:  29%|██▉       | 83/285 [02:41<05:32,  1.65s/it]Loading train:  29%|██▉       | 84/285 [02:43<05:54,  1.76s/it]Loading train:  30%|██▉       | 85/285 [02:45<05:52,  1.76s/it]Loading train:  30%|███       | 86/285 [02:47<05:53,  1.78s/it]Loading train:  31%|███       | 87/285 [02:49<05:50,  1.77s/it]Loading train:  31%|███       | 88/285 [02:51<05:53,  1.79s/it]Loading train:  31%|███       | 89/285 [02:52<05:37,  1.72s/it]Loading train:  32%|███▏      | 90/285 [02:54<05:59,  1.84s/it]Loading train:  32%|███▏      | 91/285 [02:56<05:52,  1.82s/it]Loading train:  32%|███▏      | 92/285 [02:58<05:59,  1.86s/it]Loading train:  33%|███▎      | 93/285 [02:59<05:36,  1.75s/it]Loading train:  33%|███▎      | 94/285 [03:01<05:30,  1.73s/it]Loading train:  33%|███▎      | 95/285 [03:03<05:33,  1.75s/it]Loading train:  34%|███▎      | 96/285 [03:05<05:55,  1.88s/it]Loading train:  34%|███▍      | 97/285 [03:07<06:10,  1.97s/it]Loading train:  34%|███▍      | 98/285 [03:09<06:12,  1.99s/it]Loading train:  35%|███▍      | 99/285 [03:11<06:06,  1.97s/it]Loading train:  35%|███▌      | 100/285 [03:13<06:03,  1.97s/it]Loading train:  35%|███▌      | 101/285 [03:15<05:47,  1.89s/it]Loading train:  36%|███▌      | 102/285 [03:17<05:45,  1.89s/it]Loading train:  36%|███▌      | 103/285 [03:19<06:12,  2.05s/it]Loading train:  36%|███▋      | 104/285 [03:22<06:50,  2.27s/it]Loading train:  37%|███▋      | 105/285 [03:24<06:40,  2.23s/it]Loading train:  37%|███▋      | 106/285 [03:26<06:29,  2.18s/it]Loading train:  38%|███▊      | 107/285 [03:28<06:18,  2.13s/it]Loading train:  38%|███▊      | 108/285 [03:30<05:54,  2.00s/it]Loading train:  38%|███▊      | 109/285 [03:32<06:07,  2.09s/it]Loading train:  39%|███▊      | 110/285 [03:34<06:11,  2.12s/it]Loading train:  39%|███▉      | 111/285 [03:37<06:30,  2.24s/it]Loading train:  39%|███▉      | 112/285 [03:39<06:06,  2.12s/it]Loading train:  40%|███▉      | 113/285 [03:41<05:44,  2.00s/it]Loading train:  40%|████      | 114/285 [03:42<05:34,  1.95s/it]Loading train:  40%|████      | 115/285 [03:44<05:26,  1.92s/it]Loading train:  41%|████      | 116/285 [03:46<05:34,  1.98s/it]Loading train:  41%|████      | 117/285 [03:49<05:58,  2.14s/it]Loading train:  41%|████▏     | 118/285 [03:51<05:37,  2.02s/it]Loading train:  42%|████▏     | 119/285 [03:52<05:28,  1.98s/it]Loading train:  42%|████▏     | 120/285 [03:55<05:39,  2.05s/it]Loading train:  42%|████▏     | 121/285 [03:57<05:46,  2.11s/it]Loading train:  43%|████▎     | 122/285 [03:59<05:35,  2.06s/it]Loading train:  43%|████▎     | 123/285 [04:01<05:23,  2.00s/it]Loading train:  44%|████▎     | 124/285 [04:02<05:01,  1.87s/it]Loading train:  44%|████▍     | 125/285 [04:04<04:51,  1.82s/it]Loading train:  44%|████▍     | 126/285 [04:06<04:48,  1.81s/it]Loading train:  45%|████▍     | 127/285 [04:07<04:37,  1.76s/it]Loading train:  45%|████▍     | 128/285 [04:09<04:34,  1.75s/it]Loading train:  45%|████▌     | 129/285 [04:11<04:32,  1.74s/it]Loading train:  46%|████▌     | 130/285 [04:13<04:25,  1.71s/it]Loading train:  46%|████▌     | 131/285 [04:14<04:14,  1.65s/it]Loading train:  46%|████▋     | 132/285 [04:16<04:06,  1.61s/it]Loading train:  47%|████▋     | 133/285 [04:17<04:06,  1.62s/it]Loading train:  47%|████▋     | 134/285 [04:19<03:59,  1.59s/it]Loading train:  47%|████▋     | 135/285 [04:21<04:12,  1.68s/it]Loading train:  48%|████▊     | 136/285 [04:23<04:51,  1.96s/it]Loading train:  48%|████▊     | 137/285 [04:25<04:20,  1.76s/it]Loading train:  48%|████▊     | 138/285 [04:26<04:16,  1.74s/it]Loading train:  49%|████▉     | 139/285 [04:28<04:03,  1.67s/it]Loading train:  49%|████▉     | 140/285 [04:29<03:58,  1.64s/it]Loading train:  49%|████▉     | 141/285 [04:31<03:54,  1.63s/it]Loading train:  50%|████▉     | 142/285 [04:33<04:08,  1.74s/it]Loading train:  50%|█████     | 143/285 [04:35<04:10,  1.76s/it]Loading train:  51%|█████     | 144/285 [04:37<04:15,  1.81s/it]Loading train:  51%|█████     | 145/285 [04:39<04:15,  1.82s/it]Loading train:  51%|█████     | 146/285 [04:40<04:10,  1.80s/it]Loading train:  52%|█████▏    | 147/285 [04:42<04:08,  1.80s/it]Loading train:  52%|█████▏    | 148/285 [04:44<04:03,  1.78s/it]Loading train:  52%|█████▏    | 149/285 [04:46<04:01,  1.77s/it]Loading train:  53%|█████▎    | 150/285 [04:48<04:16,  1.90s/it]Loading train:  53%|█████▎    | 151/285 [04:49<04:06,  1.84s/it]Loading train:  53%|█████▎    | 152/285 [04:52<04:30,  2.03s/it]Loading train:  54%|█████▎    | 153/285 [04:54<04:39,  2.12s/it]Loading train:  54%|█████▍    | 154/285 [04:57<04:45,  2.18s/it]Loading train:  54%|█████▍    | 155/285 [04:59<04:51,  2.24s/it]Loading train:  55%|█████▍    | 156/285 [05:01<04:34,  2.13s/it]Loading train:  55%|█████▌    | 157/285 [05:02<04:09,  1.95s/it]Loading train:  55%|█████▌    | 158/285 [05:04<04:06,  1.94s/it]Loading train:  56%|█████▌    | 159/285 [05:06<03:58,  1.89s/it]Loading train:  56%|█████▌    | 160/285 [05:08<03:54,  1.88s/it]Loading train:  56%|█████▋    | 161/285 [05:09<03:37,  1.75s/it]Loading train:  57%|█████▋    | 162/285 [05:11<03:33,  1.74s/it]Loading train:  57%|█████▋    | 163/285 [05:13<03:34,  1.76s/it]Loading train:  58%|█████▊    | 164/285 [05:15<03:35,  1.78s/it]Loading train:  58%|█████▊    | 165/285 [05:16<03:33,  1.78s/it]Loading train:  58%|█████▊    | 166/285 [05:18<03:28,  1.75s/it]Loading train:  59%|█████▊    | 167/285 [05:20<03:21,  1.71s/it]Loading train:  59%|█████▉    | 168/285 [05:21<03:10,  1.63s/it]Loading train:  59%|█████▉    | 169/285 [05:23<03:13,  1.67s/it]Loading train:  60%|█████▉    | 170/285 [05:24<03:06,  1.62s/it]Loading train:  60%|██████    | 171/285 [05:27<03:25,  1.80s/it]Loading train:  60%|██████    | 172/285 [05:28<03:19,  1.77s/it]Loading train:  61%|██████    | 173/285 [05:30<03:21,  1.80s/it]Loading train:  61%|██████    | 174/285 [05:32<03:05,  1.67s/it]Loading train:  61%|██████▏   | 175/285 [05:33<03:07,  1.71s/it]Loading train:  62%|██████▏   | 176/285 [05:35<03:03,  1.68s/it]Loading train:  62%|██████▏   | 177/285 [05:37<02:54,  1.61s/it]Loading train:  62%|██████▏   | 178/285 [05:38<02:56,  1.65s/it]Loading train:  63%|██████▎   | 179/285 [05:40<03:01,  1.72s/it]Loading train:  63%|██████▎   | 180/285 [05:42<02:59,  1.71s/it]Loading train:  64%|██████▎   | 181/285 [05:43<02:50,  1.64s/it]Loading train:  64%|██████▍   | 182/285 [05:45<02:42,  1.57s/it]Loading train:  64%|██████▍   | 183/285 [05:46<02:41,  1.58s/it]Loading train:  65%|██████▍   | 184/285 [05:48<02:47,  1.66s/it]Loading train:  65%|██████▍   | 185/285 [05:50<02:48,  1.68s/it]Loading train:  65%|██████▌   | 186/285 [05:52<02:46,  1.69s/it]Loading train:  66%|██████▌   | 187/285 [05:53<02:50,  1.74s/it]Loading train:  66%|██████▌   | 188/285 [05:56<03:01,  1.87s/it]Loading train:  66%|██████▋   | 189/285 [05:57<02:44,  1.72s/it]Loading train:  67%|██████▋   | 190/285 [05:58<02:35,  1.64s/it]Loading train:  67%|██████▋   | 191/285 [06:00<02:36,  1.66s/it]Loading train:  67%|██████▋   | 192/285 [06:02<02:39,  1.71s/it]Loading train:  68%|██████▊   | 193/285 [06:04<02:36,  1.71s/it]Loading train:  68%|██████▊   | 194/285 [06:06<02:47,  1.84s/it]Loading train:  68%|██████▊   | 195/285 [06:07<02:34,  1.71s/it]Loading train:  69%|██████▉   | 196/285 [06:09<02:27,  1.66s/it]Loading train:  69%|██████▉   | 197/285 [06:10<02:26,  1.67s/it]Loading train:  69%|██████▉   | 198/285 [06:12<02:29,  1.72s/it]Loading train:  70%|██████▉   | 199/285 [06:14<02:17,  1.60s/it]Loading train:  70%|███████   | 200/285 [06:15<02:19,  1.65s/it]Loading train:  71%|███████   | 201/285 [06:18<02:50,  2.03s/it]Loading train:  71%|███████   | 202/285 [06:20<02:38,  1.91s/it]Loading train:  71%|███████   | 203/285 [06:22<02:31,  1.84s/it]Loading train:  72%|███████▏  | 204/285 [06:24<02:31,  1.87s/it]Loading train:  72%|███████▏  | 205/285 [06:25<02:19,  1.75s/it]Loading train:  72%|███████▏  | 206/285 [06:27<02:14,  1.71s/it]Loading train:  73%|███████▎  | 207/285 [06:28<02:14,  1.73s/it]Loading train:  73%|███████▎  | 208/285 [06:30<02:15,  1.76s/it]Loading train:  73%|███████▎  | 209/285 [06:32<02:14,  1.77s/it]Loading train:  74%|███████▎  | 210/285 [06:34<02:07,  1.70s/it]Loading train:  74%|███████▍  | 211/285 [06:36<02:11,  1.78s/it]Loading train:  74%|███████▍  | 212/285 [06:37<02:02,  1.67s/it]Loading train:  75%|███████▍  | 213/285 [06:38<01:57,  1.63s/it]Loading train:  75%|███████▌  | 214/285 [06:40<01:52,  1.58s/it]Loading train:  75%|███████▌  | 215/285 [06:41<01:46,  1.52s/it]Loading train:  76%|███████▌  | 216/285 [06:43<01:40,  1.46s/it]Loading train:  76%|███████▌  | 217/285 [06:44<01:40,  1.48s/it]Loading train:  76%|███████▋  | 218/285 [06:46<01:41,  1.51s/it]Loading train:  77%|███████▋  | 219/285 [06:48<01:45,  1.60s/it]Loading train:  77%|███████▋  | 220/285 [06:49<01:45,  1.63s/it]Loading train:  78%|███████▊  | 221/285 [06:51<01:37,  1.53s/it]Loading train:  78%|███████▊  | 222/285 [06:52<01:34,  1.49s/it]Loading train:  78%|███████▊  | 223/285 [06:54<01:41,  1.64s/it]Loading train:  79%|███████▊  | 224/285 [06:55<01:36,  1.58s/it]Loading train:  79%|███████▉  | 225/285 [06:57<01:36,  1.61s/it]Loading train:  79%|███████▉  | 226/285 [06:59<01:36,  1.63s/it]Loading train:  80%|███████▉  | 227/285 [07:00<01:36,  1.66s/it]Loading train:  80%|████████  | 228/285 [07:02<01:30,  1.58s/it]Loading train:  80%|████████  | 229/285 [07:03<01:27,  1.57s/it]Loading train:  81%|████████  | 230/285 [07:05<01:21,  1.48s/it]Loading train:  81%|████████  | 231/285 [07:06<01:21,  1.52s/it]Loading train:  81%|████████▏ | 232/285 [07:08<01:26,  1.63s/it]Loading train:  82%|████████▏ | 233/285 [07:10<01:30,  1.74s/it]Loading train:  82%|████████▏ | 234/285 [07:12<01:35,  1.88s/it]Loading train:  82%|████████▏ | 235/285 [07:14<01:35,  1.91s/it]Loading train:  83%|████████▎ | 236/285 [07:16<01:28,  1.80s/it]Loading train:  83%|████████▎ | 237/285 [07:18<01:28,  1.84s/it]Loading train:  84%|████████▎ | 238/285 [07:20<01:26,  1.85s/it]Loading train:  84%|████████▍ | 239/285 [07:22<01:34,  2.06s/it]Loading train:  84%|████████▍ | 240/285 [07:24<01:25,  1.91s/it]Loading train:  85%|████████▍ | 241/285 [07:25<01:20,  1.83s/it]Loading train:  85%|████████▍ | 242/285 [07:27<01:14,  1.72s/it]Loading train:  85%|████████▌ | 243/285 [07:29<01:13,  1.74s/it]Loading train:  86%|████████▌ | 244/285 [07:31<01:16,  1.86s/it]Loading train:  86%|████████▌ | 245/285 [07:33<01:11,  1.80s/it]Loading train:  86%|████████▋ | 246/285 [07:35<01:13,  1.88s/it]Loading train:  87%|████████▋ | 247/285 [07:36<01:08,  1.82s/it]Loading train:  87%|████████▋ | 248/285 [07:38<01:07,  1.82s/it]Loading train:  87%|████████▋ | 249/285 [07:40<01:06,  1.84s/it]Loading train:  88%|████████▊ | 250/285 [07:42<01:02,  1.78s/it]Loading train:  88%|████████▊ | 251/285 [07:43<00:59,  1.74s/it]Loading train:  88%|████████▊ | 252/285 [07:45<00:59,  1.82s/it]Loading train:  89%|████████▉ | 253/285 [07:47<00:57,  1.80s/it]Loading train:  89%|████████▉ | 254/285 [07:49<00:55,  1.78s/it]Loading train:  89%|████████▉ | 255/285 [07:51<00:54,  1.81s/it]Loading train:  90%|████████▉ | 256/285 [07:52<00:49,  1.70s/it]Loading train:  90%|█████████ | 257/285 [07:54<00:47,  1.70s/it]Loading train:  91%|█████████ | 258/285 [07:55<00:43,  1.61s/it]Loading train:  91%|█████████ | 259/285 [07:57<00:43,  1.68s/it]Loading train:  91%|█████████ | 260/285 [07:58<00:39,  1.59s/it]Loading train:  92%|█████████▏| 261/285 [08:00<00:38,  1.62s/it]Loading train:  92%|█████████▏| 262/285 [08:01<00:34,  1.51s/it]Loading train:  92%|█████████▏| 263/285 [08:03<00:36,  1.66s/it]Loading train:  93%|█████████▎| 264/285 [08:05<00:36,  1.76s/it]Loading train:  93%|█████████▎| 265/285 [08:07<00:34,  1.72s/it]Loading train:  93%|█████████▎| 266/285 [08:08<00:31,  1.63s/it]Loading train:  94%|█████████▎| 267/285 [08:10<00:30,  1.67s/it]Loading train:  94%|█████████▍| 268/285 [08:12<00:31,  1.85s/it]Loading train:  94%|█████████▍| 269/285 [08:15<00:32,  2.05s/it]Loading train:  95%|█████████▍| 270/285 [08:17<00:31,  2.09s/it]Loading train:  95%|█████████▌| 271/285 [08:19<00:28,  2.04s/it]Loading train:  95%|█████████▌| 272/285 [08:21<00:25,  1.94s/it]Loading train:  96%|█████████▌| 273/285 [08:23<00:23,  1.92s/it]Loading train:  96%|█████████▌| 274/285 [08:25<00:21,  1.96s/it]Loading train:  96%|█████████▋| 275/285 [08:27<00:19,  1.93s/it]Loading train:  97%|█████████▋| 276/285 [08:28<00:16,  1.89s/it]Loading train:  97%|█████████▋| 277/285 [08:30<00:15,  1.89s/it]Loading train:  98%|█████████▊| 278/285 [08:32<00:13,  1.94s/it]Loading train:  98%|█████████▊| 279/285 [08:34<00:11,  1.92s/it]Loading train:  98%|█████████▊| 280/285 [08:36<00:09,  1.83s/it]Loading train:  99%|█████████▊| 281/285 [08:38<00:07,  1.86s/it]Loading train:  99%|█████████▉| 282/285 [08:40<00:05,  1.88s/it]Loading train:  99%|█████████▉| 283/285 [08:41<00:03,  1.87s/it]Loading train: 100%|█████████▉| 284/285 [08:43<00:01,  1.78s/it]Loading train: 100%|██████████| 285/285 [08:45<00:00,  1.78s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 43.10it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:05, 48.91it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:05, 48.24it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:04, 54.71it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:05, 50.46it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:05, 44.90it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:04, 50.31it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:05, 46.48it/s]concatenating: train:  20%|██        | 58/285 [00:01<00:04, 52.33it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:03, 57.34it/s]concatenating: train:  26%|██▌       | 74/285 [00:01<00:03, 62.00it/s]concatenating: train:  28%|██▊       | 81/285 [00:01<00:03, 59.22it/s]concatenating: train:  31%|███       | 88/285 [00:01<00:04, 47.01it/s]concatenating: train:  34%|███▎      | 96/285 [00:01<00:03, 51.96it/s]concatenating: train:  36%|███▌      | 103/285 [00:01<00:03, 56.26it/s]concatenating: train:  39%|███▊      | 110/285 [00:01<00:03, 55.32it/s]concatenating: train:  41%|████▏     | 118/285 [00:02<00:02, 56.87it/s]concatenating: train:  44%|████▎     | 124/285 [00:02<00:02, 55.84it/s]concatenating: train:  46%|████▌     | 131/285 [00:02<00:02, 58.30it/s]concatenating: train:  49%|████▉     | 139/285 [00:02<00:02, 63.41it/s]concatenating: train:  52%|█████▏    | 147/285 [00:02<00:02, 66.20it/s]concatenating: train:  54%|█████▍    | 154/285 [00:02<00:02, 65.14it/s]concatenating: train:  56%|█████▋    | 161/285 [00:02<00:01, 64.32it/s]concatenating: train:  59%|█████▉    | 168/285 [00:02<00:02, 56.37it/s]concatenating: train:  61%|██████    | 174/285 [00:03<00:01, 56.76it/s]concatenating: train:  63%|██████▎   | 180/285 [00:03<00:01, 56.31it/s]concatenating: train:  65%|██████▌   | 186/285 [00:03<00:01, 49.99it/s]concatenating: train:  67%|██████▋   | 192/285 [00:03<00:02, 43.85it/s]concatenating: train:  69%|██████▉   | 197/285 [00:03<00:02, 38.76it/s]concatenating: train:  71%|███████   | 202/285 [00:03<00:02, 37.45it/s]concatenating: train:  72%|███████▏  | 206/285 [00:03<00:02, 36.11it/s]concatenating: train:  74%|███████▍  | 211/285 [00:04<00:02, 35.68it/s]concatenating: train:  76%|███████▋  | 218/285 [00:04<00:01, 40.96it/s]concatenating: train:  79%|███████▊  | 224/285 [00:04<00:01, 45.26it/s]concatenating: train:  81%|████████▏ | 232/285 [00:04<00:01, 47.59it/s]concatenating: train:  84%|████████▎ | 238/285 [00:04<00:01, 45.64it/s]concatenating: train:  86%|████████▌ | 244/285 [00:04<00:00, 47.74it/s]concatenating: train:  88%|████████▊ | 251/285 [00:04<00:00, 51.41it/s]concatenating: train:  91%|█████████ | 258/285 [00:04<00:00, 54.30it/s]concatenating: train:  93%|█████████▎| 265/285 [00:04<00:00, 57.07it/s]concatenating: train:  95%|█████████▌| 271/285 [00:05<00:00, 56.56it/s]concatenating: train:  98%|█████████▊| 279/285 [00:05<00:00, 61.51it/s]concatenating: train: 100%|██████████| 285/285 [00:05<00:00, 53.77it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.79s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.73s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00, 17.77it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 20.87it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 80)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 80)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 160)  115360      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 160)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 80)   51280       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 160)  0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 80)   115280      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 80)   0           activation_8[0][0]               
__________________________________________________________________________________________________2019-06-30 22:06:45.268844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 22:06:45.268961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 22:06:45.268982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 22:06:45.268997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 22:06:45.269516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 40)   12840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 40)   28840       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 40)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   533         dropout_5[0][0]                  
==================================================================================================
Total params: 731,413
Trainable params: 729,813
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [2.45357524e+01 1.20808280e+01 2.83540199e+01 3.52403467e+00
 1.02430434e+01 2.67099910e+00 3.19605001e+01 4.25814537e+01
 3.25211438e+01 5.00837070e+00 1.11201025e+02 7.27972247e+01
 8.67943023e-02]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 27s - loss: 1050.7021 - acc: 0.9221 - mDice: 0.3866 - val_loss: 1059.3377 - val_acc: 0.9444 - val_mDice: 0.3985

Epoch 00001: val_mDice improved from -inf to 0.39853, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 543.5461 - acc: 0.9430 - mDice: 0.5961 - val_loss: 990.0311 - val_acc: 0.9515 - val_mDice: 0.4689

Epoch 00002: val_mDice improved from 0.39853 to 0.46889, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 458.2389 - acc: 0.9476 - mDice: 0.6543 - val_loss: 976.5526 - val_acc: 0.9528 - val_mDice: 0.5046

Epoch 00003: val_mDice improved from 0.46889 to 0.50461, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 21s - loss: 413.9279 - acc: 0.9502 - mDice: 0.6850 - val_loss: 1055.3581 - val_acc: 0.9526 - val_mDice: 0.5064

Epoch 00004: val_mDice improved from 0.50461 to 0.50637, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 19s - loss: 382.8778 - acc: 0.9521 - mDice: 0.7079 - val_loss: 1085.5758 - val_acc: 0.9537 - val_mDice: 0.5153

Epoch 00005: val_mDice improved from 0.50637 to 0.51530, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 19s - loss: 360.8338 - acc: 0.9535 - mDice: 0.7243 - val_loss: 1164.3953 - val_acc: 0.9535 - val_mDice: 0.5148

Epoch 00006: val_mDice did not improve from 0.51530
Epoch 7/300
 - 21s - loss: 343.0036 - acc: 0.9547 - mDice: 0.7372 - val_loss: 1262.6308 - val_acc: 0.9541 - val_mDice: 0.5067

Epoch 00007: val_mDice did not improve from 0.51530
Epoch 8/300
 - 20s - loss: 329.8832 - acc: 0.9556 - mDice: 0.7474 - val_loss: 1164.6526 - val_acc: 0.9535 - val_mDice: 0.5227

Epoch 00008: val_mDice improved from 0.51530 to 0.52271, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 19s - loss: 319.7053 - acc: 0.9563 - mDice: 0.7548 - val_loss: 1190.7153 - val_acc: 0.9532 - val_mDice: 0.5212

Epoch 00009: val_mDice did not improve from 0.52271
Epoch 10/300
 - 20s - loss: 309.4762 - acc: 0.9570 - mDice: 0.7626 - val_loss: 1276.4853 - val_acc: 0.9535 - val_mDice: 0.5208

Epoch 00010: val_mDice did not improve from 0.52271
Epoch 11/300
 - 21s - loss: 301.2987 - acc: 0.9576 - mDice: 0.7686 - val_loss: 1277.2641 - val_acc: 0.9539 - val_mDice: 0.5236

Epoch 00011: val_mDice improved from 0.52271 to 0.52356, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 294.1909 - acc: 0.9581 - mDice: 0.7740 - val_loss: 1313.1497 - val_acc: 0.9544 - val_mDice: 0.5254

Epoch 00012: val_mDice improved from 0.52356 to 0.52542, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 287.8553 - acc: 0.9587 - mDice: 0.7786 - val_loss: 1321.0572 - val_acc: 0.9536 - val_mDice: 0.5325

Epoch 00013: val_mDice improved from 0.52542 to 0.53250, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 19s - loss: 281.5528 - acc: 0.9590 - mDice: 0.7833 - val_loss: 1357.1539 - val_acc: 0.9540 - val_mDice: 0.5244

Epoch 00014: val_mDice did not improve from 0.53250
Epoch 15/300
 - 17s - loss: 276.4307 - acc: 0.9595 - mDice: 0.7871 - val_loss: 1321.8290 - val_acc: 0.9543 - val_mDice: 0.5251

Epoch 00015: val_mDice did not improve from 0.53250
Epoch 16/300
 - 17s - loss: 271.2251 - acc: 0.9599 - mDice: 0.7914 - val_loss: 1435.2853 - val_acc: 0.9525 - val_mDice: 0.5157

Epoch 00016: val_mDice did not improve from 0.53250
Epoch 17/300
 - 17s - loss: 267.9780 - acc: 0.9602 - mDice: 0.7939 - val_loss: 1367.9582 - val_acc: 0.9542 - val_mDice: 0.5278

Epoch 00017: val_mDice did not improve from 0.53250
Epoch 18/300
 - 17s - loss: 263.2008 - acc: 0.9606 - mDice: 0.7972 - val_loss: 1324.8637 - val_acc: 0.9545 - val_mDice: 0.5362

Epoch 00018: val_mDice improved from 0.53250 to 0.53624, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 17s - loss: 258.8968 - acc: 0.9609 - mDice: 0.8007 - val_loss: 1399.5741 - val_acc: 0.9545 - val_mDice: 0.5235

Epoch 00019: val_mDice did not improve from 0.53624
Epoch 20/300
 - 18s - loss: 255.8469 - acc: 0.9611 - mDice: 0.8031 - val_loss: 1418.7039 - val_acc: 0.9539 - val_mDice: 0.5300

Epoch 00020: val_mDice did not improve from 0.53624
Epoch 21/300
 - 18s - loss: 252.3986 - acc: 0.9613 - mDice: 0.8058 - val_loss: 1398.6056 - val_acc: 0.9549 - val_mDice: 0.5367

Epoch 00021: val_mDice improved from 0.53624 to 0.53669, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 19s - loss: 249.1770 - acc: 0.9615 - mDice: 0.8081 - val_loss: 1373.0971 - val_acc: 0.9542 - val_mDice: 0.5364

Epoch 00022: val_mDice did not improve from 0.53669
Epoch 23/300
 - 18s - loss: 245.9924 - acc: 0.9618 - mDice: 0.8104 - val_loss: 1381.1959 - val_acc: 0.9541 - val_mDice: 0.5375

Epoch 00023: val_mDice improved from 0.53669 to 0.53745, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 24/300
 - 17s - loss: 243.2761 - acc: 0.9620 - mDice: 0.8126 - val_loss: 1393.7186 - val_acc: 0.9544 - val_mDice: 0.5432

Epoch 00024: val_mDice improved from 0.53745 to 0.54321, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 18s - loss: 241.3023 - acc: 0.9622 - mDice: 0.8142 - val_loss: 1385.1513 - val_acc: 0.9541 - val_mDice: 0.5471

Epoch 00025: val_mDice improved from 0.54321 to 0.54708, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 26/300
 - 18s - loss: 237.8116 - acc: 0.9623 - mDice: 0.8169 - val_loss: 1442.0949 - val_acc: 0.9544 - val_mDice: 0.5327

Epoch 00026: val_mDice did not improve from 0.54708
Epoch 27/300
 - 17s - loss: 236.5620 - acc: 0.9626 - mDice: 0.8177 - val_loss: 1475.5424 - val_acc: 0.9545 - val_mDice: 0.5308

Epoch 00027: val_mDice did not improve from 0.54708
Epoch 28/300
 - 17s - loss: 234.1118 - acc: 0.9627 - mDice: 0.8198 - val_loss: 1434.7810 - val_acc: 0.9546 - val_mDice: 0.5375

Epoch 00028: val_mDice did not improve from 0.54708
Epoch 29/300
 - 18s - loss: 231.9473 - acc: 0.9628 - mDice: 0.8214 - val_loss: 1461.8620 - val_acc: 0.9545 - val_mDice: 0.5372

Epoch 00029: val_mDice did not improve from 0.54708
Epoch 30/300
 - 17s - loss: 230.2834 - acc: 0.9631 - mDice: 0.8227 - val_loss: 1470.5916 - val_acc: 0.9544 - val_mDice: 0.5447

Epoch 00030: val_mDice did not improve from 0.54708
Epoch 31/300
 - 17s - loss: 227.9127 - acc: 0.9632 - mDice: 0.8243 - val_loss: 1471.0723 - val_acc: 0.9542 - val_mDice: 0.5332

Epoch 00031: val_mDice did not improve from 0.54708
Epoch 32/300
 - 17s - loss: 225.2457 - acc: 0.9633 - mDice: 0.8263 - val_loss: 1500.0906 - val_acc: 0.9543 - val_mDice: 0.5333

Epoch 00032: val_mDice did not improve from 0.54708
Epoch 33/300
 - 18s - loss: 223.7285 - acc: 0.9635 - mDice: 0.8279 - val_loss: 1546.4884 - val_acc: 0.9547 - val_mDice: 0.5299

Epoch 00033: val_mDice did not improve from 0.54708
Epoch 34/300
 - 17s - loss: 222.0982 - acc: 0.9635 - mDice: 0.8291 - val_loss: 1529.2355 - val_acc: 0.9535 - val_mDice: 0.5279

Epoch 00034: val_mDice did not improve from 0.54708
Epoch 35/300
 - 17s - loss: 220.2394 - acc: 0.9636 - mDice: 0.8304 - val_loss: 1504.2211 - val_acc: 0.9546 - val_mDice: 0.5405

Epoch 00035: val_mDice did not improve from 0.54708
Epoch 36/300
 - 17s - loss: 218.3946 - acc: 0.9638 - mDice: 0.8318 - val_loss: 1470.2453 - val_acc: 0.9550 - val_mDice: 0.5468

Epoch 00036: val_mDice did not improve from 0.54708
Epoch 37/300
 - 18s - loss: 217.1507 - acc: 0.9638 - mDice: 0.8327 - val_loss: 1455.7649 - val_acc: 0.9550 - val_mDice: 0.5413

Epoch 00037: val_mDice did not improve from 0.54708
Epoch 38/300
 - 18s - loss: 215.4946 - acc: 0.9640 - mDice: 0.8341 - val_loss: 1496.1419 - val_acc: 0.9548 - val_mDice: 0.5431

Epoch 00038: val_mDice did not improve from 0.54708
Epoch 39/300
 - 18s - loss: 215.1796 - acc: 0.9638 - mDice: 0.8346 - val_loss: 1506.6115 - val_acc: 0.9540 - val_mDice: 0.5361

Epoch 00039: val_mDice did not improve from 0.54708
Epoch 40/300
 - 18s - loss: 213.1015 - acc: 0.9642 - mDice: 0.8362 - val_loss: 1510.3041 - val_acc: 0.9546 - val_mDice: 0.5389

Epoch 00040: val_mDice did not improve from 0.54708
Epoch 41/300
 - 18s - loss: 211.4891 - acc: 0.9643 - mDice: 0.8373 - val_loss: 1568.1359 - val_acc: 0.9551 - val_mDice: 0.5370

Epoch 00041: val_mDice did not improve from 0.54708
Epoch 42/300
 - 18s - loss: 209.0912 - acc: 0.9643 - mDice: 0.8392 - val_loss: 1556.4996 - val_acc: 0.9546 - val_mDice: 0.5350

Epoch 00042: val_mDice did not improve from 0.54708
Epoch 43/300
 - 18s - loss: 208.7517 - acc: 0.9644 - mDice: 0.8396 - val_loss: 1590.7500 - val_acc: 0.9546 - val_mDice: 0.5311

Epoch 00043: val_mDice did not improve from 0.54708
Epoch 44/300
 - 17s - loss: 208.0055 - acc: 0.9645 - mDice: 0.8399 - val_loss: 1534.8475 - val_acc: 0.9546 - val_mDice: 0.5422

Epoch 00044: val_mDice did not improve from 0.54708
Epoch 45/300
 - 17s - loss: 206.6532 - acc: 0.9646 - mDice: 0.8412 - val_loss: 1469.7035 - val_acc: 0.9548 - val_mDice: 0.5463

Epoch 00045: val_mDice did not improve from 0.54708
Epoch 46/300
 - 17s - loss: 204.9871 - acc: 0.9647 - mDice: 0.8423 - val_loss: 1455.6611 - val_acc: 0.9549 - val_mDice: 0.5516

Epoch 00046: val_mDice improved from 0.54708 to 0.55162, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 18s - loss: 204.1612 - acc: 0.9648 - mDice: 0.8431 - val_loss: 1534.8674 - val_acc: 0.9550 - val_mDice: 0.5423

Epoch 00047: val_mDice did not improve from 0.55162
Epoch 48/300
 - 17s - loss: 203.0326 - acc: 0.9648 - mDice: 0.8440 - val_loss: 1594.7747 - val_acc: 0.9548 - val_mDice: 0.5340

Epoch 00048: val_mDice did not improve from 0.55162
Epoch 49/300
 - 17s - loss: 202.1500 - acc: 0.9649 - mDice: 0.8447 - val_loss: 1546.5186 - val_acc: 0.9544 - val_mDice: 0.5383

Epoch 00049: val_mDice did not improve from 0.55162
Epoch 50/300
 - 17s - loss: 200.4528 - acc: 0.9651 - mDice: 0.8458 - val_loss: 1566.1955 - val_acc: 0.9544 - val_mDice: 0.5392

Epoch 00050: val_mDice did not improve from 0.55162
Epoch 51/300
 - 17s - loss: 199.6001 - acc: 0.9651 - mDice: 0.8467 - val_loss: 1539.6312 - val_acc: 0.9543 - val_mDice: 0.5449

Epoch 00051: val_mDice did not improve from 0.55162
Epoch 52/300
 - 18s - loss: 198.7001 - acc: 0.9653 - mDice: 0.8474 - val_loss: 1602.6608 - val_acc: 0.9546 - val_mDice: 0.5348

Epoch 00052: val_mDice did not improve from 0.55162
Epoch 53/300
 - 17s - loss: 197.8232 - acc: 0.9653 - mDice: 0.8480 - val_loss: 1670.6629 - val_acc: 0.9547 - val_mDice: 0.5277

Epoch 00053: val_mDice did not improve from 0.55162
Epoch 54/300
 - 17s - loss: 196.8765 - acc: 0.9654 - mDice: 0.8490 - val_loss: 1517.1449 - val_acc: 0.9552 - val_mDice: 0.5536

Epoch 00054: val_mDice improved from 0.55162 to 0.55365, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 55/300
 - 17s - loss: 196.6908 - acc: 0.9653 - mDice: 0.8488 - val_loss: 1626.7196 - val_acc: 0.9537 - val_mDice: 0.5253

Epoch 00055: val_mDice did not improve from 0.55365
Epoch 56/300
 - 17s - loss: 195.3671 - acc: 0.9655 - mDice: 0.8500 - val_loss: 1603.1277 - val_acc: 0.9557 - val_mDice: 0.5401

Epoch 00056: val_mDice did not improve from 0.55365
Epoch 57/300
 - 18s - loss: 194.3766 - acc: 0.9656 - mDice: 0.8506 - val_loss: 1613.5733 - val_acc: 0.9551 - val_mDice: 0.5427

Epoch 00057: val_mDice did not improve from 0.55365
Epoch 58/300
 - 17s - loss: 192.8557 - acc: 0.9657 - mDice: 0.8519 - val_loss: 1606.3438 - val_acc: 0.9551 - val_mDice: 0.5341

Epoch 00058: val_mDice did not improve from 0.55365
Epoch 59/300
 - 18s - loss: 192.9976 - acc: 0.9657 - mDice: 0.8517 - val_loss: 1586.5547 - val_acc: 0.9554 - val_mDice: 0.5463

Epoch 00059: val_mDice did not improve from 0.55365
Epoch 60/300
 - 18s - loss: 192.0827 - acc: 0.9658 - mDice: 0.8527 - val_loss: 1686.0601 - val_acc: 0.9548 - val_mDice: 0.5323

Epoch 00060: val_mDice did not improve from 0.55365
Epoch 61/300
 - 17s - loss: 191.1494 - acc: 0.9657 - mDice: 0.8534 - val_loss: 1581.6463 - val_acc: 0.9546 - val_mDice: 0.5445

Epoch 00061: val_mDice did not improve from 0.55365
Epoch 62/300
 - 18s - loss: 190.1871 - acc: 0.9659 - mDice: 0.8541 - val_loss: 1653.6993 - val_acc: 0.9548 - val_mDice: 0.5317

Epoch 00062: val_mDice did not improve from 0.55365
Epoch 63/300
 - 18s - loss: 189.2611 - acc: 0.9659 - mDice: 0.8548 - val_loss: 1693.7086 - val_acc: 0.9541 - val_mDice: 0.5279

Epoch 00063: val_mDice did not improve from 0.55365
Epoch 64/300
 - 17s - loss: 188.8025 - acc: 0.9659 - mDice: 0.8549 - val_loss: 1622.0636 - val_acc: 0.9546 - val_mDice: 0.5373

Epoch 00064: val_mDice did not improve from 0.55365
Epoch 65/300
 - 18s - loss: 189.2715 - acc: 0.9659 - mDice: 0.8547 - val_loss: 1690.1866 - val_acc: 0.9550 - val_mDice: 0.5292

Epoch 00065: val_mDice did not improve from 0.55365
Epoch 66/300
 - 18s - loss: 187.6572 - acc: 0.9661 - mDice: 0.8559 - val_loss: 1639.2027 - val_acc: 0.9552 - val_mDice: 0.5390

Epoch 00066: val_mDice did not improve from 0.55365
Epoch 67/300
 - 17s - loss: 186.5375 - acc: 0.9661 - mDice: 0.8567 - val_loss: 1718.7729 - val_acc: 0.9547 - val_mDice: 0.5192

Epoch 00067: val_mDice did not improve from 0.55365
Epoch 68/300
 - 18s - loss: 186.5629 - acc: 0.9663 - mDice: 0.8569 - val_loss: 1714.8437 - val_acc: 0.9551 - val_mDice: 0.5319

Epoch 00068: val_mDice did not improve from 0.55365
Epoch 69/300
 - 18s - loss: 184.5343 - acc: 0.9663 - mDice: 0.8584 - val_loss: 1670.6403 - val_acc: 0.9548 - val_mDice: 0.5283

Epoch 00069: val_mDice did not improve from 0.55365
Epoch 70/300
 - 17s - loss: 184.0025 - acc: 0.9665 - mDice: 0.8591 - val_loss: 1703.2178 - val_acc: 0.9550 - val_mDice: 0.5280

Epoch 00070: val_mDice did not improve from 0.55365
Epoch 71/300
 - 17s - loss: 184.1732 - acc: 0.9665 - mDice: 0.8586 - val_loss: 1613.7347 - val_acc: 0.9550 - val_mDice: 0.5409

Epoch 00071: val_mDice did not improve from 0.55365
Epoch 72/300
 - 18s - loss: 183.4072 - acc: 0.9665 - mDice: 0.8594 - val_loss: 1682.8252 - val_acc: 0.9548 - val_mDice: 0.5361

Epoch 00072: val_mDice did not improve from 0.55365
Epoch 73/300
 - 17s - loss: 182.0438 - acc: 0.9666 - mDice: 0.8606 - val_loss: 1618.6682 - val_acc: 0.9553 - val_mDice: 0.5395

Epoch 00073: val_mDice did not improve from 0.55365
Epoch 74/300
 - 17s - loss: 181.4206 - acc: 0.9666 - mDice: 0.8609 - val_loss: 1709.0819 - val_acc: 0.9550 - val_mDice: 0.5369

Epoch 00074: val_mDice did not improve from 0.55365
Epoch 75/300
 - 18s - loss: 180.9964 - acc: 0.9666 - mDice: 0.8611 - val_loss: 1637.9335 - val_acc: 0.9551 - val_mDice: 0.5399

Epoch 00075: val_mDice did not improve from 0.55365
Epoch 76/300
 - 18s - loss: 180.8093 - acc: 0.9667 - mDice: 0.8612 - val_loss: 1677.8987 - val_acc: 0.9549 - val_mDice: 0.5325

Epoch 00076: val_mDice did not improve from 0.55365
Epoch 77/300
 - 17s - loss: 179.9187 - acc: 0.9667 - mDice: 0.8619 - val_loss: 1707.5245 - val_acc: 0.9551 - val_mDice: 0.5245

Epoch 00077: val_mDice did not improve from 0.55365
Epoch 78/300
 - 17s - loss: 179.5620 - acc: 0.9669 - mDice: 0.8623 - val_loss: 1714.2520 - val_acc: 0.9547 - val_mDice: 0.5288

Epoch 00078: val_mDice did not improve from 0.55365
Epoch 79/300
 - 17s - loss: 179.6555 - acc: 0.9669 - mDice: 0.8622 - val_loss: 1660.4273 - val_acc: 0.9550 - val_mDice: 0.5441

Epoch 00079: val_mDice did not improve from 0.55365
Epoch 80/300
 - 18s - loss: 178.4756 - acc: 0.9669 - mDice: 0.8631 - val_loss: 1663.7151 - val_acc: 0.9552 - val_mDice: 0.5386

Epoch 00080: val_mDice did not improve from 0.55365
Epoch 81/300
 - 17s - loss: 177.9997 - acc: 0.9669 - mDice: 0.8637 - val_loss: 1660.9500 - val_acc: 0.9543 - val_mDice: 0.5354

Epoch 00081: val_mDice did not improve from 0.55365
Epoch 82/300
 - 18s - loss: 178.2833 - acc: 0.9670 - mDice: 0.8633 - val_loss: 1666.0340 - val_acc: 0.9552 - val_mDice: 0.5404

Epoch 00082: val_mDice did not improve from 0.55365
Epoch 83/300
 - 17s - loss: 176.9592 - acc: 0.9670 - mDice: 0.8643 - val_loss: 1629.3837 - val_acc: 0.9551 - val_mDice: 0.5475

Epoch 00083: val_mDice did not improve from 0.55365
Epoch 84/300
 - 18s - loss: 176.5924 - acc: 0.9671 - mDice: 0.8649 - val_loss: 1705.8377 - val_acc: 0.9549 - val_mDice: 0.5357

Epoch 00084: val_mDice did not improve from 0.55365
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
{'val_loss': [1059.337719112801, 990.0311224740311, 976.5526409468837, 1055.3580724620285, 1085.5758315784306, 1164.395329139752, 1262.6308375523743, 1164.65262608022, 1190.7152870220846, 1276.485301097678, 1277.2641369697103, 1313.1497414018854, 1321.0572025576118, 1357.1538883827252, 1321.8289651710893, 1435.2853287851344, 1367.9582478613827, 1324.8636863324896, 1399.574104181215, 1418.7039065227827, 1398.605570361601, 1373.097116821971, 1381.195866931084, 1393.7186388410003, 1385.151278533083, 1442.0949284217877, 1475.5423870406337, 1434.7809785810928, 1461.8620155377096, 1470.5916447985771, 1471.0722929032822, 1500.0906382299668, 1546.4883951368279, 1529.235494091524, 1504.2211075255325, 1470.245335413757, 1455.7649484986034, 1496.1419084431739, 1506.6114767916376, 1510.304095561278, 1568.1359317715608, 1556.49964129059, 1590.7500143210982, 1534.8475334977304, 1469.7035382659742, 1455.6610598430952, 1534.8674180014839, 1594.7747066220757, 1546.5185792379539, 1566.1955232247294, 1539.6312371792073, 1602.6607686474338, 1670.662946136304, 1517.1448995068088, 1626.719584033476, 1603.1277285101694, 1613.573292652322, 1606.3438025106932, 1586.5547488761347, 1686.060109740529, 1581.646305702252, 1653.699310132245, 1693.7085533781424, 1622.063591131285, 1690.1865527616533, 1639.2027083242406, 1718.7728748854313, 1714.8436531620985, 1670.6403399419519, 1703.2177952601257, 1613.7346648317475, 1682.825157804862, 1618.668212890625, 1709.0819303203562, 1637.9334880466567, 1677.8987402889315, 1707.5245074906163, 1714.252003589822, 1660.4272665524616, 1663.7151240343487, 1660.950027551065, 1666.0340030606233, 1629.3837420074633, 1705.8377440042336], 'val_acc': [0.9443737571465902, 0.9514644012770839, 0.952751562582048, 0.9525511714333262, 0.9537102310351153, 0.9535408053318215, 0.9541089568058205, 0.9535345871355281, 0.9532412310552331, 0.9534912325816447, 0.9539023631111869, 0.9544395021886133, 0.9535697182463534, 0.9540015349175011, 0.9543465412528821, 0.9525470297429814, 0.9541916028081372, 0.9544704932740281, 0.9545200956600338, 0.9539188815894739, 0.9548899171738651, 0.9542122716344269, 0.9541358118616668, 0.9543733996385969, 0.9540676281438859, 0.9544477805745002, 0.9544994231708889, 0.9546151271079506, 0.9545345762588459, 0.9544498640731727, 0.9542391097079442, 0.9543238198956964, 0.9547246331609162, 0.9534891557427092, 0.9546275175483533, 0.9549849646051503, 0.9549952775406438, 0.9547742208955008, 0.9539643276337139, 0.9545635024928514, 0.9551440290898584, 0.954594464275424, 0.9545634921702593, 0.954565549695958, 0.9547866306491404, 0.9548837259495059, 0.9550448825905443, 0.9548320910118145, 0.9544250708718539, 0.9544126581213328, 0.9542907533032934, 0.9545882966931306, 0.9547308183915122, 0.9552122441084026, 0.9536874873678112, 0.9557142564038325, 0.9551440477371216, 0.9551254667383332, 0.9553630558472106, 0.9547700715464587, 0.9545655640143922, 0.9547659754753113, 0.954090336181598, 0.9545696970470791, 0.954960183058371, 0.9551708991301127, 0.9546523010930535, 0.9550717249928906, 0.9547514982063677, 0.9550469351214403, 0.9550221345944112, 0.9547700805371034, 0.955290742759598, 0.9550055991337952, 0.9550696628053761, 0.9549064493046127, 0.9550758397113012, 0.954699842956479, 0.955026263631256, 0.9551667850776757, 0.9542514898257548, 0.9551584820507625, 0.9550923931532066, 0.9549456804824275], 'val_mDice': [0.39853033173683633, 0.4688916462759732, 0.5046145296629581, 0.506370955672344, 0.5152980575348411, 0.5148172813087868, 0.5067067381056993, 0.5227072452033699, 0.5211561089121429, 0.5207509190343612, 0.5235623928754689, 0.5254231511547579, 0.5324954428819305, 0.5243837137462041, 0.525082342784498, 0.5156522193434518, 0.527822526140586, 0.536243516140144, 0.5234504901497058, 0.5300052207608462, 0.5366949099402188, 0.5364403221860278, 0.5374532759855579, 0.5432068732197725, 0.5470788900079674, 0.5327111369404713, 0.53075349763785, 0.5375150177398873, 0.537192181668468, 0.5447008125275873, 0.533175767633502, 0.5333019774719323, 0.529946879634644, 0.5278756192276598, 0.5404872862653359, 0.5468446439204935, 0.5413325991710471, 0.5430869010573659, 0.5360682560078924, 0.5388777059549726, 0.5370110323309233, 0.5350436005512429, 0.5310777841999544, 0.5421775616081067, 0.5462503080261486, 0.5516164311150599, 0.5422931584898986, 0.5340030219967805, 0.5383216592186656, 0.5391728893005648, 0.5448841858842519, 0.5348433039707845, 0.5276524344636075, 0.5536489448400849, 0.5252826027364038, 0.540058513093927, 0.5427086762875818, 0.5341001222919486, 0.5462912670726883, 0.5322777572290858, 0.5444590627481152, 0.5317084263156913, 0.5278604323637552, 0.5372818175640852, 0.5291881789375283, 0.539014035263541, 0.5192292668965942, 0.5319018891736782, 0.52825602306334, 0.5279884218503643, 0.5409164337139556, 0.5361144879010803, 0.5395243480884829, 0.5368539123228808, 0.5399012409108978, 0.5324750635877001, 0.5245054688866578, 0.528814189926872, 0.5441172557503151, 0.5386480665739688, 0.5353731776082982, 0.5404055161849081, 0.5475215831948392, 0.5357392581814494], 'loss': [1050.7021205975439, 543.546074684367, 458.23886247182696, 413.9279102636873, 382.87778630175364, 360.8337749038463, 343.00364416049825, 329.88322920098324, 319.7053363169079, 309.47615780759486, 301.29868015937313, 294.19086509028534, 287.85532039212063, 281.55277660364266, 276.43073869186526, 271.22507549315185, 267.97799716606863, 263.20082366612604, 258.8968117479522, 255.84692660381018, 252.39856416016556, 249.1770188091796, 245.9924498928326, 243.2761183298723, 241.30225065617861, 237.81158935919183, 236.56195466429196, 234.11179974465958, 231.94731731590352, 230.28339964932758, 227.91266210117757, 225.245662445921, 223.72854047984796, 222.09821757664642, 220.2393755123549, 218.3945700954647, 217.15069772797105, 215.49459765402946, 215.17960786193578, 213.10145446434953, 211.489121048508, 209.0912015615845, 208.75168748943577, 208.00553693262867, 206.6532490089707, 204.98714760615735, 204.16124301966704, 203.03264986778564, 202.14995670022543, 200.45282758159397, 199.6001342919701, 198.70008261760435, 197.82321549770808, 196.8764785584603, 196.69076052424137, 195.36706061295956, 194.37664225490892, 192.85570233969716, 192.99764130916816, 192.08269500566215, 191.1494159822104, 190.18708402950398, 189.26105004838269, 188.80251542330242, 189.27148232190711, 187.65722513892254, 186.53752547098358, 186.56287533247058, 184.53425557174089, 184.00249359494856, 184.17316876098707, 183.407201133401, 182.04378089470566, 181.42060678861324, 180.99636829310361, 180.8092682946839, 179.9186553739007, 179.56196662591606, 179.6555270769518, 178.47559410250204, 177.99965466570538, 178.28331127782758, 176.95921557835587, 176.59244105003154], 'acc': [0.9220956579304411, 0.9429748068220195, 0.9475702460759684, 0.9501648848920689, 0.95211788874476, 0.9534533643221311, 0.954685274957734, 0.9555890747199851, 0.9563326484256759, 0.9570399238603462, 0.9575965807858743, 0.9581330361614806, 0.9586616549725094, 0.9590282365002083, 0.9594563696387157, 0.9598649447178906, 0.9601845539192068, 0.960578545880119, 0.9609370686657178, 0.9611440244229243, 0.9613109795130855, 0.9614762622938327, 0.9617930335433945, 0.9620045624483866, 0.9621627530912176, 0.9623418963395018, 0.9625861143619171, 0.9626884747516303, 0.9628317222428486, 0.9630514676551025, 0.9631603944568448, 0.9632957282490178, 0.9634729754002186, 0.9634988982299205, 0.9636454879572095, 0.9637773973438892, 0.963844448855536, 0.9639946850911769, 0.9638232202267869, 0.9641620013963279, 0.9642700667987948, 0.9643346192101677, 0.9644259818530889, 0.9644667894471075, 0.9646298764227367, 0.9646970894619645, 0.9647930028080051, 0.9648400544438523, 0.9649398764372716, 0.9650928735259078, 0.9650955530827253, 0.965273202381053, 0.9652597705891083, 0.965407731752368, 0.9653343947928011, 0.9654712167241191, 0.9655935168525998, 0.9656787762051866, 0.9657190015234074, 0.9657786998391171, 0.9657000664220475, 0.9658571917905143, 0.9658709106073421, 0.9659215653327664, 0.9659403792673399, 0.9661223992861977, 0.9661079372373336, 0.9662587799886221, 0.966346819629584, 0.9665036616479381, 0.9664625115244225, 0.9665424357532617, 0.9665534529678962, 0.9665810647278815, 0.9665860025998677, 0.96668787860486, 0.9667451234984701, 0.9668611566210539, 0.9668603313754154, 0.9669122575940952, 0.9668941302085505, 0.9669976381524236, 0.9670439822748721, 0.9671320839292064], 'mDice': [0.38663455999096874, 0.5960761949157839, 0.6542873634543335, 0.6849556124864156, 0.7079350942620316, 0.7243381967751538, 0.7372365648934385, 0.7473517472587777, 0.7547542644731295, 0.7626147623266258, 0.7685735426686129, 0.7739775598415991, 0.7786006188608191, 0.7832798903806881, 0.7871342765876562, 0.791415958514005, 0.7939046400641637, 0.7972116542144263, 0.800663225502498, 0.8030556869704208, 0.8058254376624341, 0.8081324760589612, 0.8104351157359351, 0.8126287808001973, 0.8142076532576223, 0.8168916277237223, 0.8177074344353857, 0.8198179309420464, 0.8214111883365915, 0.8226560611531636, 0.8243015529991111, 0.8263304865208985, 0.8278812190058132, 0.8290778568098601, 0.830379653003609, 0.8318339104966903, 0.8327258837248374, 0.8341480646639321, 0.8345834858491136, 0.8362295278555739, 0.8373246937560058, 0.8392149492823138, 0.8395778899436669, 0.8399295161884663, 0.8411589722527923, 0.8422504837369745, 0.8431384850285891, 0.8439965671680376, 0.8446663025222659, 0.845782190579149, 0.8466767405906565, 0.8473993493713239, 0.8479645041415429, 0.8490177151697289, 0.848810876787673, 0.8499805717535525, 0.8505655854143457, 0.8519269303587045, 0.851734151569991, 0.8526875029481007, 0.8533799905908386, 0.8541076181760885, 0.8548093021685349, 0.8548669284234464, 0.8546968129950991, 0.8558839616234815, 0.8566653802045439, 0.8568750665530771, 0.8583919227652401, 0.8590620884376702, 0.858649814617763, 0.8594230408827196, 0.8606076111403187, 0.8608768462264768, 0.8610581021950101, 0.8612450843029802, 0.8619233310420648, 0.8623379317706891, 0.8622481762716878, 0.8630735958676266, 0.8637245508406612, 0.8632902336285516, 0.8642617031078922, 0.8648543472182523]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.81s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.51s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.25s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:26,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:50,  1.88s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:57,  1.91s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<09:08,  1.95s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:50,  1.90s/it]predicting train subjects:   2%|▏         | 6/285 [00:12<09:34,  2.06s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<10:11,  2.20s/it]predicting train subjects:   3%|▎         | 8/285 [00:16<10:16,  2.22s/it]predicting train subjects:   3%|▎         | 9/285 [00:18<09:45,  2.12s/it]predicting train subjects:   4%|▎         | 10/285 [00:21<10:20,  2.26s/it]predicting train subjects:   4%|▍         | 11/285 [00:23<10:34,  2.31s/it]predicting train subjects:   4%|▍         | 12/285 [00:26<10:51,  2.38s/it]predicting train subjects:   5%|▍         | 13/285 [00:28<10:58,  2.42s/it]predicting train subjects:   5%|▍         | 14/285 [00:31<11:10,  2.47s/it]predicting train subjects:   5%|▌         | 15/285 [00:33<11:10,  2.48s/it]predicting train subjects:   6%|▌         | 16/285 [00:36<11:21,  2.53s/it]predicting train subjects:   6%|▌         | 17/285 [00:39<11:07,  2.49s/it]predicting train subjects:   6%|▋         | 18/285 [00:41<10:45,  2.42s/it]predicting train subjects:   7%|▋         | 19/285 [00:43<10:21,  2.34s/it]predicting train subjects:   7%|▋         | 20/285 [00:45<10:22,  2.35s/it]predicting train subjects:   7%|▋         | 21/285 [00:47<10:03,  2.29s/it]predicting train subjects:   8%|▊         | 22/285 [00:50<10:00,  2.28s/it]predicting train subjects:   8%|▊         | 23/285 [00:52<10:00,  2.29s/it]predicting train subjects:   8%|▊         | 24/285 [00:55<10:18,  2.37s/it]predicting train subjects:   9%|▉         | 25/285 [00:57<10:30,  2.43s/it]predicting train subjects:   9%|▉         | 26/285 [01:00<10:25,  2.41s/it]predicting train subjects:   9%|▉         | 27/285 [01:02<10:31,  2.45s/it]predicting train subjects:  10%|▉         | 28/285 [01:04<09:55,  2.32s/it]predicting train subjects:  10%|█         | 29/285 [01:06<09:22,  2.20s/it]predicting train subjects:  11%|█         | 30/285 [01:08<09:07,  2.15s/it]predicting train subjects:  11%|█         | 31/285 [01:10<08:46,  2.07s/it]predicting train subjects:  11%|█         | 32/285 [01:12<08:35,  2.04s/it]predicting train subjects:  12%|█▏        | 33/285 [01:14<08:53,  2.12s/it]predicting train subjects:  12%|█▏        | 34/285 [01:16<08:56,  2.14s/it]predicting train subjects:  12%|█▏        | 35/285 [01:19<09:14,  2.22s/it]predicting train subjects:  13%|█▎        | 36/285 [01:21<09:10,  2.21s/it]predicting train subjects:  13%|█▎        | 37/285 [01:23<09:07,  2.21s/it]predicting train subjects:  13%|█▎        | 38/285 [01:25<09:10,  2.23s/it]predicting train subjects:  14%|█▎        | 39/285 [01:28<09:13,  2.25s/it]predicting train subjects:  14%|█▍        | 40/285 [01:30<09:08,  2.24s/it]predicting train subjects:  14%|█▍        | 41/285 [01:32<09:07,  2.24s/it]predicting train subjects:  15%|█▍        | 42/285 [01:35<09:09,  2.26s/it]predicting train subjects:  15%|█▌        | 43/285 [01:37<09:19,  2.31s/it]predicting train subjects:  15%|█▌        | 44/285 [01:39<09:20,  2.33s/it]predicting train subjects:  16%|█▌        | 45/285 [01:42<09:19,  2.33s/it]predicting train subjects:  16%|█▌        | 46/285 [01:44<09:10,  2.30s/it]predicting train subjects:  16%|█▋        | 47/285 [01:46<08:55,  2.25s/it]predicting train subjects:  17%|█▋        | 48/285 [01:48<08:47,  2.22s/it]predicting train subjects:  17%|█▋        | 49/285 [01:50<08:30,  2.16s/it]predicting train subjects:  18%|█▊        | 50/285 [01:52<08:18,  2.12s/it]predicting train subjects:  18%|█▊        | 51/285 [01:54<08:05,  2.07s/it]predicting train subjects:  18%|█▊        | 52/285 [01:56<08:06,  2.09s/it]predicting train subjects:  19%|█▊        | 53/285 [01:58<08:07,  2.10s/it]predicting train subjects:  19%|█▉        | 54/285 [02:00<07:57,  2.07s/it]predicting train subjects:  19%|█▉        | 55/285 [02:03<08:25,  2.20s/it]predicting train subjects:  20%|█▉        | 56/285 [02:05<08:09,  2.14s/it]predicting train subjects:  20%|██        | 57/285 [02:07<08:06,  2.14s/it]predicting train subjects:  20%|██        | 58/285 [02:09<07:59,  2.11s/it]predicting train subjects:  21%|██        | 59/285 [02:11<08:01,  2.13s/it]predicting train subjects:  21%|██        | 60/285 [02:13<08:00,  2.14s/it]predicting train subjects:  21%|██▏       | 61/285 [02:16<08:05,  2.17s/it]predicting train subjects:  22%|██▏       | 62/285 [02:18<08:14,  2.22s/it]predicting train subjects:  22%|██▏       | 63/285 [02:20<08:02,  2.17s/it]predicting train subjects:  22%|██▏       | 64/285 [02:22<07:59,  2.17s/it]predicting train subjects:  23%|██▎       | 65/285 [02:25<08:12,  2.24s/it]predicting train subjects:  23%|██▎       | 66/285 [02:28<08:54,  2.44s/it]predicting train subjects:  24%|██▎       | 67/285 [02:30<09:06,  2.51s/it]predicting train subjects:  24%|██▍       | 68/285 [02:33<09:26,  2.61s/it]predicting train subjects:  24%|██▍       | 69/285 [02:36<09:38,  2.68s/it]predicting train subjects:  25%|██▍       | 70/285 [02:38<09:30,  2.65s/it]predicting train subjects:  25%|██▍       | 71/285 [02:41<09:01,  2.53s/it]predicting train subjects:  25%|██▌       | 72/285 [02:43<08:28,  2.39s/it]predicting train subjects:  26%|██▌       | 73/285 [02:45<08:27,  2.40s/it]predicting train subjects:  26%|██▌       | 74/285 [02:47<08:02,  2.29s/it]predicting train subjects:  26%|██▋       | 75/285 [02:49<07:50,  2.24s/it]predicting train subjects:  27%|██▋       | 76/285 [02:52<07:45,  2.23s/it]predicting train subjects:  27%|██▋       | 77/285 [02:54<07:32,  2.17s/it]predicting train subjects:  27%|██▋       | 78/285 [02:56<07:19,  2.13s/it]predicting train subjects:  28%|██▊       | 79/285 [02:58<07:16,  2.12s/it]predicting train subjects:  28%|██▊       | 80/285 [03:00<07:05,  2.08s/it]predicting train subjects:  28%|██▊       | 81/285 [03:02<06:59,  2.06s/it]predicting train subjects:  29%|██▉       | 82/285 [03:04<07:04,  2.09s/it]predicting train subjects:  29%|██▉       | 83/285 [03:06<06:51,  2.04s/it]predicting train subjects:  29%|██▉       | 84/285 [03:08<06:58,  2.08s/it]predicting train subjects:  30%|██▉       | 85/285 [03:10<07:06,  2.13s/it]predicting train subjects:  30%|███       | 86/285 [03:13<07:17,  2.20s/it]predicting train subjects:  31%|███       | 87/285 [03:15<07:20,  2.22s/it]predicting train subjects:  31%|███       | 88/285 [03:17<07:13,  2.20s/it]predicting train subjects:  31%|███       | 89/285 [03:19<07:15,  2.22s/it]predicting train subjects:  32%|███▏      | 90/285 [03:21<07:02,  2.17s/it]predicting train subjects:  32%|███▏      | 91/285 [03:24<07:07,  2.20s/it]predicting train subjects:  32%|███▏      | 92/285 [03:26<07:18,  2.27s/it]predicting train subjects:  33%|███▎      | 93/285 [03:28<07:12,  2.25s/it]predicting train subjects:  33%|███▎      | 94/285 [03:31<07:14,  2.27s/it]predicting train subjects:  33%|███▎      | 95/285 [03:33<07:06,  2.25s/it]predicting train subjects:  34%|███▎      | 96/285 [03:35<07:07,  2.26s/it]predicting train subjects:  34%|███▍      | 97/285 [03:37<07:03,  2.25s/it]predicting train subjects:  34%|███▍      | 98/285 [03:40<07:04,  2.27s/it]predicting train subjects:  35%|███▍      | 99/285 [03:42<07:02,  2.27s/it]predicting train subjects:  35%|███▌      | 100/285 [03:44<06:48,  2.21s/it]predicting train subjects:  35%|███▌      | 101/285 [03:46<06:46,  2.21s/it]predicting train subjects:  36%|███▌      | 102/285 [03:48<06:46,  2.22s/it]predicting train subjects:  36%|███▌      | 103/285 [03:50<06:35,  2.18s/it]predicting train subjects:  36%|███▋      | 104/285 [03:53<06:35,  2.19s/it]predicting train subjects:  37%|███▋      | 105/285 [03:55<06:29,  2.16s/it]predicting train subjects:  37%|███▋      | 106/285 [03:57<06:29,  2.18s/it]predicting train subjects:  38%|███▊      | 107/285 [03:59<06:20,  2.14s/it]predicting train subjects:  38%|███▊      | 108/285 [04:01<06:12,  2.10s/it]predicting train subjects:  38%|███▊      | 109/285 [04:03<06:12,  2.12s/it]predicting train subjects:  39%|███▊      | 110/285 [04:05<06:07,  2.10s/it]predicting train subjects:  39%|███▉      | 111/285 [04:07<06:04,  2.09s/it]predicting train subjects:  39%|███▉      | 112/285 [04:09<05:55,  2.06s/it]predicting train subjects:  40%|███▉      | 113/285 [04:11<05:45,  2.01s/it]predicting train subjects:  40%|████      | 114/285 [04:13<05:43,  2.01s/it]predicting train subjects:  40%|████      | 115/285 [04:15<05:49,  2.05s/it]predicting train subjects:  41%|████      | 116/285 [04:18<05:50,  2.07s/it]predicting train subjects:  41%|████      | 117/285 [04:20<05:52,  2.10s/it]predicting train subjects:  41%|████▏     | 118/285 [04:22<05:48,  2.09s/it]predicting train subjects:  42%|████▏     | 119/285 [04:24<05:47,  2.10s/it]predicting train subjects:  42%|████▏     | 120/285 [04:26<05:45,  2.09s/it]predicting train subjects:  42%|████▏     | 121/285 [04:28<05:31,  2.02s/it]predicting train subjects:  43%|████▎     | 122/285 [04:29<05:10,  1.90s/it]predicting train subjects:  43%|████▎     | 123/285 [04:31<05:06,  1.89s/it]predicting train subjects:  44%|████▎     | 124/285 [04:33<05:07,  1.91s/it]predicting train subjects:  44%|████▍     | 125/285 [04:35<05:06,  1.91s/it]predicting train subjects:  44%|████▍     | 126/285 [04:37<04:59,  1.88s/it]predicting train subjects:  45%|████▍     | 127/285 [04:39<05:02,  1.92s/it]predicting train subjects:  45%|████▍     | 128/285 [04:41<05:09,  1.97s/it]predicting train subjects:  45%|████▌     | 129/285 [04:43<05:05,  1.96s/it]predicting train subjects:  46%|████▌     | 130/285 [04:45<05:10,  2.00s/it]predicting train subjects:  46%|████▌     | 131/285 [04:47<05:05,  1.98s/it]predicting train subjects:  46%|████▋     | 132/285 [04:49<05:03,  1.98s/it]predicting train subjects:  47%|████▋     | 133/285 [04:51<04:52,  1.93s/it]predicting train subjects:  47%|████▋     | 134/285 [04:53<04:52,  1.94s/it]predicting train subjects:  47%|████▋     | 135/285 [04:55<04:50,  1.93s/it]predicting train subjects:  48%|████▊     | 136/285 [04:57<04:45,  1.91s/it]predicting train subjects:  48%|████▊     | 137/285 [04:59<04:56,  2.00s/it]predicting train subjects:  48%|████▊     | 138/285 [05:01<04:50,  1.98s/it]predicting train subjects:  49%|████▉     | 139/285 [05:03<04:47,  1.97s/it]predicting train subjects:  49%|████▉     | 140/285 [05:05<04:44,  1.96s/it]predicting train subjects:  49%|████▉     | 141/285 [05:06<04:38,  1.94s/it]predicting train subjects:  50%|████▉     | 142/285 [05:08<04:34,  1.92s/it]predicting train subjects:  50%|█████     | 143/285 [05:10<04:25,  1.87s/it]predicting train subjects:  51%|█████     | 144/285 [05:12<04:28,  1.90s/it]predicting train subjects:  51%|█████     | 145/285 [05:14<04:19,  1.86s/it]predicting train subjects:  51%|█████     | 146/285 [05:16<04:17,  1.85s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:18<04:18,  1.87s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:19<04:14,  1.86s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:21<04:09,  1.83s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:23<04:03,  1.81s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:25<04:03,  1.81s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:27<04:01,  1.81s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:28<03:57,  1.80s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:30<03:59,  1.83s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:32<03:56,  1.82s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:34<03:50,  1.79s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:36<03:49,  1.79s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:37<03:43,  1.76s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:39<03:42,  1.77s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:41<03:39,  1.75s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:42<03:36,  1.75s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:44<03:39,  1.78s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:46<03:37,  1.78s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:48<03:33,  1.76s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:50<03:30,  1.75s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:51<03:30,  1.77s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:53<03:29,  1.78s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:55<03:25,  1.76s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:57<03:22,  1.74s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:58<03:22,  1.76s/it]predicting train subjects:  60%|██████    | 171/285 [06:00<03:25,  1.80s/it]predicting train subjects:  60%|██████    | 172/285 [06:02<03:21,  1.79s/it]predicting train subjects:  61%|██████    | 173/285 [06:04<03:20,  1.79s/it]predicting train subjects:  61%|██████    | 174/285 [06:06<03:24,  1.84s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:08<03:18,  1.81s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:09<03:18,  1.82s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:11<03:18,  1.84s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:13<03:11,  1.79s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:15<03:06,  1.76s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:16<03:04,  1.76s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:18<03:04,  1.77s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:20<02:59,  1.75s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:22<02:54,  1.72s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:23<02:51,  1.70s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:25<02:51,  1.72s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:27<02:52,  1.74s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:29<02:52,  1.76s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:30<02:51,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:32<02:51,  1.78s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:34<02:47,  1.76s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:36<02:45,  1.76s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:37<02:44,  1.77s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:39<02:38,  1.72s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:41<02:34,  1.70s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:42<02:32,  1.70s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:44<02:36,  1.76s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:46<02:39,  1.81s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:48<02:46,  1.91s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:50<02:46,  1.94s/it]predicting train subjects:  70%|███████   | 200/285 [06:52<02:49,  1.99s/it]predicting train subjects:  71%|███████   | 201/285 [06:54<02:47,  1.99s/it]predicting train subjects:  71%|███████   | 202/285 [06:56<02:45,  1.99s/it]predicting train subjects:  71%|███████   | 203/285 [06:58<02:43,  1.99s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:01<02:44,  2.03s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:03<02:41,  2.01s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:04<02:37,  1.99s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:06<02:32,  1.96s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:08<02:33,  1.99s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:11<02:36,  2.06s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:13<02:36,  2.08s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:15<02:31,  2.05s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:16<02:22,  1.95s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:18<02:18,  1.93s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:20<02:16,  1.93s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:22<02:07,  1.82s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:23<02:01,  1.77s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:25<01:59,  1.76s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:27<01:56,  1.74s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:29<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:30<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:32<01:46,  1.67s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:33<01:44,  1.65s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:35<01:43,  1.67s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:37<01:40,  1.65s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:38<01:37,  1.62s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:40<01:36,  1.63s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:42<01:34,  1.64s/it]predicting train subjects:  80%|████████  | 228/285 [07:43<01:32,  1.63s/it]predicting train subjects:  80%|████████  | 229/285 [07:45<01:31,  1.63s/it]predicting train subjects:  81%|████████  | 230/285 [07:46<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [07:48<01:29,  1.65s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:50<01:33,  1.77s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:52<01:34,  1.82s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:54<01:39,  1.95s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:56<01:36,  1.94s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:58<01:38,  2.00s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:00<01:35,  1.99s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:02<01:34,  2.02s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:04<01:32,  2.01s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:06<01:29,  1.99s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:08<01:28,  2.01s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:10<01:26,  2.01s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:12<01:23,  2.00s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:15<01:23,  2.04s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:17<01:22,  2.07s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:19<01:20,  2.05s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:21<01:17,  2.05s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:23<01:13,  1.98s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:25<01:11,  1.99s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:26<01:06,  1.90s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:28<01:01,  1.82s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:29<00:56,  1.70s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:31<00:53,  1.68s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:33<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:34<00:48,  1.60s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:36<00:45,  1.57s/it]predicting train subjects:  90%|█████████ | 257/285 [08:37<00:45,  1.62s/it]predicting train subjects:  91%|█████████ | 258/285 [08:39<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [08:41<00:43,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [08:42<00:41,  1.66s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:44<00:38,  1.61s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:46<00:37,  1.63s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:47<00:36,  1.67s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:49<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:50<00:31,  1.59s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:52<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:53<00:28,  1.56s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:55<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:57<00:28,  1.79s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:00<00:28,  1.93s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:01<00:26,  1.90s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:04<00:25,  1.94s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:05<00:23,  1.94s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:08<00:21,  1.98s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:10<00:20,  2.00s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:12<00:18,  2.04s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:14<00:16,  2.05s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:16<00:14,  2.02s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:18<00:12,  2.05s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:20<00:10,  2.07s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:22<00:08,  2.08s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:24<00:06,  2.09s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:26<00:04,  2.12s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:28<00:02,  2.08s/it]predicting train subjects: 100%|██████████| 285/285 [09:30<00:00,  2.06s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:18,  1.33s/it]Loading train:   1%|          | 2/285 [00:02<06:40,  1.42s/it]Loading train:   1%|          | 3/285 [00:04<06:42,  1.43s/it]Loading train:   1%|▏         | 4/285 [00:06<07:00,  1.50s/it]Loading train:   2%|▏         | 5/285 [00:07<06:48,  1.46s/it]Loading train:   2%|▏         | 6/285 [00:09<07:07,  1.53s/it]Loading train:   2%|▏         | 7/285 [00:11<07:44,  1.67s/it]Loading train:   3%|▎         | 8/285 [00:13<08:33,  1.86s/it]Loading train:   3%|▎         | 9/285 [00:15<09:10,  1.99s/it]Loading train:   4%|▎         | 10/285 [00:17<09:24,  2.05s/it]Loading train:   4%|▍         | 11/285 [00:20<09:50,  2.15s/it]Loading train:   4%|▍         | 12/285 [00:22<09:19,  2.05s/it]Loading train:   5%|▍         | 13/285 [00:23<08:56,  1.97s/it]Loading train:   5%|▍         | 14/285 [00:25<08:29,  1.88s/it]Loading train:   5%|▌         | 15/285 [00:27<08:19,  1.85s/it]Loading train:   6%|▌         | 16/285 [00:29<08:02,  1.79s/it]Loading train:   6%|▌         | 17/285 [00:30<07:41,  1.72s/it]Loading train:   6%|▋         | 18/285 [00:32<07:47,  1.75s/it]Loading train:   7%|▋         | 19/285 [00:33<07:06,  1.60s/it]Loading train:   7%|▋         | 20/285 [00:35<06:48,  1.54s/it]Loading train:   7%|▋         | 21/285 [00:36<06:18,  1.43s/it]Loading train:   8%|▊         | 22/285 [00:37<06:12,  1.42s/it]Loading train:   8%|▊         | 23/285 [00:38<06:00,  1.38s/it]Loading train:   8%|▊         | 24/285 [00:40<05:51,  1.35s/it]Loading train:   9%|▉         | 25/285 [00:41<06:14,  1.44s/it]Loading train:   9%|▉         | 26/285 [00:43<06:28,  1.50s/it]Loading train:   9%|▉         | 27/285 [00:45<07:04,  1.65s/it]Loading train:  10%|▉         | 28/285 [00:47<07:42,  1.80s/it]Loading train:  10%|█         | 29/285 [00:48<06:46,  1.59s/it]Loading train:  11%|█         | 30/285 [00:50<06:29,  1.53s/it]Loading train:  11%|█         | 31/285 [00:51<05:53,  1.39s/it]Loading train:  11%|█         | 32/285 [00:52<05:25,  1.29s/it]Loading train:  12%|█▏        | 33/285 [00:53<05:01,  1.20s/it]Loading train:  12%|█▏        | 34/285 [00:54<05:13,  1.25s/it]Loading train:  12%|█▏        | 35/285 [00:55<05:16,  1.27s/it]Loading train:  13%|█▎        | 36/285 [00:57<05:11,  1.25s/it]Loading train:  13%|█▎        | 37/285 [00:58<05:00,  1.21s/it]Loading train:  13%|█▎        | 38/285 [00:59<04:56,  1.20s/it]Loading train:  14%|█▎        | 39/285 [01:00<04:42,  1.15s/it]Loading train:  14%|█▍        | 40/285 [01:01<04:27,  1.09s/it]Loading train:  14%|█▍        | 41/285 [01:02<04:18,  1.06s/it]Loading train:  15%|█▍        | 42/285 [01:03<04:09,  1.03s/it]Loading train:  15%|█▌        | 43/285 [01:04<04:00,  1.01it/s]Loading train:  15%|█▌        | 44/285 [01:05<03:57,  1.01it/s]Loading train:  16%|█▌        | 45/285 [01:06<04:00,  1.00s/it]Loading train:  16%|█▌        | 46/285 [01:07<03:54,  1.02it/s]Loading train:  16%|█▋        | 47/285 [01:08<03:56,  1.01it/s]Loading train:  17%|█▋        | 48/285 [01:08<03:42,  1.06it/s]Loading train:  17%|█▋        | 49/285 [01:09<03:47,  1.04it/s]Loading train:  18%|█▊        | 50/285 [01:10<03:41,  1.06it/s]Loading train:  18%|█▊        | 51/285 [01:11<03:43,  1.05it/s]Loading train:  18%|█▊        | 52/285 [01:12<03:32,  1.10it/s]Loading train:  19%|█▊        | 53/285 [01:13<03:45,  1.03it/s]Loading train:  19%|█▉        | 54/285 [01:14<03:42,  1.04it/s]Loading train:  19%|█▉        | 55/285 [01:15<03:53,  1.02s/it]Loading train:  20%|█▉        | 56/285 [01:16<03:52,  1.02s/it]Loading train:  20%|██        | 57/285 [01:17<03:51,  1.01s/it]Loading train:  20%|██        | 58/285 [01:18<03:39,  1.03it/s]Loading train:  21%|██        | 59/285 [01:19<03:42,  1.01it/s]Loading train:  21%|██        | 60/285 [01:20<03:45,  1.00s/it]Loading train:  21%|██▏       | 61/285 [01:21<03:43,  1.00it/s]Loading train:  22%|██▏       | 62/285 [01:22<03:50,  1.03s/it]Loading train:  22%|██▏       | 63/285 [01:23<03:46,  1.02s/it]Loading train:  22%|██▏       | 64/285 [01:25<04:16,  1.16s/it]Loading train:  23%|██▎       | 65/285 [01:26<04:35,  1.25s/it]Loading train:  23%|██▎       | 66/285 [01:28<04:35,  1.26s/it]Loading train:  24%|██▎       | 67/285 [01:29<04:26,  1.22s/it]Loading train:  24%|██▍       | 68/285 [01:30<04:20,  1.20s/it]Loading train:  24%|██▍       | 69/285 [01:31<04:06,  1.14s/it]Loading train:  25%|██▍       | 70/285 [01:32<04:14,  1.18s/it]Loading train:  25%|██▍       | 71/285 [01:33<04:18,  1.21s/it]Loading train:  25%|██▌       | 72/285 [01:35<04:07,  1.16s/it]Loading train:  26%|██▌       | 73/285 [01:36<04:03,  1.15s/it]Loading train:  26%|██▌       | 74/285 [01:37<04:04,  1.16s/it]Loading train:  26%|██▋       | 75/285 [01:38<04:05,  1.17s/it]Loading train:  27%|██▋       | 76/285 [01:39<04:07,  1.19s/it]Loading train:  27%|██▋       | 77/285 [01:40<03:46,  1.09s/it]Loading train:  27%|██▋       | 78/285 [01:41<03:32,  1.03s/it]Loading train:  28%|██▊       | 79/285 [01:42<03:36,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:43<03:46,  1.10s/it]Loading train:  28%|██▊       | 81/285 [01:45<03:55,  1.16s/it]Loading train:  29%|██▉       | 82/285 [01:46<04:08,  1.23s/it]Loading train:  29%|██▉       | 83/285 [01:47<03:58,  1.18s/it]Loading train:  29%|██▉       | 84/285 [01:48<04:00,  1.20s/it]Loading train:  30%|██▉       | 85/285 [01:50<04:01,  1.21s/it]Loading train:  30%|███       | 86/285 [01:51<04:16,  1.29s/it]Loading train:  31%|███       | 87/285 [01:52<04:14,  1.29s/it]Loading train:  31%|███       | 88/285 [01:54<04:13,  1.29s/it]Loading train:  31%|███       | 89/285 [01:55<04:09,  1.27s/it]Loading train:  32%|███▏      | 90/285 [01:56<03:59,  1.23s/it]Loading train:  32%|███▏      | 91/285 [01:57<03:51,  1.19s/it]Loading train:  32%|███▏      | 92/285 [01:58<04:02,  1.26s/it]Loading train:  33%|███▎      | 93/285 [02:00<03:57,  1.24s/it]Loading train:  33%|███▎      | 94/285 [02:01<03:53,  1.22s/it]Loading train:  33%|███▎      | 95/285 [02:02<03:45,  1.18s/it]Loading train:  34%|███▎      | 96/285 [02:03<03:56,  1.25s/it]Loading train:  34%|███▍      | 97/285 [02:05<04:08,  1.32s/it]Loading train:  34%|███▍      | 98/285 [02:06<04:12,  1.35s/it]Loading train:  35%|███▍      | 99/285 [02:08<04:09,  1.34s/it]Loading train:  35%|███▌      | 100/285 [02:09<04:08,  1.34s/it]Loading train:  35%|███▌      | 101/285 [02:10<03:51,  1.26s/it]Loading train:  36%|███▌      | 102/285 [02:11<04:00,  1.32s/it]Loading train:  36%|███▌      | 103/285 [02:13<04:10,  1.38s/it]Loading train:  36%|███▋      | 104/285 [02:14<03:54,  1.29s/it]Loading train:  37%|███▋      | 105/285 [02:15<03:44,  1.25s/it]Loading train:  37%|███▋      | 106/285 [02:16<03:40,  1.23s/it]Loading train:  38%|███▊      | 107/285 [02:18<03:44,  1.26s/it]Loading train:  38%|███▊      | 108/285 [02:19<03:44,  1.27s/it]Loading train:  38%|███▊      | 109/285 [02:20<03:46,  1.29s/it]Loading train:  39%|███▊      | 110/285 [02:21<03:34,  1.22s/it]Loading train:  39%|███▉      | 111/285 [02:23<03:39,  1.26s/it]Loading train:  39%|███▉      | 112/285 [02:24<03:29,  1.21s/it]Loading train:  40%|███▉      | 113/285 [02:25<03:24,  1.19s/it]Loading train:  40%|████      | 114/285 [02:26<03:23,  1.19s/it]Loading train:  40%|████      | 115/285 [02:27<03:24,  1.21s/it]Loading train:  41%|████      | 116/285 [02:29<03:20,  1.19s/it]Loading train:  41%|████      | 117/285 [02:30<03:24,  1.22s/it]Loading train:  41%|████▏     | 118/285 [02:31<03:12,  1.16s/it]Loading train:  42%|████▏     | 119/285 [02:32<03:15,  1.18s/it]Loading train:  42%|████▏     | 120/285 [02:33<03:19,  1.21s/it]Loading train:  42%|████▏     | 121/285 [02:35<03:32,  1.30s/it]Loading train:  43%|████▎     | 122/285 [02:36<03:31,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:37<03:29,  1.29s/it]Loading train:  44%|████▎     | 124/285 [02:39<03:18,  1.23s/it]Loading train:  44%|████▍     | 125/285 [02:40<03:10,  1.19s/it]Loading train:  44%|████▍     | 126/285 [02:41<03:12,  1.21s/it]Loading train:  45%|████▍     | 127/285 [02:42<03:07,  1.19s/it]Loading train:  45%|████▍     | 128/285 [02:43<03:03,  1.17s/it]Loading train:  45%|████▌     | 129/285 [02:44<03:04,  1.19s/it]Loading train:  46%|████▌     | 130/285 [02:45<02:58,  1.15s/it]Loading train:  46%|████▌     | 131/285 [02:46<02:45,  1.08s/it]Loading train:  46%|████▋     | 132/285 [02:47<02:41,  1.06s/it]Loading train:  47%|████▋     | 133/285 [02:48<02:35,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:50<02:48,  1.12s/it]Loading train:  47%|████▋     | 135/285 [02:51<02:49,  1.13s/it]Loading train:  48%|████▊     | 136/285 [02:52<03:03,  1.23s/it]Loading train:  48%|████▊     | 137/285 [02:53<02:51,  1.16s/it]Loading train:  48%|████▊     | 138/285 [02:55<02:58,  1.22s/it]Loading train:  49%|████▉     | 139/285 [02:56<03:01,  1.24s/it]Loading train:  49%|████▉     | 140/285 [02:57<02:59,  1.24s/it]Loading train:  49%|████▉     | 141/285 [02:59<03:02,  1.27s/it]Loading train:  50%|████▉     | 142/285 [03:00<02:55,  1.23s/it]Loading train:  50%|█████     | 143/285 [03:01<02:46,  1.17s/it]Loading train:  51%|█████     | 144/285 [03:02<02:48,  1.19s/it]Loading train:  51%|█████     | 145/285 [03:03<02:42,  1.16s/it]Loading train:  51%|█████     | 146/285 [03:04<02:38,  1.14s/it]Loading train:  52%|█████▏    | 147/285 [03:05<02:35,  1.13s/it]Loading train:  52%|█████▏    | 148/285 [03:06<02:35,  1.14s/it]Loading train:  52%|█████▏    | 149/285 [03:07<02:32,  1.12s/it]Loading train:  53%|█████▎    | 150/285 [03:09<02:34,  1.14s/it]Loading train:  53%|█████▎    | 151/285 [03:10<02:32,  1.14s/it]Loading train:  53%|█████▎    | 152/285 [03:11<02:34,  1.16s/it]Loading train:  54%|█████▎    | 153/285 [03:12<02:33,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [03:13<02:18,  1.06s/it]Loading train:  54%|█████▍    | 155/285 [03:14<02:11,  1.01s/it]Loading train:  55%|█████▍    | 156/285 [03:15<02:10,  1.01s/it]Loading train:  55%|█████▌    | 157/285 [03:16<02:05,  1.02it/s]Loading train:  55%|█████▌    | 158/285 [03:17<02:12,  1.04s/it]Loading train:  56%|█████▌    | 159/285 [03:18<02:12,  1.05s/it]Loading train:  56%|█████▌    | 160/285 [03:19<02:06,  1.01s/it]Loading train:  56%|█████▋    | 161/285 [03:20<02:05,  1.02s/it]Loading train:  57%|█████▋    | 162/285 [03:21<02:06,  1.03s/it]Loading train:  57%|█████▋    | 163/285 [03:22<02:03,  1.02s/it]Loading train:  58%|█████▊    | 164/285 [03:23<02:03,  1.02s/it]Loading train:  58%|█████▊    | 165/285 [03:24<02:00,  1.00s/it]Loading train:  58%|█████▊    | 166/285 [03:25<02:05,  1.05s/it]Loading train:  59%|█████▊    | 167/285 [03:26<02:06,  1.07s/it]Loading train:  59%|█████▉    | 168/285 [03:27<02:06,  1.08s/it]Loading train:  59%|█████▉    | 169/285 [03:29<02:12,  1.14s/it]Loading train:  60%|█████▉    | 170/285 [03:30<02:13,  1.16s/it]Loading train:  60%|██████    | 171/285 [03:31<02:07,  1.11s/it]Loading train:  60%|██████    | 172/285 [03:32<01:55,  1.03s/it]Loading train:  61%|██████    | 173/285 [03:33<02:00,  1.08s/it]Loading train:  61%|██████    | 174/285 [03:34<01:53,  1.02s/it]Loading train:  61%|██████▏   | 175/285 [03:35<01:52,  1.02s/it]Loading train:  62%|██████▏   | 176/285 [03:36<01:52,  1.04s/it]Loading train:  62%|██████▏   | 177/285 [03:37<01:54,  1.06s/it]Loading train:  62%|██████▏   | 178/285 [03:38<01:59,  1.11s/it]Loading train:  63%|██████▎   | 179/285 [03:39<01:53,  1.07s/it]Loading train:  63%|██████▎   | 180/285 [03:40<01:50,  1.05s/it]Loading train:  64%|██████▎   | 181/285 [03:41<01:46,  1.02s/it]Loading train:  64%|██████▍   | 182/285 [03:42<01:43,  1.01s/it]Loading train:  64%|██████▍   | 183/285 [03:43<01:44,  1.03s/it]Loading train:  65%|██████▍   | 184/285 [03:44<01:46,  1.06s/it]Loading train:  65%|██████▍   | 185/285 [03:46<01:48,  1.08s/it]Loading train:  65%|██████▌   | 186/285 [03:47<01:46,  1.08s/it]Loading train:  66%|██████▌   | 187/285 [03:48<01:45,  1.08s/it]Loading train:  66%|██████▌   | 188/285 [03:49<01:43,  1.07s/it]Loading train:  66%|██████▋   | 189/285 [03:50<01:40,  1.05s/it]Loading train:  67%|██████▋   | 190/285 [03:51<01:43,  1.09s/it]Loading train:  67%|██████▋   | 191/285 [03:52<01:39,  1.06s/it]Loading train:  67%|██████▋   | 192/285 [03:53<01:38,  1.06s/it]Loading train:  68%|██████▊   | 193/285 [03:54<01:33,  1.01s/it]Loading train:  68%|██████▊   | 194/285 [03:55<01:30,  1.01it/s]Loading train:  68%|██████▊   | 195/285 [03:56<01:27,  1.03it/s]Loading train:  69%|██████▉   | 196/285 [03:57<01:32,  1.04s/it]Loading train:  69%|██████▉   | 197/285 [03:58<01:37,  1.10s/it]Loading train:  69%|██████▉   | 198/285 [03:59<01:36,  1.11s/it]Loading train:  70%|██████▉   | 199/285 [04:00<01:32,  1.08s/it]Loading train:  70%|███████   | 200/285 [04:01<01:34,  1.11s/it]Loading train:  71%|███████   | 201/285 [04:02<01:30,  1.07s/it]Loading train:  71%|███████   | 202/285 [04:04<01:34,  1.14s/it]Loading train:  71%|███████   | 203/285 [04:05<01:28,  1.08s/it]Loading train:  72%|███████▏  | 204/285 [04:06<01:26,  1.06s/it]Loading train:  72%|███████▏  | 205/285 [04:07<01:20,  1.01s/it]Loading train:  72%|███████▏  | 206/285 [04:08<01:18,  1.00it/s]Loading train:  73%|███████▎  | 207/285 [04:08<01:14,  1.05it/s]Loading train:  73%|███████▎  | 208/285 [04:09<01:13,  1.05it/s]Loading train:  73%|███████▎  | 209/285 [04:10<01:10,  1.07it/s]Loading train:  74%|███████▎  | 210/285 [04:11<01:08,  1.09it/s]Loading train:  74%|███████▍  | 211/285 [04:12<01:07,  1.10it/s]Loading train:  74%|███████▍  | 212/285 [04:13<01:08,  1.07it/s]Loading train:  75%|███████▍  | 213/285 [04:14<01:04,  1.11it/s]Loading train:  75%|███████▌  | 214/285 [04:15<01:03,  1.12it/s]Loading train:  75%|███████▌  | 215/285 [04:16<01:00,  1.15it/s]Loading train:  76%|███████▌  | 216/285 [04:16<01:00,  1.14it/s]Loading train:  76%|███████▌  | 217/285 [04:17<00:59,  1.15it/s]Loading train:  76%|███████▋  | 218/285 [04:18<00:58,  1.14it/s]Loading train:  77%|███████▋  | 219/285 [04:19<00:56,  1.16it/s]Loading train:  77%|███████▋  | 220/285 [04:20<00:54,  1.19it/s]Loading train:  78%|███████▊  | 221/285 [04:21<00:54,  1.18it/s]Loading train:  78%|███████▊  | 222/285 [04:21<00:52,  1.19it/s]Loading train:  78%|███████▊  | 223/285 [04:22<00:54,  1.14it/s]Loading train:  79%|███████▊  | 224/285 [04:23<00:53,  1.14it/s]Loading train:  79%|███████▉  | 225/285 [04:24<00:53,  1.12it/s]Loading train:  79%|███████▉  | 226/285 [04:25<00:52,  1.12it/s]Loading train:  80%|███████▉  | 227/285 [04:26<00:51,  1.13it/s]Loading train:  80%|████████  | 228/285 [04:27<00:50,  1.14it/s]Loading train:  80%|████████  | 229/285 [04:28<00:48,  1.15it/s]Loading train:  81%|████████  | 230/285 [04:28<00:46,  1.18it/s]Loading train:  81%|████████  | 231/285 [04:29<00:44,  1.22it/s]Loading train:  81%|████████▏ | 232/285 [04:30<00:46,  1.15it/s]Loading train:  82%|████████▏ | 233/285 [04:31<00:47,  1.09it/s]Loading train:  82%|████████▏ | 234/285 [04:32<00:47,  1.07it/s]Loading train:  82%|████████▏ | 235/285 [04:33<00:50,  1.01s/it]Loading train:  83%|████████▎ | 236/285 [04:35<00:50,  1.04s/it]Loading train:  83%|████████▎ | 237/285 [04:36<00:52,  1.09s/it]Loading train:  84%|████████▎ | 238/285 [04:37<00:53,  1.14s/it]Loading train:  84%|████████▍ | 239/285 [04:38<00:51,  1.13s/it]Loading train:  84%|████████▍ | 240/285 [04:39<00:52,  1.16s/it]Loading train:  85%|████████▍ | 241/285 [04:40<00:49,  1.12s/it]Loading train:  85%|████████▍ | 242/285 [04:41<00:46,  1.07s/it]Loading train:  85%|████████▌ | 243/285 [04:42<00:46,  1.10s/it]Loading train:  86%|████████▌ | 244/285 [04:44<00:45,  1.12s/it]Loading train:  86%|████████▌ | 245/285 [04:45<00:43,  1.09s/it]Loading train:  86%|████████▋ | 246/285 [04:46<00:44,  1.15s/it]Loading train:  87%|████████▋ | 247/285 [04:47<00:44,  1.16s/it]Loading train:  87%|████████▋ | 248/285 [04:48<00:43,  1.17s/it]Loading train:  87%|████████▋ | 249/285 [04:50<00:42,  1.19s/it]Loading train:  88%|████████▊ | 250/285 [04:51<00:39,  1.12s/it]Loading train:  88%|████████▊ | 251/285 [04:51<00:35,  1.04s/it]Loading train:  88%|████████▊ | 252/285 [04:52<00:33,  1.01s/it]Loading train:  89%|████████▉ | 253/285 [04:53<00:32,  1.01s/it]Loading train:  89%|████████▉ | 254/285 [04:55<00:33,  1.07s/it]Loading train:  89%|████████▉ | 255/285 [04:56<00:34,  1.14s/it]Loading train:  90%|████████▉ | 256/285 [04:57<00:33,  1.15s/it]Loading train:  90%|█████████ | 257/285 [04:58<00:30,  1.09s/it]Loading train:  91%|█████████ | 258/285 [04:59<00:29,  1.08s/it]Loading train:  91%|█████████ | 259/285 [05:00<00:28,  1.11s/it]Loading train:  91%|█████████ | 260/285 [05:01<00:26,  1.08s/it]Loading train:  92%|█████████▏| 261/285 [05:02<00:26,  1.08s/it]Loading train:  92%|█████████▏| 262/285 [05:03<00:24,  1.08s/it]Loading train:  92%|█████████▏| 263/285 [05:04<00:22,  1.04s/it]Loading train:  93%|█████████▎| 264/285 [05:05<00:21,  1.04s/it]Loading train:  93%|█████████▎| 265/285 [05:06<00:20,  1.03s/it]Loading train:  93%|█████████▎| 266/285 [05:07<00:19,  1.01s/it]Loading train:  94%|█████████▎| 267/285 [05:08<00:17,  1.04it/s]Loading train:  94%|█████████▍| 268/285 [05:10<00:18,  1.10s/it]Loading train:  94%|█████████▍| 269/285 [05:11<00:17,  1.11s/it]Loading train:  95%|█████████▍| 270/285 [05:12<00:17,  1.14s/it]Loading train:  95%|█████████▌| 271/285 [05:13<00:15,  1.13s/it]Loading train:  95%|█████████▌| 272/285 [05:14<00:14,  1.13s/it]Loading train:  96%|█████████▌| 273/285 [05:15<00:13,  1.14s/it]Loading train:  96%|█████████▌| 274/285 [05:17<00:12,  1.15s/it]Loading train:  96%|█████████▋| 275/285 [05:18<00:11,  1.20s/it]Loading train:  97%|█████████▋| 276/285 [05:19<00:11,  1.23s/it]Loading train:  97%|█████████▋| 277/285 [05:20<00:09,  1.21s/it]Loading train:  98%|█████████▊| 278/285 [05:21<00:08,  1.18s/it]Loading train:  98%|█████████▊| 279/285 [05:23<00:07,  1.18s/it]Loading train:  98%|█████████▊| 280/285 [05:24<00:05,  1.18s/it]Loading train:  99%|█████████▊| 281/285 [05:25<00:04,  1.16s/it]Loading train:  99%|█████████▉| 282/285 [05:26<00:03,  1.20s/it]Loading train:  99%|█████████▉| 283/285 [05:27<00:02,  1.23s/it]Loading train: 100%|█████████▉| 284/285 [05:29<00:01,  1.37s/it]Loading train: 100%|██████████| 285/285 [05:30<00:00,  1.34s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:01, 168.37it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:01, 160.33it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:01, 138.43it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:02, 101.86it/s]concatenating: train:  23%|██▎       | 65/285 [00:00<00:02, 107.75it/s]concatenating: train:  27%|██▋       | 78/285 [00:00<00:01, 112.40it/s]concatenating: train:  32%|███▏      | 92/285 [00:00<00:01, 118.26it/s]concatenating: train:  37%|███▋      | 105/285 [00:00<00:01, 120.18it/s]concatenating: train:  41%|████▏     | 118/285 [00:00<00:01, 121.59it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:01, 122.60it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 123.30it/s]concatenating: train:  55%|█████▌    | 157/285 [00:01<00:01, 123.80it/s]concatenating: train:  60%|█████▉    | 170/285 [00:01<00:00, 124.18it/s]concatenating: train:  64%|██████▍   | 183/285 [00:01<00:00, 124.45it/s]concatenating: train:  69%|██████▉   | 196/285 [00:01<00:00, 124.59it/s]concatenating: train:  73%|███████▎  | 209/285 [00:01<00:00, 124.71it/s]concatenating: train:  78%|███████▊  | 222/285 [00:01<00:00, 124.80it/s]concatenating: train:  82%|████████▏ | 235/285 [00:01<00:00, 124.86it/s]concatenating: train:  87%|████████▋ | 248/285 [00:02<00:00, 123.49it/s]concatenating: train:  92%|█████████▏| 261/285 [00:02<00:00, 113.55it/s]concatenating: train:  99%|█████████▊| 281/285 [00:02<00:00, 130.47it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 125.59it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.43s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 117.94it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 80)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 80)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 160)  115360      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 160)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 80)   51280       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 160)  0           conv2d_transpose_1[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 80)   115280      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 80)   0           activation_8[0][0]               
__________________________________________________________________________________________________2019-06-30 22:47:53.111998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 22:47:53.112095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 22:47:53.112110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 22:47:53.112118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 22:47:53.112531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 40)   12840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 80, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 40)   28840       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 40)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   533         dropout_5[0][0]                  
==================================================================================================
Total params: 731,413
Trainable params: 729,813
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [2.22914927e+01 1.09758073e+01 2.57605072e+01 3.20169489e+00
 9.30612289e+00 2.42668560e+00 2.90680004e+01 3.86865725e+01
 2.95464687e+01 4.55026025e+00 1.01029583e+02 6.65891339e+01
 8.79274619e-02]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 2002.2385 - acc: 0.8897 - mDice: 0.3167 - val_loss: 1789.0501 - val_acc: 0.9307 - val_mDice: 0.3939

Epoch 00001: val_mDice improved from -inf to 0.39392, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 995.5824 - acc: 0.9207 - mDice: 0.5321 - val_loss: 1853.2122 - val_acc: 0.9372 - val_mDice: 0.4295

Epoch 00002: val_mDice improved from 0.39392 to 0.42949, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 837.9959 - acc: 0.9279 - mDice: 0.5954 - val_loss: 1894.9101 - val_acc: 0.9415 - val_mDice: 0.4548

Epoch 00003: val_mDice improved from 0.42949 to 0.45475, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 15s - loss: 748.6202 - acc: 0.9325 - mDice: 0.6349 - val_loss: 2028.5938 - val_acc: 0.9422 - val_mDice: 0.4660

Epoch 00004: val_mDice improved from 0.45475 to 0.46600, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 697.5950 - acc: 0.9350 - mDice: 0.6583 - val_loss: 2069.2498 - val_acc: 0.9429 - val_mDice: 0.4598

Epoch 00005: val_mDice did not improve from 0.46600
Epoch 6/300
 - 15s - loss: 656.5223 - acc: 0.9370 - mDice: 0.6776 - val_loss: 2039.4551 - val_acc: 0.9446 - val_mDice: 0.4792

Epoch 00006: val_mDice improved from 0.46600 to 0.47923, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 621.2353 - acc: 0.9386 - mDice: 0.6938 - val_loss: 2240.3837 - val_acc: 0.9435 - val_mDice: 0.4629

Epoch 00007: val_mDice did not improve from 0.47923
Epoch 8/300
 - 14s - loss: 598.8773 - acc: 0.9397 - mDice: 0.7048 - val_loss: 2079.0222 - val_acc: 0.9443 - val_mDice: 0.4814

Epoch 00008: val_mDice improved from 0.47923 to 0.48136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 578.7317 - acc: 0.9408 - mDice: 0.7144 - val_loss: 2257.0590 - val_acc: 0.9441 - val_mDice: 0.4620

Epoch 00009: val_mDice did not improve from 0.48136
Epoch 10/300
 - 14s - loss: 561.0278 - acc: 0.9415 - mDice: 0.7229 - val_loss: 2080.0548 - val_acc: 0.9448 - val_mDice: 0.4850

Epoch 00010: val_mDice improved from 0.48136 to 0.48504, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 544.1756 - acc: 0.9422 - mDice: 0.7308 - val_loss: 2070.7465 - val_acc: 0.9448 - val_mDice: 0.4921

Epoch 00011: val_mDice improved from 0.48504 to 0.49214, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 14s - loss: 529.7193 - acc: 0.9427 - mDice: 0.7379 - val_loss: 2249.2442 - val_acc: 0.9433 - val_mDice: 0.4774

Epoch 00012: val_mDice did not improve from 0.49214
Epoch 13/300
 - 14s - loss: 517.8249 - acc: 0.9435 - mDice: 0.7434 - val_loss: 2130.1569 - val_acc: 0.9448 - val_mDice: 0.4919

Epoch 00013: val_mDice did not improve from 0.49214
Epoch 14/300
 - 14s - loss: 503.9794 - acc: 0.9438 - mDice: 0.7502 - val_loss: 2189.9393 - val_acc: 0.9452 - val_mDice: 0.4840

Epoch 00014: val_mDice did not improve from 0.49214
Epoch 15/300
 - 14s - loss: 495.0351 - acc: 0.9444 - mDice: 0.7544 - val_loss: 2148.0569 - val_acc: 0.9448 - val_mDice: 0.4986

Epoch 00015: val_mDice improved from 0.49214 to 0.49860, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 15s - loss: 488.1037 - acc: 0.9447 - mDice: 0.7581 - val_loss: 2371.4929 - val_acc: 0.9446 - val_mDice: 0.4869

Epoch 00016: val_mDice did not improve from 0.49860
Epoch 17/300
 - 15s - loss: 478.9742 - acc: 0.9452 - mDice: 0.7619 - val_loss: 2280.5158 - val_acc: 0.9450 - val_mDice: 0.4867

Epoch 00017: val_mDice did not improve from 0.49860
Epoch 18/300
 - 14s - loss: 473.2727 - acc: 0.9458 - mDice: 0.7651 - val_loss: 2341.7794 - val_acc: 0.9452 - val_mDice: 0.4870

Epoch 00018: val_mDice did not improve from 0.49860
Epoch 19/300
 - 14s - loss: 464.2226 - acc: 0.9459 - mDice: 0.7696 - val_loss: 2268.8159 - val_acc: 0.9455 - val_mDice: 0.4920

Epoch 00019: val_mDice did not improve from 0.49860
Epoch 20/300
 - 14s - loss: 457.1008 - acc: 0.9468 - mDice: 0.7727 - val_loss: 2296.9565 - val_acc: 0.9458 - val_mDice: 0.4954

Epoch 00020: val_mDice did not improve from 0.49860
Epoch 21/300
 - 14s - loss: 452.1102 - acc: 0.9468 - mDice: 0.7754 - val_loss: 2498.1285 - val_acc: 0.9447 - val_mDice: 0.4785

Epoch 00021: val_mDice did not improve from 0.49860
Epoch 22/300
 - 15s - loss: 443.1068 - acc: 0.9472 - mDice: 0.7795 - val_loss: 2289.8561 - val_acc: 0.9461 - val_mDice: 0.5026

Epoch 00022: val_mDice improved from 0.49860 to 0.50260, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL3_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 14s - loss: 441.6256 - acc: 0.9473 - mDice: 0.7806 - val_loss: 2287.0121 - val_acc: 0.9454 - val_mDice: 0.4930

Epoch 00023: val_mDice did not improve from 0.50260
Epoch 24/300
 - 14s - loss: 435.8355 - acc: 0.9477 - mDice: 0.7833 - val_loss: 2477.2111 - val_acc: 0.9446 - val_mDice: 0.4837

Epoch 00024: val_mDice did not improve from 0.50260
Epoch 25/300
 - 15s - loss: 430.8501 - acc: 0.9476 - mDice: 0.7857 - val_loss: 2312.7131 - val_acc: 0.9470 - val_mDice: 0.4978

Epoch 00025: val_mDice did not improve from 0.50260
Epoch 26/300
 - 15s - loss: 426.1805 - acc: 0.9476 - mDice: 0.7877 - val_loss: 2341.6159 - val_acc: 0.9462 - val_mDice: 0.5005

Epoch 00026: val_mDice did not improve from 0.50260
Epoch 27/300
 - 14s - loss: 421.4387 - acc: 0.9482 - mDice: 0.7905 - val_loss: 2400.1997 - val_acc: 0.9450 - val_mDice: 0.4978

Epoch 00027: val_mDice did not improve from 0.50260
Epoch 28/300
 - 14s - loss: 419.1753 - acc: 0.9486 - mDice: 0.7916 - val_loss: 2360.9623 - val_acc: 0.9461 - val_mDice: 0.4934

Epoch 00028: val_mDice did not improve from 0.50260
Epoch 29/300
 - 14s - loss: 412.6355 - acc: 0.9491 - mDice: 0.7946 - val_loss: 2470.9397 - val_acc: 0.9462 - val_mDice: 0.4884

Epoch 00029: val_mDice did not improve from 0.50260
Epoch 30/300
 - 15s - loss: 411.2911 - acc: 0.9493 - mDice: 0.7956 - val_loss: 2553.4974 - val_acc: 0.9454 - val_mDice: 0.4826

Epoch 00030: val_mDice did not improve from 0.50260
Epoch 31/300
 - 15s - loss: 404.3584 - acc: 0.9494 - mDice: 0.7986 - val_loss: 2322.5602 - val_acc: 0.9459 - val_mDice: 0.5006

Epoch 00031: val_mDice did not improve from 0.50260
Epoch 32/300
 - 14s - loss: 401.2696 - acc: 0.9496 - mDice: 0.8000 - val_loss: 2513.5513 - val_acc: 0.9454 - val_mDice: 0.4901

Epoch 00032: val_mDice did not improve from 0.50260
Epoch 33/300
 - 15s - loss: 399.5170 - acc: 0.9498 - mDice: 0.8011 - val_loss: 2453.9481 - val_acc: 0.9457 - val_mDice: 0.4995

Epoch 00033: val_mDice did not improve from 0.50260
Epoch 34/300
 - 14s - loss: 395.5487 - acc: 0.9500 - mDice: 0.8029 - val_loss: 2458.4501 - val_acc: 0.9457 - val_mDice: 0.4876

Epoch 00034: val_mDice did not improve from 0.50260
Epoch 35/300
 - 15s - loss: 394.2405 - acc: 0.9501 - mDice: 0.8038 - val_loss: 2625.8200 - val_acc: 0.9465 - val_mDice: 0.4807

Epoch 00035: val_mDice did not improve from 0.50260
Epoch 36/300
 - 15s - loss: 390.0093 - acc: 0.9505 - mDice: 0.8057 - val_loss: 2611.6849 - val_acc: 0.9455 - val_mDice: 0.4895

Epoch 00036: val_mDice did not improve from 0.50260
Epoch 37/300
 - 15s - loss: 385.2399 - acc: 0.9509 - mDice: 0.8084 - val_loss: 2495.5282 - val_acc: 0.9461 - val_mDice: 0.4944

Epoch 00037: val_mDice did not improve from 0.50260
Epoch 38/300
 - 14s - loss: 383.4262 - acc: 0.9509 - mDice: 0.8094 - val_loss: 2684.0460 - val_acc: 0.9448 - val_mDice: 0.4809

Epoch 00038: val_mDice did not improve from 0.50260
Epoch 39/300
 - 15s - loss: 380.7912 - acc: 0.9514 - mDice: 0.8105 - val_loss: 2433.7064 - val_acc: 0.9456 - val_mDice: 0.5012

Epoch 00039: val_mDice did not improve from 0.50260
Epoch 40/300
 - 14s - loss: 377.3254 - acc: 0.9513 - mDice: 0.8121 - val_loss: 2621.2448 - val_acc: 0.9464 - val_mDice: 0.4908

Epoch 00040: val_mDice did not improve from 0.50260
Epoch 41/300
 - 15s - loss: 375.7493 - acc: 0.9518 - mDice: 0.8129 - val_loss: 2501.9279 - val_acc: 0.9460 - val_mDice: 0.5017

Epoch 00041: val_mDice did not improve from 0.50260
Epoch 42/300
 - 14s - loss: 372.4354 - acc: 0.9516 - mDice: 0.8145 - val_loss: 2731.5243 - val_acc: 0.9461 - val_mDice: 0.4855

Epoch 00042: val_mDice did not improve from 0.50260
Epoch 43/300
 - 15s - loss: 371.0700 - acc: 0.9519 - mDice: 0.8149 - val_loss: 2791.1232 - val_acc: 0.9454 - val_mDice: 0.4740

Epoch 00043: val_mDice did not improve from 0.50260
Epoch 44/300
 - 15s - loss: 369.8801 - acc: 0.9518 - mDice: 0.8160 - val_loss: 2596.5794 - val_acc: 0.9460 - val_mDice: 0.4922

Epoch 00044: val_mDice did not improve from 0.50260
Epoch 45/300
 - 15s - loss: 366.2368 - acc: 0.9523 - mDice: 0.8177 - val_loss: 2649.4165 - val_acc: 0.9464 - val_mDice: 0.4864

Epoch 00045: val_mDice did not improve from 0.50260
Epoch 46/300
 - 14s - loss: 362.9946 - acc: 0.9525 - mDice: 0.8191 - val_loss: 2661.5535 - val_acc: 0.9457 - val_mDice: 0.4890

Epoch 00046: val_mDice did not improve from 0.50260
Epoch 47/300
 - 14s - loss: 362.4225 - acc: 0.9526 - mDice: 0.8195 - val_loss: 2714.7123 - val_acc: 0.9452 - val_mDice: 0.4855

Epoch 00047: val_mDice did not improve from 0.50260
Epoch 48/300
 - 15s - loss: 358.8770 - acc: 0.9529 - mDice: 0.8212 - val_loss: 2773.7786 - val_acc: 0.9459 - val_mDice: 0.4795

Epoch 00048: val_mDice did not improve from 0.50260
Epoch 49/300
 - 14s - loss: 359.0076 - acc: 0.9530 - mDice: 0.8212 - val_loss: 2743.5638 - val_acc: 0.9458 - val_mDice: 0.4903

Epoch 00049: val_mDice did not improve from 0.50260
Epoch 50/300
 - 14s - loss: 356.5124 - acc: 0.9530 - mDice: 0.8221 - val_loss: 2597.3297 - val_acc: 0.9465 - val_mDice: 0.4953

Epoch 00050: val_mDice did not improve from 0.50260
Epoch 51/300
 - 15s - loss: 355.7263 - acc: 0.9527 - mDice: 0.8230 - val_loss: 2708.2008 - val_acc: 0.9463 - val_mDice: 0.4929

Epoch 00051: val_mDice did not improve from 0.50260
Epoch 52/300
 - 14s - loss: 353.1406 - acc: 0.9530 - mDice: 0.8241 - val_loss: 2712.5547 - val_acc: 0.9471 - val_mDice: 0.4899

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.58s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.29s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.08s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:23,  1.56s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:54,  1.68s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:56,  1.69s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:39,  1.85s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:26,  1.81s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:40,  1.86s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:29,  2.05s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:32,  2.07s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:36,  2.09s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<09:38,  2.11s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<10:05,  2.21s/it]predicting train subjects:   4%|▍         | 12/285 [00:25<11:22,  2.50s/it]predicting train subjects:   5%|▍         | 13/285 [00:28<11:23,  2.51s/it]predicting train subjects:   5%|▍         | 14/285 [00:30<11:08,  2.47s/it]predicting train subjects:   5%|▌         | 15/285 [00:32<10:30,  2.33s/it]predicting train subjects:   6%|▌         | 16/285 [00:34<10:00,  2.23s/it]predicting train subjects:   6%|▌         | 17/285 [00:36<09:33,  2.14s/it]predicting train subjects:   6%|▋         | 18/285 [00:38<09:15,  2.08s/it]predicting train subjects:   7%|▋         | 19/285 [00:40<09:00,  2.03s/it]predicting train subjects:   7%|▋         | 20/285 [00:42<09:01,  2.04s/it]predicting train subjects:   7%|▋         | 21/285 [00:44<08:56,  2.03s/it]predicting train subjects:   8%|▊         | 22/285 [00:46<08:48,  2.01s/it]predicting train subjects:   8%|▊         | 23/285 [00:48<08:47,  2.01s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<08:38,  1.99s/it]predicting train subjects:   9%|▉         | 25/285 [00:52<08:33,  1.98s/it]predicting train subjects:   9%|▉         | 26/285 [00:54<08:42,  2.02s/it]predicting train subjects:   9%|▉         | 27/285 [00:56<08:37,  2.00s/it]predicting train subjects:  10%|▉         | 28/285 [00:58<08:19,  1.94s/it]predicting train subjects:  10%|█         | 29/285 [01:00<08:09,  1.91s/it]predicting train subjects:  11%|█         | 30/285 [01:01<08:02,  1.89s/it]predicting train subjects:  11%|█         | 31/285 [01:03<07:44,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [01:05<07:39,  1.82s/it]predicting train subjects:  12%|█▏        | 33/285 [01:07<07:28,  1.78s/it]predicting train subjects:  12%|█▏        | 34/285 [01:08<07:28,  1.79s/it]predicting train subjects:  12%|█▏        | 35/285 [01:10<07:29,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:12<07:32,  1.82s/it]predicting train subjects:  13%|█▎        | 37/285 [01:14<07:35,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:16<07:33,  1.84s/it]predicting train subjects:  14%|█▎        | 39/285 [01:17<07:20,  1.79s/it]predicting train subjects:  14%|█▍        | 40/285 [01:19<07:11,  1.76s/it]predicting train subjects:  14%|█▍        | 41/285 [01:21<07:10,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:23<07:06,  1.76s/it]predicting train subjects:  15%|█▌        | 43/285 [01:24<07:04,  1.75s/it]predicting train subjects:  15%|█▌        | 44/285 [01:26<06:57,  1.73s/it]predicting train subjects:  16%|█▌        | 45/285 [01:28<07:00,  1.75s/it]predicting train subjects:  16%|█▌        | 46/285 [01:30<06:52,  1.73s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<06:43,  1.69s/it]predicting train subjects:  17%|█▋        | 48/285 [01:33<06:37,  1.68s/it]predicting train subjects:  17%|█▋        | 49/285 [01:35<06:42,  1.70s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<06:35,  1.68s/it]predicting train subjects:  18%|█▊        | 51/285 [01:38<06:24,  1.64s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<06:17,  1.62s/it]predicting train subjects:  19%|█▊        | 53/285 [01:41<06:12,  1.60s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<06:01,  1.57s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<06:00,  1.57s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<06:05,  1.59s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:01,  1.59s/it]predicting train subjects:  20%|██        | 58/285 [01:49<05:55,  1.56s/it]predicting train subjects:  21%|██        | 59/285 [01:50<05:53,  1.56s/it]predicting train subjects:  21%|██        | 60/285 [01:52<05:54,  1.58s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:05,  1.63s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:12,  1.67s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:13,  1.68s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:17,  1.71s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:25,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:40,  1.83s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:31,  1.80s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:27,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:15,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:19,  1.77s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:10,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<05:50,  1.65s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<05:47,  1.65s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<05:45,  1.65s/it]predicting train subjects:  27%|██▋       | 76/285 [02:19<05:42,  1.64s/it]predicting train subjects:  27%|██▋       | 77/285 [02:21<05:37,  1.62s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<05:41,  1.65s/it]predicting train subjects:  28%|██▊       | 79/285 [02:24<05:37,  1.64s/it]predicting train subjects:  28%|██▊       | 80/285 [02:26<05:32,  1.62s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<05:37,  1.65s/it]predicting train subjects:  29%|██▉       | 82/285 [02:29<05:30,  1.63s/it]predicting train subjects:  29%|██▉       | 83/285 [02:31<05:33,  1.65s/it]predicting train subjects:  29%|██▉       | 84/285 [02:33<05:37,  1.68s/it]predicting train subjects:  30%|██▉       | 85/285 [02:34<05:47,  1.74s/it]predicting train subjects:  30%|███       | 86/285 [02:36<05:50,  1.76s/it]predicting train subjects:  31%|███       | 87/285 [02:38<05:54,  1.79s/it]predicting train subjects:  31%|███       | 88/285 [02:40<05:59,  1.82s/it]predicting train subjects:  31%|███       | 89/285 [02:42<05:58,  1.83s/it]predicting train subjects:  32%|███▏      | 90/285 [02:44<05:54,  1.82s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<05:56,  1.84s/it]predicting train subjects:  32%|███▏      | 92/285 [02:47<05:55,  1.84s/it]predicting train subjects:  33%|███▎      | 93/285 [02:49<06:01,  1.88s/it]predicting train subjects:  33%|███▎      | 94/285 [02:51<06:00,  1.89s/it]predicting train subjects:  33%|███▎      | 95/285 [02:53<05:57,  1.88s/it]predicting train subjects:  34%|███▎      | 96/285 [02:55<05:51,  1.86s/it]predicting train subjects:  34%|███▍      | 97/285 [02:57<05:45,  1.84s/it]predicting train subjects:  34%|███▍      | 98/285 [02:59<05:48,  1.86s/it]predicting train subjects:  35%|███▍      | 99/285 [03:01<05:46,  1.86s/it]predicting train subjects:  35%|███▌      | 100/285 [03:02<05:42,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [03:04<05:41,  1.86s/it]predicting train subjects:  36%|███▌      | 102/285 [03:06<05:41,  1.87s/it]predicting train subjects:  36%|███▌      | 103/285 [03:08<05:36,  1.85s/it]predicting train subjects:  36%|███▋      | 104/285 [03:10<05:32,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:11<05:23,  1.80s/it]predicting train subjects:  37%|███▋      | 106/285 [03:13<05:25,  1.82s/it]predicting train subjects:  38%|███▊      | 107/285 [03:15<05:25,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:17<05:20,  1.81s/it]predicting train subjects:  38%|███▊      | 109/285 [03:19<05:21,  1.83s/it]predicting train subjects:  39%|███▊      | 110/285 [03:21<05:18,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:23<05:23,  1.86s/it]predicting train subjects:  39%|███▉      | 112/285 [03:24<05:22,  1.86s/it]predicting train subjects:  40%|███▉      | 113/285 [03:26<05:16,  1.84s/it]predicting train subjects:  40%|████      | 114/285 [03:28<05:07,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:30<05:02,  1.78s/it]predicting train subjects:  41%|████      | 116/285 [03:31<05:04,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:33<05:08,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:35<05:07,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [03:37<04:58,  1.80s/it]predicting train subjects:  42%|████▏     | 120/285 [03:39<04:51,  1.77s/it]predicting train subjects:  42%|████▏     | 121/285 [03:40<04:42,  1.72s/it]predicting train subjects:  43%|████▎     | 122/285 [03:42<04:26,  1.64s/it]predicting train subjects:  43%|████▎     | 123/285 [03:43<04:21,  1.61s/it]predicting train subjects:  44%|████▎     | 124/285 [03:45<04:25,  1.65s/it]predicting train subjects:  44%|████▍     | 125/285 [03:47<04:29,  1.69s/it]predicting train subjects:  44%|████▍     | 126/285 [03:49<04:34,  1.73s/it]predicting train subjects:  45%|████▍     | 127/285 [03:50<04:27,  1.69s/it]predicting train subjects:  45%|████▍     | 128/285 [03:52<04:29,  1.71s/it]predicting train subjects:  45%|████▌     | 129/285 [03:54<04:23,  1.69s/it]predicting train subjects:  46%|████▌     | 130/285 [03:55<04:25,  1.71s/it]predicting train subjects:  46%|████▌     | 131/285 [03:57<04:18,  1.68s/it]predicting train subjects:  46%|████▋     | 132/285 [03:59<04:18,  1.69s/it]predicting train subjects:  47%|████▋     | 133/285 [04:00<04:11,  1.66s/it]predicting train subjects:  47%|████▋     | 134/285 [04:02<04:06,  1.63s/it]predicting train subjects:  47%|████▋     | 135/285 [04:04<04:12,  1.68s/it]predicting train subjects:  48%|████▊     | 136/285 [04:05<04:06,  1.65s/it]predicting train subjects:  48%|████▊     | 137/285 [04:07<04:07,  1.67s/it]predicting train subjects:  48%|████▊     | 138/285 [04:09<04:10,  1.71s/it]predicting train subjects:  49%|████▉     | 139/285 [04:10<04:07,  1.70s/it]predicting train subjects:  49%|████▉     | 140/285 [04:12<04:03,  1.68s/it]predicting train subjects:  49%|████▉     | 141/285 [04:14<04:08,  1.72s/it]predicting train subjects:  50%|████▉     | 142/285 [04:15<04:02,  1.69s/it]predicting train subjects:  50%|█████     | 143/285 [04:17<03:58,  1.68s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<04:00,  1.70s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<04:00,  1.71s/it]predicting train subjects:  51%|█████     | 146/285 [04:22<03:56,  1.70s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:54,  1.70s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:26<03:58,  1.74s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:53,  1.72s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:29<03:47,  1.69s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:31<03:45,  1.68s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:32<03:42,  1.67s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:34<03:33,  1.62s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:36<03:33,  1.63s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:37<03:30,  1.62s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:39<03:27,  1.61s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:40<03:28,  1.63s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:42<03:34,  1.69s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:44<03:29,  1.67s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:45<03:26,  1.65s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:47<03:20,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<03:16,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<03:11,  1.57s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:09,  1.56s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<03:07,  1.56s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<03:06,  1.57s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:56<03:04,  1.57s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:58<03:03,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:59<02:59,  1.54s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<02:59,  1.56s/it]predicting train subjects:  60%|██████    | 171/285 [05:03<03:00,  1.58s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<02:58,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [05:06<02:57,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:58,  1.61s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:09<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:11<02:53,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:12<02:54,  1.61s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:14<02:52,  1.61s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:50,  1.60s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:17<02:47,  1.59s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:19<02:43,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:20<02:39,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:22<02:38,  1.56s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:23<02:39,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:25<02:34,  1.54s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:26<02:33,  1.55s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:28<02:34,  1.57s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:29<02:32,  1.58s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:31<02:28,  1.55s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:33<02:29,  1.58s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:34<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:36<02:25,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:37<02:24,  1.57s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:39<02:22,  1.56s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:40<02:22,  1.58s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:42<02:27,  1.66s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:44<02:31,  1.72s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:46<02:34,  1.77s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:48<02:34,  1.80s/it]predicting train subjects:  70%|███████   | 200/285 [05:50<02:33,  1.80s/it]predicting train subjects:  71%|███████   | 201/285 [05:51<02:30,  1.79s/it]predicting train subjects:  71%|███████   | 202/285 [05:53<02:28,  1.79s/it]predicting train subjects:  71%|███████   | 203/285 [05:55<02:27,  1.80s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:57<02:30,  1.86s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:59<02:24,  1.81s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:01<02:20,  1.78s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:02<02:16,  1.75s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:04<02:11,  1.71s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:05<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<02:06,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:09<02:05,  1.70s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:11<02:08,  1.76s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:13<02:07,  1.77s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:14<01:58,  1.67s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:15<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:47,  1.56s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:18<01:43,  1.52s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:20<01:42,  1.52s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:21<01:41,  1.54s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:23<01:41,  1.57s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:26<01:37,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:28<01:37,  1.58s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:29<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:34,  1.58s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:32<01:31,  1.56s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:34<01:33,  1.61s/it]predicting train subjects:  80%|████████  | 228/285 [06:36<01:32,  1.62s/it]predicting train subjects:  80%|████████  | 229/285 [06:37<01:29,  1.59s/it]predicting train subjects:  81%|████████  | 230/285 [06:39<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:40<01:24,  1.56s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:26,  1.63s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:44<01:28,  1.70s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:46<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:48<01:27,  1.75s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:50<01:31,  1.87s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:52<01:32,  1.92s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:54<01:32,  1.96s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:56<01:28,  1.92s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:58<01:27,  1.95s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:00<01:25,  1.95s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:02<01:25,  1.99s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:04<01:22,  1.95s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:06<01:19,  1.94s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:08<01:20,  2.02s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:10<01:19,  2.03s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:12<01:17,  2.05s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:14<01:15,  2.05s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:16<01:12,  2.01s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:17<01:05,  1.89s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:19<01:01,  1.81s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:21<00:57,  1.73s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:22<00:53,  1.68s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:24<00:51,  1.67s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:26<00:50,  1.67s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:27<00:47,  1.64s/it]predicting train subjects:  90%|█████████ | 257/285 [07:29<00:45,  1.62s/it]predicting train subjects:  91%|█████████ | 258/285 [07:30<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [07:32<00:42,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [07:34<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:35<00:38,  1.62s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:37<00:36,  1.60s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:38<00:35,  1.63s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:40<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:42<00:32,  1.61s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:43<00:30,  1.60s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:45<00:29,  1.63s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:47<00:29,  1.74s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:49<00:28,  1.81s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:51<00:27,  1.85s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:53<00:26,  1.90s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:55<00:25,  1.94s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:57<00:23,  1.98s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:59<00:22,  2.02s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:01<00:20,  2.01s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:03<00:17,  1.97s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:05<00:15,  1.98s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:07<00:14,  2.01s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:09<00:12,  2.02s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:11<00:10,  2.05s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:13<00:08,  2.00s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:15<00:06,  2.01s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:17<00:04,  2.03s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:19<00:02,  2.02s/it]predicting train subjects: 100%|██████████| 285/285 [08:21<00:00,  2.03s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:15,  1.53s/it]Loading train:   1%|          | 2/285 [00:03<07:24,  1.57s/it]Loading train:   1%|          | 3/285 [00:04<07:07,  1.52s/it]Loading train:   1%|▏         | 4/285 [00:06<07:19,  1.57s/it]
Epoch 00052: val_mDice did not improve from 0.50260
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [1789.0501491840068, 1853.2121957632212, 1894.9100823035608, 2028.593793428861, 2069.2497646625225, 2039.4551121638372, 2240.383724506085, 2079.022221491887, 2257.059018648588, 2080.054752056415, 2070.7464834359976, 2249.244233938364, 2130.1568568303037, 2189.9392618032603, 2148.0569217388447, 2371.4928653423603, 2280.51580282358, 2341.7793896014873, 2268.8158610417295, 2296.956527709961, 2498.128452007587, 2289.8561424842246, 2287.012067941519, 2477.211058983436, 2312.7130819467397, 2341.6158787653994, 2400.199741656964, 2360.9622697096606, 2470.939650315505, 2553.497407766489, 2322.56017772968, 2513.5513211763823, 2453.94806260329, 2458.450100238507, 2625.820016127366, 2611.6849060058594, 2495.5281512920674, 2684.04595888578, 2433.7064244196963, 2621.2447521503154, 2501.92787698599, 2731.5243201622598, 2791.1231971153848, 2596.5794043907754, 2649.416521512545, 2661.553490271935, 2714.7122826209434, 2773.778573843149, 2743.5637887807993, 2597.32966026893, 2708.2008361816406, 2712.5547156700723], 'val_acc': [0.9306860451514904, 0.9371949136257172, 0.941480237704057, 0.942175961457766, 0.9429433254095224, 0.9445982919289515, 0.9434587359428406, 0.9443324506282806, 0.9441244189555829, 0.9447739376471593, 0.9447831809520721, 0.9433223971953759, 0.944831710595351, 0.9451830455890069, 0.9447785661770747, 0.9445775059553293, 0.9450443845528823, 0.9452084853098943, 0.9454997090192941, 0.9458302809641912, 0.9447485002187582, 0.9460590871480795, 0.9453933926729056, 0.9445635951482333, 0.9469720904643719, 0.9462255124862378, 0.9449819899522341, 0.9461307112987225, 0.9461631155931033, 0.9454372983712417, 0.9458695627175845, 0.9453795254230499, 0.9457146640007312, 0.9456961750984192, 0.9464866816997528, 0.9454512091783377, 0.9461284279823303, 0.9448109062818381, 0.9456430077552795, 0.9463780522346497, 0.9459666265891149, 0.9461099115701822, 0.9453956851592431, 0.9460451832184424, 0.9464404491277841, 0.9456962049007416, 0.9452293102557843, 0.9458556519104884, 0.9458255997070899, 0.946489006280899, 0.94631100159425, 0.9471385089250711], 'val_mDice': [0.39391810504289776, 0.42949337225693923, 0.45475459987154376, 0.46599566019498384, 0.4597742554660027, 0.4792257776627174, 0.4628759848956878, 0.481361207480614, 0.4620413172703523, 0.4850370969909888, 0.49214167061906594, 0.4773975470318244, 0.49189339119654435, 0.4839609981729434, 0.49860296656305975, 0.4868674794068703, 0.4866602329107431, 0.48701842902944636, 0.4920027473798165, 0.4954466378459564, 0.478455462707923, 0.5026004070845934, 0.49302883417560506, 0.48371408277979266, 0.49780177496946776, 0.5004748243551987, 0.4978414452992953, 0.4934355387320885, 0.4883789165088764, 0.48255871809445894, 0.5006036603680024, 0.49009343064748323, 0.49952796646035635, 0.48764363332436633, 0.480687378690793, 0.4894790110679773, 0.494404599070549, 0.4808922785405929, 0.5012302180895438, 0.4908045312533012, 0.5017047255085065, 0.48554629660569704, 0.4739597760714017, 0.492232091151751, 0.48639693225805575, 0.488989009306981, 0.48553273196403796, 0.47946234333973664, 0.49031630559609485, 0.4952785564729801, 0.4928868536192637, 0.489921965278112], 'loss': [2002.2384771107638, 995.5824255974521, 837.9959311537623, 748.6202095479947, 697.5950431285459, 656.522287100166, 621.235292691691, 598.8773317675655, 578.7316709450005, 561.0277973510325, 544.1755778773469, 529.719277011527, 517.824940414872, 503.9794283659929, 495.0351145082126, 488.10369586531203, 478.97418544016057, 473.2726637753989, 464.222550820394, 457.1008387538084, 452.11016016130486, 443.10684581244004, 441.62558551645145, 435.8354741185945, 430.8501418776082, 426.1805199054316, 421.4386510302811, 419.17530158251446, 412.63551206587863, 411.2911381245231, 404.35839780564567, 401.26964018646777, 399.51704884498946, 395.54867433813416, 394.2405189092689, 390.0092855339328, 385.23993825908076, 383.4261942800754, 380.7911871699272, 377.32539152648303, 375.7493215601547, 372.43540138386055, 371.07004013561095, 369.8801476481127, 366.2368245978401, 362.9945893682128, 362.4224883433715, 358.8770240305931, 359.00755911094177, 356.5123507562933, 355.72633096550175, 353.1406118295668], 'acc': [0.8896942315512364, 0.9206523934237842, 0.9279073830802184, 0.9325478074626048, 0.934986544960398, 0.9369568440468452, 0.938589145075645, 0.9397299446974317, 0.9408377820821219, 0.9415201382048618, 0.9421668917471155, 0.942676416789541, 0.9435431591085564, 0.9438396751039595, 0.9443825859651017, 0.9447257736616883, 0.9452142090108313, 0.945842164733429, 0.945893662794703, 0.9467987145245609, 0.9468103068446383, 0.947170099621273, 0.9472700841728309, 0.9477113226314736, 0.9476067494732597, 0.9476129350864083, 0.9482431719138879, 0.9485887748161871, 0.9490992057964414, 0.9493106596311344, 0.9494348311406665, 0.9496381238115281, 0.9498450354897403, 0.949998448802725, 0.950099230521743, 0.9504564493375105, 0.9508585412871912, 0.9509339555156613, 0.9514277669970734, 0.951286966588723, 0.9518302525638885, 0.9515968086940935, 0.9519462208185844, 0.9517890380491556, 0.9522568191602905, 0.9524772721969321, 0.952649859592482, 0.9529165593469362, 0.9530131342577493, 0.9529501248041466, 0.9526662004617354, 0.952981896564484], 'mDice': [0.31668389560078425, 0.5321147444557575, 0.5953836622443089, 0.6349229572895191, 0.6582604118854832, 0.6775529474599944, 0.6937882745935503, 0.7048394764787892, 0.7144065273596354, 0.7228509718659596, 0.7308329321587645, 0.7379055536399081, 0.7434385155087895, 0.7501755593052366, 0.7544462499303659, 0.7580803158779509, 0.7619236354501135, 0.765091932777504, 0.7695846212456656, 0.7727241125656957, 0.7754240047334691, 0.7795412286306609, 0.7805734280564518, 0.7833087288683591, 0.7856894509220413, 0.7876759885609244, 0.7905145375411756, 0.7915932911519556, 0.7946208090697731, 0.7956235434839034, 0.7985692661120577, 0.7999960397108448, 0.8011450676155917, 0.8029448458445443, 0.8038191876155935, 0.8056877496540904, 0.8083900665979615, 0.8093770830479318, 0.8104840746711324, 0.8121332437099593, 0.8129339209894055, 0.8144896128548584, 0.8148965715185629, 0.8159914717983849, 0.8177447091507359, 0.8191455295470041, 0.8194588696968728, 0.8211506916172091, 0.8212196968868959, 0.8221470937290876, 0.8229742763469682, 0.8241400435480324]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 20 |  Upsample 1

 #layer 4 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 20 |  Upsample 1

 #layer 4 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values Loading train:   2%|▏         | 5/285 [00:07<06:57,  1.49s/it]Loading train:   2%|▏         | 6/285 [00:09<07:19,  1.58s/it]Loading train:   2%|▏         | 7/285 [00:11<07:37,  1.65s/it]Loading train:   3%|▎         | 8/285 [00:12<07:46,  1.68s/it]Loading train:   3%|▎         | 9/285 [00:14<07:12,  1.57s/it]Loading train:   4%|▎         | 10/285 [00:15<06:38,  1.45s/it]Loading train:   4%|▍         | 11/285 [00:16<06:18,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:17<06:09,  1.35s/it]Loading train:   5%|▍         | 13/285 [00:19<06:13,  1.37s/it]Loading train:   5%|▍         | 14/285 [00:20<06:02,  1.34s/it]Loading train:   5%|▌         | 15/285 [00:22<06:22,  1.42s/it]Loading train:   6%|▌         | 16/285 [00:23<06:24,  1.43s/it]Loading train:   6%|▌         | 17/285 [00:24<06:05,  1.36s/it]Loading train:   6%|▋         | 18/285 [00:26<06:04,  1.37s/it]Loading train:   7%|▋         | 19/285 [00:27<06:01,  1.36s/it]Loading train:   7%|▋         | 20/285 [00:28<05:59,  1.36s/it]Loading train:   7%|▋         | 21/285 [00:30<05:42,  1.30s/it]Loading train:   8%|▊         | 22/285 [00:31<05:36,  1.28s/it]Loading train:   8%|▊         | 23/285 [00:32<05:35,  1.28s/it]Loading train:   8%|▊         | 24/285 [00:33<05:25,  1.25s/it]Loading train:   9%|▉         | 25/285 [00:34<05:18,  1.23s/it]Loading train:   9%|▉         | 26/285 [00:36<05:21,  1.24s/it]Loading train:   9%|▉         | 27/285 [00:37<05:16,  1.23s/it]Loading train:  10%|▉         | 28/285 [00:38<05:19,  1.24s/it]Loading train:  10%|█         | 29/285 [00:40<05:23,  1.27s/it]Loading train:  11%|█         | 30/285 [00:41<05:29,  1.29s/it]Loading train:  11%|█         | 31/285 [00:42<05:54,  1.39s/it]Loading train:  11%|█         | 32/285 [00:44<05:38,  1.34s/it]Loading train:  12%|█▏        | 33/285 [00:45<05:41,  1.36s/it]Loading train:  12%|█▏        | 34/285 [00:46<05:37,  1.34s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:52,  1.41s/it]Loading train:  13%|█▎        | 36/285 [00:49<05:54,  1.42s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:36,  1.36s/it]Loading train:  13%|█▎        | 38/285 [00:52<05:40,  1.38s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:47,  1.41s/it]Loading train:  14%|█▍        | 40/285 [00:55<05:41,  1.39s/it]Loading train:  14%|█▍        | 41/285 [00:57<05:56,  1.46s/it]Loading train:  15%|█▍        | 42/285 [00:58<05:40,  1.40s/it]Loading train:  15%|█▌        | 43/285 [00:59<05:38,  1.40s/it]Loading train:  15%|█▌        | 44/285 [01:01<05:44,  1.43s/it]Loading train:  16%|█▌        | 45/285 [01:02<05:51,  1.46s/it]Loading train:  16%|█▌        | 46/285 [01:04<05:49,  1.46s/it]Loading train:  16%|█▋        | 47/285 [01:05<05:24,  1.36s/it]Loading train:  17%|█▋        | 48/285 [01:06<05:13,  1.32s/it]Loading train:  17%|█▋        | 49/285 [01:07<04:56,  1.26s/it]Loading train:  18%|█▊        | 50/285 [01:08<04:56,  1.26s/it]Loading train:  18%|█▊        | 51/285 [01:10<04:51,  1.25s/it]Loading train:  18%|█▊        | 52/285 [01:11<04:48,  1.24s/it]Loading train:  19%|█▊        | 53/285 [01:12<04:48,  1.24s/it]Loading train:  19%|█▉        | 54/285 [01:13<04:50,  1.26s/it]Loading train:  19%|█▉        | 55/285 [01:15<04:51,  1.27s/it]Loading train:  20%|█▉        | 56/285 [01:16<04:41,  1.23s/it]Loading train:  20%|██        | 57/285 [01:17<05:00,  1.32s/it]Loading train:  20%|██        | 58/285 [01:19<04:50,  1.28s/it]Loading train:  21%|██        | 59/285 [01:20<04:57,  1.32s/it]Loading train:  21%|██        | 60/285 [01:21<04:44,  1.26s/it]Loading train:  21%|██▏       | 61/285 [01:22<04:42,  1.26s/it]Loading train:  22%|██▏       | 62/285 [01:24<04:52,  1.31s/it]Loading train:  22%|██▏       | 63/285 [01:25<04:42,  1.27s/it]Loading train:  22%|██▏       | 64/285 [01:27<05:13,  1.42s/it]Loading train:  23%|██▎       | 65/285 [01:29<05:49,  1.59s/it]Loading train:  23%|██▎       | 66/285 [01:31<06:19,  1.73s/it]Loading train:  24%|██▎       | 67/285 [01:32<06:00,  1.65s/it]Loading train:  24%|██▍       | 68/285 [01:34<05:45,  1.59s/it]Loading train:  24%|██▍       | 69/285 [01:35<05:30,  1.53s/it]Loading train:  25%|██▍       | 70/285 [01:37<05:31,  1.54s/it]Loading train:  25%|██▍       | 71/285 [01:38<05:01,  1.41s/it]Loading train:  25%|██▌       | 72/285 [01:39<04:57,  1.40s/it]Loading train:  26%|██▌       | 73/285 [01:40<04:53,  1.38s/it]Loading train:  26%|██▌       | 74/285 [01:42<04:47,  1.36s/it]Loading train:  26%|██▋       | 75/285 [01:44<05:24,  1.55s/it]Loading train:  27%|██▋       | 76/285 [01:45<05:04,  1.46s/it]Loading train:  27%|██▋       | 77/285 [01:46<05:05,  1.47s/it]Loading train:  27%|██▋       | 78/285 [01:48<05:07,  1.48s/it]Loading train:  28%|██▊       | 79/285 [01:50<05:11,  1.51s/it]Loading train:  28%|██▊       | 80/285 [01:51<05:00,  1.47s/it]Loading train:  28%|██▊       | 81/285 [01:52<04:53,  1.44s/it]Loading train:  29%|██▉       | 82/285 [01:53<04:34,  1.35s/it]Loading train:  29%|██▉       | 83/285 [01:55<04:26,  1.32s/it]Loading train:  29%|██▉       | 84/285 [01:56<04:30,  1.34s/it]Loading train:  30%|██▉       | 85/285 [01:58<04:36,  1.38s/it]Loading train:  30%|███       | 86/285 [01:59<04:38,  1.40s/it]Loading train:  31%|███       | 87/285 [02:01<04:43,  1.43s/it]Loading train:  31%|███       | 88/285 [02:02<04:58,  1.51s/it]Loading train:  31%|███       | 89/285 [02:04<05:00,  1.53s/it]Loading train:  32%|███▏      | 90/285 [02:05<05:00,  1.54s/it]Loading train:  32%|███▏      | 91/285 [02:07<04:56,  1.53s/it]Loading train:  32%|███▏      | 92/285 [02:09<05:22,  1.67s/it]Loading train:  33%|███▎      | 93/285 [02:11<05:23,  1.69s/it]Loading train:  33%|███▎      | 94/285 [02:12<05:26,  1.71s/it]Loading train:  33%|███▎      | 95/285 [02:14<05:17,  1.67s/it]Loading train:  34%|███▎      | 96/285 [02:16<05:15,  1.67s/it]Loading train:  34%|███▍      | 97/285 [02:17<05:02,  1.61s/it]Loading train:  34%|███▍      | 98/285 [02:19<04:55,  1.58s/it]Loading train:  35%|███▍      | 99/285 [02:20<04:48,  1.55s/it]Loading train:  35%|███▌      | 100/285 [02:21<04:37,  1.50s/it]Loading train:  35%|███▌      | 101/285 [02:23<04:38,  1.51s/it]Loading train:  36%|███▌      | 102/285 [02:24<04:22,  1.44s/it]Loading train:  36%|███▌      | 103/285 [02:26<04:18,  1.42s/it]Loading train:  36%|███▋      | 104/285 [02:27<04:01,  1.33s/it]Loading train:  37%|███▋      | 105/285 [02:28<03:58,  1.33s/it]Loading train:  37%|███▋      | 106/285 [02:29<03:50,  1.29s/it]Loading train:  38%|███▊      | 107/285 [02:30<03:35,  1.21s/it]Loading train:  38%|███▊      | 108/285 [02:32<03:35,  1.22s/it]Loading train:  38%|███▊      | 109/285 [02:33<03:25,  1.17s/it]Loading train:  39%|███▊      | 110/285 [02:34<03:20,  1.14s/it]Loading train:  39%|███▉      | 111/285 [02:35<03:15,  1.12s/it]Loading train:  39%|███▉      | 112/285 [02:36<03:09,  1.09s/it]Loading train:  40%|███▉      | 113/285 [02:37<03:07,  1.09s/it]Loading train:  40%|████      | 114/285 [02:38<03:08,  1.10s/it]Loading train:  40%|████      | 115/285 [02:39<03:09,  1.11s/it]Loading train:  41%|████      | 116/285 [02:40<03:11,  1.13s/it]Loading train:  41%|████      | 117/285 [02:41<03:07,  1.12s/it]Loading train:  41%|████▏     | 118/285 [02:43<03:09,  1.13s/it]Loading train:  42%|████▏     | 119/285 [02:44<03:13,  1.17s/it]Loading train:  42%|████▏     | 120/285 [02:45<03:10,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:46<03:18,  1.21s/it]Loading train:  43%|████▎     | 122/285 [02:48<03:18,  1.21s/it]Loading train:  43%|████▎     | 123/285 [02:49<03:27,  1.28s/it]Loading train:  44%|████▎     | 124/285 [02:50<03:15,  1.21s/it]Loading train:  44%|████▍     | 125/285 [02:51<03:04,  1.15s/it]Loading train:  44%|████▍     | 126/285 [02:52<02:51,  1.08s/it]Loading train:  45%|████▍     | 127/285 [02:53<02:53,  1.10s/it]Loading train:  45%|████▍     | 128/285 [02:54<02:46,  1.06s/it]Loading train:  45%|████▌     | 129/285 [02:55<02:46,  1.07s/it]Loading train:  46%|████▌     | 130/285 [02:56<02:38,  1.03s/it]Loading train:  46%|████▌     | 131/285 [02:57<02:37,  1.02s/it]Loading train:  46%|████▋     | 132/285 [02:58<02:33,  1.01s/it]Loading train:  47%|████▋     | 133/285 [02:59<02:33,  1.01s/it]Loading train:  47%|████▋     | 134/285 [03:00<02:29,  1.01it/s]Loading train:  47%|████▋     | 135/285 [03:01<02:31,  1.01s/it]Loading train:  48%|████▊     | 136/285 [03:02<02:32,  1.02s/it]Loading train:  48%|████▊     | 137/285 [03:03<02:30,  1.02s/it]Loading train:  48%|████▊     | 138/285 [03:04<02:30,  1.03s/it]Loading train:  49%|████▉     | 139/285 [03:05<02:34,  1.06s/it]Loading train:  49%|████▉     | 140/285 [03:06<02:36,  1.08s/it]Loading train:  49%|████▉     | 141/285 [03:07<02:33,  1.06s/it]Loading train:  50%|████▉     | 142/285 [03:08<02:27,  1.03s/it]Loading train:  50%|█████     | 143/285 [03:09<02:25,  1.02s/it]Loading train:  51%|█████     | 144/285 [03:10<02:15,  1.04it/s]Loading train:  51%|█████     | 145/285 [03:11<02:15,  1.03it/s]Loading train:  51%|█████     | 146/285 [03:12<02:10,  1.06it/s]Loading train:  52%|█████▏    | 147/285 [03:13<02:08,  1.08it/s]Loading train:  52%|█████▏    | 148/285 [03:14<02:12,  1.03it/s]Loading train:  52%|█████▏    | 149/285 [03:15<02:11,  1.03it/s]Loading train:  53%|█████▎    | 150/285 [03:16<02:06,  1.07it/s]Loading train:  53%|█████▎    | 151/285 [03:17<02:00,  1.11it/s]Loading train:  53%|█████▎    | 152/285 [03:18<02:00,  1.11it/s]Loading train:  54%|█████▎    | 153/285 [03:19<02:05,  1.05it/s]Loading train:  54%|█████▍    | 154/285 [03:20<02:04,  1.05it/s]Loading train:  54%|█████▍    | 155/285 [03:20<02:00,  1.08it/s]Loading train:  55%|█████▍    | 156/285 [03:21<02:01,  1.06it/s]Loading train:  55%|█████▌    | 157/285 [03:22<02:02,  1.04it/s]Loading train:  55%|█████▌    | 158/285 [03:23<02:02,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [03:24<02:00,  1.05it/s]Loading train:  56%|█████▌    | 160/285 [03:25<01:54,  1.09it/s]Loading train:  56%|█████▋    | 161/285 [03:26<01:52,  1.10it/s]Loading train:  57%|█████▋    | 162/285 [03:27<01:50,  1.11it/s]Loading train:  57%|█████▋    | 163/285 [03:28<01:49,  1.12it/s]Loading train:  58%|█████▊    | 164/285 [03:29<01:52,  1.07it/s]Loading train:  58%|█████▊    | 165/285 [03:30<01:51,  1.08it/s]Loading train:  58%|█████▊    | 166/285 [03:31<01:47,  1.11it/s]Loading train:  59%|█████▊    | 167/285 [03:32<01:49,  1.08it/s]Loading train:  59%|█████▉    | 168/285 [03:32<01:46,  1.10it/s]Loading train:  59%|█████▉    | 169/285 [03:34<01:49,  1.06it/s]Loading train:  60%|█████▉    | 170/285 [03:35<01:51,  1.03it/s]Loading train:  60%|██████    | 171/285 [03:35<01:50,  1.04it/s]Loading train:  60%|██████    | 172/285 [03:37<01:51,  1.02it/s]Loading train:  61%|██████    | 173/285 [03:37<01:45,  1.06it/s]Loading train:  61%|██████    | 174/285 [03:38<01:43,  1.07it/s]Loading train:  61%|██████▏   | 175/285 [03:39<01:43,  1.07it/s]Loading train:  62%|██████▏   | 176/285 [03:40<01:37,  1.12it/s]Loading train:  62%|██████▏   | 177/285 [03:41<01:27,  1.24it/s]Loading train:  62%|██████▏   | 178/285 [03:41<01:22,  1.30it/s]Loading train:  63%|██████▎   | 179/285 [03:42<01:21,  1.30it/s]Loading train:  63%|██████▎   | 180/285 [03:43<01:18,  1.33it/s]Loading train:  64%|██████▎   | 181/285 [03:44<01:17,  1.33it/s]Loading train:  64%|██████▍   | 182/285 [03:44<01:16,  1.35it/s]Loading train:  64%|██████▍   | 183/285 [03:45<01:12,  1.40it/s]Loading train:  65%|██████▍   | 184/285 [03:46<01:10,  1.44it/s]Loading train:  65%|██████▍   | 185/285 [03:46<01:06,  1.50it/s]Loading train:  65%|██████▌   | 186/285 [03:47<01:04,  1.52it/s]Loading train:  66%|██████▌   | 187/285 [03:47<01:03,  1.55it/s]Loading train:  66%|██████▌   | 188/285 [03:48<01:02,  1.54it/s]Loading train:  66%|██████▋   | 189/285 [03:49<01:02,  1.54it/s]Loading train:  67%|██████▋   | 190/285 [03:49<01:01,  1.54it/s]Loading train:  67%|██████▋   | 191/285 [03:50<00:59,  1.57it/s]Loading train:  67%|██████▋   | 192/285 [03:51<00:59,  1.57it/s]Loading train:  68%|██████▊   | 193/285 [03:51<01:00,  1.53it/s]Loading train:  68%|██████▊   | 194/285 [03:52<01:01,  1.47it/s]Loading train:  68%|██████▊   | 195/285 [03:53<01:03,  1.43it/s]Loading train:  69%|██████▉   | 196/285 [03:54<01:08,  1.30it/s]Loading train:  69%|██████▉   | 197/285 [03:54<01:07,  1.30it/s]Loading train:  69%|██████▉   | 198/285 [03:55<01:06,  1.30it/s]Loading train:  70%|██████▉   | 199/285 [03:56<01:06,  1.29it/s]Loading train:  70%|███████   | 200/285 [03:57<01:06,  1.29it/s]Loading train:  71%|███████   | 201/285 [03:58<01:03,  1.33it/s]Loading train:  71%|███████   | 202/285 [03:58<01:01,  1.34it/s]Loading train:  71%|███████   | 203/285 [03:59<01:01,  1.34it/s]Loading train:  72%|███████▏  | 204/285 [04:00<01:02,  1.30it/s]Loading train:  72%|███████▏  | 205/285 [04:01<01:00,  1.33it/s]Loading train:  72%|███████▏  | 206/285 [04:01<01:00,  1.30it/s]Loading train:  73%|███████▎  | 207/285 [04:02<01:02,  1.25it/s]Loading train:  73%|███████▎  | 208/285 [04:03<01:01,  1.25it/s]Loading train:  73%|███████▎  | 209/285 [04:04<01:00,  1.26it/s]Loading train:  74%|███████▎  | 210/285 [04:05<01:00,  1.24it/s]Loading train:  74%|███████▍  | 211/285 [04:05<00:59,  1.24it/s]Loading train:  74%|███████▍  | 212/285 [04:06<00:59,  1.23it/s]Loading train:  75%|███████▍  | 213/285 [04:07<00:59,  1.21it/s]Loading train:  75%|███████▌  | 214/285 [04:08<00:57,  1.22it/s]Loading train:  75%|███████▌  | 215/285 [04:09<00:57,  1.23it/s]Loading train:  76%|███████▌  | 216/285 [04:09<00:53,  1.29it/s]Loading train:  76%|███████▌  | 217/285 [04:10<00:51,  1.32it/s]Loading train:  76%|███████▋  | 218/285 [04:11<00:51,  1.29it/s]Loading train:  77%|███████▋  | 219/285 [04:12<00:51,  1.29it/s]Loading train:  77%|███████▋  | 220/285 [04:12<00:50,  1.30it/s]Loading train:  78%|███████▊  | 221/285 [04:13<00:49,  1.29it/s]Loading train:  78%|███████▊  | 222/285 [04:14<00:47,  1.32it/s]Loading train:  78%|███████▊  | 223/285 [04:15<00:47,  1.30it/s]Loading train:  79%|███████▊  | 224/285 [04:15<00:45,  1.33it/s]Loading train:  79%|███████▉  | 225/285 [04:16<00:47,  1.26it/s]Loading train:  79%|███████▉  | 226/285 [04:17<00:46,  1.26it/s]Loading train:  80%|███████▉  | 227/285 [04:18<00:46,  1.25it/s]Loading train:  80%|████████  | 228/285 [04:19<00:48,  1.18it/s]Loading train:  80%|████████  | 229/285 [04:20<00:49,  1.12it/s]Loading train:  81%|████████  | 230/285 [04:21<00:47,  1.15it/s]Loading train:  81%|████████  | 231/285 [04:22<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [04:23<00:51,  1.03it/s]Loading train:  82%|████████▏ | 233/285 [04:24<00:54,  1.04s/it]Loading train:  82%|████████▏ | 234/285 [04:25<00:54,  1.07s/it]Loading train:  82%|████████▏ | 235/285 [04:26<00:51,  1.04s/it]Loading train:  83%|████████▎ | 236/285 [04:27<00:51,  1.05s/it]Loading train:  83%|████████▎ | 237/285 [04:28<00:47,  1.00it/s]Loading train:  84%|████████▎ | 238/285 [04:29<00:46,  1.01it/s]Loading train:  84%|████████▍ | 239/285 [04:30<00:44,  1.03it/s]Loading train:  84%|████████▍ | 240/285 [04:31<00:43,  1.03it/s]Loading train:  85%|████████▍ | 241/285 [04:32<00:41,  1.05it/s]Loading train:  85%|████████▍ | 242/285 [04:33<00:43,  1.02s/it]Loading train:  85%|████████▌ | 243/285 [04:34<00:45,  1.07s/it]Loading train:  86%|████████▌ | 244/285 [04:35<00:44,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:37<00:46,  1.15s/it]Loading train:  86%|████████▋ | 246/285 [04:38<00:44,  1.15s/it]Loading train:  87%|████████▋ | 247/285 [04:39<00:45,  1.20s/it]Loading train:  87%|████████▋ | 248/285 [04:40<00:44,  1.20s/it]Loading train:  87%|████████▋ | 249/285 [04:41<00:41,  1.16s/it]Loading train:  88%|████████▊ | 250/285 [04:42<00:38,  1.10s/it]Loading train:  88%|████████▊ | 251/285 [04:44<00:37,  1.12s/it]Loading train:  88%|████████▊ | 252/285 [04:45<00:39,  1.20s/it]Loading train:  89%|████████▉ | 253/285 [04:46<00:39,  1.25s/it]Loading train:  89%|████████▉ | 254/285 [04:48<00:40,  1.29s/it]Loading train:  89%|████████▉ | 255/285 [04:49<00:35,  1.18s/it]Loading train:  90%|████████▉ | 256/285 [04:50<00:33,  1.14s/it]Loading train:  90%|█████████ | 257/285 [04:51<00:29,  1.07s/it]Loading train:  91%|█████████ | 258/285 [04:52<00:29,  1.09s/it]Loading train:  91%|█████████ | 259/285 [04:53<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [04:54<00:27,  1.12s/it]Loading train:  92%|█████████▏| 261/285 [04:55<00:25,  1.06s/it]Loading train:  92%|█████████▏| 262/285 [04:56<00:25,  1.10s/it]Loading train:  92%|█████████▏| 263/285 [04:57<00:23,  1.06s/it]Loading train:  93%|█████████▎| 264/285 [04:58<00:23,  1.10s/it]Loading train:  93%|█████████▎| 265/285 [04:59<00:21,  1.08s/it]Loading train:  93%|█████████▎| 266/285 [05:00<00:19,  1.02s/it]Loading train:  94%|█████████▎| 267/285 [05:01<00:16,  1.06it/s]Loading train:  94%|█████████▍| 268/285 [05:02<00:16,  1.05it/s]Loading train:  94%|█████████▍| 269/285 [05:03<00:15,  1.04it/s]Loading train:  95%|█████████▍| 270/285 [05:04<00:14,  1.02it/s]Loading train:  95%|█████████▌| 271/285 [05:05<00:14,  1.07s/it]Loading train:  95%|█████████▌| 272/285 [05:06<00:15,  1.16s/it]Loading train:  96%|█████████▌| 273/285 [05:08<00:14,  1.21s/it]Loading train:  96%|█████████▌| 274/285 [05:09<00:13,  1.22s/it]Loading train:  96%|█████████▋| 275/285 [05:11<00:14,  1.43s/it]Loading train:  97%|█████████▋| 276/285 [05:13<00:14,  1.57s/it]Loading train:  97%|█████████▋| 277/285 [05:14<00:12,  1.54s/it]Loading train:  98%|█████████▊| 278/285 [05:16<00:10,  1.56s/it]Loading train:  98%|█████████▊| 279/285 [05:17<00:08,  1.46s/it]Loading train:  98%|█████████▊| 280/285 [05:18<00:06,  1.39s/it]Loading train:  99%|█████████▊| 281/285 [05:19<00:05,  1.27s/it]Loading train:  99%|█████████▉| 282/285 [05:20<00:03,  1.20s/it]Loading train:  99%|█████████▉| 283/285 [05:21<00:02,  1.13s/it]Loading train: 100%|█████████▉| 284/285 [05:22<00:01,  1.10s/it]Loading train: 100%|██████████| 285/285 [05:23<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:07, 35.49it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:06, 39.88it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:06, 41.51it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:05, 49.19it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:05, 49.85it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:05, 49.42it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:04, 55.48it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:03, 62.04it/s]concatenating: train:  22%|██▏       | 64/285 [00:00<00:03, 70.82it/s]concatenating: train:  26%|██▌       | 73/285 [00:01<00:02, 74.17it/s]concatenating: train:  29%|██▉       | 83/285 [00:01<00:02, 79.63it/s]concatenating: train:  34%|███▎      | 96/285 [00:01<00:02, 89.36it/s]concatenating: train:  38%|███▊      | 107/285 [00:01<00:01, 92.78it/s]concatenating: train:  42%|████▏     | 120/285 [00:01<00:01, 100.56it/s]concatenating: train:  47%|████▋     | 133/285 [00:01<00:01, 107.85it/s]concatenating: train:  57%|█████▋    | 162/285 [00:01<00:00, 132.11it/s]concatenating: train:  66%|██████▋   | 189/285 [00:01<00:00, 155.79it/s]concatenating: train:  78%|███████▊  | 221/285 [00:01<00:00, 183.39it/s]concatenating: train:  89%|████████▉ | 255/285 [00:02<00:00, 210.08it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 134.15it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.44s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.46s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 57.21it/s]min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 40, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 40, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 40, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 20, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 20, 40)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 20, 80)   28880       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 7, 10, 80)    0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 7, 10, 80)    0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 7, 10, 160)   115360      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 7, 10, 160)   640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 7, 10, 160)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 7, 10, 160)   230560      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 7, 10, 160)   640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 7, 10, 160)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 7, 10, 160)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 14, 20, 80)   51280       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 14, 20, 160)  0           conv2d_transpose_1[0][0]         
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 20, 80)   115280      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 20, 80)   320         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 20, 80)   0           batch_normalization_9[0][0]      2019-06-30 23:15:18.803124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 23:15:18.803218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 23:15:18.803232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 23:15:18.803240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 23:15:18.803649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 20, 80)   57680       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 20, 80)   320         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 20, 80)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 20, 80)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 28, 40, 40)   12840       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 40, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 40, 40)   28840       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 40, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 40, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 40, 40)   14440       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 40, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 40, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 40, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 56, 80, 20)   3220        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 80, 40)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 80, 20)   7220        concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 80, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 80, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 80, 20)   3620        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 80, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 80, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 80, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 80, 13)   273         dropout_7[0][0]                  
==================================================================================================
Total params: 756,193
Trainable params: 754,433
Non-trainable params: 1,760
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [2.29678646e+01 1.13088369e+01 2.65421366e+01 3.29884122e+00
 9.58849072e+00 2.50031647e+00 3.01177739e+01 3.98604065e+01
 3.04429722e+01 4.68832496e+00 1.04095038e+02 6.92273731e+01
 8.75539005e-02]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 18s - loss: 1845.3265 - acc: 0.8944 - mDice: 0.2060 - val_loss: 1366.3235 - val_acc: 0.9327 - val_mDice: 0.2484

Epoch 00001: val_mDice improved from -inf to 0.24838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 980.8199 - acc: 0.9146 - mDice: 0.3770 - val_loss: 1297.4748 - val_acc: 0.9420 - val_mDice: 0.3344

Epoch 00002: val_mDice improved from 0.24838 to 0.33440, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 811.5005 - acc: 0.9231 - mDice: 0.4583 - val_loss: 1291.5529 - val_acc: 0.9443 - val_mDice: 0.3762

Epoch 00003: val_mDice improved from 0.33440 to 0.37619, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 713.4639 - acc: 0.9281 - mDice: 0.5114 - val_loss: 1510.2668 - val_acc: 0.9440 - val_mDice: 0.3765

Epoch 00004: val_mDice improved from 0.37619 to 0.37645, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 10s - loss: 650.6212 - acc: 0.9317 - mDice: 0.5495 - val_loss: 1559.7933 - val_acc: 0.9451 - val_mDice: 0.3894

Epoch 00005: val_mDice improved from 0.37645 to 0.38939, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 10s - loss: 606.3977 - acc: 0.9341 - mDice: 0.5796 - val_loss: 1655.4321 - val_acc: 0.9464 - val_mDice: 0.3934

Epoch 00006: val_mDice improved from 0.38939 to 0.39340, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 573.2309 - acc: 0.9357 - mDice: 0.6010 - val_loss: 1617.5974 - val_acc: 0.9469 - val_mDice: 0.4072

Epoch 00007: val_mDice improved from 0.39340 to 0.40719, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 546.8553 - acc: 0.9369 - mDice: 0.6184 - val_loss: 1644.4155 - val_acc: 0.9472 - val_mDice: 0.4138

Epoch 00008: val_mDice improved from 0.40719 to 0.41382, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 10s - loss: 524.9418 - acc: 0.9380 - mDice: 0.6325 - val_loss: 1538.6916 - val_acc: 0.9491 - val_mDice: 0.4377

Epoch 00009: val_mDice improved from 0.41382 to 0.43771, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 10s - loss: 506.3065 - acc: 0.9390 - mDice: 0.6456 - val_loss: 1639.6540 - val_acc: 0.9491 - val_mDice: 0.4326

Epoch 00010: val_mDice did not improve from 0.43771
Epoch 11/300
 - 10s - loss: 491.4900 - acc: 0.9397 - mDice: 0.6563 - val_loss: 1646.9517 - val_acc: 0.9476 - val_mDice: 0.4284

Epoch 00011: val_mDice did not improve from 0.43771
Epoch 12/300
 - 10s - loss: 477.8077 - acc: 0.9404 - mDice: 0.6653 - val_loss: 1683.2323 - val_acc: 0.9482 - val_mDice: 0.4345

Epoch 00012: val_mDice did not improve from 0.43771
Epoch 13/300
 - 10s - loss: 465.3503 - acc: 0.9408 - mDice: 0.6738 - val_loss: 1697.3016 - val_acc: 0.9481 - val_mDice: 0.4254

Epoch 00013: val_mDice did not improve from 0.43771
Epoch 14/300
 - 10s - loss: 456.7045 - acc: 0.9411 - mDice: 0.6792 - val_loss: 1682.9457 - val_acc: 0.9477 - val_mDice: 0.4347

Epoch 00014: val_mDice did not improve from 0.43771
Epoch 15/300
 - 11s - loss: 447.6650 - acc: 0.9415 - mDice: 0.6851 - val_loss: 1788.3755 - val_acc: 0.9475 - val_mDice: 0.4276

Epoch 00015: val_mDice did not improve from 0.43771
Epoch 16/300
 - 10s - loss: 436.6239 - acc: 0.9420 - mDice: 0.6932 - val_loss: 1879.3708 - val_acc: 0.9455 - val_mDice: 0.4151

Epoch 00016: val_mDice did not improve from 0.43771
Epoch 17/300
 - 10s - loss: 429.6950 - acc: 0.9422 - mDice: 0.6977 - val_loss: 1797.8729 - val_acc: 0.9483 - val_mDice: 0.4330

Epoch 00017: val_mDice did not improve from 0.43771
Epoch 18/300
 - 10s - loss: 423.3790 - acc: 0.9425 - mDice: 0.7030 - val_loss: 1822.4334 - val_acc: 0.9479 - val_mDice: 0.4319

Epoch 00018: val_mDice did not improve from 0.43771
Epoch 19/300
 - 10s - loss: 416.6811 - acc: 0.9427 - mDice: 0.7069 - val_loss: 1893.4350 - val_acc: 0.9477 - val_mDice: 0.4218

Epoch 00019: val_mDice did not improve from 0.43771
Epoch 20/300
 - 10s - loss: 410.5428 - acc: 0.9428 - mDice: 0.7107 - val_loss: 1954.1947 - val_acc: 0.9466 - val_mDice: 0.4189

Epoch 00020: val_mDice did not improve from 0.43771
Epoch 21/300
 - 9s - loss: 402.5816 - acc: 0.9433 - mDice: 0.7161 - val_loss: 1881.0764 - val_acc: 0.9478 - val_mDice: 0.4298

Epoch 00021: val_mDice did not improve from 0.43771
Epoch 22/300
 - 9s - loss: 401.4338 - acc: 0.9433 - mDice: 0.7178 - val_loss: 1914.1198 - val_acc: 0.9467 - val_mDice: 0.4301

Epoch 00022: val_mDice did not improve from 0.43771
Epoch 23/300
 - 10s - loss: 393.0643 - acc: 0.9436 - mDice: 0.7229 - val_loss: 1866.2029 - val_acc: 0.9472 - val_mDice: 0.4372

Epoch 00023: val_mDice did not improve from 0.43771
Epoch 24/300
 - 11s - loss: 389.1388 - acc: 0.9437 - mDice: 0.7258 - val_loss: 1974.1712 - val_acc: 0.9471 - val_mDice: 0.4281

Epoch 00024: val_mDice did not improve from 0.43771
Epoch 25/300
 - 10s - loss: 383.5445 - acc: 0.9439 - mDice: 0.7297 - val_loss: 2020.6356 - val_acc: 0.9471 - val_mDice: 0.4264

Epoch 00025: val_mDice did not improve from 0.43771
Epoch 26/300
 - 10s - loss: 381.0635 - acc: 0.9441 - mDice: 0.7316 - val_loss: 2042.1019 - val_acc: 0.9453 - val_mDice: 0.4185

Epoch 00026: val_mDice did not improve from 0.43771
Epoch 27/300
 - 11s - loss: 377.6446 - acc: 0.9440 - mDice: 0.7338 - val_loss: 2111.1054 - val_acc: 0.9462 - val_mDice: 0.4203

Epoch 00027: val_mDice did not improve from 0.43771
Epoch 28/300
 - 10s - loss: 373.7360 - acc: 0.9442 - mDice: 0.7366 - val_loss: 1939.6768 - val_acc: 0.9465 - val_mDice: 0.4394

Epoch 00028: val_mDice improved from 0.43771 to 0.43937, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 10s - loss: 370.2215 - acc: 0.9443 - mDice: 0.7388 - val_loss: 1980.6251 - val_acc: 0.9469 - val_mDice: 0.4345

Epoch 00029: val_mDice did not improve from 0.43937
Epoch 30/300
 - 10s - loss: 365.6099 - acc: 0.9445 - mDice: 0.7421 - val_loss: 1992.1765 - val_acc: 0.9467 - val_mDice: 0.4337

Epoch 00030: val_mDice did not improve from 0.43937
Epoch 31/300
 - 10s - loss: 362.8118 - acc: 0.9447 - mDice: 0.7441 - val_loss: 2229.2406 - val_acc: 0.9444 - val_mDice: 0.4125

Epoch 00031: val_mDice did not improve from 0.43937
Epoch 32/300
 - 10s - loss: 361.1950 - acc: 0.9445 - mDice: 0.7456 - val_loss: 2255.5090 - val_acc: 0.9455 - val_mDice: 0.4163

Epoch 00032: val_mDice did not improve from 0.43937
Epoch 33/300
 - 9s - loss: 357.8588 - acc: 0.9446 - mDice: 0.7474 - val_loss: 2207.2370 - val_acc: 0.9458 - val_mDice: 0.4221

Epoch 00033: val_mDice did not improve from 0.43937
Epoch 34/300
 - 10s - loss: 354.6639 - acc: 0.9448 - mDice: 0.7499 - val_loss: 2209.3588 - val_acc: 0.9456 - val_mDice: 0.4243

Epoch 00034: val_mDice did not improve from 0.43937
Epoch 35/300
 - 11s - loss: 354.1157 - acc: 0.9449 - mDice: 0.7504 - val_loss: 2169.7404 - val_acc: 0.9461 - val_mDice: 0.4279

Epoch 00035: val_mDice did not improve from 0.43937
Epoch 36/300
 - 10s - loss: 348.7984 - acc: 0.9448 - mDice: 0.7543 - val_loss: 2172.3122 - val_acc: 0.9460 - val_mDice: 0.4285

Epoch 00036: val_mDice did not improve from 0.43937
Epoch 37/300
 - 10s - loss: 345.1555 - acc: 0.9450 - mDice: 0.7565 - val_loss: 2045.0523 - val_acc: 0.9460 - val_mDice: 0.4410

Epoch 00037: val_mDice improved from 0.43937 to 0.44100, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 11s - loss: 344.6196 - acc: 0.9450 - mDice: 0.7573 - val_loss: 2012.8299 - val_acc: 0.9465 - val_mDice: 0.4381

Epoch 00038: val_mDice did not improve from 0.44100
Epoch 39/300
 - 10s - loss: 342.0184 - acc: 0.9451 - mDice: 0.7587 - val_loss: 2178.8706 - val_acc: 0.9467 - val_mDice: 0.4335

Epoch 00039: val_mDice did not improve from 0.44100
Epoch 40/300
 - 10s - loss: 339.2468 - acc: 0.9453 - mDice: 0.7605 - val_loss: 1951.7167 - val_acc: 0.9472 - val_mDice: 0.4546

Epoch 00040: val_mDice improved from 0.44100 to 0.45461, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 41/300
 - 10s - loss: 337.5093 - acc: 0.9454 - mDice: 0.7619 - val_loss: 2168.8244 - val_acc: 0.9457 - val_mDice: 0.4249

Epoch 00041: val_mDice did not improve from 0.45461
Epoch 42/300
 - 10s - loss: 335.8076 - acc: 0.9455 - mDice: 0.7633 - val_loss: 2105.1803 - val_acc: 0.9475 - val_mDice: 0.4399

Epoch 00042: val_mDice did not improve from 0.45461
Epoch 43/300
 - 10s - loss: 333.8265 - acc: 0.9453 - mDice: 0.7647 - val_loss: 2075.6934 - val_acc: 0.9464 - val_mDice: 0.4461

Epoch 00043: val_mDice did not improve from 0.45461
Epoch 44/300
 - 9s - loss: 330.2325 - acc: 0.9455 - mDice: 0.7673 - val_loss: 2319.9583 - val_acc: 0.9457 - val_mDice: 0.4247

Epoch 00044: val_mDice did not improve from 0.45461
Epoch 45/300
 - 10s - loss: 330.0021 - acc: 0.9455 - mDice: 0.7670 - val_loss: 2253.4627 - val_acc: 0.9469 - val_mDice: 0.4285

Epoch 00045: val_mDice did not improve from 0.45461
Epoch 46/300
 - 10s - loss: 329.2670 - acc: 0.9454 - mDice: 0.7681 - val_loss: 2313.3931 - val_acc: 0.9455 - val_mDice: 0.4196

Epoch 00046: val_mDice did not improve from 0.45461
Epoch 47/300
 - 11s - loss: 325.9556 - acc: 0.9454 - mDice: 0.7699 - val_loss: 2410.4279 - val_acc: 0.9454 - val_mDice: 0.4169

Epoch 00047: val_mDice did not improve from 0.45461
Epoch 48/300
 - 10s - loss: 325.8101 - acc: 0.9454 - mDice: 0.7706 - val_loss: 2194.9829 - val_acc: 0.9457 - val_mDice: 0.4295

Epoch 00048: val_mDice did not improve from 0.45461
Epoch 49/300
 - 11s - loss: 323.6584 - acc: 0.9455 - mDice: 0.7721 - val_loss: 2215.2593 - val_acc: 0.9468 - val_mDice: 0.4298

Epoch 00049: val_mDice did not improve from 0.45461
Epoch 50/300
 - 10s - loss: 321.9507 - acc: 0.9454 - mDice: 0.7730 - val_loss: 2060.4132 - val_acc: 0.9470 - val_mDice: 0.4435

Epoch 00050: val_mDice did not improve from 0.45461
Epoch 51/300
 - 10s - loss: 320.3745 - acc: 0.9454 - mDice: 0.7745 - val_loss: 2192.2444 - val_acc: 0.9458 - val_mDice: 0.4342

Epoch 00051: val_mDice did not improve from 0.45461
Epoch 52/300
 - 11s - loss: 317.5261 - acc: 0.9458 - mDice: 0.7758 - val_loss: 2400.8121 - val_acc: 0.9450 - val_mDice: 0.4081

Epoch 00052: val_mDice did not improve from 0.45461
Epoch 53/300
 - 10s - loss: 316.9684 - acc: 0.9457 - mDice: 0.7764 - val_loss: 2281.1457 - val_acc: 0.9460 - val_mDice: 0.4239

Epoch 00053: val_mDice did not improve from 0.45461
Epoch 54/300
 - 10s - loss: 316.3708 - acc: 0.9456 - mDice: 0.7769 - val_loss: 2178.1552 - val_acc: 0.9465 - val_mDice: 0.4417

Epoch 00054: val_mDice did not improve from 0.45461
Epoch 55/300
 - 10s - loss: 314.2728 - acc: 0.9458 - mDice: 0.7786 - val_loss: 2283.5897 - val_acc: 0.9472 - val_mDice: 0.4331

Epoch 00055: val_mDice did not improve from 0.45461
Epoch 56/300
 - 10s - loss: 311.5087 - acc: 0.9458 - mDice: 0.7805 - val_loss: 2310.2044 - val_acc: 0.9455 - val_mDice: 0.4274

Epoch 00056: val_mDice did not improve from 0.45461
Epoch 57/300
 - 10s - loss: 311.9611 - acc: 0.9456 - mDice: 0.7800 - val_loss: 2291.9926 - val_acc: 0.9461 - val_mDice: 0.4256

Epoch 00057: val_mDice did not improve from 0.45461
Epoch 58/300
 - 10s - loss: 309.2845 - acc: 0.9456 - mDice: 0.7820 - val_loss: 2193.3461 - val_acc: 0.9465 - val_mDice: 0.4369

Epoch 00058: val_mDice did not improve from 0.45461
Epoch 59/300
 - 10s - loss: 307.9240 - acc: 0.9457 - mDice: 0.7824 - val_loss: 2214.1892 - val_acc: 0.9473 - val_mDice: 0.4441

Epoch 00059: val_mDice did not improve from 0.45461
Epoch 60/300
 - 10s - loss: 308.0951 - acc: 0.9457 - mDice: 0.7831 - val_loss: 2449.7946 - val_acc: 0.9457 - val_mDice: 0.4219

Epoch 00060: val_mDice did not improve from 0.45461
Epoch 61/300
 - 10s - loss: 308.6514 - acc: 0.9456 - mDice: 0.7827 - val_loss: 2421.6365 - val_acc: 0.9452 - val_mDice: 0.4228

Epoch 00061: val_mDice did not improve from 0.45461
Epoch 62/300
 - 10s - loss: 304.9711 - acc: 0.9457 - mDice: 0.7847 - val_loss: 2292.1247 - val_acc: 0.9470 - val_mDice: 0.4370

Epoch 00062: val_mDice did not improve from 0.45461
Epoch 63/300
 - 9s - loss: 302.6470 - acc: 0.9458 - mDice: 0.7865 - val_loss: 2393.6707 - val_acc: 0.9451 - val_mDice: 0.4218

Epoch 00063: val_mDice did not improve from 0.45461
Epoch 64/300
 - 10s - loss: 302.2508 - acc: 0.9459 - mDice: 0.7867 - val_loss: 2350.5011 - val_acc: 0.9452 - val_mDice: 0.4246

Epoch 00064: val_mDice did not improve from 0.45461
Epoch 65/300
 - 11s - loss: 300.7543 - acc: 0.9458 - mDice: 0.7877 - val_loss: 2427.0338 - val_acc: 0.9448 - val_mDice: 0.4264

Epoch 00065: val_mDice did not improve from 0.45461
Epoch 66/300
 - 10s - loss: 302.3114 - acc: 0.9458 - mDice: 0.7872 - val_loss: 2297.3468 - val_acc: 0.9460 - val_mDice: 0.4348

Epoch 00066: val_mDice did not improve from 0.45461
Epoch 67/300
 - 10s - loss: 299.9175 - acc: 0.9459 - mDice: 0.7888 - val_loss: 2264.8094 - val_acc: 0.9466 - val_mDice: 0.4381

Epoch 00067: val_mDice did not improve from 0.45461
Epoch 68/300
 - 11s - loss: 298.1879 - acc: 0.9459 - mDice: 0.7897 - val_loss: 2230.4685 - val_acc: 0.9468 - val_mDice: 0.4388

Epoch 00068: val_mDice did not improve from 0.45461
Epoch 69/300
 - 10s - loss: 297.1691 - acc: 0.9460 - mDice: 0.7908 - val_loss: 2430.4482 - val_acc: 0.9456 - val_mDice: 0.4210

Epoch 00069: val_mDice did not improve from 0.45461
Epoch 70/300
 - 10s - loss: 295.6311 - acc: 0.9459 - mDice: 0.7913 - val_loss: 2495.5268 - val_acc: 0.9457 - val_mDice: 0.4195

Epoch 00070: val_mDice did not improve from 0.45461
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
{'val_loss': [1366.3234721251897, 1297.4748026359648, 1291.5529048272542, 1510.2667527198792, 1559.7932612441834, 1655.432062500999, 1617.5973540147145, 1644.4155475809462, 1538.6915807894297, 1639.6539947532472, 1646.951670839673, 1683.2323250997633, 1697.3015687806267, 1682.9456512814477, 1788.3755109423682, 1879.3707565125965, 1797.87288914408, 1822.4333588963464, 1893.4349744206384, 1954.1947452681404, 1881.0764069330125, 1914.1198209807985, 1866.2028779869988, 1974.1712458928425, 2020.6356486592974, 2042.101852961949, 2111.1053769247874, 1939.6768284184593, 1980.6250590256282, 1992.1764943486169, 2229.2405931268418, 2255.5090066364833, 2207.237015712829, 2209.3588256835938, 2169.740404832931, 2172.3122029418037, 2045.052340359915, 2012.8298653648012, 2178.870609056382, 1951.7167137577421, 2168.8243791148775, 2105.180268219539, 2075.6933590116955, 2319.9583275885807, 2253.462744871775, 2313.3930582659586, 2410.427851166044, 2194.982861144202, 2215.259332180023, 2060.413221574965, 2192.2444430759974, 2400.8120519887834, 2281.1457412129357, 2178.1551875954583, 2283.5896809895835, 2310.2043726557777, 2291.992564473833, 2193.346073286874, 2214.189152535938, 2449.7945999417984, 2421.63648547445, 2292.12470018296, 2393.6707478477842, 2350.5011273565747, 2427.033815293085, 2297.3468424706234, 2264.8093975612096, 2230.468549614861, 2430.448191631408, 2495.5267998831614], 'val_acc': [0.9327359682037717, 0.9420280428159804, 0.9442899766422453, 0.943971071924482, 0.9450701304844448, 0.9464264398529416, 0.9469154051371983, 0.9471768821988787, 0.9491454050654456, 0.9491432933580308, 0.9476041822206407, 0.9481547389711652, 0.9480973510515123, 0.9477231871514094, 0.947521238099961, 0.9454528064954848, 0.9482525360016596, 0.9479018052419027, 0.9477125973928542, 0.9466305460248675, 0.94779124997911, 0.9466581656819298, 0.9471896205629621, 0.9471237120174226, 0.9470833057448977, 0.9452720880508423, 0.9462202390034994, 0.9465029495103019, 0.9468941149257478, 0.9467240628742036, 0.944440884249551, 0.9454697966575623, 0.9458290962945848, 0.9456058740615845, 0.9460650341851371, 0.9460034228506542, 0.9460161782446361, 0.94649662006469, 0.9467091872578576, 0.9472002358663649, 0.9457227956681025, 0.9475106398264567, 0.9463902938933599, 0.9456994306473505, 0.9469323867843265, 0.9455420743851435, 0.9454060367175511, 0.9456993823959714, 0.9467538339751107, 0.9469791395323617, 0.9457695824759347, 0.9449766335033235, 0.9460459379922777, 0.946524251075018, 0.9472342417353675, 0.9454527781123206, 0.9461373175893512, 0.946536986600785, 0.9473192947251456, 0.9457121803646996, 0.945218943414234, 0.946979182107108, 0.9450531289691017, 0.9451509373528617, 0.9448022785640898, 0.9459566332045055, 0.9466326804388137, 0.9468430933498201, 0.9455548354557582, 0.9456866468702044], 'val_mDice': [0.24838398467926753, 0.33439615794590544, 0.37619299814105034, 0.37645319210631506, 0.389385057701951, 0.3933956449230512, 0.40718819413866314, 0.41382131601373356, 0.4377060190197967, 0.43259475185048013, 0.4284141734242439, 0.4344547978114514, 0.4254132303453627, 0.4347441592032001, 0.42756228237634614, 0.4150639359972307, 0.432983554544903, 0.43187625067574636, 0.4218151196837425, 0.41894089421700864, 0.42975751417023794, 0.43006708331051324, 0.43722414278558325, 0.42809001001573743, 0.4263528844430333, 0.41854305529878255, 0.42030921259096693, 0.4393699170932883, 0.4345173544826962, 0.43367968073913027, 0.41254196794969694, 0.41631385932366055, 0.42209763097621145, 0.4242842626713571, 0.4279167690270004, 0.42847089815352646, 0.4410044914554982, 0.43809940062818076, 0.4335458851641133, 0.45461180256236167, 0.4249145333167343, 0.43991010414347764, 0.4461343485329832, 0.42466502893893493, 0.428532912617638, 0.4196299282567842, 0.41689238058669226, 0.4295032261205571, 0.4297501145019418, 0.4434559482726313, 0.4342386765139444, 0.40805281335044474, 0.4239061308935994, 0.44167680240103174, 0.433072849043778, 0.4274190713961919, 0.4255661161705142, 0.4369185201468922, 0.4440661464773473, 0.4218641955937658, 0.42275758069895564, 0.43696853793447926, 0.4217780769935676, 0.4245559006397213, 0.4264267191645645, 0.4348280695045278, 0.43812158872329054, 0.4388275436524834, 0.4210153282398269, 0.41951960059148924], 'loss': [1845.3264508457894, 980.8199149183807, 811.5004518507808, 713.4638630926023, 650.621161986528, 606.3976611521103, 573.230856006123, 546.8552755484903, 524.9418070910638, 506.3065266268134, 491.48996447064366, 477.80771425304926, 465.35028785718805, 456.7044907778197, 447.6650344616236, 436.62394434007945, 429.69500877155326, 423.37895814812157, 416.68109115562345, 410.5427950463222, 402.58157760475973, 401.43382971259655, 393.06432851302685, 389.1387780717004, 383.54448374447986, 381.06347560937724, 377.6445779588978, 373.7360245259897, 370.22154995102125, 365.6098848559481, 362.811793088867, 361.1950325613792, 357.8588232537191, 354.66390811176643, 354.1156627330703, 348.79836820797675, 345.1554928292928, 344.61961515068845, 342.01840744768697, 339.246769113947, 337.5092650414065, 335.8075733673878, 333.82651717607195, 330.23246783081316, 330.0021016238764, 329.26698896276804, 325.955602995573, 325.8100815363557, 323.65841958682296, 321.95065473531145, 320.37454041245127, 317.5260881814098, 316.96835765173057, 316.3707906775606, 314.27284579610745, 311.50873122206997, 311.96111596046626, 309.28446739230606, 307.9240156048314, 308.09510180751136, 308.65137343280736, 304.9710531328509, 302.6469615923777, 302.25082160945294, 300.7543080618369, 302.31136343937425, 299.91745518158, 298.18788123732935, 297.1691371784611, 295.63111189957505], 'acc': [0.894404970085044, 0.914625807858304, 0.9230919870218837, 0.9280680696100588, 0.9317029223682013, 0.9340590920226753, 0.9356852829950449, 0.936943186853165, 0.9380266211017699, 0.938976777204319, 0.9396994819824053, 0.940361528376382, 0.9407772525831847, 0.9411222096787544, 0.9415024697539295, 0.9419618538286912, 0.9422322113504294, 0.9425141245316329, 0.9427157374092074, 0.9428288271621585, 0.9432570074067448, 0.9433179627454003, 0.9435825785943394, 0.9436642794864634, 0.9438582070075595, 0.9440650051215124, 0.9440249171655992, 0.9441978910972738, 0.9442806225280805, 0.944517887923353, 0.9446596403169751, 0.9445377694105674, 0.9445584902350604, 0.9447831219966779, 0.944869965125261, 0.9447811891146884, 0.9450075227285318, 0.9450487287053259, 0.9451478963898445, 0.9453378262973967, 0.9454275279783297, 0.9455085603722446, 0.945336599845934, 0.9455238168400929, 0.9454809764182152, 0.9454200836604147, 0.9454152617515202, 0.9453687011241821, 0.9455258395140034, 0.9454336821837579, 0.9454328226450208, 0.9457661147427416, 0.9456687514690483, 0.9456062042370729, 0.9457543873823698, 0.9457859942304944, 0.9456248387266313, 0.9456054258718871, 0.9457178505509948, 0.9457018671868646, 0.945570549915263, 0.945746321162898, 0.9457861716769806, 0.9458570450699488, 0.9457693850693042, 0.9458498607510106, 0.9459250608643333, 0.945865050478204, 0.9460299972373671, 0.9458949787781743], 'mDice': [0.2059705695760418, 0.37695859053448855, 0.4583180513206373, 0.5113830762905079, 0.549504536791346, 0.5795603189506074, 0.6009528554655671, 0.6184330735221313, 0.6325329619035892, 0.6456128835609154, 0.6562926430037561, 0.6652948130457209, 0.6738086359243942, 0.6792375659101474, 0.6850689588563852, 0.6932072693588693, 0.6977031132102541, 0.7029559628476705, 0.7069206650095775, 0.7106962059765439, 0.7160510261876518, 0.7177905295312071, 0.7228892647693768, 0.7258290915055291, 0.729691643257097, 0.7315674608604559, 0.7338263361537206, 0.7366485867469049, 0.738755184663659, 0.7421115156954737, 0.7440955935127592, 0.7456303952124989, 0.7473850738733334, 0.7498760744742582, 0.7504429626906104, 0.75430326574865, 0.7564895611198187, 0.757308520332154, 0.7587236996696293, 0.7604822097358755, 0.7619173762907245, 0.7632895571224396, 0.7647208768737231, 0.7672723353610049, 0.7670053655250422, 0.7681444564696702, 0.7699270841816567, 0.7706124240868993, 0.7721369082766368, 0.7730368425764742, 0.7744679610715888, 0.7757959950514927, 0.7764143805203236, 0.7768658104833666, 0.7786436971957131, 0.7804959571864855, 0.7800433070001883, 0.7820201970052232, 0.7824267383391214, 0.7830548204965667, 0.7826656404432359, 0.7846876160703644, 0.7864723613502571, 0.7867287118494201, 0.7877452876817429, 0.7871803662118274, 0.788798289697065, 0.7896606849065884, 0.7908188210578008, 0.7912658593869287]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.69s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.14s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:03,  1.49s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:57,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:48,  1.66s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:08,  1.74s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:46,  1.67s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:23,  1.81s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:45,  1.89s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:51,  1.92s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:34,  1.86s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:56,  1.95s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:08,  2.00s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:21,  2.06s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:26,  2.08s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:29,  2.10s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:21,  2.08s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:07,  2.04s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<08:57,  2.01s/it]predicting train subjects:   6%|▋         | 18/285 [00:35<08:53,  2.00s/it]predicting train subjects:   7%|▋         | 19/285 [00:37<08:44,  1.97s/it]predicting train subjects:   7%|▋         | 20/285 [00:39<08:43,  1.98s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<08:45,  1.99s/it]predicting train subjects:   8%|▊         | 22/285 [00:43<08:41,  1.98s/it]predicting train subjects:   8%|▊         | 23/285 [00:45<08:47,  2.01s/it]predicting train subjects:   8%|▊         | 24/285 [00:47<08:41,  2.00s/it]predicting train subjects:   9%|▉         | 25/285 [00:49<08:30,  1.96s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:20,  1.93s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:24,  1.95s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:25,  1.97s/it]predicting train subjects:  10%|█         | 29/285 [00:56<08:21,  1.96s/it]predicting train subjects:  11%|█         | 30/285 [00:58<08:14,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [01:00<08:19,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [01:02<08:15,  1.96s/it]predicting train subjects:  12%|█▏        | 33/285 [01:04<08:11,  1.95s/it]predicting train subjects:  12%|█▏        | 34/285 [01:06<08:08,  1.95s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<08:02,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<08:03,  1.94s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<07:55,  1.92s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<07:53,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<07:48,  1.90s/it]predicting train subjects:  14%|█▍        | 40/285 [01:17<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:19<07:32,  1.85s/it]predicting train subjects:  15%|█▍        | 42/285 [01:21<07:26,  1.84s/it]predicting train subjects:  15%|█▌        | 43/285 [01:23<07:24,  1.84s/it]predicting train subjects:  15%|█▌        | 44/285 [01:25<07:29,  1.87s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:28,  1.87s/it]predicting train subjects:  16%|█▌        | 46/285 [01:28<07:07,  1.79s/it]predicting train subjects:  16%|█▋        | 47/285 [01:30<07:02,  1.78s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<06:58,  1.77s/it]predicting train subjects:  17%|█▋        | 49/285 [01:33<06:47,  1.73s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<06:40,  1.71s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<06:38,  1.70s/it]predicting train subjects:  18%|█▊        | 52/285 [01:38<06:30,  1.68s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<06:40,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<06:26,  1.67s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<06:26,  1.68s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<06:38,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:30,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:49<06:32,  1.73s/it]predicting train subjects:  21%|██        | 59/285 [01:50<06:31,  1.73s/it]predicting train subjects:  21%|██        | 60/285 [01:52<06:23,  1.71s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:24,  1.72s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<06:32,  1.76s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:24,  1.73s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:20,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:32,  1.79s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:42,  1.84s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:25,  1.77s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:19,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:17,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:11,  1.73s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:13,  1.75s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:02,  1.70s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:02,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:09,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<06:09,  1.76s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:15,  1.80s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:08,  1.77s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:02,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<05:53,  1.72s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<05:47,  1.70s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<05:40,  1.67s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<05:39,  1.67s/it]predicting train subjects:  29%|██▉       | 83/285 [02:32<05:48,  1.72s/it]predicting train subjects:  29%|██▉       | 84/285 [02:34<05:52,  1.75s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<06:04,  1.82s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:04,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:40<06:05,  1.85s/it]predicting train subjects:  31%|███       | 88/285 [02:41<06:00,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:43<06:00,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<05:57,  1.83s/it]predicting train subjects:  32%|███▏      | 91/285 [02:47<05:53,  1.82s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<05:54,  1.84s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<06:01,  1.88s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<06:04,  1.91s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<06:09,  1.95s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<06:05,  1.94s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<06:01,  1.92s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<05:56,  1.92s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<05:54,  1.92s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<05:59,  1.95s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<05:59,  1.96s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:52,  1.94s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:43,  1.90s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:40,  1.89s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:40,  1.90s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:40,  1.91s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:43,  1.94s/it]predicting train subjects:  38%|███▊      | 109/285 [03:22<05:35,  1.91s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:27,  1.87s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:22,  1.86s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:21,  1.86s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:15,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:12,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:08,  1.82s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:05,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:02,  1.81s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:08,  1.86s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<05:06,  1.86s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<05:00,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:45,  1.75s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:27,  1.65s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:24,  1.64s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:27,  1.67s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:23,  1.66s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:20,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<04:17,  1.64s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:25,  1.70s/it]predicting train subjects:  46%|████▌     | 130/285 [03:58<04:28,  1.73s/it]predicting train subjects:  46%|████▌     | 131/285 [04:00<04:35,  1.79s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:31,  1.78s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:33,  1.80s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:26,  1.76s/it]predicting train subjects:  47%|████▋     | 135/285 [04:08<04:32,  1.82s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<04:29,  1.81s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<04:20,  1.76s/it]predicting train subjects:  48%|████▊     | 138/285 [04:13<04:14,  1.73s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<04:11,  1.72s/it]predicting train subjects:  49%|████▉     | 140/285 [04:16<04:07,  1.71s/it]predicting train subjects:  49%|████▉     | 141/285 [04:18<04:03,  1.69s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<03:57,  1.66s/it]predicting train subjects:  50%|█████     | 143/285 [04:21<03:55,  1.66s/it]predicting train subjects:  51%|█████     | 144/285 [04:23<03:55,  1.67s/it]predicting train subjects:  51%|█████     | 145/285 [04:24<03:45,  1.61s/it]predicting train subjects:  51%|█████     | 146/285 [04:26<03:34,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:27<03:27,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:29<03:30,  1.54s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:30<03:29,  1.54s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:25,  1.52s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:33<03:23,  1.52s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:36<03:11,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:10,  1.45s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:39<03:10,  1.46s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:40<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<03:18,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:44<03:18,  1.56s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:45<03:11,  1.52s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:05,  1.48s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:48<03:00,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<02:56,  1.44s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:51<02:52,  1.41s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<02:54,  1.44s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:54<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<02:55,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:57<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:58<02:57,  1.52s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:00<02:55,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<02:54,  1.52s/it]predicting train subjects:  60%|██████    | 171/285 [05:03<02:53,  1.52s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<02:48,  1.49s/it]predicting train subjects:  61%|██████    | 173/285 [05:06<02:49,  1.51s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:50,  1.54s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:09<02:48,  1.53s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<02:46,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:12<02:43,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:37,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:36,  1.49s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:39,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:19<02:40,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:21<02:38,  1.56s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:22<02:32,  1.51s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:24<02:27,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:25<02:30,  1.52s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:27<02:26,  1.50s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:28<02:23,  1.48s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:30<02:21,  1.47s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:31<02:19,  1.47s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:33<02:19,  1.48s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:21,  1.52s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:36<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:37<02:15,  1.49s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:39<02:18,  1.54s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:41<02:28,  1.67s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:43<02:28,  1.69s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:45<02:34,  1.78s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:47<02:35,  1.81s/it]predicting train subjects:  70%|███████   | 200/285 [05:48<02:29,  1.76s/it]predicting train subjects:  71%|███████   | 201/285 [05:50<02:31,  1.81s/it]predicting train subjects:  71%|███████   | 202/285 [05:52<02:31,  1.82s/it]predicting train subjects:  71%|███████   | 203/285 [05:54<02:29,  1.83s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:56<02:28,  1.83s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:57<02:26,  1.83s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:59<02:23,  1.81s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:01<02:23,  1.85s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:03<02:21,  1.83s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:05<02:19,  1.84s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<02:16,  1.82s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:08<02:12,  1.79s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:10<02:14,  1.84s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:12<02:12,  1.84s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:14<02:06,  1.79s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:16<02:09,  1.85s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<02:03,  1.79s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:58,  1.74s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:21<01:54,  1.71s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:24<01:47,  1.66s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:26<01:47,  1.68s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:46,  1.68s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:29<01:42,  1.66s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:31<01:41,  1.66s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:32<01:39,  1.66s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:34<01:39,  1.68s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:36<01:39,  1.71s/it]predicting train subjects:  80%|████████  | 228/285 [06:38<01:38,  1.72s/it]predicting train subjects:  80%|████████  | 229/285 [06:39<01:35,  1.71s/it]predicting train subjects:  81%|████████  | 230/285 [06:41<01:34,  1.72s/it]predicting train subjects:  81%|████████  | 231/285 [06:42<01:29,  1.65s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:45<01:38,  1.85s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:47<01:40,  1.93s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:49<01:40,  1.98s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:51<01:40,  2.01s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:53<01:37,  1.99s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:55<01:37,  2.03s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:57<01:36,  2.04s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:59<01:35,  2.07s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:01<01:32,  2.06s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:03<01:30,  2.06s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:06<01:28,  2.07s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:07<01:24,  2.00s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:09<01:20,  1.95s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:11<01:17,  1.95s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:13<01:15,  1.93s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:15<01:12,  1.92s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:17<01:10,  1.91s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:19<01:09,  1.92s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:20<01:04,  1.84s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:22<00:59,  1.75s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:23<00:54,  1.64s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:25<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:26<00:48,  1.56s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:28<00:45,  1.50s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:29<00:42,  1.47s/it]predicting train subjects:  90%|█████████ | 257/285 [07:31<00:40,  1.45s/it]predicting train subjects:  91%|█████████ | 258/285 [07:32<00:38,  1.42s/it]predicting train subjects:  91%|█████████ | 259/285 [07:33<00:37,  1.42s/it]predicting train subjects:  91%|█████████ | 260/285 [07:35<00:35,  1.41s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:36<00:34,  1.42s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:38<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:39<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:41<00:30,  1.47s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:42<00:29,  1.48s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:44<00:28,  1.49s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:45<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:47<00:28,  1.66s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:49<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:51<00:27,  1.84s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:53<00:26,  1.92s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:55<00:25,  1.99s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:58<00:24,  2.03s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:00<00:22,  2.02s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:01<00:20,  2.00s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:04<00:18,  2.03s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:06<00:16,  2.07s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:08<00:14,  2.05s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:10<00:12,  2.01s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:11<00:09,  1.95s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:13<00:07,  1.92s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:15<00:05,  1.95s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:18<00:04,  2.03s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:20<00:02,  2.08s/it]predicting train subjects: 100%|██████████| 285/285 [08:22<00:00,  2.05s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:51,  1.66s/it]Loading train:   1%|          | 2/285 [00:03<08:32,  1.81s/it]Loading train:   1%|          | 3/285 [00:05<08:50,  1.88s/it]Loading train:   1%|▏         | 4/285 [00:08<09:28,  2.02s/it]Loading train:   2%|▏         | 5/285 [00:10<09:50,  2.11s/it]Loading train:   2%|▏         | 6/285 [00:12<09:59,  2.15s/it]Loading train:   2%|▏         | 7/285 [00:15<10:07,  2.19s/it]Loading train:   3%|▎         | 8/285 [00:17<10:44,  2.33s/it]Loading train:   3%|▎         | 9/285 [00:19<10:06,  2.20s/it]Loading train:   4%|▎         | 10/285 [00:21<10:18,  2.25s/it]Loading train:   4%|▍         | 11/285 [00:24<10:10,  2.23s/it]Loading train:   4%|▍         | 12/285 [00:26<10:01,  2.20s/it]Loading train:   5%|▍         | 13/285 [00:28<09:46,  2.15s/it]Loading train:   5%|▍         | 14/285 [00:31<10:25,  2.31s/it]Loading train:   5%|▌         | 15/285 [00:33<10:15,  2.28s/it]Loading train:   6%|▌         | 16/285 [00:35<10:13,  2.28s/it]Loading train:   6%|▌         | 17/285 [00:37<09:32,  2.14s/it]Loading train:   6%|▋         | 18/285 [00:39<09:20,  2.10s/it]Loading train:   7%|▋         | 19/285 [00:41<08:57,  2.02s/it]Loading train:   7%|▋         | 20/285 [00:43<08:49,  2.00s/it]Loading train:   7%|▋         | 21/285 [00:45<08:44,  1.99s/it]Loading train:   8%|▊         | 22/285 [00:47<08:49,  2.01s/it]Loading train:   8%|▊         | 23/285 [00:49<09:11,  2.11s/it]Loading train:   8%|▊         | 24/285 [00:51<09:08,  2.10s/it]Loading train:   9%|▉         | 25/285 [00:53<09:06,  2.10s/it]Loading train:   9%|▉         | 26/285 [00:55<09:02,  2.09s/it]Loading train:   9%|▉         | 27/285 [00:57<08:32,  1.99s/it]Loading train:  10%|▉         | 28/285 [00:59<08:19,  1.94s/it]Loading train:  10%|█         | 29/285 [01:00<07:51,  1.84s/it]Loading train:  11%|█         | 30/285 [01:02<07:25,  1.75s/it]Loading train:  11%|█         | 31/285 [01:04<07:59,  1.89s/it]Loading train:  11%|█         | 32/285 [01:06<07:50,  1.86s/it]Loading train:  12%|█▏        | 33/285 [01:08<07:59,  1.90s/it]Loading train:  12%|█▏        | 34/285 [01:10<07:58,  1.91s/it]Loading train:  12%|█▏        | 35/285 [01:11<07:30,  1.80s/it]Loading train:  13%|█▎        | 36/285 [01:13<07:31,  1.81s/it]Loading train:  13%|█▎        | 37/285 [01:15<07:44,  1.87s/it]Loading train:  13%|█▎        | 38/285 [01:17<07:55,  1.92s/it]Loading train:  14%|█▎        | 39/285 [01:20<09:17,  2.27s/it]Loading train:  14%|█▍        | 40/285 [01:22<08:53,  2.18s/it]Loading train:  14%|█▍        | 41/285 [01:25<09:10,  2.26s/it]Loading train:  15%|█▍        | 42/285 [01:27<08:39,  2.14s/it]Loading train:  15%|█▌        | 43/285 [01:29<08:24,  2.09s/it]Loading train:  15%|█▌        | 44/285 [01:30<08:07,  2.02s/it]Loading train:  16%|█▌        | 45/285 [01:32<08:01,  2.01s/it]Loading train:  16%|█▌        | 46/285 [01:34<07:46,  1.95s/it]Loading train:  16%|█▋        | 47/285 [01:36<08:02,  2.03s/it]Loading train:  17%|█▋        | 48/285 [01:38<07:39,  1.94s/it]Loading train:  17%|█▋        | 49/285 [01:40<07:21,  1.87s/it]Loading train:  18%|█▊        | 50/285 [01:42<07:36,  1.94s/it]Loading train:  18%|█▊        | 51/285 [01:44<07:18,  1.87s/it]Loading train:  18%|█▊        | 52/285 [01:46<07:17,  1.88s/it]Loading train:  19%|█▊        | 53/285 [01:48<07:45,  2.00s/it]Loading train:  19%|█▉        | 54/285 [01:50<07:59,  2.07s/it]Loading train:  19%|█▉        | 55/285 [01:52<07:37,  1.99s/it]Loading train:  20%|█▉        | 56/285 [01:54<07:12,  1.89s/it]Loading train:  20%|██        | 57/285 [01:55<06:54,  1.82s/it]Loading train:  20%|██        | 58/285 [01:57<06:58,  1.84s/it]Loading train:  21%|██        | 59/285 [01:59<06:59,  1.86s/it]Loading train:  21%|██        | 60/285 [02:01<06:50,  1.82s/it]Loading train:  21%|██▏       | 61/285 [02:03<07:20,  1.97s/it]Loading train:  22%|██▏       | 62/285 [02:05<07:00,  1.89s/it]Loading train:  22%|██▏       | 63/285 [02:07<07:14,  1.96s/it]Loading train:  22%|██▏       | 64/285 [02:09<07:27,  2.02s/it]Loading train:  23%|██▎       | 65/285 [02:12<08:02,  2.19s/it]Loading train:  23%|██▎       | 66/285 [02:14<08:16,  2.27s/it]Loading train:  24%|██▎       | 67/285 [02:16<07:46,  2.14s/it]Loading train:  24%|██▍       | 68/285 [02:18<07:44,  2.14s/it]Loading train:  24%|██▍       | 69/285 [02:20<07:29,  2.08s/it]Loading train:  25%|██▍       | 70/285 [02:22<07:49,  2.18s/it]Loading train:  25%|██▍       | 71/285 [02:25<07:37,  2.14s/it]Loading train:  25%|██▌       | 72/285 [02:26<07:17,  2.05s/it]Loading train:  26%|██▌       | 73/285 [02:28<07:00,  1.98s/it]Loading train:  26%|██▌       | 74/285 [02:30<06:53,  1.96s/it]Loading train:  26%|██▋       | 75/285 [02:32<06:42,  1.92s/it]Loading train:  27%|██▋       | 76/285 [02:34<06:47,  1.95s/it]Loading train:  27%|██▋       | 77/285 [02:36<06:39,  1.92s/it]Loading train:  27%|██▋       | 78/285 [02:38<06:45,  1.96s/it]Loading train:  28%|██▊       | 79/285 [02:40<06:48,  1.98s/it]Loading train:  28%|██▊       | 80/285 [02:42<06:55,  2.03s/it]Loading train:  28%|██▊       | 81/285 [02:44<06:42,  1.97s/it]Loading train:  29%|██▉       | 82/285 [02:46<06:53,  2.04s/it]Loading train:  29%|██▉       | 83/285 [02:48<07:03,  2.10s/it]Loading train:  29%|██▉       | 84/285 [02:50<07:07,  2.13s/it]Loading train:  30%|██▉       | 85/285 [02:53<07:06,  2.13s/it]Loading train:  30%|███       | 86/285 [02:55<06:56,  2.09s/it]Loading train:  31%|███       | 87/285 [02:57<07:14,  2.19s/it]Loading train:  31%|███       | 88/285 [02:59<06:57,  2.12s/it]Loading train:  31%|███       | 89/285 [03:01<06:53,  2.11s/it]Loading train:  32%|███▏      | 90/285 [03:03<06:38,  2.05s/it]Loading train:  32%|███▏      | 91/285 [03:05<06:44,  2.09s/it]Loading train:  32%|███▏      | 92/285 [03:07<06:34,  2.04s/it]Loading train:  33%|███▎      | 93/285 [03:09<06:46,  2.12s/it]Loading train:  33%|███▎      | 94/285 [03:11<06:37,  2.08s/it]Loading train:  33%|███▎      | 95/285 [03:13<06:22,  2.01s/it]Loading train:  34%|███▎      | 96/285 [03:15<06:13,  1.98s/it]Loading train:  34%|███▍      | 97/285 [03:17<06:27,  2.06s/it]Loading train:  34%|███▍      | 98/285 [03:20<06:37,  2.13s/it]Loading train:  35%|███▍      | 99/285 [03:21<06:13,  2.01s/it]Loading train:  35%|███▌      | 100/285 [03:23<06:05,  1.98s/it]Loading train:  35%|███▌      | 101/285 [03:25<05:57,  1.94s/it]Loading train:  36%|███▌      | 102/285 [03:27<06:05,  2.00s/it]Loading train:  36%|███▌      | 103/285 [03:29<06:13,  2.05s/it]Loading train:  36%|███▋      | 104/285 [03:31<06:05,  2.02s/it]Loading train:  37%|███▋      | 105/285 [03:34<06:07,  2.04s/it]Loading train:  37%|███▋      | 106/285 [03:36<06:12,  2.08s/it]Loading train:  38%|███▊      | 107/285 [03:38<06:26,  2.17s/it]Loading train:  38%|███▊      | 108/285 [03:41<06:44,  2.28s/it]Loading train:  38%|███▊      | 109/285 [03:44<07:26,  2.54s/it]Loading train:  39%|███▊      | 110/285 [03:47<07:47,  2.67s/it]Loading train:  39%|███▉      | 111/285 [03:50<07:56,  2.74s/it]Loading train:  39%|███▉      | 112/285 [03:52<07:47,  2.70s/it]Loading train:  40%|███▉      | 113/285 [03:54<06:54,  2.41s/it]Loading train:  40%|████      | 114/285 [03:56<06:28,  2.27s/it]Loading train:  40%|████      | 115/285 [03:58<06:19,  2.23s/it]Loading train:  41%|████      | 116/285 [04:00<05:45,  2.05s/it]Loading train:  41%|████      | 117/285 [04:01<05:16,  1.89s/it]Loading train:  41%|████▏     | 118/285 [04:03<04:55,  1.77s/it]Loading train:  42%|████▏     | 119/285 [04:04<04:30,  1.63s/it]Loading train:  42%|████▏     | 120/285 [04:06<04:42,  1.71s/it]Loading train:  42%|████▏     | 121/285 [04:08<04:51,  1.78s/it]Loading train:  43%|████▎     | 122/285 [04:09<04:41,  1.73s/it]Loading train:  43%|████▎     | 123/285 [04:11<04:36,  1.71s/it]Loading train:  44%|████▎     | 124/285 [04:12<04:13,  1.57s/it]Loading train:  44%|████▍     | 125/285 [04:14<03:56,  1.48s/it]Loading train:  44%|████▍     | 126/285 [04:15<03:50,  1.45s/it]Loading train:  45%|████▍     | 127/285 [04:16<03:50,  1.46s/it]Loading train:  45%|████▍     | 128/285 [04:17<03:28,  1.33s/it]Loading train:  45%|████▌     | 129/285 [04:19<03:17,  1.27s/it]Loading train:  46%|████▌     | 130/285 [04:20<03:18,  1.28s/it]Loading train:  46%|████▌     | 131/285 [04:21<03:15,  1.27s/it]Loading train:  46%|████▋     | 132/285 [04:22<03:17,  1.29s/it]Loading train:  47%|████▋     | 133/285 [04:24<03:13,  1.28s/it]Loading train:  47%|████▋     | 134/285 [04:25<03:13,  1.28s/it]Loading train:  47%|████▋     | 135/285 [04:26<03:16,  1.31s/it]Loading train:  48%|████▊     | 136/285 [04:27<03:04,  1.24s/it]Loading train:  48%|████▊     | 137/285 [04:29<02:57,  1.20s/it]Loading train:  48%|████▊     | 138/285 [04:30<02:52,  1.17s/it]Loading train:  49%|████▉     | 139/285 [04:31<02:58,  1.22s/it]Loading train:  49%|████▉     | 140/285 [04:32<02:52,  1.19s/it]Loading train:  49%|████▉     | 141/285 [04:33<02:46,  1.16s/it]Loading train:  50%|████▉     | 142/285 [04:34<02:38,  1.11s/it]Loading train:  50%|█████     | 143/285 [04:35<02:32,  1.08s/it]Loading train:  51%|█████     | 144/285 [04:36<02:27,  1.05s/it]Loading train:  51%|█████     | 145/285 [04:37<02:27,  1.06s/it]Loading train:  51%|█████     | 146/285 [04:38<02:22,  1.02s/it]Loading train:  52%|█████▏    | 147/285 [04:39<02:22,  1.03s/it]Loading train:  52%|█████▏    | 148/285 [04:40<02:19,  1.02s/it]Loading train:  52%|█████▏    | 149/285 [04:41<02:22,  1.04s/it]Loading train:  53%|█████▎    | 150/285 [04:42<02:21,  1.05s/it]Loading train:  53%|█████▎    | 151/285 [04:44<02:23,  1.07s/it]Loading train:  53%|█████▎    | 152/285 [04:45<02:26,  1.10s/it]Loading train:  54%|█████▎    | 153/285 [04:46<02:33,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [04:47<02:29,  1.14s/it]Loading train:  54%|█████▍    | 155/285 [04:48<02:27,  1.14s/it]Loading train:  55%|█████▍    | 156/285 [04:49<02:25,  1.13s/it]Loading train:  55%|█████▌    | 157/285 [04:50<02:17,  1.07s/it]Loading train:  55%|█████▌    | 158/285 [04:51<02:13,  1.05s/it]Loading train:  56%|█████▌    | 159/285 [04:53<02:31,  1.20s/it]Loading train:  56%|█████▌    | 160/285 [04:54<02:41,  1.29s/it]Loading train:  56%|█████▋    | 161/285 [04:55<02:30,  1.21s/it]Loading train:  57%|█████▋    | 162/285 [04:56<02:25,  1.18s/it]Loading train:  57%|█████▋    | 163/285 [04:58<02:24,  1.18s/it]Loading train:  58%|█████▊    | 164/285 [04:59<02:22,  1.18s/it]Loading train:  58%|█████▊    | 165/285 [05:00<02:26,  1.22s/it]Loading train:  58%|█████▊    | 166/285 [05:02<02:34,  1.30s/it]Loading train:  59%|█████▊    | 167/285 [05:03<02:28,  1.26s/it]Loading train:  59%|█████▉    | 168/285 [05:04<02:28,  1.27s/it]Loading train:  59%|█████▉    | 169/285 [05:06<02:38,  1.37s/it]Loading train:  60%|█████▉    | 170/285 [05:07<02:36,  1.36s/it]Loading train:  60%|██████    | 171/285 [05:08<02:34,  1.36s/it]Loading train:  60%|██████    | 172/285 [05:10<02:40,  1.42s/it]Loading train:  61%|██████    | 173/285 [05:11<02:36,  1.40s/it]Loading train:  61%|██████    | 174/285 [05:13<02:45,  1.49s/it]Loading train:  61%|██████▏   | 175/285 [05:15<02:45,  1.50s/it]Loading train:  62%|██████▏   | 176/285 [05:16<02:36,  1.43s/it]Loading train:  62%|██████▏   | 177/285 [05:17<02:23,  1.33s/it]Loading train:  62%|██████▏   | 178/285 [05:18<02:21,  1.32s/it]Loading train:  63%|██████▎   | 179/285 [05:19<02:18,  1.31s/it]Loading train:  63%|██████▎   | 180/285 [05:21<02:19,  1.33s/it]Loading train:  64%|██████▎   | 181/285 [05:23<02:34,  1.49s/it]Loading train:  64%|██████▍   | 182/285 [05:24<02:26,  1.42s/it]Loading train:  64%|██████▍   | 183/285 [05:26<02:36,  1.53s/it]Loading train:  65%|██████▍   | 184/285 [05:27<02:30,  1.49s/it]Loading train:  65%|██████▍   | 185/285 [05:29<02:43,  1.64s/it]Loading train:  65%|██████▌   | 186/285 [05:31<02:41,  1.63s/it]Loading train:  66%|██████▌   | 187/285 [05:32<02:24,  1.48s/it]Loading train:  66%|██████▌   | 188/285 [05:33<02:15,  1.39s/it]Loading train:  66%|██████▋   | 189/285 [05:34<02:01,  1.26s/it]Loading train:  67%|██████▋   | 190/285 [05:35<01:59,  1.26s/it]Loading train:  67%|██████▋   | 191/285 [05:37<02:02,  1.30s/it]Loading train:  67%|██████▋   | 192/285 [05:38<02:04,  1.34s/it]Loading train:  68%|██████▊   | 193/285 [05:39<01:59,  1.30s/it]Loading train:  68%|██████▊   | 194/285 [05:40<01:49,  1.20s/it]Loading train:  68%|██████▊   | 195/285 [05:41<01:42,  1.13s/it]Loading train:  69%|██████▉   | 196/285 [05:43<01:48,  1.22s/it]Loading train:  69%|██████▉   | 197/285 [05:45<02:05,  1.42s/it]Loading train:  69%|██████▉   | 198/285 [05:46<02:11,  1.51s/it]Loading train:  70%|██████▉   | 199/285 [05:48<02:16,  1.59s/it]Loading train:  70%|███████   | 200/285 [05:49<02:05,  1.48s/it]Loading train:  71%|███████   | 201/285 [05:51<02:06,  1.51s/it]Loading train:  71%|███████   | 202/285 [05:52<02:04,  1.50s/it]Loading train:  71%|███████   | 203/285 [05:54<02:00,  1.47s/it]Loading train:  72%|███████▏  | 204/285 [05:55<02:04,  1.54s/it]Loading train:  72%|███████▏  | 205/285 [05:57<01:52,  1.40s/it]Loading train:  72%|███████▏  | 206/285 [05:58<01:49,  1.39s/it]Loading train:  73%|███████▎  | 207/285 [05:59<01:41,  1.31s/it]Loading train:  73%|███████▎  | 208/285 [06:00<01:42,  1.33s/it]Loading train:  73%|███████▎  | 209/285 [06:02<01:53,  1.50s/it]Loading train:  74%|███████▎  | 210/285 [06:04<02:01,  1.62s/it]Loading train:  74%|███████▍  | 211/285 [06:06<02:08,  1.74s/it]Loading train:  74%|███████▍  | 212/285 [06:07<01:56,  1.60s/it]Loading train:  75%|███████▍  | 213/285 [06:09<01:51,  1.55s/it]Loading train:  75%|███████▌  | 214/285 [06:10<01:41,  1.43s/it]Loading train:  75%|███████▌  | 215/285 [06:11<01:40,  1.43s/it]Loading train:  76%|███████▌  | 216/285 [06:13<01:33,  1.35s/it]Loading train:  76%|███████▌  | 217/285 [06:14<01:26,  1.26s/it]Loading train:  76%|███████▋  | 218/285 [06:15<01:21,  1.22s/it]Loading train:  77%|███████▋  | 219/285 [06:16<01:15,  1.14s/it]Loading train:  77%|███████▋  | 220/285 [06:17<01:22,  1.26s/it]Loading train:  78%|███████▊  | 221/285 [06:18<01:18,  1.22s/it]Loading train:  78%|███████▊  | 222/285 [06:20<01:13,  1.17s/it]Loading train:  78%|███████▊  | 223/285 [06:21<01:14,  1.20s/it]Loading train:  79%|███████▊  | 224/285 [06:22<01:13,  1.20s/it]Loading train:  79%|███████▉  | 225/285 [06:24<01:19,  1.33s/it]Loading train:  79%|███████▉  | 226/285 [06:25<01:24,  1.43s/it]Loading train:  80%|███████▉  | 227/285 [06:27<01:27,  1.51s/it]Loading train:  80%|████████  | 228/285 [06:28<01:18,  1.38s/it]Loading train:  80%|████████  | 229/285 [06:29<01:13,  1.30s/it]Loading train:  81%|████████  | 230/285 [06:30<01:07,  1.22s/it]Loading train:  81%|████████  | 231/285 [06:31<01:03,  1.18s/it]Loading train:  81%|████████▏ | 232/285 [06:33<01:14,  1.41s/it]Loading train:  82%|████████▏ | 233/285 [06:35<01:13,  1.42s/it]Loading train:  82%|████████▏ | 234/285 [06:36<01:08,  1.35s/it]Loading train:  82%|████████▏ | 235/285 [06:37<01:05,  1.32s/it]Loading train:  83%|████████▎ | 236/285 [06:38<01:03,  1.30s/it]Loading train:  83%|████████▎ | 237/285 [06:40<01:13,  1.53s/it]Loading train:  84%|████████▎ | 238/285 [06:42<01:08,  1.46s/it]Loading train:  84%|████████▍ | 239/285 [06:43<01:03,  1.38s/it]Loading train:  84%|████████▍ | 240/285 [06:45<01:05,  1.45s/it]Loading train:  85%|████████▍ | 241/285 [06:46<01:07,  1.54s/it]Loading train:  85%|████████▍ | 242/285 [06:48<01:04,  1.50s/it]Loading train:  85%|████████▌ | 243/285 [06:49<01:01,  1.46s/it]Loading train:  86%|████████▌ | 244/285 [06:50<00:58,  1.43s/it]Loading train:  86%|████████▌ | 245/285 [06:52<00:55,  1.38s/it]Loading train:  86%|████████▋ | 246/285 [06:53<00:51,  1.32s/it]Loading train:  87%|████████▋ | 247/285 [06:54<00:48,  1.28s/it]Loading train:  87%|████████▋ | 248/285 [06:55<00:44,  1.21s/it]Loading train:  87%|████████▋ | 249/285 [06:56<00:44,  1.23s/it]Loading train:  88%|████████▊ | 250/285 [06:58<00:43,  1.23s/it]Loading train:  88%|████████▊ | 251/285 [06:59<00:38,  1.14s/it]Loading train:  88%|████████▊ | 252/285 [07:00<00:37,  1.13s/it]Loading train:  89%|████████▉ | 253/285 [07:01<00:34,  1.07s/it]Loading train:  89%|████████▉ | 254/285 [07:02<00:32,  1.05s/it]Loading train:  89%|████████▉ | 255/285 [07:03<00:31,  1.03s/it]Loading train:  90%|████████▉ | 256/285 [07:04<00:29,  1.02s/it]Loading train:  90%|█████████ | 257/285 [07:05<00:28,  1.03s/it]Loading train:  91%|█████████ | 258/285 [07:06<00:27,  1.01s/it]Loading train:  91%|█████████ | 259/285 [07:07<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [07:08<00:26,  1.06s/it]Loading train:  92%|█████████▏| 261/285 [07:09<00:24,  1.02s/it]Loading train:  92%|█████████▏| 262/285 [07:10<00:23,  1.00s/it]Loading train:  92%|█████████▏| 263/285 [07:11<00:21,  1.00it/s]Loading train:  93%|█████████▎| 264/285 [07:12<00:20,  1.02it/s]Loading train:  93%|█████████▎| 265/285 [07:13<00:20,  1.03s/it]Loading train:  93%|█████████▎| 266/285 [07:14<00:18,  1.00it/s]Loading train:  94%|█████████▎| 267/285 [07:15<00:17,  1.02it/s]Loading train:  94%|█████████▍| 268/285 [07:16<00:17,  1.05s/it]Loading train:  94%|█████████▍| 269/285 [07:17<00:17,  1.09s/it]Loading train:  95%|█████████▍| 270/285 [07:18<00:17,  1.15s/it]Loading train:  95%|█████████▌| 271/285 [07:20<00:16,  1.19s/it]Loading train:  95%|█████████▌| 272/285 [07:21<00:15,  1.20s/it]Loading train:  96%|█████████▌| 273/285 [07:22<00:14,  1.21s/it]Loading train:  96%|█████████▌| 274/285 [07:23<00:13,  1.26s/it]Loading train:  96%|█████████▋| 275/285 [07:25<00:12,  1.26s/it]Loading train:  97%|█████████▋| 276/285 [07:26<00:11,  1.23s/it]Loading train:  97%|█████████▋| 277/285 [07:27<00:10,  1.26s/it]Loading train:  98%|█████████▊| 278/285 [07:28<00:08,  1.26s/it]Loading train:  98%|█████████▊| 279/285 [07:30<00:07,  1.24s/it]Loading train:  98%|█████████▊| 280/285 [07:31<00:06,  1.22s/it]Loading train:  99%|█████████▊| 281/285 [07:32<00:04,  1.22s/it]Loading train:  99%|█████████▉| 282/285 [07:33<00:03,  1.20s/it]Loading train:  99%|█████████▉| 283/285 [07:34<00:02,  1.21s/it]Loading train: 100%|█████████▉| 284/285 [07:36<00:01,  1.20s/it]Loading train: 100%|██████████| 285/285 [07:37<00:00,  1.20s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 62.72it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:06, 42.55it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:06, 43.54it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:05, 47.57it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:04, 56.02it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:03, 71.17it/s]concatenating: train:  27%|██▋       | 77/285 [00:00<00:02, 90.61it/s]concatenating: train:  34%|███▍      | 98/285 [00:00<00:01, 108.56it/s]concatenating: train:  40%|████      | 115/285 [00:03<00:08, 19.59it/s]concatenating: train:  45%|████▍     | 127/285 [00:03<00:06, 25.72it/s]concatenating: train:  54%|█████▍    | 154/285 [00:03<00:03, 35.29it/s]concatenating: train:  64%|██████▍   | 182/285 [00:03<00:02, 47.77it/s]concatenating: train:  73%|███████▎  | 209/285 [00:03<00:01, 63.37it/s]concatenating: train:  82%|████████▏ | 234/285 [00:03<00:00, 81.51it/s]concatenating: train:  91%|█████████ | 260/285 [00:04<00:00, 102.26it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 69.12it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.58s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.50s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 518.16it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 40)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 80)   28880       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 80)     0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 7, 7, 80)     0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 7, 7, 160)    115360      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 7, 7, 160)    640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 7, 7, 160)    0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 7, 7, 160)    230560      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 7, 7, 160)    640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 7, 7, 160)    0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 7, 7, 160)    0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 80)   51280       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 14, 14, 160)  0           conv2d_transpose_1[0][0]         2019-06-30 23:43:54.705051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-06-30 23:43:54.705144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 23:43:54.705158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-06-30 23:43:54.705167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-06-30 23:43:54.705574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 14, 80)   115280      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 14, 80)   320         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 14, 80)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 14, 80)   57680       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 14, 80)   320         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 14, 80)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 14, 80)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 40)   12840       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 40)   28840       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 28, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 28, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 40)   14440       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 28, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 28, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 28, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 56, 56, 20)   3220        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 56, 40)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 56, 20)   7220        concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 56, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 56, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 56, 20)   3620        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 56, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 56, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 56, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 56, 13)   273         dropout_7[0][0]                  
==================================================================================================
Total params: 756,193
Trainable params: 754,433
Non-trainable params: 1,760
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [2.84556655e+01 1.40109011e+01 3.28839521e+01 4.08704613e+00
 1.18795059e+01 3.09772677e+00 3.70666155e+01 4.93844078e+01
 3.77168295e+01 5.80852460e+00 1.28966869e+02 8.44275505e+01
 8.52866433e-02]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 21s - loss: 1478.0490 - acc: 0.9079 - mDice: 0.2128 - val_loss: 1066.8794 - val_acc: 0.9362 - val_mDice: 0.3500

Epoch 00001: val_mDice improved from -inf to 0.35000, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 782.6016 - acc: 0.9243 - mDice: 0.4631 - val_loss: 1081.0649 - val_acc: 0.9393 - val_mDice: 0.4461

Epoch 00002: val_mDice improved from 0.35000 to 0.44612, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 646.0251 - acc: 0.9277 - mDice: 0.5499 - val_loss: 1253.0372 - val_acc: 0.9390 - val_mDice: 0.4551

Epoch 00003: val_mDice improved from 0.44612 to 0.45507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 581.6805 - acc: 0.9295 - mDice: 0.5927 - val_loss: 1253.0377 - val_acc: 0.9398 - val_mDice: 0.4654

Epoch 00004: val_mDice improved from 0.45507 to 0.46542, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 539.0760 - acc: 0.9307 - mDice: 0.6209 - val_loss: 1269.3090 - val_acc: 0.9413 - val_mDice: 0.4892

Epoch 00005: val_mDice improved from 0.46542 to 0.48921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 14s - loss: 509.3351 - acc: 0.9312 - mDice: 0.6405 - val_loss: 1196.5791 - val_acc: 0.9409 - val_mDice: 0.5197

Epoch 00006: val_mDice improved from 0.48921 to 0.51970, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 487.6750 - acc: 0.9317 - mDice: 0.6558 - val_loss: 1281.2775 - val_acc: 0.9396 - val_mDice: 0.5096

Epoch 00007: val_mDice did not improve from 0.51970
Epoch 8/300
 - 14s - loss: 472.0670 - acc: 0.9321 - mDice: 0.6668 - val_loss: 1277.9022 - val_acc: 0.9402 - val_mDice: 0.5123

Epoch 00008: val_mDice did not improve from 0.51970
Epoch 9/300
 - 14s - loss: 455.9233 - acc: 0.9324 - mDice: 0.6775 - val_loss: 1257.0914 - val_acc: 0.9352 - val_mDice: 0.5224

Epoch 00009: val_mDice improved from 0.51970 to 0.52237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 14s - loss: 443.4093 - acc: 0.9327 - mDice: 0.6865 - val_loss: 1283.7624 - val_acc: 0.9366 - val_mDice: 0.5235

Epoch 00010: val_mDice improved from 0.52237 to 0.52348, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 14s - loss: 433.0817 - acc: 0.9327 - mDice: 0.6933 - val_loss: 1330.7535 - val_acc: 0.9356 - val_mDice: 0.5185

Epoch 00011: val_mDice did not improve from 0.52348
Epoch 12/300
 - 14s - loss: 423.3462 - acc: 0.9325 - mDice: 0.7004 - val_loss: 1308.7196 - val_acc: 0.9342 - val_mDice: 0.5213

Epoch 00012: val_mDice did not improve from 0.52348
Epoch 13/300
 - 14s - loss: 414.4017 - acc: 0.9324 - mDice: 0.7066 - val_loss: 1378.5575 - val_acc: 0.9356 - val_mDice: 0.5142

Epoch 00013: val_mDice did not improve from 0.52348
Epoch 14/300
 - 14s - loss: 408.3291 - acc: 0.9321 - mDice: 0.7103 - val_loss: 1422.1523 - val_acc: 0.9347 - val_mDice: 0.4918

Epoch 00014: val_mDice did not improve from 0.52348
Epoch 15/300
 - 14s - loss: 400.2129 - acc: 0.9320 - mDice: 0.7158 - val_loss: 1439.5716 - val_acc: 0.9344 - val_mDice: 0.5064

Epoch 00015: val_mDice did not improve from 0.52348
Epoch 16/300
 - 14s - loss: 395.7070 - acc: 0.9320 - mDice: 0.7190 - val_loss: 1455.6106 - val_acc: 0.9336 - val_mDice: 0.5157

Epoch 00016: val_mDice did not improve from 0.52348
Epoch 17/300
 - 13s - loss: 390.6936 - acc: 0.9323 - mDice: 0.7229 - val_loss: 1285.0949 - val_acc: 0.9330 - val_mDice: 0.5270

Epoch 00017: val_mDice improved from 0.52348 to 0.52700, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 13s - loss: 384.9999 - acc: 0.9325 - mDice: 0.7265 - val_loss: 1362.9360 - val_acc: 0.9350 - val_mDice: 0.5266

Epoch 00018: val_mDice did not improve from 0.52700
Epoch 19/300
 - 14s - loss: 378.6873 - acc: 0.9327 - mDice: 0.7310 - val_loss: 1288.7080 - val_acc: 0.9335 - val_mDice: 0.5359

Epoch 00019: val_mDice improved from 0.52700 to 0.53593, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 15s - loss: 374.5292 - acc: 0.9330 - mDice: 0.7341 - val_loss: 1367.2887 - val_acc: 0.9349 - val_mDice: 0.5307

Epoch 00020: val_mDice did not improve from 0.53593
Epoch 21/300
 - 14s - loss: 370.6288 - acc: 0.9329 - mDice: 0.7370 - val_loss: 1431.6932 - val_acc: 0.9336 - val_mDice: 0.5129

Epoch 00021: val_mDice did not improve from 0.53593
Epoch 22/300
 - 14s - loss: 365.2108 - acc: 0.9330 - mDice: 0.7409 - val_loss: 1480.6585 - val_acc: 0.9345 - val_mDice: 0.5186

Epoch 00022: val_mDice did not improve from 0.53593
Epoch 23/300
 - 14s - loss: 361.3616 - acc: 0.9336 - mDice: 0.7433 - val_loss: 1515.5746 - val_acc: 0.9345 - val_mDice: 0.5129

Epoch 00023: val_mDice did not improve from 0.53593
Epoch 24/300
 - 14s - loss: 360.0463 - acc: 0.9335 - mDice: 0.7448 - val_loss: 1545.9759 - val_acc: 0.9339 - val_mDice: 0.5083

Epoch 00024: val_mDice did not improve from 0.53593
Epoch 25/300
 - 14s - loss: 355.1717 - acc: 0.9333 - mDice: 0.7477 - val_loss: 1452.7654 - val_acc: 0.9337 - val_mDice: 0.5204

Epoch 00025: val_mDice did not improve from 0.53593
Epoch 26/300
 - 15s - loss: 352.1639 - acc: 0.9333 - mDice: 0.7497 - val_loss: 1427.5028 - val_acc: 0.9344 - val_mDice: 0.5249

Epoch 00026: val_mDice did not improve from 0.53593
Epoch 27/300
 - 14s - loss: 348.5902 - acc: 0.9333 - mDice: 0.7526 - val_loss: 1497.2156 - val_acc: 0.9366 - val_mDice: 0.5176

Epoch 00027: val_mDice did not improve from 0.53593
Epoch 28/300
 - 13s - loss: 346.7059 - acc: 0.9336 - mDice: 0.7536 - val_loss: 1376.6279 - val_acc: 0.9373 - val_mDice: 0.5371

Epoch 00028: val_mDice improved from 0.53593 to 0.53710, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 14s - loss: 343.9653 - acc: 0.9340 - mDice: 0.7557 - val_loss: 1442.1602 - val_acc: 0.9358 - val_mDice: 0.5224

Epoch 00029: val_mDice did not improve from 0.53710
Epoch 30/300
 - 14s - loss: 341.8746 - acc: 0.9336 - mDice: 0.7569 - val_loss: 1431.1950 - val_acc: 0.9354 - val_mDice: 0.5248

Epoch 00030: val_mDice did not improve from 0.53710
Epoch 31/300
 - 13s - loss: 339.9900 - acc: 0.9338 - mDice: 0.7586 - val_loss: 1481.2957 - val_acc: 0.9347 - val_mDice: 0.5278

Epoch 00031: val_mDice did not improve from 0.53710
Epoch 32/300
 - 14s - loss: 337.3597 - acc: 0.9339 - mDice: 0.7605 - val_loss: 1513.9555 - val_acc: 0.9351 - val_mDice: 0.5231

Epoch 00032: val_mDice did not improve from 0.53710
Epoch 33/300
 - 14s - loss: 334.4478 - acc: 0.9339 - mDice: 0.7622 - val_loss: 1488.4705 - val_acc: 0.9338 - val_mDice: 0.5239

Epoch 00033: val_mDice did not improve from 0.53710
Epoch 34/300
 - 14s - loss: 332.6903 - acc: 0.9342 - mDice: 0.7636 - val_loss: 1521.1414 - val_acc: 0.9348 - val_mDice: 0.5190

Epoch 00034: val_mDice did not improve from 0.53710
Epoch 35/300
 - 14s - loss: 331.2800 - acc: 0.9342 - mDice: 0.7645 - val_loss: 1559.9495 - val_acc: 0.9370 - val_mDice: 0.5219

Epoch 00035: val_mDice did not improve from 0.53710
Epoch 36/300
 - 14s - loss: 329.7313 - acc: 0.9340 - mDice: 0.7655 - val_loss: 1455.0704 - val_acc: 0.9358 - val_mDice: 0.5314

Epoch 00036: val_mDice did not improve from 0.53710
Epoch 37/300
 - 14s - loss: 328.3513 - acc: 0.9348 - mDice: 0.7667 - val_loss: 1528.5508 - val_acc: 0.9365 - val_mDice: 0.5222

Epoch 00037: val_mDice did not improve from 0.53710
Epoch 38/300
 - 14s - loss: 325.1768 - acc: 0.9348 - mDice: 0.7688 - val_loss: 1515.6129 - val_acc: 0.9385 - val_mDice: 0.5282

Epoch 00038: val_mDice did not improve from 0.53710
Epoch 39/300
 - 13s - loss: 323.9881 - acc: 0.9357 - mDice: 0.7697 - val_loss: 1567.6941 - val_acc: 0.9353 - val_mDice: 0.5238

Epoch 00039: val_mDice did not improve from 0.53710
Epoch 40/300
 - 15s - loss: 322.0199 - acc: 0.9357 - mDice: 0.7707 - val_loss: 1640.8944 - val_acc: 0.9373 - val_mDice: 0.5083

Epoch 00040: val_mDice did not improve from 0.53710
Epoch 41/300
 - 13s - loss: 320.0564 - acc: 0.9352 - mDice: 0.7723 - val_loss: 1490.8384 - val_acc: 0.9351 - val_mDice: 0.5297

Epoch 00041: val_mDice did not improve from 0.53710
Epoch 42/300
 - 14s - loss: 319.5849 - acc: 0.9347 - mDice: 0.7732 - val_loss: 1574.7926 - val_acc: 0.9366 - val_mDice: 0.5249

Epoch 00042: val_mDice did not improve from 0.53710
Epoch 43/300
 - 13s - loss: 317.7291 - acc: 0.9345 - mDice: 0.7738 - val_loss: 1585.0553 - val_acc: 0.9347 - val_mDice: 0.5216

Epoch 00043: val_mDice did not improve from 0.53710
Epoch 44/300
 - 13s - loss: 317.7252 - acc: 0.9341 - mDice: 0.7744 - val_loss: 1545.0954 - val_acc: 0.9373 - val_mDice: 0.5343

Epoch 00044: val_mDice did not improve from 0.53710
Epoch 45/300
 - 14s - loss: 315.0791 - acc: 0.9341 - mDice: 0.7760 - val_loss: 1645.3368 - val_acc: 0.9365 - val_mDice: 0.5275

Epoch 00045: val_mDice did not improve from 0.53710
Epoch 46/300
 - 14s - loss: 313.1157 - acc: 0.9342 - mDice: 0.7776 - val_loss: 1577.6858 - val_acc: 0.9318 - val_mDice: 0.5361

Epoch 00046: val_mDice did not improve from 0.53710
Epoch 47/300
 - 14s - loss: 312.9124 - acc: 0.9342 - mDice: 0.7776 - val_loss: 1623.5645 - val_acc: 0.9355 - val_mDice: 0.5298

Epoch 00047: val_mDice did not improve from 0.53710
Epoch 48/300
 - 14s - loss: 310.1701 - acc: 0.9346 - mDice: 0.7798 - val_loss: 1647.4508 - val_acc: 0.9320 - val_mDice: 0.5249

Epoch 00048: val_mDice did not improve from 0.53710
Epoch 49/300
 - 14s - loss: 309.7647 - acc: 0.9342 - mDice: 0.7800 - val_loss: 1508.4288 - val_acc: 0.9332 - val_mDice: 0.5389

Epoch 00049: val_mDice improved from 0.53710 to 0.53889, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 50/300
 - 14s - loss: 308.0335 - acc: 0.9344 - mDice: 0.7810 - val_loss: 1641.9988 - val_acc: 0.9337 - val_mDice: 0.5339

Epoch 00050: val_mDice did not improve from 0.53889
Epoch 51/300
 - 13s - loss: 307.2702 - acc: 0.9345 - mDice: 0.7815 - val_loss: 1600.5950 - val_acc: 0.9350 - val_mDice: 0.5307

Epoch 00051: val_mDice did not improve from 0.53889
Epoch 52/300
 - 13s - loss: 307.2765 - acc: 0.9347 - mDice: 0.7815 - val_loss: 1645.6606 - val_acc: 0.9308 - val_mDice: 0.5322

Epoch 00052: val_mDice did not improve from 0.53889
Epoch 53/300
 - 14s - loss: 305.9536 - acc: 0.9345 - mDice: 0.7825 - val_loss: 1732.8632 - val_acc: 0.9307 - val_mDice: 0.5169

Epoch 00053: val_mDice did not improve from 0.53889
Epoch 54/300
 - 14s - loss: 304.7162 - acc: 0.9343 - mDice: 0.7834 - val_loss: 1632.4454 - val_acc: 0.9325 - val_mDice: 0.5298

Epoch 00054: val_mDice did not improve from 0.53889
Epoch 55/300
 - 14s - loss: 302.4565 - acc: 0.9347 - mDice: 0.7846 - val_loss: 1590.6995 - val_acc: 0.9349 - val_mDice: 0.5367

Epoch 00055: val_mDice did not improve from 0.53889
Epoch 56/300
 - 13s - loss: 302.6111 - acc: 0.9346 - mDice: 0.7851 - val_loss: 1606.4380 - val_acc: 0.9359 - val_mDice: 0.5340

Epoch 00056: val_mDice did not improve from 0.53889
Epoch 57/300
 - 14s - loss: 301.6330 - acc: 0.9345 - mDice: 0.7860 - val_loss: 1599.4180 - val_acc: 0.9362 - val_mDice: 0.5366

Epoch 00057: val_mDice did not improve from 0.53889
Epoch 58/300
 - 14s - loss: 299.6958 - acc: 0.9342 - mDice: 0.7867 - val_loss: 1534.3761 - val_acc: 0.9323 - val_mDice: 0.5371

Epoch 00058: val_mDice did not improve from 0.53889
Epoch 59/300
 - 14s - loss: 299.8890 - acc: 0.9339 - mDice: 0.7869 - val_loss: 1592.2145 - val_acc: 0.9326 - val_mDice: 0.5447

Epoch 00059: val_mDice improved from 0.53889 to 0.54472, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 60/300
 - 14s - loss: 298.7355 - acc: 0.9344 - mDice: 0.7880 - val_loss: 1629.4763 - val_acc: 0.9335 - val_mDice: 0.5393

Epoch 00060: val_mDice did not improve from 0.54472
Epoch 61/300
 - 15s - loss: 296.6334 - acc: 0.9345 - mDice: 0.7891 - val_loss: 1570.1646 - val_acc: 0.9295 - val_mDice: 0.5376

Epoch 00061: val_mDice did not improve from 0.54472
Epoch 62/300
 - 15s - loss: 297.7064 - acc: 0.9347 - mDice: 0.7886 - val_loss: 1568.4912 - val_acc: 0.9379 - val_mDice: 0.5367

Epoch 00062: val_mDice did not improve from 0.54472
Epoch 63/300
 - 14s - loss: 296.0801 - acc: 0.9346 - mDice: 0.7892 - val_loss: 1584.1257 - val_acc: 0.9314 - val_mDice: 0.5366

Epoch 00063: val_mDice did not improve from 0.54472
Epoch 64/300
 - 13s - loss: 295.3779 - acc: 0.9347 - mDice: 0.7898 - val_loss: 1618.3099 - val_acc: 0.9345 - val_mDice: 0.5400

Epoch 00064: val_mDice did not improve from 0.54472
Epoch 65/300
 - 14s - loss: 294.5776 - acc: 0.9350 - mDice: 0.7904 - val_loss: 1744.7201 - val_acc: 0.9358 - val_mDice: 0.5245

Epoch 00065: val_mDice did not improve from 0.54472
Epoch 66/300
 - 13s - loss: 292.8530 - acc: 0.9344 - mDice: 0.7914 - val_loss: 1694.5493 - val_acc: 0.9357 - val_mDice: 0.5340

Epoch 00066: val_mDice did not improve from 0.54472
Epoch 67/300
 - 15s - loss: 292.6558 - acc: 0.9351 - mDice: 0.7918 - val_loss: 1685.7576 - val_acc: 0.9349 - val_mDice: 0.5331

Epoch 00067: val_mDice did not improve from 0.54472
Epoch 68/300
 - 15s - loss: 292.1161 - acc: 0.9348 - mDice: 0.7926 - val_loss: 1619.6585 - val_acc: 0.9401 - val_mDice: 0.5426

Epoch 00068: val_mDice did not improve from 0.54472
Epoch 69/300
 - 14s - loss: 292.1095 - acc: 0.9356 - mDice: 0.7926 - val_loss: 1629.1645 - val_acc: 0.9369 - val_mDice: 0.5412

Epoch 00069: val_mDice did not improve from 0.54472
Epoch 70/300
 - 14s - loss: 290.8972 - acc: 0.9355 - mDice: 0.7933 - val_loss: 1745.9295 - val_acc: 0.9352 - val_mDice: 0.5291

Epoch 00070: val_mDice did not improve from 0.54472
Epoch 71/300
 - 14s - loss: 289.4337 - acc: 0.9356 - mDice: 0.7944 - val_loss: 1778.5601 - val_acc: 0.9394 - val_mDice: 0.5196

Epoch 00071: val_mDice did not improve from 0.54472
Epoch 72/300
 - 14s - loss: 288.9702 - acc: 0.9360 - mDice: 0.7946 - val_loss: 1814.8278 - val_acc: 0.9386 - val_mDice: 0.5193

Epoch 00072: val_mDice did not improve from 0.54472
Epoch 73/300
 - 14s - loss: 288.6768 - acc: 0.9360 - mDice: 0.7949 - val_loss: 1638.0243 - val_acc: 0.9403 - val_mDice: 0.5388

Epoch 00073: val_mDice did not improve from 0.54472
Epoch 74/300
 - 14s - loss: 287.1614 - acc: 0.9360 - mDice: 0.7959 - val_loss: 1723.3732 - val_acc: 0.9386 - val_mDice: 0.5356

Epoch 00074: val_mDice did not improve from 0.54472
Epoch 75/300
 - 14s - loss: 287.1535 - acc: 0.9362 - mDice: 0.7960 - val_loss: 1676.4853 - val_acc: 0.9405 - val_mDice: 0.5352

Epoch 00075: val_mDice did not improve from 0.54472
Epoch 76/300
 - 14s - loss: 285.9511 - acc: 0.9359 - mDice: 0.7968 - val_loss: 1671.9550 - val_acc: 0.9458 - val_mDice: 0.5428

Epoch 00076: val_mDice did not improve from 0.54472
Epoch 77/300
 - 15s - loss: 285.1637 - acc: 0.9364 - mDice: 0.7971 - val_loss: 1707.9226 - val_acc: 0.9437 - val_mDice: 0.5279

Epoch 00077: val_mDice did not improve from 0.54472
Epoch 78/300
 - 15s - loss: 284.1417 - acc: 0.9369 - mDice: 0.7982 - val_loss: 1712.5302 - val_acc: 0.9456 - val_mDice: 0.5412

Epoch 00078: val_mDice did not improve from 0.54472
Epoch 79/300
 - 14s - loss: 285.2235 - acc: 0.9371 - mDice: 0.7973 - val_loss: 1743.4408 - val_acc: 0.9441 - val_mDice: 0.5266

Epoch 00079: val_mDice did not improve from 0.54472
Epoch 80/300
 - 14s - loss: 283.9506 - acc: 0.9368 - mDice: 0.7980 - val_loss: 1805.5648 - val_acc: 0.9442 - val_mDice: 0.5249

Epoch 00080: val_mDice did not improve from 0.54472
Epoch 81/300
 - 14s - loss: 282.7053 - acc: 0.9367 - mDice: 0.7992 - val_loss: 1662.3059 - val_acc: 0.9437 - val_mDice: 0.5389

Epoch 00081: val_mDice did not improve from 0.54472
Epoch 82/300
 - 15s - loss: 281.3608 - acc: 0.9368 - mDice: 0.7999 - val_loss: 1732.4914 - val_acc: 0.9434 - val_mDice: 0.5310

Epoch 00082: val_mDice did not improve from 0.54472
Epoch 83/300
 - 15s - loss: 282.3081 - acc: 0.9368 - mDice: 0.7995 - val_loss: 1645.5032 - val_acc: 0.9410 - val_mDice: 0.5404

Epoch 00083: val_mDice did not improve from 0.54472
Epoch 84/300
 - 14s - loss: 281.4438 - acc: 0.9364 - mDice: 0.7999 - val_loss: 1761.6067 - val_acc: 0.9362 - val_mDice: 0.5268

Epoch 00084: val_mDice did not improve from 0.54472
Epoch 85/300
 - 14s - loss: 280.3648 - acc: 0.9372 - mDice: 0.8006 - val_loss: 1734.7970 - val_acc: 0.9448 - val_mDice: 0.5358

Epoch 00085: val_mDice did not improve from 0.54472
Epoch 86/300
 - 14s - loss: 280.0671 - acc: 0.9378 - mDice: 0.8012 - val_loss: 1578.8724 - val_acc: 0.9441 - val_mDice: 0.5490

Epoch 00086: val_mDice improved from 0.54472 to 0.54900, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 87/300
 - 15s - loss: 278.9885 - acc: 0.9381 - mDice: 0.8017 - val_loss: 1687.0929 - val_acc: 0.9457 - val_mDice: 0.5392

Epoch 00087: val_mDice did not improve from 0.54900
Epoch 88/300
 - 14s - loss: 279.0337 - acc: 0.9384 - mDice: 0.8017 - val_loss: 1763.3466 - val_acc: 0.9447 - val_mDice: 0.5309

Epoch 00088: val_mDice did not improve from 0.54900
Epoch 89/300
 - 14s - loss: 277.8288 - acc: 0.9383 - mDice: 0.8028 - val_loss: 1778.9257 - val_acc: 0.9481 - val_mDice: 0.5297

Epoch 00089: val_mDice did not improve from 0.54900
Epoch 90/300
 - 14s - loss: 277.6216 - acc: 0.9383 - mDice: 0.8031 - val_loss: 1729.7264 - val_acc: 0.9453 - val_mDice: 0.5359

Epoch 00090: val_mDice did not improve from 0.54900
Epoch 91/300
 - 14s - loss: 277.8813 - acc: 0.9391 - mDice: 0.8029 - val_loss: 1731.6385 - val_acc: 0.9470 - val_mDice: 0.5296

Epoch 00091: val_mDice did not improve from 0.54900
Epoch 92/300
 - 14s - loss: 275.5001 - acc: 0.9395 - mDice: 0.8042 - val_loss: 1796.6399 - val_acc: 0.9476 - val_mDice: 0.5318

Epoch 00092: val_mDice did not improve from 0.54900
Epoch 93/300
 - 14s - loss: 276.2401 - acc: 0.9395 - mDice: 0.8037 - val_loss: 1776.4444 - val_acc: 0.9461 - val_mDice: 0.5326

Epoch 00093: val_mDice did not improve from 0.54900
Epoch 94/300
 - 14s - loss: 274.8336 - acc: 0.9395 - mDice: 0.8048 - val_loss: 1695.2966 - val_acc: 0.9422 - val_mDice: 0.5469

Epoch 00094: val_mDice did not improve from 0.54900
Epoch 95/300
 - 14s - loss: 274.4983 - acc: 0.9396 - mDice: 0.8052 - val_loss: 1620.5340 - val_acc: 0.9500 - val_mDice: 0.5541

Epoch 00095: val_mDice improved from 0.54900 to 0.55411, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 96/300
 - 14s - loss: 272.9806 - acc: 0.9396 - mDice: 0.8061 - val_loss: 1679.0966 - val_acc: 0.9479 - val_mDice: 0.5381

Epoch 00096: val_mDice did not improve from 0.55411
Epoch 97/300
 - 15s - loss: 273.5059 - acc: 0.9393 - mDice: 0.8059 - val_loss: 1910.5931 - val_acc: 0.9476 - val_mDice: 0.5213

Epoch 00097: val_mDice did not improve from 0.55411
Epoch 98/300
 - 15s - loss: 271.9528 - acc: 0.9399 - mDice: 0.8070 - val_loss: 1812.4102 - val_acc: 0.9476 - val_mDice: 0.5325

Epoch 00098: val_mDice did not improve from 0.55411
Epoch 99/300
 - 14s - loss: 272.5667 - acc: 0.9399 - mDice: 0.8065 - val_loss: 1718.7669 - val_acc: 0.9504 - val_mDice: 0.5378

Epoch 00099: val_mDice did not improve from 0.55411
Epoch 100/300
 - 14s - loss: 272.6700 - acc: 0.9401 - mDice: 0.8064 - val_loss: 1684.5216 - val_acc: 0.9500 - val_mDice: 0.5397

Epoch 00100: val_mDice did not improve from 0.55411
Epoch 101/300
 - 14s - loss: 272.6794 - acc: 0.9405 - mDice: 0.8065 - val_loss: 1706.2544 - val_acc: 0.9511 - val_mDice: 0.5358

Epoch 00101: val_mDice did not improve from 0.55411
Epoch 102/300
 - 15s - loss: 271.7349 - acc: 0.9406 - mDice: 0.8069 - val_loss: 1748.9038 - val_acc: 0.9498 - val_mDice: 0.5346

Epoch 00102: val_mDice did not improve from 0.55411
Epoch 103/300
 - 14s - loss: 271.6634 - acc: 0.9407 - mDice: 0.8072 - val_loss: 1842.3352 - val_acc: 0.9491 - val_mDice: 0.5257

Epoch 00103: val_mDice did not improve from 0.55411
Epoch 104/300
 - 14s - loss: 269.7753 - acc: 0.9411 - mDice: 0.8082 - val_loss: 1731.3353 - val_acc: 0.9514 - val_mDice: 0.5376

Epoch 00104: val_mDice did not improve from 0.55411
Epoch 105/300
 - 15s - loss: 269.8027 - acc: 0.9415 - mDice: 0.8084 - val_loss: 1856.8354 - val_acc: 0.9508 - val_mDice: 0.5258

Epoch 00105: val_mDice did not improve from 0.55411
Epoch 106/300
 - 14s - loss: 268.9915 - acc: 0.9418 - mDice: 0.8089 - val_loss: 1671.1804 - val_acc: 0.9516 - val_mDice: 0.5442

Epoch 00106: val_mDice did not improve from 0.55411
Epoch 107/300
 - 14s - loss: 269.6212 - acc: 0.9418 - mDice: 0.8085 - val_loss: 1685.1349 - val_acc: 0.9510 - val_mDice: 0.5411

Epoch 00107: val_mDice did not improve from 0.55411
Epoch 108/300
 - 14s - loss: 268.5998 - acc: 0.9422 - mDice: 0.8091 - val_loss: 1686.7483 - val_acc: 0.9520 - val_mDice: 0.5486

Epoch 00108: val_mDice did not improve from 0.55411
Epoch 109/300
 - 14s - loss: 267.9350 - acc: 0.9423 - mDice: 0.8100 - val_loss: 1726.8643 - val_acc: 0.9517 - val_mDice: 0.5372

Epoch 00109: val_mDice did not improve from 0.55411
Epoch 110/300
 - 14s - loss: 267.4383 - acc: 0.9420 - mDice: 0.8100 - val_loss: 1724.8310 - val_acc: 0.9511 - val_mDice: 0.5340

Epoch 00110: val_mDice did not improve from 0.55411
Epoch 111/300
 - 14s - loss: 267.4864 - acc: 0.9423 - mDice: 0.8100 - val_loss: 1717.9430 - val_acc: 0.9531 - val_mDice: 0.5386

Epoch 00111: val_mDice did not improve from 0.55411
Epoch 112/300
 - 15s - loss: 266.7090 - acc: 0.9426 - mDice: 0.8106 - val_loss: 1793.6398 - val_acc: 0.9531 - val_mDice: 0.5389

Epoch 00112: val_mDice did not improve from 0.55411
Epoch 113/300
 - 15s - loss: 268.3711 - acc: 0.9425 - mDice: 0.8097 - val_loss: 1780.3731 - val_acc: 0.9524 - val_mDice: 0.5375

Epoch 00113: val_mDice did not improve from 0.55411
Epoch 114/300
 - 14s - loss: 266.3895 - acc: 0.9422 - mDice: 0.8109 - val_loss: 1808.0547 - val_acc: 0.9514 - val_mDice: 0.5314

Epoch 00114: val_mDice did not improve from 0.55411
Epoch 115/300
 - 14s - loss: 265.5653 - acc: 0.9425 - mDice: 0.8116 - val_loss: 1732.5518 - val_acc: 0.9512 - val_mDice: 0.5383

Epoch 00115: val_mDice did not improve from 0.55411
Epoch 116/300
 - 14s - loss: 265.9066 - acc: 0.9423 - mDice: 0.8114 - val_loss: 1812.1379 - val_acc: 0.9531 - val_mDice: 0.5254

Epoch 00116: val_mDice did not improve from 0.55411
Epoch 117/300
 - 14s - loss: 264.9626 - acc: 0.9430 - mDice: 0.8118 - val_loss: 1782.7098 - val_acc: 0.9526 - val_mDice: 0.5312

Epoch 00117: val_mDice did not improve from 0.55411
Epoch 118/300
 - 14s - loss: 264.2456 - acc: 0.9434 - mDice: 0.8123 - val_loss: 1789.5025 - val_acc: 0.9525 - val_mDice: 0.5374

Epoch 00118: val_mDice did not improve from 0.55411
Epoch 119/300
 - 14s - loss: 264.4806 - acc: 0.9433 - mDice: 0.8125 - val_loss: 1787.0810 - val_acc: 0.9523 - val_mDice: 0.5290

Epoch 00119: val_mDice did not improve from 0.55411
Epoch 120/300
 - 14s - loss: 263.1651 - acc: 0.9436 - mDice: 0.8133 - val_loss: 1750.4818 - val_acc: 0.9536 - val_mDice: 0.5373

Epoch 00120: val_mDice did not improve from 0.55411
Epoch 121/300
 - 15s - loss: 263.5681 - acc: 0.9435 - mDice: 0.8131 - val_loss: 1807.0371 - val_acc: 0.9531 - val_mDice: 0.5347

Epoch 00121: val_mDice did not improve from 0.55411
Epoch 122/300
 - 14s - loss: 263.5112 - acc: 0.9434 - mDice: 0.8131 - val_loss: 1837.0242 - val_acc: 0.9527 - val_mDice: 0.5303

Epoch 00122: val_mDice did not improve from 0.55411
Epoch 123/300
 - 14s - loss: 262.1455 - acc: 0.9437 - mDice: 0.8140 - val_loss: 1729.1017 - val_acc: 0.9523 - val_mDice: 0.5347

Epoch 00123: val_mDice did not improve from 0.55411
Epoch 124/300
 - 14s - loss: 263.1741 - acc: 0.9437 - mDice: 0.8132 - val_loss: 1754.3178 - val_acc: 0.9533 - val_mDice: 0.5359

Epoch 00124: val_mDice did not improve from 0.55411
Epoch 125/300
 - 15s - loss: 262.2335 - acc: 0.9438 - mDice: 0.8138 - val_loss: 1862.3931 - val_acc: 0.9537 - val_mDice: 0.5300

Epoch 00125: val_mDice did not improve from 0.55411
Restoring model weights from the end of the best epoch
Epoch 00125: early stopping
{'val_loss': [1066.8793515679556, 1081.0649250392808, 1253.0372089407297, 1253.0376972219797, 1269.3089845113914, 1196.5791152016411, 1281.2775428814596, 1277.9021705329085, 1257.091436119719, 1283.7623959333537, 1330.7534957118542, 1308.7196038102304, 1378.557461701292, 1422.1523226093313, 1439.5715918514315, 1455.610556831573, 1285.0948643178247, 1362.9359546853177, 1288.7080064485858, 1367.2886983349338, 1431.6932243475035, 1480.658537283956, 1515.574567230054, 1545.9758846346892, 1452.7653972263442, 1427.5028294398132, 1497.2155843553596, 1376.6279221859725, 1442.1601548860858, 1431.1950247141235, 1481.2957374956354, 1513.955462066821, 1488.4704944461419, 1521.1413785625437, 1559.9495379059008, 1455.0703991085456, 1528.5508419441778, 1515.6128652561977, 1567.6941224849425, 1640.8944310023132, 1490.8383904995198, 1574.792584126222, 1585.0552828485074, 1545.095405791725, 1645.3368274539544, 1577.6858373887046, 1623.5645110913495, 1647.4508179392894, 1508.428839145426, 1641.9988079390712, 1600.5950000272783, 1645.6605967942562, 1732.8631782744849, 1632.445427750742, 1590.6995038080481, 1606.4380435197713, 1599.4179551108589, 1534.3761381863217, 1592.214457080351, 1629.4763483654854, 1570.164576013661, 1568.491221166856, 1584.1256915044519, 1618.3098512788058, 1744.720085953867, 1694.5492584399005, 1685.7575847263442, 1619.6584765897783, 1629.164538506023, 1745.9294569985161, 1778.5600763246334, 1814.8277690184184, 1638.0242892643594, 1723.3731730370548, 1676.4852833667946, 1671.954962874258, 1707.9225658224948, 1712.5302386576902, 1743.4408040819221, 1805.56478864787, 1662.3059429829348, 1732.4913677876223, 1645.5032433877443, 1761.606690135082, 1734.7970338959933, 1578.8723601442475, 1687.0929466545915, 1763.3465794398132, 1778.925715782123, 1729.7264138333624, 1731.638478199197, 1796.63987757507, 1776.4443904940642, 1695.2966131284916, 1620.5339560055866, 1679.096639452034, 1910.5931362386523, 1812.4101903478527, 1718.76686070618, 1684.5216296318522, 1706.2543624792686, 1748.903834508118, 1842.3352255368366, 1731.335256224904, 1856.8353919343576, 1671.180419921875, 1685.1348651907297, 1686.7483332969623, 1726.8642625861994, 1724.8309946752793, 1717.9430047573323, 1793.639775281512, 1780.3730959759077, 1808.0546806804296, 1732.5518403293033, 1812.137888988303, 1782.7098415950156, 1789.5024598190905, 1787.0810151339908, 1750.4817890188547, 1807.0370745951902, 1837.024223114525, 1729.1017132125087, 1754.3178151732716, 1862.3930827732192], 'val_acc': [0.9362013346656075, 0.9393437851074687, 0.9390338369587946, 0.9398479281857027, 0.9412962567872841, 0.9409078922351646, 0.9395878278343371, 0.9401525671921629, 0.9351930628275739, 0.9366075140137912, 0.9355920733020292, 0.9341722663554399, 0.9355635819488397, 0.9347387871928721, 0.9343539609589391, 0.933557688856924, 0.9329751460245868, 0.9349810714162262, 0.9335202508132551, 0.9349062099803094, 0.9335594446965436, 0.9345071778617091, 0.9345232215007591, 0.9338640797071617, 0.9336877488557187, 0.934357548892165, 0.9365664993584489, 0.9372826671467147, 0.9357987305971497, 0.9354121598451497, 0.9346710773153678, 0.9351413779418561, 0.9338017209282135, 0.934826070036968, 0.9369798169455714, 0.9358450414082191, 0.9365041835348034, 0.9384691052596662, 0.9352892490738597, 0.9373218523723453, 0.9350843719263983, 0.9366377778559424, 0.9347262965234299, 0.9372755398963417, 0.9365219813485385, 0.9317637695280533, 0.9354744796646374, 0.93202564769617, 0.9331764658736117, 0.933718018691633, 0.9350148992165507, 0.9308142572141892, 0.9307055956158559, 0.9325279976402581, 0.9348527745827616, 0.9359180770772796, 0.9362031068215823, 0.9323284955664054, 0.9325867891311646, 0.9335113747159862, 0.9294764099840346, 0.9378758625611247, 0.9313664992428359, 0.9344751178885305, 0.9358058675041412, 0.9357274677500379, 0.9349454138532031, 0.9400902150729515, 0.9368729448185287, 0.9352429182835797, 0.9394257241787192, 0.9386062695327417, 0.9403449496743399, 0.9386472292452551, 0.9405070486681422, 0.945764095090621, 0.9437350387679798, 0.9455806113488181, 0.9440930782083693, 0.9442373750596073, 0.9437385963994032, 0.9434322055491655, 0.9409845011860298, 0.936179957909291, 0.9447557956146795, 0.9440824196325334, 0.9457160101256556, 0.9447059121877788, 0.9480657161281095, 0.9452563857233058, 0.9469808383360921, 0.9475508725176977, 0.9460669396309879, 0.9421762667554717, 0.9500181641658592, 0.9478555121901315, 0.9476185730715704, 0.9476434944728234, 0.950435016408313, 0.9500128463659873, 0.9511493987211302, 0.949791925579476, 0.9491149749835777, 0.9514361982904999, 0.9508251471226442, 0.9516428222869362, 0.9510246958146548, 0.951958156164798, 0.951715875937286, 0.9511119736639481, 0.9531321385719257, 0.9531285376522128, 0.9524480314228122, 0.9514272878955863, 0.9511992598379124, 0.9531196578920886, 0.9525905687715754, 0.9525371237174093, 0.9523287072528008, 0.953570358913038, 0.9531356888776384, 0.952695678066275, 0.9522841509494036, 0.9533049337690769, 0.9537306860838523], 'val_mDice': [0.3500016987656748, 0.4461184413739423, 0.4550748514063531, 0.4654167985449956, 0.4892069301125724, 0.5197005260257082, 0.5095968023358777, 0.512328541811618, 0.5223733216690618, 0.5234798785694484, 0.5184916604164592, 0.5212725602381723, 0.5142451188417786, 0.4917854658385229, 0.5064446519872996, 0.5156585853859033, 0.5269997682651328, 0.5265814472177175, 0.5359290746670196, 0.5307139284783902, 0.5128613347447785, 0.5185590006785685, 0.512928093944848, 0.5082642106370553, 0.5203726166786429, 0.5248539897316661, 0.5175564750279794, 0.5371009590905472, 0.5223907182336519, 0.5247543857084306, 0.5277710581957961, 0.5230771449691091, 0.5238581363049299, 0.5189598782102489, 0.5219040539677583, 0.5313774350635166, 0.5222310533736672, 0.5281963524871698, 0.5238247492126913, 0.5083103408027627, 0.5296817899749265, 0.5248953969784955, 0.5216471311433355, 0.5342585770777484, 0.5275444684747878, 0.5361435661435793, 0.5298025083608467, 0.5249252500813767, 0.5388880863203017, 0.5338751813552899, 0.5307099353001771, 0.5321679015399358, 0.5168573113793101, 0.5298201593273845, 0.5366876453327734, 0.5339989871952121, 0.5365682543989, 0.5370665397390973, 0.544717791027197, 0.5393127249605829, 0.5375892506631393, 0.5367167232422855, 0.5366007044661645, 0.5399885487290068, 0.5245082524901662, 0.5339684433111266, 0.5331310142018941, 0.5426133141837306, 0.5412385923236442, 0.529086584485443, 0.5195606442470124, 0.5193270315005126, 0.5388070807776637, 0.5356237705193418, 0.5352386712361981, 0.5427677253438108, 0.5279398560523987, 0.5411827539265489, 0.5265741076882325, 0.5249381688054048, 0.5388791228139866, 0.5309595239229042, 0.5403672032183109, 0.5267887010587661, 0.5358493927470799, 0.5490033862977054, 0.53920686994185, 0.5308681714801149, 0.529687746443562, 0.5359198289543556, 0.5295904416944728, 0.5318429105441663, 0.5326133089025593, 0.5468953881183816, 0.5541117106403053, 0.5380534439779526, 0.5213089525366629, 0.5324907963835327, 0.5377564906408001, 0.5396798562737151, 0.5358115935791804, 0.5346081679759744, 0.5257229114044978, 0.537557997683573, 0.5257787541304221, 0.5442402342844276, 0.5411142074196033, 0.5485928118561899, 0.5371968975946224, 0.5340384734409481, 0.5385874997637126, 0.538853689611957, 0.537457389705008, 0.5313853355093375, 0.5383006564065731, 0.5254016668436914, 0.5312335024998841, 0.5374129419553213, 0.5290085758243859, 0.5373307206777221, 0.5347404110365074, 0.5303228337671504, 0.5346870565547623, 0.5358524970169174, 0.5299941597704115], 'loss': [1478.049014601181, 782.601595959472, 646.0250962594322, 581.6804646984968, 539.0759542745791, 509.33513921959246, 487.6750394190509, 472.0670253707331, 455.9232536861498, 443.4092923753318, 433.08170758183957, 423.34618366757326, 414.40174265210646, 408.32914069966097, 400.21292449417643, 395.7069874498542, 390.6935648887247, 384.9999309336397, 378.6873211378392, 374.5291745404157, 370.6287845644606, 365.21079194606125, 361.3615721800275, 360.04630989210585, 355.1716697721542, 352.163934225117, 348.59020934513427, 346.7058712595864, 343.9652707966433, 341.8746070344492, 339.99001500279445, 337.35967245538745, 334.44779712882064, 332.69031899251047, 331.279997042416, 329.7313437706232, 328.35130611145644, 325.1768087338573, 323.98811590891637, 322.01991801596654, 320.0564438330764, 319.58491230732955, 317.72909012036115, 317.725220788636, 315.079137163571, 313.1156993587775, 312.9124061314799, 310.17008124254323, 309.7647058310238, 308.03352204208494, 307.2701961828352, 307.2765260788553, 305.953560950443, 304.71618510235317, 302.45648716833654, 302.611132796544, 301.63298656371586, 299.6957524444379, 299.8889654178348, 298.7355454449404, 296.63344079628405, 297.70637275775164, 296.0801286806982, 295.37792314885, 294.5776471250763, 292.85295904859805, 292.65584085237083, 292.116147326109, 292.1095399970316, 290.89724198580245, 289.4337271382935, 288.97020552193544, 288.6768173484538, 287.1613925501488, 287.1534598239217, 285.9510582040438, 285.16372962554004, 284.1416735890371, 285.2234768314589, 283.9505634398237, 282.7052966179616, 281.36075820702627, 282.30805305483864, 281.4438149630001, 280.3648426709732, 280.0671494131118, 278.9884936198333, 279.0337458362728, 277.8288097141628, 277.62163424571094, 277.88130954792086, 275.50011040827957, 276.24009219509776, 274.83357499301655, 274.4982827301217, 272.9806084484065, 273.50592950509593, 271.95279839493196, 272.56668921032735, 272.67002662138043, 272.6793951139777, 271.73493035227494, 271.66344931956553, 269.7753415726595, 269.8026718140479, 268.9914530570273, 269.62124429684786, 268.5997784782174, 267.9349912036044, 267.438257755404, 267.4864128532054, 266.70896313934634, 268.3710504484803, 266.38945026188907, 265.56530905156853, 265.906582302702, 264.96258062916667, 264.24562730774124, 264.4805757277321, 263.1651387818985, 263.5680897944724, 263.5111593197948, 262.14547689934517, 263.17414826205675, 262.2334580490788], 'acc': [0.9079351472890972, 0.924341789842866, 0.9276626234863274, 0.9295078112853001, 0.9307134360388262, 0.9312423011308844, 0.9316990013333176, 0.9320973152688669, 0.9323882834498811, 0.9326850028087628, 0.9327213334450307, 0.9325492784521313, 0.9323850554563168, 0.9320763893574388, 0.9320253283978418, 0.9319961544254702, 0.9323159182268409, 0.9324803304376182, 0.9326592492944281, 0.9330136581421885, 0.9329299480980904, 0.9329674281388883, 0.9335653063655062, 0.9335490177382922, 0.9333038975337928, 0.9332787663995956, 0.9333166119599289, 0.9335624769741488, 0.933988001512667, 0.9335699804688414, 0.9337541241835654, 0.9338537385946629, 0.9338644567764856, 0.9342051126632184, 0.9341813547569295, 0.9340033403902972, 0.9347784515332503, 0.9347993272282279, 0.9356924679003914, 0.9356535796921508, 0.9352142114368154, 0.9347336947460215, 0.9344961657989493, 0.934141062383889, 0.9340913731848893, 0.9341694592364791, 0.9342369127913722, 0.9345864067571847, 0.9342275145597807, 0.9343795482547875, 0.9344924678730293, 0.934702660255615, 0.9345170750602918, 0.9342720260398593, 0.934739030262567, 0.934601186774316, 0.9344715585435153, 0.9342016582525112, 0.9338793402747595, 0.9344331416570312, 0.9344563086492149, 0.934658534142727, 0.934576836424932, 0.9347159116689263, 0.9350453312182361, 0.9344244050431645, 0.9350638623902704, 0.9348203408114953, 0.935593454736256, 0.9354848961192314, 0.935568881430246, 0.9360328626089915, 0.9360448106702173, 0.936030447547988, 0.9361738144205479, 0.9359231178235023, 0.9364183780174552, 0.9368652668168592, 0.9370989245232476, 0.9367971350396032, 0.9366527474801087, 0.9367599862507827, 0.936837946847272, 0.936410318226812, 0.9372261196600509, 0.9378178689248824, 0.9380758082183006, 0.938388744189286, 0.9383176276155446, 0.9383326147832445, 0.9390537138468533, 0.9395286007505584, 0.9394967485880463, 0.9395331505706942, 0.939605744671545, 0.9396306975988591, 0.939299510442823, 0.9398784255982744, 0.939926134336294, 0.9400522704997306, 0.9404767579349594, 0.9406433101670622, 0.9406958085494288, 0.9410616281466133, 0.9414913622156921, 0.9418132609385083, 0.9418023712111353, 0.9421826429073863, 0.9422832862574202, 0.9420352656430561, 0.9423431312652866, 0.9425989661943379, 0.942527205337919, 0.9422392080139343, 0.9425219253681888, 0.9422788386783545, 0.9430258688885924, 0.9433682762643532, 0.943271997223479, 0.9436146659624095, 0.9434707450890072, 0.9433868076409021, 0.9436916009279048, 0.9437173052548544, 0.9438149429673911], 'mDice': [0.21279277264898194, 0.46307994240178607, 0.549921263917249, 0.592698927558291, 0.6209012665011564, 0.640506279971058, 0.6558250922125984, 0.6668087125642582, 0.677518097188022, 0.6865273638427611, 0.6932766055120673, 0.7003603682468142, 0.706613568450415, 0.7103277293985611, 0.7157557401825391, 0.7190213945266319, 0.7228950304693142, 0.7264782370425577, 0.7310007947909599, 0.734074218981108, 0.7369599621395005, 0.7409491162175194, 0.7432697127116128, 0.7447560201393195, 0.7476783473145877, 0.7496894089707258, 0.7526106250214035, 0.7536251287523694, 0.7556723647501713, 0.7569406040548065, 0.7585569946446857, 0.7604948364080125, 0.7621650272358166, 0.7635697853811283, 0.764545969243442, 0.765464901391746, 0.7666972098731766, 0.7688079110340292, 0.7697160361470314, 0.7707430489812112, 0.7722537772411757, 0.7731814009517011, 0.7738116665555465, 0.7744185753257166, 0.7760464312996352, 0.7776228709032863, 0.7776014213208559, 0.7797820066179911, 0.7799783869932617, 0.7809593691252447, 0.781505061542473, 0.7815478559341782, 0.7825392823964382, 0.7833745688058784, 0.7845991792115801, 0.7851366349947128, 0.7859645865788212, 0.7866735307227993, 0.7868506563241546, 0.7880086394691447, 0.7890821432023324, 0.788644617480732, 0.7892293640584391, 0.7898310084928842, 0.7903692965595546, 0.7913754304946946, 0.7918132253867285, 0.7926415197145873, 0.7925709496558047, 0.7932945100623963, 0.7943808726447384, 0.7945994253765231, 0.7948706349602751, 0.7958504922327266, 0.7959647095383242, 0.79680341008208, 0.7971061679034132, 0.798170778481414, 0.7973187262407738, 0.7979562786836834, 0.7992363063658409, 0.7999366573645693, 0.7994590068388061, 0.7998972743608406, 0.8005561600303567, 0.8012451184003041, 0.8017205222390146, 0.8017160032681212, 0.8027981870717573, 0.8030800797906708, 0.8028713979269709, 0.8042197050686515, 0.8036578370039191, 0.804772661068712, 0.8051709034403817, 0.8061080207934301, 0.8059077099980914, 0.8070051726429598, 0.8064629386553129, 0.8064255554245862, 0.8065429442874565, 0.8069399061704745, 0.8071979437899689, 0.808219016471542, 0.8083801711769731, 0.8089217920071172, 0.8085086011697015, 0.8090898233342746, 0.8099689576712954, 0.8100421959119881, 0.809998254407615, 0.810645201335928, 0.8097435258830868, 0.8108879515959945, 0.811641764617435, 0.8113788953372046, 0.8118458942717492, 0.8123252194020348, 0.812531435942833, 0.8133076889200295, 0.8130523216217329, 0.8131073081092789, 0.8140379564706669, 0.8132121324617095, 0.8137594154604211]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.02s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.71s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.43s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:28,  2.00s/it]predicting train subjects:   1%|          | 2/285 [00:04<09:46,  2.07s/it]predicting train subjects:   1%|          | 3/285 [00:06<09:48,  2.09s/it]predicting train subjects:   1%|▏         | 4/285 [00:09<11:04,  2.36s/it]predicting train subjects:   2%|▏         | 5/285 [00:11<10:15,  2.20s/it]predicting train subjects:   2%|▏         | 6/285 [00:13<10:34,  2.28s/it]predicting train subjects:   2%|▏         | 7/285 [00:16<10:53,  2.35s/it]predicting train subjects:   3%|▎         | 8/285 [00:18<10:49,  2.35s/it]predicting train subjects:   3%|▎         | 9/285 [00:20<10:32,  2.29s/it]predicting train subjects:   4%|▎         | 10/285 [00:23<10:42,  2.34s/it]predicting train subjects:   4%|▍         | 11/285 [00:25<10:58,  2.40s/it]predicting train subjects:   4%|▍         | 12/285 [00:28<11:15,  2.47s/it]predicting train subjects:   5%|▍         | 13/285 [00:30<11:10,  2.47s/it]predicting train subjects:   5%|▍         | 14/285 [00:33<11:23,  2.52s/it]predicting train subjects:   5%|▌         | 15/285 [00:36<11:40,  2.59s/it]predicting train subjects:   6%|▌         | 16/285 [00:38<11:33,  2.58s/it]predicting train subjects:   6%|▌         | 17/285 [00:41<11:40,  2.61s/it]predicting train subjects:   6%|▋         | 18/285 [00:44<11:39,  2.62s/it]predicting train subjects:   7%|▋         | 19/285 [00:46<11:33,  2.61s/it]predicting train subjects:   7%|▋         | 20/285 [00:49<11:28,  2.60s/it]predicting train subjects:   7%|▋         | 21/285 [00:52<11:55,  2.71s/it]predicting train subjects:   8%|▊         | 22/285 [00:54<11:40,  2.66s/it]predicting train subjects:   8%|▊         | 23/285 [00:57<11:32,  2.64s/it]predicting train subjects:   8%|▊         | 24/285 [00:59<11:23,  2.62s/it]predicting train subjects:   9%|▉         | 25/285 [01:02<11:13,  2.59s/it]predicting train subjects:   9%|▉         | 26/285 [01:04<11:08,  2.58s/it]predicting train subjects:   9%|▉         | 27/285 [01:07<11:02,  2.57s/it]predicting train subjects:  10%|▉         | 28/285 [01:09<10:44,  2.51s/it]predicting train subjects:  10%|█         | 29/285 [01:12<10:24,  2.44s/it]predicting train subjects:  11%|█         | 30/285 [01:14<10:07,  2.38s/it]predicting train subjects:  11%|█         | 31/285 [01:16<09:48,  2.32s/it]predicting train subjects:  11%|█         | 32/285 [01:18<09:31,  2.26s/it]predicting train subjects:  12%|█▏        | 33/285 [01:20<09:31,  2.27s/it]predicting train subjects:  12%|█▏        | 34/285 [01:23<09:24,  2.25s/it]predicting train subjects:  12%|█▏        | 35/285 [01:25<09:17,  2.23s/it]predicting train subjects:  13%|█▎        | 36/285 [01:27<09:17,  2.24s/it]predicting train subjects:  13%|█▎        | 37/285 [01:29<09:16,  2.24s/it]predicting train subjects:  13%|█▎        | 38/285 [01:32<09:11,  2.23s/it]predicting train subjects:  14%|█▎        | 39/285 [01:34<09:19,  2.27s/it]predicting train subjects:  14%|█▍        | 40/285 [01:36<09:07,  2.24s/it]predicting train subjects:  14%|█▍        | 41/285 [01:38<08:57,  2.20s/it]predicting train subjects:  15%|█▍        | 42/285 [01:40<08:55,  2.20s/it]predicting train subjects:  15%|█▌        | 43/285 [01:43<08:58,  2.22s/it]predicting train subjects:  15%|█▌        | 44/285 [01:45<08:59,  2.24s/it]predicting train subjects:  16%|█▌        | 45/285 [01:47<08:53,  2.22s/it]predicting train subjects:  16%|█▌        | 46/285 [01:49<08:30,  2.14s/it]predicting train subjects:  16%|█▋        | 47/285 [01:51<08:21,  2.11s/it]predicting train subjects:  17%|█▋        | 48/285 [01:53<08:16,  2.10s/it]predicting train subjects:  17%|█▋        | 49/285 [01:55<08:11,  2.08s/it]predicting train subjects:  18%|█▊        | 50/285 [01:57<08:15,  2.11s/it]predicting train subjects:  18%|█▊        | 51/285 [02:00<08:40,  2.22s/it]predicting train subjects:  18%|█▊        | 52/285 [02:02<08:15,  2.13s/it]predicting train subjects:  19%|█▊        | 53/285 [02:04<08:11,  2.12s/it]predicting train subjects:  19%|█▉        | 54/285 [02:06<08:07,  2.11s/it]predicting train subjects:  19%|█▉        | 55/285 [02:08<08:01,  2.09s/it]predicting train subjects:  20%|█▉        | 56/285 [02:10<07:53,  2.07s/it]predicting train subjects:  20%|██        | 57/285 [02:12<07:52,  2.07s/it]predicting train subjects:  20%|██        | 58/285 [02:15<09:07,  2.41s/it]predicting train subjects:  21%|██        | 59/285 [02:18<08:48,  2.34s/it]predicting train subjects:  21%|██        | 60/285 [02:20<08:23,  2.24s/it]predicting train subjects:  21%|██▏       | 61/285 [02:22<08:04,  2.16s/it]predicting train subjects:  22%|██▏       | 62/285 [02:24<07:59,  2.15s/it]predicting train subjects:  22%|██▏       | 63/285 [02:25<07:32,  2.04s/it]predicting train subjects:  22%|██▏       | 64/285 [02:28<07:34,  2.06s/it]predicting train subjects:  23%|██▎       | 65/285 [02:30<07:40,  2.10s/it]predicting train subjects:  23%|██▎       | 66/285 [02:32<07:56,  2.17s/it]predicting train subjects:  24%|██▎       | 67/285 [02:34<07:43,  2.12s/it]predicting train subjects:  24%|██▍       | 68/285 [02:36<07:25,  2.05s/it]predicting train subjects:  24%|██▍       | 69/285 [02:38<07:18,  2.03s/it]predicting train subjects:  25%|██▍       | 70/285 [02:40<07:19,  2.04s/it]predicting train subjects:  25%|██▍       | 71/285 [02:42<07:23,  2.07s/it]predicting train subjects:  25%|██▌       | 72/285 [02:44<07:25,  2.09s/it]predicting train subjects:  26%|██▌       | 73/285 [02:46<07:17,  2.07s/it]predicting train subjects:  26%|██▌       | 74/285 [02:48<07:09,  2.04s/it]predicting train subjects:  26%|██▋       | 75/285 [02:50<07:08,  2.04s/it]predicting train subjects:  27%|██▋       | 76/285 [02:52<07:13,  2.07s/it]predicting train subjects:  27%|██▋       | 77/285 [02:55<07:21,  2.12s/it]predicting train subjects:  27%|██▋       | 78/285 [02:57<07:29,  2.17s/it]predicting train subjects:  28%|██▊       | 79/285 [02:59<07:22,  2.15s/it]predicting train subjects:  28%|██▊       | 80/285 [03:01<07:22,  2.16s/it]predicting train subjects:  28%|██▊       | 81/285 [03:03<07:14,  2.13s/it]predicting train subjects:  29%|██▉       | 82/285 [03:05<07:06,  2.10s/it]predicting train subjects:  29%|██▉       | 83/285 [03:07<07:02,  2.09s/it]predicting train subjects:  29%|██▉       | 84/285 [03:10<07:03,  2.11s/it]predicting train subjects:  30%|██▉       | 85/285 [03:12<07:02,  2.11s/it]predicting train subjects:  30%|███       | 86/285 [03:14<06:57,  2.10s/it]predicting train subjects:  31%|███       | 87/285 [03:16<06:48,  2.06s/it]predicting train subjects:  31%|███       | 88/285 [03:18<06:46,  2.07s/it]predicting train subjects:  31%|███       | 89/285 [03:20<06:51,  2.10s/it]predicting train subjects:  32%|███▏      | 90/285 [03:22<06:49,  2.10s/it]predicting train subjects:  32%|███▏      | 91/285 [03:24<06:47,  2.10s/it]predicting train subjects:  32%|███▏      | 92/285 [03:26<06:41,  2.08s/it]predicting train subjects:  33%|███▎      | 93/285 [03:28<06:30,  2.03s/it]predicting train subjects:  33%|███▎      | 94/285 [03:30<06:35,  2.07s/it]predicting train subjects:  33%|███▎      | 95/285 [03:32<06:38,  2.10s/it]predicting train subjects:  34%|███▎      | 96/285 [03:35<06:56,  2.20s/it]predicting train subjects:  34%|███▍      | 97/285 [03:37<07:06,  2.27s/it]predicting train subjects:  34%|███▍      | 98/285 [03:40<07:22,  2.37s/it]predicting train subjects:  35%|███▍      | 99/285 [03:42<07:16,  2.35s/it]predicting train subjects:  35%|███▌      | 100/285 [03:45<07:18,  2.37s/it]predicting train subjects:  35%|███▌      | 101/285 [03:47<07:13,  2.36s/it]predicting train subjects:  36%|███▌      | 102/285 [03:49<07:10,  2.35s/it]predicting train subjects:  36%|███▌      | 103/285 [03:52<07:08,  2.35s/it]predicting train subjects:  36%|███▋      | 104/285 [03:54<07:02,  2.33s/it]predicting train subjects:  37%|███▋      | 105/285 [03:56<07:00,  2.34s/it]predicting train subjects:  37%|███▋      | 106/285 [03:59<07:04,  2.37s/it]predicting train subjects:  38%|███▊      | 107/285 [04:01<06:57,  2.35s/it]predicting train subjects:  38%|███▊      | 108/285 [04:04<07:10,  2.43s/it]predicting train subjects:  38%|███▊      | 109/285 [04:06<06:56,  2.36s/it]predicting train subjects:  39%|███▊      | 110/285 [04:08<06:46,  2.32s/it]predicting train subjects:  39%|███▉      | 111/285 [04:10<06:43,  2.32s/it]predicting train subjects:  39%|███▉      | 112/285 [04:13<06:42,  2.33s/it]predicting train subjects:  40%|███▉      | 113/285 [04:15<06:52,  2.40s/it]predicting train subjects:  40%|████      | 114/285 [04:18<06:50,  2.40s/it]predicting train subjects:  40%|████      | 115/285 [04:20<06:47,  2.40s/it]predicting train subjects:  41%|████      | 116/285 [04:22<06:43,  2.39s/it]predicting train subjects:  41%|████      | 117/285 [04:25<06:33,  2.34s/it]predicting train subjects:  41%|████▏     | 118/285 [04:27<06:27,  2.32s/it]predicting train subjects:  42%|████▏     | 119/285 [04:29<06:23,  2.31s/it]predicting train subjects:  42%|████▏     | 120/285 [04:32<06:21,  2.31s/it]predicting train subjects:  42%|████▏     | 121/285 [04:34<06:12,  2.27s/it]predicting train subjects:  43%|████▎     | 122/285 [04:36<05:56,  2.19s/it]predicting train subjects:  43%|████▎     | 123/285 [04:38<05:33,  2.06s/it]predicting train subjects:  44%|████▎     | 124/285 [04:40<05:36,  2.09s/it]predicting train subjects:  44%|████▍     | 125/285 [04:42<05:51,  2.20s/it]predicting train subjects:  44%|████▍     | 126/285 [04:44<05:49,  2.20s/it]predicting train subjects:  45%|████▍     | 127/285 [04:46<05:37,  2.13s/it]predicting train subjects:  45%|████▍     | 128/285 [04:49<05:43,  2.19s/it]predicting train subjects:  45%|████▌     | 129/285 [04:51<05:54,  2.27s/it]predicting train subjects:  46%|████▌     | 130/285 [04:53<05:45,  2.23s/it]predicting train subjects:  46%|████▌     | 131/285 [04:56<05:49,  2.27s/it]predicting train subjects:  46%|████▋     | 132/285 [04:58<05:34,  2.18s/it]predicting train subjects:  47%|████▋     | 133/285 [05:00<05:30,  2.18s/it]predicting train subjects:  47%|████▋     | 134/285 [05:02<05:41,  2.26s/it]predicting train subjects:  47%|████▋     | 135/285 [05:04<05:30,  2.20s/it]predicting train subjects:  48%|████▊     | 136/285 [05:06<05:22,  2.16s/it]predicting train subjects:  48%|████▊     | 137/285 [05:08<05:16,  2.14s/it]predicting train subjects:  48%|████▊     | 138/285 [05:11<05:17,  2.16s/it]predicting train subjects:  49%|████▉     | 139/285 [05:13<05:20,  2.19s/it]predicting train subjects:  49%|████▉     | 140/285 [05:15<05:16,  2.18s/it]predicting train subjects:  49%|████▉     | 141/285 [05:17<05:17,  2.21s/it]predicting train subjects:  50%|████▉     | 142/285 [05:19<05:05,  2.14s/it]predicting train subjects:  50%|█████     | 143/285 [05:21<04:57,  2.09s/it]predicting train subjects:  51%|█████     | 144/285 [05:23<04:47,  2.04s/it]predicting train subjects:  51%|█████     | 145/285 [05:25<04:41,  2.01s/it]predicting train subjects:  51%|█████     | 146/285 [05:27<04:40,  2.01s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:29<04:32,  1.97s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:31<04:27,  1.96s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:33<04:26,  1.96s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:35<04:30,  2.00s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:37<04:27,  2.00s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:39<04:23,  1.98s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:41<04:18,  1.96s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:43<04:26,  2.03s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:45<04:38,  2.14s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:48<04:39,  2.16s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:50<04:33,  2.14s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:52<04:30,  2.13s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:54<04:29,  2.14s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:56<04:36,  2.21s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:58<04:23,  2.13s/it]predicting train subjects:  57%|█████▋    | 162/285 [06:00<04:14,  2.07s/it]predicting train subjects:  57%|█████▋    | 163/285 [06:02<04:10,  2.06s/it]predicting train subjects:  58%|█████▊    | 164/285 [06:04<04:06,  2.04s/it]predicting train subjects:  58%|█████▊    | 165/285 [06:06<04:03,  2.03s/it]predicting train subjects:  58%|█████▊    | 166/285 [06:09<04:12,  2.12s/it]predicting train subjects:  59%|█████▊    | 167/285 [06:11<04:02,  2.06s/it]predicting train subjects:  59%|█████▉    | 168/285 [06:13<04:02,  2.07s/it]predicting train subjects:  59%|█████▉    | 169/285 [06:15<03:54,  2.02s/it]predicting train subjects:  60%|█████▉    | 170/285 [06:17<03:54,  2.04s/it]predicting train subjects:  60%|██████    | 171/285 [06:19<03:53,  2.05s/it]predicting train subjects:  60%|██████    | 172/285 [06:21<03:46,  2.00s/it]predicting train subjects:  61%|██████    | 173/285 [06:22<03:37,  1.94s/it]predicting train subjects:  61%|██████    | 174/285 [06:24<03:37,  1.96s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:27<03:44,  2.04s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:29<03:38,  2.01s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:31<03:40,  2.04s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:33<03:37,  2.03s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:34<03:22,  1.91s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:36<03:15,  1.86s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:38<03:13,  1.86s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:40<03:10,  1.85s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:42<03:07,  1.84s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:43<02:58,  1.76s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:45<02:52,  1.73s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:46<02:49,  1.72s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:48<02:47,  1.71s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:50<02:42,  1.68s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:51<02:37,  1.64s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:53<02:34,  1.63s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:55<02:37,  1.68s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:56<02:36,  1.69s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:58<02:38,  1.72s/it]predicting train subjects:  68%|██████▊   | 194/285 [07:00<02:32,  1.68s/it]predicting train subjects:  68%|██████▊   | 195/285 [07:02<02:31,  1.69s/it]predicting train subjects:  69%|██████▉   | 196/285 [07:03<02:36,  1.76s/it]predicting train subjects:  69%|██████▉   | 197/285 [07:05<02:37,  1.79s/it]predicting train subjects:  69%|██████▉   | 198/285 [07:07<02:37,  1.80s/it]predicting train subjects:  70%|██████▉   | 199/285 [07:09<02:35,  1.81s/it]predicting train subjects:  70%|███████   | 200/285 [07:11<02:35,  1.82s/it]predicting train subjects:  71%|███████   | 201/285 [07:13<02:32,  1.82s/it]predicting train subjects:  71%|███████   | 202/285 [07:14<02:28,  1.79s/it]predicting train subjects:  71%|███████   | 203/285 [07:16<02:24,  1.77s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:18<02:22,  1.76s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:20<02:19,  1.74s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:21<02:17,  1.75s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:23<02:19,  1.79s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:25<02:17,  1.78s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:27<02:13,  1.75s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:28<02:09,  1.73s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:30<02:08,  1.74s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:32<02:05,  1.72s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:33<02:05,  1.74s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:35<01:59,  1.68s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:37<01:55,  1.65s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:38<01:49,  1.59s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:40<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:41<01:41,  1.52s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:42<01:39,  1.51s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:44<01:36,  1.49s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:45<01:34,  1.48s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:47<01:33,  1.48s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:48<01:33,  1.50s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:50<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:51<01:31,  1.52s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:53<01:29,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:55<01:29,  1.55s/it]predicting train subjects:  80%|████████  | 228/285 [07:56<01:26,  1.53s/it]predicting train subjects:  80%|████████  | 229/285 [07:58<01:25,  1.53s/it]predicting train subjects:  81%|████████  | 230/285 [07:59<01:23,  1.52s/it]predicting train subjects:  81%|████████  | 231/285 [08:01<01:24,  1.56s/it]predicting train subjects:  81%|████████▏ | 232/285 [08:03<01:28,  1.68s/it]predicting train subjects:  82%|████████▏ | 233/285 [08:05<01:30,  1.74s/it]predicting train subjects:  82%|████████▏ | 234/285 [08:06<01:30,  1.78s/it]predicting train subjects:  82%|████████▏ | 235/285 [08:08<01:30,  1.80s/it]predicting train subjects:  83%|████████▎ | 236/285 [08:10<01:28,  1.81s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:12<01:26,  1.81s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:14<01:26,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:16<01:25,  1.85s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:18<01:22,  1.84s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:20<01:22,  1.88s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:21<01:21,  1.88s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:23<01:18,  1.87s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:25<01:16,  1.86s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:27<01:14,  1.87s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:29<01:12,  1.86s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:31<01:10,  1.85s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:32<01:08,  1.84s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:34<01:06,  1.85s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:36<01:01,  1.76s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:37<00:57,  1.68s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:39<00:54,  1.66s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:40<00:51,  1.60s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:42<00:48,  1.57s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:43<00:46,  1.56s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:45<00:44,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [08:47<00:42,  1.54s/it]predicting train subjects:  91%|█████████ | 258/285 [08:48<00:41,  1.53s/it]predicting train subjects:  91%|█████████ | 259/285 [08:50<00:39,  1.53s/it]predicting train subjects:  91%|█████████ | 260/285 [08:51<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:53<00:36,  1.52s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:54<00:34,  1.50s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:56<00:32,  1.50s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:57<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:58<00:29,  1.49s/it]predicting train subjects:  93%|█████████▎| 266/285 [09:00<00:28,  1.48s/it]predicting train subjects:  94%|█████████▎| 267/285 [09:01<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [09:03<00:27,  1.63s/it]predicting train subjects:  94%|█████████▍| 269/285 [09:05<00:27,  1.69s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:07<00:26,  1.75s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:09<00:25,  1.79s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:11<00:24,  1.85s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:13<00:22,  1.86s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:15<00:20,  1.88s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:17<00:18,  1.88s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:19<00:16,  1.88s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:21<00:15,  1.91s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:22<00:13,  1.90s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:24<00:11,  1.90s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:26<00:09,  1.88s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:28<00:07,  1.86s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:30<00:05,  1.87s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:32<00:03,  1.88s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:34<00:01,  1.90s/it]predicting train subjects: 100%|██████████| 285/285 [09:36<00:00,  1.89s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:52,  1.24s/it]Loading train:   1%|          | 2/285 [00:02<06:15,  1.33s/it]Loading train:   1%|          | 3/285 [00:04<06:09,  1.31s/it]Loading train:   1%|▏         | 4/285 [00:05<06:38,  1.42s/it]Loading train:   2%|▏         | 5/285 [00:06<06:04,  1.30s/it]Loading train:   2%|▏         | 6/285 [00:08<06:26,  1.39s/it]Loading train:   2%|▏         | 7/285 [00:10<06:52,  1.48s/it]Loading train:   3%|▎         | 8/285 [00:11<07:05,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:13<06:55,  1.50s/it]Loading train:   4%|▎         | 10/285 [00:14<06:17,  1.37s/it]Loading train:   4%|▍         | 11/285 [00:15<06:09,  1.35s/it]Loading train:   4%|▍         | 12/285 [00:16<05:42,  1.26s/it]Loading train:   5%|▍         | 13/285 [00:17<05:30,  1.21s/it]Loading train:   5%|▍         | 14/285 [00:18<05:16,  1.17s/it]Loading train:   5%|▌         | 15/285 [00:19<05:07,  1.14s/it]Loading train:   6%|▌         | 16/285 [00:20<05:01,  1.12s/it]Loading train:   6%|▌         | 17/285 [00:21<05:00,  1.12s/it]Loading train:   6%|▋         | 18/285 [00:23<04:54,  1.10s/it]Loading train:   7%|▋         | 19/285 [00:24<04:45,  1.07s/it]Loading train:   7%|▋         | 20/285 [00:25<04:37,  1.05s/it]Loading train:   7%|▋         | 21/285 [00:25<04:25,  1.00s/it]Loading train:   8%|▊         | 22/285 [00:27<04:30,  1.03s/it]Loading train:   8%|▊         | 23/285 [00:28<04:32,  1.04s/it]Loading train:   8%|▊         | 24/285 [00:29<04:43,  1.09s/it]Loading train:   9%|▉         | 25/285 [00:30<04:53,  1.13s/it]Loading train:   9%|▉         | 26/285 [00:32<05:29,  1.27s/it]Loading train:   9%|▉         | 27/285 [00:33<05:43,  1.33s/it]Loading train:  10%|▉         | 28/285 [00:35<05:49,  1.36s/it]Loading train:  10%|█         | 29/285 [00:36<06:02,  1.42s/it]Loading train:  11%|█         | 30/285 [00:37<05:43,  1.35s/it]Loading train:  11%|█         | 31/285 [00:39<05:49,  1.38s/it]Loading train:  11%|█         | 32/285 [00:40<05:43,  1.36s/it]Loading train:  12%|█▏        | 33/285 [00:41<05:42,  1.36s/it]Loading train:  12%|█▏        | 34/285 [00:43<05:44,  1.37s/it]Loading train:  12%|█▏        | 35/285 [00:44<05:36,  1.35s/it]Loading train:  13%|█▎        | 36/285 [00:46<06:17,  1.52s/it]Loading train:  13%|█▎        | 37/285 [00:47<06:00,  1.45s/it]Loading train:  13%|█▎        | 38/285 [00:49<05:51,  1.42s/it]Loading train:  14%|█▎        | 39/285 [00:50<05:55,  1.45s/it]Loading train:  14%|█▍        | 40/285 [00:51<05:40,  1.39s/it]Loading train:  14%|█▍        | 41/285 [00:53<05:38,  1.39s/it]Loading train:  15%|█▍        | 42/285 [00:54<06:00,  1.48s/it]Loading train:  15%|█▌        | 43/285 [00:56<05:55,  1.47s/it]Loading train:  15%|█▌        | 44/285 [00:58<06:19,  1.58s/it]Loading train:  16%|█▌        | 45/285 [01:00<06:45,  1.69s/it]Loading train:  16%|█▌        | 46/285 [01:01<06:24,  1.61s/it]Loading train:  16%|█▋        | 47/285 [01:02<05:32,  1.40s/it]Loading train:  17%|█▋        | 48/285 [01:03<04:59,  1.26s/it]Loading train:  17%|█▋        | 49/285 [01:04<04:37,  1.18s/it]Loading train:  18%|█▊        | 50/285 [01:05<04:27,  1.14s/it]Loading train:  18%|█▊        | 51/285 [01:06<04:19,  1.11s/it]Loading train:  18%|█▊        | 52/285 [01:07<04:24,  1.13s/it]Loading train:  19%|█▊        | 53/285 [01:09<04:56,  1.28s/it]Loading train:  19%|█▉        | 54/285 [01:10<04:34,  1.19s/it]Loading train:  19%|█▉        | 55/285 [01:11<04:19,  1.13s/it]Loading train:  20%|█▉        | 56/285 [01:12<04:12,  1.10s/it]Loading train:  20%|██        | 57/285 [01:13<03:54,  1.03s/it]Loading train:  20%|██        | 58/285 [01:14<03:58,  1.05s/it]Loading train:  21%|██        | 59/285 [01:15<04:31,  1.20s/it]Loading train:  21%|██        | 60/285 [01:16<04:23,  1.17s/it]Loading train:  21%|██▏       | 61/285 [01:17<04:12,  1.13s/it]Loading train:  22%|██▏       | 62/285 [01:19<04:07,  1.11s/it]Loading train:  22%|██▏       | 63/285 [01:20<03:56,  1.07s/it]Loading train:  22%|██▏       | 64/285 [01:21<04:36,  1.25s/it]Loading train:  23%|██▎       | 65/285 [01:23<05:29,  1.50s/it]Loading train:  23%|██▎       | 66/285 [01:25<06:05,  1.67s/it]Loading train:  24%|██▎       | 67/285 [01:26<05:19,  1.46s/it]Loading train:  24%|██▍       | 68/285 [01:27<04:37,  1.28s/it]Loading train:  24%|██▍       | 69/285 [01:28<04:12,  1.17s/it]Loading train:  25%|██▍       | 70/285 [01:29<03:59,  1.12s/it]Loading train:  25%|██▍       | 71/285 [01:30<03:58,  1.12s/it]Loading train:  25%|██▌       | 72/285 [01:31<03:59,  1.13s/it]Loading train:  26%|██▌       | 73/285 [01:32<03:44,  1.06s/it]Loading train:  26%|██▌       | 74/285 [01:33<03:33,  1.01s/it]Loading train:  26%|██▋       | 75/285 [01:34<03:34,  1.02s/it]Loading train:  27%|██▋       | 76/285 [01:35<03:25,  1.02it/s]Loading train:  27%|██▋       | 77/285 [01:36<03:19,  1.04it/s]Loading train:  27%|██▋       | 78/285 [01:37<03:32,  1.03s/it]Loading train:  28%|██▊       | 79/285 [01:38<03:30,  1.02s/it]Loading train:  28%|██▊       | 80/285 [01:39<03:27,  1.01s/it]Loading train:  28%|██▊       | 81/285 [01:40<03:21,  1.01it/s]Loading train:  29%|██▉       | 82/285 [01:41<03:20,  1.01it/s]Loading train:  29%|██▉       | 83/285 [01:42<03:17,  1.02it/s]Loading train:  29%|██▉       | 84/285 [01:43<03:18,  1.01it/s]Loading train:  30%|██▉       | 85/285 [01:45<03:45,  1.13s/it]Loading train:  30%|███       | 86/285 [01:46<03:42,  1.12s/it]Loading train:  31%|███       | 87/285 [01:47<03:31,  1.07s/it]Loading train:  31%|███       | 88/285 [01:48<03:26,  1.05s/it]Loading train:  31%|███       | 89/285 [01:49<03:21,  1.03s/it]Loading train:  32%|███▏      | 90/285 [01:50<03:28,  1.07s/it]Loading train:  32%|███▏      | 91/285 [01:51<03:48,  1.18s/it]Loading train:  32%|███▏      | 92/285 [01:52<03:46,  1.18s/it]Loading train:  33%|███▎      | 93/285 [01:53<03:39,  1.14s/it]Loading train:  33%|███▎      | 94/285 [01:55<03:39,  1.15s/it]Loading train:  33%|███▎      | 95/285 [01:56<03:33,  1.13s/it]Loading train:  34%|███▎      | 96/285 [01:57<03:36,  1.15s/it]Loading train:  34%|███▍      | 97/285 [01:58<03:58,  1.27s/it]Loading train:  34%|███▍      | 98/285 [02:00<04:20,  1.39s/it]Loading train:  35%|███▍      | 99/285 [02:02<05:04,  1.64s/it]Loading train:  35%|███▌      | 100/285 [02:04<05:06,  1.66s/it]Loading train:  35%|███▌      | 101/285 [02:05<04:52,  1.59s/it]Loading train:  36%|███▌      | 102/285 [02:07<04:39,  1.53s/it]Loading train:  36%|███▌      | 103/285 [02:08<04:14,  1.40s/it]Loading train:  36%|███▋      | 104/285 [02:09<03:55,  1.30s/it]Loading train:  37%|███▋      | 105/285 [02:10<03:38,  1.21s/it]Loading train:  37%|███▋      | 106/285 [02:11<03:31,  1.18s/it]Loading train:  38%|███▊      | 107/285 [02:12<03:16,  1.10s/it]Loading train:  38%|███▊      | 108/285 [02:13<03:08,  1.07s/it]Loading train:  38%|███▊      | 109/285 [02:14<02:58,  1.02s/it]Loading train:  39%|███▊      | 110/285 [02:15<02:52,  1.01it/s]Loading train:  39%|███▉      | 111/285 [02:16<02:48,  1.03it/s]Loading train:  39%|███▉      | 112/285 [02:17<02:46,  1.04it/s]Loading train:  40%|███▉      | 113/285 [02:18<02:53,  1.01s/it]Loading train:  40%|████      | 114/285 [02:19<02:47,  1.02it/s]Loading train:  40%|████      | 115/285 [02:20<02:42,  1.04it/s]Loading train:  41%|████      | 116/285 [02:20<02:35,  1.09it/s]Loading train:  41%|████      | 117/285 [02:21<02:34,  1.09it/s]Loading train:  41%|████▏     | 118/285 [02:22<02:29,  1.12it/s]Loading train:  42%|████▏     | 119/285 [02:23<02:34,  1.08it/s]Loading train:  42%|████▏     | 120/285 [02:24<02:37,  1.05it/s]Loading train:  42%|████▏     | 121/285 [02:26<02:56,  1.08s/it]Loading train:  43%|████▎     | 122/285 [02:27<03:01,  1.12s/it]Loading train:  43%|████▎     | 123/285 [02:28<02:59,  1.11s/it]Loading train:  44%|████▎     | 124/285 [02:29<02:47,  1.04s/it]Loading train:  44%|████▍     | 125/285 [02:30<02:38,  1.01it/s]Loading train:  44%|████▍     | 126/285 [02:30<02:30,  1.06it/s]Loading train:  45%|████▍     | 127/285 [02:31<02:27,  1.07it/s]Loading train:  45%|████▍     | 128/285 [02:32<02:26,  1.07it/s]Loading train:  45%|████▌     | 129/285 [02:33<02:22,  1.09it/s]Loading train:  46%|████▌     | 130/285 [02:34<02:19,  1.11it/s]Loading train:  46%|████▌     | 131/285 [02:35<02:11,  1.17it/s]Loading train:  46%|████▋     | 132/285 [02:36<02:10,  1.17it/s]Loading train:  47%|████▋     | 133/285 [02:37<02:09,  1.17it/s]Loading train:  47%|████▋     | 134/285 [02:37<02:09,  1.17it/s]Loading train:  47%|████▋     | 135/285 [02:38<02:07,  1.18it/s]Loading train:  48%|████▊     | 136/285 [02:39<02:08,  1.16it/s]Loading train:  48%|████▊     | 137/285 [02:40<02:08,  1.15it/s]Loading train:  48%|████▊     | 138/285 [02:41<02:07,  1.16it/s]Loading train:  49%|████▉     | 139/285 [02:42<02:11,  1.11it/s]Loading train:  49%|████▉     | 140/285 [02:43<02:03,  1.17it/s]Loading train:  49%|████▉     | 141/285 [02:43<02:03,  1.16it/s]Loading train:  50%|████▉     | 142/285 [02:44<02:03,  1.16it/s]Loading train:  50%|█████     | 143/285 [02:45<02:01,  1.17it/s]Loading train:  51%|█████     | 144/285 [02:46<01:59,  1.18it/s]Loading train:  51%|█████     | 145/285 [02:47<01:57,  1.19it/s]Loading train:  51%|█████     | 146/285 [02:48<01:58,  1.17it/s]Loading train:  52%|█████▏    | 147/285 [02:48<01:55,  1.20it/s]Loading train:  52%|█████▏    | 148/285 [02:49<01:57,  1.17it/s]Loading train:  52%|█████▏    | 149/285 [02:50<01:57,  1.15it/s]Loading train:  53%|█████▎    | 150/285 [02:51<01:54,  1.18it/s]Loading train:  53%|█████▎    | 151/285 [02:52<01:54,  1.17it/s]Loading train:  53%|█████▎    | 152/285 [02:53<01:50,  1.20it/s]Loading train:  54%|█████▎    | 153/285 [02:54<01:51,  1.19it/s]Loading train:  54%|█████▍    | 154/285 [02:54<01:45,  1.24it/s]Loading train:  54%|█████▍    | 155/285 [02:55<01:42,  1.26it/s]Loading train:  55%|█████▍    | 156/285 [02:56<01:41,  1.27it/s]Loading train:  55%|█████▌    | 157/285 [02:57<01:41,  1.26it/s]Loading train:  55%|█████▌    | 158/285 [02:58<01:48,  1.17it/s]Loading train:  56%|█████▌    | 159/285 [02:59<01:48,  1.17it/s]Loading train:  56%|█████▌    | 160/285 [02:59<01:43,  1.21it/s]Loading train:  56%|█████▋    | 161/285 [03:00<01:42,  1.21it/s]Loading train:  57%|█████▋    | 162/285 [03:01<01:41,  1.22it/s]Loading train:  57%|█████▋    | 163/285 [03:02<01:39,  1.22it/s]Loading train:  58%|█████▊    | 164/285 [03:02<01:36,  1.25it/s]Loading train:  58%|█████▊    | 165/285 [03:03<01:34,  1.27it/s]Loading train:  58%|█████▊    | 166/285 [03:04<01:34,  1.26it/s]Loading train:  59%|█████▊    | 167/285 [03:05<01:34,  1.25it/s]Loading train:  59%|█████▉    | 168/285 [03:06<01:31,  1.28it/s]Loading train:  59%|█████▉    | 169/285 [03:06<01:31,  1.26it/s]Loading train:  60%|█████▉    | 170/285 [03:07<01:28,  1.30it/s]Loading train:  60%|██████    | 171/285 [03:08<01:29,  1.27it/s]Loading train:  60%|██████    | 172/285 [03:09<01:26,  1.30it/s]Loading train:  61%|██████    | 173/285 [03:09<01:26,  1.29it/s]Loading train:  61%|██████    | 174/285 [03:10<01:29,  1.24it/s]Loading train:  61%|██████▏   | 175/285 [03:11<01:28,  1.25it/s]Loading train:  62%|██████▏   | 176/285 [03:12<01:29,  1.22it/s]Loading train:  62%|██████▏   | 177/285 [03:13<01:27,  1.23it/s]Loading train:  62%|██████▏   | 178/285 [03:14<01:25,  1.26it/s]Loading train:  63%|██████▎   | 179/285 [03:14<01:22,  1.29it/s]Loading train:  63%|██████▎   | 180/285 [03:15<01:21,  1.30it/s]Loading train:  64%|██████▎   | 181/285 [03:16<01:20,  1.29it/s]Loading train:  64%|██████▍   | 182/285 [03:17<01:17,  1.32it/s]Loading train:  64%|██████▍   | 183/285 [03:17<01:15,  1.34it/s]Loading train:  65%|██████▍   | 184/285 [03:18<01:16,  1.32it/s]Loading train:  65%|██████▍   | 185/285 [03:19<01:14,  1.33it/s]Loading train:  65%|██████▌   | 186/285 [03:19<01:13,  1.35it/s]Loading train:  66%|██████▌   | 187/285 [03:20<01:17,  1.26it/s]Loading train:  66%|██████▌   | 188/285 [03:21<01:14,  1.30it/s]Loading train:  66%|██████▋   | 189/285 [03:22<01:11,  1.34it/s]Loading train:  67%|██████▋   | 190/285 [03:23<01:09,  1.37it/s]Loading train:  67%|██████▋   | 191/285 [03:23<01:08,  1.37it/s]Loading train:  67%|██████▋   | 192/285 [03:24<01:08,  1.36it/s]Loading train:  68%|██████▊   | 193/285 [03:25<01:07,  1.36it/s]Loading train:  68%|██████▊   | 194/285 [03:25<01:06,  1.36it/s]Loading train:  68%|██████▊   | 195/285 [03:26<01:06,  1.36it/s]Loading train:  69%|██████▉   | 196/285 [03:27<01:12,  1.23it/s]Loading train:  69%|██████▉   | 197/285 [03:28<01:13,  1.20it/s]Loading train:  69%|██████▉   | 198/285 [03:29<01:15,  1.15it/s]Loading train:  70%|██████▉   | 199/285 [03:30<01:13,  1.17it/s]Loading train:  70%|███████   | 200/285 [03:31<01:13,  1.16it/s]Loading train:  71%|███████   | 201/285 [03:32<01:12,  1.15it/s]Loading train:  71%|███████   | 202/285 [03:33<01:12,  1.14it/s]Loading train:  71%|███████   | 203/285 [03:33<01:13,  1.11it/s]Loading train:  72%|███████▏  | 204/285 [03:34<01:14,  1.08it/s]Loading train:  72%|███████▏  | 205/285 [03:36<01:17,  1.03it/s]Loading train:  72%|███████▏  | 206/285 [03:37<01:26,  1.09s/it]Loading train:  73%|███████▎  | 207/285 [03:38<01:25,  1.09s/it]Loading train:  73%|███████▎  | 208/285 [03:39<01:18,  1.01s/it]Loading train:  73%|███████▎  | 209/285 [03:40<01:13,  1.04it/s]Loading train:  74%|███████▎  | 210/285 [03:41<01:10,  1.06it/s]Loading train:  74%|███████▍  | 211/285 [03:41<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [03:42<01:07,  1.09it/s]Loading train:  75%|███████▍  | 213/285 [03:44<01:20,  1.12s/it]Loading train:  75%|███████▌  | 214/285 [03:46<01:31,  1.29s/it]Loading train:  75%|███████▌  | 215/285 [03:47<01:26,  1.24s/it]Loading train:  76%|███████▌  | 216/285 [03:48<01:20,  1.17s/it]Loading train:  76%|███████▌  | 217/285 [03:49<01:20,  1.19s/it]Loading train:  76%|███████▋  | 218/285 [03:50<01:21,  1.21s/it]Loading train:  77%|███████▋  | 219/285 [03:52<01:22,  1.25s/it]Loading train:  77%|███████▋  | 220/285 [03:53<01:17,  1.19s/it]Loading train:  78%|███████▊  | 221/285 [03:54<01:18,  1.22s/it]Loading train:  78%|███████▊  | 222/285 [03:55<01:18,  1.25s/it]Loading train:  78%|███████▊  | 223/285 [03:56<01:15,  1.22s/it]Loading train:  79%|███████▊  | 224/285 [03:58<01:13,  1.20s/it]Loading train:  79%|███████▉  | 225/285 [03:59<01:10,  1.18s/it]Loading train:  79%|███████▉  | 226/285 [04:00<01:09,  1.19s/it]Loading train:  80%|███████▉  | 227/285 [04:01<01:05,  1.13s/it]Loading train:  80%|████████  | 228/285 [04:02<01:05,  1.15s/it]Loading train:  80%|████████  | 229/285 [04:03<01:02,  1.12s/it]Loading train:  81%|████████  | 230/285 [04:04<01:03,  1.15s/it]Loading train:  81%|████████  | 231/285 [04:06<01:04,  1.19s/it]Loading train:  81%|████████▏ | 232/285 [04:07<01:04,  1.22s/it]Loading train:  82%|████████▏ | 233/285 [04:09<01:09,  1.33s/it]Loading train:  82%|████████▏ | 234/285 [04:10<01:14,  1.46s/it]Loading train:  82%|████████▏ | 235/285 [04:12<01:14,  1.49s/it]Loading train:  83%|████████▎ | 236/285 [04:13<01:13,  1.50s/it]Loading train:  83%|████████▎ | 237/285 [04:15<01:09,  1.44s/it]Loading train:  84%|████████▎ | 238/285 [04:16<01:09,  1.49s/it]Loading train:  84%|████████▍ | 239/285 [04:18<01:06,  1.45s/it]Loading train:  84%|████████▍ | 240/285 [04:19<01:05,  1.46s/it]Loading train:  85%|████████▍ | 241/285 [04:20<01:00,  1.37s/it]Loading train:  85%|████████▍ | 242/285 [04:21<00:54,  1.26s/it]Loading train:  85%|████████▌ | 243/285 [04:22<00:50,  1.21s/it]Loading train:  86%|████████▌ | 244/285 [04:23<00:47,  1.17s/it]Loading train:  86%|████████▌ | 245/285 [04:25<00:50,  1.27s/it]Loading train:  86%|████████▋ | 246/285 [04:27<00:57,  1.48s/it]Loading train:  87%|████████▋ | 247/285 [04:29<00:58,  1.55s/it]Loading train:  87%|████████▋ | 248/285 [04:30<00:52,  1.41s/it]Loading train:  87%|████████▋ | 249/285 [04:31<00:46,  1.30s/it]Loading train:  88%|████████▊ | 250/285 [04:32<00:42,  1.20s/it]Loading train:  88%|████████▊ | 251/285 [04:32<00:36,  1.06s/it]Loading train:  88%|████████▊ | 252/285 [04:33<00:34,  1.04s/it]Loading train:  89%|████████▉ | 253/285 [04:35<00:35,  1.11s/it]Loading train:  89%|████████▉ | 254/285 [04:36<00:34,  1.11s/it]Loading train:  89%|████████▉ | 255/285 [04:37<00:31,  1.06s/it]Loading train:  90%|████████▉ | 256/285 [04:38<00:28,  1.02it/s]Loading train:  90%|█████████ | 257/285 [04:38<00:26,  1.04it/s]Loading train:  91%|█████████ | 258/285 [04:39<00:25,  1.06it/s]Loading train:  91%|█████████ | 259/285 [04:41<00:26,  1.02s/it]Loading train:  91%|█████████ | 260/285 [04:41<00:24,  1.01it/s]Loading train:  92%|█████████▏| 261/285 [04:42<00:23,  1.03it/s]Loading train:  92%|█████████▏| 262/285 [04:43<00:21,  1.05it/s]Loading train:  92%|█████████▏| 263/285 [04:44<00:20,  1.09it/s]Loading train:  93%|█████████▎| 264/285 [04:45<00:18,  1.11it/s]Loading train:  93%|█████████▎| 265/285 [04:46<00:18,  1.10it/s]Loading train:  93%|█████████▎| 266/285 [04:47<00:18,  1.01it/s]Loading train:  94%|█████████▎| 267/285 [04:48<00:19,  1.09s/it]Loading train:  94%|█████████▍| 268/285 [04:50<00:20,  1.23s/it]Loading train:  94%|█████████▍| 269/285 [04:51<00:18,  1.17s/it]Loading train:  95%|█████████▍| 270/285 [04:52<00:16,  1.12s/it]Loading train:  95%|█████████▌| 271/285 [04:53<00:15,  1.14s/it]Loading train:  95%|█████████▌| 272/285 [04:54<00:14,  1.13s/it]Loading train:  96%|█████████▌| 273/285 [04:56<00:15,  1.28s/it]Loading train:  96%|█████████▌| 274/285 [04:57<00:14,  1.28s/it]Loading train:  96%|█████████▋| 275/285 [04:58<00:12,  1.21s/it]Loading train:  97%|█████████▋| 276/285 [04:59<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [05:00<00:09,  1.14s/it]Loading train:  98%|█████████▊| 278/285 [05:01<00:07,  1.11s/it]Loading train:  98%|█████████▊| 279/285 [05:03<00:06,  1.14s/it]Loading train:  98%|█████████▊| 280/285 [05:04<00:05,  1.15s/it]Loading train:  99%|█████████▊| 281/285 [05:05<00:04,  1.15s/it]Loading train:  99%|█████████▉| 282/285 [05:06<00:03,  1.11s/it]Loading train:  99%|█████████▉| 283/285 [05:07<00:02,  1.09s/it]Loading train: 100%|█████████▉| 284/285 [05:08<00:01,  1.09s/it]Loading train: 100%|██████████| 285/285 [05:09<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:01, 182.02it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:01, 193.60it/s]concatenating: train:  20%|█▉        | 56/285 [00:00<00:01, 171.73it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:00, 198.05it/s]concatenating: train:  41%|████▏     | 118/285 [00:00<00:00, 220.82it/s]concatenating: train:  49%|████▉     | 140/285 [00:00<00:00, 214.17it/s]concatenating: train:  60%|█████▉    | 170/285 [00:00<00:00, 233.88it/s]concatenating: train:  71%|███████   | 202/285 [00:00<00:00, 253.12it/s]concatenating: train:  82%|████████▏ | 234/285 [00:00<00:00, 268.72it/s]concatenating: train:  94%|█████████▎| 267/285 [00:01<00:00, 283.45it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 255.92it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.33s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 68.63it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 56, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 56, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 56, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 56, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 56, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 56, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 28, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 28, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 28, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 28, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 28, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 28, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 28, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 28, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 14, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 14, 40)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 14, 80)   28880       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 14, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 14, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 14, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 14, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 14, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 10, 7, 80)    0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 10, 7, 80)    0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 10, 7, 160)   115360      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 10, 7, 160)   640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 10, 7, 160)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 10, 7, 160)   230560      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 10, 7, 160)   640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 10, 7, 160)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 10, 7, 160)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 20, 14, 80)   51280       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 20, 14, 160)  0           conv2d_transpose_1[0][0]         2019-07-01 00:28:54.778376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-01 00:28:54.778494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-01 00:28:54.778510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-01 00:28:54.778518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-01 00:28:54.778969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 20, 14, 80)   115280      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 20, 14, 80)   320         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 20, 14, 80)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 20, 14, 80)   57680       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 20, 14, 80)   320         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 20, 14, 80)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 14, 80)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 40, 28, 40)   12840       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 28, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 40, 28, 40)   28840       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 40, 28, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 40, 28, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 40, 28, 40)   14440       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 40, 28, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 40, 28, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 28, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 80, 56, 20)   3220        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 80, 56, 40)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 56, 20)   7220        concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 56, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 56, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 56, 20)   3620        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 56, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 56, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 56, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 56, 13)   273         dropout_7[0][0]                  
==================================================================================================
Total params: 756,193
Trainable params: 754,433
Non-trainable params: 1,760
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [2.40062229e+01 1.18201001e+01 2.77420847e+01 3.44797912e+00
 1.00219785e+01 2.61335372e+00 3.13040004e+01 4.16624627e+01
 3.18192739e+01 4.90028027e+00 1.08801089e+02 7.17113750e+01
 8.70380757e-02]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 19s - loss: 2267.2224 - acc: 0.8938 - mDice: 0.2437 - val_loss: 1585.9674 - val_acc: 0.9197 - val_mDice: 0.3527

Epoch 00001: val_mDice improved from -inf to 0.35272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 1194.0812 - acc: 0.9085 - mDice: 0.4540 - val_loss: 1762.2700 - val_acc: 0.9200 - val_mDice: 0.3866

Epoch 00002: val_mDice improved from 0.35272 to 0.38664, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 10s - loss: 994.2508 - acc: 0.9144 - mDice: 0.5285 - val_loss: 1788.9809 - val_acc: 0.9232 - val_mDice: 0.4212

Epoch 00003: val_mDice improved from 0.38664 to 0.42119, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 890.9239 - acc: 0.9177 - mDice: 0.5733 - val_loss: 2064.4147 - val_acc: 0.9295 - val_mDice: 0.4137

Epoch 00004: val_mDice did not improve from 0.42119
Epoch 5/300
 - 10s - loss: 815.9301 - acc: 0.9199 - mDice: 0.6064 - val_loss: 2020.3174 - val_acc: 0.9276 - val_mDice: 0.4181

Epoch 00005: val_mDice did not improve from 0.42119
Epoch 6/300
 - 10s - loss: 771.9971 - acc: 0.9215 - mDice: 0.6256 - val_loss: 2117.2356 - val_acc: 0.9295 - val_mDice: 0.4071

Epoch 00006: val_mDice did not improve from 0.42119
Epoch 7/300
 - 10s - loss: 735.7409 - acc: 0.9226 - mDice: 0.6416 - val_loss: 1992.3204 - val_acc: 0.9310 - val_mDice: 0.4358

Epoch 00007: val_mDice improved from 0.42119 to 0.43583, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 708.2422 - acc: 0.9239 - mDice: 0.6544 - val_loss: 1992.7489 - val_acc: 0.9340 - val_mDice: 0.4406

Epoch 00008: val_mDice improved from 0.43583 to 0.44062, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 10s - loss: 684.1326 - acc: 0.9250 - mDice: 0.6648 - val_loss: 2215.7888 - val_acc: 0.9343 - val_mDice: 0.4232

Epoch 00009: val_mDice did not improve from 0.44062
Epoch 10/300
 - 10s - loss: 665.1633 - acc: 0.9259 - mDice: 0.6737 - val_loss: 1949.5686 - val_acc: 0.9370 - val_mDice: 0.4583

Epoch 00010: val_mDice improved from 0.44062 to 0.45832, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 650.5702 - acc: 0.9264 - mDice: 0.6807 - val_loss: 2178.0754 - val_acc: 0.9356 - val_mDice: 0.4340

Epoch 00011: val_mDice did not improve from 0.45832
Epoch 12/300
 - 10s - loss: 633.5965 - acc: 0.9271 - mDice: 0.6885 - val_loss: 2171.4258 - val_acc: 0.9357 - val_mDice: 0.4398

Epoch 00012: val_mDice did not improve from 0.45832
Epoch 13/300
 - 10s - loss: 619.8395 - acc: 0.9277 - mDice: 0.6946 - val_loss: 2077.1952 - val_acc: 0.9358 - val_mDice: 0.4552

Epoch 00013: val_mDice did not improve from 0.45832
Epoch 14/300
 - 10s - loss: 610.5284 - acc: 0.9283 - mDice: 0.6988 - val_loss: 2142.7650 - val_acc: 0.9356 - val_mDice: 0.4503

Epoch 00014: val_mDice did not improve from 0.45832
Epoch 15/300
 - 10s - loss: 596.2631 - acc: 0.9289 - mDice: 0.7060 - val_loss: 2117.9744 - val_acc: 0.9370 - val_mDice: 0.4551

Epoch 00015: val_mDice did not improve from 0.45832
Epoch 16/300
 - 10s - loss: 588.3657 - acc: 0.9295 - mDice: 0.7098 - val_loss: 2091.8940 - val_acc: 0.9366 - val_mDice: 0.4622

Epoch 00016: val_mDice improved from 0.45832 to 0.46222, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 578.9552 - acc: 0.9298 - mDice: 0.7140 - val_loss: 2278.1262 - val_acc: 0.9370 - val_mDice: 0.4508

Epoch 00017: val_mDice did not improve from 0.46222
Epoch 18/300
 - 10s - loss: 571.4484 - acc: 0.9299 - mDice: 0.7180 - val_loss: 2131.4362 - val_acc: 0.9372 - val_mDice: 0.4613

Epoch 00018: val_mDice did not improve from 0.46222
Epoch 19/300
 - 11s - loss: 565.8134 - acc: 0.9302 - mDice: 0.7204 - val_loss: 2290.1684 - val_acc: 0.9374 - val_mDice: 0.4513

Epoch 00019: val_mDice did not improve from 0.46222
Epoch 20/300
 - 10s - loss: 558.0487 - acc: 0.9305 - mDice: 0.7240 - val_loss: 2354.9394 - val_acc: 0.9361 - val_mDice: 0.4482

Epoch 00020: val_mDice did not improve from 0.46222
Epoch 21/300
 - 10s - loss: 550.3750 - acc: 0.9308 - mDice: 0.7273 - val_loss: 2412.5965 - val_acc: 0.9372 - val_mDice: 0.4433

Epoch 00021: val_mDice did not improve from 0.46222
Epoch 22/300
 - 10s - loss: 545.8388 - acc: 0.9311 - mDice: 0.7300 - val_loss: 2224.2781 - val_acc: 0.9367 - val_mDice: 0.4624

Epoch 00022: val_mDice improved from 0.46222 to 0.46244, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 10s - loss: 539.6631 - acc: 0.9314 - mDice: 0.7329 - val_loss: 2311.0223 - val_acc: 0.9370 - val_mDice: 0.4646

Epoch 00023: val_mDice improved from 0.46244 to 0.46458, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 10s - loss: 533.9477 - acc: 0.9317 - mDice: 0.7354 - val_loss: 2337.3918 - val_acc: 0.9388 - val_mDice: 0.4659

Epoch 00024: val_mDice improved from 0.46458 to 0.46592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 10s - loss: 528.7194 - acc: 0.9321 - mDice: 0.7384 - val_loss: 2297.9763 - val_acc: 0.9377 - val_mDice: 0.4681

Epoch 00025: val_mDice improved from 0.46592 to 0.46808, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 10s - loss: 523.6326 - acc: 0.9322 - mDice: 0.7404 - val_loss: 2356.5040 - val_acc: 0.9376 - val_mDice: 0.4628

Epoch 00026: val_mDice did not improve from 0.46808
Epoch 27/300
 - 10s - loss: 520.7988 - acc: 0.9326 - mDice: 0.7420 - val_loss: 2382.0629 - val_acc: 0.9374 - val_mDice: 0.4579

Epoch 00027: val_mDice did not improve from 0.46808
Epoch 28/300
 - 10s - loss: 515.6328 - acc: 0.9327 - mDice: 0.7445 - val_loss: 2309.0450 - val_acc: 0.9370 - val_mDice: 0.4689

Epoch 00028: val_mDice improved from 0.46808 to 0.46888, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 10s - loss: 513.5519 - acc: 0.9325 - mDice: 0.7455 - val_loss: 2512.0775 - val_acc: 0.9379 - val_mDice: 0.4574

Epoch 00029: val_mDice did not improve from 0.46888
Epoch 30/300
 - 10s - loss: 507.6125 - acc: 0.9329 - mDice: 0.7485 - val_loss: 2342.2941 - val_acc: 0.9369 - val_mDice: 0.4689

Epoch 00030: val_mDice improved from 0.46888 to 0.46890, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 10s - loss: 503.2174 - acc: 0.9332 - mDice: 0.7502 - val_loss: 2414.8660 - val_acc: 0.9369 - val_mDice: 0.4610

Epoch 00031: val_mDice did not improve from 0.46890
Epoch 32/300
 - 10s - loss: 499.9731 - acc: 0.9333 - mDice: 0.7518 - val_loss: 2460.1237 - val_acc: 0.9380 - val_mDice: 0.4600

Epoch 00032: val_mDice did not improve from 0.46890
Epoch 33/300
 - 10s - loss: 496.6295 - acc: 0.9336 - mDice: 0.7539 - val_loss: 2520.4851 - val_acc: 0.9376 - val_mDice: 0.4584

Epoch 00033: val_mDice did not improve from 0.46890
Epoch 34/300
 - 11s - loss: 494.3840 - acc: 0.9336 - mDice: 0.7550 - val_loss: 2353.9803 - val_acc: 0.9380 - val_mDice: 0.4776

Epoch 00034: val_mDice improved from 0.46890 to 0.47761, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 12s - loss: 490.5316 - acc: 0.9336 - mDice: 0.7564 - val_loss: 2369.8650 - val_acc: 0.9373 - val_mDice: 0.4737

Epoch 00035: val_mDice did not improve from 0.47761
Epoch 36/300
 - 11s - loss: 488.9473 - acc: 0.9338 - mDice: 0.7576 - val_loss: 2316.3392 - val_acc: 0.9383 - val_mDice: 0.4823

Epoch 00036: val_mDice improved from 0.47761 to 0.48226, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 11s - loss: 483.8540 - acc: 0.9339 - mDice: 0.7595 - val_loss: 2356.0889 - val_acc: 0.9379 - val_mDice: 0.4770

Epoch 00037: val_mDice did not improve from 0.48226
Epoch 38/300
 - 10s - loss: 480.1613 - acc: 0.9340 - mDice: 0.7617 - val_loss: 2385.8498 - val_acc: 0.9374 - val_mDice: 0.4797

Epoch 00038: val_mDice did not improve from 0.48226
Epoch 39/300
 - 10s - loss: 479.0467 - acc: 0.9341 - mDice: 0.7626 - val_loss: 2447.3905 - val_acc: 0.9375 - val_mDice: 0.4710

Epoch 00039: val_mDice did not improve from 0.48226
Epoch 40/300
 - 10s - loss: 477.5331 - acc: 0.9340 - mDice: 0.7627 - val_loss: 2523.9392 - val_acc: 0.9368 - val_mDice: 0.4652

Epoch 00040: val_mDice did not improve from 0.48226
Epoch 41/300
 - 10s - loss: 474.5422 - acc: 0.9343 - mDice: 0.7649 - val_loss: 2507.0611 - val_acc: 0.9378 - val_mDice: 0.4717

Epoch 00041: val_mDice did not improve from 0.48226
Epoch 42/300
 - 10s - loss: 472.0440 - acc: 0.9344 - mDice: 0.7655 - val_loss: 2439.7766 - val_acc: 0.9372 - val_mDice: 0.4748

Epoch 00042: val_mDice did not improve from 0.48226
Epoch 43/300
 - 11s - loss: 470.6627 - acc: 0.9346 - mDice: 0.7665 - val_loss: 2540.2546 - val_acc: 0.9381 - val_mDice: 0.4655

Epoch 00043: val_mDice did not improve from 0.48226
Epoch 44/300
 - 10s - loss: 469.9357 - acc: 0.9345 - mDice: 0.7666 - val_loss: 2405.1664 - val_acc: 0.9381 - val_mDice: 0.4793

Epoch 00044: val_mDice did not improve from 0.48226
Epoch 45/300
 - 10s - loss: 465.3264 - acc: 0.9348 - mDice: 0.7694 - val_loss: 2474.8148 - val_acc: 0.9379 - val_mDice: 0.4813

Epoch 00045: val_mDice did not improve from 0.48226
Epoch 46/300
 - 10s - loss: 462.6025 - acc: 0.9346 - mDice: 0.7702 - val_loss: 2459.1555 - val_acc: 0.9387 - val_mDice: 0.4793

Epoch 00046: val_mDice did not improve from 0.48226
Epoch 47/300
 - 10s - loss: 460.7582 - acc: 0.9348 - mDice: 0.7710 - val_loss: 2493.7245 - val_acc: 0.9381 - val_mDice: 0.4743

Epoch 00047: val_mDice did not improve from 0.48226
Epoch 48/300
 - 10s - loss: 458.9789 - acc: 0.9351 - mDice: 0.7718 - val_loss: 2472.6737 - val_acc: 0.9383 - val_mDice: 0.4799

Epoch 00048: val_mDice did not improve from 0.48226
Epoch 49/300
 - 10s - loss: 459.0487 - acc: 0.9350 - mDice: 0.7717 - val_loss: 2415.6524 - val_acc: 0.9385 - val_mDice: 0.4842

Epoch 00049: val_mDice improved from 0.48226 to 0.48415, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 50/300
 - 11s - loss: 454.9951 - acc: 0.9353 - mDice: 0.7738 - val_loss: 2441.2334 - val_acc: 0.9382 - val_mDice: 0.4830

Epoch 00050: val_mDice did not improve from 0.48415
Epoch 51/300
 - 10s - loss: 454.6279 - acc: 0.9352 - mDice: 0.7742 - val_loss: 2552.8867 - val_acc: 0.9379 - val_mDice: 0.4753

Epoch 00051: val_mDice did not improve from 0.48415
Epoch 52/300
 - 10s - loss: 453.4702 - acc: 0.9350 - mDice: 0.7750 - val_loss: 2503.5069 - val_acc: 0.9371 - val_mDice: 0.4730

Epoch 00052: val_mDice did not improve from 0.48415
Epoch 53/300
 - 10s - loss: 450.7016 - acc: 0.9352 - mDice: 0.7764 - val_loss: 2484.8457 - val_acc: 0.9380 - val_mDice: 0.4887

Epoch 00053: val_mDice improved from 0.48415 to 0.48869, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 54/300
 - 10s - loss: 447.7314 - acc: 0.9352 - mDice: 0.7775 - val_loss: 2516.6180 - val_acc: 0.9380 - val_mDice: 0.4828

Epoch 00054: val_mDice did not improve from 0.48869
Epoch 55/300
 - 10s - loss: 448.5834 - acc: 0.9350 - mDice: 0.7773 - val_loss: 2548.8724 - val_acc: 0.9377 - val_mDice: 0.4784

Epoch 00055: val_mDice did not improve from 0.48869
Epoch 56/300
 - 10s - loss: 446.4951 - acc: 0.9352 - mDice: 0.7780 - val_loss: 2501.2888 - val_acc: 0.9382 - val_mDice: 0.4797

Epoch 00056: val_mDice did not improve from 0.48869
Epoch 57/300
 - 10s - loss: 445.2055 - acc: 0.9352 - mDice: 0.7789 - val_loss: 2504.3842 - val_acc: 0.9379 - val_mDice: 0.4822

Epoch 00057: val_mDice did not improve from 0.48869
Epoch 58/300
 - 10s - loss: 443.5672 - acc: 0.9356 - mDice: 0.7799 - val_loss: 2512.1267 - val_acc: 0.9382 - val_mDice: 0.4795

Epoch 00058: val_mDice did not improve from 0.48869
Epoch 59/300
 - 10s - loss: 442.3476 - acc: 0.9352 - mDice: 0.7801 - val_loss: 2503.7475 - val_acc: 0.9394 - val_mDice: 0.4923

Epoch 00059: val_mDice improved from 0.48869 to 0.49231, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 60/300
 - 10s - loss: 440.5314 - acc: 0.9355 - mDice: 0.7810 - val_loss: 2472.4975 - val_acc: 0.9387 - val_mDice: 0.4888

Epoch 00060: val_mDice did not improve from 0.49231
Epoch 61/300
 - 10s - loss: 437.0094 - acc: 0.9357 - mDice: 0.7829 - val_loss: 2565.0159 - val_acc: 0.9378 - val_mDice: 0.4786

Epoch 00061: val_mDice did not improve from 0.49231
Epoch 62/300
 - 10s - loss: 436.8609 - acc: 0.9354 - mDice: 0.7829 - val_loss: 2403.8492 - val_acc: 0.9391 - val_mDice: 0.4932

Epoch 00062: val_mDice improved from 0.49231 to 0.49321, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 63/300
 - 10s - loss: 436.4132 - acc: 0.9357 - mDice: 0.7835 - val_loss: 2391.8147 - val_acc: 0.9384 - val_mDice: 0.4912

Epoch 00063: val_mDice did not improve from 0.49321
Epoch 64/300
 - 10s - loss: 434.7298 - acc: 0.9356 - mDice: 0.7840 - val_loss: 2490.5464 - val_acc: 0.9386 - val_mDice: 0.4912

Epoch 00064: val_mDice did not improve from 0.49321
Epoch 65/300
 - 10s - loss: 432.1639 - acc: 0.9358 - mDice: 0.7854 - val_loss: 2561.4220 - val_acc: 0.9381 - val_mDice: 0.4775

Epoch 00065: val_mDice did not improve from 0.49321
Epoch 66/300
 - 10s - loss: 430.9469 - acc: 0.9355 - mDice: 0.7856 - val_loss: 2459.4700 - val_acc: 0.9378 - val_mDice: 0.4887

Epoch 00066: val_mDice did not improve from 0.49321
Epoch 67/300
 - 10s - loss: 431.0096 - acc: 0.9356 - mDice: 0.7859 - val_loss: 2391.2297 - val_acc: 0.9383 - val_mDice: 0.4959

Epoch 00067: val_mDice improved from 0.49321 to 0.49588, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 68/300
 - 10s - loss: 428.8779 - acc: 0.9361 - mDice: 0.7867 - val_loss: 2462.1582 - val_acc: 0.9384 - val_mDice: 0.4882

Epoch 00068: val_mDice did not improve from 0.49588
Epoch 69/300
 - 11s - loss: 428.5262 - acc: 0.9359 - mDice: 0.7870 - val_loss: 2593.5578 - val_acc: 0.9381 - val_mDice: 0.4824

Epoch 00069: val_mDice did not improve from 0.49588
Epoch 70/300
 - 10s - loss: 425.7723 - acc: 0.9360 - mDice: 0.7882 - val_loss: 2669.2447 - val_acc: 0.9384 - val_mDice: 0.4735

Epoch 00070: val_mDice did not improve from 0.49588
Epoch 71/300
 - 10s - loss: 426.0787 - acc: 0.9358 - mDice: 0.7881 - val_loss: 2450.1829 - val_acc: 0.9382 - val_mDice: 0.4950

Epoch 00071: val_mDice did not improve from 0.49588
Epoch 72/300
 - 11s - loss: 423.1162 - acc: 0.9359 - mDice: 0.7895 - val_loss: 2478.7406 - val_acc: 0.9376 - val_mDice: 0.4892

Epoch 00072: val_mDice did not improve from 0.49588
Epoch 73/300
 - 10s - loss: 423.7221 - acc: 0.9360 - mDice: 0.7894 - val_loss: 2586.2020 - val_acc: 0.9378 - val_mDice: 0.4785

Epoch 00073: val_mDice did not improve from 0.49588
Epoch 74/300
 - 10s - loss: 421.3021 - acc: 0.9359 - mDice: 0.7906 - val_loss: 2581.9353 - val_acc: 0.9378 - val_mDice: 0.4801

Epoch 00074: val_mDice did not improve from 0.49588
Epoch 75/300
 - 10s - loss: 421.5875 - acc: 0.9360 - mDice: 0.7906 - val_loss: 2481.5704 - val_acc: 0.9384 - val_mDice: 0.4913

Epoch 00075: val_mDice did not improve from 0.49588
Epoch 76/300
 - 10s - loss: 419.6578 - acc: 0.9358 - mDice: 0.7916 - val_loss: 2636.7136 - val_acc: 0.9380 - val_mDice: 0.4823

Epoch 00076: val_mDice did not improve from 0.49588
Epoch 77/300
 - 10s - loss: 419.7068 - acc: 0.9360 - mDice: 0.7917 - val_loss: 2518.4151 - val_acc: 0.9376 - val_mDice: 0.4975

Epoch 00077: val_mDice improved from 0.49588 to 0.49750, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 78/300
 - 10s - loss: 419.1102 - acc: 0.9359 - mDice: 0.7917 - val_loss: 2743.4262 - val_acc: 0.9379 - val_mDice: 0.4750

Epoch 00078: val_mDice did not improve from 0.49750
Epoch 79/300
 - 10s - loss: 417.2696 - acc: 0.9357 - mDice: 0.7926 - val_loss: 2589.5703 - val_acc: 0.9379 - val_mDice: 0.4815

Epoch 00079: val_mDice did not improve from 0.49750
Epoch 80/300
 - 11s - loss: 416.5727 - acc: 0.9359 - mDice: 0.7930 - val_loss: 2572.6530 - val_acc: 0.9376 - val_mDice: 0.4878

Epoch 00080: val_mDice did not improve from 0.49750
Epoch 81/300
 - 10s - loss: 416.7710 - acc: 0.9361 - mDice: 0.7929 - val_loss: 2458.7599 - val_acc: 0.9380 - val_mDice: 0.4947

Epoch 00081: val_mDice did not improve from 0.49750
Epoch 82/300
 - 10s - loss: 414.9327 - acc: 0.9358 - mDice: 0.7937 - val_loss: 2602.9998 - val_acc: 0.9369 - val_mDice: 0.4807

Epoch 00082: val_mDice did not improve from 0.49750
Epoch 83/300
 - 10s - loss: 412.4887 - acc: 0.9355 - mDice: 0.7950 - val_loss: 2505.8642 - val_acc: 0.9365 - val_mDice: 0.4917

Epoch 00083: val_mDice did not improve from 0.49750
Epoch 84/300
 - 10s - loss: 413.1472 - acc: 0.9357 - mDice: 0.7946 - val_loss: 2630.8176 - val_acc: 0.9379 - val_mDice: 0.4806

Epoch 00084: val_mDice did not improve from 0.49750
Epoch 85/300
 - 10s - loss: 412.5665 - acc: 0.9360 - mDice: 0.7952 - val_loss: 2505.5194 - val_acc: 0.9378 - val_mDice: 0.4899

Epoch 00085: val_mDice did not improve from 0.49750
Epoch 86/300
 - 10s - loss: 410.3211 - acc: 0.9359 - mDice: 0.7959 - val_loss: 2559.2892 - val_acc: 0.9383 - val_mDice: 0.4920

Epoch 00086: val_mDice did not improve from 0.49750
Epoch 87/300
 - 10s - loss: 409.0631 - acc: 0.9360 - mDice: 0.7965 - val_loss: 2557.1696 - val_acc: 0.9369 - val_mDice: 0.4902

Epoch 00087: val_mDice did not improve from 0.49750
Epoch 88/300
 - 11s - loss: 408.8577 - acc: 0.9360 - mDice: 0.7968 - val_loss: 2575.3931 - val_acc: 0.9379 - val_mDice: 0.4897

Epoch 00088: val_mDice did not improve from 0.49750
Epoch 89/300
 - 10s - loss: 408.5745 - acc: 0.9362 - mDice: 0.7965 - val_loss: 2633.0781 - val_acc: 0.9378 - val_mDice: 0.4814

Epoch 00089: val_mDice did not improve from 0.49750
Epoch 90/300
 - 10s - loss: 407.5876 - acc: 0.9362 - mDice: 0.7974 - val_loss: 2614.1306 - val_acc: 0.9379 - val_mDice: 0.4866

Epoch 00090: val_mDice did not improve from 0.49750
Epoch 91/300
 - 10s - loss: 406.4897 - acc: 0.9361 - mDice: 0.7980 - val_loss: 2613.4192 - val_acc: 0.9382 - val_mDice: 0.4824

Epoch 00091: val_mDice did not improve from 0.49750
Epoch 92/300
 - 10s - loss: 406.6849 - acc: 0.9365 - mDice: 0.7975 - val_loss: 2529.4691 - val_acc: 0.9388 - val_mDice: 0.4957

Epoch 00092: val_mDice did not improve from 0.49750
Epoch 93/300
 - 10s - loss: 405.3898 - acc: 0.9364 - mDice: 0.7987 - val_loss: 2519.0080 - val_acc: 0.9377 - val_mDice: 0.4931

Epoch 00093: val_mDice did not improve from 0.49750
Epoch 94/300
 - 10s - loss: 404.8733 - acc: 0.9363 - mDice: 0.7988 - val_loss: 2753.1709 - val_acc: 0.9369 - val_mDice: 0.4689

Epoch 00094: val_mDice did not improve from 0.49750
Epoch 95/300
 - 11s - loss: 403.8989 - acc: 0.9361 - mDice: 0.7993 - val_loss: 2606.2407 - val_acc: 0.9380 - val_mDice: 0.4872

Epoch 00095: val_mDice did not improve from 0.49750
Epoch 96/300
 - 10s - loss: 403.4504 - acc: 0.9364 - mDice: 0.7997 - val_loss: 2494.7114 - val_acc: 0.9383 - val_mDice: 0.4983

Epoch 00096: val_mDice improved from 0.49750 to 0.49826, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 10s - loss: 401.4864 - acc: 0.9364 - mDice: 0.8002 - val_loss: 2426.0296 - val_acc: 0.9378 - val_mDice: 0.4968

Epoch 00097: val_mDice did not improve from 0.49826
Epoch 98/300
 - 10s - loss: 401.7702 - acc: 0.9366 - mDice: 0.8002 - val_loss: 2539.4047 - val_acc: 0.9378 - val_mDice: 0.4964

Epoch 00098: val_mDice did not improve from 0.49826
Epoch 99/300
 - 10s - loss: 401.0358 - acc: 0.9363 - mDice: 0.8008 - val_loss: 2583.8375 - val_acc: 0.9383 - val_mDice: 0.4920

Epoch 00099: val_mDice did not improve from 0.49826
Epoch 100/300
 - 10s - loss: 398.8289 - acc: 0.9368 - mDice: 0.8018 - val_loss: 2694.3453 - val_acc: 0.9385 - val_mDice: 0.4861

Epoch 00100: val_mDice did not improve from 0.49826
Epoch 101/300
 - 10s - loss: 398.8137 - acc: 0.9368 - mDice: 0.8018 - val_loss: 2664.4560 - val_acc: 0.9389 - val_mDice: 0.4878

Epoch 00101: val_mDice did not improve from 0.49826
Epoch 102/300
 - 11s - loss: 398.7462 - acc: 0.9368 - mDice: 0.8018 - val_loss: 2554.3554 - val_acc: 0.9379 - val_mDice: 0.4934

Epoch 00102: val_mDice did not improve from 0.49826
Epoch 103/300
 - 10s - loss: 398.0777 - acc: 0.9369 - mDice: 0.8025 - val_loss: 2556.4586 - val_acc: 0.9386 - val_mDice: 0.4910

Epoch 00103: val_mDice did not improve from 0.49826
Epoch 104/300
 - 10s - loss: 397.0496 - acc: 0.9369 - mDice: 0.8024 - val_loss: 2541.6271 - val_acc: 0.9379 - val_mDice: 0.4981

Epoch 00104: val_mDice did not improve from 0.49826
Epoch 105/300
 - 11s - loss: 397.9886 - acc: 0.9370 - mDice: 0.8024 - val_loss: 2617.7840 - val_acc: 0.9385 - val_mDice: 0.4925

Epoch 00105: val_mDice did not improve from 0.49826
Epoch 106/300
 - 10s - loss: 396.7258 - acc: 0.9369 - mDice: 0.8028 - val_loss: 2621.2644 - val_acc: 0.9378 - val_mDice: 0.4900

Epoch 00106: val_mDice did not improve from 0.49826
Epoch 107/300
 - 10s - loss: 394.8384 - acc: 0.9370 - mDice: 0.8038 - val_loss: 2602.0422 - val_acc: 0.9386 - val_mDice: 0.4956

Epoch 00107: val_mDice did not improve from 0.49826
Epoch 108/300
 - 10s - loss: 393.9015 - acc: 0.9370 - mDice: 0.8040 - val_loss: 2647.9058 - val_acc: 0.9376 - val_mDice: 0.4853

Epoch 00108: val_mDice did not improve from 0.49826
Epoch 109/300
 - 10s - loss: 394.1875 - acc: 0.9371 - mDice: 0.8041 - val_loss: 2541.7528 - val_acc: 0.9381 - val_mDice: 0.4991

Epoch 00109: val_mDice improved from 0.49826 to 0.49909, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 110/300
 - 10s - loss: 392.4273 - acc: 0.9377 - mDice: 0.8051 - val_loss: 2588.2834 - val_acc: 0.9376 - val_mDice: 0.4937

Epoch 00110: val_mDice did not improve from 0.49909
Epoch 111/300
 - 11s - loss: 392.6269 - acc: 0.9371 - mDice: 0.8047 - val_loss: 2688.1337 - val_acc: 0.9376 - val_mDice: 0.4835

Epoch 00111: val_mDice did not improve from 0.49909
Epoch 112/300
 - 10s - loss: 392.8835 - acc: 0.9374 - mDice: 0.8048 - val_loss: 2644.0797 - val_acc: 0.9378 - val_mDice: 0.4854

Epoch 00112: val_mDice did not improve from 0.49909
Epoch 113/300
 - 10s - loss: 392.4635 - acc: 0.9377 - mDice: 0.8048 - val_loss: 2584.9938 - val_acc: 0.9384 - val_mDice: 0.4931

Epoch 00113: val_mDice did not improve from 0.49909
Epoch 114/300
 - 10s - loss: 389.5496 - acc: 0.9374 - mDice: 0.8064 - val_loss: 2626.6469 - val_acc: 0.9380 - val_mDice: 0.4901

Epoch 00114: val_mDice did not improve from 0.49909
Epoch 115/300
 - 10s - loss: 389.5982 - acc: 0.9376 - mDice: 0.8063 - val_loss: 2670.4363 - val_acc: 0.9375 - val_mDice: 0.4871

Epoch 00115: val_mDice did not improve from 0.49909
Epoch 116/300
 - 10s - loss: 390.2458 - acc: 0.9375 - mDice: 0.8061 - val_loss: 2409.1172 - val_acc: 0.9386 - val_mDice: 0.5075

Epoch 00116: val_mDice improved from 0.49909 to 0.50750, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 117/300
 - 10s - loss: 387.4410 - acc: 0.9375 - mDice: 0.8075 - val_loss: 2591.6894 - val_acc: 0.9385 - val_mDice: 0.4980

Epoch 00117: val_mDice did not improve from 0.50750
Epoch 118/300
 - 10s - loss: 388.9095 - acc: 0.9376 - mDice: 0.8068 - val_loss: 2563.8232 - val_acc: 0.9386 - val_mDice: 0.4999

Epoch 00118: val_mDice did not improve from 0.50750
Epoch 119/300
 - 10s - loss: 390.3652 - acc: 0.9374 - mDice: 0.8059 - val_loss: 2734.9131 - val_acc: 0.9378 - val_mDice: 0.4848

Epoch 00119: val_mDice did not improve from 0.50750
Epoch 120/300
 - 10s - loss: 387.5239 - acc: 0.9376 - mDice: 0.8073 - val_loss: 2489.9544 - val_acc: 0.9388 - val_mDice: 0.5038

Epoch 00120: val_mDice did not improve from 0.50750
Epoch 121/300
 - 10s - loss: 386.7123 - acc: 0.9379 - mDice: 0.8077 - val_loss: 2618.6892 - val_acc: 0.9384 - val_mDice: 0.5005

Epoch 00121: val_mDice did not improve from 0.50750
Epoch 122/300
 - 10s - loss: 385.0819 - acc: 0.9379 - mDice: 0.8088 - val_loss: 2644.9206 - val_acc: 0.9382 - val_mDice: 0.4885

Epoch 00122: val_mDice did not improve from 0.50750
Epoch 123/300
 - 10s - loss: 384.8596 - acc: 0.9380 - mDice: 0.8084 - val_loss: 2565.2699 - val_acc: 0.9385 - val_mDice: 0.5012

Epoch 00123: val_mDice did not improve from 0.50750
Epoch 124/300
 - 10s - loss: 385.3888 - acc: 0.9380 - mDice: 0.8081 - val_loss: 2590.1229 - val_acc: 0.9385 - val_mDice: 0.4974

Epoch 00124: val_mDice did not improve from 0.50750
Epoch 125/300
 - 10s - loss: 385.4257 - acc: 0.9378 - mDice: 0.8084 - val_loss: 2612.4659 - val_acc: 0.9381 - val_mDice: 0.4938

Epoch 00125: val_mDice did not improve from 0.50750
Epoch 126/300
 - 10s - loss: 384.2991 - acc: 0.9380 - mDice: 0.8091 - val_loss: 2665.4809 - val_acc: 0.9383 - val_mDice: 0.4928

Epoch 00126: val_mDice did not improve from 0.50750
Epoch 127/300
 - 10s - loss: 382.9831 - acc: 0.9378 - mDice: 0.8095 - val_loss: 2677.0651 - val_acc: 0.9390 - val_mDice: 0.4903

Epoch 00127: val_mDice did not improve from 0.50750
Epoch 128/300
 - 10s - loss: 383.5014 - acc: 0.9383 - mDice: 0.8094 - val_loss: 2590.5346 - val_acc: 0.9391 - val_mDice: 0.4943

Epoch 00128: val_mDice did not improve from 0.50750
Epoch 129/300
 - 10s - loss: 383.2344 - acc: 0.9383 - mDice: 0.8096 - val_loss: 2549.6349 - val_acc: 0.9385 - val_mDice: 0.4974

Epoch 00129: val_mDice did not improve from 0.50750
Epoch 130/300
 - 10s - loss: 382.3853 - acc: 0.9381 - mDice: 0.8098 - val_loss: 2505.5376 - val_acc: 0.9378 - val_mDice: 0.4994

Epoch 00130: val_mDice did not improve from 0.50750
Epoch 131/300
 - 10s - loss: 381.9588 - acc: 0.9381 - mDice: 0.8098 - val_loss: 2496.3642 - val_acc: 0.9387 - val_mDice: 0.5080

Epoch 00131: val_mDice improved from 0.50750 to 0.50805, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 132/300
 - 10s - loss: 381.5475 - acc: 0.9381 - mDice: 0.8102 - val_loss: 2541.0811 - val_acc: 0.9394 - val_mDice: 0.5009

Epoch 00132: val_mDice did not improve from 0.50805
Epoch 133/300
 - 10s - loss: 379.8023 - acc: 0.9381 - mDice: 0.8108 - val_loss: 2531.7122 - val_acc: 0.9390 - val_mDice: 0.5044

Epoch 00133: val_mDice did not improve from 0.50805
Epoch 134/300
 - 10s - loss: 380.4426 - acc: 0.9380 - mDice: 0.8109 - val_loss: 2636.6396 - val_acc: 0.9381 - val_mDice: 0.4890

Epoch 00134: val_mDice did not improve from 0.50805
Epoch 135/300
 - 10s - loss: 380.3606 - acc: 0.9380 - mDice: 0.8108 - val_loss: 2610.7890 - val_acc: 0.9386 - val_mDice: 0.4985

Epoch 00135: val_mDice did not improve from 0.50805
Epoch 136/300
 - 10s - loss: 378.4572 - acc: 0.9381 - mDice: 0.8121 - val_loss: 2523.1666 - val_acc: 0.9384 - val_mDice: 0.5032

Epoch 00136: val_mDice did not improve from 0.50805
Epoch 137/300
 - 10s - loss: 379.4085 - acc: 0.9383 - mDice: 0.8115 - val_loss: 2705.9247 - val_acc: 0.9383 - val_mDice: 0.4883

Epoch 00137: val_mDice did not improve from 0.50805
Epoch 138/300
 - 10s - loss: 379.3057 - acc: 0.9383 - mDice: 0.8117 - val_loss: 2688.7587 - val_acc: 0.9381 - val_mDice: 0.4927

Epoch 00138: val_mDice did not improve from 0.50805
Epoch 139/300
 - 10s - loss: 377.9195 - acc: 0.9379 - mDice: 0.8120 - val_loss: 2663.4901 - val_acc: 0.9380 - val_mDice: 0.4888

Epoch 00139: val_mDice did not improve from 0.50805
Epoch 140/300
 - 10s - loss: 378.9489 - acc: 0.9383 - mDice: 0.8117 - val_loss: 2588.8482 - val_acc: 0.9383 - val_mDice: 0.5007

Epoch 00140: val_mDice did not improve from 0.50805
Epoch 141/300
 - 10s - loss: 377.3686 - acc: 0.9381 - mDice: 0.8123 - val_loss: 2615.7542 - val_acc: 0.9374 - val_mDice: 0.4941

Epoch 00141: val_mDice did not improve from 0.50805
Epoch 142/300
 - 11s - loss: 377.6620 - acc: 0.9382 - mDice: 0.8125 - val_loss: 2644.1036 - val_acc: 0.9384 - val_mDice: 0.4984

Epoch 00142: val_mDice did not improve from 0.50805
Epoch 143/300
 - 11s - loss: 375.2897 - acc: 0.9382 - mDice: 0.8133 - val_loss: 2679.8664 - val_acc: 0.9381 - val_mDice: 0.4964

Epoch 00143: val_mDice did not improve from 0.50805
Epoch 144/300
 - 10s - loss: 375.3774 - acc: 0.9383 - mDice: 0.8135 - val_loss: 2671.9306 - val_acc: 0.9382 - val_mDice: 0.4945

Epoch 00144: val_mDice did not improve from 0.50805
Epoch 145/300
 - 10s - loss: 375.1170 - acc: 0.9386 - mDice: 0.8135 - val_loss: 2667.8071 - val_acc: 0.9383 - val_mDice: 0.4885

Epoch 00145: val_mDice did not improve from 0.50805
Epoch 146/300
 - 10s - loss: 376.9387 - acc: 0.9382 - mDice: 0.8128 - val_loss: 2677.7785 - val_acc: 0.9390 - val_mDice: 0.4956

Epoch 00146: val_mDice did not improve from 0.50805
Epoch 147/300
 - 10s - loss: 374.6761 - acc: 0.9384 - mDice: 0.8137 - val_loss: 2751.0677 - val_acc: 0.9387 - val_mDice: 0.4934

Epoch 00147: val_mDice did not improve from 0.50805
Epoch 148/300
 - 10s - loss: 374.3457 - acc: 0.9385 - mDice: 0.8136 - val_loss: 2692.9945 - val_acc: 0.9386 - val_mDice: 0.4959

Epoch 00148: val_mDice did not improve from 0.50805
Epoch 149/300
 - 10s - loss: 374.4752 - acc: 0.9386 - mDice: 0.8140 - val_loss: 2618.0598 - val_acc: 0.9386 - val_mDice: 0.5009

Epoch 00149: val_mDice did not improve from 0.50805
Epoch 150/300
 - 11s - loss: 373.2982 - acc: 0.9386 - mDice: 0.8147 - val_loss: 2745.6315 - val_acc: 0.9379 - val_mDice: 0.4839

Epoch 00150: val_mDice did not improve from 0.50805
Epoch 151/300
 - 10s - loss: 373.5438 - acc: 0.9386 - mDice: 0.8145 - val_loss: 2701.4571 - val_acc: 0.9378 - val_mDice: 0.4821

Epoch 00151: val_mDice did not improve from 0.50805
Epoch 152/300
 - 10s - loss: 372.9524 - acc: 0.9385 - mDice: 0.8147 - val_loss: 2714.3543 - val_acc: 0.9382 - val_mDice: 0.4920

Epoch 00152: val_mDice did not improve from 0.50805
Epoch 153/300
 - 10s - loss: 371.7802 - acc: 0.9387 - mDice: 0.8152 - val_loss: 2685.4193 - val_acc: 0.9381 - val_mDice: 0.4913

Epoch 00153: val_mDice did not improve from 0.50805
Epoch 154/300
 - 10s - loss: 372.1661 - acc: 0.9386 - mDice: 0.8153 - val_loss: 2613.7397 - val_acc: 0.9383 - val_mDice: 0.5026

Epoch 00154: val_mDice did not improve from 0.50805
Epoch 155/300
 - 10s - loss: 371.5408 - acc: 0.9384 - mDice: 0.8153 - val_loss: 2858.7630 - val_acc: 0.9374 - val_mDice: 0.4801

Epoch 00155: val_mDice did not improve from 0.50805
Epoch 156/300
 - 11s - loss: 370.9635 - acc: 0.9381 - mDice: 0.8156 - val_loss: 2637.5925 - val_acc: 0.9389 - val_mDice: 0.5030

Epoch 00156: val_mDice did not improve from 0.50805
Epoch 157/300
 - 11s - loss: 371.0393 - acc: 0.9383 - mDice: 0.8157 - val_loss: 2817.5821 - val_acc: 0.9382 - val_mDice: 0.4830

Epoch 00157: val_mDice did not improve from 0.50805
Epoch 158/300
 - 10s - loss: 371.1918 - acc: 0.9381 - mDice: 0.8155 - val_loss: 2748.9472 - val_acc: 0.9380 - val_mDice: 0.4835

Epoch 00158: val_mDice did not improve from 0.50805
Epoch 159/300
 - 10s - loss: 369.2621 - acc: 0.9384 - mDice: 0.8160 - val_loss: 2602.9996 - val_acc: 0.9387 - val_mDice: 0.5029

Epoch 00159: val_mDice did not improve from 0.50805
Epoch 160/300
 - 10s - loss: 369.5571 - acc: 0.9385 - mDice: 0.8165 - val_loss: 2666.7335 - val_acc: 0.9383 - val_mDice: 0.4967

Epoch 00160: val_mDice did not improve from 0.50805
Epoch 161/300
 - 10s - loss: 371.1958 - acc: 0.9383 - mDice: 0.8155 - val_loss: 2727.5049 - val_acc: 0.9379 - val_mDice: 0.4865

Epoch 00161: val_mDice did not improve from 0.50805
Restoring model weights from the end of the best epoch
Epoch 00161: early stopping
{'val_loss': [1585.9673667320837, 1762.2699937086838, 1788.9809229924128, 2064.4147057166465, 2020.3174479557917, 2117.235630328839, 1992.3203606238733, 1992.7489412747896, 2215.788779625526, 1949.5685894305889, 2178.0754112830527, 2171.425797682542, 2077.1951528695913, 2142.7650169959434, 2117.974443875826, 2091.8940259493315, 2278.1261966411885, 2131.43624995305, 2290.168388366699, 2354.93938269982, 2412.596479562613, 2224.278065608098, 2311.022340627817, 2337.3918427687427, 2297.976268474872, 2356.5040177565356, 2382.0628838172324, 2309.0450286865234, 2512.0774806096006, 2342.294149545523, 2414.8659920325645, 2460.123729999249, 2520.485123854417, 2353.9803232046274, 2369.8650013850283, 2316.339191143329, 2356.0889094426084, 2385.8497537466196, 2447.3905158409707, 2523.939159686749, 2507.0610703688403, 2439.776610154372, 2540.25457411546, 2405.1663912259614, 2474.8147559532754, 2459.155485886794, 2493.7245342548076, 2472.673679645245, 2415.65243941087, 2441.233437171349, 2552.886669452374, 2503.506870563214, 2484.845737750714, 2516.6179973895732, 2548.872424199031, 2501.288831270658, 2504.384178161621, 2512.1267389150767, 2503.747485234187, 2472.4974846473106, 2565.015870314378, 2403.849199735201, 2391.8147336519683, 2490.546432495117, 2561.4220246535083, 2459.4700141319863, 2391.229749239408, 2462.158193734976, 2593.5577832735503, 2669.244666466346, 2450.1828630887544, 2478.7405994121846, 2586.2019794170674, 2581.935280433068, 2481.5703735351562, 2636.713632436899, 2518.415051973783, 2743.4261545034556, 2589.5703125, 2572.6529611440806, 2458.7598536564756, 2602.9997758131763, 2505.864177997296, 2630.81763282189, 2505.5194232647236, 2559.2891880915713, 2557.169597919171, 2575.393060537485, 2633.078053401067, 2614.130629319411, 2613.419236403245, 2529.469072782076, 2519.008017906776, 2753.170906653771, 2606.240696833684, 2494.711371788612, 2426.0296478271484, 2539.4047182523286, 2583.8374938964844, 2694.3453333928037, 2664.4560112586387, 2554.3553842397837, 2556.458550086388, 2541.62707226093, 2617.7840270996094, 2621.2644295325645, 2602.0421541654146, 2647.9058051476113, 2541.7528334397534, 2588.283433180589, 2688.1336752084585, 2644.0797283466045, 2584.9938119741587, 2626.6468834510215, 2670.436328594501, 2409.117168719952, 2591.689370375413, 2563.8231741098257, 2734.913108238807, 2489.9543726994443, 2618.6892441969653, 2644.920567439153, 2565.269940889799, 2590.122900742751, 2612.4659259502705, 2665.480941772461, 2677.0651080791768, 2590.5346227792593, 2549.6349193866436, 2505.537561856783, 2496.3641826923076, 2541.081067598783, 2531.7122333233174, 2636.6395580585186, 2610.788990901067, 2523.1665502694937, 2705.9246579683745, 2688.758725679838, 2663.4901252159707, 2588.8481973501353, 2615.754246051495, 2644.1036001352163, 2679.8663823054385, 2671.9306194598857, 2667.807106604943, 2677.7784752478965, 2751.0676539494443, 2692.9944692758413, 2618.059799194336, 2745.6314709003154, 2701.4570635282075, 2714.3543407733623, 2685.419287461501, 2613.739721444937, 2858.762987576998, 2637.592470022348, 2817.5821063701924, 2748.9471670297476, 2602.9996220515322, 2666.7334876427285, 2727.504896897536], 'val_acc': [0.9197480380535126, 0.9200335007447463, 0.9232400220174056, 0.9295222209050105, 0.9275626952831562, 0.9295372687853299, 0.9310246637234321, 0.9339672074868128, 0.934334220794531, 0.9369505231197064, 0.9356241340820606, 0.935679956124379, 0.9357722539168137, 0.9356198471326095, 0.9370256524819595, 0.9366264801758987, 0.937029955478815, 0.9371887743473053, 0.9373840941832616, 0.9360662652896001, 0.9372166670285739, 0.9366715389948624, 0.9370364225827731, 0.938755594767057, 0.937669540827091, 0.937607311285459, 0.937433483508917, 0.9370364248752594, 0.9379163797085102, 0.9368582551295941, 0.9369355463064634, 0.9379786459299234, 0.9376030312134669, 0.9379786000801966, 0.9373047053813934, 0.9382791083592635, 0.9379443021921011, 0.9373626296336834, 0.9374549136712, 0.936817480967595, 0.937794022835218, 0.937163029725735, 0.9380687452279605, 0.9381438791751862, 0.9379056554574233, 0.9386740487355453, 0.9380945242368258, 0.9382619284666501, 0.9384830250189855, 0.938208295748784, 0.9379442838522104, 0.9370557115628169, 0.9380000692147475, 0.9380408754715552, 0.9376738598713508, 0.9382275778513688, 0.937886309165221, 0.9382425936368796, 0.9394359359374413, 0.9386611191126016, 0.9378112118977767, 0.9390860910599048, 0.9384035834899316, 0.9385709923047286, 0.9380515722128061, 0.9378176698317895, 0.9382533201804528, 0.9383907318115234, 0.9380644880808316, 0.9383842692925379, 0.9381889769664178, 0.9376116096973419, 0.9378455418806809, 0.9377640050191146, 0.9383692626769726, 0.9380408433767465, 0.9376438214228704, 0.9379292543117816, 0.9379013455831088, 0.9375837101386144, 0.9379507440787095, 0.9369226373158969, 0.9364805313257071, 0.93787347811919, 0.9378112302376673, 0.9383156047417567, 0.9369011704738324, 0.937851974597344, 0.937751116660925, 0.9379400106576773, 0.9382039675345788, 0.9388049611678491, 0.9376609462958115, 0.9368711251478928, 0.9380430212387671, 0.9383220259959881, 0.9377725743330442, 0.9378498471700228, 0.9382769763469696, 0.9385237877185528, 0.9389208669845874, 0.9378841840303861, 0.9386396591479962, 0.9379206689504477, 0.9384872798736279, 0.9378347947047307, 0.9386397072902093, 0.9375643638464121, 0.9381052622428308, 0.9376438237153567, 0.9376330925868108, 0.9378348176295941, 0.938407858976951, 0.9379549966408656, 0.9374742668408614, 0.9385666847229004, 0.9385066078259394, 0.9385559604718134, 0.9377661255689768, 0.9388285737771255, 0.9384121711437519, 0.9381632300523611, 0.9384551048278809, 0.9384743983928974, 0.9380687543979058, 0.9382597895768973, 0.938974522627317, 0.9390818178653717, 0.9384658474188584, 0.9377661599562719, 0.9386568573805002, 0.9394187996020684, 0.9390410230709956, 0.9381267153299772, 0.9385817555280832, 0.9383713763493758, 0.938324158008282, 0.9380666132156665, 0.9379872106588804, 0.938268393278122, 0.937375531746791, 0.9383627886955554, 0.9381267313773816, 0.9381911296110886, 0.9382919715001032, 0.9389959780069498, 0.9386611512074103, 0.9385774387763097, 0.9385516666449033, 0.9378734666567582, 0.9377876015809866, 0.9381610659452585, 0.9380644697409409, 0.9383069895781003, 0.937442041360415, 0.9389229623170999, 0.9382039606571198, 0.9379657208919525, 0.9386976475899036, 0.9383348799668826, 0.9378562936416039], 'val_mDice': [0.352717737452342, 0.38663641162789786, 0.42118804214092403, 0.4136892677499698, 0.4180733787898834, 0.4070811297457952, 0.43583169092352575, 0.4406211255834653, 0.4232320668032536, 0.45832159714056897, 0.43402152221936446, 0.43984740342085177, 0.45524903988608945, 0.4502553524306187, 0.45506643188687473, 0.46221858664200854, 0.45079166986621344, 0.4612786079255434, 0.45126514681256735, 0.4482039494010118, 0.4432641691886462, 0.46244444239598054, 0.4645835800239673, 0.46592052137622464, 0.4680833833721968, 0.4627705505834176, 0.4579355659393164, 0.46888025735433286, 0.4574207182113941, 0.468897935289603, 0.46104939024035746, 0.460037234884042, 0.45842668786644936, 0.4776142021784416, 0.473736941241301, 0.4822565921797202, 0.4769736643020923, 0.4797442394953508, 0.4709975028840395, 0.46516950256549394, 0.4717456652567937, 0.4747948210973006, 0.46549213133179224, 0.47934239042493015, 0.481292011646124, 0.4793012494651171, 0.4743107287929608, 0.47991513919371825, 0.4841540169257384, 0.4830387461070831, 0.47534642253930753, 0.47296159313275266, 0.4886935273042092, 0.48277425508086497, 0.4784330568061425, 0.47965134393710357, 0.48220961111096233, 0.4794804018277388, 0.49231291046509373, 0.4888377648133498, 0.4785536963206071, 0.49320818598453814, 0.4912116006016731, 0.4912145518912719, 0.47745845925349456, 0.4886726983464681, 0.4958835444771327, 0.48815325590280384, 0.482392817735672, 0.4734942460289368, 0.49502821925740975, 0.48915663762734485, 0.4784591547571696, 0.48011681638084924, 0.49128390504763675, 0.4822512183051843, 0.4975003700416822, 0.47500023818933046, 0.48149188607931137, 0.48784680320666385, 0.49473214321411574, 0.48071829688090545, 0.4916640047270518, 0.4806401271086473, 0.48986055616002816, 0.4919974419933099, 0.4901825768443254, 0.48967041419102597, 0.4813528788777498, 0.4865736416899241, 0.48241735278413844, 0.4957072826532217, 0.4930982690017957, 0.46889699737613016, 0.4871737693364804, 0.498261372343852, 0.49675888596818996, 0.496385916780967, 0.4920134229155687, 0.48608229423944765, 0.4877865437704783, 0.49337685337433446, 0.49100494327453464, 0.4980589392093512, 0.4925120481504844, 0.4899856694615804, 0.49559905895820033, 0.48529276194480747, 0.49909474586065, 0.49367371516732067, 0.4835197656200482, 0.4853862085594581, 0.49314304842398715, 0.49006545027861226, 0.48707501819500554, 0.5074987709522247, 0.4979823472408148, 0.49986076011107516, 0.48480772456297505, 0.5037779679092077, 0.5005404146818014, 0.48846045680917227, 0.5012324584218172, 0.4973618626021422, 0.4937697442678305, 0.492789502040698, 0.4903390556573868, 0.49434996568239653, 0.497362352334536, 0.4993926856953364, 0.508049552830366, 0.5008646155206057, 0.5044199405954435, 0.4889622898055957, 0.498511741654231, 0.5032481121329161, 0.4882663287795507, 0.49267846517837965, 0.4887747185734602, 0.5006922449056919, 0.4941047103359149, 0.4984122675198775, 0.4964301927158466, 0.49450980671323264, 0.4884631610833682, 0.49557098688987583, 0.493366767007571, 0.49593989751659906, 0.5008822834262481, 0.48392051744919556, 0.4821069956972049, 0.4920331064898234, 0.49132974761036724, 0.5025978429386249, 0.48009442480710834, 0.502964725288061, 0.48296450021175236, 0.4834608126145143, 0.502936299603719, 0.4966890625655651, 0.4864915357186244], 'loss': [2267.2223863511094, 1194.08124802929, 994.250795618564, 890.9239089038444, 815.9301020864916, 771.9971056344225, 735.7408810110426, 708.2421708100399, 684.1326216405953, 665.1633160506778, 650.5702413185863, 633.5964766694733, 619.8395010401025, 610.5284429372682, 596.263122361579, 588.3656601913299, 578.9551688713814, 571.4484434689828, 565.8134284501012, 558.0487074239397, 550.3750495252756, 545.838794193551, 539.6631237615093, 533.9476614838364, 528.7194210658662, 523.6325927357233, 520.7988250065387, 515.6327703430744, 513.5519230642145, 507.61248174180275, 503.2174426301054, 499.97307381704263, 496.6295197650558, 494.3840499915925, 490.53163846374866, 488.9473068095173, 483.85397515336075, 480.1612831516085, 479.046744173791, 477.5331271012463, 474.54216413630735, 472.0439622177691, 470.66272914668, 469.9356527507036, 465.3263957709566, 462.6024510166274, 460.7582414924884, 458.97891108277076, 459.04871729719105, 454.995128614353, 454.62791828316296, 453.4702221755116, 450.7016334100963, 447.7313606032122, 448.58338517165544, 446.4951161475438, 445.2054724175695, 443.5671871543799, 442.34756733585544, 440.53142556543446, 437.00937198961526, 436.86088137445023, 436.413200756264, 434.7298057364063, 432.1639376067482, 430.9468641892401, 431.00962033791154, 428.8778632400683, 428.526228805777, 425.7723340487707, 426.0786656210214, 423.11623877849263, 423.7221269925054, 421.302091437205, 421.58754415212167, 419.6577714052652, 419.70681904827353, 419.11018527364376, 417.269575123768, 416.57274805350596, 416.770982124, 414.93272444371377, 412.4886924028067, 413.1472286740473, 412.5665367384695, 410.3210748019698, 409.0631252697976, 408.8577126236757, 408.57454263092046, 407.5876006784556, 406.48969661209907, 406.6848507558993, 405.38977078785484, 404.87328884564874, 403.89885256214137, 403.45044457128563, 401.48642112157074, 401.7702012308781, 401.03584385384363, 398.82887278339314, 398.8137038048921, 398.74624174181895, 398.07765028602705, 397.0496092207656, 397.9885535806151, 396.72583020337004, 394.8384490406712, 393.90148554971427, 394.1875002898931, 392.4273283642772, 392.62689648749347, 392.8834811144404, 392.46345258130697, 389.54955821647246, 389.59815317738116, 390.2458000418819, 387.44100809594227, 388.9094890653235, 390.365158537003, 387.52386177117165, 386.7122920225503, 385.0818520791964, 384.8596387323304, 385.38883252079216, 385.42566527307093, 384.2990998941232, 382.9830805528629, 383.50140982739305, 383.23439754129697, 382.3853286648878, 381.95884376419633, 381.5474680001958, 379.8023016279742, 380.4426188192321, 380.36060313620845, 378.45724367970064, 379.4085306211403, 379.3056864687012, 377.9194695925587, 378.94891255537124, 377.36858335482856, 377.6620249640488, 375.28973014343933, 375.37741249293447, 375.1169815197165, 376.9386776328955, 374.6761182366202, 374.34570028939544, 374.47518263995113, 373.29816963993005, 373.54378927122303, 372.95242974354227, 371.7802165410599, 372.1660762619051, 371.5408325758212, 370.9634822235769, 371.0393238934843, 371.19184268260807, 369.2620649048403, 369.55708738117875, 371.1957760221303], 'acc': [0.8937953924831512, 0.9084590450265932, 0.9144016973352032, 0.9177141307981914, 0.9198974048223902, 0.9214813949755501, 0.9226088142203722, 0.9239219525890972, 0.9249607642825147, 0.9258983934771077, 0.926376771687208, 0.9271443205093927, 0.9277387444387885, 0.928330842016984, 0.9289031091578979, 0.9294722959101007, 0.9298129324421368, 0.9298950286684667, 0.9301948638064806, 0.9305395140898994, 0.9307619046540451, 0.9310954367280018, 0.9314052374240032, 0.9317466191817592, 0.9320600408585564, 0.9321911527223719, 0.9325921468097962, 0.932716014249336, 0.9325102982536009, 0.9328694017481168, 0.9332358722349028, 0.9333361045885249, 0.9336054121162755, 0.9335538211766395, 0.9336239158980776, 0.9337937533882924, 0.9339234240983209, 0.9339640835581984, 0.9341130832195238, 0.9339938505839501, 0.9343262094529168, 0.9344042337909347, 0.9345520814989124, 0.9344557985040872, 0.9347586196627463, 0.9346475167972822, 0.9347628610364781, 0.9350778086427546, 0.9349638443035821, 0.9352909523073316, 0.9352141693598625, 0.935036163163847, 0.935185348829264, 0.9352280860137183, 0.9350036579085201, 0.935160335118641, 0.9352391613460957, 0.9356326836177721, 0.9351997597899415, 0.9354774812529318, 0.9357322581324709, 0.9353770281592825, 0.935664731259167, 0.9355509969170744, 0.9358346544540777, 0.935518244887634, 0.935565983156299, 0.9360561174054784, 0.9359217921625278, 0.9360027165746244, 0.9358458095323354, 0.9358811540092631, 0.936042259619661, 0.9359219572393038, 0.936009198265037, 0.9357573717686893, 0.9359659471272609, 0.9358861591722938, 0.93574310432531, 0.9358722011475482, 0.936124996237239, 0.9357810239449733, 0.9355482397556173, 0.9356925022411883, 0.9359983107507817, 0.9359067673559153, 0.9359833025892733, 0.9360118986418422, 0.9362462701023939, 0.9361551337814701, 0.9360803457453365, 0.9364672009876532, 0.936430308164227, 0.9363212455718553, 0.9360964240529138, 0.9363800807378724, 0.936423805557493, 0.9365603717437895, 0.9362623926833098, 0.9368154532650151, 0.9367801055668091, 0.9367620745598363, 0.9369432312046196, 0.9368532458090929, 0.9369988127749949, 0.936872661289645, 0.9369994309196324, 0.9370156733969707, 0.9370530748140831, 0.937657584236368, 0.9371343495429557, 0.9373977078037443, 0.9376558376658087, 0.9374107378034654, 0.9376483826545797, 0.9374820479693189, 0.9375161810366747, 0.9375870795825152, 0.9374376650139337, 0.9376351687671359, 0.9378598427284383, 0.9379167639768333, 0.9380435950694725, 0.9380450145593376, 0.9377580061176986, 0.9380305841940306, 0.9377778315251685, 0.9382597038988411, 0.9382652227403404, 0.9381298275052385, 0.9380921596565184, 0.9381168827099806, 0.9381453736972009, 0.9380120573025793, 0.9380166891106466, 0.9381019802954566, 0.9383065619779163, 0.938304049573151, 0.9379186763222956, 0.9383184183218883, 0.9380840661560248, 0.9382457284319173, 0.9382484869236635, 0.9382849046634943, 0.9386421387446033, 0.9382176060117193, 0.9384249725333441, 0.9384840547923045, 0.9385807662226557, 0.9385598532159445, 0.9385678182500958, 0.9385303912496562, 0.9387432504522617, 0.9386481044257928, 0.9383823586205082, 0.9381463585453567, 0.9383078374337591, 0.9381370749364071, 0.9383655356094317, 0.9385147086425999, 0.9383225962540259], 'mDice': [0.24365999317032863, 0.45397829055170463, 0.52850828337997, 0.5733070259416146, 0.6063976214895782, 0.6255967208273372, 0.6416377096524442, 0.6543982658759591, 0.6648207713699447, 0.6736902641786109, 0.6807422532450831, 0.6885493300964414, 0.6945535069757377, 0.6988196689011942, 0.706047508941523, 0.7097625129998835, 0.7139981320827175, 0.7180235203612195, 0.7204396388500607, 0.7239957563135881, 0.7272759635411296, 0.7300326894660569, 0.7328577641520367, 0.7353611027502897, 0.7383534163387787, 0.740401989335362, 0.7420414476215229, 0.7445039675704758, 0.7454506290428403, 0.7484784506458556, 0.7501633174138174, 0.751780023359784, 0.7539020766963886, 0.7550029072838055, 0.7564127052126034, 0.7575545325321453, 0.7595252702291806, 0.761716899254616, 0.7626470703981046, 0.7627124054058335, 0.7649490736589147, 0.7655463571710296, 0.7664598617883095, 0.7666038627181668, 0.7693609659779306, 0.7702334661452102, 0.7710245209053347, 0.7718411757147181, 0.7717131217621266, 0.773821952591894, 0.7742390136684448, 0.7750249826566195, 0.7763750007437745, 0.7775026741122821, 0.777338227563422, 0.7780191992785475, 0.7788927365655467, 0.7798667160730064, 0.7800962714309854, 0.7810346776573001, 0.7828616491710195, 0.7828893070894667, 0.7834777598186227, 0.7840240740703501, 0.7854183573383341, 0.7855688765305584, 0.7858897397342912, 0.7867119828570454, 0.7869593284121961, 0.788238302814579, 0.7881355767516999, 0.7895010627966289, 0.7894472272855861, 0.7905507579254816, 0.7906232127995549, 0.7915525315740853, 0.7916545001033223, 0.7917154919427226, 0.7926456248156646, 0.7930005622571942, 0.7928759987081844, 0.7936586222832882, 0.7949649609125794, 0.7946310951559568, 0.7951675635207396, 0.7958606752172493, 0.7965498319864383, 0.7968454471397892, 0.7964908942672299, 0.7973873534348138, 0.7980223635702371, 0.7974865161755819, 0.7987141968589817, 0.7987682345299816, 0.7992680413492336, 0.7996723842084337, 0.8002333759403994, 0.8002443720051408, 0.8007677192563974, 0.8018259611844819, 0.8017620213256269, 0.8018410675345142, 0.8024519327370034, 0.8024227005259242, 0.8024438619998442, 0.8028464508839422, 0.8038264542699882, 0.8040389664155756, 0.8041371626848666, 0.8051006246743294, 0.8047386312643057, 0.8048299653255487, 0.8047550063032973, 0.8064143051028548, 0.8063034652883052, 0.8061153387425296, 0.807498462968874, 0.8067658688599231, 0.8058724256939612, 0.8072846193303924, 0.8076536783452603, 0.8087522380028573, 0.8084376957719313, 0.8081399014017453, 0.8083840922094255, 0.8090942570020448, 0.8094982370551438, 0.8093697141976547, 0.8095829857843647, 0.8098240287928611, 0.8098373923488157, 0.8102381278654311, 0.8107772708422889, 0.8109447783257572, 0.8108208089981706, 0.8120657795086609, 0.8115173529008652, 0.8117077113693076, 0.8120050255931041, 0.8117458325882279, 0.8123433662386582, 0.8125283049721346, 0.8133330336578392, 0.8134786134154047, 0.8135209995244884, 0.8127533834127662, 0.8136670053868257, 0.8136168286818635, 0.8139964074630266, 0.8146654051420797, 0.8145283247056201, 0.8147093299448209, 0.8151590030186513, 0.8152538658474728, 0.8152601158751956, 0.8155962234931734, 0.8157055539353949, 0.815514606423762, 0.8160394247218294, 0.8164841422161295, 0.8154590378979151]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.56s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.34s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.09s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:53,  1.46s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:28,  1.59s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:37,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:53,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:43,  1.65s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:57,  1.71s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:34,  1.85s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<09:09,  1.98s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<09:05,  1.98s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:26,  2.06s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<10:14,  2.24s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<10:06,  2.22s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:58,  2.20s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<10:01,  2.22s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:54,  2.20s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:57,  2.22s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:58,  2.23s/it]predicting train subjects:   6%|▋         | 18/285 [00:37<09:55,  2.23s/it]predicting train subjects:   7%|▋         | 19/285 [00:39<10:01,  2.26s/it]predicting train subjects:   7%|▋         | 20/285 [00:41<10:01,  2.27s/it]predicting train subjects:   7%|▋         | 21/285 [00:44<09:55,  2.25s/it]predicting train subjects:   8%|▊         | 22/285 [00:46<09:50,  2.25s/it]predicting train subjects:   8%|▊         | 23/285 [00:48<10:04,  2.31s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<09:59,  2.30s/it]predicting train subjects:   9%|▉         | 25/285 [00:53<10:04,  2.32s/it]predicting train subjects:   9%|▉         | 26/285 [00:55<09:50,  2.28s/it]predicting train subjects:   9%|▉         | 27/285 [00:57<09:38,  2.24s/it]predicting train subjects:  10%|▉         | 28/285 [00:59<09:35,  2.24s/it]predicting train subjects:  10%|█         | 29/285 [01:02<09:28,  2.22s/it]predicting train subjects:  11%|█         | 30/285 [01:04<09:14,  2.17s/it]predicting train subjects:  11%|█         | 31/285 [01:06<08:52,  2.10s/it]predicting train subjects:  11%|█         | 32/285 [01:07<08:32,  2.02s/it]predicting train subjects:  12%|█▏        | 33/285 [01:09<08:24,  2.00s/it]predicting train subjects:  12%|█▏        | 34/285 [01:11<08:20,  1.99s/it]predicting train subjects:  12%|█▏        | 35/285 [01:13<08:16,  1.99s/it]predicting train subjects:  13%|█▎        | 36/285 [01:15<08:15,  1.99s/it]predicting train subjects:  13%|█▎        | 37/285 [01:17<08:28,  2.05s/it]predicting train subjects:  13%|█▎        | 38/285 [01:20<08:27,  2.06s/it]predicting train subjects:  14%|█▎        | 39/285 [01:22<08:16,  2.02s/it]predicting train subjects:  14%|█▍        | 40/285 [01:23<07:57,  1.95s/it]predicting train subjects:  14%|█▍        | 41/285 [01:25<08:08,  2.00s/it]predicting train subjects:  15%|█▍        | 42/285 [01:27<08:11,  2.02s/it]predicting train subjects:  15%|█▌        | 43/285 [01:29<07:56,  1.97s/it]predicting train subjects:  15%|█▌        | 44/285 [01:31<07:51,  1.96s/it]predicting train subjects:  16%|█▌        | 45/285 [01:33<07:48,  1.95s/it]predicting train subjects:  16%|█▌        | 46/285 [01:35<07:38,  1.92s/it]predicting train subjects:  16%|█▋        | 47/285 [01:37<07:26,  1.88s/it]predicting train subjects:  17%|█▋        | 48/285 [01:39<07:12,  1.82s/it]predicting train subjects:  17%|█▋        | 49/285 [01:40<07:15,  1.84s/it]predicting train subjects:  18%|█▊        | 50/285 [01:42<06:58,  1.78s/it]predicting train subjects:  18%|█▊        | 51/285 [01:44<06:57,  1.79s/it]predicting train subjects:  18%|█▊        | 52/285 [01:45<06:45,  1.74s/it]predicting train subjects:  19%|█▊        | 53/285 [01:47<06:34,  1.70s/it]predicting train subjects:  19%|█▉        | 54/285 [01:49<06:31,  1.69s/it]predicting train subjects:  19%|█▉        | 55/285 [01:50<06:28,  1.69s/it]predicting train subjects:  20%|█▉        | 56/285 [01:52<06:33,  1.72s/it]predicting train subjects:  20%|██        | 57/285 [01:54<06:29,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:56<06:55,  1.83s/it]predicting train subjects:  21%|██        | 59/285 [01:58<06:31,  1.73s/it]predicting train subjects:  21%|██        | 60/285 [01:59<06:33,  1.75s/it]predicting train subjects:  21%|██▏       | 61/285 [02:01<06:25,  1.72s/it]predicting train subjects:  22%|██▏       | 62/285 [02:03<06:19,  1.70s/it]predicting train subjects:  22%|██▏       | 63/285 [02:04<06:19,  1.71s/it]predicting train subjects:  22%|██▏       | 64/285 [02:06<06:18,  1.71s/it]predicting train subjects:  23%|██▎       | 65/285 [02:08<06:16,  1.71s/it]predicting train subjects:  23%|██▎       | 66/285 [02:10<06:25,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [02:11<06:18,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [02:13<06:07,  1.69s/it]predicting train subjects:  24%|██▍       | 69/285 [02:15<06:00,  1.67s/it]predicting train subjects:  25%|██▍       | 70/285 [02:16<05:59,  1.67s/it]predicting train subjects:  25%|██▍       | 71/285 [02:18<05:54,  1.66s/it]predicting train subjects:  25%|██▌       | 72/285 [02:19<05:48,  1.63s/it]predicting train subjects:  26%|██▌       | 73/285 [02:21<05:42,  1.61s/it]predicting train subjects:  26%|██▌       | 74/285 [02:23<05:40,  1.62s/it]predicting train subjects:  26%|██▋       | 75/285 [02:24<05:36,  1.60s/it]predicting train subjects:  27%|██▋       | 76/285 [02:26<05:33,  1.59s/it]predicting train subjects:  27%|██▋       | 77/285 [02:27<05:32,  1.60s/it]predicting train subjects:  27%|██▋       | 78/285 [02:29<05:27,  1.58s/it]predicting train subjects:  28%|██▊       | 79/285 [02:30<05:22,  1.56s/it]predicting train subjects:  28%|██▊       | 80/285 [02:32<05:26,  1.59s/it]predicting train subjects:  28%|██▊       | 81/285 [02:34<05:29,  1.61s/it]predicting train subjects:  29%|██▉       | 82/285 [02:35<05:26,  1.61s/it]predicting train subjects:  29%|██▉       | 83/285 [02:37<05:26,  1.61s/it]predicting train subjects:  29%|██▉       | 84/285 [02:39<05:31,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:41<05:45,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:42<05:51,  1.77s/it]predicting train subjects:  31%|███       | 87/285 [02:45<06:08,  1.86s/it]predicting train subjects:  31%|███       | 88/285 [02:46<06:04,  1.85s/it]predicting train subjects:  31%|███       | 89/285 [02:48<06:03,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:50<05:57,  1.83s/it]predicting train subjects:  32%|███▏      | 91/285 [02:52<05:49,  1.80s/it]predicting train subjects:  32%|███▏      | 92/285 [02:54<05:45,  1.79s/it]predicting train subjects:  33%|███▎      | 93/285 [02:55<05:39,  1.77s/it]predicting train subjects:  33%|███▎      | 94/285 [02:57<05:40,  1.78s/it]predicting train subjects:  33%|███▎      | 95/285 [02:59<05:46,  1.82s/it]predicting train subjects:  34%|███▎      | 96/285 [03:01<05:38,  1.79s/it]predicting train subjects:  34%|███▍      | 97/285 [03:02<05:37,  1.80s/it]predicting train subjects:  34%|███▍      | 98/285 [03:04<05:33,  1.78s/it]predicting train subjects:  35%|███▍      | 99/285 [03:06<05:31,  1.78s/it]predicting train subjects:  35%|███▌      | 100/285 [03:08<05:34,  1.81s/it]predicting train subjects:  35%|███▌      | 101/285 [03:10<05:29,  1.79s/it]predicting train subjects:  36%|███▌      | 102/285 [03:11<05:25,  1.78s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:21,  1.77s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:15,  1.75s/it]predicting train subjects:  37%|███▋      | 105/285 [03:17<05:15,  1.75s/it]predicting train subjects:  37%|███▋      | 106/285 [03:18<05:13,  1.75s/it]predicting train subjects:  38%|███▊      | 107/285 [03:20<05:12,  1.76s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:11,  1.76s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:07,  1.75s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:06,  1.75s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:02,  1.74s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<04:58,  1.72s/it]predicting train subjects:  40%|███▉      | 113/285 [03:30<04:55,  1.72s/it]predicting train subjects:  40%|████      | 114/285 [03:32<04:50,  1.70s/it]predicting train subjects:  40%|████      | 115/285 [03:34<04:48,  1.70s/it]predicting train subjects:  41%|████      | 116/285 [03:36<04:53,  1.73s/it]predicting train subjects:  41%|████      | 117/285 [03:37<04:48,  1.72s/it]predicting train subjects:  41%|████▏     | 118/285 [03:39<04:56,  1.77s/it]predicting train subjects:  42%|████▏     | 119/285 [03:41<04:58,  1.80s/it]predicting train subjects:  42%|████▏     | 120/285 [03:43<04:54,  1.78s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<04:41,  1.72s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:38,  1.71s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:21,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:19,  1.61s/it]predicting train subjects:  44%|████▍     | 125/285 [03:51<04:19,  1.62s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:22,  1.65s/it]predicting train subjects:  45%|████▍     | 127/285 [03:54<04:17,  1.63s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:08,  1.60s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:07,  1.60s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:20,  1.69s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:14,  1.66s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:07,  1.63s/it]predicting train subjects:  47%|████▋     | 134/285 [04:05<04:06,  1.63s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<04:08,  1.66s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<04:06,  1.65s/it]predicting train subjects:  48%|████▊     | 137/285 [04:10<04:04,  1.65s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<04:04,  1.67s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<04:07,  1.70s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:58,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<03:53,  1.62s/it]predicting train subjects:  50%|████▉     | 142/285 [04:18<03:43,  1.57s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:40,  1.55s/it]predicting train subjects:  51%|█████     | 144/285 [04:21<03:37,  1.55s/it]predicting train subjects:  51%|█████     | 145/285 [04:23<03:33,  1.52s/it]predicting train subjects:  51%|█████     | 146/285 [04:24<03:30,  1.51s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:26<03:28,  1.51s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:29<03:19,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:19,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:32<03:14,  1.45s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:33<03:12,  1.45s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:35<03:09,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:36<03:07,  1.43s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:37<03:07,  1.44s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:39<03:06,  1.45s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:40<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:42<03:04,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:43<03:01,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:45<02:57,  1.42s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:46<02:57,  1.43s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:47<02:54,  1.42s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:49<02:53,  1.42s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:50<02:50,  1.41s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:52<02:48,  1.40s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:53<02:50,  1.44s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:55<02:48,  1.43s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:56<02:49,  1.45s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:58<02:49,  1.46s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:59<02:52,  1.50s/it]predicting train subjects:  60%|██████    | 171/285 [05:01<02:54,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [05:02<02:48,  1.49s/it]predicting train subjects:  61%|██████    | 173/285 [05:04<02:49,  1.51s/it]predicting train subjects:  61%|██████    | 174/285 [05:06<02:57,  1.60s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:07<02:50,  1.55s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:46,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:10<02:45,  1.53s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:12<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:13<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:14<02:31,  1.45s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:16<02:37,  1.52s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:17<02:31,  1.47s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:19<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:20<02:32,  1.51s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:22<02:30,  1.51s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:23<02:30,  1.52s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:25<02:28,  1.52s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:26<02:28,  1.53s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:28<02:24,  1.50s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:29<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:31<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:33<02:22,  1.53s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:34<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:36<02:17,  1.51s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:37<02:17,  1.52s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:39<02:24,  1.62s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:41<02:28,  1.69s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:43<02:29,  1.72s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:45<02:32,  1.77s/it]predicting train subjects:  70%|███████   | 200/285 [05:46<02:33,  1.81s/it]predicting train subjects:  71%|███████   | 201/285 [05:48<02:34,  1.84s/it]predicting train subjects:  71%|███████   | 202/285 [05:50<02:31,  1.82s/it]predicting train subjects:  71%|███████   | 203/285 [05:52<02:28,  1.81s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:54<02:26,  1.81s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:56<02:28,  1.86s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:58<02:26,  1.85s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:59<02:25,  1.86s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:01<02:21,  1.84s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:03<02:17,  1.81s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:05<02:15,  1.81s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:07<02:16,  1.85s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:09<02:14,  1.85s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:10<02:11,  1.82s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:12<02:03,  1.74s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:13<01:56,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:15<01:55,  1.67s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:17<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:18<01:49,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:20<01:45,  1.60s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:21<01:42,  1.57s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:23<01:44,  1.64s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:25<01:42,  1.63s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:26<01:40,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:28<01:37,  1.60s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:30<01:38,  1.64s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:31<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:34<01:33,  1.64s/it]predicting train subjects:  80%|████████  | 229/285 [06:36<01:30,  1.62s/it]predicting train subjects:  81%|████████  | 230/285 [06:38<01:26,  1.57s/it]predicting train subjects:  81%|████████  | 231/285 [06:39<01:25,  1.59s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:41<01:31,  1.73s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:43<01:34,  1.82s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:45<01:35,  1.87s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:47<01:31,  1.83s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:49<01:27,  1.79s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:50<01:25,  1.78s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:52<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:54<01:19,  1.74s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:55<01:17,  1.71s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:57<01:14,  1.68s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:59<01:12,  1.69s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:01<01:11,  1.70s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:02<01:09,  1.69s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:04<01:08,  1.70s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:06<01:06,  1.70s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:07<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:09<01:02,  1.69s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:11<01:00,  1.69s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:12<00:55,  1.58s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:13<00:50,  1.48s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:15<00:46,  1.42s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:16<00:44,  1.38s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:17<00:42,  1.36s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:18<00:39,  1.33s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:20<00:38,  1.33s/it]predicting train subjects:  90%|█████████ | 257/285 [07:21<00:37,  1.35s/it]predicting train subjects:  91%|█████████ | 258/285 [07:23<00:36,  1.36s/it]predicting train subjects:  91%|█████████ | 259/285 [07:24<00:35,  1.36s/it]predicting train subjects:  91%|█████████ | 260/285 [07:25<00:33,  1.35s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:27<00:32,  1.36s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:28<00:32,  1.40s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:29<00:30,  1.40s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:31<00:28,  1.37s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:32<00:26,  1.34s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:33<00:25,  1.32s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:35<00:23,  1.32s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:36<00:24,  1.45s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:38<00:24,  1.54s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:40<00:23,  1.59s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:42<00:22,  1.64s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:43<00:21,  1.68s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:45<00:20,  1.69s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:47<00:18,  1.69s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:49<00:17,  1.70s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:50<00:15,  1.71s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:52<00:13,  1.71s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:54<00:12,  1.72s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:55<00:10,  1.73s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:57<00:08,  1.75s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:59<00:06,  1.73s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:01<00:05,  1.75s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:02<00:03,  1.74s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:04<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:06<00:00,  1.72s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:15,  1.32s/it]Loading train:   1%|          | 2/285 [00:02<06:21,  1.35s/it]Loading train:   1%|          | 3/285 [00:04<06:22,  1.36s/it]Loading train:   1%|▏         | 4/285 [00:05<06:40,  1.43s/it]Loading train:   2%|▏         | 5/285 [00:06<06:07,  1.31s/it]Loading train:   2%|▏         | 6/285 [00:08<06:29,  1.40s/it]Loading train:   2%|▏         | 7/285 [00:09<06:43,  1.45s/it]Loading train:   3%|▎         | 8/285 [00:11<06:56,  1.51s/it]Loading train:   3%|▎         | 9/285 [00:12<06:38,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<06:07,  1.34s/it]Loading train:   4%|▍         | 11/285 [00:15<05:57,  1.31s/it]Loading train:   4%|▍         | 12/285 [00:16<05:55,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:17<05:35,  1.23s/it]Loading train:   5%|▍         | 14/285 [00:18<05:17,  1.17s/it]Loading train:   5%|▌         | 15/285 [00:19<05:15,  1.17s/it]Loading train:   6%|▌         | 16/285 [00:20<05:08,  1.15s/it]Loading train:   6%|▌         | 17/285 [00:21<05:07,  1.15s/it]Loading train:   6%|▋         | 18/285 [00:23<04:59,  1.12s/it]Loading train:   7%|▋         | 19/285 [00:23<04:43,  1.07s/it]Loading train:   7%|▋         | 20/285 [00:25<04:45,  1.08s/it]Loading train:   7%|▋         | 21/285 [00:26<04:41,  1.07s/it]Loading train:   8%|▊         | 22/285 [00:27<04:40,  1.07s/it]Loading train:   8%|▊         | 23/285 [00:28<04:40,  1.07s/it]Loading train:   8%|▊         | 24/285 [00:29<04:34,  1.05s/it]Loading train:   9%|▉         | 25/285 [00:30<04:28,  1.03s/it]Loading train:   9%|▉         | 26/285 [00:31<04:36,  1.07s/it]Loading train:   9%|▉         | 27/285 [00:32<04:32,  1.06s/it]Loading train:  10%|▉         | 28/285 [00:33<04:37,  1.08s/it]Loading train:  10%|█         | 29/285 [00:34<04:28,  1.05s/it]Loading train:  11%|█         | 30/285 [00:35<04:29,  1.06s/it]Loading train:  11%|█         | 31/285 [00:36<04:31,  1.07s/it]Loading train:  11%|█         | 32/285 [00:37<04:29,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:38<04:24,  1.05s/it]Loading train:  12%|█▏        | 34/285 [00:39<04:27,  1.06s/it]Loading train:  12%|█▏        | 35/285 [00:41<04:33,  1.09s/it]Loading train:  13%|█▎        | 36/285 [00:42<04:24,  1.06s/it]Loading train:  13%|█▎        | 37/285 [00:43<04:28,  1.08s/it]Loading train:  13%|█▎        | 38/285 [00:44<04:11,  1.02s/it]Loading train:  14%|█▎        | 39/285 [00:45<04:14,  1.03s/it]Loading train:  14%|█▍        | 40/285 [00:46<04:10,  1.02s/it]Loading train:  14%|█▍        | 41/285 [00:47<04:13,  1.04s/it]Loading train:  15%|█▍        | 42/285 [00:48<04:16,  1.05s/it]Loading train:  15%|█▌        | 43/285 [00:49<04:07,  1.02s/it]Loading train:  15%|█▌        | 44/285 [00:50<04:09,  1.04s/it]Loading train:  16%|█▌        | 45/285 [00:51<04:08,  1.04s/it]Loading train:  16%|█▌        | 46/285 [00:52<03:59,  1.00s/it]Loading train:  16%|█▋        | 47/285 [00:53<03:48,  1.04it/s]Loading train:  17%|█▋        | 48/285 [00:54<03:54,  1.01it/s]Loading train:  17%|█▋        | 49/285 [00:55<03:46,  1.04it/s]Loading train:  18%|█▊        | 50/285 [00:55<03:33,  1.10it/s]Loading train:  18%|█▊        | 51/285 [00:56<03:23,  1.15it/s]Loading train:  18%|█▊        | 52/285 [00:57<03:34,  1.09it/s]Loading train:  19%|█▊        | 53/285 [00:58<03:25,  1.13it/s]Loading train:  19%|█▉        | 54/285 [00:59<03:21,  1.15it/s]Loading train:  19%|█▉        | 55/285 [01:00<03:22,  1.13it/s]Loading train:  20%|█▉        | 56/285 [01:01<03:20,  1.14it/s]Loading train:  20%|██        | 57/285 [01:01<03:18,  1.15it/s]Loading train:  20%|██        | 58/285 [01:02<03:29,  1.09it/s]Loading train:  21%|██        | 59/285 [01:03<03:33,  1.06it/s]Loading train:  21%|██        | 60/285 [01:04<03:28,  1.08it/s]Loading train:  21%|██▏       | 61/285 [01:05<03:17,  1.14it/s]Loading train:  22%|██▏       | 62/285 [01:06<03:18,  1.12it/s]Loading train:  22%|██▏       | 63/285 [01:07<03:15,  1.13it/s]Loading train:  22%|██▏       | 64/285 [01:09<04:02,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:10<04:42,  1.28s/it]Loading train:  23%|██▎       | 66/285 [01:11<04:39,  1.28s/it]Loading train:  24%|██▎       | 67/285 [01:12<04:11,  1.16s/it]Loading train:  24%|██▍       | 68/285 [01:13<03:57,  1.09s/it]Loading train:  24%|██▍       | 69/285 [01:14<03:35,  1.00it/s]Loading train:  25%|██▍       | 70/285 [01:15<03:35,  1.00s/it]Loading train:  25%|██▍       | 71/285 [01:16<03:32,  1.01it/s]Loading train:  25%|██▌       | 72/285 [01:17<03:19,  1.07it/s]Loading train:  26%|██▌       | 73/285 [01:18<03:21,  1.05it/s]Loading train:  26%|██▌       | 74/285 [01:19<03:13,  1.09it/s]Loading train:  26%|██▋       | 75/285 [01:20<03:09,  1.11it/s]Loading train:  27%|██▋       | 76/285 [01:20<03:00,  1.16it/s]Loading train:  27%|██▋       | 77/285 [01:21<03:05,  1.12it/s]Loading train:  27%|██▋       | 78/285 [01:22<03:02,  1.13it/s]Loading train:  28%|██▊       | 79/285 [01:23<03:08,  1.09it/s]Loading train:  28%|██▊       | 80/285 [01:24<03:11,  1.07it/s]Loading train:  28%|██▊       | 81/285 [01:25<03:19,  1.02it/s]Loading train:  29%|██▉       | 82/285 [01:26<03:30,  1.04s/it]Loading train:  29%|██▉       | 83/285 [01:28<03:42,  1.10s/it]Loading train:  29%|██▉       | 84/285 [01:29<03:58,  1.19s/it]Loading train:  30%|██▉       | 85/285 [01:30<04:05,  1.23s/it]Loading train:  30%|███       | 86/285 [01:32<04:12,  1.27s/it]Loading train:  31%|███       | 87/285 [01:33<04:08,  1.25s/it]Loading train:  31%|███       | 88/285 [01:34<04:15,  1.30s/it]Loading train:  31%|███       | 89/285 [01:35<03:59,  1.22s/it]Loading train:  32%|███▏      | 90/285 [01:37<03:56,  1.21s/it]Loading train:  32%|███▏      | 91/285 [01:38<03:43,  1.15s/it]Loading train:  32%|███▏      | 92/285 [01:39<03:48,  1.18s/it]Loading train:  33%|███▎      | 93/285 [01:40<03:57,  1.24s/it]Loading train:  33%|███▎      | 94/285 [01:41<03:57,  1.24s/it]Loading train:  33%|███▎      | 95/285 [01:43<03:55,  1.24s/it]Loading train:  34%|███▎      | 96/285 [01:44<04:08,  1.31s/it]Loading train:  34%|███▍      | 97/285 [01:46<04:23,  1.40s/it]Loading train:  34%|███▍      | 98/285 [01:47<04:12,  1.35s/it]Loading train:  35%|███▍      | 99/285 [01:48<04:18,  1.39s/it]Loading train:  35%|███▌      | 100/285 [01:50<04:23,  1.42s/it]Loading train:  35%|███▌      | 101/285 [01:51<04:09,  1.36s/it]Loading train:  36%|███▌      | 102/285 [01:52<04:04,  1.34s/it]Loading train:  36%|███▌      | 103/285 [01:54<04:06,  1.36s/it]Loading train:  36%|███▋      | 104/285 [01:55<04:08,  1.37s/it]Loading train:  37%|███▋      | 105/285 [01:57<04:01,  1.34s/it]Loading train:  37%|███▋      | 106/285 [01:58<03:55,  1.32s/it]Loading train:  38%|███▊      | 107/285 [01:59<03:43,  1.26s/it]Loading train:  38%|███▊      | 108/285 [02:00<03:35,  1.22s/it]Loading train:  38%|███▊      | 109/285 [02:01<03:31,  1.20s/it]Loading train:  39%|███▊      | 110/285 [02:02<03:29,  1.20s/it]Loading train:  39%|███▉      | 111/285 [02:04<03:29,  1.20s/it]Loading train:  39%|███▉      | 112/285 [02:05<03:28,  1.20s/it]Loading train:  40%|███▉      | 113/285 [02:06<03:34,  1.24s/it]Loading train:  40%|████      | 114/285 [02:07<03:25,  1.20s/it]Loading train:  40%|████      | 115/285 [02:09<03:30,  1.24s/it]Loading train:  41%|████      | 116/285 [02:10<03:24,  1.21s/it]Loading train:  41%|████      | 117/285 [02:11<03:24,  1.22s/it]Loading train:  41%|████▏     | 118/285 [02:12<03:17,  1.18s/it]Loading train:  42%|████▏     | 119/285 [02:13<03:15,  1.18s/it]Loading train:  42%|████▏     | 120/285 [02:14<03:09,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:16<03:32,  1.30s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:39,  1.35s/it]Loading train:  43%|████▎     | 123/285 [02:19<03:49,  1.41s/it]Loading train:  44%|████▎     | 124/285 [02:20<03:36,  1.34s/it]Loading train:  44%|████▍     | 125/285 [02:21<03:33,  1.34s/it]Loading train:  44%|████▍     | 126/285 [02:23<03:27,  1.30s/it]Loading train:  45%|████▍     | 127/285 [02:24<03:24,  1.29s/it]Loading train:  45%|████▍     | 128/285 [02:25<03:17,  1.26s/it]Loading train:  45%|████▌     | 129/285 [02:26<03:11,  1.23s/it]Loading train:  46%|████▌     | 130/285 [02:27<02:58,  1.15s/it]Loading train:  46%|████▌     | 131/285 [02:28<02:42,  1.05s/it]Loading train:  46%|████▋     | 132/285 [02:29<02:30,  1.01it/s]Loading train:  47%|████▋     | 133/285 [02:30<02:26,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:31<02:30,  1.00it/s]Loading train:  47%|████▋     | 135/285 [02:32<02:34,  1.03s/it]Loading train:  48%|████▊     | 136/285 [02:33<02:36,  1.05s/it]Loading train:  48%|████▊     | 137/285 [02:34<02:34,  1.05s/it]Loading train:  48%|████▊     | 138/285 [02:35<02:33,  1.05s/it]Loading train:  49%|████▉     | 139/285 [02:37<02:45,  1.13s/it]Loading train:  49%|████▉     | 140/285 [02:38<02:38,  1.10s/it]Loading train:  49%|████▉     | 141/285 [02:39<02:46,  1.15s/it]Loading train:  50%|████▉     | 142/285 [02:40<02:46,  1.16s/it]Loading train:  50%|█████     | 143/285 [02:41<02:50,  1.20s/it]Loading train:  51%|█████     | 144/285 [02:43<02:47,  1.19s/it]Loading train:  51%|█████     | 145/285 [02:44<02:43,  1.17s/it]Loading train:  51%|█████     | 146/285 [02:45<02:36,  1.13s/it]Loading train:  52%|█████▏    | 147/285 [02:46<02:38,  1.15s/it]Loading train:  52%|█████▏    | 148/285 [02:47<02:46,  1.22s/it]Loading train:  52%|█████▏    | 149/285 [02:48<02:41,  1.19s/it]Loading train:  53%|█████▎    | 150/285 [02:49<02:34,  1.14s/it]Loading train:  53%|█████▎    | 151/285 [02:50<02:31,  1.13s/it]Loading train:  53%|█████▎    | 152/285 [02:52<02:37,  1.18s/it]Loading train:  54%|█████▎    | 153/285 [02:53<02:29,  1.13s/it]Loading train:  54%|█████▍    | 154/285 [02:54<02:28,  1.13s/it]Loading train:  54%|█████▍    | 155/285 [02:55<02:24,  1.12s/it]Loading train:  55%|█████▍    | 156/285 [02:56<02:19,  1.08s/it]Loading train:  55%|█████▌    | 157/285 [02:57<02:20,  1.10s/it]Loading train:  55%|█████▌    | 158/285 [02:58<02:19,  1.10s/it]Loading train:  56%|█████▌    | 159/285 [02:59<02:16,  1.08s/it]Loading train:  56%|█████▌    | 160/285 [03:01<02:32,  1.22s/it]Loading train:  56%|█████▋    | 161/285 [03:02<02:23,  1.16s/it]Loading train:  57%|█████▋    | 162/285 [03:03<02:19,  1.13s/it]Loading train:  57%|█████▋    | 163/285 [03:04<02:19,  1.14s/it]Loading train:  58%|█████▊    | 164/285 [03:05<02:18,  1.14s/it]Loading train:  58%|█████▊    | 165/285 [03:06<02:12,  1.11s/it]Loading train:  58%|█████▊    | 166/285 [03:07<02:15,  1.14s/it]Loading train:  59%|█████▊    | 167/285 [03:08<02:08,  1.09s/it]Loading train:  59%|█████▉    | 168/285 [03:09<02:03,  1.05s/it]Loading train:  59%|█████▉    | 169/285 [03:10<02:01,  1.05s/it]Loading train:  60%|█████▉    | 170/285 [03:12<02:02,  1.06s/it]Loading train:  60%|██████    | 171/285 [03:13<02:06,  1.11s/it]Loading train:  60%|██████    | 172/285 [03:14<02:04,  1.10s/it]Loading train:  61%|██████    | 173/285 [03:15<02:05,  1.12s/it]Loading train:  61%|██████    | 174/285 [03:16<02:01,  1.10s/it]Loading train:  61%|██████▏   | 175/285 [03:17<01:58,  1.07s/it]Loading train:  62%|██████▏   | 176/285 [03:18<01:53,  1.04s/it]Loading train:  62%|██████▏   | 177/285 [03:19<01:54,  1.06s/it]Loading train:  62%|██████▏   | 178/285 [03:20<01:53,  1.06s/it]Loading train:  63%|██████▎   | 179/285 [03:21<01:55,  1.09s/it]Loading train:  63%|██████▎   | 180/285 [03:23<01:55,  1.10s/it]Loading train:  64%|██████▎   | 181/285 [03:23<01:47,  1.03s/it]Loading train:  64%|██████▍   | 182/285 [03:24<01:43,  1.00s/it]Loading train:  64%|██████▍   | 183/285 [03:25<01:36,  1.06it/s]Loading train:  65%|██████▍   | 184/285 [03:26<01:31,  1.10it/s]Loading train:  65%|██████▍   | 185/285 [03:27<01:24,  1.18it/s]Loading train:  65%|██████▌   | 186/285 [03:27<01:20,  1.24it/s]Loading train:  66%|██████▌   | 187/285 [03:28<01:16,  1.28it/s]Loading train:  66%|██████▌   | 188/285 [03:29<01:15,  1.29it/s]Loading train:  66%|██████▋   | 189/285 [03:30<01:12,  1.33it/s]Loading train:  67%|██████▋   | 190/285 [03:30<01:11,  1.33it/s]Loading train:  67%|██████▋   | 191/285 [03:31<01:17,  1.21it/s]Loading train:  67%|██████▋   | 192/285 [03:32<01:15,  1.23it/s]Loading train:  68%|██████▊   | 193/285 [03:33<01:18,  1.18it/s]Loading train:  68%|██████▊   | 194/285 [03:34<01:16,  1.20it/s]Loading train:  68%|██████▊   | 195/285 [03:35<01:17,  1.16it/s]Loading train:  69%|██████▉   | 196/285 [03:36<01:14,  1.19it/s]Loading train:  69%|██████▉   | 197/285 [03:36<01:15,  1.17it/s]Loading train:  69%|██████▉   | 198/285 [03:37<01:11,  1.21it/s]Loading train:  70%|██████▉   | 199/285 [03:38<01:14,  1.16it/s]Loading train:  70%|███████   | 200/285 [03:39<01:11,  1.19it/s]Loading train:  71%|███████   | 201/285 [03:40<01:11,  1.18it/s]Loading train:  71%|███████   | 202/285 [03:41<01:09,  1.20it/s]Loading train:  71%|███████   | 203/285 [03:42<01:12,  1.13it/s]Loading train:  72%|███████▏  | 204/285 [03:43<01:13,  1.11it/s]Loading train:  72%|███████▏  | 205/285 [03:43<01:13,  1.09it/s]Loading train:  72%|███████▏  | 206/285 [03:44<01:11,  1.11it/s]Loading train:  73%|███████▎  | 207/285 [03:45<01:10,  1.10it/s]Loading train:  73%|███████▎  | 208/285 [03:46<01:08,  1.13it/s]Loading train:  73%|███████▎  | 209/285 [03:47<01:09,  1.09it/s]Loading train:  74%|███████▎  | 210/285 [03:48<01:06,  1.13it/s]Loading train:  74%|███████▍  | 211/285 [03:49<01:03,  1.16it/s]Loading train:  74%|███████▍  | 212/285 [03:50<01:02,  1.16it/s]Loading train:  75%|███████▍  | 213/285 [03:50<01:00,  1.19it/s]Loading train:  75%|███████▌  | 214/285 [03:51<01:01,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [03:52<00:59,  1.18it/s]Loading train:  76%|███████▌  | 216/285 [03:53<00:58,  1.18it/s]Loading train:  76%|███████▌  | 217/285 [03:54<00:56,  1.21it/s]Loading train:  76%|███████▋  | 218/285 [03:55<00:54,  1.22it/s]Loading train:  77%|███████▋  | 219/285 [03:55<00:52,  1.26it/s]Loading train:  77%|███████▋  | 220/285 [03:56<00:49,  1.30it/s]Loading train:  78%|███████▊  | 221/285 [03:57<00:49,  1.30it/s]Loading train:  78%|███████▊  | 222/285 [03:57<00:46,  1.35it/s]Loading train:  78%|███████▊  | 223/285 [03:58<00:48,  1.29it/s]Loading train:  79%|███████▊  | 224/285 [03:59<00:46,  1.30it/s]Loading train:  79%|███████▉  | 225/285 [04:00<00:45,  1.31it/s]Loading train:  79%|███████▉  | 226/285 [04:00<00:44,  1.33it/s]Loading train:  80%|███████▉  | 227/285 [04:01<00:44,  1.32it/s]Loading train:  80%|████████  | 228/285 [04:02<00:43,  1.31it/s]Loading train:  80%|████████  | 229/285 [04:03<00:45,  1.22it/s]Loading train:  81%|████████  | 230/285 [04:04<00:47,  1.17it/s]Loading train:  81%|████████  | 231/285 [04:05<00:43,  1.24it/s]Loading train:  81%|████████▏ | 232/285 [04:06<00:45,  1.16it/s]Loading train:  82%|████████▏ | 233/285 [04:07<00:46,  1.12it/s]Loading train:  82%|████████▏ | 234/285 [04:08<00:46,  1.09it/s]Loading train:  82%|████████▏ | 235/285 [04:09<00:49,  1.01it/s]Loading train:  83%|████████▎ | 236/285 [04:10<00:52,  1.07s/it]Loading train:  83%|████████▎ | 237/285 [04:11<00:51,  1.08s/it]Loading train:  84%|████████▎ | 238/285 [04:12<00:50,  1.08s/it]Loading train:  84%|████████▍ | 239/285 [04:14<00:54,  1.19s/it]Loading train:  84%|████████▍ | 240/285 [04:15<00:52,  1.17s/it]Loading train:  85%|████████▍ | 241/285 [04:16<00:50,  1.16s/it]Loading train:  85%|████████▍ | 242/285 [04:17<00:50,  1.18s/it]Loading train:  85%|████████▌ | 243/285 [04:18<00:48,  1.16s/it]Loading train:  86%|████████▌ | 244/285 [04:19<00:47,  1.15s/it]Loading train:  86%|████████▌ | 245/285 [04:20<00:45,  1.14s/it]Loading train:  86%|████████▋ | 246/285 [04:22<00:44,  1.13s/it]Loading train:  87%|████████▋ | 247/285 [04:23<00:47,  1.26s/it]Loading train:  87%|████████▋ | 248/285 [04:24<00:46,  1.26s/it]Loading train:  87%|████████▋ | 249/285 [04:25<00:43,  1.21s/it]Loading train:  88%|████████▊ | 250/285 [04:27<00:40,  1.16s/it]Loading train:  88%|████████▊ | 251/285 [04:27<00:37,  1.10s/it]Loading train:  88%|████████▊ | 252/285 [04:29<00:35,  1.08s/it]Loading train:  89%|████████▉ | 253/285 [04:30<00:34,  1.07s/it]Loading train:  89%|████████▉ | 254/285 [04:31<00:32,  1.06s/it]Loading train:  89%|████████▉ | 255/285 [04:32<00:31,  1.04s/it]Loading train:  90%|████████▉ | 256/285 [04:33<00:29,  1.03s/it]Loading train:  90%|█████████ | 257/285 [04:34<00:28,  1.03s/it]Loading train:  91%|█████████ | 258/285 [04:35<00:28,  1.07s/it]Loading train:  91%|█████████ | 259/285 [04:36<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [04:37<00:26,  1.07s/it]Loading train:  92%|█████████▏| 261/285 [04:38<00:24,  1.01s/it]Loading train:  92%|█████████▏| 262/285 [04:39<00:24,  1.04s/it]Loading train:  92%|█████████▏| 263/285 [04:40<00:21,  1.01it/s]Loading train:  93%|█████████▎| 264/285 [04:41<00:20,  1.04it/s]Loading train:  93%|█████████▎| 265/285 [04:42<00:19,  1.02it/s]Loading train:  93%|█████████▎| 266/285 [04:42<00:17,  1.08it/s]Loading train:  94%|█████████▎| 267/285 [04:44<00:17,  1.02it/s]Loading train:  94%|█████████▍| 268/285 [04:45<00:18,  1.07s/it]Loading train:  94%|█████████▍| 269/285 [04:46<00:16,  1.04s/it]Loading train:  95%|█████████▍| 270/285 [04:47<00:16,  1.08s/it]Loading train:  95%|█████████▌| 271/285 [04:48<00:15,  1.14s/it]Loading train:  95%|█████████▌| 272/285 [04:49<00:14,  1.15s/it]Loading train:  96%|█████████▌| 273/285 [04:51<00:14,  1.18s/it]Loading train:  96%|█████████▌| 274/285 [04:52<00:12,  1.17s/it]Loading train:  96%|█████████▋| 275/285 [04:53<00:11,  1.17s/it]Loading train:  97%|█████████▋| 276/285 [04:54<00:10,  1.20s/it]Loading train:  97%|█████████▋| 277/285 [04:55<00:09,  1.18s/it]Loading train:  98%|█████████▊| 278/285 [04:57<00:08,  1.15s/it]Loading train:  98%|█████████▊| 279/285 [04:58<00:07,  1.20s/it]Loading train:  98%|█████████▊| 280/285 [04:59<00:05,  1.18s/it]Loading train:  99%|█████████▊| 281/285 [05:00<00:04,  1.17s/it]Loading train:  99%|█████████▉| 282/285 [05:01<00:03,  1.17s/it]Loading train:  99%|█████████▉| 283/285 [05:02<00:02,  1.12s/it]Loading train: 100%|█████████▉| 284/285 [05:04<00:01,  1.18s/it]Loading train: 100%|██████████| 285/285 [05:05<00:00,  1.19s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:01, 158.01it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:01, 158.24it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:01, 167.68it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:01, 160.33it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:01, 178.91it/s]concatenating: train:  42%|████▏     | 120/285 [00:00<00:00, 197.77it/s]concatenating: train:  53%|█████▎    | 150/285 [00:00<00:00, 219.06it/s]concatenating: train:  61%|██████    | 173/285 [00:00<00:00, 188.11it/s]concatenating: train:  69%|██████▉   | 196/285 [00:00<00:00, 196.39it/s]concatenating: train:  78%|███████▊  | 223/285 [00:01<00:00, 212.37it/s]concatenating: train:  86%|████████▋ | 246/285 [00:01<00:00, 207.86it/s]concatenating: train:  94%|█████████▍| 268/285 [00:01<00:00, 202.08it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 206.28it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.48s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.51s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.53s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 719.81it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 30 |  Upsample 1

 #layer 4 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 30 |  Upsample 1

 #layer 4 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 80, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 40, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 40, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 40, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 40, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 40, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 20, 60)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 20, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 20, 120)  64920       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 20, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 20, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 20, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 7, 10, 120)   0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 7, 10, 120)   0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 7, 10, 240)   259440      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 7, 10, 240)   960         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 7, 10, 240)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________2019-07-01 01:10:33.183100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-01 01:10:33.183190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-01 01:10:33.183204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-01 01:10:33.183213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-01 01:10:33.183600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

conv2d_8 (Conv2D)               (None, 7, 10, 240)   518640      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 7, 10, 240)   960         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 7, 10, 240)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 7, 10, 240)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 14, 20, 120)  115320      dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 14, 20, 240)  0           conv2d_transpose_1[0][0]         
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 20, 120)  259320      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 20, 120)  480         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 20, 120)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 20, 120)  129720      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 20, 120)  480         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 20, 120)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 20, 120)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 28, 40, 60)   28860       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 40, 120)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 40, 60)   64860       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 40, 60)   240         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 40, 60)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 40, 60)   32460       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 40, 60)   240         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 40, 60)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 40, 60)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 56, 80, 30)   7230        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 80, 60)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 80, 30)   16230       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 80, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 80, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 80, 30)   8130        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 80, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 80, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 80, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 80, 13)   403         dropout_7[0][0]                  
==================================================================================================
Total params: 1,697,683
Trainable params: 1,695,043
Non-trainable params: 2,640
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [2.29678646e+01 1.13088369e+01 2.65421366e+01 3.29884122e+00
 9.58849072e+00 2.50031647e+00 3.01177739e+01 3.98604065e+01
 3.04429722e+01 4.68832496e+00 1.04095038e+02 6.92273731e+01
 8.75539005e-02]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 21s - loss: 1429.9968 - acc: 0.9023 - mDice: 0.3413 - val_loss: 1273.1844 - val_acc: 0.9340 - val_mDice: 0.3812

Epoch 00001: val_mDice improved from -inf to 0.38119, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 12s - loss: 659.5799 - acc: 0.9172 - mDice: 0.5599 - val_loss: 1356.5180 - val_acc: 0.9363 - val_mDice: 0.4051

Epoch 00002: val_mDice improved from 0.38119 to 0.40509, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 542.1507 - acc: 0.9218 - mDice: 0.6277 - val_loss: 1153.0932 - val_acc: 0.9394 - val_mDice: 0.4578

Epoch 00003: val_mDice improved from 0.40509 to 0.45781, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 485.5693 - acc: 0.9249 - mDice: 0.6629 - val_loss: 1319.4086 - val_acc: 0.9384 - val_mDice: 0.4420

Epoch 00004: val_mDice did not improve from 0.45781
Epoch 5/300
 - 12s - loss: 444.5318 - acc: 0.9278 - mDice: 0.6896 - val_loss: 1407.3073 - val_acc: 0.9385 - val_mDice: 0.4522

Epoch 00005: val_mDice did not improve from 0.45781
Epoch 6/300
 - 12s - loss: 414.7223 - acc: 0.9291 - mDice: 0.7099 - val_loss: 1427.6614 - val_acc: 0.9387 - val_mDice: 0.4550

Epoch 00006: val_mDice did not improve from 0.45781
Epoch 7/300
 - 12s - loss: 392.7422 - acc: 0.9303 - mDice: 0.7243 - val_loss: 1571.2190 - val_acc: 0.9382 - val_mDice: 0.4426

Epoch 00007: val_mDice did not improve from 0.45781
Epoch 8/300
 - 12s - loss: 373.9243 - acc: 0.9311 - mDice: 0.7370 - val_loss: 1576.5816 - val_acc: 0.9382 - val_mDice: 0.4568

Epoch 00008: val_mDice did not improve from 0.45781
Epoch 9/300
 - 12s - loss: 360.4921 - acc: 0.9323 - mDice: 0.7459 - val_loss: 1422.9391 - val_acc: 0.9392 - val_mDice: 0.4829

Epoch 00009: val_mDice improved from 0.45781 to 0.48291, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 12s - loss: 348.0744 - acc: 0.9325 - mDice: 0.7550 - val_loss: 1655.7690 - val_acc: 0.9387 - val_mDice: 0.4521

Epoch 00010: val_mDice did not improve from 0.48291
Epoch 11/300
 - 12s - loss: 338.3783 - acc: 0.9330 - mDice: 0.7611 - val_loss: 1683.1625 - val_acc: 0.9383 - val_mDice: 0.4551

Epoch 00011: val_mDice did not improve from 0.48291
Epoch 12/300
 - 11s - loss: 328.2334 - acc: 0.9337 - mDice: 0.7681 - val_loss: 1728.3819 - val_acc: 0.9384 - val_mDice: 0.4505

Epoch 00012: val_mDice did not improve from 0.48291
Epoch 13/300
 - 12s - loss: 319.4097 - acc: 0.9342 - mDice: 0.7742 - val_loss: 1714.6840 - val_acc: 0.9392 - val_mDice: 0.4653

Epoch 00013: val_mDice did not improve from 0.48291
Epoch 14/300
 - 12s - loss: 312.2438 - acc: 0.9343 - mDice: 0.7793 - val_loss: 1753.1624 - val_acc: 0.9394 - val_mDice: 0.4609

Epoch 00014: val_mDice did not improve from 0.48291
Epoch 15/300
 - 11s - loss: 307.0149 - acc: 0.9345 - mDice: 0.7829 - val_loss: 1685.3637 - val_acc: 0.9383 - val_mDice: 0.4667

Epoch 00015: val_mDice did not improve from 0.48291
Epoch 16/300
 - 12s - loss: 302.2034 - acc: 0.9343 - mDice: 0.7865 - val_loss: 1753.6493 - val_acc: 0.9390 - val_mDice: 0.4671

Epoch 00016: val_mDice did not improve from 0.48291
Epoch 17/300
 - 12s - loss: 295.5128 - acc: 0.9342 - mDice: 0.7911 - val_loss: 1848.7068 - val_acc: 0.9382 - val_mDice: 0.4606

Epoch 00017: val_mDice did not improve from 0.48291
Epoch 18/300
 - 12s - loss: 290.7218 - acc: 0.9345 - mDice: 0.7939 - val_loss: 1889.6779 - val_acc: 0.9374 - val_mDice: 0.4552

Epoch 00018: val_mDice did not improve from 0.48291
Epoch 19/300
 - 12s - loss: 285.6144 - acc: 0.9349 - mDice: 0.7977 - val_loss: 1718.7776 - val_acc: 0.9399 - val_mDice: 0.4743

Epoch 00019: val_mDice did not improve from 0.48291
Epoch 20/300
 - 12s - loss: 281.7428 - acc: 0.9351 - mDice: 0.8005 - val_loss: 1794.2720 - val_acc: 0.9386 - val_mDice: 0.4762

Epoch 00020: val_mDice did not improve from 0.48291
Epoch 21/300
 - 12s - loss: 279.0731 - acc: 0.9350 - mDice: 0.8024 - val_loss: 1800.7634 - val_acc: 0.9388 - val_mDice: 0.4647

Epoch 00021: val_mDice did not improve from 0.48291
Epoch 22/300
 - 12s - loss: 274.5198 - acc: 0.9351 - mDice: 0.8051 - val_loss: 1969.4117 - val_acc: 0.9381 - val_mDice: 0.4586

Epoch 00022: val_mDice did not improve from 0.48291
Epoch 23/300
 - 12s - loss: 269.5990 - acc: 0.9351 - mDice: 0.8090 - val_loss: 1911.8445 - val_acc: 0.9388 - val_mDice: 0.4655

Epoch 00023: val_mDice did not improve from 0.48291
Epoch 24/300
 - 12s - loss: 266.6151 - acc: 0.9356 - mDice: 0.8109 - val_loss: 1919.9287 - val_acc: 0.9392 - val_mDice: 0.4647

Epoch 00024: val_mDice did not improve from 0.48291
Epoch 25/300
 - 12s - loss: 262.7974 - acc: 0.9357 - mDice: 0.8135 - val_loss: 1877.2415 - val_acc: 0.9392 - val_mDice: 0.4728

Epoch 00025: val_mDice did not improve from 0.48291
Epoch 26/300
 - 12s - loss: 262.8941 - acc: 0.9353 - mDice: 0.8136 - val_loss: 1964.7353 - val_acc: 0.9384 - val_mDice: 0.4586

Epoch 00026: val_mDice did not improve from 0.48291
Epoch 27/300
 - 11s - loss: 257.7216 - acc: 0.9356 - mDice: 0.8174 - val_loss: 2098.2009 - val_acc: 0.9374 - val_mDice: 0.4522

Epoch 00027: val_mDice did not improve from 0.48291
Epoch 28/300
 - 12s - loss: 256.1726 - acc: 0.9359 - mDice: 0.8182 - val_loss: 2079.2040 - val_acc: 0.9373 - val_mDice: 0.4554

Epoch 00028: val_mDice did not improve from 0.48291
Epoch 29/300
 - 12s - loss: 253.4170 - acc: 0.9357 - mDice: 0.8203 - val_loss: 1915.8175 - val_acc: 0.9393 - val_mDice: 0.4697

Epoch 00029: val_mDice did not improve from 0.48291
Epoch 30/300
 - 12s - loss: 249.9699 - acc: 0.9359 - mDice: 0.8227 - val_loss: 1949.0329 - val_acc: 0.9390 - val_mDice: 0.4688

Epoch 00030: val_mDice did not improve from 0.48291
Epoch 31/300
 - 13s - loss: 247.4434 - acc: 0.9361 - mDice: 0.8245 - val_loss: 1983.2172 - val_acc: 0.9395 - val_mDice: 0.4707

Epoch 00031: val_mDice did not improve from 0.48291
Epoch 32/300
 - 13s - loss: 245.1941 - acc: 0.9366 - mDice: 0.8262 - val_loss: 1889.8506 - val_acc: 0.9401 - val_mDice: 0.4772

Epoch 00032: val_mDice did not improve from 0.48291
Epoch 33/300
 - 12s - loss: 243.7778 - acc: 0.9367 - mDice: 0.8270 - val_loss: 2118.4340 - val_acc: 0.9389 - val_mDice: 0.4651

Epoch 00033: val_mDice did not improve from 0.48291
Epoch 34/300
 - 12s - loss: 241.0621 - acc: 0.9368 - mDice: 0.8290 - val_loss: 2091.5914 - val_acc: 0.9393 - val_mDice: 0.4649

Epoch 00034: val_mDice did not improve from 0.48291
Epoch 35/300
 - 12s - loss: 239.1972 - acc: 0.9366 - mDice: 0.8304 - val_loss: 2108.8646 - val_acc: 0.9385 - val_mDice: 0.4586

Epoch 00035: val_mDice did not improve from 0.48291
Epoch 36/300
 - 12s - loss: 237.7094 - acc: 0.9367 - mDice: 0.8316 - val_loss: 2151.4439 - val_acc: 0.9383 - val_mDice: 0.4625

Epoch 00036: val_mDice did not improve from 0.48291
Epoch 37/300
 - 12s - loss: 236.4052 - acc: 0.9362 - mDice: 0.8323 - val_loss: 1930.4733 - val_acc: 0.9388 - val_mDice: 0.4789

Epoch 00037: val_mDice did not improve from 0.48291
Epoch 38/300
 - 12s - loss: 233.9435 - acc: 0.9363 - mDice: 0.8340 - val_loss: 2133.5439 - val_acc: 0.9391 - val_mDice: 0.4651

Epoch 00038: val_mDice did not improve from 0.48291
Epoch 39/300
 - 12s - loss: 231.4780 - acc: 0.9368 - mDice: 0.8360 - val_loss: 2143.2394 - val_acc: 0.9383 - val_mDice: 0.4595

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.42s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.13s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:58,  1.47s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:19,  1.55s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:13,  1.54s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:41,  1.64s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:18,  1.57s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:46,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:12,  1.77s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:19,  1.80s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:08,  1.77s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:19,  1.82s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:24,  1.84s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:30,  1.87s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:31,  1.88s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:32,  1.89s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:39,  1.93s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:44,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:39,  1.94s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:41,  1.95s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:52,  2.01s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:47,  2.00s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:46,  2.00s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:42,  1.99s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:38,  1.99s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:31,  1.97s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:43,  2.02s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:37,  2.00s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:31,  1.99s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:22,  1.96s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:15,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:07,  1.92s/it]predicting train subjects:  11%|█         | 32/285 [01:00<08:01,  1.90s/it]predicting train subjects:  12%|█▏        | 33/285 [01:02<07:58,  1.90s/it]predicting train subjects:  12%|█▏        | 34/285 [01:04<08:03,  1.93s/it]predicting train subjects:  12%|█▏        | 35/285 [01:06<08:01,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:08<07:56,  1.91s/it]predicting train subjects:  13%|█▎        | 37/285 [01:10<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:44,  1.88s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:46,  1.89s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<07:46,  1.91s/it]predicting train subjects:  14%|█▍        | 41/285 [01:17<07:47,  1.92s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:48,  1.93s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:45,  1.92s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<07:42,  1.92s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:38,  1.91s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:20,  1.84s/it]predicting train subjects:  16%|█▋        | 47/285 [01:28<06:54,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:30<06:42,  1.70s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<06:32,  1.66s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<06:22,  1.63s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<06:24,  1.65s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<06:26,  1.66s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<06:22,  1.65s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<06:14,  1.62s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<06:14,  1.63s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<06:15,  1.64s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:17,  1.66s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:14,  1.65s/it]predicting train subjects:  21%|██        | 59/285 [01:48<06:12,  1.65s/it]predicting train subjects:  21%|██        | 60/285 [01:49<06:09,  1.64s/it]predicting train subjects:  21%|██▏       | 61/285 [01:51<06:08,  1.65s/it]predicting train subjects:  22%|██▏       | 62/285 [01:53<06:03,  1.63s/it]predicting train subjects:  22%|██▏       | 63/285 [01:54<06:00,  1.62s/it]predicting train subjects:  22%|██▏       | 64/285 [01:56<06:08,  1.67s/it]predicting train subjects:  23%|██▎       | 65/285 [01:58<06:25,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [02:00<06:28,  1.77s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<06:25,  1.77s/it]predicting train subjects:  24%|██▍       | 68/285 [02:03<06:23,  1.77s/it]predicting train subjects:  24%|██▍       | 69/285 [02:05<06:18,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:07<06:09,  1.72s/it]predicting train subjects:  25%|██▍       | 71/285 [02:08<06:03,  1.70s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<05:57,  1.68s/it]predicting train subjects:  26%|██▌       | 73/285 [02:12<05:58,  1.69s/it]predicting train subjects:  26%|██▌       | 74/285 [02:13<05:59,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:15<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 76/285 [02:17<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 77/285 [02:18<05:56,  1.71s/it]predicting train subjects:  27%|██▋       | 78/285 [02:20<05:56,  1.72s/it]predicting train subjects:  28%|██▊       | 79/285 [02:22<05:50,  1.70s/it]predicting train subjects:  28%|██▊       | 80/285 [02:24<05:44,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:25<05:44,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:27<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:29<05:37,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:30<05:34,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:32<05:49,  1.75s/it]predicting train subjects:  30%|███       | 86/285 [02:34<05:57,  1.80s/it]predicting train subjects:  31%|███       | 87/285 [02:36<06:03,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:38<06:07,  1.86s/it]predicting train subjects:  31%|███       | 89/285 [02:40<06:10,  1.89s/it]predicting train subjects:  32%|███▏      | 90/285 [02:42<06:11,  1.90s/it]predicting train subjects:  32%|███▏      | 91/285 [02:44<06:07,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [02:46<06:09,  1.91s/it]predicting train subjects:  33%|███▎      | 93/285 [02:48<06:10,  1.93s/it]predicting train subjects:  33%|███▎      | 94/285 [02:49<06:03,  1.90s/it]predicting train subjects:  33%|███▎      | 95/285 [02:51<06:03,  1.91s/it]predicting train subjects:  34%|███▎      | 96/285 [02:53<05:55,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [02:55<05:54,  1.89s/it]predicting train subjects:  34%|███▍      | 98/285 [02:57<05:47,  1.86s/it]predicting train subjects:  35%|███▍      | 99/285 [02:59<05:50,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [03:01<05:49,  1.89s/it]predicting train subjects:  35%|███▌      | 101/285 [03:03<05:49,  1.90s/it]predicting train subjects:  36%|███▌      | 102/285 [03:04<05:46,  1.89s/it]predicting train subjects:  36%|███▌      | 103/285 [03:06<05:39,  1.87s/it]predicting train subjects:  36%|███▋      | 104/285 [03:08<05:38,  1.87s/it]predicting train subjects:  37%|███▋      | 105/285 [03:10<05:32,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:12<05:33,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:14<05:34,  1.88s/it]predicting train subjects:  38%|███▊      | 108/285 [03:16<05:37,  1.91s/it]predicting train subjects:  38%|███▊      | 109/285 [03:18<05:39,  1.93s/it]predicting train subjects:  39%|███▊      | 110/285 [03:20<05:47,  1.99s/it]predicting train subjects:  39%|███▉      | 111/285 [03:22<05:33,  1.92s/it]predicting train subjects:  39%|███▉      | 112/285 [03:23<05:28,  1.90s/it]predicting train subjects:  40%|███▉      | 113/285 [03:25<05:25,  1.89s/it]predicting train subjects:  40%|████      | 114/285 [03:27<05:19,  1.87s/it]predicting train subjects:  40%|████      | 115/285 [03:29<05:11,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:31<05:16,  1.87s/it]predicting train subjects:  41%|████      | 117/285 [03:33<05:15,  1.88s/it]predicting train subjects:  41%|████▏     | 118/285 [03:35<05:30,  1.98s/it]predicting train subjects:  42%|████▏     | 119/285 [03:37<05:30,  1.99s/it]predicting train subjects:  42%|████▏     | 120/285 [03:39<05:29,  2.00s/it]predicting train subjects:  42%|████▏     | 121/285 [03:41<05:19,  1.95s/it]predicting train subjects:  43%|████▎     | 122/285 [03:43<05:05,  1.87s/it]predicting train subjects:  43%|████▎     | 123/285 [03:44<04:50,  1.79s/it]predicting train subjects:  44%|████▎     | 124/285 [03:46<04:55,  1.83s/it]predicting train subjects:  44%|████▍     | 125/285 [03:48<04:53,  1.84s/it]predicting train subjects:  44%|████▍     | 126/285 [03:50<04:49,  1.82s/it]predicting train subjects:  45%|████▍     | 127/285 [03:51<04:46,  1.81s/it]predicting train subjects:  45%|████▍     | 128/285 [03:53<04:39,  1.78s/it]predicting train subjects:  45%|████▌     | 129/285 [03:55<04:39,  1.79s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<04:37,  1.79s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<04:38,  1.81s/it]predicting train subjects:  46%|████▋     | 132/285 [04:00<04:37,  1.81s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<04:38,  1.83s/it]predicting train subjects:  47%|████▋     | 134/285 [04:04<04:39,  1.85s/it]predicting train subjects:  47%|████▋     | 135/285 [04:06<04:44,  1.90s/it]predicting train subjects:  48%|████▊     | 136/285 [04:08<04:37,  1.86s/it]predicting train subjects:  48%|████▊     | 137/285 [04:10<04:36,  1.87s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<04:31,  1.85s/it]predicting train subjects:  49%|████▉     | 139/285 [04:13<04:23,  1.81s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<04:26,  1.84s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<04:20,  1.81s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<04:08,  1.74s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:59,  1.69s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<04:00,  1.71s/it]predicting train subjects:  51%|█████     | 145/285 [04:24<03:54,  1.67s/it]predicting train subjects:  51%|█████     | 146/285 [04:25<03:50,  1.66s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:27<03:50,  1.67s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:29<03:47,  1.66s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:30<03:46,  1.67s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:38,  1.62s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:33<03:32,  1.58s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:33,  1.60s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:36<03:32,  1.61s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:38<03:35,  1.65s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:40<03:40,  1.70s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:42<03:35,  1.67s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:43<03:29,  1.63s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:45<03:22,  1.60s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:46<03:27,  1.65s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:48<03:29,  1.67s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:50<03:23,  1.64s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:51<03:22,  1.65s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:53<03:27,  1.70s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:55<03:20,  1.65s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:56<03:19,  1.66s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:58<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<03:11,  1.63s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:01<03:10,  1.63s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<03:10,  1.64s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:05<03:09,  1.65s/it]predicting train subjects:  60%|██████    | 171/285 [05:06<03:05,  1.63s/it]predicting train subjects:  60%|██████    | 172/285 [05:08<03:02,  1.62s/it]predicting train subjects:  61%|██████    | 173/285 [05:09<02:58,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [05:11<02:56,  1.59s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:13<02:55,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:14<02:52,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:16<02:51,  1.59s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:17<02:53,  1.62s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:19<02:52,  1.63s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:21<02:49,  1.61s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:22<02:45,  1.60s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:24<02:42,  1.58s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:25<02:39,  1.56s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:27<02:34,  1.53s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:28<02:36,  1.56s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:30<02:33,  1.55s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:31<02:34,  1.57s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:33<02:32,  1.57s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:34<02:26,  1.53s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:36<02:23,  1.51s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:38<02:26,  1.56s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:39<02:23,  1.54s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:41<02:23,  1.56s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:42<02:15,  1.49s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:43<02:08,  1.43s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:45<02:13,  1.50s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:47<02:15,  1.54s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:48<02:15,  1.56s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:50<02:16,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:51<02:14,  1.59s/it]predicting train subjects:  71%|███████   | 201/285 [05:53<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:55<02:11,  1.58s/it]predicting train subjects:  71%|███████   | 203/285 [05:56<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:58<02:12,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:00<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:01<02:07,  1.61s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:03<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:05<02:05,  1.63s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:06<02:02,  1.61s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:08<02:03,  1.64s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:09<02:00,  1.63s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:11<02:00,  1.65s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:13<01:59,  1.66s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:14<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:16<01:47,  1.53s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:43,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:18<01:39,  1.46s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:20<01:37,  1.45s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:21<01:35,  1.45s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:23<01:33,  1.44s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:24<01:30,  1.42s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:26<01:30,  1.44s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:27<01:29,  1.44s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:28<01:28,  1.44s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:30<01:25,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:31<01:23,  1.42s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:21,  1.41s/it]predicting train subjects:  80%|████████  | 228/285 [06:34<01:21,  1.42s/it]predicting train subjects:  80%|████████  | 229/285 [06:35<01:20,  1.43s/it]predicting train subjects:  81%|████████  | 230/285 [06:37<01:18,  1.43s/it]predicting train subjects:  81%|████████  | 231/285 [06:38<01:16,  1.42s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:40<01:21,  1.54s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:42<01:25,  1.64s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:44<01:28,  1.73s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:46<01:27,  1.74s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:48<01:26,  1.77s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:49<01:26,  1.80s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:51<01:24,  1.80s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:53<01:23,  1.82s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:55<01:21,  1.82s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:57<01:19,  1.80s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:58<01:17,  1.80s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:00<01:15,  1.80s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:02<01:13,  1.79s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:04<01:11,  1.80s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:06<01:10,  1.80s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:07<01:08,  1.81s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:09<01:06,  1.80s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:11<01:05,  1.81s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:12<00:58,  1.67s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:14<00:53,  1.57s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:15<00:49,  1.50s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:16<00:46,  1.44s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:18<00:43,  1.42s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:19<00:41,  1.40s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:20<00:40,  1.39s/it]predicting train subjects:  90%|█████████ | 257/285 [07:22<00:38,  1.37s/it]predicting train subjects:  91%|█████████ | 258/285 [07:23<00:37,  1.37s/it]predicting train subjects:  91%|█████████ | 259/285 [07:25<00:35,  1.36s/it]predicting train subjects:  91%|█████████ | 260/285 [07:26<00:33,  1.35s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:27<00:32,  1.34s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:29<00:30,  1.34s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:30<00:29,  1.35s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:31<00:28,  1.34s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:33<00:26,  1.34s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:34<00:25,  1.36s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:35<00:24,  1.36s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:37<00:25,  1.50s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:39<00:25,  1.59s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:41<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:43<00:23,  1.70s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:44<00:22,  1.71s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:46<00:20,  1.73s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:48<00:19,  1.75s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:50<00:17,  1.77s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:52<00:16,  1.79s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:53<00:14,  1.80s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:55<00:12,  1.79s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:57<00:10,  1.80s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:59<00:08,  1.80s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:00<00:07,  1.79s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:02<00:05,  1.80s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:04<00:03,  1.81s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:06<00:01,  1.81s/it]predicting train subjects: 100%|██████████| 285/285 [08:08<00:00,  1.80s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:45,  1.43s/it]Loading train:   1%|          | 2/285 [00:02<06:53,  1.46s/it]Loading train:   1%|          | 3/285 [00:04<06:51,  1.46s/it]Loading train:   1%|▏         | 4/285 [00:06<07:14,  1.55s/it]Loading train:   2%|▏         | 5/285 [00:07<06:51,  1.47s/it]Loading train:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]Loading train:   2%|▏         | 7/285 [00:11<07:38,  1.65s/it]Loading train:   3%|▎         | 8/285 [00:12<07:48,  1.69s/it]Loading train:   3%|▎         | 9/285 [00:14<07:27,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<07:11,  1.57s/it]Loading train:   4%|▍         | 11/285 [00:16<06:40,  1.46s/it]Loading train:   4%|▍         | 12/285 [00:18<06:19,  1.39s/it]Loading train:   5%|▍         | 13/285 [00:19<06:02,  1.33s/it]Loading train:   5%|▍         | 14/285 [00:20<06:20,  1.41s/it]Loading train:   5%|▌         | 15/285 [00:22<06:10,  1.37s/it]Loading train:   6%|▌         | 16/285 [00:23<05:57,  1.33s/it]Loading train:   6%|▌         | 17/285 [00:24<05:51,  1.31s/it]Loading train:   6%|▋         | 18/285 [00:25<05:37,  1.26s/it]Loading train:   7%|▋         | 19/285 [00:27<05:33,  1.25s/it]Loading train:   7%|▋         | 20/285 [00:28<05:33,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:29<05:33,  1.26s/it]Loading train:   8%|▊         | 22/285 [00:30<05:25,  1.24s/it]Loading train:   8%|▊         | 23/285 [00:32<05:23,  1.23s/it]Loading train:   8%|▊         | 24/285 [00:33<05:21,  1.23s/it]Loading train:   9%|▉         | 25/285 [00:34<05:17,  1.22s/it]Loading train:   9%|▉         | 26/285 [00:35<05:09,  1.20s/it]Loading train:   9%|▉         | 27/285 [00:36<05:13,  1.21s/it]Loading train:  10%|▉         | 28/285 [00:38<05:20,  1.25s/it]Loading train:  10%|█         | 29/285 [00:39<05:02,  1.18s/it]Loading train:  11%|█         | 30/285 [00:40<04:53,  1.15s/it]Loading train:  11%|█         | 31/285 [00:41<04:42,  1.11s/it]Loading train:  11%|█         | 32/285 [00:42<04:38,  1.10s/it]Loading train:  12%|█▏        | 33/285 [00:43<04:41,  1.12s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:48,  1.15s/it]Loading train:  12%|█▏        | 35/285 [00:45<04:42,  1.13s/it]Loading train:  13%|█▎        | 36/285 [00:46<04:37,  1.11s/it]Loading train:  13%|█▎        | 37/285 [00:47<04:27,  1.08s/it]Loading train:  13%|█▎        | 38/285 [00:48<04:20,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:50<04:19,  1.06s/it]Loading train:  14%|█▍        | 40/285 [00:51<04:17,  1.05s/it]Loading train:  14%|█▍        | 41/285 [00:52<04:15,  1.05s/it]Loading train:  15%|█▍        | 42/285 [00:53<04:13,  1.04s/it]Loading train:  15%|█▌        | 43/285 [00:54<04:16,  1.06s/it]Loading train:  15%|█▌        | 44/285 [00:55<04:16,  1.06s/it]Loading train:  16%|█▌        | 45/285 [00:56<04:13,  1.05s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:10,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:58<04:06,  1.04s/it]Loading train:  17%|█▋        | 48/285 [00:59<04:10,  1.06s/it]Loading train:  17%|█▋        | 49/285 [01:00<04:05,  1.04s/it]Loading train:  18%|█▊        | 50/285 [01:01<03:59,  1.02s/it]Loading train:  18%|█▊        | 51/285 [01:02<03:49,  1.02it/s]Loading train:  18%|█▊        | 52/285 [01:03<03:44,  1.04it/s]Loading train:  19%|█▊        | 53/285 [01:04<03:37,  1.07it/s]Loading train:  19%|█▉        | 54/285 [01:05<03:35,  1.07it/s]Loading train:  19%|█▉        | 55/285 [01:06<03:34,  1.07it/s]Loading train:  20%|█▉        | 56/285 [01:06<03:35,  1.06it/s]Loading train:  20%|██        | 57/285 [01:07<03:37,  1.05it/s]Loading train:  20%|██        | 58/285 [01:09<03:44,  1.01it/s]Loading train:  21%|██        | 59/285 [01:10<03:44,  1.01it/s]Loading train:  21%|██        | 60/285 [01:11<03:48,  1.02s/it]Loading train:  21%|██▏       | 61/285 [01:12<03:48,  1.02s/it]Loading train:  22%|██▏       | 62/285 [01:13<03:56,  1.06s/it]Loading train:  22%|██▏       | 63/285 [01:14<04:02,  1.09s/it]Loading train:  22%|██▏       | 64/285 [01:16<04:39,  1.27s/it]Loading train:  23%|██▎       | 65/285 [01:17<05:05,  1.39s/it]Loading train:  23%|██▎       | 66/285 [01:19<05:39,  1.55s/it]Loading train:  24%|██▎       | 67/285 [01:21<05:27,  1.50s/it]Loading train:  24%|██▍       | 68/285 [01:22<05:13,  1.44s/it]Loading train:  24%|██▍       | 69/285 [01:23<04:55,  1.37s/it]Loading train:  25%|██▍       | 70/285 [01:24<04:45,  1.33s/it]Loading train:  25%|██▍       | 71/285 [01:26<04:34,  1.28s/it]Loading train:  25%|██▌       | 72/285 [01:27<04:31,  1.27s/it]Loading train:  26%|██▌       | 73/285 [01:28<04:35,  1.30s/it]Loading train:  26%|██▌       | 74/285 [01:29<04:34,  1.30s/it]Loading train:  26%|██▋       | 75/285 [01:31<04:28,  1.28s/it]Loading train:  27%|██▋       | 76/285 [01:32<04:34,  1.31s/it]Loading train:  27%|██▋       | 77/285 [01:33<04:31,  1.31s/it]Loading train:  27%|██▋       | 78/285 [01:35<04:39,  1.35s/it]Loading train:  28%|██▊       | 79/285 [01:36<04:27,  1.30s/it]Loading train:  28%|██▊       | 80/285 [01:37<04:25,  1.29s/it]Loading train:  28%|██▊       | 81/285 [01:39<04:42,  1.39s/it]Loading train:  29%|██▉       | 82/285 [01:40<04:30,  1.33s/it]Loading train:  29%|██▉       | 83/285 [01:41<04:26,  1.32s/it]Loading train:  29%|██▉       | 84/285 [01:43<04:42,  1.40s/it]Loading train:  30%|██▉       | 85/285 [01:44<04:38,  1.39s/it]Loading train:  30%|███       | 86/285 [01:46<04:41,  1.41s/it]Loading train:  31%|███       | 87/285 [01:47<04:46,  1.44s/it]Loading train:  31%|███       | 88/285 [01:49<04:33,  1.39s/it]Loading train:  31%|███       | 89/285 [01:50<04:47,  1.47s/it]Loading train:  32%|███▏      | 90/285 [01:52<04:52,  1.50s/it]Loading train:  32%|███▏      | 91/285 [01:53<04:45,  1.47s/it]Loading train:  32%|███▏      | 92/285 [01:55<04:45,  1.48s/it]Loading train:  33%|███▎      | 93/285 [01:56<04:32,  1.42s/it]Loading train:  33%|███▎      | 94/285 [01:57<04:22,  1.38s/it]Loading train:  33%|███▎      | 95/285 [01:59<04:24,  1.39s/it]Loading train:  34%|███▎      | 96/285 [02:00<04:25,  1.40s/it]Loading train:  34%|███▍      | 97/285 [02:01<04:20,  1.39s/it]Loading train:  34%|███▍      | 98/285 [02:03<04:24,  1.41s/it]Loading train:  35%|███▍      | 99/285 [02:04<04:16,  1.38s/it]Loading train:  35%|███▌      | 100/285 [02:06<04:19,  1.40s/it]Loading train:  35%|███▌      | 101/285 [02:07<04:15,  1.39s/it]Loading train:  36%|███▌      | 102/285 [02:08<04:09,  1.36s/it]Loading train:  36%|███▌      | 103/285 [02:10<04:07,  1.36s/it]Loading train:  36%|███▋      | 104/285 [02:11<04:00,  1.33s/it]Loading train:  37%|███▋      | 105/285 [02:13<04:09,  1.38s/it]Loading train:  37%|███▋      | 106/285 [02:14<04:05,  1.37s/it]Loading train:  38%|███▊      | 107/285 [02:15<04:04,  1.37s/it]Loading train:  38%|███▊      | 108/285 [02:17<03:57,  1.34s/it]Loading train:  38%|███▊      | 109/285 [02:18<03:57,  1.35s/it]Loading train:  39%|███▊      | 110/285 [02:19<03:52,  1.33s/it]Loading train:  39%|███▉      | 111/285 [02:20<03:51,  1.33s/it]Loading train:  39%|███▉      | 112/285 [02:22<03:46,  1.31s/it]Loading train:  40%|███▉      | 113/285 [02:23<03:41,  1.29s/it]Loading train:  40%|████      | 114/285 [02:24<03:43,  1.31s/it]Loading train:  40%|████      | 115/285 [02:26<03:45,  1.33s/it]Loading train:  41%|████      | 116/285 [02:27<03:49,  1.36s/it]Loading train:  41%|████      | 117/285 [02:29<03:51,  1.38s/it]Loading train:  41%|████▏     | 118/285 [02:30<03:49,  1.37s/it]Loading train:  42%|████▏     | 119/285 [02:32<04:00,  1.45s/it]Loading train:  42%|████▏     | 120/285 [02:33<03:48,  1.39s/it]Loading train:  42%|████▏     | 121/285 [02:34<03:54,  1.43s/it]Loading train:  43%|████▎     | 122/285 [02:36<04:01,  1.48s/it]Loading train:  43%|████▎     | 123/285 [02:37<03:58,  1.47s/it]Loading train:  44%|████▎     | 124/285 [02:39<03:42,  1.38s/it]Loading train:  44%|████▍     | 125/285 [02:40<03:29,  1.31s/it]Loading train:  44%|████▍     | 126/285 [02:41<03:16,  1.24s/it]Loading train:  45%|████▍     | 127/285 [02:42<03:09,  1.20s/it]Loading train:  45%|████▍     | 128/285 [02:43<03:07,  1.19s/it]Loading train:  45%|████▌     | 129/285 [02:44<03:04,  1.18s/it]Loading train:  46%|████▌     | 130/285 [02:45<03:02,  1.18s/it]Loading train:  46%|████▌     | 131/285 [02:47<03:04,  1.20s/it]Loading train:  46%|████▋     | 132/285 [02:48<03:04,  1.21s/it]Loading train:  47%|████▋     | 133/285 [02:49<02:58,  1.17s/it]Loading train:  47%|████▋     | 134/285 [02:50<02:56,  1.17s/it]Loading train:  47%|████▋     | 135/285 [02:51<02:59,  1.20s/it]Loading train:  48%|████▊     | 136/285 [02:53<02:56,  1.18s/it]Loading train:  48%|████▊     | 137/285 [02:54<02:56,  1.19s/it]Loading train:  48%|████▊     | 138/285 [02:55<02:58,  1.22s/it]Loading train:  49%|████▉     | 139/285 [02:56<02:58,  1.22s/it]Loading train:  49%|████▉     | 140/285 [02:57<02:50,  1.18s/it]Loading train:  49%|████▉     | 141/285 [02:58<02:49,  1.18s/it]Loading train:  50%|████▉     | 142/285 [03:00<02:48,  1.18s/it]Loading train:  50%|█████     | 143/285 [03:01<02:44,  1.16s/it]Loading train:  51%|█████     | 144/285 [03:02<02:41,  1.15s/it]Loading train:  51%|█████     | 145/285 [03:03<02:41,  1.15s/it]Loading train:  51%|█████     | 146/285 [03:04<02:38,  1.14s/it]Loading train:  52%|█████▏    | 147/285 [03:05<02:44,  1.19s/it]Loading train:  52%|█████▏    | 148/285 [03:07<02:37,  1.15s/it]Loading train:  52%|█████▏    | 149/285 [03:08<02:48,  1.24s/it]Loading train:  53%|█████▎    | 150/285 [03:09<02:45,  1.23s/it]Loading train:  53%|█████▎    | 151/285 [03:10<02:39,  1.19s/it]Loading train:  53%|█████▎    | 152/285 [03:11<02:32,  1.15s/it]Loading train:  54%|█████▎    | 153/285 [03:12<02:27,  1.12s/it]Loading train:  54%|█████▍    | 154/285 [03:13<02:18,  1.06s/it]Loading train:  54%|█████▍    | 155/285 [03:14<02:11,  1.01s/it]Loading train:  55%|█████▍    | 156/285 [03:15<02:10,  1.01s/it]Loading train:  55%|█████▌    | 157/285 [03:16<02:04,  1.03it/s]Loading train:  55%|█████▌    | 158/285 [03:17<02:01,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [03:18<01:56,  1.08it/s]Loading train:  56%|█████▌    | 160/285 [03:19<01:56,  1.08it/s]Loading train:  56%|█████▋    | 161/285 [03:20<01:55,  1.08it/s]Loading train:  57%|█████▋    | 162/285 [03:21<01:52,  1.10it/s]Loading train:  57%|█████▋    | 163/285 [03:22<01:51,  1.10it/s]Loading train:  58%|█████▊    | 164/285 [03:22<01:48,  1.12it/s]Loading train:  58%|█████▊    | 165/285 [03:23<01:46,  1.13it/s]Loading train:  58%|█████▊    | 166/285 [03:24<01:46,  1.11it/s]Loading train:  59%|█████▊    | 167/285 [03:25<01:44,  1.13it/s]Loading train:  59%|█████▉    | 168/285 [03:26<01:41,  1.15it/s]Loading train:  59%|█████▉    | 169/285 [03:27<01:41,  1.14it/s]Loading train:  60%|█████▉    | 170/285 [03:28<01:39,  1.15it/s]Loading train:  60%|██████    | 171/285 [03:28<01:37,  1.16it/s]Loading train:  60%|██████    | 172/285 [03:29<01:37,  1.15it/s]Loading train:  61%|██████    | 173/285 [03:30<01:37,  1.15it/s]Loading train:  61%|██████    | 174/285 [03:31<01:35,  1.16it/s]Loading train:  61%|██████▏   | 175/285 [03:32<01:38,  1.11it/s]Loading train:  62%|██████▏   | 176/285 [03:33<01:37,  1.12it/s]Loading train:  62%|██████▏   | 177/285 [03:34<01:39,  1.08it/s]Loading train:  62%|██████▏   | 178/285 [03:35<01:38,  1.08it/s]Loading train:  63%|██████▎   | 179/285 [03:36<01:38,  1.07it/s]Loading train:  63%|██████▎   | 180/285 [03:37<01:36,  1.09it/s]Loading train:  64%|██████▎   | 181/285 [03:37<01:33,  1.12it/s]Loading train:  64%|██████▍   | 182/285 [03:38<01:31,  1.13it/s]Loading train:  64%|██████▍   | 183/285 [03:39<01:27,  1.17it/s]Loading train:  65%|██████▍   | 184/285 [03:40<01:24,  1.19it/s]Loading train:  65%|██████▍   | 185/285 [03:41<01:24,  1.19it/s]Loading train:  65%|██████▌   | 186/285 [03:42<01:27,  1.13it/s]Loading train:  66%|██████▌   | 187/285 [03:43<01:26,  1.13it/s]Loading train:  66%|██████▌   | 188/285 [03:44<01:25,  1.14it/s]Loading train:  66%|██████▋   | 189/285 [03:44<01:25,  1.12it/s]Loading train:  67%|██████▋   | 190/285 [03:45<01:22,  1.15it/s]Loading train:  67%|██████▋   | 191/285 [03:46<01:19,  1.18it/s]Loading train:  67%|██████▋   | 192/285 [03:47<01:21,  1.14it/s]Loading train:  68%|██████▊   | 193/285 [03:48<01:22,  1.12it/s]Loading train:  68%|██████▊   | 194/285 [03:49<01:22,  1.10it/s]Loading train:  68%|██████▊   | 195/285 [03:50<01:21,  1.10it/s]Loading train:  69%|██████▉   | 196/285 [03:51<01:24,  1.06it/s]Loading train:  69%|██████▉   | 197/285 [03:52<01:27,  1.01it/s]Loading train:  69%|██████▉   | 198/285 [03:53<01:25,  1.02it/s]Loading train:  70%|██████▉   | 199/285 [03:54<01:22,  1.04it/s]Loading train:  70%|███████   | 200/285 [03:55<01:19,  1.06it/s]Loading train:  71%|███████   | 201/285 [03:56<01:19,  1.05it/s]Loading train:  71%|███████   | 202/285 [03:57<01:17,  1.08it/s]Loading train:  71%|███████   | 203/285 [03:58<01:19,  1.03it/s]Loading train:  72%|███████▏  | 204/285 [03:59<01:17,  1.04it/s]Loading train:  72%|███████▏  | 205/285 [03:59<01:16,  1.05it/s]Loading train:  72%|███████▏  | 206/285 [04:00<01:15,  1.05it/s]Loading train:  73%|███████▎  | 207/285 [04:01<01:15,  1.03it/s]Loading train:  73%|███████▎  | 208/285 [04:02<01:13,  1.05it/s]Loading train:  73%|███████▎  | 209/285 [04:03<01:11,  1.06it/s]Loading train:  74%|███████▎  | 210/285 [04:04<01:14,  1.01it/s]Loading train:  74%|███████▍  | 211/285 [04:05<01:11,  1.03it/s]Loading train:  74%|███████▍  | 212/285 [04:06<01:11,  1.03it/s]Loading train:  75%|███████▍  | 213/285 [04:07<01:10,  1.02it/s]Loading train:  75%|███████▌  | 214/285 [04:08<01:08,  1.03it/s]Loading train:  75%|███████▌  | 215/285 [04:09<01:06,  1.05it/s]Loading train:  76%|███████▌  | 216/285 [04:10<01:04,  1.07it/s]Loading train:  76%|███████▌  | 217/285 [04:11<01:01,  1.10it/s]Loading train:  76%|███████▋  | 218/285 [04:12<01:03,  1.06it/s]Loading train:  77%|███████▋  | 219/285 [04:13<01:00,  1.09it/s]Loading train:  77%|███████▋  | 220/285 [04:14<00:58,  1.11it/s]Loading train:  78%|███████▊  | 221/285 [04:15<00:58,  1.10it/s]Loading train:  78%|███████▊  | 222/285 [04:16<01:02,  1.01it/s]Loading train:  78%|███████▊  | 223/285 [04:17<01:01,  1.01it/s]Loading train:  79%|███████▊  | 224/285 [04:18<00:58,  1.04it/s]Loading train:  79%|███████▉  | 225/285 [04:18<00:56,  1.06it/s]Loading train:  79%|███████▉  | 226/285 [04:19<00:54,  1.09it/s]Loading train:  80%|███████▉  | 227/285 [04:20<00:54,  1.07it/s]Loading train:  80%|████████  | 228/285 [04:21<00:54,  1.05it/s]Loading train:  80%|████████  | 229/285 [04:22<00:52,  1.07it/s]Loading train:  81%|████████  | 230/285 [04:23<00:51,  1.08it/s]Loading train:  81%|████████  | 231/285 [04:24<00:49,  1.10it/s]Loading train:  81%|████████▏ | 232/285 [04:25<00:52,  1.01it/s]Loading train:  82%|████████▏ | 233/285 [04:26<00:53,  1.03s/it]Loading train:  82%|████████▏ | 234/285 [04:27<00:52,  1.04s/it]Loading train:  82%|████████▏ | 235/285 [04:28<00:52,  1.05s/it]Loading train:  83%|████████▎ | 236/285 [04:30<00:51,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [04:31<00:50,  1.05s/it]Loading train:  84%|████████▎ | 238/285 [04:32<00:49,  1.05s/it]Loading train:  84%|████████▍ | 239/285 [04:33<00:46,  1.02s/it]Loading train:  84%|████████▍ | 240/285 [04:34<00:47,  1.06s/it]Loading train:  85%|████████▍ | 241/285 [04:35<00:45,  1.04s/it]Loading train:  85%|████████▍ | 242/285 [04:36<00:44,  1.05s/it]Loading train:  85%|████████▌ | 243/285 [04:37<00:44,  1.05s/it]Loading train:  86%|████████▌ | 244/285 [04:38<00:42,  1.03s/it]Loading train:  86%|████████▌ | 245/285 [04:39<00:41,  1.04s/it]Loading train:  86%|████████▋ | 246/285 [04:40<00:41,  1.06s/it]Loading train:  87%|████████▋ | 247/285 [04:41<00:40,  1.06s/it]Loading train:  87%|████████▋ | 248/285 [04:42<00:39,  1.06s/it]Loading train:  87%|████████▋ | 249/285 [04:43<00:37,  1.03s/it]Loading train:  88%|████████▊ | 250/285 [04:44<00:34,  1.02it/s]Loading train:  88%|████████▊ | 251/285 [04:45<00:32,  1.05it/s]Loading train:  88%|████████▊ | 252/285 [04:46<00:31,  1.04it/s]Loading train:  89%|████████▉ | 253/285 [04:47<00:30,  1.04it/s]Loading train:  89%|████████▉ | 254/285 [04:48<00:29,  1.07it/s]Loading train:  89%|████████▉ | 255/285 [04:48<00:26,  1.11it/s]Loading train:  90%|████████▉ | 256/285 [04:49<00:26,  1.08it/s]Loading train:  90%|█████████ | 257/285 [04:50<00:25,  1.10it/s]Loading train:  91%|█████████ | 258/285 [04:51<00:24,  1.11it/s]Loading train:  91%|█████████ | 259/285 [04:52<00:23,  1.10it/s]Loading train:  91%|█████████ | 260/285 [04:53<00:22,  1.11it/s]Loading train:  92%|█████████▏| 261/285 [04:54<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [04:55<00:21,  1.09it/s]Loading train:  92%|█████████▏| 263/285 [04:56<00:20,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [04:57<00:18,  1.12it/s]Loading train:  93%|█████████▎| 265/285 [04:58<00:18,  1.10it/s]Loading train:  93%|█████████▎| 266/285 [04:58<00:17,  1.08it/s]Loading train:  94%|█████████▎| 267/285 [04:59<00:16,  1.10it/s]Loading train:  94%|█████████▍| 268/285 [05:00<00:16,  1.04it/s]Loading train:  94%|█████████▍| 269/285 [05:02<00:16,  1.02s/it]Loading train:  95%|█████████▍| 270/285 [05:03<00:15,  1.06s/it]Loading train:  95%|█████████▌| 271/285 [05:04<00:15,  1.07s/it]Loading train:  95%|█████████▌| 272/285 [05:05<00:13,  1.07s/it]Loading train:  96%|█████████▌| 273/285 [05:06<00:12,  1.08s/it]Loading train:  96%|█████████▌| 274/285 [05:07<00:12,  1.10s/it]Loading train:  96%|█████████▋| 275/285 [05:08<00:10,  1.09s/it]Loading train:  97%|█████████▋| 276/285 [05:09<00:09,  1.08s/it]Loading train:  97%|█████████▋| 277/285 [05:10<00:08,  1.06s/it]Loading train:  98%|█████████▊| 278/285 [05:11<00:07,  1.07s/it]Loading train:  98%|█████████▊| 279/285 [05:12<00:06,  1.07s/it]Loading train:  98%|█████████▊| 280/285 [05:14<00:05,  1.06s/it]Loading train:  99%|█████████▊| 281/285 [05:15<00:04,  1.09s/it]Loading train:  99%|█████████▉| 282/285 [05:16<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [05:17<00:02,  1.06s/it]Loading train: 100%|█████████▉| 284/285 [05:18<00:01,  1.07s/it]Loading train: 100%|██████████| 285/285 [05:19<00:00,  1.08s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:01, 186.49it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:01, 198.77it/s]concatenating: train:  22%|██▏       | 64/285 [00:00<00:01, 200.74it/s]concatenating: train:  31%|███       | 89/285 [00:00<00:00, 212.70it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 212.71it/s]concatenating: train:  47%|████▋     | 135/285 [00:00<00:00, 214.88it/s]concatenating: train:  56%|█████▌    | 160/285 [00:00<00:00, 222.34it/s]concatenating: train:  64%|██████▍   | 182/285 [00:00<00:00, 221.54it/s]concatenating: train:  72%|███████▏  | 205/285 [00:00<00:00, 223.36it/s]concatenating: train:  82%|████████▏ | 233/285 [00:01<00:00, 236.58it/s]concatenating: train:  91%|█████████ | 260/285 [00:01<00:00, 241.67it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 231.62it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.44s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 196.58it/s]
Epoch 00039: val_mDice did not improve from 0.48291
Restoring model weights from the end of the best epoch
Epoch 00039: early stopping
{'val_loss': [1273.1843798274085, 1356.5179584821065, 1153.093192299207, 1319.4086233774822, 1407.3073373408545, 1427.6613744724364, 1571.2189749308995, 1576.5816411688215, 1422.9390552327745, 1655.769026517868, 1683.1624798888251, 1728.38187228498, 1714.6839636393956, 1753.16236274583, 1685.3637307655245, 1753.649313444183, 1848.706758260727, 1889.6779393127986, 1718.777553149632, 1794.2719815004439, 1800.7634180613927, 1969.411734342575, 1911.8445249171484, 1919.9286846887499, 1877.2415173110508, 1964.735301471892, 2098.200881833122, 2079.2039806161606, 1915.8175060976118, 1949.0328596773602, 1983.2171705336798, 1889.8505507423765, 2118.4340420223416, 2091.591386085465, 2108.8645710547767, 2151.4439045247577, 1930.473297482445, 2133.5439077842802, 2143.239445567131], 'val_acc': [0.9340497397241139, 0.9363180342174712, 0.9393516268048968, 0.9384459768022809, 0.9384693645295643, 0.9386968272072929, 0.938161123366583, 0.9381568658919561, 0.939232587814331, 0.938745759782337, 0.9383354527609689, 0.9384332611447289, 0.9391624246324811, 0.9393622421082997, 0.9383311952863421, 0.9390242553892589, 0.9382419018518358, 0.9374425751822335, 0.9398958455948603, 0.9386267207917713, 0.9388052508944557, 0.9381016322544643, 0.9388328960963658, 0.939173039935884, 0.9392432031177339, 0.9383758703867594, 0.9374043146769205, 0.9373086634136382, 0.9392814636230469, 0.9389880952380952, 0.939451535542806, 0.9400722753433954, 0.938856283823649, 0.939270848319644, 0.9384800365992955, 0.9382738045283726, 0.938849925994873, 0.9391092913491386, 0.9382844198317755], 'val_mDice': [0.3811917918778601, 0.4050938845390365, 0.4578112986470972, 0.44202619702333495, 0.4521775199543862, 0.45504668745256605, 0.4426384699486551, 0.45682077287208467, 0.48291011225609554, 0.4520621184437048, 0.45510718581222354, 0.4505252721054213, 0.46530364719884737, 0.4608843395752566, 0.46672777600941207, 0.46714491539058234, 0.4606334666411082, 0.45519005400793894, 0.4743383853208451, 0.47621748312598183, 0.46465943860156195, 0.4585931973443145, 0.46553989357891534, 0.4646975806071645, 0.47277042198748814, 0.4585613796398753, 0.45223313711938407, 0.4553792710815157, 0.46971274025383447, 0.468811699144897, 0.4706688274939855, 0.477152152075654, 0.4651382938027382, 0.46487328179535414, 0.45862960034892675, 0.4624887449400766, 0.47894274975572315, 0.46510329594214755, 0.4595164456183002], 'loss': [1429.9968136989107, 659.579872809418, 542.1507410093932, 485.569262658835, 444.5318313931049, 414.72231746781694, 392.7421610008344, 373.9243419228755, 360.4920614348089, 348.07436168899375, 338.37833722689857, 328.23342836084726, 319.40970475222764, 312.24379918348683, 307.014938792811, 302.2033786306681, 295.51280960486025, 290.7217792858847, 285.61443138674133, 281.74277627980615, 279.0730999839405, 274.51975516912586, 269.5989554268973, 266.615069505358, 262.7974363422265, 262.894064108071, 257.72157158161235, 256.1726156587382, 253.41696245536562, 249.96991586915004, 247.44343721924062, 245.1941350433485, 243.77775814658716, 241.06205729213735, 239.19724046138296, 237.70943023640456, 236.40518868606122, 233.94354024474873, 231.47795351498016], 'acc': [0.9023314650655827, 0.9171794750843523, 0.9218396897349993, 0.9249198314356211, 0.9277566765598969, 0.9291002218126216, 0.9303378872221459, 0.931149817349618, 0.9322869091657217, 0.9325400347973493, 0.9329942933437979, 0.933700493806034, 0.9341567774969924, 0.9342612837214495, 0.9345176984217209, 0.9342625989421199, 0.9342179935470767, 0.9344560737345107, 0.9348786622889129, 0.9350683133979512, 0.934952207238591, 0.9350895688371528, 0.9351181052934004, 0.9355587426789216, 0.9356648866349341, 0.9353181658417176, 0.9355641858573591, 0.9359149058384083, 0.935701977983706, 0.9359100857910817, 0.9360957116043727, 0.936598645921431, 0.9366739751264405, 0.9368267851067067, 0.936639439239193, 0.9366627209835116, 0.9362121212452575, 0.9363449195434713, 0.9367765878835854], 'mDice': [0.34134987611427736, 0.5598788605229069, 0.6276896788431818, 0.6629302717367532, 0.6896079193311595, 0.7098567973953785, 0.7243434982261194, 0.737035709480479, 0.7459384835430577, 0.7550074499605339, 0.7611493476902976, 0.7681370256768502, 0.7742385328884688, 0.7792513857164525, 0.7828576393915275, 0.7865025133256488, 0.7911005505987829, 0.7939366933718935, 0.7976603097761208, 0.8005427364579556, 0.8024018096836495, 0.8051169598426621, 0.8090437442575642, 0.810916842259675, 0.8135449416218683, 0.8136100435454606, 0.8173530834107724, 0.8182339996116709, 0.8202918140052118, 0.8226756511084808, 0.8245162923073571, 0.8261761118709777, 0.8270184876074422, 0.8290136013965007, 0.830351965078527, 0.831587878775684, 0.8323202607993425, 0.8339720899621622, 0.8359765074881419]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 60)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 120)  64920       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 120)    0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 7, 7, 120)    0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 7, 7, 240)    259440      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 7, 7, 240)    960         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 7, 7, 240)    0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 7, 7, 240)    518640      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 7, 7, 240)    960         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 7, 7, 240)    0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 7, 7, 240)    0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 120)  115320      dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 14, 14, 240)  0           conv2d_transpose_1[0][0]         
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 14, 120)  259320      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 14, 120)  480         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 14, 120)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 14, 120)  129720      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 14, 120)  480         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 14, 120)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 14, 120)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 60)   28860       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 120)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 60)   64860       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 28, 60)   240         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 28, 60)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 60)   32460       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 28, 60)   240         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 28, 60)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 28, 60)   0           activation_12[0][0]              2019-07-01 01:32:32.607446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-01 01:32:32.607542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-01 01:32:32.607557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-01 01:32:32.607566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-01 01:32:32.608009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 56, 56, 30)   7230        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 56, 60)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 56, 30)   16230       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 56, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 56, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 56, 30)   8130        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 56, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 56, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 56, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 56, 13)   403         dropout_7[0][0]                  
==================================================================================================
Total params: 1,697,683
Trainable params: 1,695,043
Non-trainable params: 2,640
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [2.84556655e+01 1.40109011e+01 3.28839521e+01 4.08704613e+00
 1.18795059e+01 3.09772677e+00 3.70666155e+01 4.93844078e+01
 3.77168295e+01 5.80852460e+00 1.28966869e+02 8.44275505e+01
 8.52866433e-02]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 24s - loss: 1149.7445 - acc: 0.9303 - mDice: 0.3893 - val_loss: 1018.1384 - val_acc: 0.9568 - val_mDice: 0.4491

Epoch 00001: val_mDice improved from -inf to 0.44906, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 563.1674 - acc: 0.9471 - mDice: 0.6098 - val_loss: 1107.5516 - val_acc: 0.9588 - val_mDice: 0.4778

Epoch 00002: val_mDice improved from 0.44906 to 0.47781, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 16s - loss: 475.5038 - acc: 0.9516 - mDice: 0.6657 - val_loss: 1190.1618 - val_acc: 0.9589 - val_mDice: 0.4926

Epoch 00003: val_mDice improved from 0.47781 to 0.49264, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 16s - loss: 431.2018 - acc: 0.9538 - mDice: 0.6954 - val_loss: 1210.6615 - val_acc: 0.9589 - val_mDice: 0.4952

Epoch 00004: val_mDice improved from 0.49264 to 0.49524, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 17s - loss: 402.4620 - acc: 0.9553 - mDice: 0.7148 - val_loss: 1322.5209 - val_acc: 0.9585 - val_mDice: 0.4993

Epoch 00005: val_mDice improved from 0.49524 to 0.49934, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 381.5175 - acc: 0.9563 - mDice: 0.7293 - val_loss: 1281.4080 - val_acc: 0.9590 - val_mDice: 0.5144

Epoch 00006: val_mDice improved from 0.49934 to 0.51438, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 16s - loss: 363.5562 - acc: 0.9572 - mDice: 0.7414 - val_loss: 1246.6201 - val_acc: 0.9589 - val_mDice: 0.5258

Epoch 00007: val_mDice improved from 0.51438 to 0.52585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 16s - loss: 353.1914 - acc: 0.9577 - mDice: 0.7494 - val_loss: 1436.8965 - val_acc: 0.9594 - val_mDice: 0.5048

Epoch 00008: val_mDice did not improve from 0.52585
Epoch 9/300
 - 16s - loss: 342.0396 - acc: 0.9582 - mDice: 0.7569 - val_loss: 1284.6917 - val_acc: 0.9598 - val_mDice: 0.5300

Epoch 00009: val_mDice improved from 0.52585 to 0.52996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 17s - loss: 332.1336 - acc: 0.9585 - mDice: 0.7639 - val_loss: 1412.1684 - val_acc: 0.9600 - val_mDice: 0.5148

Epoch 00010: val_mDice did not improve from 0.52996
Epoch 11/300
 - 17s - loss: 324.5400 - acc: 0.9589 - mDice: 0.7689 - val_loss: 1385.6521 - val_acc: 0.9606 - val_mDice: 0.5290

Epoch 00011: val_mDice did not improve from 0.52996
Epoch 12/300
 - 16s - loss: 317.0875 - acc: 0.9596 - mDice: 0.7744 - val_loss: 1389.0407 - val_acc: 0.9601 - val_mDice: 0.5270

Epoch 00012: val_mDice did not improve from 0.52996
Epoch 13/300
 - 17s - loss: 309.0152 - acc: 0.9600 - mDice: 0.7800 - val_loss: 1416.8704 - val_acc: 0.9603 - val_mDice: 0.5282

Epoch 00013: val_mDice did not improve from 0.52996
Epoch 14/300
 - 16s - loss: 303.3684 - acc: 0.9603 - mDice: 0.7838 - val_loss: 1381.6463 - val_acc: 0.9602 - val_mDice: 0.5397

Epoch 00014: val_mDice improved from 0.52996 to 0.53965, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 16s - loss: 299.3476 - acc: 0.9605 - mDice: 0.7867 - val_loss: 1537.5966 - val_acc: 0.9599 - val_mDice: 0.5187

Epoch 00015: val_mDice did not improve from 0.53965
Epoch 16/300
 - 17s - loss: 293.8401 - acc: 0.9609 - mDice: 0.7902 - val_loss: 1400.8161 - val_acc: 0.9601 - val_mDice: 0.5423

Epoch 00016: val_mDice improved from 0.53965 to 0.54234, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 16s - loss: 288.7432 - acc: 0.9613 - mDice: 0.7942 - val_loss: 1543.4702 - val_acc: 0.9603 - val_mDice: 0.5296

Epoch 00017: val_mDice did not improve from 0.54234
Epoch 18/300
 - 16s - loss: 286.1703 - acc: 0.9615 - mDice: 0.7959 - val_loss: 1568.9768 - val_acc: 0.9600 - val_mDice: 0.5319

Epoch 00018: val_mDice did not improve from 0.54234
Epoch 19/300
 - 16s - loss: 281.0361 - acc: 0.9620 - mDice: 0.7997 - val_loss: 1466.3465 - val_acc: 0.9603 - val_mDice: 0.5379

Epoch 00019: val_mDice did not improve from 0.54234
Epoch 20/300
 - 16s - loss: 277.6958 - acc: 0.9621 - mDice: 0.8021 - val_loss: 1512.9917 - val_acc: 0.9600 - val_mDice: 0.5338

Epoch 00020: val_mDice did not improve from 0.54234
Epoch 21/300
 - 16s - loss: 274.4112 - acc: 0.9622 - mDice: 0.8047 - val_loss: 1518.7571 - val_acc: 0.9604 - val_mDice: 0.5357

Epoch 00021: val_mDice did not improve from 0.54234
Epoch 22/300
 - 16s - loss: 270.8673 - acc: 0.9625 - mDice: 0.8068 - val_loss: 1630.6564 - val_acc: 0.9600 - val_mDice: 0.5319

Epoch 00022: val_mDice did not improve from 0.54234
Epoch 23/300
 - 16s - loss: 268.2869 - acc: 0.9627 - mDice: 0.8088 - val_loss: 1604.0741 - val_acc: 0.9600 - val_mDice: 0.5317

Epoch 00023: val_mDice did not improve from 0.54234
Epoch 24/300
 - 16s - loss: 265.2005 - acc: 0.9629 - mDice: 0.8109 - val_loss: 1489.8345 - val_acc: 0.9603 - val_mDice: 0.5413

Epoch 00024: val_mDice did not improve from 0.54234
Epoch 25/300
 - 16s - loss: 262.4588 - acc: 0.9631 - mDice: 0.8127 - val_loss: 1566.8093 - val_acc: 0.9599 - val_mDice: 0.5353

Epoch 00025: val_mDice did not improve from 0.54234
Epoch 26/300
 - 16s - loss: 259.8651 - acc: 0.9633 - mDice: 0.8147 - val_loss: 1648.8904 - val_acc: 0.9600 - val_mDice: 0.5267

Epoch 00026: val_mDice did not improve from 0.54234
Epoch 27/300
 - 16s - loss: 259.1140 - acc: 0.9632 - mDice: 0.8153 - val_loss: 1652.0377 - val_acc: 0.9599 - val_mDice: 0.5277

Epoch 00027: val_mDice did not improve from 0.54234
Epoch 28/300
 - 16s - loss: 255.4115 - acc: 0.9633 - mDice: 0.8177 - val_loss: 1584.1965 - val_acc: 0.9597 - val_mDice: 0.5388

Epoch 00028: val_mDice did not improve from 0.54234
Epoch 29/300
 - 16s - loss: 253.1718 - acc: 0.9635 - mDice: 0.8194 - val_loss: 1544.6836 - val_acc: 0.9600 - val_mDice: 0.5380

Epoch 00029: val_mDice did not improve from 0.54234
Epoch 30/300
 - 16s - loss: 252.2006 - acc: 0.9638 - mDice: 0.8202 - val_loss: 1685.7428 - val_acc: 0.9593 - val_mDice: 0.5309

Epoch 00030: val_mDice did not improve from 0.54234
Epoch 31/300
 - 16s - loss: 248.4002 - acc: 0.9639 - mDice: 0.8226 - val_loss: 1743.0433 - val_acc: 0.9600 - val_mDice: 0.5207

Epoch 00031: val_mDice did not improve from 0.54234
Epoch 32/300
 - 16s - loss: 247.1782 - acc: 0.9639 - mDice: 0.8239 - val_loss: 1584.0111 - val_acc: 0.9599 - val_mDice: 0.5442

Epoch 00032: val_mDice improved from 0.54234 to 0.54421, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 33/300
 - 16s - loss: 244.7085 - acc: 0.9640 - mDice: 0.8257 - val_loss: 1559.6228 - val_acc: 0.9598 - val_mDice: 0.5457

Epoch 00033: val_mDice improved from 0.54421 to 0.54575, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 16s - loss: 243.7735 - acc: 0.9640 - mDice: 0.8260 - val_loss: 1518.9543 - val_acc: 0.9595 - val_mDice: 0.5516

Epoch 00034: val_mDice improved from 0.54575 to 0.55163, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 35/300
 - 16s - loss: 241.8823 - acc: 0.9644 - mDice: 0.8276 - val_loss: 1531.5511 - val_acc: 0.9601 - val_mDice: 0.5496

Epoch 00035: val_mDice did not improve from 0.55163
Epoch 36/300
 - 16s - loss: 239.7920 - acc: 0.9644 - mDice: 0.8290 - val_loss: 1688.0966 - val_acc: 0.9598 - val_mDice: 0.5347

Epoch 00036: val_mDice did not improve from 0.55163
Epoch 37/300
 - 16s - loss: 238.0449 - acc: 0.9645 - mDice: 0.8304 - val_loss: 1669.7538 - val_acc: 0.9592 - val_mDice: 0.5361

Epoch 00037: val_mDice did not improve from 0.55163
Epoch 38/300
 - 17s - loss: 237.2014 - acc: 0.9647 - mDice: 0.8311 - val_loss: 1574.2153 - val_acc: 0.9596 - val_mDice: 0.5430

Epoch 00038: val_mDice did not improve from 0.55163
Epoch 39/300
 - 16s - loss: 235.6894 - acc: 0.9648 - mDice: 0.8319 - val_loss: 1842.0149 - val_acc: 0.9595 - val_mDice: 0.5210

Epoch 00039: val_mDice did not improve from 0.55163
Epoch 40/300
 - 16s - loss: 234.4485 - acc: 0.9650 - mDice: 0.8328 - val_loss: 1702.9918 - val_acc: 0.9599 - val_mDice: 0.5320

Epoch 00040: val_mDice did not improve from 0.55163
Epoch 41/300
 - 16s - loss: 233.4275 - acc: 0.9651 - mDice: 0.8338 - val_loss: 1642.0860 - val_acc: 0.9598 - val_mDice: 0.5391

Epoch 00041: val_mDice did not improve from 0.55163
Epoch 42/300
 - 16s - loss: 230.3258 - acc: 0.9652 - mDice: 0.8359 - val_loss: 1738.2392 - val_acc: 0.9595 - val_mDice: 0.5367

Epoch 00042: val_mDice did not improve from 0.55163
Epoch 43/300
 - 16s - loss: 230.2678 - acc: 0.9650 - mDice: 0.8358 - val_loss: 1702.2434 - val_acc: 0.9595 - val_mDice: 0.5389

Epoch 00043: val_mDice did not improve from 0.55163
Epoch 44/300
 - 17s - loss: 228.5900 - acc: 0.9654 - mDice: 0.8373 - val_loss: 1697.0727 - val_acc: 0.9593 - val_mDice: 0.5384

Epoch 00044: val_mDice did not improve from 0.55163
Epoch 45/300
 - 16s - loss: 227.3741 - acc: 0.9655 - mDice: 0.8380 - val_loss: 1623.4756 - val_acc: 0.9601 - val_mDice: 0.5432

Epoch 00045: val_mDice did not improve from 0.55163
Epoch 46/300
 - 16s - loss: 226.3761 - acc: 0.9656 - mDice: 0.8387 - val_loss: 1757.3470 - val_acc: 0.9593 - val_mDice: 0.5362

Epoch 00046: val_mDice did not improve from 0.55163
Epoch 47/300
 - 16s - loss: 225.1446 - acc: 0.9656 - mDice: 0.8395 - val_loss: 1728.3880 - val_acc: 0.9598 - val_mDice: 0.5341

Epoch 00047: val_mDice did not improve from 0.55163
Epoch 48/300
 - 16s - loss: 223.6770 - acc: 0.9657 - mDice: 0.8405 - val_loss: 1666.7339 - val_acc: 0.9599 - val_mDice: 0.5410

Epoch 00048: val_mDice did not improve from 0.55163
Epoch 49/300
 - 16s - loss: 222.2451 - acc: 0.9658 - mDice: 0.8417 - val_loss: 1643.2547 - val_acc: 0.9596 - val_mDice: 0.5433

Epoch 00049: val_mDice did not improve from 0.55163
Epoch 50/300
 - 16s - loss: 222.0420 - acc: 0.9658 - mDice: 0.8420 - val_loss: 1818.4773 - val_acc: 0.9587 - val_mDice: 0.5284

Epoch 00050: val_mDice did not improve from 0.55163
Epoch 51/300
 - 17s - loss: 220.3796 - acc: 0.9660 - mDice: 0.8432 - val_loss: 1679.7899 - val_acc: 0.9595 - val_mDice: 0.5410

Epoch 00051: val_mDice did not improve from 0.55163
Epoch 52/300
 - 16s - loss: 219.9691 - acc: 0.9661 - mDice: 0.8435 - val_loss: 1724.4831 - val_acc: 0.9597 - val_mDice: 0.5374

Epoch 00052: val_mDice did not improve from 0.55163
Epoch 53/300
 - 16s - loss: 217.5522 - acc: 0.9661 - mDice: 0.8448 - val_loss: 1851.2854 - val_acc: 0.9594 - val_mDice: 0.5287

Epoch 00053: val_mDice did not improve from 0.55163
Epoch 54/300
 - 16s - loss: 217.4124 - acc: 0.9661 - mDice: 0.8451 - val_loss: 1610.6402 - val_acc: 0.9605 - val_mDice: 0.5533

Epoch 00054: val_mDice improved from 0.55163 to 0.55335, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 55/300
 - 16s - loss: 216.5252 - acc: 0.9659 - mDice: 0.8457 - val_loss: 1750.7787 - val_acc: 0.9597 - val_mDice: 0.5390

Epoch 00055: val_mDice did not improve from 0.55335
Epoch 56/300
 - 16s - loss: 215.4033 - acc: 0.9662 - mDice: 0.8468 - val_loss: 1759.5088 - val_acc: 0.9591 - val_mDice: 0.5341

Epoch 00056: val_mDice did not improve from 0.55335
Epoch 57/300
 - 17s - loss: 214.1049 - acc: 0.9662 - mDice: 0.8477 - val_loss: 1706.9454 - val_acc: 0.9598 - val_mDice: 0.5477

Epoch 00057: val_mDice did not improve from 0.55335
Epoch 58/300
 - 16s - loss: 213.2047 - acc: 0.9664 - mDice: 0.8482 - val_loss: 1709.4705 - val_acc: 0.9607 - val_mDice: 0.5453

Epoch 00058: val_mDice did not improve from 0.55335
Epoch 59/300
 - 16s - loss: 212.8657 - acc: 0.9666 - mDice: 0.8486 - val_loss: 1734.2703 - val_acc: 0.9596 - val_mDice: 0.5400

Epoch 00059: val_mDice did not improve from 0.55335
Epoch 60/300
 - 17s - loss: 212.0877 - acc: 0.9666 - mDice: 0.8492 - val_loss: 1761.7772 - val_acc: 0.9599 - val_mDice: 0.5400

Epoch 00060: val_mDice did not improve from 0.55335
Epoch 61/300
 - 17s - loss: 210.5236 - acc: 0.9667 - mDice: 0.8501 - val_loss: 1746.5889 - val_acc: 0.9597 - val_mDice: 0.5373

Epoch 00061: val_mDice did not improve from 0.55335
Epoch 62/300
 - 16s - loss: 210.1259 - acc: 0.9668 - mDice: 0.8504 - val_loss: 1634.7519 - val_acc: 0.9602 - val_mDice: 0.5545

Epoch 00062: val_mDice improved from 0.55335 to 0.55448, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 63/300
 - 16s - loss: 209.8755 - acc: 0.9668 - mDice: 0.8508 - val_loss: 1685.8554 - val_acc: 0.9605 - val_mDice: 0.5494

Epoch 00063: val_mDice did not improve from 0.55448
Epoch 64/300
 - 17s - loss: 208.8852 - acc: 0.9669 - mDice: 0.8517 - val_loss: 1716.5025 - val_acc: 0.9602 - val_mDice: 0.5446

Epoch 00064: val_mDice did not improve from 0.55448
Epoch 65/300
 - 16s - loss: 207.4204 - acc: 0.9670 - mDice: 0.8525 - val_loss: 1810.8852 - val_acc: 0.9598 - val_mDice: 0.5372

Epoch 00065: val_mDice did not improve from 0.55448
Epoch 66/300
 - 16s - loss: 206.3736 - acc: 0.9669 - mDice: 0.8531 - val_loss: 1752.3886 - val_acc: 0.9594 - val_mDice: 0.5380

Epoch 00066: val_mDice did not improve from 0.55448
Epoch 67/300
 - 16s - loss: 205.8802 - acc: 0.9670 - mDice: 0.8537 - val_loss: 1657.8358 - val_acc: 0.9607 - val_mDice: 0.5564

Epoch 00067: val_mDice improved from 0.55448 to 0.55639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 68/300
 - 16s - loss: 205.5340 - acc: 0.9669 - mDice: 0.8537 - val_loss: 1774.9524 - val_acc: 0.9602 - val_mDice: 0.5403

Epoch 00068: val_mDice did not improve from 0.55639
Epoch 69/300
 - 16s - loss: 204.7061 - acc: 0.9670 - mDice: 0.8545 - val_loss: 1697.5943 - val_acc: 0.9598 - val_mDice: 0.5467

Epoch 00069: val_mDice did not improve from 0.55639
Epoch 70/300
 - 16s - loss: 204.1252 - acc: 0.9671 - mDice: 0.8549 - val_loss: 1755.5054 - val_acc: 0.9595 - val_mDice: 0.5432

Epoch 00070: val_mDice did not improve from 0.55639
Epoch 71/300
 - 16s - loss: 202.7579 - acc: 0.9671 - mDice: 0.8558 - val_loss: 1839.9728 - val_acc: 0.9594 - val_mDice: 0.5347

Epoch 00071: val_mDice did not improve from 0.55639
Epoch 72/300
 - 16s - loss: 202.3775 - acc: 0.9671 - mDice: 0.8563 - val_loss: 1833.2109 - val_acc: 0.9599 - val_mDice: 0.5392

Epoch 00072: val_mDice did not improve from 0.55639
Epoch 73/300
 - 17s - loss: 202.3729 - acc: 0.9673 - mDice: 0.8561 - val_loss: 1880.5235 - val_acc: 0.9598 - val_mDice: 0.5278

Epoch 00073: val_mDice did not improve from 0.55639
Epoch 74/300
 - 16s - loss: 200.7777 - acc: 0.9675 - mDice: 0.8571 - val_loss: 1832.5711 - val_acc: 0.9601 - val_mDice: 0.5308

Epoch 00074: val_mDice did not improve from 0.55639
Epoch 75/300
 - 16s - loss: 201.3696 - acc: 0.9673 - mDice: 0.8570 - val_loss: 1675.6644 - val_acc: 0.9601 - val_mDice: 0.5406

Epoch 00075: val_mDice did not improve from 0.55639
Epoch 76/300
 - 16s - loss: 200.4498 - acc: 0.9675 - mDice: 0.8577 - val_loss: 1670.7839 - val_acc: 0.9598 - val_mDice: 0.5516

Epoch 00076: val_mDice did not improve from 0.55639
Epoch 77/300
 - 16s - loss: 199.8380 - acc: 0.9676 - mDice: 0.8581 - val_loss: 1827.6077 - val_acc: 0.9599 - val_mDice: 0.5337

Epoch 00077: val_mDice did not improve from 0.55639
Epoch 78/300
 - 17s - loss: 200.1980 - acc: 0.9675 - mDice: 0.8579 - val_loss: 1843.8590 - val_acc: 0.9599 - val_mDice: 0.5357

Epoch 00078: val_mDice did not improve from 0.55639
Epoch 79/300
 - 16s - loss: 198.0419 - acc: 0.9676 - mDice: 0.8594 - val_loss: 1784.2798 - val_acc: 0.9601 - val_mDice: 0.5373

Epoch 00079: val_mDice did not improve from 0.55639
Epoch 80/300
 - 16s - loss: 197.5519 - acc: 0.9678 - mDice: 0.8597 - val_loss: 1870.8212 - val_acc: 0.9597 - val_mDice: 0.5273

Epoch 00080: val_mDice did not improve from 0.55639
Epoch 81/300
 - 17s - loss: 197.3873 - acc: 0.9679 - mDice: 0.8599 - val_loss: 1799.3927 - val_acc: 0.9597 - val_mDice: 0.5345

Epoch 00081: val_mDice did not improve from 0.55639
Epoch 82/300
 - 16s - loss: 196.3507 - acc: 0.9678 - mDice: 0.8606 - val_loss: 1798.4839 - val_acc: 0.9598 - val_mDice: 0.5351

Epoch 00082: val_mDice did not improve from 0.55639
Epoch 83/300
 - 16s - loss: 195.9300 - acc: 0.9679 - mDice: 0.8609 - val_loss: 1802.9412 - val_acc: 0.9600 - val_mDice: 0.5362

Epoch 00083: val_mDice did not improve from 0.55639
Epoch 84/300
 - 16s - loss: 195.7202 - acc: 0.9679 - mDice: 0.8610 - val_loss: 1868.1583 - val_acc: 0.9602 - val_mDice: 0.5305

Epoch 00084: val_mDice did not improve from 0.55639
Epoch 85/300
 - 16s - loss: 194.6431 - acc: 0.9680 - mDice: 0.8621 - val_loss: 1961.3265 - val_acc: 0.9598 - val_mDice: 0.5233

Epoch 00085: val_mDice did not improve from 0.55639
Epoch 86/300
 - 16s - loss: 194.3319 - acc: 0.9679 - mDice: 0.8621 - val_loss: 1793.4376 - val_acc: 0.9595 - val_mDice: 0.5370

Epoch 00086: val_mDice did not improve from 0.55639
Epoch 87/300
 - 16s - loss: 193.4790 - acc: 0.9680 - mDice: 0.8625 - val_loss: 1700.9047 - val_acc: 0.9606 - val_mDice: 0.5535

Epoch 00087: val_mDice did not improve from 0.55639
Epoch 88/300
 - 16s - loss: 194.0553 - acc: 0.9679 - mDice: 0.8623 - val_loss: 1754.6619 - val_acc: 0.9601 - val_mDice: 0.5474

Epoch 00088: val_mDice did not improve from 0.55639
Epoch 89/300
 - 16s - loss: 192.8028 - acc: 0.9682 - mDice: 0.8632 - val_loss: 1825.9633 - val_acc: 0.9604 - val_mDice: 0.5435

Epoch 00089: val_mDice did not improve from 0.55639
Epoch 90/300
 - 16s - loss: 192.5020 - acc: 0.9679 - mDice: 0.8635 - val_loss: 1913.3073 - val_acc: 0.9601 - val_mDice: 0.5329

Epoch 00090: val_mDice did not improve from 0.55639
Epoch 91/300
 - 16s - loss: 192.0034 - acc: 0.9681 - mDice: 0.8636 - val_loss: 1745.4476 - val_acc: 0.9597 - val_mDice: 0.5478

Epoch 00091: val_mDice did not improve from 0.55639
Epoch 92/300
 - 16s - loss: 190.8514 - acc: 0.9681 - mDice: 0.8647 - val_loss: 1850.8939 - val_acc: 0.9603 - val_mDice: 0.5393

Epoch 00092: val_mDice did not improve from 0.55639
Epoch 93/300
 - 16s - loss: 191.1411 - acc: 0.9682 - mDice: 0.8643 - val_loss: 1861.6779 - val_acc: 0.9606 - val_mDice: 0.5321

Epoch 00093: val_mDice did not improve from 0.55639
Epoch 94/300
 - 17s - loss: 190.3984 - acc: 0.9683 - mDice: 0.8651 - val_loss: 1670.9222 - val_acc: 0.9606 - val_mDice: 0.5543

Epoch 00094: val_mDice did not improve from 0.55639
Epoch 95/300
 - 17s - loss: 189.7234 - acc: 0.9683 - mDice: 0.8656 - val_loss: 1825.8950 - val_acc: 0.9604 - val_mDice: 0.5391

Epoch 00095: val_mDice did not improve from 0.55639
Epoch 96/300
 - 16s - loss: 189.4406 - acc: 0.9683 - mDice: 0.8658 - val_loss: 1781.7556 - val_acc: 0.9604 - val_mDice: 0.5473

Epoch 00096: val_mDice did not improve from 0.55639
Epoch 97/300
 - 16s - loss: 189.6365 - acc: 0.9683 - mDice: 0.8655 - val_loss: 1803.8780 - val_acc: 0.9602 - val_mDice: 0.5411

Epoch 00097: val_mDice did not improve from 0.55639
Restoring model weights from the end of the best epoch
Epoch 00097: early stopping
{'val_loss': [1018.1384413735161, 1107.5516186932612, 1190.1618338643505, 1210.6614506044868, 1322.520878797137, 1281.407984898743, 1246.6200544474511, 1436.896485056957, 1284.6916769869501, 1412.1683942912011, 1385.6521432546265, 1389.040718291725, 1416.8703797409655, 1381.6463022924668, 1537.5965589811017, 1400.816111644553, 1543.470188929382, 1568.9768114143244, 1466.346524883249, 1512.9917005826642, 1518.7570691668122, 1630.6564375381895, 1604.0740932699023, 1489.8344951608328, 1566.8093179883904, 1648.8903617645776, 1652.0376726715258, 1584.1964854661312, 1544.6836333035092, 1685.7428237659306, 1743.0433104104836, 1584.0110818021124, 1559.6228354683135, 1518.9542850089472, 1531.5511229104836, 1688.0965869413408, 1669.7538080481843, 1574.2153156642808, 1842.0148884863827, 1702.991826744719, 1642.0859661421962, 1738.2391746137396, 1702.2434000196404, 1697.0727239001396, 1623.4755975307698, 1757.3469688372904, 1728.3879694592354, 1666.733873761566, 1643.254704821709, 1818.477282646648, 1679.789910172617, 1724.483101104225, 1851.2853690206005, 1610.6402035505412, 1750.7786981167073, 1759.508814976868, 1706.9453834235335, 1709.4704610302463, 1734.270316864525, 1761.7771609855097, 1746.5888780988128, 1634.7519040240923, 1685.8554455634603, 1716.502543017851, 1810.8852252640538, 1752.3885736731843, 1657.8357629189943, 1774.9524062172661, 1697.5942819265015, 1755.5054147390015, 1839.9728281031773, 1833.2108529373254, 1880.5235302461592, 1832.5710681084147, 1675.6644443959497, 1670.7838748526972, 1827.6077328474162, 1843.859028565817, 1784.2798192541027, 1870.821223594623, 1799.3927377029504, 1798.4839058135474, 1802.941162109375, 1868.1583258772696, 1961.3265128535265, 1793.4376063853003, 1700.9047005935754, 1754.6619238826815, 1825.9633079827165, 1913.3072980315992, 1745.4476407013792, 1850.8939297638792, 1861.6778953168646, 1670.9221805167597, 1825.8950113477654, 1781.7555524943261, 1803.8779965192912], 'val_acc': [0.9567644725964722, 0.958786425643793, 0.9588683457347934, 0.9589146728622181, 0.9585209858484108, 0.9590375763077975, 0.9589413917264459, 0.9594223649142175, 0.9597519466330885, 0.9600031389204483, 0.9605856474551409, 0.9600850876483171, 0.9603006330282329, 0.960215142985296, 0.9598588450660919, 0.9601082378925558, 0.9602970707349937, 0.960013823136271, 0.9603006356921275, 0.9599568201176947, 0.9603808082681794, 0.9600244860409358, 0.9600387681795898, 0.9602810407484044, 0.9598980476070382, 0.9599888817558075, 0.9599229743360808, 0.9597465905397298, 0.9600049247288837, 0.9592852286120367, 0.9599817691568556, 0.9599033817232654, 0.9597822297884765, 0.9595364169035544, 0.9601135933199408, 0.9598231931638451, 0.9592121626411736, 0.9595666700901266, 0.9595346091179874, 0.9599497101826375, 0.9597715512334302, 0.9595417400312157, 0.9594793919078465, 0.9593315400890798, 0.9601474444293443, 0.9593475697426822, 0.9597733483634181, 0.9599033750635285, 0.9595773972612519, 0.9587044502769768, 0.9594740491339614, 0.9597127540817474, 0.9594259595071803, 0.9604680941091569, 0.9597216618127663, 0.9590696775713446, 0.9598463620553469, 0.960680101503873, 0.9595773789469756, 0.9598713087635999, 0.9596610785196613, 0.9602276103456593, 0.9604520677854229, 0.9601563225245343, 0.9597893417214548, 0.9594188119446099, 0.9607157387546987, 0.9601741669564273, 0.9597858190536499, 0.9595043179709152, 0.9594295201354852, 0.9598873417470708, 0.9598499273454677, 0.9600940000411519, 0.9601028971165918, 0.9598481432019665, 0.9598570599236302, 0.9599123014418106, 0.9600779447475625, 0.9597359329628545, 0.9597483913325731, 0.959798282751158, 0.959983544309712, 0.9601759164692969, 0.9597715435747328, 0.9595061384099822, 0.9605892260647353, 0.9600672542049898, 0.9604253405965241, 0.9601456532931195, 0.959666419961599, 0.9603308995342787, 0.9605981354606884, 0.9606159655741473, 0.9603843552440239, 0.9604271180802884, 0.9602186849663378], 'val_mDice': [0.44905740222451407, 0.47780542999672493, 0.49264071573758256, 0.4952370344593538, 0.4993412794347582, 0.5143785791357136, 0.5258453666497875, 0.5048279031361947, 0.5299561604774198, 0.5148198026851569, 0.5290361950850354, 0.5270483147498616, 0.5281909058213899, 0.5396531493970136, 0.5187467011992491, 0.542340971904094, 0.5296281080006221, 0.5319420014346778, 0.5378725830070133, 0.5338149838274417, 0.5356806225283852, 0.5318957415705953, 0.5317025414392269, 0.5413074823065177, 0.5353090511686975, 0.5267221048557559, 0.5277462175438524, 0.5387867992150717, 0.5379557882607316, 0.5308503398682152, 0.5207159092972399, 0.5442106239289545, 0.5457477173325735, 0.5516265692324612, 0.5495945564861404, 0.5347422021727323, 0.5361064314509237, 0.5429792645590266, 0.5209787414726599, 0.5320117308773809, 0.5391469289803638, 0.5366677826676289, 0.5388876714186961, 0.538417844465991, 0.5432073440631675, 0.5362326021634001, 0.534105507521656, 0.5410408071299505, 0.5432786598551873, 0.5284346984751398, 0.5409663486081129, 0.5374430353082092, 0.5286996466154493, 0.5533480877316864, 0.5389903159447889, 0.5340987816869214, 0.5477301230310728, 0.5452752115007219, 0.5399769924206441, 0.5399602673240214, 0.5373370064703445, 0.5544757919604552, 0.5494317518932194, 0.5446486055185009, 0.5371521986063632, 0.537970416039728, 0.5563930299694978, 0.540276149797706, 0.5466996421361102, 0.5432119406135388, 0.5346698571183828, 0.5391924456178143, 0.5277934717066461, 0.5308329196615592, 0.5405723978687265, 0.5515531729386506, 0.5336841721108506, 0.5357474911146324, 0.5372647121964886, 0.5273026760729997, 0.5345144671434797, 0.5350686366664631, 0.5361524129380061, 0.5304910583869039, 0.5233216082583593, 0.5370193783131392, 0.5534531131137017, 0.5474074622772259, 0.5434857395441173, 0.5329205445404159, 0.5477672059442744, 0.5392839465727354, 0.5320717409336367, 0.554348493088557, 0.5390939865698362, 0.5473145985736527, 0.541099845364107], 'loss': [1149.7444766457904, 563.167396571588, 475.50383036243494, 431.2017508546717, 402.4619927606541, 381.51753080206095, 363.55615034259733, 353.1913898817679, 342.03963565904326, 332.1336231745898, 324.54004768457594, 317.08750341359416, 309.0152489561562, 303.3683688033543, 299.3476167338832, 293.84012345429903, 288.7432450983793, 286.1702896466371, 281.0360619510858, 277.69582646215514, 274.4112018672257, 270.86728622547054, 268.2868711214869, 265.2004592876394, 262.4588194120411, 259.86509953321155, 259.11401061197296, 255.41154820043454, 253.171762441811, 252.20058525055947, 248.40022804131857, 247.1781803112613, 244.70853761932986, 243.77354236272652, 241.88234136400771, 239.79199016972646, 238.0449347387218, 237.20138002147044, 235.68941830178568, 234.44845923610805, 233.42751063981623, 230.32584994621354, 230.26778716691976, 228.58995801265914, 227.3741473361081, 226.37608377209327, 225.1445745523508, 223.67700741806684, 222.24510813411248, 222.04198583417272, 220.37958053124314, 219.96907006891118, 217.55215839124, 217.4123938029501, 216.52515446904061, 215.40329404487815, 214.10493541622168, 213.20466810394416, 212.86565400624247, 212.08767305615876, 210.52363803702096, 210.12592628769454, 209.87552578374846, 208.8852095463964, 207.42039339077914, 206.37355309099902, 205.8801883830269, 205.53398143709515, 204.70610666262039, 204.12523146721216, 202.75785171943426, 202.377539758582, 202.37292065445644, 200.7777250028242, 201.36955321148702, 200.44978829691283, 199.83803170501625, 200.1980050924615, 198.04185492737506, 197.55194665216865, 197.38729995853026, 196.35068242455495, 195.9300045771547, 195.72022697698458, 194.64305293669753, 194.33192029489385, 193.47904453430291, 194.05531893596626, 192.80282476178039, 192.50204184221408, 192.00335889734947, 190.85139797957177, 191.14111584418805, 190.3984239598088, 189.72339022260212, 189.44056063668089, 189.63651989376444], 'acc': [0.9302567364434441, 0.947053578549705, 0.9515825231106061, 0.953830329377591, 0.9553349119510197, 0.9563184657632366, 0.9571721773087593, 0.9577165179396498, 0.9582027110501082, 0.95848136499137, 0.9589459708421152, 0.9596449248632712, 0.9600133157349069, 0.9603206801502788, 0.9605337567730905, 0.960896765644933, 0.961321613720563, 0.9614641327275202, 0.9619771043048381, 0.9621059496310157, 0.9621853866768548, 0.9625479082326005, 0.9627053748482901, 0.9628662471677488, 0.9630833541208814, 0.9632761621843995, 0.9631682441622972, 0.9633170144534969, 0.9635433061899011, 0.9638380570437912, 0.963941585088528, 0.9639140753813296, 0.9639998015109039, 0.9639799834842951, 0.964378802064496, 0.964416297541277, 0.9645444142858055, 0.9646695452015369, 0.9647877282173336, 0.9650317008546881, 0.9650914962401701, 0.9651631687722508, 0.9649591251991068, 0.9653834731164214, 0.9654638839926272, 0.9656086886385532, 0.96559898149577, 0.9656907128233333, 0.9657555624561031, 0.9658120054122468, 0.9660093480157382, 0.966149238896431, 0.966101915489893, 0.9661396186269061, 0.9658629933796081, 0.9661856792304363, 0.9662346681779288, 0.9664047097667656, 0.9665592778326996, 0.966571484903554, 0.9666871175735606, 0.9667618621292279, 0.9668431441272684, 0.9668722329014534, 0.9669961141193428, 0.9669178062732895, 0.967044324482989, 0.966948248680936, 0.9669880880898403, 0.9670537899024969, 0.9670718502559458, 0.9671231178239854, 0.967263131514074, 0.9674949140877488, 0.9673496202461392, 0.9674776317046025, 0.9676065308148744, 0.9675100053988293, 0.9676457121607123, 0.9677560794886522, 0.9678871306963498, 0.9677593775917701, 0.9678688806377526, 0.9679323046251966, 0.9679746287534273, 0.9679311233813139, 0.968013253748128, 0.9679370805475876, 0.9681731660955191, 0.967893003722719, 0.9680731350135118, 0.9680811230162832, 0.9682165538035643, 0.9682605942053562, 0.9683158579400394, 0.9683339006857548, 0.9683468918623498], 'mDice': [0.38928256369589537, 0.6098394504228933, 0.6656682158755254, 0.6953873374085431, 0.71478926288842, 0.7292805285334594, 0.7414304568457075, 0.7494226517185693, 0.756945181614264, 0.7638572016531564, 0.7689138714131378, 0.7744112767384246, 0.7800031357273531, 0.7838213311276089, 0.7866977861481914, 0.7901915045002954, 0.794178060350137, 0.7959201341717794, 0.7996879303794912, 0.8021310037546224, 0.8046981289745007, 0.8068463610418546, 0.8087646262096844, 0.8109110879077416, 0.812695042434247, 0.8146625223466757, 0.8153485156768976, 0.8176942856494498, 0.8194264684144944, 0.820181372995295, 0.8226027450792138, 0.8238820974996008, 0.8256919781410268, 0.825983029001127, 0.8276077361188938, 0.8290011170908852, 0.8304003845255306, 0.8310774423887667, 0.8319003264386308, 0.832814727452292, 0.8338056084221663, 0.8358550279444712, 0.8358163661046795, 0.8372632022465206, 0.8380022465348419, 0.8386500330702632, 0.8395077196914551, 0.8405349874969116, 0.8417255047502409, 0.8419960920772134, 0.843160164362075, 0.8434997303839973, 0.8447504349604366, 0.8450958453474673, 0.8456803349574454, 0.8467503315800837, 0.8476988323814799, 0.8482133813117573, 0.8486101030913854, 0.8492198227199943, 0.8501485498841893, 0.8504463295409131, 0.8507640239823767, 0.8516682695117977, 0.8524968748122257, 0.853099877272327, 0.8537212977721783, 0.8537119596906039, 0.8545419335540594, 0.8548864266963431, 0.8557500388911721, 0.8563163259840825, 0.8560671234311351, 0.8571461686822598, 0.8570020257449541, 0.8577035218956073, 0.8580916876055616, 0.8578920249721854, 0.8594084606276612, 0.8597299111193935, 0.8599119315018329, 0.8605937820609038, 0.86090473812602, 0.8610395713703258, 0.8620934512294344, 0.8621171444149671, 0.8625283323305052, 0.8623298666042334, 0.8632419551193412, 0.8634835043949964, 0.8636235645553475, 0.8647116884044634, 0.8643143341553107, 0.8650788160445845, 0.865607362015952, 0.8658265465777474, 0.8654783256471654]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.41s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.18s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.97s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:03,  1.49s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:23,  1.57s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:16,  1.55s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:42,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:32,  1.62s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:52,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:26,  1.82s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:37,  1.87s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:25,  1.83s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:40,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:50,  1.94s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<08:59,  1.98s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<09:08,  2.02s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<09:12,  2.04s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:20,  2.07s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:19,  2.08s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<09:16,  2.08s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<09:25,  2.12s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<09:33,  2.15s/it]predicting train subjects:   7%|▋         | 20/285 [00:39<09:26,  2.14s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<09:19,  2.12s/it]predicting train subjects:   8%|▊         | 22/285 [00:43<09:14,  2.11s/it]predicting train subjects:   8%|▊         | 23/285 [00:45<09:09,  2.10s/it]predicting train subjects:   8%|▊         | 24/285 [00:47<09:03,  2.08s/it]predicting train subjects:   9%|▉         | 25/285 [00:49<09:02,  2.09s/it]predicting train subjects:   9%|▉         | 26/285 [00:51<09:01,  2.09s/it]predicting train subjects:   9%|▉         | 27/285 [00:53<08:54,  2.07s/it]predicting train subjects:  10%|▉         | 28/285 [00:55<08:38,  2.02s/it]predicting train subjects:  10%|█         | 29/285 [00:57<08:26,  1.98s/it]predicting train subjects:  11%|█         | 30/285 [00:59<08:14,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [01:01<08:10,  1.93s/it]predicting train subjects:  11%|█         | 32/285 [01:02<08:01,  1.90s/it]predicting train subjects:  12%|█▏        | 33/285 [01:04<08:01,  1.91s/it]predicting train subjects:  12%|█▏        | 34/285 [01:06<07:54,  1.89s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<07:53,  1.89s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<07:52,  1.90s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<07:50,  1.90s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<07:44,  1.88s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<07:42,  1.88s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<07:39,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:19<07:44,  1.90s/it]predicting train subjects:  15%|█▍        | 42/285 [01:21<07:38,  1.89s/it]predicting train subjects:  15%|█▌        | 43/285 [01:23<07:42,  1.91s/it]predicting train subjects:  15%|█▌        | 44/285 [01:25<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:38,  1.91s/it]predicting train subjects:  16%|█▌        | 46/285 [01:29<07:21,  1.85s/it]predicting train subjects:  16%|█▋        | 47/285 [01:30<07:03,  1.78s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<06:55,  1.75s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<06:43,  1.71s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<06:36,  1.69s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<06:41,  1.71s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<06:36,  1.70s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<06:32,  1.69s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<06:31,  1.69s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<06:26,  1.68s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<06:18,  1.65s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:16,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:49<06:17,  1.66s/it]predicting train subjects:  21%|██        | 59/285 [01:50<06:15,  1.66s/it]predicting train subjects:  21%|██        | 60/285 [01:52<06:14,  1.66s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:12,  1.66s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:11,  1.66s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:11,  1.67s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:16,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:30,  1.77s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:37,  1.81s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:26,  1.77s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:19,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:14,  1.73s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:12,  1.73s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:11,  1.74s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:11,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:06,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<05:59,  1.72s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<05:57,  1.72s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<05:57,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<05:56,  1.73s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<05:54,  1.73s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<05:53,  1.73s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<05:53,  1.74s/it]predicting train subjects:  29%|██▉       | 83/285 [02:32<05:50,  1.74s/it]predicting train subjects:  29%|██▉       | 84/285 [02:34<05:47,  1.73s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<05:58,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:03,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:39<06:03,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:41<06:02,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:43<06:00,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<06:04,  1.87s/it]predicting train subjects:  32%|███▏      | 91/285 [02:47<06:04,  1.88s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<06:03,  1.89s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<06:00,  1.88s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:59,  1.88s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:55,  1.87s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<05:54,  1.87s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<05:52,  1.87s/it]predicting train subjects:  34%|███▍      | 98/285 [03:00<05:50,  1.87s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<05:48,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<05:45,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<05:45,  1.88s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<05:47,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:40,  1.87s/it]predicting train subjects:  36%|███▋      | 104/285 [03:11<05:37,  1.86s/it]predicting train subjects:  37%|███▋      | 105/285 [03:13<05:35,  1.86s/it]predicting train subjects:  37%|███▋      | 106/285 [03:15<05:34,  1.87s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:34,  1.88s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:32,  1.88s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:26,  1.85s/it]predicting train subjects:  39%|███▊      | 110/285 [03:22<05:22,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:24<05:23,  1.86s/it]predicting train subjects:  39%|███▉      | 112/285 [03:26<05:20,  1.85s/it]predicting train subjects:  40%|███▉      | 113/285 [03:28<05:18,  1.85s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:20,  1.87s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:23,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:21,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:19,  1.90s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:17,  1.90s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:16,  1.90s/it]predicting train subjects:  42%|████▏     | 120/285 [03:41<05:12,  1.89s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<05:01,  1.84s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:49,  1.78s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:38,  1.72s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:37,  1.72s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:34,  1.72s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:32,  1.71s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:34,  1.74s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<04:37,  1.77s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:31,  1.74s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:31,  1.75s/it]predicting train subjects:  46%|████▌     | 131/285 [04:00<04:30,  1.76s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:27,  1.75s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:26,  1.75s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:22,  1.74s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<04:22,  1.75s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<04:18,  1.74s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<04:15,  1.73s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<04:13,  1.72s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<04:14,  1.74s/it]predicting train subjects:  49%|████▉     | 140/285 [04:16<04:10,  1.73s/it]predicting train subjects:  49%|████▉     | 141/285 [04:18<04:10,  1.74s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<04:02,  1.70s/it]predicting train subjects:  50%|█████     | 143/285 [04:21<03:55,  1.66s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<03:50,  1.63s/it]predicting train subjects:  51%|█████     | 145/285 [04:24<03:46,  1.62s/it]predicting train subjects:  51%|█████     | 146/285 [04:26<03:46,  1.63s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:28<03:52,  1.68s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:29<03:52,  1.70s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:31<03:48,  1.68s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:33<03:48,  1.69s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:34<03:49,  1.71s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:36<03:43,  1.68s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:38<03:47,  1.72s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:40<03:45,  1.72s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:41<03:40,  1.70s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:43<03:38,  1.70s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:45<03:38,  1.71s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:46<03:36,  1.71s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:48<03:34,  1.71s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:50<03:31,  1.69s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:51<03:23,  1.64s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:53<03:16,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:54<03:11,  1.57s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:56<03:07,  1.55s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:57<03:03,  1.53s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:59<03:00,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:02<02:58,  1.53s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<02:54,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:05<02:51,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [05:06<02:49,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [05:08<02:46,  1.47s/it]predicting train subjects:  61%|██████    | 173/285 [05:09<02:47,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:11<02:46,  1.50s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:12<02:46,  1.51s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:14<02:44,  1.51s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:15<02:43,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:17<02:40,  1.50s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:18<02:38,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:20<02:35,  1.48s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:21<02:34,  1.49s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:23<02:31,  1.47s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:24<02:29,  1.46s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:25<02:25,  1.44s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:27<02:22,  1.42s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:28<02:22,  1.44s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:30<02:29,  1.53s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:31<02:25,  1.50s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:33<02:21,  1.47s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:34<02:19,  1.47s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:36<02:20,  1.49s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:37<02:16,  1.47s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:39<02:16,  1.48s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:40<02:14,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:42<02:14,  1.49s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:43<02:18,  1.55s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:45<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:47<02:23,  1.65s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:49<02:23,  1.67s/it]predicting train subjects:  70%|███████   | 200/285 [05:50<02:26,  1.72s/it]predicting train subjects:  71%|███████   | 201/285 [05:52<02:23,  1.71s/it]predicting train subjects:  71%|███████   | 202/285 [05:54<02:22,  1.72s/it]predicting train subjects:  71%|███████   | 203/285 [05:56<02:19,  1.71s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:57<02:18,  1.71s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:59<02:16,  1.71s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:01<02:16,  1.73s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:02<02:15,  1.73s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:04<02:13,  1.74s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:06<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:08<02:09,  1.72s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:09<02:05,  1.70s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:11<02:04,  1.71s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:13<02:03,  1.72s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:14<01:57,  1.65s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:16<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:49,  1.59s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:20<01:42,  1.53s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:41,  1.53s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:23<01:38,  1.52s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:26<01:35,  1.52s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:28<01:33,  1.51s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:29<01:32,  1.51s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:32<01:30,  1.54s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:34<01:29,  1.54s/it]predicting train subjects:  80%|████████  | 228/285 [06:36<01:27,  1.53s/it]predicting train subjects:  80%|████████  | 229/285 [06:37<01:25,  1.54s/it]predicting train subjects:  81%|████████  | 230/285 [06:39<01:23,  1.51s/it]predicting train subjects:  81%|████████  | 231/285 [06:40<01:21,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:24,  1.59s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:44<01:26,  1.66s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:45<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:47<01:27,  1.74s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:49<01:27,  1.78s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:51<01:26,  1.81s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:53<01:24,  1.80s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:55<01:22,  1.79s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:56<01:20,  1.79s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:58<01:19,  1.80s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:00<01:17,  1.81s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:02<01:16,  1.83s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:04<01:15,  1.84s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:06<01:13,  1.83s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:07<01:11,  1.84s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:09<01:10,  1.85s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:11<01:08,  1.85s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:13<01:05,  1.83s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:14<01:01,  1.75s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:16<00:56,  1.67s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:17<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:19<00:49,  1.55s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:20<00:46,  1.50s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:22<00:44,  1.48s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:23<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [07:25<00:40,  1.46s/it]predicting train subjects:  91%|█████████ | 258/285 [07:26<00:39,  1.46s/it]predicting train subjects:  91%|█████████ | 259/285 [07:27<00:38,  1.46s/it]predicting train subjects:  91%|█████████ | 260/285 [07:29<00:36,  1.44s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:30<00:34,  1.46s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:32<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:33<00:32,  1.47s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:35<00:30,  1.47s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:36<00:29,  1.48s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:38<00:28,  1.48s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:39<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:41<00:27,  1.64s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:43<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:45<00:26,  1.78s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:47<00:25,  1.82s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:49<00:23,  1.82s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:51<00:22,  1.84s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:53<00:20,  1.86s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:55<00:18,  1.88s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:56<00:17,  1.89s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:58<00:15,  1.91s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:00<00:13,  1.91s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:02<00:11,  1.89s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:04<00:09,  1.91s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:06<00:07,  1.90s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:08<00:05,  1.90s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:10<00:03,  1.90s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:12<00:01,  1.91s/it]predicting train subjects: 100%|██████████| 285/285 [08:14<00:00,  1.94s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:06,  1.29s/it]Loading train:   1%|          | 2/285 [00:02<06:17,  1.34s/it]Loading train:   1%|          | 3/285 [00:03<06:06,  1.30s/it]Loading train:   1%|▏         | 4/285 [00:05<06:27,  1.38s/it]Loading train:   2%|▏         | 5/285 [00:06<05:53,  1.26s/it]Loading train:   2%|▏         | 6/285 [00:07<06:02,  1.30s/it]Loading train:   2%|▏         | 7/285 [00:09<06:22,  1.38s/it]Loading train:   3%|▎         | 8/285 [00:10<06:24,  1.39s/it]Loading train:   3%|▎         | 9/285 [00:12<06:14,  1.36s/it]Loading train:   4%|▎         | 10/285 [00:13<05:42,  1.25s/it]Loading train:   4%|▍         | 11/285 [00:14<05:15,  1.15s/it]Loading train:   4%|▍         | 12/285 [00:14<04:53,  1.07s/it]Loading train:   5%|▍         | 13/285 [00:15<04:40,  1.03s/it]Loading train:   5%|▍         | 14/285 [00:16<04:30,  1.00it/s]Loading train:   5%|▌         | 15/285 [00:17<04:19,  1.04it/s]Loading train:   6%|▌         | 16/285 [00:18<04:31,  1.01s/it]Loading train:   6%|▌         | 17/285 [00:19<04:28,  1.00s/it]Loading train:   6%|▋         | 18/285 [00:20<04:27,  1.00s/it]Loading train:   7%|▋         | 19/285 [00:21<04:27,  1.01s/it]Loading train:   7%|▋         | 20/285 [00:22<04:31,  1.03s/it]Loading train:   7%|▋         | 21/285 [00:23<04:35,  1.04s/it]Loading train:   8%|▊         | 22/285 [00:24<04:32,  1.04s/it]Loading train:   8%|▊         | 23/285 [00:25<04:24,  1.01s/it]Loading train:   8%|▊         | 24/285 [00:26<04:13,  1.03it/s]Loading train:   9%|▉         | 25/285 [00:27<04:15,  1.02it/s]Loading train:   9%|▉         | 26/285 [00:28<04:12,  1.02it/s]Loading train:   9%|▉         | 27/285 [00:29<04:08,  1.04it/s]Loading train:  10%|▉         | 28/285 [00:30<04:12,  1.02it/s]Loading train:  10%|█         | 29/285 [00:31<04:06,  1.04it/s]Loading train:  11%|█         | 30/285 [00:32<04:01,  1.05it/s]Loading train:  11%|█         | 31/285 [00:33<03:57,  1.07it/s]Loading train:  11%|█         | 32/285 [00:34<03:58,  1.06it/s]Loading train:  12%|█▏        | 33/285 [00:35<03:52,  1.08it/s]Loading train:  12%|█▏        | 34/285 [00:36<03:50,  1.09it/s]Loading train:  12%|█▏        | 35/285 [00:37<03:54,  1.07it/s]Loading train:  13%|█▎        | 36/285 [00:38<03:47,  1.10it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:45,  1.10it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:37,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:29,  1.17it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:23,  1.20it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:25,  1.19it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:26,  1.18it/s]Loading train:  15%|█▌        | 43/285 [00:43<03:25,  1.18it/s]Loading train:  15%|█▌        | 44/285 [00:44<03:24,  1.18it/s]Loading train:  16%|█▌        | 45/285 [00:45<03:26,  1.16it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:29,  1.14it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:13,  1.23it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:09,  1.25it/s]Loading train:  17%|█▋        | 49/285 [00:48<03:21,  1.17it/s]Loading train:  18%|█▊        | 50/285 [00:49<03:27,  1.13it/s]Loading train:  18%|█▊        | 51/285 [00:50<03:29,  1.12it/s]Loading train:  18%|█▊        | 52/285 [00:51<03:24,  1.14it/s]Loading train:  19%|█▊        | 53/285 [00:52<03:24,  1.14it/s]Loading train:  19%|█▉        | 54/285 [00:53<03:14,  1.19it/s]Loading train:  19%|█▉        | 55/285 [00:54<03:17,  1.16it/s]Loading train:  20%|█▉        | 56/285 [00:55<03:15,  1.17it/s]Loading train:  20%|██        | 57/285 [00:55<03:11,  1.19it/s]Loading train:  20%|██        | 58/285 [00:56<03:12,  1.18it/s]Loading train:  21%|██        | 59/285 [00:57<03:12,  1.17it/s]Loading train:  21%|██        | 60/285 [00:58<03:06,  1.20it/s]Loading train:  21%|██▏       | 61/285 [00:59<03:02,  1.23it/s]Loading train:  22%|██▏       | 62/285 [00:59<02:57,  1.25it/s]Loading train:  22%|██▏       | 63/285 [01:00<02:53,  1.28it/s]Loading train:  22%|██▏       | 64/285 [01:01<03:25,  1.08it/s]Loading train:  23%|██▎       | 65/285 [01:03<03:55,  1.07s/it]Loading train:  23%|██▎       | 66/285 [01:04<04:09,  1.14s/it]Loading train:  24%|██▎       | 67/285 [01:05<03:45,  1.03s/it]Loading train:  24%|██▍       | 68/285 [01:06<03:29,  1.03it/s]Loading train:  24%|██▍       | 69/285 [01:06<03:14,  1.11it/s]Loading train:  25%|██▍       | 70/285 [01:07<03:03,  1.17it/s]Loading train:  25%|██▍       | 71/285 [01:08<02:51,  1.25it/s]Loading train:  25%|██▌       | 72/285 [01:09<02:43,  1.30it/s]Loading train:  26%|██▌       | 73/285 [01:09<02:42,  1.31it/s]Loading train:  26%|██▌       | 74/285 [01:10<02:42,  1.30it/s]Loading train:  26%|██▋       | 75/285 [01:11<02:38,  1.33it/s]Loading train:  27%|██▋       | 76/285 [01:12<02:39,  1.31it/s]Loading train:  27%|██▋       | 77/285 [01:12<02:32,  1.36it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:33,  1.35it/s]Loading train:  28%|██▊       | 79/285 [01:14<02:35,  1.32it/s]Loading train:  28%|██▊       | 80/285 [01:15<02:37,  1.30it/s]Loading train:  28%|██▊       | 81/285 [01:15<02:39,  1.28it/s]Loading train:  29%|██▉       | 82/285 [01:16<02:49,  1.20it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:49,  1.19it/s]Loading train:  29%|██▉       | 84/285 [01:18<02:53,  1.16it/s]Loading train:  30%|██▉       | 85/285 [01:19<03:09,  1.05it/s]Loading train:  30%|███       | 86/285 [01:20<03:10,  1.04it/s]Loading train:  31%|███       | 87/285 [01:21<03:03,  1.08it/s]Loading train:  31%|███       | 88/285 [01:22<03:03,  1.07it/s]Loading train:  31%|███       | 89/285 [01:23<03:04,  1.06it/s]Loading train:  32%|███▏      | 90/285 [01:24<03:02,  1.07it/s]Loading train:  32%|███▏      | 91/285 [01:25<03:02,  1.06it/s]Loading train:  32%|███▏      | 92/285 [01:26<03:01,  1.06it/s]Loading train:  33%|███▎      | 93/285 [01:27<02:58,  1.08it/s]Loading train:  33%|███▎      | 94/285 [01:28<02:56,  1.08it/s]Loading train:  33%|███▎      | 95/285 [01:29<02:53,  1.09it/s]Loading train:  34%|███▎      | 96/285 [01:30<02:56,  1.07it/s]Loading train:  34%|███▍      | 97/285 [01:31<02:57,  1.06it/s]Loading train:  34%|███▍      | 98/285 [01:31<02:53,  1.08it/s]Loading train:  35%|███▍      | 99/285 [01:32<02:49,  1.09it/s]Loading train:  35%|███▌      | 100/285 [01:33<02:51,  1.08it/s]Loading train:  35%|███▌      | 101/285 [01:34<02:51,  1.07it/s]Loading train:  36%|███▌      | 102/285 [01:35<02:45,  1.11it/s]Loading train:  36%|███▌      | 103/285 [01:36<02:46,  1.09it/s]Loading train:  36%|███▋      | 104/285 [01:37<02:40,  1.13it/s]Loading train:  37%|███▋      | 105/285 [01:38<02:39,  1.13it/s]Loading train:  37%|███▋      | 106/285 [01:39<02:40,  1.12it/s]Loading train:  38%|███▊      | 107/285 [01:39<02:37,  1.13it/s]Loading train:  38%|███▊      | 108/285 [01:40<02:34,  1.14it/s]Loading train:  38%|███▊      | 109/285 [01:41<02:36,  1.13it/s]Loading train:  39%|███▊      | 110/285 [01:42<02:37,  1.11it/s]Loading train:  39%|███▉      | 111/285 [01:43<02:40,  1.08it/s]Loading train:  39%|███▉      | 112/285 [01:44<02:42,  1.07it/s]Loading train:  40%|███▉      | 113/285 [01:45<02:43,  1.05it/s]Loading train:  40%|████      | 114/285 [01:46<02:42,  1.05it/s]Loading train:  40%|████      | 115/285 [01:47<02:47,  1.01it/s]Loading train:  41%|████      | 116/285 [01:48<02:59,  1.06s/it]Loading train:  41%|████      | 117/285 [01:49<02:52,  1.02s/it]Loading train:  41%|████▏     | 118/285 [01:50<02:52,  1.03s/it]Loading train:  42%|████▏     | 119/285 [01:52<03:05,  1.12s/it]Loading train:  42%|████▏     | 120/285 [01:53<03:01,  1.10s/it]Loading train:  42%|████▏     | 121/285 [01:54<03:09,  1.16s/it]Loading train:  43%|████▎     | 122/285 [01:55<03:15,  1.20s/it]Loading train:  43%|████▎     | 123/285 [01:56<03:09,  1.17s/it]Loading train:  44%|████▎     | 124/285 [01:57<02:49,  1.05s/it]Loading train:  44%|████▍     | 125/285 [01:58<02:36,  1.03it/s]Loading train:  44%|████▍     | 126/285 [01:59<02:26,  1.09it/s]Loading train:  45%|████▍     | 127/285 [02:00<02:20,  1.12it/s]Loading train:  45%|████▍     | 128/285 [02:01<02:32,  1.03it/s]Loading train:  45%|████▌     | 129/285 [02:02<02:33,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:03<02:38,  1.02s/it]Loading train:  46%|████▌     | 131/285 [02:04<02:32,  1.01it/s]Loading train:  46%|████▋     | 132/285 [02:05<02:36,  1.02s/it]Loading train:  47%|████▋     | 133/285 [02:06<02:37,  1.04s/it]Loading train:  47%|████▋     | 134/285 [02:07<02:37,  1.04s/it]Loading train:  47%|████▋     | 135/285 [02:08<02:42,  1.09s/it]Loading train:  48%|████▊     | 136/285 [02:09<02:40,  1.08s/it]Loading train:  48%|████▊     | 137/285 [02:10<02:43,  1.10s/it]Loading train:  48%|████▊     | 138/285 [02:12<02:44,  1.12s/it]Loading train:  49%|████▉     | 139/285 [02:13<02:48,  1.15s/it]Loading train:  49%|████▉     | 140/285 [02:14<02:35,  1.07s/it]Loading train:  49%|████▉     | 141/285 [02:15<02:27,  1.02s/it]Loading train:  50%|████▉     | 142/285 [02:16<02:33,  1.07s/it]Loading train:  50%|█████     | 143/285 [02:17<02:28,  1.05s/it]Loading train:  51%|█████     | 144/285 [02:18<02:31,  1.07s/it]Loading train:  51%|█████     | 145/285 [02:19<02:32,  1.09s/it]Loading train:  51%|█████     | 146/285 [02:20<02:34,  1.11s/it]Loading train:  52%|█████▏    | 147/285 [02:21<02:32,  1.10s/it]Loading train:  52%|█████▏    | 148/285 [02:22<02:29,  1.09s/it]Loading train:  52%|█████▏    | 149/285 [02:23<02:25,  1.07s/it]Loading train:  53%|█████▎    | 150/285 [02:25<02:26,  1.09s/it]Loading train:  53%|█████▎    | 151/285 [02:26<02:23,  1.07s/it]Loading train:  53%|█████▎    | 152/285 [02:26<02:17,  1.03s/it]Loading train:  54%|█████▎    | 153/285 [02:28<02:17,  1.04s/it]Loading train:  54%|█████▍    | 154/285 [02:29<02:16,  1.05s/it]Loading train:  54%|█████▍    | 155/285 [02:30<02:15,  1.04s/it]Loading train:  55%|█████▍    | 156/285 [02:31<02:10,  1.01s/it]Loading train:  55%|█████▌    | 157/285 [02:32<02:09,  1.01s/it]Loading train:  55%|█████▌    | 158/285 [02:33<02:10,  1.03s/it]Loading train:  56%|█████▌    | 159/285 [02:34<02:17,  1.09s/it]Loading train:  56%|█████▌    | 160/285 [02:35<02:12,  1.06s/it]Loading train:  56%|█████▋    | 161/285 [02:36<02:06,  1.02s/it]Loading train:  57%|█████▋    | 162/285 [02:37<02:04,  1.02s/it]Loading train:  57%|█████▋    | 163/285 [02:38<01:58,  1.03it/s]Loading train:  58%|█████▊    | 164/285 [02:39<01:56,  1.04it/s]Loading train:  58%|█████▊    | 165/285 [02:40<02:01,  1.01s/it]Loading train:  58%|█████▊    | 166/285 [02:41<02:03,  1.04s/it]Loading train:  59%|█████▊    | 167/285 [02:42<02:11,  1.11s/it]Loading train:  59%|█████▉    | 168/285 [02:43<02:12,  1.13s/it]Loading train:  59%|█████▉    | 169/285 [02:44<02:09,  1.12s/it]Loading train:  60%|█████▉    | 170/285 [02:46<02:15,  1.18s/it]Loading train:  60%|██████    | 171/285 [02:47<02:15,  1.19s/it]Loading train:  60%|██████    | 172/285 [02:48<02:10,  1.15s/it]Loading train:  61%|██████    | 173/285 [02:49<02:08,  1.15s/it]Loading train:  61%|██████    | 174/285 [02:50<02:08,  1.16s/it]Loading train:  61%|██████▏   | 175/285 [02:52<02:08,  1.17s/it]Loading train:  62%|██████▏   | 176/285 [02:53<02:09,  1.19s/it]Loading train:  62%|██████▏   | 177/285 [02:54<02:05,  1.16s/it]Loading train:  62%|██████▏   | 178/285 [02:55<02:00,  1.12s/it]Loading train:  63%|██████▎   | 179/285 [02:56<01:58,  1.12s/it]Loading train:  63%|██████▎   | 180/285 [02:57<01:54,  1.09s/it]Loading train:  64%|██████▎   | 181/285 [02:58<01:56,  1.12s/it]Loading train:  64%|██████▍   | 182/285 [02:59<01:54,  1.11s/it]Loading train:  64%|██████▍   | 183/285 [03:00<01:52,  1.10s/it]Loading train:  65%|██████▍   | 184/285 [03:01<01:51,  1.11s/it]Loading train:  65%|██████▍   | 185/285 [03:03<01:51,  1.12s/it]Loading train:  65%|██████▌   | 186/285 [03:04<02:02,  1.24s/it]Loading train:  66%|██████▌   | 187/285 [03:05<02:00,  1.23s/it]Loading train:  66%|██████▌   | 188/285 [03:06<01:55,  1.19s/it]Loading train:  66%|██████▋   | 189/285 [03:08<01:57,  1.22s/it]Loading train:  67%|██████▋   | 190/285 [03:09<01:55,  1.22s/it]Loading train:  67%|██████▋   | 191/285 [03:10<01:57,  1.25s/it]Loading train:  67%|██████▋   | 192/285 [03:12<01:58,  1.27s/it]Loading train:  68%|██████▊   | 193/285 [03:13<01:59,  1.30s/it]Loading train:  68%|██████▊   | 194/285 [03:14<01:52,  1.24s/it]Loading train:  68%|██████▊   | 195/285 [03:15<01:48,  1.21s/it]Loading train:  69%|██████▉   | 196/285 [03:16<01:48,  1.22s/it]Loading train:  69%|██████▉   | 197/285 [03:18<01:44,  1.19s/it]Loading train:  69%|██████▉   | 198/285 [03:19<01:50,  1.26s/it]Loading train:  70%|██████▉   | 199/285 [03:20<01:49,  1.27s/it]Loading train:  70%|███████   | 200/285 [03:22<01:47,  1.27s/it]Loading train:  71%|███████   | 201/285 [03:23<01:45,  1.26s/it]Loading train:  71%|███████   | 202/285 [03:24<01:50,  1.33s/it]Loading train:  71%|███████   | 203/285 [03:26<01:50,  1.35s/it]Loading train:  72%|███████▏  | 204/285 [03:27<01:50,  1.36s/it]Loading train:  72%|███████▏  | 205/285 [03:28<01:44,  1.31s/it]Loading train:  72%|███████▏  | 206/285 [03:29<01:39,  1.26s/it]Loading train:  73%|███████▎  | 207/285 [03:31<01:39,  1.27s/it]Loading train:  73%|███████▎  | 208/285 [03:32<01:47,  1.40s/it]Loading train:  73%|███████▎  | 209/285 [03:34<01:44,  1.37s/it]Loading train:  74%|███████▎  | 210/285 [03:35<01:37,  1.30s/it]Loading train:  74%|███████▍  | 211/285 [03:37<01:45,  1.43s/it]Loading train:  74%|███████▍  | 212/285 [03:38<01:47,  1.47s/it]Loading train:  75%|███████▍  | 213/285 [03:39<01:39,  1.38s/it]Loading train:  75%|███████▌  | 214/285 [03:40<01:31,  1.28s/it]Loading train:  75%|███████▌  | 215/285 [03:42<01:29,  1.28s/it]Loading train:  76%|███████▌  | 216/285 [03:43<01:25,  1.24s/it]Loading train:  76%|███████▌  | 217/285 [03:44<01:26,  1.27s/it]Loading train:  76%|███████▋  | 218/285 [03:45<01:21,  1.22s/it]Loading train:  77%|███████▋  | 219/285 [03:47<01:21,  1.24s/it]Loading train:  77%|███████▋  | 220/285 [03:47<01:14,  1.14s/it]Loading train:  78%|███████▊  | 221/285 [03:48<01:06,  1.04s/it]Loading train:  78%|███████▊  | 222/285 [03:49<00:59,  1.05it/s]Loading train:  78%|███████▊  | 223/285 [03:50<00:54,  1.14it/s]Loading train:  79%|███████▊  | 224/285 [03:50<00:51,  1.19it/s]Loading train:  79%|███████▉  | 225/285 [03:51<00:49,  1.20it/s]Loading train:  79%|███████▉  | 226/285 [03:52<00:48,  1.22it/s]Loading train:  80%|███████▉  | 227/285 [03:53<00:45,  1.27it/s]Loading train:  80%|████████  | 228/285 [03:54<00:46,  1.21it/s]Loading train:  80%|████████  | 229/285 [03:55<00:46,  1.20it/s]Loading train:  81%|████████  | 230/285 [03:55<00:45,  1.20it/s]Loading train:  81%|████████  | 231/285 [03:56<00:45,  1.18it/s]Loading train:  81%|████████▏ | 232/285 [03:57<00:47,  1.12it/s]Loading train:  82%|████████▏ | 233/285 [03:58<00:48,  1.08it/s]Loading train:  82%|████████▏ | 234/285 [03:59<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [04:00<00:46,  1.08it/s]Loading train:  83%|████████▎ | 236/285 [04:01<00:44,  1.09it/s]Loading train:  83%|████████▎ | 237/285 [04:02<00:46,  1.04it/s]Loading train:  84%|████████▎ | 238/285 [04:03<00:44,  1.05it/s]Loading train:  84%|████████▍ | 239/285 [04:04<00:43,  1.05it/s]Loading train:  84%|████████▍ | 240/285 [04:05<00:41,  1.09it/s]Loading train:  85%|████████▍ | 241/285 [04:06<00:41,  1.05it/s]Loading train:  85%|████████▍ | 242/285 [04:07<00:41,  1.05it/s]Loading train:  85%|████████▌ | 243/285 [04:08<00:39,  1.07it/s]Loading train:  86%|████████▌ | 244/285 [04:09<00:37,  1.10it/s]Loading train:  86%|████████▌ | 245/285 [04:09<00:36,  1.09it/s]Loading train:  86%|████████▋ | 246/285 [04:10<00:36,  1.07it/s]Loading train:  87%|████████▋ | 247/285 [04:11<00:34,  1.09it/s]Loading train:  87%|████████▋ | 248/285 [04:12<00:34,  1.09it/s]Loading train:  87%|████████▋ | 249/285 [04:13<00:34,  1.04it/s]Loading train:  88%|████████▊ | 250/285 [04:14<00:32,  1.09it/s]Loading train:  88%|████████▊ | 251/285 [04:15<00:29,  1.15it/s]Loading train:  88%|████████▊ | 252/285 [04:16<00:26,  1.23it/s]Loading train:  89%|████████▉ | 253/285 [04:16<00:27,  1.18it/s]Loading train:  89%|████████▉ | 254/285 [04:17<00:25,  1.20it/s]Loading train:  89%|████████▉ | 255/285 [04:18<00:25,  1.18it/s]Loading train:  90%|████████▉ | 256/285 [04:19<00:24,  1.19it/s]Loading train:  90%|█████████ | 257/285 [04:20<00:22,  1.22it/s]Loading train:  91%|█████████ | 258/285 [04:21<00:21,  1.24it/s]Loading train:  91%|█████████ | 259/285 [04:21<00:20,  1.24it/s]Loading train:  91%|█████████ | 260/285 [04:22<00:20,  1.23it/s]Loading train:  92%|█████████▏| 261/285 [04:23<00:18,  1.29it/s]Loading train:  92%|█████████▏| 262/285 [04:24<00:17,  1.30it/s]Loading train:  92%|█████████▏| 263/285 [04:24<00:17,  1.28it/s]Loading train:  93%|█████████▎| 264/285 [04:25<00:16,  1.26it/s]Loading train:  93%|█████████▎| 265/285 [04:26<00:15,  1.30it/s]Loading train:  93%|█████████▎| 266/285 [04:27<00:14,  1.30it/s]Loading train:  94%|█████████▎| 267/285 [04:27<00:13,  1.32it/s]Loading train:  94%|█████████▍| 268/285 [04:28<00:13,  1.24it/s]Loading train:  94%|█████████▍| 269/285 [04:29<00:13,  1.17it/s]Loading train:  95%|█████████▍| 270/285 [04:30<00:13,  1.14it/s]Loading train:  95%|█████████▌| 271/285 [04:31<00:12,  1.11it/s]Loading train:  95%|█████████▌| 272/285 [04:32<00:11,  1.10it/s]Loading train:  96%|█████████▌| 273/285 [04:33<00:11,  1.09it/s]Loading train:  96%|█████████▌| 274/285 [04:34<00:10,  1.09it/s]Loading train:  96%|█████████▋| 275/285 [04:35<00:09,  1.10it/s]Loading train:  97%|█████████▋| 276/285 [04:36<00:08,  1.07it/s]Loading train:  97%|█████████▋| 277/285 [04:37<00:07,  1.10it/s]Loading train:  98%|█████████▊| 278/285 [04:38<00:06,  1.09it/s]Loading train:  98%|█████████▊| 279/285 [04:39<00:05,  1.07it/s]Loading train:  98%|█████████▊| 280/285 [04:40<00:04,  1.07it/s]Loading train:  99%|█████████▊| 281/285 [04:40<00:03,  1.08it/s]Loading train:  99%|█████████▉| 282/285 [04:41<00:02,  1.09it/s]Loading train:  99%|█████████▉| 283/285 [04:42<00:01,  1.09it/s]Loading train: 100%|█████████▉| 284/285 [04:43<00:00,  1.07it/s]Loading train: 100%|██████████| 285/285 [04:44<00:00,  1.05it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:01, 169.69it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:01, 173.84it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:01, 175.57it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:01, 172.47it/s]concatenating: train:  30%|███       | 86/285 [00:00<00:01, 125.11it/s]concatenating: train:  36%|███▌      | 102/285 [00:00<00:01, 132.88it/s]concatenating: train:  41%|████▏     | 118/285 [00:00<00:01, 138.52it/s]concatenating: train:  49%|████▉     | 141/285 [00:00<00:00, 155.57it/s]concatenating: train:  55%|█████▌    | 158/285 [00:01<00:00, 157.81it/s]concatenating: train:  62%|██████▏   | 176/285 [00:01<00:00, 162.96it/s]concatenating: train:  72%|███████▏  | 206/285 [00:01<00:00, 188.74it/s]concatenating: train:  82%|████████▏ | 235/285 [00:01<00:00, 209.80it/s]concatenating: train:  93%|█████████▎| 265/285 [00:01<00:00, 229.98it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 191.25it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.87s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.64s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 170.09it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 56, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 56, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 56, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 56, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 56, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 56, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 28, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 28, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 28, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 28, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 28, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 28, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 28, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 28, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 14, 60)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 14, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 14, 120)  64920       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 14, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 14, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 14, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 14, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 14, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 10, 7, 120)   0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 10, 7, 120)   0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 10, 7, 240)   259440      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 10, 7, 240)   960         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 10, 7, 240)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 10, 7, 240)   518640      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 10, 7, 240)   960         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 10, 7, 240)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 10, 7, 240)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 20, 14, 120)  115320      dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 20, 14, 240)  0           conv2d_transpose_1[0][0]         2019-07-01 02:12:32.613924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-01 02:12:32.614040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-01 02:12:32.614055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-01 02:12:32.614063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-01 02:12:32.614500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 20, 14, 120)  259320      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 20, 14, 120)  480         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 20, 14, 120)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 20, 14, 120)  129720      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 20, 14, 120)  480         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 20, 14, 120)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 14, 120)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 40, 28, 60)   28860       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 28, 120)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 40, 28, 60)   64860       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 40, 28, 60)   240         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 40, 28, 60)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 40, 28, 60)   32460       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 40, 28, 60)   240         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 40, 28, 60)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 28, 60)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 80, 56, 30)   7230        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 80, 56, 60)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 56, 30)   16230       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 56, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 56, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 56, 30)   8130        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 56, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 56, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 56, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 56, 13)   403         dropout_7[0][0]                  
==================================================================================================
Total params: 1,697,683
Trainable params: 1,695,043
Non-trainable params: 2,640
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [2.40062229e+01 1.18201001e+01 2.77420847e+01 3.44797912e+00
 1.00219785e+01 2.61335372e+00 3.13040004e+01 4.16624627e+01
 3.18192739e+01 4.90028027e+00 1.08801089e+02 7.17113750e+01
 8.70380757e-02]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 1876.0233 - acc: 0.9047 - mDice: 0.3405 - val_loss: 1556.9537 - val_acc: 0.9296 - val_mDice: 0.4101

Epoch 00001: val_mDice improved from -inf to 0.41012, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 13s - loss: 909.9870 - acc: 0.9205 - mDice: 0.5693 - val_loss: 1876.5901 - val_acc: 0.9330 - val_mDice: 0.4184

Epoch 00002: val_mDice improved from 0.41012 to 0.41843, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 755.8327 - acc: 0.9261 - mDice: 0.6337 - val_loss: 1903.1427 - val_acc: 0.9344 - val_mDice: 0.4472

Epoch 00003: val_mDice improved from 0.41843 to 0.44720, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 12s - loss: 677.8209 - acc: 0.9290 - mDice: 0.6685 - val_loss: 2121.4346 - val_acc: 0.9357 - val_mDice: 0.4410

Epoch 00004: val_mDice did not improve from 0.44720
Epoch 5/300
 - 13s - loss: 627.3856 - acc: 0.9308 - mDice: 0.6918 - val_loss: 2146.9522 - val_acc: 0.9362 - val_mDice: 0.4485

Epoch 00005: val_mDice improved from 0.44720 to 0.44853, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 12s - loss: 591.9446 - acc: 0.9320 - mDice: 0.7088 - val_loss: 2119.5202 - val_acc: 0.9369 - val_mDice: 0.4537

Epoch 00006: val_mDice improved from 0.44853 to 0.45375, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 12s - loss: 564.6428 - acc: 0.9329 - mDice: 0.7211 - val_loss: 2246.4102 - val_acc: 0.9359 - val_mDice: 0.4490

Epoch 00007: val_mDice did not improve from 0.45375
Epoch 8/300
 - 13s - loss: 542.2549 - acc: 0.9337 - mDice: 0.7310 - val_loss: 2313.5354 - val_acc: 0.9378 - val_mDice: 0.4520

Epoch 00008: val_mDice did not improve from 0.45375
Epoch 9/300
 - 12s - loss: 523.1539 - acc: 0.9343 - mDice: 0.7406 - val_loss: 2266.7374 - val_acc: 0.9369 - val_mDice: 0.4585

Epoch 00009: val_mDice improved from 0.45375 to 0.45852, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 12s - loss: 509.9391 - acc: 0.9348 - mDice: 0.7470 - val_loss: 2228.9311 - val_acc: 0.9375 - val_mDice: 0.4687

Epoch 00010: val_mDice improved from 0.45852 to 0.46867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 12s - loss: 497.1726 - acc: 0.9349 - mDice: 0.7530 - val_loss: 2442.1710 - val_acc: 0.9380 - val_mDice: 0.4461

Epoch 00011: val_mDice did not improve from 0.46867
Epoch 12/300
 - 13s - loss: 484.4667 - acc: 0.9355 - mDice: 0.7590 - val_loss: 2338.0290 - val_acc: 0.9366 - val_mDice: 0.4638

Epoch 00012: val_mDice did not improve from 0.46867
Epoch 13/300
 - 12s - loss: 473.1468 - acc: 0.9358 - mDice: 0.7644 - val_loss: 2589.2314 - val_acc: 0.9371 - val_mDice: 0.4462

Epoch 00013: val_mDice did not improve from 0.46867
Epoch 14/300
 - 12s - loss: 463.2515 - acc: 0.9362 - mDice: 0.7694 - val_loss: 2345.6030 - val_acc: 0.9353 - val_mDice: 0.4652

Epoch 00014: val_mDice did not improve from 0.46867
Epoch 15/300
 - 12s - loss: 455.8414 - acc: 0.9364 - mDice: 0.7729 - val_loss: 2556.4576 - val_acc: 0.9361 - val_mDice: 0.4488

Epoch 00015: val_mDice did not improve from 0.46867
Epoch 16/300
 - 12s - loss: 448.2220 - acc: 0.9364 - mDice: 0.7766 - val_loss: 2437.6600 - val_acc: 0.9361 - val_mDice: 0.4674

Epoch 00016: val_mDice did not improve from 0.46867
Epoch 17/300
 - 12s - loss: 441.1280 - acc: 0.9365 - mDice: 0.7800 - val_loss: 2396.4024 - val_acc: 0.9379 - val_mDice: 0.4757

Epoch 00017: val_mDice improved from 0.46867 to 0.47568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 12s - loss: 434.1104 - acc: 0.9369 - mDice: 0.7838 - val_loss: 2446.7830 - val_acc: 0.9357 - val_mDice: 0.4740

Epoch 00018: val_mDice did not improve from 0.47568
Epoch 19/300
 - 13s - loss: 428.2767 - acc: 0.9369 - mDice: 0.7863 - val_loss: 2459.9794 - val_acc: 0.9356 - val_mDice: 0.4677

Epoch 00019: val_mDice did not improve from 0.47568
Epoch 20/300
 - 12s - loss: 422.7223 - acc: 0.9371 - mDice: 0.7888 - val_loss: 2510.4126 - val_acc: 0.9357 - val_mDice: 0.4704

Epoch 00020: val_mDice did not improve from 0.47568
Epoch 21/300
 - 12s - loss: 417.2935 - acc: 0.9372 - mDice: 0.7919 - val_loss: 2494.1567 - val_acc: 0.9353 - val_mDice: 0.4733

Epoch 00021: val_mDice did not improve from 0.47568
Epoch 22/300
 - 12s - loss: 412.4267 - acc: 0.9374 - mDice: 0.7940 - val_loss: 2487.3859 - val_acc: 0.9354 - val_mDice: 0.4739

Epoch 00022: val_mDice did not improve from 0.47568
Epoch 23/300
 - 12s - loss: 407.4778 - acc: 0.9374 - mDice: 0.7968 - val_loss: 2558.9752 - val_acc: 0.9354 - val_mDice: 0.4733

Epoch 00023: val_mDice did not improve from 0.47568
Epoch 24/300
 - 13s - loss: 403.0354 - acc: 0.9372 - mDice: 0.7988 - val_loss: 2522.0594 - val_acc: 0.9354 - val_mDice: 0.4741

Epoch 00024: val_mDice did not improve from 0.47568
Epoch 25/300
 - 12s - loss: 398.5565 - acc: 0.9374 - mDice: 0.8011 - val_loss: 2488.3538 - val_acc: 0.9350 - val_mDice: 0.4846

Epoch 00025: val_mDice improved from 0.47568 to 0.48463, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 12s - loss: 394.6053 - acc: 0.9376 - mDice: 0.8032 - val_loss: 2509.6991 - val_acc: 0.9359 - val_mDice: 0.4816

Epoch 00026: val_mDice did not improve from 0.48463
Epoch 27/300
 - 12s - loss: 390.8896 - acc: 0.9376 - mDice: 0.8047 - val_loss: 2623.2858 - val_acc: 0.9358 - val_mDice: 0.4741

Epoch 00027: val_mDice did not improve from 0.48463
Epoch 28/300
 - 12s - loss: 386.9849 - acc: 0.9374 - mDice: 0.8068 - val_loss: 2475.0087 - val_acc: 0.9360 - val_mDice: 0.4886

Epoch 00028: val_mDice improved from 0.48463 to 0.48858, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 13s - loss: 384.4066 - acc: 0.9374 - mDice: 0.8080 - val_loss: 2523.2507 - val_acc: 0.9362 - val_mDice: 0.4867

Epoch 00029: val_mDice did not improve from 0.48858
Epoch 30/300
 - 12s - loss: 381.6415 - acc: 0.9376 - mDice: 0.8096 - val_loss: 2609.9560 - val_acc: 0.9347 - val_mDice: 0.4732

Epoch 00030: val_mDice did not improve from 0.48858
Epoch 31/300
 - 12s - loss: 378.3907 - acc: 0.9374 - mDice: 0.8111 - val_loss: 2708.9736 - val_acc: 0.9360 - val_mDice: 0.4693

Epoch 00031: val_mDice did not improve from 0.48858
Epoch 32/300
 - 12s - loss: 374.7272 - acc: 0.9377 - mDice: 0.8129 - val_loss: 2639.5413 - val_acc: 0.9354 - val_mDice: 0.4827

Epoch 00032: val_mDice did not improve from 0.48858
Epoch 33/300
 - 12s - loss: 372.7836 - acc: 0.9377 - mDice: 0.8141 - val_loss: 2694.5685 - val_acc: 0.9350 - val_mDice: 0.4719

Epoch 00033: val_mDice did not improve from 0.48858
Epoch 34/300
 - 12s - loss: 368.7548 - acc: 0.9378 - mDice: 0.8159 - val_loss: 2636.3236 - val_acc: 0.9357 - val_mDice: 0.4797

Epoch 00034: val_mDice did not improve from 0.48858
Epoch 35/300
 - 12s - loss: 367.7749 - acc: 0.9379 - mDice: 0.8166 - val_loss: 2594.8164 - val_acc: 0.9363 - val_mDice: 0.4880

Epoch 00035: val_mDice did not improve from 0.48858
Epoch 36/300
 - 12s - loss: 363.9327 - acc: 0.9377 - mDice: 0.8183 - val_loss: 2651.0995 - val_acc: 0.9358 - val_mDice: 0.4850

Epoch 00036: val_mDice did not improve from 0.48858
Epoch 37/300
 - 13s - loss: 360.2615 - acc: 0.9380 - mDice: 0.8201 - val_loss: 2548.7843 - val_acc: 0.9360 - val_mDice: 0.4913

Epoch 00037: val_mDice improved from 0.48858 to 0.49134, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 12s - loss: 360.2384 - acc: 0.9380 - mDice: 0.8204 - val_loss: 2690.7484 - val_acc: 0.9358 - val_mDice: 0.4831

Epoch 00038: val_mDice did not improve from 0.49134
Epoch 39/300
 - 12s - loss: 355.4875 - acc: 0.9379 - mDice: 0.8226 - val_loss: 2611.3649 - val_acc: 0.9358 - val_mDice: 0.4888

Epoch 00039: val_mDice did not improve from 0.49134
Epoch 40/300
 - 12s - loss: 354.0629 - acc: 0.9382 - mDice: 0.8231 - val_loss: 2549.8631 - val_acc: 0.9352 - val_mDice: 0.4928

Epoch 00040: val_mDice improved from 0.49134 to 0.49279, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 12s - loss: 353.1043 - acc: 0.9381 - mDice: 0.8238 - val_loss: 2596.8639 - val_acc: 0.9354 - val_mDice: 0.4892

Epoch 00041: val_mDice did not improve from 0.49279
Epoch 42/300
 - 12s - loss: 349.5744 - acc: 0.9381 - mDice: 0.8255 - val_loss: 2650.4273 - val_acc: 0.9361 - val_mDice: 0.4922

Epoch 00042: val_mDice did not improve from 0.49279
Epoch 43/300
 - 13s - loss: 346.5820 - acc: 0.9383 - mDice: 0.8272 - val_loss: 2585.0650 - val_acc: 0.9360 - val_mDice: 0.4909

Epoch 00043: val_mDice did not improve from 0.49279
Epoch 44/300
 - 14s - loss: 346.2362 - acc: 0.9379 - mDice: 0.8273 - val_loss: 2669.2484 - val_acc: 0.9365 - val_mDice: 0.4930

Epoch 00044: val_mDice improved from 0.49279 to 0.49296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 45/300
 - 13s - loss: 342.9405 - acc: 0.9380 - mDice: 0.8288 - val_loss: 2518.6403 - val_acc: 0.9359 - val_mDice: 0.5045

Epoch 00045: val_mDice improved from 0.49296 to 0.50452, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 13s - loss: 341.7347 - acc: 0.9378 - mDice: 0.8294 - val_loss: 2673.5876 - val_acc: 0.9363 - val_mDice: 0.4924

Epoch 00046: val_mDice did not improve from 0.50452
Epoch 47/300
 - 12s - loss: 339.4555 - acc: 0.9377 - mDice: 0.8307 - val_loss: 2677.1741 - val_acc: 0.9360 - val_mDice: 0.4921

Epoch 00047: val_mDice did not improve from 0.50452
Epoch 48/300
 - 13s - loss: 337.0283 - acc: 0.9376 - mDice: 0.8317 - val_loss: 2641.1186 - val_acc: 0.9369 - val_mDice: 0.4970

Epoch 00048: val_mDice did not improve from 0.50452
Epoch 49/300
 - 12s - loss: 336.2782 - acc: 0.9378 - mDice: 0.8321 - val_loss: 2754.2868 - val_acc: 0.9368 - val_mDice: 0.4899

Epoch 00049: val_mDice did not improve from 0.50452
Epoch 50/300
 - 12s - loss: 334.9612 - acc: 0.9378 - mDice: 0.8330 - val_loss: 2648.1348 - val_acc: 0.9360 - val_mDice: 0.4938

Epoch 00050: val_mDice did not improve from 0.50452
Epoch 51/300
 - 12s - loss: 332.8544 - acc: 0.9382 - mDice: 0.8337 - val_loss: 2624.9762 - val_acc: 0.9368 - val_mDice: 0.5048

Epoch 00051: val_mDice improved from 0.50452 to 0.50475, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 52/300
 - 13s - loss: 330.4782 - acc: 0.9384 - mDice: 0.8350 - val_loss: 2653.3972 - val_acc: 0.9365 - val_mDice: 0.4998

Epoch 00052: val_mDice did not improve from 0.50475
Epoch 53/300
 - 12s - loss: 329.0421 - acc: 0.9383 - mDice: 0.8360 - val_loss: 2617.8232 - val_acc: 0.9355 - val_mDice: 0.5031

Epoch 00053: val_mDice did not improve from 0.50475
Epoch 54/300
 - 12s - loss: 326.9946 - acc: 0.9385 - mDice: 0.8368 - val_loss: 2644.8374 - val_acc: 0.9365 - val_mDice: 0.5021

Epoch 00054: val_mDice did not improve from 0.50475
Epoch 55/300
 - 12s - loss: 325.5677 - acc: 0.9380 - mDice: 0.8376 - val_loss: 2695.5258 - val_acc: 0.9361 - val_mDice: 0.4978

Epoch 00055: val_mDice did not improve from 0.50475
Epoch 56/300
 - 12s - loss: 324.0966 - acc: 0.9384 - mDice: 0.8385 - val_loss: 2738.2568 - val_acc: 0.9362 - val_mDice: 0.4964

Epoch 00056: val_mDice did not improve from 0.50475
Epoch 57/300
 - 12s - loss: 323.5462 - acc: 0.9383 - mDice: 0.8387 - val_loss: 2725.0318 - val_acc: 0.9363 - val_mDice: 0.4960

Epoch 00057: val_mDice did not improve from 0.50475
Epoch 58/300
 - 12s - loss: 321.8283 - acc: 0.9383 - mDice: 0.8395 - val_loss: 2620.0650 - val_acc: 0.9368 - val_mDice: 0.5064

Epoch 00058: val_mDice improved from 0.50475 to 0.50639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 59/300
 - 13s - loss: 319.3912 - acc: 0.9384 - mDice: 0.8407 - val_loss: 2750.1415 - val_acc: 0.9369 - val_mDice: 0.4958

Epoch 00059: val_mDice did not improve from 0.50639
Epoch 60/300
 - 12s - loss: 319.5879 - acc: 0.9383 - mDice: 0.8407 - val_loss: 2768.3948 - val_acc: 0.9362 - val_mDice: 0.4938

Epoch 00060: val_mDice did not improve from 0.50639
Epoch 61/300
 - 12s - loss: 318.3648 - acc: 0.9388 - mDice: 0.8415 - val_loss: 2690.1013 - val_acc: 0.9372 - val_mDice: 0.5064

Epoch 00061: val_mDice did not improve from 0.50639
Epoch 62/300
 - 12s - loss: 316.4045 - acc: 0.9385 - mDice: 0.8420 - val_loss: 2619.7839 - val_acc: 0.9364 - val_mDice: 0.5068

Epoch 00062: val_mDice improved from 0.50639 to 0.50675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 63/300
 - 12s - loss: 314.9013 - acc: 0.9386 - mDice: 0.8431 - val_loss: 2715.3131 - val_acc: 0.9365 - val_mDice: 0.5044

Epoch 00063: val_mDice did not improve from 0.50675
Epoch 64/300
 - 13s - loss: 314.2913 - acc: 0.9386 - mDice: 0.8436 - val_loss: 2802.7043 - val_acc: 0.9366 - val_mDice: 0.4946

Epoch 00064: val_mDice did not improve from 0.50675
Epoch 65/300
 - 12s - loss: 313.1503 - acc: 0.9385 - mDice: 0.8438 - val_loss: 2799.0770 - val_acc: 0.9368 - val_mDice: 0.4979

Epoch 00065: val_mDice did not improve from 0.50675
Epoch 66/300
 - 12s - loss: 310.2575 - acc: 0.9388 - mDice: 0.8455 - val_loss: 2817.9289 - val_acc: 0.9352 - val_mDice: 0.4915

Epoch 00066: val_mDice did not improve from 0.50675
Epoch 67/300
 - 13s - loss: 308.5715 - acc: 0.9386 - mDice: 0.8459 - val_loss: 2741.8340 - val_acc: 0.9365 - val_mDice: 0.5057

Epoch 00067: val_mDice did not improve from 0.50675
Epoch 68/300
 - 12s - loss: 308.1229 - acc: 0.9386 - mDice: 0.8464 - val_loss: 2977.1657 - val_acc: 0.9371 - val_mDice: 0.4803

Epoch 00068: val_mDice did not improve from 0.50675
Epoch 69/300
 - 13s - loss: 306.8711 - acc: 0.9386 - mDice: 0.8472 - val_loss: 2742.3870 - val_acc: 0.9373 - val_mDice: 0.5063

Epoch 00069: val_mDice did not improve from 0.50675
Epoch 70/300
 - 13s - loss: 304.7617 - acc: 0.9385 - mDice: 0.8481 - val_loss: 2741.5316 - val_acc: 0.9370 - val_mDice: 0.5044

Epoch 00070: val_mDice did not improve from 0.50675
Epoch 71/300
 - 13s - loss: 304.2114 - acc: 0.9386 - mDice: 0.8484 - val_loss: 2737.3330 - val_acc: 0.9367 - val_mDice: 0.5068

Epoch 00071: val_mDice improved from 0.50675 to 0.50684, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 72/300
 - 13s - loss: 304.4816 - acc: 0.9388 - mDice: 0.8485 - val_loss: 2799.7368 - val_acc: 0.9366 - val_mDice: 0.5013

Epoch 00072: val_mDice did not improve from 0.50684
Epoch 73/300
 - 13s - loss: 302.7213 - acc: 0.9390 - mDice: 0.8491 - val_loss: 2773.5172 - val_acc: 0.9372 - val_mDice: 0.5045

Epoch 00073: val_mDice did not improve from 0.50684
Epoch 74/300
 - 13s - loss: 301.4470 - acc: 0.9390 - mDice: 0.8498 - val_loss: 2748.9641 - val_acc: 0.9374 - val_mDice: 0.5074

Epoch 00074: val_mDice improved from 0.50684 to 0.50742, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 75/300
 - 12s - loss: 300.5762 - acc: 0.9388 - mDice: 0.8501 - val_loss: 2907.6676 - val_acc: 0.9368 - val_mDice: 0.4985

Epoch 00075: val_mDice did not improve from 0.50742
Epoch 76/300
 - 12s - loss: 299.2586 - acc: 0.9385 - mDice: 0.8510 - val_loss: 2798.2818 - val_acc: 0.9370 - val_mDice: 0.5026

Epoch 00076: val_mDice did not improve from 0.50742
Epoch 77/300
 - 12s - loss: 298.7032 - acc: 0.9387 - mDice: 0.8510 - val_loss: 2812.4694 - val_acc: 0.9378 - val_mDice: 0.5056

Epoch 00077: val_mDice did not improve from 0.50742
Epoch 78/300
 - 12s - loss: 298.2094 - acc: 0.9390 - mDice: 0.8514 - val_loss: 2836.5243 - val_acc: 0.9378 - val_mDice: 0.5028

Epoch 00078: val_mDice did not improve from 0.50742
Epoch 79/300
 - 12s - loss: 296.2647 - acc: 0.9388 - mDice: 0.8522 - val_loss: 2865.7974 - val_acc: 0.9365 - val_mDice: 0.4961

Epoch 00079: val_mDice did not improve from 0.50742
Epoch 80/300
 - 12s - loss: 296.1788 - acc: 0.9389 - mDice: 0.8527 - val_loss: 2916.5779 - val_acc: 0.9367 - val_mDice: 0.4930

Epoch 00080: val_mDice did not improve from 0.50742
Epoch 81/300
 - 12s - loss: 295.1901 - acc: 0.9391 - mDice: 0.8529 - val_loss: 2943.1954 - val_acc: 0.9374 - val_mDice: 0.4953

Epoch 00081: val_mDice did not improve from 0.50742
Epoch 82/300
 - 13s - loss: 293.7410 - acc: 0.9392 - mDice: 0.8535 - val_loss: 2941.0675 - val_acc: 0.9372 - val_mDice: 0.4954

Epoch 00082: val_mDice did not improve from 0.50742
Epoch 83/300
 - 12s - loss: 292.6337 - acc: 0.9393 - mDice: 0.8541 - val_loss: 2837.0038 - val_acc: 0.9373 - val_mDice: 0.5004

Epoch 00083: val_mDice did not improve from 0.50742
Epoch 84/300
 - 12s - loss: 291.5149 - acc: 0.9395 - mDice: 0.8547 - val_loss: 2948.2467 - val_acc: 0.9355 - val_mDice: 0.4878

Epoch 00084: val_mDice did not improve from 0.50742
Epoch 85/300
 - 12s - loss: 291.7887 - acc: 0.9393 - mDice: 0.8547 - val_loss: 2857.0626 - val_acc: 0.9377 - val_mDice: 0.5038

Epoch 00085: val_mDice did not improve from 0.50742
Epoch 86/300
 - 12s - loss: 289.4149 - acc: 0.9391 - mDice: 0.8558 - val_loss: 2833.3549 - val_acc: 0.9370 - val_mDice: 0.5056

Epoch 00086: val_mDice did not improve from 0.50742
Epoch 87/300
 - 12s - loss: 290.4366 - acc: 0.9395 - mDice: 0.8555 - val_loss: 2753.4283 - val_acc: 0.9382 - val_mDice: 0.5137

Epoch 00087: val_mDice improved from 0.50742 to 0.51373, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 88/300
 - 12s - loss: 290.2440 - acc: 0.9389 - mDice: 0.8556 - val_loss: 2836.5556 - val_acc: 0.9372 - val_mDice: 0.5021

Epoch 00088: val_mDice did not improve from 0.51373
Epoch 89/300
 - 12s - loss: 288.3644 - acc: 0.9393 - mDice: 0.8565 - val_loss: 2957.1035 - val_acc: 0.9365 - val_mDice: 0.4943

Epoch 00089: val_mDice did not improve from 0.51373
Epoch 90/300
 - 12s - loss: 286.7572 - acc: 0.9395 - mDice: 0.8574 - val_loss: 2806.6923 - val_acc: 0.9370 - val_mDice: 0.5127

Epoch 00090: val_mDice did not improve from 0.51373
Epoch 91/300
 - 13s - loss: 286.2849 - acc: 0.9393 - mDice: 0.8573 - val_loss: 2992.6310 - val_acc: 0.9373 - val_mDice: 0.4933

Epoch 00091: val_mDice did not improve from 0.51373
Epoch 92/300
 - 12s - loss: 284.4460 - acc: 0.9398 - mDice: 0.8584 - val_loss: 2935.2148 - val_acc: 0.9371 - val_mDice: 0.4991

Epoch 00092: val_mDice did not improve from 0.51373
Epoch 93/300
 - 12s - loss: 284.1813 - acc: 0.9400 - mDice: 0.8587 - val_loss: 2925.1291 - val_acc: 0.9373 - val_mDice: 0.4997

Epoch 00093: val_mDice did not improve from 0.51373
Epoch 94/300
 - 12s - loss: 283.6443 - acc: 0.9399 - mDice: 0.8589 - val_loss: 3003.5523 - val_acc: 0.9362 - val_mDice: 0.4864

Epoch 00094: val_mDice did not improve from 0.51373
Epoch 95/300
 - 12s - loss: 282.3809 - acc: 0.9396 - mDice: 0.8596 - val_loss: 2930.5944 - val_acc: 0.9368 - val_mDice: 0.4962

Epoch 00095: val_mDice did not improve from 0.51373
Epoch 96/300
 - 12s - loss: 282.8700 - acc: 0.9399 - mDice: 0.8591 - val_loss: 3013.4765 - val_acc: 0.9376 - val_mDice: 0.4951

Epoch 00096: val_mDice did not improve from 0.51373
Epoch 97/300
 - 12s - loss: 281.7868 - acc: 0.9399 - mDice: 0.8597 - val_loss: 2915.6777 - val_acc: 0.9373 - val_mDice: 0.5016

Epoch 00097: val_mDice did not improve from 0.51373
Epoch 98/300
 - 12s - loss: 280.4408 - acc: 0.9398 - mDice: 0.8605 - val_loss: 2897.7504 - val_acc: 0.9368 - val_mDice: 0.5019

Epoch 00098: val_mDice did not improve from 0.51373
Epoch 99/300
 - 12s - loss: 279.4363 - acc: 0.9400 - mDice: 0.8608 - val_loss: 3024.3854 - val_acc: 0.9368 - val_mDice: 0.4899

Epoch 00099: val_mDice did not improve from 0.51373
Epoch 100/300
 - 13s - loss: 279.1628 - acc: 0.9401 - mDice: 0.8611 - val_loss: 2927.2930 - val_acc: 0.9373 - val_mDice: 0.5004

Epoch 00100: val_mDice did not improve from 0.51373
Epoch 101/300
 - 12s - loss: 278.3933 - acc: 0.9401 - mDice: 0.8616 - val_loss: 2909.4705 - val_acc: 0.9371 - val_mDice: 0.4989

Epoch 00101: val_mDice did not improve from 0.51373
Epoch 102/300
 - 12s - loss: 277.0071 - acc: 0.9399 - mDice: 0.8621 - val_loss: 3058.2145 - val_acc: 0.9367 - val_mDice: 0.4880

Epoch 00102: val_mDice did not improve from 0.51373
Epoch 103/300
 - 12s - loss: 277.8078 - acc: 0.9395 - mDice: 0.8619 - val_loss: 2930.2104 - val_acc: 0.9378 - val_mDice: 0.5045

Epoch 00103: val_mDice did not improve from 0.51373
Epoch 104/300
 - 12s - loss: 276.5531 - acc: 0.9398 - mDice: 0.8626 - val_loss: 2966.5380 - val_acc: 0.9368 - val_mDice: 0.5032

Epoch 00104: val_mDice did not improve from 0.51373
Epoch 105/300
 - 12s - loss: 275.9867 - acc: 0.9397 - mDice: 0.8625 - val_loss: 3032.0152 - val_acc: 0.9366 - val_mDice: 0.4945

Epoch 00105: val_mDice did not improve from 0.51373
Epoch 106/300
 - 13s - loss: 275.7032 - acc: 0.9399 - mDice: 0.8630 - val_loss: 2960.9042 - val_acc: 0.9371 - val_mDice: 0.5023

Epoch 00106: val_mDice did not improve from 0.51373
Epoch 107/300
 - 12s - loss: 274.6769 - acc: 0.9403 - mDice: 0.8633 - val_loss: 3039.3123 - val_acc: 0.9378 - val_mDice: 0.5020

Epoch 00107: val_mDice did not improve from 0.51373
Epoch 108/300
 - 12s - loss: 273.9285 - acc: 0.9405 - mDice: 0.8637 - val_loss: 3016.5372 - val_acc: 0.9376 - val_mDice: 0.5011

Epoch 00108: val_mDice did not improve from 0.51373
Epoch 109/300
 - 12s - loss: 273.0917 - acc: 0.9401 - mDice: 0.8642 - val_loss: 2870.7460 - val_acc: 0.9371 - val_mDice: 0.5073

Epoch 00109: val_mDice did not improve from 0.51373
Epoch 110/300
 - 13s - loss: 272.6431 - acc: 0.9401 - mDice: 0.8646 - val_loss: 2996.7637 - val_acc: 0.9379 - val_mDice: 0.5053

Epoch 00110: val_mDice did not improve from 0.51373
Epoch 111/300
 - 12s - loss: 271.6737 - acc: 0.9403 - mDice: 0.8650 - val_loss: 2961.3804 - val_acc: 0.9369 - val_mDice: 0.5020

Epoch 00111: val_mDice did not improve from 0.51373
Epoch 112/300
 - 12s - loss: 271.2943 - acc: 0.9404 - mDice: 0.8650 - val_loss: 3006.7434 - val_acc: 0.9378 - val_mDice: 0.4988

Epoch 00112: val_mDice did not improve from 0.51373
Epoch 113/300
 - 12s - loss: 269.6706 - acc: 0.9405 - mDice: 0.8659 - val_loss: 3094.1194 - val_acc: 0.9370 - val_mDice: 0.4912

Epoch 00113: val_mDice did not improve from 0.51373
Epoch 114/300
 - 13s - loss: 270.6615 - acc: 0.9403 - mDice: 0.8656 - val_loss: 3095.1050 - val_acc: 0.9371 - val_mDice: 0.4949

Epoch 00114: val_mDice did not improve from 0.51373
Epoch 115/300
 - 13s - loss: 268.2971 - acc: 0.9404 - mDice: 0.8667 - val_loss: 3042.7784 - val_acc: 0.9370 - val_mDice: 0.4973

Epoch 00115: val_mDice did not improve from 0.51373
Epoch 116/300
 - 13s - loss: 268.8483 - acc: 0.9406 - mDice: 0.8661 - val_loss: 3082.0926 - val_acc: 0.9376 - val_mDice: 0.5002

Epoch 00116: val_mDice did not improve from 0.51373
Epoch 117/300
 - 13s - loss: 268.9486 - acc: 0.9408 - mDice: 0.8666 - val_loss: 3041.5146 - val_acc: 0.9381 - val_mDice: 0.4994

Epoch 00117: val_mDice did not improve from 0.51373
Restoring model weights from the end of the best epoch
Epoch 00117: early stopping
{'val_loss': [1556.9536825326772, 1876.5900614811824, 1903.1427131065955, 2121.4346237182617, 2146.9522212101865, 2119.5202120267427, 2246.4102407602163, 2313.535399216872, 2266.737361027644, 2228.9311259343076, 2442.1709794264575, 2338.0289553128755, 2589.2314048180215, 2345.603001521184, 2556.4575547438403, 2437.660019507775, 2396.4024458665112, 2446.782998891977, 2459.9794018085186, 2510.4125530536357, 2494.156690157377, 2487.385877755972, 2558.9752138577974, 2522.0594482421875, 2488.353757418119, 2509.6990509033203, 2623.2858340923603, 2475.0087468073916, 2523.25068957989, 2609.9559672429014, 2708.9736298781177, 2639.5412961519683, 2694.5684861403247, 2636.3235990084136, 2594.816383948693, 2651.0995272122896, 2548.7842571551982, 2690.748367896447, 2611.3648963341348, 2549.8631040132964, 2596.8638845590444, 2650.4272572444033, 2585.0649525569033, 2669.2483743520884, 2518.6403403648965, 2673.5875537578877, 2677.17406639686, 2641.118580744817, 2754.286831195538, 2648.134756234976, 2624.976200397198, 2653.3971598698545, 2617.8232392531177, 2644.8373741736777, 2695.525843106783, 2738.2568048330454, 2725.0317746675933, 2620.06503706712, 2750.1414783184346, 2768.3947630662183, 2690.101333618164, 2619.783944936899, 2715.3131256103516, 2802.704283494216, 2799.0769981971152, 2817.9288975642276, 2741.8339556180513, 2977.165686387282, 2742.3870368370644, 2741.531613276555, 2737.333003117488, 2799.736751849835, 2773.5172095665566, 2748.9641271737905, 2907.6675743689902, 2798.2818497877856, 2812.469410822942, 2836.5243107722354, 2865.797376192533, 2916.577914898212, 2943.19544337346, 2941.0675119253306, 2837.003762465257, 2948.2467029278096, 2857.0626115065356, 2833.354944669283, 2753.428344139686, 2836.555615938627, 2957.103530883789, 2806.6923311673677, 2992.6310354379507, 2935.2147709773135, 2925.1291210468, 3003.552259005033, 2930.59438089224, 3013.4764639047476, 2915.677743765024, 2897.7504102266753, 3024.3853689340444, 2927.2929728581357, 2909.4705382127026, 3058.214491037222, 2930.2103547316333, 2966.5379767784707, 3032.015162541316, 2960.9042299710786, 3039.3123168945312, 3016.5371704101562, 2870.7460033710186, 2996.763669527494, 2961.380352313702, 3006.7433647742637, 3094.119354248047, 3095.1050309401294, 3042.7783707838794, 3082.0926384559043, 3041.514585054838], 'val_acc': [0.9296166805120615, 0.9329906518642719, 0.9344200446055486, 0.935737880376669, 0.9362165217216198, 0.9368775762044467, 0.9358902986233051, 0.937759708899718, 0.9368990201216477, 0.9375128516784081, 0.9379829145394839, 0.936555626300665, 0.9370514452457428, 0.9353322409666501, 0.9361285338034997, 0.93613712145732, 0.9378519975222074, 0.935667083813594, 0.9356219722674444, 0.9357378712067237, 0.935327967772117, 0.9353558398210086, 0.935428805076159, 0.9353579924656794, 0.9350081590505747, 0.9358644989820627, 0.9358216180251195, 0.9359718629947076, 0.9362422892680535, 0.9347291130285996, 0.9359976099087641, 0.9354052245616913, 0.9349823754567367, 0.9357035664411691, 0.936298104432913, 0.9358237637923315, 0.9360212156405816, 0.9358173241982093, 0.935815189893429, 0.9351734473155096, 0.9353687167167664, 0.936134968812649, 0.9360448167874262, 0.9365427494049072, 0.9359031457167405, 0.9362851885648874, 0.9360469373372885, 0.9368689702107356, 0.9367981644777151, 0.9359654142306402, 0.9368110597133636, 0.9364654628130106, 0.9355104130048019, 0.9364955196013818, 0.9360641562021695, 0.9361929045273707, 0.936319513962819, 0.9367874356416556, 0.9368689977205716, 0.9362100981749021, 0.9371608770810641, 0.9364397548712217, 0.9365363006408398, 0.936600712629465, 0.9367574040706341, 0.9351713015482976, 0.9365384830878332, 0.9370793012472299, 0.9373154319249667, 0.9369763112985171, 0.9366565140394064, 0.9366136078651135, 0.9372145579411433, 0.9374098525597498, 0.9367981851100922, 0.9370385637650123, 0.9377790116346799, 0.9378369679817786, 0.9365405990527227, 0.9366951378492209, 0.9373647937407861, 0.937171594454692, 0.9372638968320993, 0.9355082649451035, 0.937650244969588, 0.9369677144747514, 0.938208268238948, 0.9372081275169666, 0.9364719069921054, 0.9369526734718909, 0.9372639243419354, 0.9371308455100427, 0.9373304431255047, 0.9362186697813181, 0.9367509277967306, 0.9376073387952951, 0.9373476298955771, 0.9368239182692307, 0.9368475308785071, 0.9372703433036804, 0.9370578917173239, 0.93669727903146, 0.9377747269777151, 0.9367552078687228, 0.9366135688928457, 0.9371158343095046, 0.9378434190383325, 0.9376437939130343, 0.9371265264657828, 0.9378884847347553, 0.9369011681813461, 0.9377532853530004, 0.937010645866394, 0.9370922217002282, 0.9369655618300805, 0.9375622593439542, 0.9381395761783307], 'val_mDice': [0.41011632635043216, 0.41843463193911773, 0.4472042511288936, 0.44098321004555774, 0.44852808805612415, 0.4537483797623561, 0.44895737904768723, 0.45202329410956454, 0.4585240672414119, 0.46867219960460293, 0.44608943794782346, 0.46383024838108283, 0.44617270248440594, 0.46515286885775053, 0.44881749095825046, 0.4673704387476811, 0.47567537742165417, 0.47400110157636494, 0.46766510147314805, 0.47042086204657185, 0.47325966077355236, 0.47393696640546507, 0.4732789463148667, 0.4740642045552914, 0.4846336136643703, 0.4815803373662325, 0.47409123612137943, 0.4885769750063236, 0.48667398668252504, 0.4732073155733255, 0.4693082980811596, 0.4827388014930945, 0.4719206793950154, 0.4797018167491143, 0.4880347211773579, 0.48501096178705877, 0.49133992940187454, 0.4831035824922415, 0.48882130820017594, 0.49279088698900664, 0.48918255934348476, 0.4921609323758345, 0.49086110637738156, 0.4929644505564983, 0.5045181037141726, 0.4923833430959628, 0.49208210523311907, 0.4970310806081845, 0.4898911754672344, 0.49379415666827786, 0.5047509945355929, 0.4997965240707764, 0.5031295645122345, 0.5021470197691367, 0.4978331955006489, 0.4963877642383942, 0.49598390609025955, 0.5063925657707912, 0.49583267305906004, 0.493846228489509, 0.5063743095558423, 0.506753591963878, 0.5043688198694816, 0.49457273517663664, 0.49792615266946644, 0.4915282138838218, 0.5057067865362534, 0.4802618599854983, 0.5062994529994634, 0.5043714212683531, 0.5068441893045719, 0.5013260253920004, 0.5045013341766137, 0.5074228587058874, 0.49847841492066014, 0.5025742082641675, 0.5055826701796972, 0.5028230831600152, 0.49607681311093843, 0.49297253500956756, 0.49528427250110185, 0.4954105455141801, 0.5003781255621177, 0.487836546336229, 0.5037717472475308, 0.5055992451424782, 0.5137349673761771, 0.5021004762787086, 0.494338685216812, 0.512713933793398, 0.4933103285729885, 0.4990523256934606, 0.49965192664128083, 0.48636864670194113, 0.49623719258950305, 0.49510819063736844, 0.5016184569551394, 0.5019276528977431, 0.4899324505374982, 0.5003678202629089, 0.4989071279191054, 0.4879847558645102, 0.5045138308062003, 0.5032013915479183, 0.49446477454442245, 0.5023128940508916, 0.5019902667173972, 0.5010778829455376, 0.5072721007924813, 0.5052837875600045, 0.5019877593104656, 0.4987749789769833, 0.4912072508954085, 0.49488004211049813, 0.49733547465159345, 0.5002308416251953, 0.49942221779089707], 'loss': [1876.0233292629343, 909.9870132999338, 755.8326865828346, 677.8209186551493, 627.3855981373824, 591.9445731418001, 564.6428407976726, 542.2549301185456, 523.1538755562344, 509.93912144792614, 497.1725849678274, 484.4667460015809, 473.146802349701, 463.251460143542, 455.84143814639964, 448.2219684998026, 441.1280051019154, 434.11039031388566, 428.2767253771244, 422.722255068952, 417.2935055897463, 412.42667937813064, 407.4777856826958, 403.035405130236, 398.5564624083105, 394.60527180002634, 390.8896315885208, 386.98491321040575, 384.40664837218117, 381.6415059836294, 378.3907142603275, 374.7272283717142, 372.7835925625642, 368.75478003977804, 367.7748641130461, 363.93265749389457, 360.2615420826904, 360.23842897444183, 355.48753979640793, 354.0628676885478, 353.10428050926976, 349.57442896680334, 346.5819519262499, 346.23619479107526, 342.94048383417777, 341.7347077761345, 339.45551961807155, 337.02833621440135, 336.2782244113696, 334.9612254665466, 332.8544483320262, 330.47821670936105, 329.04211415930513, 326.9945851000299, 325.56766557926557, 324.0965833381611, 323.5461749560849, 321.828302890208, 319.39119403546755, 319.5878840489305, 318.36476324669474, 316.4044944371265, 314.9013010693643, 314.2913070941866, 313.1502926073687, 310.2575481597385, 308.5714740902694, 308.1228731474313, 306.8710781591004, 304.76174974322794, 304.2114094290293, 304.48161688838667, 302.72128700060034, 301.44703173617603, 300.57619722938557, 299.25861746269015, 298.70324767120735, 298.20940086127627, 296.2647078655791, 296.1787504058784, 295.1901152098101, 293.7409551758218, 292.6337340123691, 291.51494237781395, 291.78870079929203, 289.414853418356, 290.4365719481499, 290.24401861519914, 288.364402591572, 286.757154746699, 286.28487656510737, 284.4459749654706, 284.18126305616465, 283.6442680664963, 282.38085986472225, 282.8699663839997, 281.78683012846506, 280.44082208732107, 279.43632648471186, 279.1628376877111, 278.39329193742867, 277.00705196764443, 277.80780134840467, 276.55313069963546, 275.9866584018622, 275.70321260470035, 274.67690959685206, 273.9285281331823, 273.09170144811213, 272.6430976921855, 271.6736833424099, 271.29431063405684, 269.6705942158328, 270.66153273969013, 268.29710405563105, 268.84829409074314, 268.94855660116013], 'acc': [0.904705737730591, 0.9205441568309637, 0.9260654477992644, 0.929003896527896, 0.9308365731675565, 0.9320299435803056, 0.9329402982655414, 0.9337115538116971, 0.9342775637512221, 0.9348391532557131, 0.9349338093125423, 0.9355314383644862, 0.9357749747689069, 0.9362390254912183, 0.9364162276044693, 0.93644768411379, 0.936544396660045, 0.93685314823624, 0.9369382655599686, 0.9371202276233025, 0.9372427960026146, 0.9374195898765459, 0.9374301100606178, 0.9371560097048558, 0.937419796884912, 0.9376247943156784, 0.9375721945222163, 0.9373543757821959, 0.9373866507051221, 0.937581750252233, 0.9374477719398681, 0.9376676927564506, 0.9377496879907549, 0.937812844518255, 0.9378647646274688, 0.9377497691603743, 0.9380225747381201, 0.9380087620502006, 0.9378504327145448, 0.9381684283593215, 0.9381192267837092, 0.9381495300093932, 0.9382524177903433, 0.9379272433232306, 0.9379636567313766, 0.9378176824056849, 0.9376622628958959, 0.9375966719614451, 0.9378430452072388, 0.9377841905651305, 0.9382176899188759, 0.9383596887307492, 0.9383338376471535, 0.9384953564607184, 0.9379519470490224, 0.9383508421547307, 0.9383276992262833, 0.9382624880948498, 0.9383662382933878, 0.9383024640225357, 0.9387527001274585, 0.938504865828513, 0.938555610715315, 0.938623257028785, 0.9384621511765163, 0.9387862758421869, 0.9386440683233555, 0.9385906888430908, 0.9386147352191978, 0.9384721364029921, 0.9385912663369538, 0.9388243986662492, 0.9389996300937175, 0.9390117752258489, 0.9388161280833959, 0.9385478695929957, 0.9387053324982083, 0.9389976739366699, 0.9388193791448921, 0.9389208485134015, 0.9391170509086042, 0.9392069885951285, 0.939331536109208, 0.939453841113279, 0.9392978396625039, 0.9390965272533073, 0.9394944567175948, 0.9389135208306228, 0.9392981914524925, 0.939509526435205, 0.9392808565330013, 0.9397849027580367, 0.9400131014190916, 0.9398515193948093, 0.9396183649618269, 0.9399254473056299, 0.9398950632126648, 0.9398479776046905, 0.9399680169286361, 0.9400732922980588, 0.9400537989186392, 0.939902368384974, 0.9394837520686087, 0.9397674084512287, 0.9396925773566075, 0.93987189909854, 0.9402934030986059, 0.9404580456452166, 0.9400990269428842, 0.9400641761351191, 0.9403440852584318, 0.9403682291963977, 0.9405273003386009, 0.9403302691183572, 0.9403620147786435, 0.940613533846294, 0.9407704788787794], 'mDice': [0.34050909885014047, 0.5692750871329909, 0.6337125150411758, 0.6684569047955825, 0.6918384307239764, 0.7087530276272489, 0.721143846685328, 0.730951969978456, 0.7406082270132883, 0.7469992370147234, 0.753033066229067, 0.7589978422668272, 0.7643902636559414, 0.7693888497706611, 0.7728883994303979, 0.7765566774106362, 0.7800286708475753, 0.783792913091982, 0.7862547015028994, 0.7888164969318678, 0.7918744418802026, 0.7940261050980436, 0.7968486415980366, 0.7987828680282257, 0.801116985290965, 0.8031562091316298, 0.8046582509734078, 0.8067523702246604, 0.8079700963826766, 0.8096353469668505, 0.8111399739450231, 0.8128960523385025, 0.8141142226316541, 0.815896464737647, 0.8165927749052596, 0.8182501216430809, 0.8201018702793658, 0.8204431192610829, 0.8225919961665462, 0.823111859544731, 0.8238307995944845, 0.8255106916091632, 0.8271628678378217, 0.8273070579875519, 0.8288356316361185, 0.8294034462006761, 0.8306622850843256, 0.8317040767406259, 0.8320826263013475, 0.8330333669896078, 0.8337487125489079, 0.8350373395230513, 0.8360088844751394, 0.8367821759791938, 0.8375956869252899, 0.838457627511053, 0.8386644147082931, 0.8394580489648265, 0.8406592533507713, 0.840656654977451, 0.8414539373977525, 0.8420120850047381, 0.8430568291276163, 0.8435522411996056, 0.843795711831678, 0.845515483465514, 0.8459452252254752, 0.8464451114882691, 0.8471522808052963, 0.8481088576694592, 0.8483629563104773, 0.8484614395978738, 0.8491158672972358, 0.8497722273678574, 0.8500623303806277, 0.8509655708999725, 0.851043555378793, 0.8513700132944768, 0.8521964364657375, 0.8526740368690304, 0.8528974393653571, 0.8535155634109158, 0.8541069742961089, 0.8547234809850509, 0.8547374845089799, 0.8558400410364818, 0.8555302554079277, 0.855649151936631, 0.8564749421926483, 0.8574492362090211, 0.8572700645093998, 0.8583981389050817, 0.8587305957921634, 0.8589207910473338, 0.8596109877892177, 0.8591487339410815, 0.8596874112563083, 0.8604608171267405, 0.860826938934875, 0.8610851822782902, 0.8616237057032625, 0.8621112199921588, 0.8619407767311933, 0.8625828378382814, 0.8625232778076622, 0.8630291629539011, 0.8633465844140461, 0.8637168256490859, 0.8642386742582798, 0.8645557769108091, 0.8650054389410415, 0.8650404853067923, 0.8658673162446254, 0.8656039036893541, 0.8667043769952172, 0.8661092929071379, 0.8665676783736996]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.21s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.99s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:38,  1.40s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:59,  1.48s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:53,  1.47s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:16,  1.55s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<06:58,  1.50s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:19,  1.58s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:48,  1.68s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:03,  1.75s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:05,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:19,  1.82s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:18,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:19,  1.84s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:26,  1.87s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:26,  1.87s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:29,  1.89s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:20,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:19,  1.87s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<08:13,  1.86s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:18,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:16,  1.88s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:10,  1.86s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:12,  1.88s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<08:07,  1.87s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<08:11,  1.89s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:12,  1.90s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<08:10,  1.90s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:58,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:57,  1.87s/it]predicting train subjects:  11%|█         | 30/285 [00:54<07:52,  1.85s/it]predicting train subjects:  11%|█         | 31/285 [00:56<07:51,  1.86s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:43,  1.83s/it]predicting train subjects:  12%|█▏        | 33/285 [00:59<07:37,  1.82s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:34,  1.81s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:28,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:26,  1.79s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:17,  1.76s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:18,  1.78s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:17,  1.78s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<07:11,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<07:06,  1.76s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:00,  1.74s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<06:54,  1.72s/it]predicting train subjects:  16%|█▌        | 45/285 [01:20<06:59,  1.75s/it]predicting train subjects:  16%|█▌        | 46/285 [01:22<06:41,  1.68s/it]predicting train subjects:  16%|█▋        | 47/285 [01:23<06:23,  1.61s/it]predicting train subjects:  17%|█▋        | 48/285 [01:25<06:14,  1.58s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<06:15,  1.59s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<06:10,  1.58s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<06:07,  1.57s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<06:10,  1.59s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<06:06,  1.58s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<06:02,  1.57s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:04,  1.58s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:12,  1.63s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:18,  1.66s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:09,  1.63s/it]predicting train subjects:  21%|██        | 59/285 [01:42<05:59,  1.59s/it]predicting train subjects:  21%|██        | 60/285 [01:44<05:56,  1.59s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<05:48,  1.56s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<05:46,  1.55s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<05:46,  1.56s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<05:41,  1.55s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<05:54,  1.61s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:02,  1.65s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<05:52,  1.62s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<05:45,  1.59s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<05:44,  1.59s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<05:41,  1.59s/it]predicting train subjects:  25%|██▍       | 71/285 [02:01<05:39,  1.59s/it]predicting train subjects:  25%|██▌       | 72/285 [02:03<05:35,  1.58s/it]predicting train subjects:  26%|██▌       | 73/285 [02:04<05:30,  1.56s/it]predicting train subjects:  26%|██▌       | 74/285 [02:06<05:26,  1.55s/it]predicting train subjects:  26%|██▋       | 75/285 [02:08<05:25,  1.55s/it]predicting train subjects:  27%|██▋       | 76/285 [02:09<05:23,  1.55s/it]predicting train subjects:  27%|██▋       | 77/285 [02:11<05:23,  1.55s/it]predicting train subjects:  27%|██▋       | 78/285 [02:12<05:21,  1.55s/it]predicting train subjects:  28%|██▊       | 79/285 [02:14<05:16,  1.54s/it]predicting train subjects:  28%|██▊       | 80/285 [02:15<05:15,  1.54s/it]predicting train subjects:  28%|██▊       | 81/285 [02:17<05:14,  1.54s/it]predicting train subjects:  29%|██▉       | 82/285 [02:18<05:11,  1.54s/it]predicting train subjects:  29%|██▉       | 83/285 [02:20<05:10,  1.54s/it]predicting train subjects:  29%|██▉       | 84/285 [02:21<05:09,  1.54s/it]predicting train subjects:  30%|██▉       | 85/285 [02:23<05:19,  1.60s/it]predicting train subjects:  30%|███       | 86/285 [02:25<05:25,  1.64s/it]predicting train subjects:  31%|███       | 87/285 [02:27<05:29,  1.67s/it]predicting train subjects:  31%|███       | 88/285 [02:28<05:33,  1.69s/it]predicting train subjects:  31%|███       | 89/285 [02:30<05:36,  1.72s/it]predicting train subjects:  32%|███▏      | 90/285 [02:32<05:34,  1.72s/it]predicting train subjects:  32%|███▏      | 91/285 [02:34<05:31,  1.71s/it]predicting train subjects:  32%|███▏      | 92/285 [02:35<05:33,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:37<05:39,  1.77s/it]predicting train subjects:  33%|███▎      | 94/285 [02:39<05:35,  1.76s/it]predicting train subjects:  33%|███▎      | 95/285 [02:41<05:30,  1.74s/it]predicting train subjects:  34%|███▎      | 96/285 [02:42<05:28,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:44<05:29,  1.75s/it]predicting train subjects:  34%|███▍      | 98/285 [02:46<05:28,  1.76s/it]predicting train subjects:  35%|███▍      | 99/285 [02:48<05:30,  1.78s/it]predicting train subjects:  35%|███▌      | 100/285 [02:49<05:27,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [02:51<05:27,  1.78s/it]predicting train subjects:  36%|███▌      | 102/285 [02:53<05:23,  1.77s/it]predicting train subjects:  36%|███▌      | 103/285 [02:55<05:23,  1.77s/it]predicting train subjects:  36%|███▋      | 104/285 [02:56<05:17,  1.76s/it]predicting train subjects:  37%|███▋      | 105/285 [02:58<05:15,  1.75s/it]predicting train subjects:  37%|███▋      | 106/285 [03:00<05:10,  1.74s/it]predicting train subjects:  38%|███▊      | 107/285 [03:02<05:08,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:03<05:04,  1.72s/it]predicting train subjects:  38%|███▊      | 109/285 [03:05<04:59,  1.70s/it]predicting train subjects:  39%|███▊      | 110/285 [03:07<04:57,  1.70s/it]predicting train subjects:  39%|███▉      | 111/285 [03:08<04:56,  1.71s/it]predicting train subjects:  39%|███▉      | 112/285 [03:10<04:53,  1.70s/it]predicting train subjects:  40%|███▉      | 113/285 [03:12<04:52,  1.70s/it]predicting train subjects:  40%|████      | 114/285 [03:14<04:51,  1.70s/it]predicting train subjects:  40%|████      | 115/285 [03:15<04:51,  1.71s/it]predicting train subjects:  41%|████      | 116/285 [03:17<04:48,  1.71s/it]predicting train subjects:  41%|████      | 117/285 [03:19<04:45,  1.70s/it]predicting train subjects:  41%|████▏     | 118/285 [03:20<04:45,  1.71s/it]predicting train subjects:  42%|████▏     | 119/285 [03:22<04:45,  1.72s/it]predicting train subjects:  42%|████▏     | 120/285 [03:24<04:45,  1.73s/it]predicting train subjects:  42%|████▏     | 121/285 [03:25<04:33,  1.67s/it]predicting train subjects:  43%|████▎     | 122/285 [03:27<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:28<04:11,  1.55s/it]predicting train subjects:  44%|████▎     | 124/285 [03:30<04:16,  1.59s/it]predicting train subjects:  44%|████▍     | 125/285 [03:32<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 126/285 [03:33<04:09,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:35<04:05,  1.55s/it]predicting train subjects:  45%|████▍     | 128/285 [03:36<04:01,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:38<03:57,  1.52s/it]predicting train subjects:  46%|████▌     | 130/285 [03:39<04:03,  1.57s/it]predicting train subjects:  46%|████▌     | 131/285 [03:41<04:00,  1.56s/it]predicting train subjects:  46%|████▋     | 132/285 [03:42<03:57,  1.55s/it]predicting train subjects:  47%|████▋     | 133/285 [03:44<03:57,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [03:45<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 135/285 [03:47<03:59,  1.60s/it]predicting train subjects:  48%|████▊     | 136/285 [03:49<03:58,  1.60s/it]predicting train subjects:  48%|████▊     | 137/285 [03:50<03:55,  1.59s/it]predicting train subjects:  48%|████▊     | 138/285 [03:52<03:57,  1.62s/it]predicting train subjects:  49%|████▉     | 139/285 [03:54<03:53,  1.60s/it]predicting train subjects:  49%|████▉     | 140/285 [03:55<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [03:57<03:43,  1.55s/it]predicting train subjects:  50%|████▉     | 142/285 [03:58<03:36,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [03:59<03:29,  1.48s/it]predicting train subjects:  51%|█████     | 144/285 [04:01<03:25,  1.46s/it]predicting train subjects:  51%|█████     | 145/285 [04:02<03:24,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:04<03:21,  1.45s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:05<03:19,  1.44s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:07<03:16,  1.43s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:08<03:12,  1.41s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:09<03:17,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:11<03:17,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:12<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:14<03:15,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:15<03:14,  1.49s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:17<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:18<03:06,  1.44s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:20<03:03,  1.43s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:21<03:00,  1.42s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:22<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:24<02:54,  1.40s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:25<02:52,  1.39s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:27<02:49,  1.38s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:28<02:56,  1.45s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:30<02:57,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:31<02:57,  1.48s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:33<02:57,  1.49s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:34<02:58,  1.52s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:36<02:57,  1.52s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:37<02:55,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:39<02:53,  1.51s/it]predicting train subjects:  60%|██████    | 171/285 [04:41<03:00,  1.58s/it]predicting train subjects:  60%|██████    | 172/285 [04:42<03:00,  1.60s/it]predicting train subjects:  61%|██████    | 173/285 [04:44<02:58,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [04:45<02:55,  1.58s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:48<02:48,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:50<02:49,  1.57s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:53<02:43,  1.55s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:54<02:40,  1.53s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:56<02:35,  1.49s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:57<02:33,  1.49s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:59<02:28,  1.46s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:00<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:02<02:23,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:03<02:22,  1.44s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:04<02:20,  1.43s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:06<02:23,  1.48s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:07<02:20,  1.46s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:09<02:20,  1.48s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:10<02:18,  1.48s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:12<02:18,  1.49s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:13<02:14,  1.46s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:15<02:15,  1.48s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:16<02:13,  1.49s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:18<02:18,  1.56s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:20<02:25,  1.65s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:22<02:26,  1.68s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:24<02:27,  1.72s/it]predicting train subjects:  70%|███████   | 200/285 [05:25<02:27,  1.73s/it]predicting train subjects:  71%|███████   | 201/285 [05:27<02:26,  1.75s/it]predicting train subjects:  71%|███████   | 202/285 [05:29<02:28,  1.78s/it]predicting train subjects:  71%|███████   | 203/285 [05:31<02:25,  1.77s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:32<02:22,  1.75s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:34<02:19,  1.75s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:36<02:20,  1.77s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:38<02:18,  1.77s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:39<02:11,  1.71s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:41<02:06,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:43<02:04,  1.66s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:44<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:46<01:57,  1.61s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:47<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:49<01:49,  1.54s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:50<01:43,  1.48s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:51<01:40,  1.45s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:53<01:36,  1.42s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:54<01:34,  1.41s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:55<01:32,  1.40s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:57<01:30,  1.40s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:58<01:29,  1.39s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:00<01:27,  1.39s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:01<01:27,  1.41s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:02<01:25,  1.40s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:04<01:24,  1.40s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:05<01:22,  1.40s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:07<01:21,  1.40s/it]predicting train subjects:  80%|████████  | 228/285 [06:08<01:19,  1.40s/it]predicting train subjects:  80%|████████  | 229/285 [06:09<01:17,  1.38s/it]predicting train subjects:  81%|████████  | 230/285 [06:11<01:16,  1.38s/it]predicting train subjects:  81%|████████  | 231/285 [06:12<01:14,  1.38s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:14<01:18,  1.48s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:16<01:22,  1.59s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:17<01:23,  1.64s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:19<01:24,  1.68s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:21<01:25,  1.74s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:23<01:24,  1.75s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:25<01:21,  1.74s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:27<01:21,  1.78s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:28<01:20,  1.79s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:30<01:17,  1.76s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:32<01:15,  1.77s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:34<01:14,  1.78s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:35<01:12,  1.77s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:37<01:09,  1.74s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:39<01:08,  1.75s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:40<01:05,  1.73s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:42<01:04,  1.73s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:44<01:02,  1.74s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:45<00:56,  1.61s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:47<00:51,  1.51s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:48<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:49<00:45,  1.41s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:50<00:42,  1.38s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:52<00:40,  1.36s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:53<00:38,  1.34s/it]predicting train subjects:  90%|█████████ | 257/285 [06:55<00:38,  1.36s/it]predicting train subjects:  91%|█████████ | 258/285 [06:56<00:36,  1.35s/it]predicting train subjects:  91%|█████████ | 259/285 [06:57<00:34,  1.34s/it]predicting train subjects:  91%|█████████ | 260/285 [06:58<00:33,  1.33s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:00<00:31,  1.33s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:01<00:30,  1.34s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:02<00:29,  1.34s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:04<00:27,  1.33s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:05<00:26,  1.34s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:07<00:25,  1.36s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:08<00:24,  1.34s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:10<00:24,  1.45s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:11<00:24,  1.53s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:13<00:23,  1.59s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:15<00:22,  1.63s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:17<00:21,  1.67s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:18<00:20,  1.71s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:20<00:18,  1.71s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:22<00:17,  1.72s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:24<00:15,  1.73s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:25<00:13,  1.74s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:27<00:12,  1.75s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:29<00:10,  1.75s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:31<00:08,  1.76s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:32<00:07,  1.76s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:34<00:05,  1.74s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:36<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:38<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 285/285 [07:39<00:00,  1.73s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:07,  1.29s/it]Loading train:   1%|          | 2/285 [00:02<06:13,  1.32s/it]Loading train:   1%|          | 3/285 [00:04<06:13,  1.32s/it]Loading train:   1%|▏         | 4/285 [00:05<06:44,  1.44s/it]Loading train:   2%|▏         | 5/285 [00:06<06:09,  1.32s/it]Loading train:   2%|▏         | 6/285 [00:08<06:17,  1.35s/it]Loading train:   2%|▏         | 7/285 [00:09<06:36,  1.43s/it]Loading train:   3%|▎         | 8/285 [00:11<06:50,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:12<06:33,  1.43s/it]Loading train:   4%|▎         | 10/285 [00:13<05:54,  1.29s/it]Loading train:   4%|▍         | 11/285 [00:14<05:25,  1.19s/it]Loading train:   4%|▍         | 12/285 [00:15<05:05,  1.12s/it]Loading train:   5%|▍         | 13/285 [00:16<05:04,  1.12s/it]Loading train:   5%|▍         | 14/285 [00:17<04:49,  1.07s/it]Loading train:   5%|▌         | 15/285 [00:18<04:46,  1.06s/it]Loading train:   6%|▌         | 16/285 [00:19<04:38,  1.03s/it]Loading train:   6%|▌         | 17/285 [00:20<04:32,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:21<04:32,  1.02s/it]Loading train:   7%|▋         | 19/285 [00:22<04:27,  1.01s/it]Loading train:   7%|▋         | 20/285 [00:23<04:24,  1.00it/s]Loading train:   7%|▋         | 21/285 [00:24<04:23,  1.00it/s]Loading train:   8%|▊         | 22/285 [00:25<04:19,  1.01it/s]Loading train:   8%|▊         | 23/285 [00:26<04:15,  1.03it/s]Loading train:   8%|▊         | 24/285 [00:27<04:12,  1.03it/s]Loading train:   9%|▉         | 25/285 [00:28<04:21,  1.01s/it]Loading train:   9%|▉         | 26/285 [00:29<04:22,  1.01s/it]Loading train:   9%|▉         | 27/285 [00:30<04:23,  1.02s/it]Loading train:  10%|▉         | 28/285 [00:31<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:32<04:21,  1.02s/it]Loading train:  11%|█         | 30/285 [00:33<04:13,  1.01it/s]Loading train:  11%|█         | 31/285 [00:34<04:06,  1.03it/s]Loading train:  11%|█         | 32/285 [00:35<04:02,  1.04it/s]Loading train:  12%|█▏        | 33/285 [00:36<04:00,  1.05it/s]Loading train:  12%|█▏        | 34/285 [00:37<03:59,  1.05it/s]Loading train:  12%|█▏        | 35/285 [00:38<03:59,  1.04it/s]Loading train:  13%|█▎        | 36/285 [00:39<03:53,  1.07it/s]Loading train:  13%|█▎        | 37/285 [00:40<03:48,  1.08it/s]Loading train:  13%|█▎        | 38/285 [00:40<03:46,  1.09it/s]Loading train:  14%|█▎        | 39/285 [00:41<03:37,  1.13it/s]Loading train:  14%|█▍        | 40/285 [00:42<03:33,  1.15it/s]Loading train:  14%|█▍        | 41/285 [00:43<03:34,  1.14it/s]Loading train:  15%|█▍        | 42/285 [00:44<03:41,  1.10it/s]Loading train:  15%|█▌        | 43/285 [00:45<03:41,  1.09it/s]Loading train:  15%|█▌        | 44/285 [00:46<03:46,  1.06it/s]Loading train:  16%|█▌        | 45/285 [00:47<03:49,  1.05it/s]Loading train:  16%|█▌        | 46/285 [00:48<03:41,  1.08it/s]Loading train:  16%|█▋        | 47/285 [00:49<03:30,  1.13it/s]Loading train:  17%|█▋        | 48/285 [00:49<03:22,  1.17it/s]Loading train:  17%|█▋        | 49/285 [00:50<03:33,  1.11it/s]Loading train:  18%|█▊        | 50/285 [00:51<03:29,  1.12it/s]Loading train:  18%|█▊        | 51/285 [00:52<03:24,  1.15it/s]Loading train:  18%|█▊        | 52/285 [00:53<03:14,  1.20it/s]Loading train:  19%|█▊        | 53/285 [00:54<03:13,  1.20it/s]Loading train:  19%|█▉        | 54/285 [00:54<03:05,  1.25it/s]Loading train:  19%|█▉        | 55/285 [00:55<03:09,  1.21it/s]Loading train:  20%|█▉        | 56/285 [00:56<03:03,  1.25it/s]Loading train:  20%|██        | 57/285 [00:57<03:01,  1.25it/s]Loading train:  20%|██        | 58/285 [00:57<02:52,  1.32it/s]Loading train:  21%|██        | 59/285 [00:58<02:48,  1.34it/s]Loading train:  21%|██        | 60/285 [00:59<02:49,  1.33it/s]Loading train:  21%|██▏       | 61/285 [01:00<02:44,  1.36it/s]Loading train:  22%|██▏       | 62/285 [01:00<02:46,  1.34it/s]Loading train:  22%|██▏       | 63/285 [01:01<02:43,  1.36it/s]Loading train:  22%|██▏       | 64/285 [01:02<03:17,  1.12it/s]Loading train:  23%|██▎       | 65/285 [01:04<03:59,  1.09s/it]Loading train:  23%|██▎       | 66/285 [01:05<04:17,  1.18s/it]Loading train:  24%|██▎       | 67/285 [01:06<03:59,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:07<03:40,  1.01s/it]Loading train:  24%|██▍       | 69/285 [01:08<03:31,  1.02it/s]Loading train:  25%|██▍       | 70/285 [01:09<03:19,  1.08it/s]Loading train:  25%|██▍       | 71/285 [01:10<03:13,  1.11it/s]Loading train:  25%|██▌       | 72/285 [01:10<03:03,  1.16it/s]Loading train:  26%|██▌       | 73/285 [01:11<03:00,  1.18it/s]Loading train:  26%|██▌       | 74/285 [01:12<02:52,  1.22it/s]Loading train:  26%|██▋       | 75/285 [01:13<02:51,  1.23it/s]Loading train:  27%|██▋       | 76/285 [01:14<02:49,  1.23it/s]Loading train:  27%|██▋       | 77/285 [01:14<02:45,  1.26it/s]Loading train:  27%|██▋       | 78/285 [01:15<02:47,  1.24it/s]Loading train:  28%|██▊       | 79/285 [01:16<02:45,  1.25it/s]Loading train:  28%|██▊       | 80/285 [01:17<02:46,  1.23it/s]Loading train:  28%|██▊       | 81/285 [01:18<02:47,  1.22it/s]Loading train:  29%|██▉       | 82/285 [01:18<02:43,  1.24it/s]Loading train:  29%|██▉       | 83/285 [01:19<02:41,  1.25it/s]Loading train:  29%|██▉       | 84/285 [01:20<02:44,  1.22it/s]Loading train:  30%|██▉       | 85/285 [01:21<02:48,  1.18it/s]Loading train:  30%|███       | 86/285 [01:22<02:55,  1.13it/s]Loading train:  31%|███       | 87/285 [01:23<02:58,  1.11it/s]Loading train:  31%|███       | 88/285 [01:24<02:55,  1.13it/s]Loading train:  31%|███       | 89/285 [01:25<02:55,  1.12it/s]Loading train:  32%|███▏      | 90/285 [01:26<02:57,  1.10it/s]Loading train:  32%|███▏      | 91/285 [01:27<03:01,  1.07it/s]Loading train:  32%|███▏      | 92/285 [01:27<02:59,  1.07it/s]Loading train:  33%|███▎      | 93/285 [01:29<03:10,  1.01it/s]Loading train:  33%|███▎      | 94/285 [01:30<03:11,  1.00s/it]Loading train:  33%|███▎      | 95/285 [01:30<03:01,  1.05it/s]Loading train:  34%|███▎      | 96/285 [01:32<03:08,  1.00it/s]Loading train:  34%|███▍      | 97/285 [01:32<03:00,  1.04it/s]Loading train:  34%|███▍      | 98/285 [01:34<03:04,  1.02it/s]Loading train:  35%|███▍      | 99/285 [01:34<02:56,  1.06it/s]Loading train:  35%|███▌      | 100/285 [01:35<02:59,  1.03it/s]Loading train:  35%|███▌      | 101/285 [01:36<02:58,  1.03it/s]Loading train:  36%|███▌      | 102/285 [01:37<02:54,  1.05it/s]Loading train:  36%|███▌      | 103/285 [01:38<02:52,  1.05it/s]Loading train:  36%|███▋      | 104/285 [01:39<02:51,  1.05it/s]Loading train:  37%|███▋      | 105/285 [01:40<02:50,  1.05it/s]Loading train:  37%|███▋      | 106/285 [01:41<02:46,  1.07it/s]Loading train:  38%|███▊      | 107/285 [01:42<02:45,  1.07it/s]Loading train:  38%|███▊      | 108/285 [01:43<02:43,  1.08it/s]Loading train:  38%|███▊      | 109/285 [01:44<02:39,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:45<02:33,  1.14it/s]Loading train:  39%|███▉      | 111/285 [01:45<02:34,  1.12it/s]Loading train:  39%|███▉      | 112/285 [01:46<02:29,  1.16it/s]Loading train:  40%|███▉      | 113/285 [01:47<02:34,  1.11it/s]Loading train:  40%|████      | 114/285 [01:48<02:28,  1.15it/s]Loading train:  40%|████      | 115/285 [01:49<02:26,  1.16it/s]Loading train:  41%|████      | 116/285 [01:50<02:23,  1.18it/s]Loading train:  41%|████      | 117/285 [01:51<02:23,  1.17it/s]Loading train:  41%|████▏     | 118/285 [01:51<02:20,  1.19it/s]Loading train:  42%|████▏     | 119/285 [01:52<02:19,  1.19it/s]Loading train:  42%|████▏     | 120/285 [01:53<02:21,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:54<02:40,  1.02it/s]Loading train:  43%|████▎     | 122/285 [01:55<02:45,  1.02s/it]Loading train:  43%|████▎     | 123/285 [01:57<02:52,  1.06s/it]Loading train:  44%|████▎     | 124/285 [01:57<02:40,  1.00it/s]Loading train:  44%|████▍     | 125/285 [01:58<02:28,  1.08it/s]Loading train:  44%|████▍     | 126/285 [01:59<02:24,  1.10it/s]Loading train:  45%|████▍     | 127/285 [02:00<02:21,  1.12it/s]Loading train:  45%|████▍     | 128/285 [02:01<02:25,  1.08it/s]Loading train:  45%|████▌     | 129/285 [02:02<02:20,  1.11it/s]Loading train:  46%|████▌     | 130/285 [02:03<02:27,  1.05it/s]Loading train:  46%|████▌     | 131/285 [02:04<02:31,  1.02it/s]Loading train:  46%|████▋     | 132/285 [02:05<02:36,  1.02s/it]Loading train:  47%|████▋     | 133/285 [02:06<02:27,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:07<02:19,  1.09it/s]Loading train:  47%|████▋     | 135/285 [02:08<02:19,  1.08it/s]Loading train:  48%|████▊     | 136/285 [02:09<02:30,  1.01s/it]Loading train:  48%|████▊     | 137/285 [02:10<02:31,  1.02s/it]Loading train:  48%|████▊     | 138/285 [02:11<02:33,  1.04s/it]Loading train:  49%|████▉     | 139/285 [02:12<02:20,  1.04it/s]Loading train:  49%|████▉     | 140/285 [02:13<02:11,  1.10it/s]Loading train:  49%|████▉     | 141/285 [02:13<02:06,  1.14it/s]Loading train:  50%|████▉     | 142/285 [02:14<02:05,  1.14it/s]Loading train:  50%|█████     | 143/285 [02:15<02:03,  1.15it/s]Loading train:  51%|█████     | 144/285 [02:16<02:02,  1.15it/s]Loading train:  51%|█████     | 145/285 [02:17<02:15,  1.03it/s]Loading train:  51%|█████     | 146/285 [02:18<02:09,  1.07it/s]Loading train:  52%|█████▏    | 147/285 [02:19<02:24,  1.04s/it]Loading train:  52%|█████▏    | 148/285 [02:20<02:14,  1.02it/s]Loading train:  52%|█████▏    | 149/285 [02:21<02:05,  1.08it/s]Loading train:  53%|█████▎    | 150/285 [02:22<01:52,  1.19it/s]Loading train:  53%|█████▎    | 151/285 [02:22<01:46,  1.26it/s]Loading train:  53%|█████▎    | 152/285 [02:23<01:42,  1.30it/s]Loading train:  54%|█████▎    | 153/285 [02:24<01:36,  1.36it/s]Loading train:  54%|█████▍    | 154/285 [02:24<01:37,  1.34it/s]Loading train:  54%|█████▍    | 155/285 [02:25<01:40,  1.30it/s]Loading train:  55%|█████▍    | 156/285 [02:26<01:42,  1.26it/s]Loading train:  55%|█████▌    | 157/285 [02:27<01:46,  1.20it/s]Loading train:  55%|█████▌    | 158/285 [02:28<02:03,  1.03it/s]Loading train:  56%|█████▌    | 159/285 [02:30<02:12,  1.05s/it]Loading train:  56%|█████▌    | 160/285 [02:31<02:17,  1.10s/it]Loading train:  56%|█████▋    | 161/285 [02:32<02:19,  1.13s/it]Loading train:  57%|█████▋    | 162/285 [02:33<02:15,  1.10s/it]Loading train:  57%|█████▋    | 163/285 [02:34<02:08,  1.05s/it]Loading train:  58%|█████▊    | 164/285 [02:35<02:05,  1.04s/it]Loading train:  58%|█████▊    | 165/285 [02:36<01:59,  1.01it/s]Loading train:  58%|█████▊    | 166/285 [02:37<02:00,  1.01s/it]Loading train:  59%|█████▊    | 167/285 [02:38<02:09,  1.10s/it]Loading train:  59%|█████▉    | 168/285 [02:39<02:08,  1.10s/it]Loading train:  59%|█████▉    | 169/285 [02:41<02:13,  1.15s/it]Loading train:  60%|█████▉    | 170/285 [02:41<02:04,  1.09s/it]Loading train:  60%|██████    | 171/285 [02:43<02:03,  1.08s/it]Loading train:  60%|██████    | 172/285 [02:44<02:08,  1.14s/it]Loading train:  61%|██████    | 173/285 [02:45<02:11,  1.17s/it]Loading train:  61%|██████    | 174/285 [02:46<02:09,  1.16s/it]Loading train:  61%|██████▏   | 175/285 [02:47<02:09,  1.18s/it]Loading train:  62%|██████▏   | 176/285 [02:49<02:16,  1.25s/it]Loading train:  62%|██████▏   | 177/285 [02:51<02:33,  1.42s/it]Loading train:  62%|██████▏   | 178/285 [02:52<02:14,  1.25s/it]Loading train:  63%|██████▎   | 179/285 [02:53<02:07,  1.20s/it]Loading train:  63%|██████▎   | 180/285 [02:54<01:58,  1.13s/it]Loading train:  64%|██████▎   | 181/285 [02:55<01:51,  1.08s/it]Loading train:  64%|██████▍   | 182/285 [02:56<01:56,  1.13s/it]Loading train:  64%|██████▍   | 183/285 [02:57<01:47,  1.06s/it]Loading train:  65%|██████▍   | 184/285 [02:58<01:41,  1.01s/it]Loading train:  65%|██████▍   | 185/285 [02:58<01:35,  1.04it/s]Loading train:  65%|██████▌   | 186/285 [02:59<01:33,  1.06it/s]Loading train:  66%|██████▌   | 187/285 [03:00<01:27,  1.12it/s]Loading train:  66%|██████▌   | 188/285 [03:01<01:23,  1.16it/s]Loading train:  66%|██████▋   | 189/285 [03:02<01:21,  1.17it/s]Loading train:  67%|██████▋   | 190/285 [03:03<01:23,  1.13it/s]Loading train:  67%|██████▋   | 191/285 [03:04<01:31,  1.02it/s]Loading train:  67%|██████▋   | 192/285 [03:05<01:26,  1.07it/s]Loading train:  68%|██████▊   | 193/285 [03:06<01:25,  1.08it/s]Loading train:  68%|██████▊   | 194/285 [03:07<01:23,  1.08it/s]Loading train:  68%|██████▊   | 195/285 [03:07<01:18,  1.14it/s]Loading train:  69%|██████▉   | 196/285 [03:08<01:22,  1.08it/s]Loading train:  69%|██████▉   | 197/285 [03:09<01:21,  1.08it/s]Loading train:  69%|██████▉   | 198/285 [03:10<01:28,  1.02s/it]Loading train:  70%|██████▉   | 199/285 [03:12<01:35,  1.11s/it]Loading train:  70%|███████   | 200/285 [03:13<01:40,  1.18s/it]Loading train:  71%|███████   | 201/285 [03:14<01:41,  1.21s/it]Loading train:  71%|███████   | 202/285 [03:16<01:49,  1.32s/it]Loading train:  71%|███████   | 203/285 [03:17<01:44,  1.27s/it]Loading train:  72%|███████▏  | 204/285 [03:18<01:42,  1.27s/it]Loading train:  72%|███████▏  | 205/285 [03:19<01:32,  1.15s/it]Loading train:  72%|███████▏  | 206/285 [03:20<01:31,  1.16s/it]Loading train:  73%|███████▎  | 207/285 [03:22<01:34,  1.21s/it]Loading train:  73%|███████▎  | 208/285 [03:23<01:26,  1.13s/it]Loading train:  73%|███████▎  | 209/285 [03:24<01:20,  1.06s/it]Loading train:  74%|███████▎  | 210/285 [03:25<01:18,  1.04s/it]Loading train:  74%|███████▍  | 211/285 [03:26<01:13,  1.01it/s]Loading train:  74%|███████▍  | 212/285 [03:27<01:15,  1.03s/it]Loading train:  75%|███████▍  | 213/285 [03:28<01:23,  1.15s/it]Loading train:  75%|███████▌  | 214/285 [03:30<01:30,  1.27s/it]Loading train:  75%|███████▌  | 215/285 [03:31<01:23,  1.20s/it]Loading train:  76%|███████▌  | 216/285 [03:32<01:16,  1.11s/it]Loading train:  76%|███████▌  | 217/285 [03:32<01:11,  1.05s/it]Loading train:  76%|███████▋  | 218/285 [03:33<01:06,  1.01it/s]Loading train:  77%|███████▋  | 219/285 [03:34<01:04,  1.02it/s]Loading train:  77%|███████▋  | 220/285 [03:36<01:11,  1.09s/it]Loading train:  78%|███████▊  | 221/285 [03:36<01:04,  1.01s/it]Loading train:  78%|███████▊  | 222/285 [03:38<01:07,  1.08s/it]Loading train:  78%|███████▊  | 223/285 [03:38<01:01,  1.01it/s]Loading train:  79%|███████▊  | 224/285 [03:39<00:59,  1.02it/s]Loading train:  79%|███████▉  | 225/285 [03:40<00:54,  1.10it/s]Loading train:  79%|███████▉  | 226/285 [03:41<00:58,  1.01it/s]Loading train:  80%|███████▉  | 227/285 [03:42<00:57,  1.01it/s]Loading train:  80%|████████  | 228/285 [03:44<01:00,  1.06s/it]Loading train:  80%|████████  | 229/285 [03:44<00:55,  1.01it/s]Loading train:  81%|████████  | 230/285 [03:45<00:51,  1.08it/s]Loading train:  81%|████████  | 231/285 [03:46<00:50,  1.08it/s]Loading train:  81%|████████▏ | 232/285 [03:47<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [03:49<00:57,  1.10s/it]Loading train:  82%|████████▏ | 234/285 [03:50<00:58,  1.14s/it]Loading train:  82%|████████▏ | 235/285 [03:51<00:55,  1.10s/it]Loading train:  83%|████████▎ | 236/285 [03:52<00:54,  1.11s/it]Loading train:  83%|████████▎ | 237/285 [03:53<00:50,  1.06s/it]Loading train:  84%|████████▎ | 238/285 [03:54<00:53,  1.14s/it]Loading train:  84%|████████▍ | 239/285 [03:56<00:55,  1.20s/it]Loading train:  84%|████████▍ | 240/285 [03:57<00:55,  1.24s/it]Loading train:  85%|████████▍ | 241/285 [03:58<00:53,  1.21s/it]Loading train:  85%|████████▍ | 242/285 [03:59<00:52,  1.22s/it]Loading train:  85%|████████▌ | 243/285 [04:00<00:49,  1.18s/it]Loading train:  86%|████████▌ | 244/285 [04:01<00:47,  1.15s/it]Loading train:  86%|████████▌ | 245/285 [04:03<00:48,  1.22s/it]Loading train:  86%|████████▋ | 246/285 [04:04<00:44,  1.15s/it]Loading train:  87%|████████▋ | 247/285 [04:05<00:44,  1.17s/it]Loading train:  87%|████████▋ | 248/285 [04:06<00:42,  1.14s/it]Loading train:  87%|████████▋ | 249/285 [04:07<00:40,  1.13s/it]Loading train:  88%|████████▊ | 250/285 [04:09<00:43,  1.23s/it]Loading train:  88%|████████▊ | 251/285 [04:10<00:40,  1.19s/it]Loading train:  88%|████████▊ | 252/285 [04:11<00:36,  1.12s/it]Loading train:  89%|████████▉ | 253/285 [04:11<00:32,  1.01s/it]Loading train:  89%|████████▉ | 254/285 [04:12<00:30,  1.03it/s]Loading train:  89%|████████▉ | 255/285 [04:13<00:27,  1.07it/s]Loading train:  90%|████████▉ | 256/285 [04:14<00:25,  1.12it/s]Loading train:  90%|█████████ | 257/285 [04:16<00:30,  1.10s/it]Loading train:  91%|█████████ | 258/285 [04:17<00:31,  1.18s/it]Loading train:  91%|█████████ | 259/285 [04:18<00:28,  1.08s/it]Loading train:  91%|█████████ | 260/285 [04:19<00:26,  1.06s/it]Loading train:  92%|█████████▏| 261/285 [04:20<00:24,  1.01s/it]Loading train:  92%|█████████▏| 262/285 [04:21<00:21,  1.05it/s]Loading train:  92%|█████████▏| 263/285 [04:21<00:20,  1.07it/s]Loading train:  93%|█████████▎| 264/285 [04:22<00:18,  1.11it/s]Loading train:  93%|█████████▎| 265/285 [04:23<00:17,  1.15it/s]Loading train:  93%|█████████▎| 266/285 [04:24<00:15,  1.23it/s]Loading train:  94%|█████████▎| 267/285 [04:24<00:14,  1.25it/s]Loading train:  94%|█████████▍| 268/285 [04:25<00:14,  1.16it/s]Loading train:  94%|█████████▍| 269/285 [04:26<00:13,  1.15it/s]Loading train:  95%|█████████▍| 270/285 [04:27<00:13,  1.11it/s]Loading train:  95%|█████████▌| 271/285 [04:28<00:13,  1.05it/s]Loading train:  95%|█████████▌| 272/285 [04:29<00:12,  1.06it/s]Loading train:  96%|█████████▌| 273/285 [04:30<00:11,  1.03it/s]Loading train:  96%|█████████▌| 274/285 [04:31<00:10,  1.06it/s]Loading train:  96%|█████████▋| 275/285 [04:32<00:09,  1.05it/s]Loading train:  97%|█████████▋| 276/285 [04:33<00:08,  1.06it/s]Loading train:  97%|█████████▋| 277/285 [04:34<00:07,  1.07it/s]Loading train:  98%|█████████▊| 278/285 [04:35<00:06,  1.06it/s]Loading train:  98%|█████████▊| 279/285 [04:36<00:05,  1.08it/s]Loading train:  98%|█████████▊| 280/285 [04:37<00:04,  1.08it/s]Loading train:  99%|█████████▊| 281/285 [04:38<00:03,  1.09it/s]Loading train:  99%|█████████▉| 282/285 [04:39<00:02,  1.09it/s]Loading train:  99%|█████████▉| 283/285 [04:40<00:01,  1.08it/s]Loading train: 100%|█████████▉| 284/285 [04:41<00:00,  1.07it/s]Loading train: 100%|██████████| 285/285 [04:42<00:00,  1.05it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 61.09it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:03, 74.95it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:02, 85.18it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:02, 97.44it/s]concatenating: train:  28%|██▊       | 80/285 [00:00<00:01, 121.15it/s]concatenating: train:  39%|███▊      | 110/285 [00:00<00:01, 147.36it/s]concatenating: train:  49%|████▉     | 141/285 [00:00<00:00, 174.09it/s]concatenating: train:  61%|██████    | 173/285 [00:00<00:00, 200.74it/s]concatenating: train:  73%|███████▎  | 208/285 [00:00<00:00, 228.98it/s]concatenating: train:  84%|████████▍ | 240/285 [00:01<00:00, 250.32it/s]concatenating: train:  95%|█████████▌| 271/285 [00:01<00:00, 264.69it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 241.56it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.22s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 107.12it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 40 |  Upsample 1

 #layer 4 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 40 |  Upsample 1

 #layer 4 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 80, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 80, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 80, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 40, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 40, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 40, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 40, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 40, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 40, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 40, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 40, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 20, 80)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 20, 80)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 20, 160)  115360      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 20, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 20, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 20, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 20, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 20, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 7, 10, 160)   0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 7, 10, 160)   0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 7, 10, 320)   461120      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 7, 10, 320)   1280        conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 7, 10, 320)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________2019-07-01 02:50:06.486173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-01 02:50:06.486270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-01 02:50:06.486285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-01 02:50:06.486304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-01 02:50:06.486687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

conv2d_8 (Conv2D)               (None, 7, 10, 320)   921920      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 7, 10, 320)   1280        conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 7, 10, 320)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 7, 10, 320)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 14, 20, 160)  204960      dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 14, 20, 320)  0           conv2d_transpose_1[0][0]         
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 20, 160)  460960      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 20, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 20, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 20, 160)  230560      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 20, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 20, 160)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 20, 160)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 28, 40, 80)   51280       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 40, 160)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 40, 80)   115280      concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 40, 80)   320         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 40, 80)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 40, 80)   57680       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 40, 80)   320         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 40, 80)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 40, 80)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 56, 80, 40)   12840       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 80, 80)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 80, 40)   28840       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 80, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 80, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 80, 40)   14440       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 80, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 80, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 80, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 80, 13)   533         dropout_7[0][0]                  
==================================================================================================
Total params: 3,014,773
Trainable params: 3,011,253
Non-trainable params: 3,520
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [2.29678646e+01 1.13088369e+01 2.65421366e+01 3.29884122e+00
 9.58849072e+00 2.50031647e+00 3.01177739e+01 3.98604065e+01
 3.04429722e+01 4.68832496e+00 1.04095038e+02 6.92273731e+01
 8.75539005e-02]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 25s - loss: 1224.1821 - acc: 0.9174 - mDice: 0.3748 - val_loss: 1121.1898 - val_acc: 0.9473 - val_mDice: 0.3999

Epoch 00001: val_mDice improved from -inf to 0.39994, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 576.3827 - acc: 0.9433 - mDice: 0.6086 - val_loss: 1322.4292 - val_acc: 0.9503 - val_mDice: 0.4179

Epoch 00002: val_mDice improved from 0.39994 to 0.41790, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 16s - loss: 468.3927 - acc: 0.9499 - mDice: 0.6750 - val_loss: 1636.2763 - val_acc: 0.9505 - val_mDice: 0.3871

Epoch 00003: val_mDice did not improve from 0.41790
Epoch 4/300
 - 16s - loss: 417.0318 - acc: 0.9529 - mDice: 0.7083 - val_loss: 1407.4381 - val_acc: 0.9519 - val_mDice: 0.4491

Epoch 00004: val_mDice improved from 0.41790 to 0.44907, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 16s - loss: 382.3509 - acc: 0.9552 - mDice: 0.7308 - val_loss: 1606.4927 - val_acc: 0.9521 - val_mDice: 0.4378

Epoch 00005: val_mDice did not improve from 0.44907
Epoch 6/300
 - 16s - loss: 357.6909 - acc: 0.9569 - mDice: 0.7478 - val_loss: 1726.2436 - val_acc: 0.9513 - val_mDice: 0.4283

Epoch 00006: val_mDice did not improve from 0.44907
Epoch 7/300
 - 16s - loss: 338.5604 - acc: 0.9580 - mDice: 0.7605 - val_loss: 1563.7469 - val_acc: 0.9540 - val_mDice: 0.4627

Epoch 00007: val_mDice improved from 0.44907 to 0.46274, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 17s - loss: 322.9271 - acc: 0.9591 - mDice: 0.7714 - val_loss: 1573.7692 - val_acc: 0.9525 - val_mDice: 0.4603

Epoch 00008: val_mDice did not improve from 0.46274
Epoch 9/300
 - 16s - loss: 310.6342 - acc: 0.9599 - mDice: 0.7797 - val_loss: 1737.9762 - val_acc: 0.9523 - val_mDice: 0.4494

Epoch 00009: val_mDice did not improve from 0.46274
Epoch 10/300
 - 16s - loss: 300.1214 - acc: 0.9605 - mDice: 0.7876 - val_loss: 1737.3067 - val_acc: 0.9527 - val_mDice: 0.4479

Epoch 00010: val_mDice did not improve from 0.46274
Epoch 11/300
 - 16s - loss: 291.3859 - acc: 0.9611 - mDice: 0.7929 - val_loss: 1826.4212 - val_acc: 0.9527 - val_mDice: 0.4455

Epoch 00011: val_mDice did not improve from 0.46274
Epoch 12/300
 - 16s - loss: 282.7908 - acc: 0.9617 - mDice: 0.7991 - val_loss: 1801.3503 - val_acc: 0.9530 - val_mDice: 0.4551

Epoch 00012: val_mDice did not improve from 0.46274
Epoch 13/300
 - 16s - loss: 275.3356 - acc: 0.9621 - mDice: 0.8047 - val_loss: 1819.5449 - val_acc: 0.9531 - val_mDice: 0.4580

Epoch 00013: val_mDice did not improve from 0.46274
Epoch 14/300
 - 16s - loss: 267.9198 - acc: 0.9626 - mDice: 0.8092 - val_loss: 2241.6464 - val_acc: 0.9503 - val_mDice: 0.4115

Epoch 00014: val_mDice did not improve from 0.46274
Epoch 15/300
 - 16s - loss: 263.8919 - acc: 0.9629 - mDice: 0.8124 - val_loss: 1962.1945 - val_acc: 0.9524 - val_mDice: 0.4435

Epoch 00015: val_mDice did not improve from 0.46274
Epoch 16/300
 - 16s - loss: 257.9463 - acc: 0.9632 - mDice: 0.8165 - val_loss: 1797.0065 - val_acc: 0.9530 - val_mDice: 0.4708

Epoch 00016: val_mDice improved from 0.46274 to 0.47078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 17s - loss: 253.4759 - acc: 0.9635 - mDice: 0.8200 - val_loss: 1888.9899 - val_acc: 0.9525 - val_mDice: 0.4615

Epoch 00017: val_mDice did not improve from 0.47078
Epoch 18/300
 - 17s - loss: 247.2067 - acc: 0.9638 - mDice: 0.8239 - val_loss: 2005.6110 - val_acc: 0.9534 - val_mDice: 0.4529

Epoch 00018: val_mDice did not improve from 0.47078
Epoch 19/300
 - 16s - loss: 243.5668 - acc: 0.9640 - mDice: 0.8267 - val_loss: 1919.9340 - val_acc: 0.9529 - val_mDice: 0.4667

Epoch 00019: val_mDice did not improve from 0.47078
Epoch 20/300
 - 16s - loss: 240.4089 - acc: 0.9642 - mDice: 0.8288 - val_loss: 1985.1577 - val_acc: 0.9526 - val_mDice: 0.4584

Epoch 00020: val_mDice did not improve from 0.47078
Epoch 21/300
 - 16s - loss: 235.2101 - acc: 0.9645 - mDice: 0.8327 - val_loss: 2023.8074 - val_acc: 0.9522 - val_mDice: 0.4559

Epoch 00021: val_mDice did not improve from 0.47078
Epoch 22/300
 - 16s - loss: 231.5588 - acc: 0.9647 - mDice: 0.8350 - val_loss: 1847.2282 - val_acc: 0.9542 - val_mDice: 0.4786

Epoch 00022: val_mDice improved from 0.47078 to 0.47856, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 16s - loss: 229.5550 - acc: 0.9648 - mDice: 0.8370 - val_loss: 2091.1461 - val_acc: 0.9530 - val_mDice: 0.4465

Epoch 00023: val_mDice did not improve from 0.47856
Epoch 24/300
 - 16s - loss: 224.5873 - acc: 0.9651 - mDice: 0.8401 - val_loss: 2098.5322 - val_acc: 0.9521 - val_mDice: 0.4483

Epoch 00024: val_mDice did not improve from 0.47856
Epoch 25/300
 - 16s - loss: 221.7826 - acc: 0.9652 - mDice: 0.8421 - val_loss: 1979.6285 - val_acc: 0.9531 - val_mDice: 0.4708

Epoch 00025: val_mDice did not improve from 0.47856
Epoch 26/300
 - 16s - loss: 221.2954 - acc: 0.9653 - mDice: 0.8426 - val_loss: 2042.5293 - val_acc: 0.9520 - val_mDice: 0.4646

Epoch 00026: val_mDice did not improve from 0.47856
Epoch 27/300
 - 16s - loss: 216.6748 - acc: 0.9655 - mDice: 0.8458 - val_loss: 1988.0403 - val_acc: 0.9527 - val_mDice: 0.4700

Epoch 00027: val_mDice did not improve from 0.47856
Epoch 28/300
 - 16s - loss: 215.1804 - acc: 0.9656 - mDice: 0.8470 - val_loss: 2122.3899 - val_acc: 0.9533 - val_mDice: 0.4536

Epoch 00028: val_mDice did not improve from 0.47856
Epoch 29/300
 - 16s - loss: 212.2646 - acc: 0.9659 - mDice: 0.8489 - val_loss: 2016.3746 - val_acc: 0.9534 - val_mDice: 0.4732

Epoch 00029: val_mDice did not improve from 0.47856
Epoch 30/300
 - 16s - loss: 210.0579 - acc: 0.9660 - mDice: 0.8505 - val_loss: 2177.9600 - val_acc: 0.9532 - val_mDice: 0.4573

Epoch 00030: val_mDice did not improve from 0.47856
Epoch 31/300
 - 17s - loss: 208.0010 - acc: 0.9661 - mDice: 0.8524 - val_loss: 2096.3575 - val_acc: 0.9535 - val_mDice: 0.4664

Epoch 00031: val_mDice did not improve from 0.47856
Epoch 32/300
 - 16s - loss: 205.5813 - acc: 0.9662 - mDice: 0.8538 - val_loss: 2337.8402 - val_acc: 0.9527 - val_mDice: 0.4360

Epoch 00032: val_mDice did not improve from 0.47856
Epoch 33/300
 - 16s - loss: 203.5830 - acc: 0.9664 - mDice: 0.8555 - val_loss: 2220.2410 - val_acc: 0.9532 - val_mDice: 0.4504

Epoch 00033: val_mDice did not improve from 0.47856
Epoch 34/300
 - 16s - loss: 201.8439 - acc: 0.9664 - mDice: 0.8565 - val_loss: 2151.7127 - val_acc: 0.9521 - val_mDice: 0.4583

Epoch 00034: val_mDice did not improve from 0.47856
Epoch 35/300
 - 16s - loss: 199.4515 - acc: 0.9665 - mDice: 0.8581 - val_loss: 2193.6016 - val_acc: 0.9526 - val_mDice: 0.4609

Epoch 00035: val_mDice did not improve from 0.47856
Epoch 36/300
 - 16s - loss: 197.6271 - acc: 0.9666 - mDice: 0.8595 - val_loss: 2273.5895 - val_acc: 0.9521 - val_mDice: 0.4472

Epoch 00036: val_mDice did not improve from 0.47856
Epoch 37/300
 - 16s - loss: 195.2215 - acc: 0.9668 - mDice: 0.8613 - val_loss: 2261.0707 - val_acc: 0.9521 - val_mDice: 0.4523

Epoch 00037: val_mDice did not improve from 0.47856
Epoch 38/300
 - 16s - loss: 194.1737 - acc: 0.9668 - mDice: 0.8619 - val_loss: 2357.0005 - val_acc: 0.9520 - val_mDice: 0.4441

Epoch 00038: val_mDice did not improve from 0.47856
Epoch 39/300
 - 16s - loss: 192.3923 - acc: 0.9669 - mDice: 0.8634 - val_loss: 2278.5179 - val_acc: 0.9522 - val_mDice: 0.4553

Epoch 00039: val_mDice did not improve from 0.47856
Epoch 40/300
 - 16s - loss: 190.2153 - acc: 0.9670 - mDice: 0.8648 - val_loss: 2094.1635 - val_acc: 0.9540 - val_mDice: 0.4768

Epoch 00040: val_mDice did not improve from 0.47856
Epoch 41/300
 - 16s - loss: 188.4024 - acc: 0.9672 - mDice: 0.8661 - val_loss: 2199.8598 - val_acc: 0.9529 - val_mDice: 0.4612

Epoch 00041: val_mDice did not improve from 0.47856
Epoch 42/300
 - 16s - loss: 187.6912 - acc: 0.9672 - mDice: 0.8668 - val_loss: 2312.7054 - val_acc: 0.9529 - val_mDice: 0.4553

Epoch 00042: val_mDice did not improve from 0.47856
Epoch 43/300
 - 17s - loss: 186.5391 - acc: 0.9673 - mDice: 0.8674 - val_loss: 2186.3744 - val_acc: 0.9525 - val_mDice: 0.4621

Epoch 00043: val_mDice did not improve from 0.47856
Epoch 44/300
 - 17s - loss: 185.6362 - acc: 0.9674 - mDice: 0.8683 - val_loss: 2095.7650 - val_acc: 0.9536 - val_mDice: 0.4824

Epoch 00044: val_mDice improved from 0.47856 to 0.48239, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 17s - loss: 182.1740 - acc: 0.9675 - mDice: 0.8705 - val_loss: 2332.7445 - val_acc: 0.9533 - val_mDice: 0.4549

Epoch 00045: val_mDice did not improve from 0.48239
Epoch 46/300
 - 17s - loss: 181.5196 - acc: 0.9676 - mDice: 0.8711 - val_loss: 2345.5970 - val_acc: 0.9526 - val_mDice: 0.4482

Epoch 00046: val_mDice did not improve from 0.48239
Epoch 47/300
 - 16s - loss: 180.1928 - acc: 0.9676 - mDice: 0.8720 - val_loss: 2282.8413 - val_acc: 0.9531 - val_mDice: 0.4574

Epoch 00047: val_mDice did not improve from 0.48239
Epoch 48/300
 - 16s - loss: 179.1304 - acc: 0.9677 - mDice: 0.8728 - val_loss: 2368.8785 - val_acc: 0.9523 - val_mDice: 0.4516

Epoch 00048: val_mDice did not improve from 0.48239
Epoch 49/300
 - 17s - loss: 177.9311 - acc: 0.9678 - mDice: 0.8737 - val_loss: 2275.9340 - val_acc: 0.9530 - val_mDice: 0.4587

Epoch 00049: val_mDice did not improve from 0.48239
Epoch 50/300
 - 17s - loss: 176.6511 - acc: 0.9678 - mDice: 0.8745 - val_loss: 2247.4982 - val_acc: 0.9531 - val_mDice: 0.4651

Epoch 00050: val_mDice did not improve from 0.48239
Epoch 51/300
 - 17s - loss: 175.7321 - acc: 0.9678 - mDice: 0.8754 - val_loss: 2247.0098 - val_acc: 0.9523 - val_mDice: 0.4700

Epoch 00051: val_mDice did not improve from 0.48239
Epoch 52/300
 - 17s - loss: 174.2030 - acc: 0.9679 - mDice: 0.8764 - val_loss: 2314.8934 - val_acc: 0.9525 - val_mDice: 0.4557

Epoch 00052: val_mDice did not improve from 0.48239
Epoch 53/300
 - 17s - loss: 173.4501 - acc: 0.9680 - mDice: 0.8769 - val_loss: 2414.4884 - val_acc: 0.9530 - val_mDice: 0.4547

Epoch 00053: val_mDice did not improve from 0.48239
Epoch 54/300
 - 17s - loss: 172.1143 - acc: 0.9681 - mDice: 0.8780 - val_loss: 2226.8415 - val_acc: 0.9534 - val_mDice: 0.4735

Epoch 00054: val_mDice did not improve from 0.48239
Epoch 55/300
 - 17s - loss: 171.1179 - acc: 0.9682 - mDice: 0.8787 - val_loss: 2232.4686 - val_acc: 0.9532 - val_mDice: 0.4711

Epoch 00055: val_mDice did not improve from 0.48239
Epoch 56/300
 - 16s - loss: 170.3559 - acc: 0.9682 - mDice: 0.8793 - val_loss: 2178.4847 - val_acc: 0.9532 - val_mDice: 0.4771

Epoch 00056: val_mDice did not improve from 0.48239
Epoch 57/300
 - 17s - loss: 167.5109 - acc: 0.9683 - mDice: 0.8812 - val_loss: 2217.2134 - val_acc: 0.9537 - val_mDice: 0.4725

Epoch 00057: val_mDice did not improve from 0.48239
Epoch 58/300
 - 17s - loss: 168.8798 - acc: 0.9683 - mDice: 0.8804 - val_loss: 2231.9666 - val_acc: 0.9528 - val_mDice: 0.4698

Epoch 00058: val_mDice did not improve from 0.48239
Epoch 59/300
 - 17s - loss: 166.6539 - acc: 0.9684 - mDice: 0.8819 - val_loss: 2356.9512 - val_acc: 0.9525 - val_mDice: 0.4596

Epoch 00059: val_mDice did not improve from 0.48239
Epoch 60/300
 - 17s - loss: 165.9191 - acc: 0.9684 - mDice: 0.8823 - val_loss: 2181.5891 - val_acc: 0.9529 - val_mDice: 0.4740

Epoch 00060: val_mDice did not improve from 0.48239
Epoch 61/300
 - 16s - loss: 164.7030 - acc: 0.9686 - mDice: 0.8834 - val_loss: 2395.3302 - val_acc: 0.9524 - val_mDice: 0.4573

Epoch 00061: val_mDice did not improve from 0.48239
Epoch 62/300
 - 17s - loss: 164.1743 - acc: 0.9685 - mDice: 0.8837 - val_loss: 2381.1850 - val_acc: 0.9528 - val_mDice: 0.4566

Epoch 00062: val_mDice did not improve from 0.48239
Epoch 63/300
 - 17s - loss: 163.1345 - acc: 0.9685 - mDice: 0.8844 - val_loss: 2436.4731 - val_acc: 0.9521 - val_mDice: 0.4472

Epoch 00063: val_mDice did not improve from 0.48239
Epoch 64/300
 - 17s - loss: 161.8192 - acc: 0.9686 - mDice: 0.8854 - val_loss: 2417.3647 - val_acc: 0.9514 - val_mDice: 0.4527

Epoch 00064: val_mDice did not improve from 0.48239
Epoch 65/300
 - 19s - loss: 162.4130 - acc: 0.9686 - mDice: 0.8851 - val_loss: 2317.8492 - val_acc: 0.9520 - val_mDice: 0.4629

Epoch 00065: val_mDice did not improve from 0.48239
Epoch 66/300
 - 17s - loss: 160.6026 - acc: 0.9687 - mDice: 0.8863 - val_loss: 2319.7732 - val_acc: 0.9524 - val_mDice: 0.4712

Epoch 00066: val_mDice did not improve from 0.48239
Epoch 67/300
 - 17s - loss: 159.5199 - acc: 0.9687 - mDice: 0.8871 - val_loss: 2414.7341 - val_acc: 0.9530 - val_mDice: 0.4658

Epoch 00067: val_mDice did not improve from 0.48239
Epoch 68/300
 - 16s - loss: 159.4226 - acc: 0.9688 - mDice: 0.8871 - val_loss: 2416.2614 - val_acc: 0.9525 - val_mDice: 0.4564

Epoch 00068: val_mDice did not improve from 0.48239
Epoch 69/300
 - 17s - loss: 157.9876 - acc: 0.9689 - mDice: 0.8882 - val_loss: 2172.6895 - val_acc: 0.9531 - val_mDice: 0.4862

Epoch 00069: val_mDice improved from 0.48239 to 0.48619, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 70/300
 - 16s - loss: 157.9024 - acc: 0.9688 - mDice: 0.8884 - val_loss: 2389.5786 - val_acc: 0.9527 - val_mDice: 0.4590

Epoch 00070: val_mDice did not improve from 0.48619
Epoch 71/300
 - 16s - loss: 156.4251 - acc: 0.9689 - mDice: 0.8892 - val_loss: 2486.0779 - val_acc: 0.9515 - val_mDice: 0.4539

Epoch 00071: val_mDice did not improve from 0.48619
Epoch 72/300
 - 16s - loss: 155.2260 - acc: 0.9689 - mDice: 0.8901 - val_loss: 2347.0974 - val_acc: 0.9532 - val_mDice: 0.4727

Epoch 00072: val_mDice did not improve from 0.48619
Epoch 73/300
 - 17s - loss: 154.0048 - acc: 0.9690 - mDice: 0.8911 - val_loss: 2218.5191 - val_acc: 0.9533 - val_mDice: 0.4816

Epoch 00073: val_mDice did not improve from 0.48619
Epoch 74/300
 - 16s - loss: 154.5427 - acc: 0.9690 - mDice: 0.8908 - val_loss: 2396.9547 - val_acc: 0.9527 - val_mDice: 0.4597

Epoch 00074: val_mDice did not improve from 0.48619
Epoch 75/300
 - 16s - loss: 152.6222 - acc: 0.9690 - mDice: 0.8921 - val_loss: 2416.7818 - val_acc: 0.9526 - val_mDice: 0.4660

Epoch 00075: val_mDice did not improve from 0.48619
Epoch 76/300
 - 16s - loss: 152.8992 - acc: 0.9691 - mDice: 0.8918 - val_loss: 2482.8396 - val_acc: 0.9521 - val_mDice: 0.4531

Epoch 00076: val_mDice did not improve from 0.48619
Epoch 77/300
 - 16s - loss: 151.8239 - acc: 0.9692 - mDice: 0.8927 - val_loss: 2413.2248 - val_acc: 0.9524 - val_mDice: 0.4606

Epoch 00077: val_mDice did not improve from 0.48619
Epoch 78/300
 - 16s - loss: 151.8147 - acc: 0.9692 - mDice: 0.8927 - val_loss: 2414.5766 - val_acc: 0.9522 - val_mDice: 0.4641

Epoch 00078: val_mDice did not improve from 0.48619
Epoch 79/300
 - 16s - loss: 150.7373 - acc: 0.9692 - mDice: 0.8933 - val_loss: 2433.5821 - val_acc: 0.9519 - val_mDice: 0.4648

Epoch 00079: val_mDice did not improve from 0.48619
Epoch 80/300
 - 17s - loss: 149.5867 - acc: 0.9692 - mDice: 0.8943 - val_loss: 2349.6310 - val_acc: 0.9520 - val_mDice: 0.4731

Epoch 00080: val_mDice did not improve from 0.48619
Epoch 81/300
 - 16s - loss: 149.5745 - acc: 0.9692 - mDice: 0.8942 - val_loss: 2421.1745 - val_acc: 0.9522 - val_mDice: 0.4602

Epoch 00081: val_mDice did not improve from 0.48619
Epoch 82/300
 - 16s - loss: 148.8824 - acc: 0.9692 - mDice: 0.8948 - val_loss: 2452.5586 - val_acc: 0.9526 - val_mDice: 0.4577

Epoch 00082: val_mDice did not improve from 0.48619
Epoch 83/300
 - 16s - loss: 147.6991 - acc: 0.9693 - mDice: 0.8957 - val_loss: 2424.3304 - val_acc: 0.9537 - val_mDice: 0.4689

Epoch 00083: val_mDice did not improve from 0.48619
Epoch 84/300
 - 16s - loss: 147.5773 - acc: 0.9693 - mDice: 0.8957 - val_loss: 2394.9772 - val_acc: 0.9528 - val_mDice: 0.4668

Epoch 00084: val_mDice did not improve from 0.48619
Epoch 85/300
 - 16s - loss: 146.6634 - acc: 0.9694 - mDice: 0.8963 - val_loss: 2388.8261 - val_acc: 0.9527 - val_mDice: 0.4712

Epoch 00085: val_mDice did not improve from 0.48619
Epoch 86/300
 - 16s - loss: 147.2018 - acc: 0.9694 - mDice: 0.8960 - val_loss: 2353.2239 - val_acc: 0.9529 - val_mDice: 0.4729

Epoch 00086: val_mDice did not improve from 0.48619
Epoch 87/300
 - 17s - loss: 145.9645 - acc: 0.9694 - mDice: 0.8971 - val_loss: 2313.5380 - val_acc: 0.9528 - val_mDice: 0.4781

Epoch 00087: val_mDice did not improve from 0.48619
Epoch 88/300
 - 17s - loss: 145.6837 - acc: 0.9694 - mDice: 0.8971 - val_loss: 2370.9255 - val_acc: 0.9524 - val_mDice: 0.4728

Epoch 00088: val_mDice did not improve from 0.48619
Epoch 89/300
 - 16s - loss: 145.0941 - acc: 0.9694 - mDice: 0.8976 - val_loss: 2512.5525 - val_acc: 0.9528 - val_mDice: 0.4558

Epoch 00089: val_mDice did not improve from 0.48619
Epoch 90/300
 - 16s - loss: 144.1539 - acc: 0.9695 - mDice: 0.8981 - val_loss: 2354.6449 - val_acc: 0.9524 - val_mDice: 0.4707

Epoch 00090: val_mDice did not improve from 0.48619
Epoch 91/300
 - 16s - loss: 143.5903 - acc: 0.9696 - mDice: 0.8987 - val_loss: 2488.3382 - val_acc: 0.9518 - val_mDice: 0.4534

Epoch 00091: val_mDice did not improve from 0.48619
Epoch 92/300
 - 16s - loss: 143.3179 - acc: 0.9696 - mDice: 0.8987 - val_loss: 2425.8866 - val_acc: 0.9517 - val_mDice: 0.4656

Epoch 00092: val_mDice did not improve from 0.48619
Epoch 93/300
 - 17s - loss: 142.1482 - acc: 0.9697 - mDice: 0.8997 - val_loss: 2463.6967 - val_acc: 0.9528 - val_mDice: 0.4628

Epoch 00093: val_mDice did not improve from 0.48619
Epoch 94/300
 - 16s - loss: 141.8510 - acc: 0.9697 - mDice: 0.8999 - val_loss: 2427.2972 - val_acc: 0.9521 - val_mDice: 0.4682

Epoch 00094: val_mDice did not improve from 0.48619
Epoch 95/300
 - 16s - loss: 141.3189 - acc: 0.9698 - mDice: 0.9001 - val_loss: 2428.9589 - val_acc: 0.9533 - val_mDice: 0.4684

Epoch 00095: val_mDice did not improve from 0.48619
Epoch 96/300
 - 17s - loss: 141.4074 - acc: 0.9697 - mDice: 0.9004 - val_loss: 2438.6561 - val_acc: 0.9521 - val_mDice: 0.4713

Epoch 00096: val_mDice did not improve from 0.48619
Epoch 97/300
 - 16s - loss: 139.8092 - acc: 0.9697 - mDice: 0.9012 - val_loss: 2497.2775 - val_acc: 0.9518 - val_mDice: 0.4621

Epoch 00097: val_mDice did not improve from 0.48619
Epoch 98/300
 - 16s - loss: 140.3758 - acc: 0.9697 - mDice: 0.9011 - val_loss: 2346.3475 - val_acc: 0.9528 - val_mDice: 0.4786

Epoch 00098: val_mDice did not improve from 0.48619
Epoch 99/300
 - 17s - loss: 140.0205 - acc: 0.9698 - mDice: 0.9013 - val_loss: 2412.8852 - val_acc: 0.9525 - val_mDice: 0.4724

Epoch 00099: val_mDice did not improve from 0.48619
Restoring model weights from the end of the best epoch
Epoch 00099: early stopping
{'val_loss': [1121.1898491950262, 1322.4291932128724, 1636.2763181130092, 1407.4380808046885, 1606.4927130653746, 1726.2436259587605, 1563.7468551113493, 1573.7691766988664, 1737.9762160891578, 1737.3067088524501, 1826.4211829389844, 1801.3503213042304, 1819.5448572238286, 2241.646372068496, 1962.194504709471, 1797.0064512888591, 1888.9898525306157, 2005.6110054368064, 1919.93401661941, 1985.1576902071636, 2023.8074488866896, 1847.2282246975672, 2091.146102326257, 2098.532224291847, 1979.6285085110437, 2042.5293350560326, 1988.040330341884, 2122.389898039046, 2016.3745870022547, 2177.960032894498, 2096.3575241679237, 2337.8401770024075, 2220.2410062608265, 2151.7126780748367, 2193.601623398917, 2273.589486564909, 2261.070651383627, 2357.0005084219433, 2278.517902533213, 2094.1635327566237, 2199.8597611699784, 2312.7053536006383, 2186.37438308625, 2095.7649874233066, 2332.744547412509, 2345.596958444232, 2282.8412612165725, 2368.8785122689746, 2275.9340344497136, 2247.49815927233, 2247.0098405565536, 2314.893384138743, 2414.488396417527, 2226.8414838654653, 2232.468636614936, 2178.4846602848597, 2217.2134428932554, 2231.966590302331, 2356.9512324673788, 2181.589106673286, 2395.3301983560837, 2381.1849544275374, 2436.473099016008, 2417.3647425742374, 2317.849227973393, 2319.773196947007, 2414.734131790343, 2416.261398133777, 2172.689521755491, 2389.5785808222636, 2486.07791251228, 2347.0974248136795, 2218.5190573873974, 2396.954727354504, 2416.7818043799625, 2482.839599745614, 2413.2248447736106, 2414.576572633925, 2433.5820574760437, 2349.630961974462, 2421.1744567326136, 2452.558562937237, 2424.330428645724, 2394.9771576381863, 2388.8261036191666, 2353.2238888967604, 2313.5379996413276, 2370.925544420878, 2512.5524533022017, 2354.6448988573893, 2488.338234821955, 2425.8866115524656, 2463.696734451112, 2427.2971505664646, 2428.9588917550586, 2438.6560785656884, 2497.2775184313455, 2346.3475067388445, 2412.8852214472636], 'val_acc': [0.9472937839371818, 0.950316744191306, 0.9505442210606166, 0.9518665188834781, 0.9520960620471409, 0.9512840395882016, 0.9540263641448248, 0.9525319082396371, 0.9523172037942069, 0.9527062291190738, 0.9527040719985962, 0.9529910740398225, 0.9531271031924656, 0.950338017372858, 0.9523681771187555, 0.9530378551710219, 0.952536111786252, 0.9533524768693107, 0.9529315261613756, 0.9526381889979044, 0.9521853952180772, 0.9541751884278797, 0.9529974517368135, 0.952100328036717, 0.9531334780511402, 0.951981280531202, 0.9527062234424409, 0.953254691192082, 0.9534077303750175, 0.9532291520209539, 0.9534502313250587, 0.9526764239583697, 0.9531696609088353, 0.9520727112179711, 0.9525978111085438, 0.9521152348745436, 0.9521173579352242, 0.951987644036611, 0.9521577273096357, 0.9540093597911653, 0.952884779089973, 0.9528805386452448, 0.9525106095132374, 0.9535969126792181, 0.9532972148486546, 0.9525850358463469, 0.9531037693931943, 0.9523150608653114, 0.95298684494836, 0.953125, 0.9522768060366312, 0.9524681341080439, 0.9530484647977919, 0.9533971008800325, 0.9532248888696943, 0.9531781190917605, 0.9536883660725185, 0.9528082353728158, 0.9525233620689029, 0.9528635428065345, 0.9524447265125456, 0.952827376978738, 0.9520833350363231, 0.9514009611947196, 0.9519876894496736, 0.9524277335121518, 0.9530357008888608, 0.9525467639877683, 0.9531292745045253, 0.9527444953010196, 0.9515029929933094, 0.9531845194952828, 0.9533375898996989, 0.9526572908673968, 0.9525616481190636, 0.9521237299555824, 0.95237455197743, 0.9521874813806444, 0.9518813831465585, 0.9520301932380313, 0.9521747713997251, 0.9525659141086397, 0.9536777252242679, 0.9527593652407328, 0.9527146901403155, 0.9528869135039193, 0.9528295199076334, 0.952391593229203, 0.9527721263113476, 0.9523936907450358, 0.9518090883890787, 0.9516602868125552, 0.9528486671901885, 0.9520663250060308, 0.9533077989305768, 0.9520684764498756, 0.9517729679743449, 0.9528252283732096, 0.9525233620689029], 'val_mDice': [0.39993666999396826, 0.4178984828648113, 0.38711143285036087, 0.4490664757433392, 0.4377848839475995, 0.4283212066761085, 0.46274291741706075, 0.46027102179470514, 0.44936928685222355, 0.4478973554713385, 0.4455468161475091, 0.4551366358285859, 0.4579808559446108, 0.41149963438510895, 0.44352677429006215, 0.47077750148517744, 0.46147480429638, 0.45290198567367734, 0.4667375435431798, 0.4584391581870261, 0.4558507234212898, 0.4785648442450024, 0.446519394715627, 0.4483118976155917, 0.47080573936303455, 0.4646042748576119, 0.46997531326044173, 0.45363504013844896, 0.47318191755385625, 0.4572957468529542, 0.4664307360847791, 0.436045342790229, 0.4503835604659149, 0.4583394690638497, 0.4609277097597009, 0.4471686363575004, 0.45229750286255566, 0.44413808910619645, 0.45529736436548685, 0.4767888889071487, 0.46119226586251033, 0.45533742223467144, 0.46210617820421857, 0.48238549416973475, 0.4548642954656056, 0.44822762445324943, 0.4573738890744391, 0.4515786926661219, 0.45868687402634395, 0.46509368327401934, 0.4699878634086677, 0.45566555041642415, 0.4546957363684972, 0.4735438997546832, 0.47105236032179426, 0.4771172750209059, 0.4724963882139751, 0.4697530876312937, 0.4595620573631355, 0.47398698294446584, 0.4573064875744638, 0.4565600238385655, 0.4471920593863442, 0.4527247427474885, 0.46291409840896014, 0.47118638792917844, 0.4657713614758991, 0.4564271398953029, 0.48619020943130764, 0.4589570558496884, 0.45387843818891616, 0.4726955895977361, 0.4816295039795694, 0.459715201031594, 0.4660171852225349, 0.45305267934288296, 0.46059866568871904, 0.46414757519960403, 0.46482070358026595, 0.4730521830774489, 0.4602286835156736, 0.4576780239031428, 0.46891761234118823, 0.4668306541584787, 0.4712274372577667, 0.472917899312008, 0.47812837291331517, 0.4728170509139697, 0.45580772115361123, 0.47068607274975094, 0.4534335331547828, 0.46563695264714106, 0.46279363050347283, 0.4681702834509668, 0.46841963699885775, 0.4713294811192013, 0.4621062376314685, 0.4786494615532103, 0.47242279829723494], 'loss': [1224.1821288474152, 576.3827270896122, 468.3927395086838, 417.03180707670805, 382.35088806564187, 357.69090869051195, 338.5603814787871, 322.92707114571755, 310.6341761774196, 300.12139337178206, 291.38594013108946, 282.79082707731806, 275.33555020269273, 267.9198059235002, 263.8918800920288, 257.9463013854357, 253.47586870607162, 247.2067347405755, 243.56677504966592, 240.40891779055136, 235.21012739273814, 231.55875207721922, 229.55503949058155, 224.5873417027865, 221.78262863909322, 221.29543465209278, 216.6747953886698, 215.18042630544397, 212.26460650892463, 210.05791729761037, 208.0010371858131, 205.58125288407882, 203.58295252549757, 201.84385726749264, 199.45147148207337, 197.62707315227627, 195.2215342495008, 194.173661131424, 192.39232012291095, 190.21525574024642, 188.4024254861585, 187.69122014984313, 186.53907984448048, 185.63623931749447, 182.17398227789462, 181.51962786252176, 180.1927969193261, 179.13035852370842, 177.9310877240874, 176.65105919059312, 175.73211416932506, 174.20304521421303, 173.45008464435955, 172.11428857718403, 171.11793932557129, 170.35594950628712, 167.51088614139294, 168.87982309524187, 166.65393730944606, 165.919132752618, 164.70301545560304, 164.1743281643722, 163.1345068698263, 161.81919825097742, 162.41299955928076, 160.60256115494377, 159.5198828463888, 159.42263096753678, 157.98756380744905, 157.90241409869512, 156.4250825374876, 155.22596606873628, 154.00481589239917, 154.5427041348865, 152.62222611865073, 152.8991845349528, 151.8239279387198, 151.81467208435754, 150.7372758084693, 149.58672621495145, 149.57445151198684, 148.88244556098263, 147.69907739954417, 147.57725721998713, 146.66337983319127, 147.20181910270483, 145.96445140320142, 145.68373706406518, 145.09408992063524, 144.1539428840374, 143.59031763438983, 143.31787655067185, 142.14820886232823, 141.85097668840635, 141.31893284600756, 141.40737274917123, 139.80924840853214, 140.37575199472116, 140.0205441208871], 'acc': [0.9173882285225292, 0.9433144810964129, 0.9499397946042961, 0.9529406019711463, 0.9552186000822871, 0.9569214483504354, 0.9580247381047429, 0.9591335817318283, 0.9598939831899912, 0.9605482611923704, 0.9611067727440834, 0.9617008481132334, 0.9621404326442398, 0.9625846043312414, 0.9629349763829607, 0.9631787219993498, 0.9635094154632595, 0.963818499249991, 0.9640103648893401, 0.9641913879646233, 0.9644694455745065, 0.9646601466422874, 0.9647921963948746, 0.9651259201235318, 0.9652351181999392, 0.9652614115243797, 0.9655192428777873, 0.9656092491778698, 0.9658684821195034, 0.9660260930143157, 0.9661273942624348, 0.966225663280818, 0.9663559205389124, 0.9664288664659324, 0.9665205906713907, 0.966575134379661, 0.966761406593661, 0.9668059204616183, 0.9668918388621159, 0.9670459637413003, 0.967247015413623, 0.9672163528285551, 0.9673227090492675, 0.9674036140751696, 0.9675454516987224, 0.9675621478824641, 0.9675858821831206, 0.9676983068277548, 0.9677790772921782, 0.9677703447693089, 0.9678044900260773, 0.9679126769953525, 0.9680221333010982, 0.968063420485917, 0.9681544208402507, 0.9681669417111566, 0.9682812793236006, 0.9682623864897925, 0.9684048941513695, 0.9684397929409277, 0.9685845789776985, 0.9685429222716608, 0.9684765892771597, 0.9685882384868538, 0.9686152633155314, 0.9686814034079365, 0.9687368973546665, 0.9688010800429477, 0.9688562728638407, 0.9688117318997292, 0.9689458862926681, 0.9688905660692888, 0.9689726780806291, 0.9689985379010744, 0.9690210261348586, 0.9690943734365919, 0.9691678741567967, 0.9691523385801732, 0.9691938229647817, 0.9692321045793548, 0.9692400644596358, 0.9692491220674098, 0.9693027191569356, 0.9693404367853963, 0.969360298277993, 0.9694106300281196, 0.969424460787798, 0.969389414187454, 0.9694466253271079, 0.9695296579986633, 0.9696020193359216, 0.9696333217257729, 0.9696575115474865, 0.9696963683060881, 0.9697738087473748, 0.9696624172154432, 0.9696939384774111, 0.9697293290771086, 0.9697878337421237], 'mDice': [0.3747801412466475, 0.6085684212710739, 0.6749677012392797, 0.7083205373640669, 0.7307530902864755, 0.7478012235173376, 0.7605216659767816, 0.7714206944868839, 0.7797452131401534, 0.7876408066344165, 0.792920777557304, 0.7990723812030831, 0.8047473377084742, 0.809237686085154, 0.8124025490832324, 0.8164836866951688, 0.8199847964323944, 0.8238819350574847, 0.8267324743460248, 0.828803763215841, 0.8326624026297603, 0.834996300923105, 0.8369737342531474, 0.8401158462720775, 0.8420527969248749, 0.8425750657614426, 0.845818082008928, 0.8470057316637232, 0.848867262365824, 0.8504997172382311, 0.8523901955387784, 0.8538406943916378, 0.8554779855139066, 0.8565391444828967, 0.8581342940296491, 0.8594764643766206, 0.8612761508988718, 0.8619197241276796, 0.8633606896502494, 0.8648411644569178, 0.8661282249836418, 0.8667811256096684, 0.8673872663401583, 0.8683072002563308, 0.8704726083765422, 0.8711455694760848, 0.8720197127760319, 0.8728430406054896, 0.8736634284907139, 0.8744871397571847, 0.8754026281918683, 0.876366685782183, 0.8768644175456856, 0.8779604362342912, 0.8786955863748738, 0.8792690698043767, 0.8811596878604069, 0.8803650908831436, 0.8819215378137092, 0.882344549518572, 0.8833558377397757, 0.8836712794242302, 0.8843656946566147, 0.8853729931357188, 0.8851117358539567, 0.8862763762887742, 0.8870713667118506, 0.8871017407998658, 0.8882382554035323, 0.8884187621465418, 0.8892491632443713, 0.8901245624361319, 0.8910648007486651, 0.8908328694462523, 0.8921255270180409, 0.8917660358693528, 0.8926972044164652, 0.8926992306296527, 0.8932917070154375, 0.8942874433080976, 0.8942081188222496, 0.8947529334748023, 0.8957465523489413, 0.8956941664621093, 0.896348626392527, 0.8959686492756656, 0.897087745165949, 0.8970746568386003, 0.8975916200229284, 0.8980686635278842, 0.8986605271935486, 0.8986631485453823, 0.8996643275453425, 0.8999083224279655, 0.9001330744905327, 0.9004081175096099, 0.9011847556315338, 0.9010757470903127, 0.9013072987133215]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.85s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.43s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.17s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:21,  1.34s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:50,  1.45s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:53,  1.47s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:22,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:56,  1.71s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:20,  1.80s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:48,  1.91s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:24,  1.83s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:35,  1.87s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:57,  1.96s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:04,  1.99s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<09:26,  2.08s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<09:21,  2.07s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:42,  2.16s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:33,  2.13s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<09:41,  2.17s/it]predicting train subjects:   6%|▋         | 18/285 [00:35<10:16,  2.31s/it]predicting train subjects:   7%|▋         | 19/285 [00:37<10:01,  2.26s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:54,  2.24s/it]predicting train subjects:   7%|▋         | 21/285 [00:42<09:59,  2.27s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:57,  2.27s/it]predicting train subjects:   8%|▊         | 23/285 [00:46<09:38,  2.21s/it]predicting train subjects:   8%|▊         | 24/285 [00:49<10:01,  2.30s/it]predicting train subjects:   9%|▉         | 25/285 [00:51<10:14,  2.36s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:52,  2.29s/it]predicting train subjects:   9%|▉         | 27/285 [00:56<10:03,  2.34s/it]predicting train subjects:  10%|▉         | 28/285 [00:58<09:55,  2.32s/it]predicting train subjects:  10%|█         | 29/285 [01:00<09:46,  2.29s/it]predicting train subjects:  11%|█         | 30/285 [01:03<09:40,  2.28s/it]predicting train subjects:  11%|█         | 31/285 [01:05<09:19,  2.20s/it]predicting train subjects:  11%|█         | 32/285 [01:07<09:03,  2.15s/it]predicting train subjects:  12%|█▏        | 33/285 [01:09<09:05,  2.16s/it]predicting train subjects:  12%|█▏        | 34/285 [01:11<09:02,  2.16s/it]predicting train subjects:  12%|█▏        | 35/285 [01:13<08:56,  2.15s/it]predicting train subjects:  13%|█▎        | 36/285 [01:15<08:47,  2.12s/it]predicting train subjects:  13%|█▎        | 37/285 [01:17<08:44,  2.12s/it]predicting train subjects:  13%|█▎        | 38/285 [01:19<08:35,  2.09s/it]predicting train subjects:  14%|█▎        | 39/285 [01:21<08:15,  2.02s/it]predicting train subjects:  14%|█▍        | 40/285 [01:23<07:59,  1.96s/it]predicting train subjects:  14%|█▍        | 41/285 [01:25<07:58,  1.96s/it]predicting train subjects:  15%|█▍        | 42/285 [01:27<07:58,  1.97s/it]predicting train subjects:  15%|█▌        | 43/285 [01:29<07:49,  1.94s/it]predicting train subjects:  15%|█▌        | 44/285 [01:31<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:32<07:26,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:34<07:02,  1.77s/it]predicting train subjects:  16%|█▋        | 47/285 [01:35<06:37,  1.67s/it]predicting train subjects:  17%|█▋        | 48/285 [01:37<06:36,  1.67s/it]predicting train subjects:  17%|█▋        | 49/285 [01:39<06:31,  1.66s/it]predicting train subjects:  18%|█▊        | 50/285 [01:40<06:36,  1.69s/it]predicting train subjects:  18%|█▊        | 51/285 [01:42<06:36,  1.69s/it]predicting train subjects:  18%|█▊        | 52/285 [01:44<06:37,  1.71s/it]predicting train subjects:  19%|█▊        | 53/285 [01:46<06:52,  1.78s/it]predicting train subjects:  19%|█▉        | 54/285 [01:47<06:47,  1.77s/it]predicting train subjects:  19%|█▉        | 55/285 [01:49<06:48,  1.77s/it]predicting train subjects:  20%|█▉        | 56/285 [01:51<06:32,  1.71s/it]predicting train subjects:  20%|██        | 57/285 [01:53<06:26,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:54<06:25,  1.70s/it]predicting train subjects:  21%|██        | 59/285 [01:56<06:12,  1.65s/it]predicting train subjects:  21%|██        | 60/285 [01:57<06:02,  1.61s/it]predicting train subjects:  21%|██▏       | 61/285 [01:59<05:57,  1.60s/it]predicting train subjects:  22%|██▏       | 62/285 [02:01<06:02,  1.62s/it]predicting train subjects:  22%|██▏       | 63/285 [02:02<06:05,  1.65s/it]predicting train subjects:  22%|██▏       | 64/285 [02:04<06:05,  1.65s/it]predicting train subjects:  23%|██▎       | 65/285 [02:06<06:16,  1.71s/it]predicting train subjects:  23%|██▎       | 66/285 [02:08<06:20,  1.74s/it]predicting train subjects:  24%|██▎       | 67/285 [02:09<06:14,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [02:11<06:20,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [02:13<06:15,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:15<06:17,  1.76s/it]predicting train subjects:  25%|██▍       | 71/285 [02:16<06:18,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:18<06:14,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:20<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:22<06:11,  1.76s/it]predicting train subjects:  26%|██▋       | 75/285 [02:23<06:04,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:25<05:58,  1.72s/it]predicting train subjects:  27%|██▋       | 77/285 [02:27<05:59,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:29<06:00,  1.74s/it]predicting train subjects:  28%|██▊       | 79/285 [02:30<06:00,  1.75s/it]predicting train subjects:  28%|██▊       | 80/285 [02:32<06:04,  1.78s/it]predicting train subjects:  28%|██▊       | 81/285 [02:34<06:03,  1.78s/it]predicting train subjects:  29%|██▉       | 82/285 [02:36<06:10,  1.82s/it]predicting train subjects:  29%|██▉       | 83/285 [02:38<06:21,  1.89s/it]predicting train subjects:  29%|██▉       | 84/285 [02:40<06:20,  1.89s/it]predicting train subjects:  30%|██▉       | 85/285 [02:42<06:32,  1.96s/it]predicting train subjects:  30%|███       | 86/285 [02:44<06:32,  1.97s/it]predicting train subjects:  31%|███       | 87/285 [02:46<06:53,  2.09s/it]predicting train subjects:  31%|███       | 88/285 [02:48<06:56,  2.11s/it]predicting train subjects:  31%|███       | 89/285 [02:51<07:06,  2.18s/it]predicting train subjects:  32%|███▏      | 90/285 [02:53<07:01,  2.16s/it]predicting train subjects:  32%|███▏      | 91/285 [02:55<06:58,  2.15s/it]predicting train subjects:  32%|███▏      | 92/285 [02:57<06:53,  2.14s/it]predicting train subjects:  33%|███▎      | 93/285 [02:59<06:50,  2.14s/it]predicting train subjects:  33%|███▎      | 94/285 [03:01<06:50,  2.15s/it]predicting train subjects:  33%|███▎      | 95/285 [03:04<06:44,  2.13s/it]predicting train subjects:  34%|███▎      | 96/285 [03:06<06:41,  2.12s/it]predicting train subjects:  34%|███▍      | 97/285 [03:08<06:42,  2.14s/it]predicting train subjects:  34%|███▍      | 98/285 [03:10<06:39,  2.14s/it]predicting train subjects:  35%|███▍      | 99/285 [03:12<06:33,  2.11s/it]predicting train subjects:  35%|███▌      | 100/285 [03:14<06:21,  2.06s/it]predicting train subjects:  35%|███▌      | 101/285 [03:16<06:07,  2.00s/it]predicting train subjects:  36%|███▌      | 102/285 [03:18<05:55,  1.94s/it]predicting train subjects:  36%|███▌      | 103/285 [03:19<05:47,  1.91s/it]predicting train subjects:  36%|███▋      | 104/285 [03:21<05:43,  1.90s/it]predicting train subjects:  37%|███▋      | 105/285 [03:23<05:38,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:25<05:26,  1.83s/it]predicting train subjects:  38%|███▊      | 107/285 [03:27<05:26,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:28<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:30<05:18,  1.81s/it]predicting train subjects:  39%|███▊      | 110/285 [03:32<05:14,  1.80s/it]predicting train subjects:  39%|███▉      | 111/285 [03:34<05:08,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:36<05:06,  1.77s/it]predicting train subjects:  40%|███▉      | 113/285 [03:38<05:20,  1.86s/it]predicting train subjects:  40%|████      | 114/285 [03:40<05:24,  1.90s/it]predicting train subjects:  40%|████      | 115/285 [03:41<05:19,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:43<05:18,  1.88s/it]predicting train subjects:  41%|████      | 117/285 [03:45<05:23,  1.93s/it]predicting train subjects:  41%|████▏     | 118/285 [03:47<05:25,  1.95s/it]predicting train subjects:  42%|████▏     | 119/285 [03:49<05:19,  1.92s/it]predicting train subjects:  42%|████▏     | 120/285 [03:51<05:11,  1.89s/it]predicting train subjects:  42%|████▏     | 121/285 [03:53<04:54,  1.80s/it]predicting train subjects:  43%|████▎     | 122/285 [03:54<04:38,  1.71s/it]predicting train subjects:  43%|████▎     | 123/285 [03:56<04:22,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:57<04:20,  1.62s/it]predicting train subjects:  44%|████▍     | 125/285 [03:59<04:17,  1.61s/it]predicting train subjects:  44%|████▍     | 126/285 [04:00<04:17,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [04:02<04:15,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [04:04<04:13,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [04:05<04:18,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [04:07<04:28,  1.73s/it]predicting train subjects:  46%|████▌     | 131/285 [04:09<04:23,  1.71s/it]predicting train subjects:  46%|████▋     | 132/285 [04:11<04:18,  1.69s/it]predicting train subjects:  47%|████▋     | 133/285 [04:12<04:14,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:14<04:14,  1.69s/it]predicting train subjects:  47%|████▋     | 135/285 [04:16<04:23,  1.76s/it]predicting train subjects:  48%|████▊     | 136/285 [04:18<04:25,  1.78s/it]predicting train subjects:  48%|████▊     | 137/285 [04:20<04:30,  1.83s/it]predicting train subjects:  48%|████▊     | 138/285 [04:21<04:29,  1.83s/it]predicting train subjects:  49%|████▉     | 139/285 [04:23<04:34,  1.88s/it]predicting train subjects:  49%|████▉     | 140/285 [04:25<04:33,  1.89s/it]predicting train subjects:  49%|████▉     | 141/285 [04:27<04:32,  1.89s/it]predicting train subjects:  50%|████▉     | 142/285 [04:29<04:15,  1.78s/it]predicting train subjects:  50%|█████     | 143/285 [04:30<04:10,  1.77s/it]predicting train subjects:  51%|█████     | 144/285 [04:32<04:08,  1.76s/it]predicting train subjects:  51%|█████     | 145/285 [04:34<04:07,  1.77s/it]predicting train subjects:  51%|█████     | 146/285 [04:36<04:00,  1.73s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:37<03:59,  1.74s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:39<03:54,  1.71s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:41<03:47,  1.67s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:42<03:45,  1.67s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:44<03:35,  1.61s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:45<03:26,  1.55s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:47<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:48<03:19,  1.52s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:50<03:23,  1.56s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:51<03:25,  1.59s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:53<03:28,  1.63s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:55<03:27,  1.63s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:56<03:23,  1.62s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:58<03:22,  1.62s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:00<03:23,  1.64s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:01<03:23,  1.65s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:03<03:25,  1.68s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:05<03:21,  1.66s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:06<03:18,  1.65s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:08<03:15,  1.64s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:09<03:03,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:11<02:55,  1.50s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:12<02:56,  1.52s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:14<02:50,  1.48s/it]predicting train subjects:  60%|██████    | 171/285 [05:15<02:48,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [05:17<02:44,  1.46s/it]predicting train subjects:  61%|██████    | 173/285 [05:18<02:41,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [05:19<02:37,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:21<02:35,  1.41s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:22<02:36,  1.43s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:24<02:32,  1.41s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:25<02:27,  1.38s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:26<02:23,  1.35s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:28<02:21,  1.35s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:29<02:21,  1.36s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:30<02:20,  1.36s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:32<02:22,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:33<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:35<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:36<02:19,  1.41s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:37<02:15,  1.38s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:39<02:12,  1.36s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:40<02:13,  1.40s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:42<02:10,  1.37s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:43<02:08,  1.37s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:44<02:08,  1.38s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:46<02:06,  1.37s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:47<02:01,  1.34s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:48<01:58,  1.32s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:50<02:03,  1.39s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:51<02:06,  1.44s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:53<02:08,  1.48s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:55<02:10,  1.52s/it]predicting train subjects:  70%|███████   | 200/285 [05:56<02:09,  1.53s/it]predicting train subjects:  71%|███████   | 201/285 [05:58<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:59<02:11,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [06:01<02:10,  1.59s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:03<02:09,  1.60s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:04<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:06<02:06,  1.61s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:07<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:09<02:05,  1.63s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:11<02:08,  1.68s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:13<02:05,  1.67s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:14<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:16<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:18<01:59,  1.66s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:19<01:53,  1.60s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:20<01:46,  1.52s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:22<01:43,  1.50s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:23<01:39,  1.47s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:25<01:37,  1.45s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:26<01:34,  1.43s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:27<01:32,  1.42s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:29<01:30,  1.42s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:30<01:28,  1.40s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:32<01:28,  1.42s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:33<01:26,  1.41s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:34<01:23,  1.40s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:36<01:22,  1.40s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:37<01:21,  1.40s/it]predicting train subjects:  80%|████████  | 228/285 [06:39<01:20,  1.41s/it]predicting train subjects:  80%|████████  | 229/285 [06:40<01:19,  1.42s/it]predicting train subjects:  81%|████████  | 230/285 [06:41<01:18,  1.42s/it]predicting train subjects:  81%|████████  | 231/285 [06:43<01:16,  1.42s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:45<01:21,  1.54s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:46<01:24,  1.62s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:48<01:24,  1.66s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:50<01:24,  1.70s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:52<01:25,  1.74s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:54<01:24,  1.76s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:55<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:57<01:21,  1.76s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:59<01:19,  1.78s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:01<01:18,  1.79s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:03<01:15,  1.76s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:05<01:16,  1.83s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:06<01:15,  1.83s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:08<01:12,  1.82s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:10<01:10,  1.80s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:12<01:07,  1.78s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:13<01:06,  1.80s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:15<01:04,  1.80s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:17<00:58,  1.67s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:18<00:54,  1.59s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:19<00:49,  1.51s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:21<00:48,  1.52s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:22<00:46,  1.50s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:24<00:43,  1.46s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:25<00:41,  1.43s/it]predicting train subjects:  90%|█████████ | 257/285 [07:27<00:40,  1.44s/it]predicting train subjects:  91%|█████████ | 258/285 [07:28<00:38,  1.42s/it]predicting train subjects:  91%|█████████ | 259/285 [07:29<00:36,  1.39s/it]predicting train subjects:  91%|█████████ | 260/285 [07:31<00:34,  1.39s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:32<00:33,  1.38s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:33<00:32,  1.41s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:35<00:30,  1.40s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:36<00:28,  1.37s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:38<00:27,  1.36s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:39<00:25,  1.35s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:40<00:24,  1.34s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:42<00:25,  1.49s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:44<00:25,  1.57s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:46<00:24,  1.64s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:47<00:23,  1.70s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:49<00:22,  1.72s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:51<00:21,  1.76s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:53<00:19,  1.79s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:55<00:17,  1.79s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:56<00:16,  1.79s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:58<00:14,  1.86s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:00<00:12,  1.83s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:02<00:11,  1.85s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:04<00:09,  1.86s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:06<00:07,  1.87s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:08<00:05,  1.84s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:10<00:03,  1.83s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:11<00:01,  1.82s/it]predicting train subjects: 100%|██████████| 285/285 [08:13<00:00,  1.80s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:31,  1.38s/it]Loading train:   1%|          | 2/285 [00:03<06:51,  1.45s/it]Loading train:   1%|          | 3/285 [00:04<06:35,  1.40s/it]Loading train:   1%|▏         | 4/285 [00:05<06:53,  1.47s/it]Loading train:   2%|▏         | 5/285 [00:07<06:28,  1.39s/it]Loading train:   2%|▏         | 6/285 [00:08<06:56,  1.49s/it]Loading train:   2%|▏         | 7/285 [00:10<07:16,  1.57s/it]Loading train:   3%|▎         | 8/285 [00:12<07:22,  1.60s/it]Loading train:   3%|▎         | 9/285 [00:13<07:07,  1.55s/it]Loading train:   4%|▎         | 10/285 [00:14<06:37,  1.44s/it]Loading train:   4%|▍         | 11/285 [00:16<06:16,  1.37s/it]Loading train:   4%|▍         | 12/285 [00:17<06:02,  1.33s/it]Loading train:   5%|▍         | 13/285 [00:18<05:49,  1.29s/it]Loading train:   5%|▍         | 14/285 [00:19<05:41,  1.26s/it]Loading train:   5%|▌         | 15/285 [00:20<05:33,  1.24s/it]Loading train:   6%|▌         | 16/285 [00:22<05:25,  1.21s/it]Loading train:   6%|▌         | 17/285 [00:23<05:27,  1.22s/it]Loading train:   6%|▋         | 18/285 [00:24<05:23,  1.21s/it]Loading train:   7%|▋         | 19/285 [00:25<05:26,  1.23s/it]Loading train:   7%|▋         | 20/285 [00:26<05:26,  1.23s/it]Loading train:   7%|▋         | 21/285 [00:28<05:21,  1.22s/it]Loading train:   8%|▊         | 22/285 [00:29<05:20,  1.22s/it]Loading train:   8%|▊         | 23/285 [00:30<05:17,  1.21s/it]Loading train:   8%|▊         | 24/285 [00:31<05:12,  1.20s/it]Loading train:   9%|▉         | 25/285 [00:33<05:16,  1.22s/it]Loading train:   9%|▉         | 26/285 [00:34<05:13,  1.21s/it]Loading train:   9%|▉         | 27/285 [00:35<05:11,  1.21s/it]Loading train:  10%|▉         | 28/285 [00:36<05:06,  1.19s/it]Loading train:  10%|█         | 29/285 [00:37<04:53,  1.15s/it]Loading train:  11%|█         | 30/285 [00:38<04:44,  1.12s/it]Loading train:  11%|█         | 31/285 [00:39<04:36,  1.09s/it]Loading train:  11%|█         | 32/285 [00:40<04:27,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:29,  1.07s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:23,  1.05s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:19,  1.04s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:16,  1.03s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:14,  1.03s/it]Loading train:  13%|█▎        | 38/285 [00:46<04:13,  1.03s/it]Loading train:  14%|█▎        | 39/285 [00:47<04:14,  1.03s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:16,  1.05s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:11,  1.03s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:09,  1.03s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:06,  1.02s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:04,  1.01s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:04,  1.02s/it]Loading train:  16%|█▌        | 46/285 [00:54<03:55,  1.02it/s]Loading train:  16%|█▋        | 47/285 [00:55<03:51,  1.03it/s]Loading train:  17%|█▋        | 48/285 [00:56<03:47,  1.04it/s]Loading train:  17%|█▋        | 49/285 [00:57<03:41,  1.06it/s]Loading train:  18%|█▊        | 50/285 [00:58<03:41,  1.06it/s]Loading train:  18%|█▊        | 51/285 [00:59<03:36,  1.08it/s]Loading train:  18%|█▊        | 52/285 [01:00<03:34,  1.09it/s]Loading train:  19%|█▊        | 53/285 [01:01<03:41,  1.05it/s]Loading train:  19%|█▉        | 54/285 [01:02<03:38,  1.06it/s]Loading train:  19%|█▉        | 55/285 [01:03<03:42,  1.04it/s]Loading train:  20%|█▉        | 56/285 [01:04<03:42,  1.03it/s]Loading train:  20%|██        | 57/285 [01:05<03:45,  1.01it/s]Loading train:  20%|██        | 58/285 [01:06<03:51,  1.02s/it]Loading train:  21%|██        | 59/285 [01:07<03:44,  1.00it/s]Loading train:  21%|██        | 60/285 [01:08<03:39,  1.02it/s]Loading train:  21%|██▏       | 61/285 [01:09<03:39,  1.02it/s]Loading train:  22%|██▏       | 62/285 [01:10<03:36,  1.03it/s]Loading train:  22%|██▏       | 63/285 [01:11<03:39,  1.01it/s]Loading train:  22%|██▏       | 64/285 [01:12<04:13,  1.15s/it]Loading train:  23%|██▎       | 65/285 [01:14<04:43,  1.29s/it]Loading train:  23%|██▎       | 66/285 [01:15<04:46,  1.31s/it]Loading train:  24%|██▎       | 67/285 [01:16<04:25,  1.22s/it]Loading train:  24%|██▍       | 68/285 [01:17<04:06,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:18<03:58,  1.10s/it]Loading train:  25%|██▍       | 70/285 [01:19<03:50,  1.07s/it]Loading train:  25%|██▍       | 71/285 [01:20<03:53,  1.09s/it]Loading train:  25%|██▌       | 72/285 [01:21<03:47,  1.07s/it]Loading train:  26%|██▌       | 73/285 [01:22<03:43,  1.05s/it]Loading train:  26%|██▌       | 74/285 [01:24<03:41,  1.05s/it]Loading train:  26%|██▋       | 75/285 [01:25<03:39,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:26<03:33,  1.02s/it]Loading train:  27%|██▋       | 77/285 [01:27<03:32,  1.02s/it]Loading train:  27%|██▋       | 78/285 [01:28<03:30,  1.02s/it]Loading train:  28%|██▊       | 79/285 [01:29<03:27,  1.01s/it]Loading train:  28%|██▊       | 80/285 [01:30<03:26,  1.01s/it]Loading train:  28%|██▊       | 81/285 [01:31<03:30,  1.03s/it]Loading train:  29%|██▉       | 82/285 [01:32<03:31,  1.04s/it]Loading train:  29%|██▉       | 83/285 [01:33<03:26,  1.02s/it]Loading train:  29%|██▉       | 84/285 [01:34<03:24,  1.02s/it]Loading train:  30%|██▉       | 85/285 [01:35<03:28,  1.04s/it]Loading train:  30%|███       | 86/285 [01:36<03:35,  1.08s/it]Loading train:  31%|███       | 87/285 [01:37<03:35,  1.09s/it]Loading train:  31%|███       | 88/285 [01:38<03:37,  1.11s/it]Loading train:  31%|███       | 89/285 [01:39<03:35,  1.10s/it]Loading train:  32%|███▏      | 90/285 [01:40<03:33,  1.10s/it]Loading train:  32%|███▏      | 91/285 [01:41<03:30,  1.09s/it]Loading train:  32%|███▏      | 92/285 [01:43<03:33,  1.11s/it]Loading train:  33%|███▎      | 93/285 [01:44<03:26,  1.08s/it]Loading train:  33%|███▎      | 94/285 [01:45<03:32,  1.11s/it]Loading train:  33%|███▎      | 95/285 [01:46<03:28,  1.10s/it]Loading train:  34%|███▎      | 96/285 [01:47<03:29,  1.11s/it]Loading train:  34%|███▍      | 97/285 [01:48<03:25,  1.09s/it]Loading train:  34%|███▍      | 98/285 [01:49<03:25,  1.10s/it]Loading train:  35%|███▍      | 99/285 [01:50<03:29,  1.13s/it]Loading train:  35%|███▌      | 100/285 [01:52<03:30,  1.14s/it]Loading train:  35%|███▌      | 101/285 [01:53<03:28,  1.13s/it]Loading train:  36%|███▌      | 102/285 [01:54<03:24,  1.12s/it]Loading train:  36%|███▌      | 103/285 [01:55<03:31,  1.16s/it]Loading train:  36%|███▋      | 104/285 [01:56<03:27,  1.15s/it]Loading train:  37%|███▋      | 105/285 [01:57<03:20,  1.11s/it]Loading train:  37%|███▋      | 106/285 [01:58<03:19,  1.11s/it]Loading train:  38%|███▊      | 107/285 [01:59<03:11,  1.08s/it]Loading train:  38%|███▊      | 108/285 [02:00<03:12,  1.09s/it]Loading train:  38%|███▊      | 109/285 [02:01<03:09,  1.08s/it]Loading train:  39%|███▊      | 110/285 [02:02<03:07,  1.07s/it]Loading train:  39%|███▉      | 111/285 [02:04<03:07,  1.08s/it]Loading train:  39%|███▉      | 112/285 [02:05<03:05,  1.07s/it]Loading train:  40%|███▉      | 113/285 [02:06<03:06,  1.09s/it]Loading train:  40%|████      | 114/285 [02:07<03:01,  1.06s/it]Loading train:  40%|████      | 115/285 [02:08<02:58,  1.05s/it]Loading train:  41%|████      | 116/285 [02:09<02:55,  1.04s/it]Loading train:  41%|████      | 117/285 [02:10<02:52,  1.03s/it]Loading train:  41%|████▏     | 118/285 [02:11<02:50,  1.02s/it]Loading train:  42%|████▏     | 119/285 [02:12<02:49,  1.02s/it]Loading train:  42%|████▏     | 120/285 [02:13<02:50,  1.04s/it]Loading train:  42%|████▏     | 121/285 [02:14<03:05,  1.13s/it]Loading train:  43%|████▎     | 122/285 [02:15<03:09,  1.16s/it]Loading train:  43%|████▎     | 123/285 [02:17<03:08,  1.16s/it]Loading train:  44%|████▎     | 124/285 [02:18<02:53,  1.08s/it]Loading train:  44%|████▍     | 125/285 [02:18<02:44,  1.03s/it]Loading train:  44%|████▍     | 126/285 [02:19<02:37,  1.01it/s]Loading train:  45%|████▍     | 127/285 [02:20<02:36,  1.01it/s]Loading train:  45%|████▍     | 128/285 [02:21<02:28,  1.06it/s]Loading train:  45%|████▌     | 129/285 [02:22<02:23,  1.09it/s]Loading train:  46%|████▌     | 130/285 [02:23<02:22,  1.09it/s]Loading train:  46%|████▌     | 131/285 [02:24<02:20,  1.10it/s]Loading train:  46%|████▋     | 132/285 [02:25<02:22,  1.08it/s]Loading train:  47%|████▋     | 133/285 [02:26<02:20,  1.08it/s]Loading train:  47%|████▋     | 134/285 [02:27<02:18,  1.09it/s]Loading train:  47%|████▋     | 135/285 [02:28<02:20,  1.06it/s]Loading train:  48%|████▊     | 136/285 [02:29<02:20,  1.06it/s]Loading train:  48%|████▊     | 137/285 [02:29<02:14,  1.10it/s]Loading train:  48%|████▊     | 138/285 [02:30<02:14,  1.10it/s]Loading train:  49%|████▉     | 139/285 [02:31<02:16,  1.07it/s]Loading train:  49%|████▉     | 140/285 [02:32<02:14,  1.08it/s]Loading train:  49%|████▉     | 141/285 [02:33<02:16,  1.05it/s]Loading train:  50%|████▉     | 142/285 [02:34<02:16,  1.05it/s]Loading train:  50%|█████     | 143/285 [02:35<02:15,  1.05it/s]Loading train:  51%|█████     | 144/285 [02:36<02:15,  1.04it/s]Loading train:  51%|█████     | 145/285 [02:37<02:13,  1.05it/s]Loading train:  51%|█████     | 146/285 [02:38<02:10,  1.07it/s]Loading train:  52%|█████▏    | 147/285 [02:39<02:14,  1.02it/s]Loading train:  52%|█████▏    | 148/285 [02:40<02:15,  1.01it/s]Loading train:  52%|█████▏    | 149/285 [02:41<02:16,  1.00s/it]Loading train:  53%|█████▎    | 150/285 [02:42<02:17,  1.02s/it]Loading train:  53%|█████▎    | 151/285 [02:43<02:18,  1.04s/it]Loading train:  53%|█████▎    | 152/285 [02:44<02:10,  1.02it/s]Loading train:  54%|█████▎    | 153/285 [02:45<02:09,  1.02it/s]Loading train:  54%|█████▍    | 154/285 [02:46<02:04,  1.05it/s]Loading train:  54%|█████▍    | 155/285 [02:47<02:00,  1.08it/s]Loading train:  55%|█████▍    | 156/285 [02:48<01:56,  1.10it/s]Loading train:  55%|█████▌    | 157/285 [02:49<01:59,  1.07it/s]Loading train:  55%|█████▌    | 158/285 [02:50<02:01,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [02:51<02:01,  1.04it/s]Loading train:  56%|█████▌    | 160/285 [02:52<02:04,  1.00it/s]Loading train:  56%|█████▋    | 161/285 [02:53<02:01,  1.02it/s]Loading train:  57%|█████▋    | 162/285 [02:54<02:03,  1.00s/it]Loading train:  57%|█████▋    | 163/285 [02:55<02:03,  1.01s/it]Loading train:  58%|█████▊    | 164/285 [02:56<01:56,  1.04it/s]Loading train:  58%|█████▊    | 165/285 [02:57<01:53,  1.05it/s]Loading train:  58%|█████▊    | 166/285 [02:57<01:50,  1.07it/s]Loading train:  59%|█████▊    | 167/285 [02:58<01:46,  1.11it/s]Loading train:  59%|█████▉    | 168/285 [02:59<01:43,  1.14it/s]Loading train:  59%|█████▉    | 169/285 [03:00<01:42,  1.13it/s]Loading train:  60%|█████▉    | 170/285 [03:01<01:39,  1.15it/s]Loading train:  60%|██████    | 171/285 [03:02<01:40,  1.13it/s]Loading train:  60%|██████    | 172/285 [03:03<01:37,  1.16it/s]Loading train:  61%|██████    | 173/285 [03:03<01:36,  1.16it/s]Loading train:  61%|██████    | 174/285 [03:04<01:35,  1.16it/s]Loading train:  61%|██████▏   | 175/285 [03:05<01:37,  1.13it/s]Loading train:  62%|██████▏   | 176/285 [03:06<01:33,  1.16it/s]Loading train:  62%|██████▏   | 177/285 [03:07<01:31,  1.18it/s]Loading train:  62%|██████▏   | 178/285 [03:08<01:33,  1.14it/s]Loading train:  63%|██████▎   | 179/285 [03:09<01:33,  1.13it/s]Loading train:  63%|██████▎   | 180/285 [03:09<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [03:10<01:33,  1.12it/s]Loading train:  64%|██████▍   | 182/285 [03:11<01:30,  1.14it/s]Loading train:  64%|██████▍   | 183/285 [03:12<01:30,  1.12it/s]Loading train:  65%|██████▍   | 184/285 [03:13<01:31,  1.10it/s]Loading train:  65%|██████▍   | 185/285 [03:14<01:29,  1.12it/s]Loading train:  65%|██████▌   | 186/285 [03:15<01:29,  1.11it/s]Loading train:  66%|██████▌   | 187/285 [03:16<01:27,  1.12it/s]Loading train:  66%|██████▌   | 188/285 [03:17<01:27,  1.11it/s]Loading train:  66%|██████▋   | 189/285 [03:18<01:32,  1.03it/s]Loading train:  67%|██████▋   | 190/285 [03:19<01:33,  1.02it/s]Loading train:  67%|██████▋   | 191/285 [03:20<01:27,  1.07it/s]Loading train:  67%|██████▋   | 192/285 [03:21<01:27,  1.06it/s]Loading train:  68%|██████▊   | 193/285 [03:21<01:23,  1.10it/s]Loading train:  68%|██████▊   | 194/285 [03:22<01:21,  1.12it/s]Loading train:  68%|██████▊   | 195/285 [03:23<01:17,  1.16it/s]Loading train:  69%|██████▉   | 196/285 [03:24<01:20,  1.10it/s]Loading train:  69%|██████▉   | 197/285 [03:25<01:22,  1.07it/s]Loading train:  69%|██████▉   | 198/285 [03:26<01:22,  1.05it/s]Loading train:  70%|██████▉   | 199/285 [03:27<01:22,  1.04it/s]Loading train:  70%|███████   | 200/285 [03:28<01:21,  1.05it/s]Loading train:  71%|███████   | 201/285 [03:29<01:19,  1.05it/s]Loading train:  71%|███████   | 202/285 [03:30<01:18,  1.06it/s]Loading train:  71%|███████   | 203/285 [03:31<01:18,  1.05it/s]Loading train:  72%|███████▏  | 204/285 [03:32<01:15,  1.07it/s]Loading train:  72%|███████▏  | 205/285 [03:33<01:17,  1.04it/s]Loading train:  72%|███████▏  | 206/285 [03:34<01:22,  1.04s/it]Loading train:  73%|███████▎  | 207/285 [03:35<01:19,  1.02s/it]Loading train:  73%|███████▎  | 208/285 [03:36<01:17,  1.00s/it]Loading train:  73%|███████▎  | 209/285 [03:37<01:15,  1.00it/s]Loading train:  74%|███████▎  | 210/285 [03:38<01:15,  1.00s/it]Loading train:  74%|███████▍  | 211/285 [03:39<01:12,  1.02it/s]Loading train:  74%|███████▍  | 212/285 [03:40<01:10,  1.03it/s]Loading train:  75%|███████▍  | 213/285 [03:41<01:10,  1.03it/s]Loading train:  75%|███████▌  | 214/285 [03:42<01:07,  1.06it/s]Loading train:  75%|███████▌  | 215/285 [03:43<01:04,  1.09it/s]Loading train:  76%|███████▌  | 216/285 [03:43<01:01,  1.12it/s]Loading train:  76%|███████▌  | 217/285 [03:44<01:01,  1.10it/s]Loading train:  76%|███████▋  | 218/285 [03:45<01:01,  1.08it/s]Loading train:  77%|███████▋  | 219/285 [03:46<01:01,  1.07it/s]Loading train:  77%|███████▋  | 220/285 [03:47<01:01,  1.06it/s]Loading train:  78%|███████▊  | 221/285 [03:48<01:00,  1.05it/s]Loading train:  78%|███████▊  | 222/285 [03:49<01:00,  1.04it/s]Loading train:  78%|███████▊  | 223/285 [03:50<00:59,  1.05it/s]Loading train:  79%|███████▊  | 224/285 [03:51<00:56,  1.07it/s]Loading train:  79%|███████▉  | 225/285 [03:52<00:58,  1.03it/s]Loading train:  79%|███████▉  | 226/285 [03:53<00:56,  1.04it/s]Loading train:  80%|███████▉  | 227/285 [03:54<00:54,  1.07it/s]Loading train:  80%|████████  | 228/285 [03:55<00:51,  1.10it/s]Loading train:  80%|████████  | 229/285 [03:56<00:49,  1.13it/s]Loading train:  81%|████████  | 230/285 [03:57<00:50,  1.08it/s]Loading train:  81%|████████  | 231/285 [03:57<00:49,  1.08it/s]Loading train:  81%|████████▏ | 232/285 [03:59<00:54,  1.02s/it]Loading train:  82%|████████▏ | 233/285 [04:00<00:53,  1.03s/it]Loading train:  82%|████████▏ | 234/285 [04:01<00:54,  1.06s/it]Loading train:  82%|████████▏ | 235/285 [04:02<00:53,  1.07s/it]Loading train:  83%|████████▎ | 236/285 [04:03<00:52,  1.08s/it]Loading train:  83%|████████▎ | 237/285 [04:04<00:50,  1.06s/it]Loading train:  84%|████████▎ | 238/285 [04:05<00:49,  1.06s/it]Loading train:  84%|████████▍ | 239/285 [04:06<00:49,  1.08s/it]Loading train:  84%|████████▍ | 240/285 [04:07<00:49,  1.10s/it]Loading train:  85%|████████▍ | 241/285 [04:09<00:48,  1.10s/it]Loading train:  85%|████████▍ | 242/285 [04:10<00:47,  1.10s/it]Loading train:  85%|████████▌ | 243/285 [04:11<00:44,  1.07s/it]Loading train:  86%|████████▌ | 244/285 [04:12<00:45,  1.12s/it]Loading train:  86%|████████▌ | 245/285 [04:13<00:45,  1.15s/it]Loading train:  86%|████████▋ | 246/285 [04:14<00:44,  1.13s/it]Loading train:  87%|████████▋ | 247/285 [04:15<00:42,  1.11s/it]Loading train:  87%|████████▋ | 248/285 [04:16<00:39,  1.07s/it]Loading train:  87%|████████▋ | 249/285 [04:17<00:38,  1.06s/it]Loading train:  88%|████████▊ | 250/285 [04:18<00:37,  1.08s/it]Loading train:  88%|████████▊ | 251/285 [04:19<00:35,  1.04s/it]Loading train:  88%|████████▊ | 252/285 [04:20<00:33,  1.01s/it]Loading train:  89%|████████▉ | 253/285 [04:21<00:31,  1.00it/s]Loading train:  89%|████████▉ | 254/285 [04:22<00:31,  1.01s/it]Loading train:  89%|████████▉ | 255/285 [04:23<00:30,  1.01s/it]Loading train:  90%|████████▉ | 256/285 [04:24<00:28,  1.02it/s]Loading train:  90%|█████████ | 257/285 [04:25<00:28,  1.00s/it]Loading train:  91%|█████████ | 258/285 [04:26<00:25,  1.04it/s]Loading train:  91%|█████████ | 259/285 [04:27<00:24,  1.05it/s]Loading train:  91%|█████████ | 260/285 [04:28<00:23,  1.06it/s]Loading train:  92%|█████████▏| 261/285 [04:29<00:22,  1.07it/s]Loading train:  92%|█████████▏| 262/285 [04:30<00:20,  1.10it/s]Loading train:  92%|█████████▏| 263/285 [04:31<00:19,  1.12it/s]Loading train:  93%|█████████▎| 264/285 [04:32<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [04:33<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [04:34<00:18,  1.01it/s]Loading train:  94%|█████████▎| 267/285 [04:35<00:17,  1.03it/s]Loading train:  94%|█████████▍| 268/285 [04:36<00:17,  1.01s/it]Loading train:  94%|█████████▍| 269/285 [04:37<00:16,  1.05s/it]Loading train:  95%|█████████▍| 270/285 [04:38<00:16,  1.10s/it]Loading train:  95%|█████████▌| 271/285 [04:39<00:15,  1.10s/it]Loading train:  95%|█████████▌| 272/285 [04:40<00:14,  1.12s/it]Loading train:  96%|█████████▌| 273/285 [04:41<00:13,  1.11s/it]Loading train:  96%|█████████▌| 274/285 [04:42<00:11,  1.09s/it]Loading train:  96%|█████████▋| 275/285 [04:43<00:10,  1.06s/it]Loading train:  97%|█████████▋| 276/285 [04:44<00:09,  1.04s/it]Loading train:  97%|█████████▋| 277/285 [04:46<00:08,  1.07s/it]Loading train:  98%|█████████▊| 278/285 [04:47<00:07,  1.08s/it]Loading train:  98%|█████████▊| 279/285 [04:48<00:06,  1.06s/it]Loading train:  98%|█████████▊| 280/285 [04:49<00:05,  1.05s/it]Loading train:  99%|█████████▊| 281/285 [04:50<00:04,  1.05s/it]Loading train:  99%|█████████▉| 282/285 [04:51<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [04:52<00:02,  1.06s/it]Loading train: 100%|█████████▉| 284/285 [04:53<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [04:54<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 44.26it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:05, 51.83it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:04, 57.49it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:03, 67.62it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:02, 81.34it/s]concatenating: train:  25%|██▍       | 70/285 [00:00<00:02, 98.73it/s]concatenating: train:  32%|███▏      | 90/285 [00:00<00:01, 115.94it/s]concatenating: train:  41%|████      | 116/285 [00:00<00:01, 138.97it/s]concatenating: train:  50%|█████     | 143/285 [00:00<00:00, 162.48it/s]concatenating: train:  60%|█████▉    | 170/285 [00:01<00:00, 184.07it/s]concatenating: train:  68%|██████▊   | 194/285 [00:01<00:00, 197.49it/s]concatenating: train:  78%|███████▊  | 222/285 [00:01<00:00, 216.44it/s]concatenating: train:  87%|████████▋ | 247/285 [00:01<00:00, 219.65it/s]concatenating: train:  95%|█████████▌| 271/285 [00:01<00:00, 221.78it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 190.66it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.52s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.47s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 60.85it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 80)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 80)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 160)  115360      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 160)    0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 7, 7, 160)    0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 7, 7, 320)    461120      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 7, 7, 320)    1280        conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 7, 7, 320)    0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 7, 7, 320)    921920      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 7, 7, 320)    1280        conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 7, 7, 320)    0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 7, 7, 320)    0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 160)  204960      dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 14, 14, 320)  0           conv2d_transpose_1[0][0]         2019-07-01 03:31:15.517656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-01 03:31:15.517798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-01 03:31:15.517814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-01 03:31:15.517823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-01 03:31:15.518252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 14, 160)  460960      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 14, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 14, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 14, 160)  230560      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 14, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 14, 160)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 14, 160)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 80)   51280       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 160)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 80)   115280      concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 28, 80)   320         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 28, 80)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 80)   57680       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 28, 80)   320         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 28, 80)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 28, 80)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 56, 56, 40)   12840       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 56, 80)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 56, 40)   28840       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 56, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 56, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 56, 40)   14440       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 56, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 56, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 56, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 56, 13)   533         dropout_7[0][0]                  
==================================================================================================
Total params: 3,014,773
Trainable params: 3,011,253
Non-trainable params: 3,520
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [2.84556655e+01 1.40109011e+01 3.28839521e+01 4.08704613e+00
 1.18795059e+01 3.09772677e+00 3.70666155e+01 4.93844078e+01
 3.77168295e+01 5.80852460e+00 1.28966869e+02 8.44275505e+01
 8.52866433e-02]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 31s - loss: 1027.6715 - acc: 0.9366 - mDice: 0.4599 - val_loss: 1160.7240 - val_acc: 0.9521 - val_mDice: 0.4474

Epoch 00001: val_mDice improved from -inf to 0.44739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 22s - loss: 499.0195 - acc: 0.9550 - mDice: 0.6517 - val_loss: 1183.3182 - val_acc: 0.9546 - val_mDice: 0.4986

Epoch 00002: val_mDice improved from 0.44739 to 0.49856, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 22s - loss: 423.0371 - acc: 0.9593 - mDice: 0.7011 - val_loss: 1142.2399 - val_acc: 0.9565 - val_mDice: 0.5272

Epoch 00003: val_mDice improved from 0.49856 to 0.52718, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 22s - loss: 384.9870 - acc: 0.9617 - mDice: 0.7269 - val_loss: 1209.5124 - val_acc: 0.9579 - val_mDice: 0.5245

Epoch 00004: val_mDice did not improve from 0.52718
Epoch 5/300
 - 22s - loss: 356.9147 - acc: 0.9631 - mDice: 0.7462 - val_loss: 1143.0811 - val_acc: 0.9586 - val_mDice: 0.5477

Epoch 00005: val_mDice improved from 0.52718 to 0.54775, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 22s - loss: 338.6007 - acc: 0.9641 - mDice: 0.7584 - val_loss: 1201.7978 - val_acc: 0.9588 - val_mDice: 0.5431

Epoch 00006: val_mDice did not improve from 0.54775
Epoch 7/300
 - 22s - loss: 323.1514 - acc: 0.9650 - mDice: 0.7694 - val_loss: 1314.0912 - val_acc: 0.9581 - val_mDice: 0.5319

Epoch 00007: val_mDice did not improve from 0.54775
Epoch 8/300
 - 22s - loss: 310.6503 - acc: 0.9657 - mDice: 0.7781 - val_loss: 1238.0694 - val_acc: 0.9591 - val_mDice: 0.5545

Epoch 00008: val_mDice improved from 0.54775 to 0.55450, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 22s - loss: 299.4482 - acc: 0.9663 - mDice: 0.7858 - val_loss: 1383.9192 - val_acc: 0.9586 - val_mDice: 0.5362

Epoch 00009: val_mDice did not improve from 0.55450
Epoch 10/300
 - 21s - loss: 291.5244 - acc: 0.9668 - mDice: 0.7913 - val_loss: 1320.2191 - val_acc: 0.9597 - val_mDice: 0.5537

Epoch 00010: val_mDice did not improve from 0.55450
Epoch 11/300
 - 22s - loss: 283.3675 - acc: 0.9671 - mDice: 0.7972 - val_loss: 1373.2583 - val_acc: 0.9594 - val_mDice: 0.5462

Epoch 00011: val_mDice did not improve from 0.55450
Epoch 12/300
 - 21s - loss: 276.6682 - acc: 0.9675 - mDice: 0.8021 - val_loss: 1398.9692 - val_acc: 0.9598 - val_mDice: 0.5512

Epoch 00012: val_mDice did not improve from 0.55450
Epoch 13/300
 - 22s - loss: 269.6355 - acc: 0.9678 - mDice: 0.8068 - val_loss: 1418.4552 - val_acc: 0.9586 - val_mDice: 0.5530

Epoch 00013: val_mDice did not improve from 0.55450
Epoch 14/300
 - 22s - loss: 263.9029 - acc: 0.9680 - mDice: 0.8108 - val_loss: 1466.4300 - val_acc: 0.9589 - val_mDice: 0.5470

Epoch 00014: val_mDice did not improve from 0.55450
Epoch 15/300
 - 22s - loss: 259.4190 - acc: 0.9681 - mDice: 0.8142 - val_loss: 1464.0900 - val_acc: 0.9589 - val_mDice: 0.5556

Epoch 00015: val_mDice improved from 0.55450 to 0.55558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 21s - loss: 255.5647 - acc: 0.9683 - mDice: 0.8168 - val_loss: 1428.0876 - val_acc: 0.9596 - val_mDice: 0.5590

Epoch 00016: val_mDice improved from 0.55558 to 0.55901, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 22s - loss: 250.7413 - acc: 0.9686 - mDice: 0.8202 - val_loss: 1469.1252 - val_acc: 0.9592 - val_mDice: 0.5488

Epoch 00017: val_mDice did not improve from 0.55901
Epoch 18/300
 - 22s - loss: 247.5057 - acc: 0.9687 - mDice: 0.8228 - val_loss: 1416.0192 - val_acc: 0.9596 - val_mDice: 0.5637

Epoch 00018: val_mDice improved from 0.55901 to 0.56370, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 23s - loss: 243.2309 - acc: 0.9690 - mDice: 0.8258 - val_loss: 1506.8877 - val_acc: 0.9579 - val_mDice: 0.5473

Epoch 00019: val_mDice did not improve from 0.56370
Epoch 20/300
 - 21s - loss: 237.6124 - acc: 0.9692 - mDice: 0.8293 - val_loss: 1585.4666 - val_acc: 0.9602 - val_mDice: 0.5419

Epoch 00020: val_mDice did not improve from 0.56370
Epoch 21/300
 - 22s - loss: 236.8798 - acc: 0.9694 - mDice: 0.8306 - val_loss: 1555.9311 - val_acc: 0.9596 - val_mDice: 0.5393

Epoch 00021: val_mDice did not improve from 0.56370
Epoch 22/300
 - 22s - loss: 232.3757 - acc: 0.9696 - mDice: 0.8337 - val_loss: 1525.6573 - val_acc: 0.9599 - val_mDice: 0.5530

Epoch 00022: val_mDice did not improve from 0.56370
Epoch 23/300
 - 22s - loss: 229.7999 - acc: 0.9697 - mDice: 0.8354 - val_loss: 1572.8903 - val_acc: 0.9598 - val_mDice: 0.5423

Epoch 00023: val_mDice did not improve from 0.56370
Epoch 24/300
 - 22s - loss: 227.4037 - acc: 0.9698 - mDice: 0.8374 - val_loss: 1562.5737 - val_acc: 0.9593 - val_mDice: 0.5511

Epoch 00024: val_mDice did not improve from 0.56370
Epoch 25/300
 - 22s - loss: 224.3486 - acc: 0.9700 - mDice: 0.8395 - val_loss: 1555.5598 - val_acc: 0.9595 - val_mDice: 0.5535

Epoch 00025: val_mDice did not improve from 0.56370
Epoch 26/300
 - 22s - loss: 222.1833 - acc: 0.9700 - mDice: 0.8408 - val_loss: 1491.9701 - val_acc: 0.9599 - val_mDice: 0.5595

Epoch 00026: val_mDice did not improve from 0.56370
Epoch 27/300
 - 22s - loss: 220.4212 - acc: 0.9701 - mDice: 0.8424 - val_loss: 1629.3537 - val_acc: 0.9586 - val_mDice: 0.5400

Epoch 00027: val_mDice did not improve from 0.56370
Epoch 28/300
 - 22s - loss: 218.1140 - acc: 0.9702 - mDice: 0.8438 - val_loss: 1651.4293 - val_acc: 0.9591 - val_mDice: 0.5456

Epoch 00028: val_mDice did not improve from 0.56370
Epoch 29/300
 - 22s - loss: 214.8135 - acc: 0.9704 - mDice: 0.8461 - val_loss: 1644.7265 - val_acc: 0.9598 - val_mDice: 0.5491

Epoch 00029: val_mDice did not improve from 0.56370
Epoch 30/300
 - 21s - loss: 212.7437 - acc: 0.9705 - mDice: 0.8476 - val_loss: 1577.9525 - val_acc: 0.9597 - val_mDice: 0.5598

Epoch 00030: val_mDice did not improve from 0.56370
Epoch 31/300
 - 22s - loss: 211.0421 - acc: 0.9705 - mDice: 0.8491 - val_loss: 1627.2268 - val_acc: 0.9598 - val_mDice: 0.5527

Epoch 00031: val_mDice did not improve from 0.56370
Epoch 32/300
 - 22s - loss: 209.5798 - acc: 0.9705 - mDice: 0.8500 - val_loss: 1652.1075 - val_acc: 0.9599 - val_mDice: 0.5509

Epoch 00032: val_mDice did not improve from 0.56370
Epoch 33/300
 - 22s - loss: 206.9718 - acc: 0.9705 - mDice: 0.8518 - val_loss: 1695.0358 - val_acc: 0.9594 - val_mDice: 0.5454

Epoch 00033: val_mDice did not improve from 0.56370
Epoch 34/300
 - 21s - loss: 205.3768 - acc: 0.9706 - mDice: 0.8531 - val_loss: 1673.2542 - val_acc: 0.9592 - val_mDice: 0.5442

Epoch 00034: val_mDice did not improve from 0.56370
Epoch 35/300
 - 22s - loss: 203.9933 - acc: 0.9707 - mDice: 0.8540 - val_loss: 1631.6614 - val_acc: 0.9598 - val_mDice: 0.5576

Epoch 00035: val_mDice did not improve from 0.56370
Epoch 36/300
 - 22s - loss: 201.6757 - acc: 0.9710 - mDice: 0.8556 - val_loss: 1672.9857 - val_acc: 0.9599 - val_mDice: 0.5554

Epoch 00036: val_mDice did not improve from 0.56370
Epoch 37/300
 - 21s - loss: 200.1904 - acc: 0.9709 - mDice: 0.8568 - val_loss: 1727.2363 - val_acc: 0.9596 - val_mDice: 0.5473

Epoch 00037: val_mDice did not improve from 0.56370
Epoch 38/300
 - 21s - loss: 199.4636 - acc: 0.9710 - mDice: 0.8574 - val_loss: 1632.1549 - val_acc: 0.9597 - val_mDice: 0.5573

Epoch 00038: val_mDice did not improve from 0.56370
Epoch 39/300
 - 22s - loss: 197.4824 - acc: 0.9712 - mDice: 0.8591 - val_loss: 1674.3011 - val_acc: 0.9596 - val_mDice: 0.5575

Epoch 00039: val_mDice did not improve from 0.56370
Epoch 40/300
 - 22s - loss: 196.2801 - acc: 0.9712 - mDice: 0.8598 - val_loss: 1711.1967 - val_acc: 0.9597 - val_mDice: 0.5433

Epoch 00040: val_mDice did not improve from 0.56370
Epoch 41/300
 - 21s - loss: 194.8457 - acc: 0.9713 - mDice: 0.8607 - val_loss: 1718.5312 - val_acc: 0.9598 - val_mDice: 0.5525

Epoch 00041: val_mDice did not improve from 0.56370
Epoch 42/300
 - 21s - loss: 193.2094 - acc: 0.9713 - mDice: 0.8621 - val_loss: 1757.4472 - val_acc: 0.9605 - val_mDice: 0.5450

Epoch 00042: val_mDice did not improve from 0.56370
Epoch 43/300
 - 21s - loss: 192.7453 - acc: 0.9715 - mDice: 0.8622 - val_loss: 1762.4074 - val_acc: 0.9604 - val_mDice: 0.5520

Epoch 00043: val_mDice did not improve from 0.56370
Epoch 44/300
 - 22s - loss: 190.7673 - acc: 0.9715 - mDice: 0.8637 - val_loss: 1749.9149 - val_acc: 0.9601 - val_mDice: 0.5481

Epoch 00044: val_mDice did not improve from 0.56370
Epoch 45/300
 - 21s - loss: 188.2584 - acc: 0.9717 - mDice: 0.8654 - val_loss: 1749.6228 - val_acc: 0.9596 - val_mDice: 0.5534

Epoch 00045: val_mDice did not improve from 0.56370
Epoch 46/300
 - 21s - loss: 188.3416 - acc: 0.9716 - mDice: 0.8655 - val_loss: 1690.4899 - val_acc: 0.9601 - val_mDice: 0.5598

Epoch 00046: val_mDice did not improve from 0.56370
Epoch 47/300
 - 21s - loss: 186.3226 - acc: 0.9717 - mDice: 0.8668 - val_loss: 1706.9104 - val_acc: 0.9603 - val_mDice: 0.5537

Epoch 00047: val_mDice did not improve from 0.56370
Epoch 48/300
 - 22s - loss: 185.3467 - acc: 0.9717 - mDice: 0.8677 - val_loss: 1816.7870 - val_acc: 0.9601 - val_mDice: 0.5438

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.50s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.26s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.06s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:33,  1.60s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:00,  1.70s/it]predicting train subjects:   1%|          | 3/285 [00:05<07:59,  1.70s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:18,  1.77s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:00,  1.72s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:24,  1.81s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:04,  1.96s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:14,  2.00s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:53,  1.93s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:07,  1.99s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:24,  2.06s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:32,  2.10s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:34,  2.11s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:44,  2.16s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:50,  2.19s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<10:02,  2.24s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:45,  2.18s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:45,  2.19s/it]predicting train subjects:   7%|▋         | 19/285 [00:39<09:46,  2.21s/it]predicting train subjects:   7%|▋         | 20/285 [00:41<09:45,  2.21s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:53,  2.25s/it]predicting train subjects:   8%|▊         | 22/285 [00:45<09:42,  2.21s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:39,  2.21s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<09:35,  2.21s/it]predicting train subjects:   9%|▉         | 25/285 [00:52<09:31,  2.20s/it]predicting train subjects:   9%|▉         | 26/285 [00:54<09:31,  2.21s/it]predicting train subjects:   9%|▉         | 27/285 [00:56<09:39,  2.24s/it]predicting train subjects:  10%|▉         | 28/285 [00:58<09:16,  2.16s/it]predicting train subjects:  10%|█         | 29/285 [01:00<08:52,  2.08s/it]predicting train subjects:  11%|█         | 30/285 [01:02<08:56,  2.11s/it]predicting train subjects:  11%|█         | 31/285 [01:04<08:43,  2.06s/it]predicting train subjects:  11%|█         | 32/285 [01:06<08:29,  2.01s/it]predicting train subjects:  12%|█▏        | 33/285 [01:08<08:31,  2.03s/it]predicting train subjects:  12%|█▏        | 34/285 [01:10<08:29,  2.03s/it]predicting train subjects:  12%|█▏        | 35/285 [01:12<08:26,  2.03s/it]predicting train subjects:  13%|█▎        | 36/285 [01:14<08:19,  2.00s/it]predicting train subjects:  13%|█▎        | 37/285 [01:16<08:14,  2.00s/it]predicting train subjects:  13%|█▎        | 38/285 [01:18<08:10,  1.99s/it]predicting train subjects:  14%|█▎        | 39/285 [01:20<08:12,  2.00s/it]predicting train subjects:  14%|█▍        | 40/285 [01:22<08:04,  1.98s/it]predicting train subjects:  14%|█▍        | 41/285 [01:24<08:01,  1.97s/it]predicting train subjects:  15%|█▍        | 42/285 [01:26<07:52,  1.95s/it]predicting train subjects:  15%|█▌        | 43/285 [01:28<07:50,  1.95s/it]predicting train subjects:  15%|█▌        | 44/285 [01:30<07:44,  1.93s/it]predicting train subjects:  16%|█▌        | 45/285 [01:32<07:39,  1.91s/it]predicting train subjects:  16%|█▌        | 46/285 [01:34<07:27,  1.87s/it]predicting train subjects:  16%|█▋        | 47/285 [01:35<07:17,  1.84s/it]predicting train subjects:  17%|█▋        | 48/285 [01:37<07:11,  1.82s/it]predicting train subjects:  17%|█▋        | 49/285 [01:39<07:08,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:41<07:05,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:42<06:53,  1.77s/it]predicting train subjects:  18%|█▊        | 52/285 [01:44<06:55,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:46<06:55,  1.79s/it]predicting train subjects:  19%|█▉        | 54/285 [01:48<06:50,  1.78s/it]predicting train subjects:  19%|█▉        | 55/285 [01:49<06:47,  1.77s/it]predicting train subjects:  20%|█▉        | 56/285 [01:51<06:46,  1.77s/it]predicting train subjects:  20%|██        | 57/285 [01:53<06:41,  1.76s/it]predicting train subjects:  20%|██        | 58/285 [01:55<06:46,  1.79s/it]predicting train subjects:  21%|██        | 59/285 [01:57<06:45,  1.80s/it]predicting train subjects:  21%|██        | 60/285 [01:58<06:43,  1.80s/it]predicting train subjects:  21%|██▏       | 61/285 [02:00<06:41,  1.79s/it]predicting train subjects:  22%|██▏       | 62/285 [02:02<06:37,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [02:04<06:33,  1.77s/it]predicting train subjects:  22%|██▏       | 64/285 [02:06<06:36,  1.79s/it]predicting train subjects:  23%|██▎       | 65/285 [02:08<06:42,  1.83s/it]predicting train subjects:  23%|██▎       | 66/285 [02:10<06:55,  1.90s/it]predicting train subjects:  24%|██▎       | 67/285 [02:11<06:49,  1.88s/it]predicting train subjects:  24%|██▍       | 68/285 [02:13<06:37,  1.83s/it]predicting train subjects:  24%|██▍       | 69/285 [02:15<06:34,  1.83s/it]predicting train subjects:  25%|██▍       | 70/285 [02:17<06:33,  1.83s/it]predicting train subjects:  25%|██▍       | 71/285 [02:19<06:30,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:21<06:35,  1.86s/it]predicting train subjects:  26%|██▌       | 73/285 [02:22<06:39,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:24<06:34,  1.87s/it]predicting train subjects:  26%|██▋       | 75/285 [02:26<06:29,  1.85s/it]predicting train subjects:  27%|██▋       | 76/285 [02:28<06:24,  1.84s/it]predicting train subjects:  27%|██▋       | 77/285 [02:30<06:20,  1.83s/it]predicting train subjects:  27%|██▋       | 78/285 [02:32<06:19,  1.83s/it]predicting train subjects:  28%|██▊       | 79/285 [02:33<06:16,  1.83s/it]predicting train subjects:  28%|██▊       | 80/285 [02:35<06:13,  1.82s/it]predicting train subjects:  28%|██▊       | 81/285 [02:37<06:11,  1.82s/it]predicting train subjects:  29%|██▉       | 82/285 [02:39<06:07,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:41<06:04,  1.80s/it]predicting train subjects:  29%|██▉       | 84/285 [02:42<06:01,  1.80s/it]predicting train subjects:  30%|██▉       | 85/285 [02:44<06:12,  1.86s/it]predicting train subjects:  30%|███       | 86/285 [02:46<06:14,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:48<06:21,  1.93s/it]predicting train subjects:  31%|███       | 88/285 [02:50<06:25,  1.96s/it]predicting train subjects:  31%|███       | 89/285 [02:52<06:24,  1.96s/it]predicting train subjects:  32%|███▏      | 90/285 [02:54<06:23,  1.97s/it]predicting train subjects:  32%|███▏      | 91/285 [02:56<06:20,  1.96s/it]predicting train subjects:  32%|███▏      | 92/285 [02:58<06:20,  1.97s/it]predicting train subjects:  33%|███▎      | 93/285 [03:00<06:15,  1.96s/it]predicting train subjects:  33%|███▎      | 94/285 [03:02<06:19,  1.99s/it]predicting train subjects:  33%|███▎      | 95/285 [03:04<06:12,  1.96s/it]predicting train subjects:  34%|███▎      | 96/285 [03:06<06:10,  1.96s/it]predicting train subjects:  34%|███▍      | 97/285 [03:08<06:09,  1.97s/it]predicting train subjects:  34%|███▍      | 98/285 [03:10<06:10,  1.98s/it]predicting train subjects:  35%|███▍      | 99/285 [03:12<06:04,  1.96s/it]predicting train subjects:  35%|███▌      | 100/285 [03:14<06:06,  1.98s/it]predicting train subjects:  35%|███▌      | 101/285 [03:16<06:01,  1.97s/it]predicting train subjects:  36%|███▌      | 102/285 [03:18<06:07,  2.01s/it]predicting train subjects:  36%|███▌      | 103/285 [03:20<06:04,  2.00s/it]predicting train subjects:  36%|███▋      | 104/285 [03:22<06:01,  2.00s/it]predicting train subjects:  37%|███▋      | 105/285 [03:24<05:56,  1.98s/it]predicting train subjects:  37%|███▋      | 106/285 [03:26<05:58,  2.00s/it]predicting train subjects:  38%|███▊      | 107/285 [03:28<05:54,  1.99s/it]predicting train subjects:  38%|███▊      | 108/285 [03:30<05:48,  1.97s/it]predicting train subjects:  38%|███▊      | 109/285 [03:32<05:41,  1.94s/it]predicting train subjects:  39%|███▊      | 110/285 [03:34<05:44,  1.97s/it]predicting train subjects:  39%|███▉      | 111/285 [03:36<05:40,  1.96s/it]predicting train subjects:  39%|███▉      | 112/285 [03:38<05:37,  1.95s/it]predicting train subjects:  40%|███▉      | 113/285 [03:40<05:29,  1.92s/it]predicting train subjects:  40%|████      | 114/285 [03:41<05:26,  1.91s/it]predicting train subjects:  40%|████      | 115/285 [03:43<05:25,  1.92s/it]predicting train subjects:  41%|████      | 116/285 [03:45<05:23,  1.92s/it]predicting train subjects:  41%|████      | 117/285 [03:47<05:25,  1.94s/it]predicting train subjects:  41%|████▏     | 118/285 [03:49<05:21,  1.92s/it]predicting train subjects:  42%|████▏     | 119/285 [03:51<05:18,  1.92s/it]predicting train subjects:  42%|████▏     | 120/285 [03:53<05:14,  1.91s/it]predicting train subjects:  42%|████▏     | 121/285 [03:55<05:00,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:56<04:46,  1.76s/it]predicting train subjects:  43%|████▎     | 123/285 [03:58<04:36,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [04:00<04:38,  1.73s/it]predicting train subjects:  44%|████▍     | 125/285 [04:01<04:36,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [04:03<04:37,  1.75s/it]predicting train subjects:  45%|████▍     | 127/285 [04:05<04:36,  1.75s/it]predicting train subjects:  45%|████▍     | 128/285 [04:07<04:35,  1.76s/it]predicting train subjects:  45%|████▌     | 129/285 [04:08<04:35,  1.77s/it]predicting train subjects:  46%|████▌     | 130/285 [04:10<04:34,  1.77s/it]predicting train subjects:  46%|████▌     | 131/285 [04:12<04:30,  1.75s/it]predicting train subjects:  46%|████▋     | 132/285 [04:14<04:25,  1.74s/it]predicting train subjects:  47%|████▋     | 133/285 [04:15<04:21,  1.72s/it]predicting train subjects:  47%|████▋     | 134/285 [04:17<04:19,  1.72s/it]predicting train subjects:  47%|████▋     | 135/285 [04:19<04:22,  1.75s/it]predicting train subjects:  48%|████▊     | 136/285 [04:21<04:25,  1.78s/it]predicting train subjects:  48%|████▊     | 137/285 [04:22<04:21,  1.77s/it]predicting train subjects:  48%|████▊     | 138/285 [04:24<04:22,  1.78s/it]predicting train subjects:  49%|████▉     | 139/285 [04:26<04:16,  1.76s/it]predicting train subjects:  49%|████▉     | 140/285 [04:28<04:13,  1.74s/it]predicting train subjects:  49%|████▉     | 141/285 [04:29<04:12,  1.75s/it]predicting train subjects:  50%|████▉     | 142/285 [04:31<04:07,  1.73s/it]predicting train subjects:  50%|█████     | 143/285 [04:33<04:00,  1.70s/it]predicting train subjects:  51%|█████     | 144/285 [04:34<04:02,  1.72s/it]predicting train subjects:  51%|█████     | 145/285 [04:36<03:55,  1.68s/it]predicting train subjects:  51%|█████     | 146/285 [04:38<03:48,  1.64s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:39<03:45,  1.64s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:41<03:44,  1.64s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:42<03:40,  1.62s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:44<03:40,  1.63s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:46<03:42,  1.66s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:47<03:40,  1.65s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:49<03:35,  1.64s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:51<03:33,  1.63s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:52<03:30,  1.62s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:54<03:31,  1.64s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:56<03:34,  1.68s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:57<03:30,  1.66s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:59<03:28,  1.65s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:01<03:29,  1.67s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:02<03:22,  1.63s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:04<03:18,  1.61s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:05<03:14,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:07<03:14,  1.61s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:09<03:18,  1.65s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:10<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:12<03:13,  1.64s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:14<03:10,  1.63s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:15<03:06,  1.61s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:17<03:03,  1.59s/it]predicting train subjects:  60%|██████    | 171/285 [05:18<03:01,  1.59s/it]predicting train subjects:  60%|██████    | 172/285 [05:20<02:57,  1.57s/it]predicting train subjects:  61%|██████    | 173/285 [05:21<02:55,  1.57s/it]predicting train subjects:  61%|██████    | 174/285 [05:23<02:53,  1.56s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:25<02:55,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:26<02:52,  1.58s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:28<02:50,  1.58s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:29<02:48,  1.58s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:31<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:32<02:43,  1.56s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:34<02:40,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:35<02:36,  1.52s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:37<02:33,  1.50s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:38<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:40<02:27,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:41<02:24,  1.46s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:43<02:24,  1.48s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:44<02:23,  1.48s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:46<02:21,  1.47s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:47<02:21,  1.49s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:49<02:21,  1.50s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:50<02:19,  1.50s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:52<02:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:53<02:19,  1.53s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:55<02:17,  1.53s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:57<02:24,  1.62s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:58<02:25,  1.65s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:00<02:28,  1.70s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:02<02:27,  1.72s/it]predicting train subjects:  70%|███████   | 200/285 [06:04<02:26,  1.73s/it]predicting train subjects:  71%|███████   | 201/285 [06:06<02:27,  1.75s/it]predicting train subjects:  71%|███████   | 202/285 [06:07<02:26,  1.77s/it]predicting train subjects:  71%|███████   | 203/285 [06:09<02:25,  1.77s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:11<02:23,  1.77s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:13<02:22,  1.78s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:14<02:21,  1.79s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:16<02:22,  1.83s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:18<02:20,  1.83s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:20<02:17,  1.81s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:22<02:16,  1.82s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:24<02:15,  1.83s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:26<02:13,  1.82s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:27<02:11,  1.83s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:29<02:04,  1.76s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:31<01:59,  1.71s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:32<01:54,  1.66s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:34<01:49,  1.61s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:35<01:45,  1.58s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:37<01:43,  1.57s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:38<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:40<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:41<01:39,  1.58s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:43<01:39,  1.60s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:45<01:37,  1.60s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:46<01:34,  1.57s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:48<01:31,  1.55s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:49<01:28,  1.52s/it]predicting train subjects:  80%|████████  | 228/285 [06:50<01:25,  1.50s/it]predicting train subjects:  80%|████████  | 229/285 [06:52<01:24,  1.50s/it]predicting train subjects:  81%|████████  | 230/285 [06:54<01:24,  1.54s/it]predicting train subjects:  81%|████████  | 231/285 [06:55<01:25,  1.58s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:57<01:28,  1.67s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:59<01:30,  1.75s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:01<01:31,  1.80s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:03<01:30,  1.82s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:05<01:29,  1.82s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:07<01:30,  1.88s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:09<01:28,  1.88s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:10<01:25,  1.86s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:12<01:23,  1.86s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:14<01:23,  1.90s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:16<01:21,  1.89s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:18<01:19,  1.89s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:20<01:16,  1.88s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:22<01:18,  1.96s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:24<01:16,  1.97s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:26<01:15,  1.99s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:28<01:14,  2.00s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:30<01:13,  2.04s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:32<01:06,  1.89s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:33<01:00,  1.77s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:35<00:56,  1.72s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:37<00:56,  1.76s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:38<00:52,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:40<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:41<00:46,  1.59s/it]predicting train subjects:  90%|█████████ | 257/285 [07:43<00:43,  1.55s/it]predicting train subjects:  91%|█████████ | 258/285 [07:44<00:41,  1.53s/it]predicting train subjects:  91%|█████████ | 259/285 [07:46<00:39,  1.52s/it]predicting train subjects:  91%|█████████ | 260/285 [07:47<00:38,  1.53s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:49<00:36,  1.53s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:50<00:35,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:52<00:33,  1.53s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:53<00:32,  1.53s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:55<00:30,  1.52s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:56<00:29,  1.54s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:58<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:00<00:27,  1.65s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:02<00:28,  1.75s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:04<00:27,  1.83s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:06<00:25,  1.85s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:08<00:24,  1.89s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:10<00:22,  1.90s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:12<00:20,  1.90s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:13<00:19,  1.92s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:15<00:17,  1.92s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:17<00:15,  1.93s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:19<00:13,  1.94s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:21<00:11,  1.92s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:23<00:09,  1.91s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:25<00:07,  1.93s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:27<00:05,  1.91s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:29<00:03,  1.92s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:31<00:01,  1.91s/it]predicting train subjects: 100%|██████████| 285/285 [08:33<00:00,  1.92s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:16,  1.54s/it]Loading train:   1%|          | 2/285 [00:03<07:13,  1.53s/it]Loading train:   1%|          | 3/285 [00:04<06:59,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:06<07:15,  1.55s/it]Loading train:   2%|▏         | 5/285 [00:07<07:02,  1.51s/it]Loading train:   2%|▏         | 6/285 [00:09<07:13,  1.55s/it]Loading train:   2%|▏         | 7/285 [00:11<07:42,  1.66s/it]Loading train:   3%|▎         | 8/285 [00:12<07:50,  1.70s/it]Loading train:   3%|▎         | 9/285 [00:14<07:25,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<06:34,  1.44s/it]Loading train:   4%|▍         | 11/285 [00:16<06:39,  1.46s/it]Loading train:   4%|▍         | 12/285 [00:18<06:30,  1.43s/it]Loading train:   5%|▍         | 13/285 [00:19<06:03,  1.34s/it]Loading train:   5%|▍         | 14/285 [00:20<05:48,  1.29s/it]Loading train:   5%|▌         | 15/285 [00:21<05:34,  1.24s/it]Loading train:   6%|▌         | 16/285 [00:22<05:23,  1.20s/it]Loading train:   6%|▌         | 17/285 [00:23<05:24,  1.21s/it]Loading train:   6%|▋         | 18/285 [00:25<05:36,  1.26s/it]Loading train:   7%|▋         | 19/285 [00:26<05:37,  1.27s/it]Loading train:   7%|▋         | 20/285 [00:27<05:40,  1.28s/it]Loading train:   7%|▋         | 21/285 [00:29<05:23,  1.23s/it]Loading train:   8%|▊         | 22/285 [00:30<05:26,  1.24s/it]Loading train:   8%|▊         | 23/285 [00:31<05:22,  1.23s/it]Loading train:   8%|▊         | 24/285 [00:32<05:17,  1.22s/it]Loading train:   9%|▉         | 25/285 [00:34<05:28,  1.26s/it]Loading train:   9%|▉         | 26/285 [00:35<05:42,  1.32s/it]Loading train:   9%|▉         | 27/285 [00:36<05:26,  1.26s/it]Loading train:  10%|▉         | 28/285 [00:37<05:21,  1.25s/it]Loading train:  10%|█         | 29/285 [00:39<05:39,  1.33s/it]Loading train:  11%|█         | 30/285 [00:40<05:30,  1.30s/it]Loading train:  11%|█         | 31/285 [00:42<05:39,  1.34s/it]Loading train:  11%|█         | 32/285 [00:43<05:31,  1.31s/it]Loading train:  12%|█▏        | 33/285 [00:44<05:07,  1.22s/it]Loading train:  12%|█▏        | 34/285 [00:45<05:08,  1.23s/it]Loading train:  12%|█▏        | 35/285 [00:46<05:03,  1.21s/it]Loading train:  13%|█▎        | 36/285 [00:48<05:03,  1.22s/it]Loading train:  13%|█▎        | 37/285 [00:49<04:58,  1.21s/it]Loading train:  13%|█▎        | 38/285 [00:50<04:52,  1.19s/it]Loading train:  14%|█▎        | 39/285 [00:51<04:43,  1.15s/it]Loading train:  14%|█▍        | 40/285 [00:52<04:50,  1.18s/it]Loading train:  14%|█▍        | 41/285 [00:53<04:48,  1.18s/it]Loading train:  15%|█▍        | 42/285 [00:54<04:41,  1.16s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:41,  1.16s/it]Loading train:  15%|█▌        | 44/285 [00:57<04:42,  1.17s/it]Loading train:  16%|█▌        | 45/285 [00:58<04:47,  1.20s/it]Loading train:  16%|█▌        | 46/285 [00:59<04:40,  1.17s/it]Loading train:  16%|█▋        | 47/285 [01:00<04:34,  1.15s/it]Loading train:  17%|█▋        | 48/285 [01:01<04:34,  1.16s/it]Loading train:  17%|█▋        | 49/285 [01:03<04:45,  1.21s/it]Loading train:  18%|█▊        | 50/285 [01:04<04:50,  1.23s/it]Loading train:  18%|█▊        | 51/285 [01:05<04:32,  1.16s/it]Loading train:  18%|█▊        | 52/285 [01:06<04:32,  1.17s/it]Loading train:  19%|█▊        | 53/285 [01:07<04:30,  1.16s/it]Loading train:  19%|█▉        | 54/285 [01:09<04:44,  1.23s/it]Loading train:  19%|█▉        | 55/285 [01:10<04:52,  1.27s/it]Loading train:  20%|█▉        | 56/285 [01:11<04:41,  1.23s/it]Loading train:  20%|██        | 57/285 [01:12<04:34,  1.20s/it]Loading train:  20%|██        | 58/285 [01:13<04:09,  1.10s/it]Loading train:  21%|██        | 59/285 [01:14<03:57,  1.05s/it]Loading train:  21%|██        | 60/285 [01:15<03:59,  1.07s/it]Loading train:  21%|██▏       | 61/285 [01:16<04:03,  1.09s/it]Loading train:  22%|██▏       | 62/285 [01:18<04:02,  1.09s/it]Loading train:  22%|██▏       | 63/285 [01:19<03:55,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:20<04:31,  1.23s/it]Loading train:  23%|██▎       | 65/285 [01:22<05:02,  1.37s/it]Loading train:  23%|██▎       | 66/285 [01:24<05:25,  1.49s/it]Loading train:  24%|██▎       | 67/285 [01:25<05:05,  1.40s/it]Loading train:  24%|██▍       | 68/285 [01:26<04:53,  1.35s/it]Loading train:  24%|██▍       | 69/285 [01:27<04:52,  1.35s/it]Loading train:  25%|██▍       | 70/285 [01:29<04:32,  1.27s/it]Loading train:  25%|██▍       | 71/285 [01:30<04:21,  1.22s/it]Loading train:  25%|██▌       | 72/285 [01:31<04:00,  1.13s/it]Loading train:  26%|██▌       | 73/285 [01:32<03:54,  1.11s/it]Loading train:  26%|██▌       | 74/285 [01:33<03:52,  1.10s/it]Loading train:  26%|██▋       | 75/285 [01:34<03:46,  1.08s/it]Loading train:  27%|██▋       | 76/285 [01:35<03:43,  1.07s/it]Loading train:  27%|██▋       | 77/285 [01:36<03:31,  1.02s/it]Loading train:  27%|██▋       | 78/285 [01:37<03:20,  1.03it/s]Loading train:  28%|██▊       | 79/285 [01:38<03:21,  1.02it/s]Loading train:  28%|██▊       | 80/285 [01:39<03:23,  1.01it/s]Loading train:  28%|██▊       | 81/285 [01:40<03:25,  1.01s/it]Loading train:  29%|██▉       | 82/285 [01:41<03:28,  1.03s/it]Loading train:  29%|██▉       | 83/285 [01:42<03:45,  1.12s/it]Loading train:  29%|██▉       | 84/285 [01:43<03:41,  1.10s/it]Loading train:  30%|██▉       | 85/285 [01:44<03:43,  1.12s/it]Loading train:  30%|███       | 86/285 [01:45<03:45,  1.13s/it]Loading train:  31%|███       | 87/285 [01:47<03:49,  1.16s/it]Loading train:  31%|███       | 88/285 [01:48<03:45,  1.15s/it]Loading train:  31%|███       | 89/285 [01:49<03:42,  1.14s/it]Loading train:  32%|███▏      | 90/285 [01:50<03:39,  1.13s/it]Loading train:  32%|███▏      | 91/285 [01:51<03:31,  1.09s/it]Loading train:  32%|███▏      | 92/285 [01:52<03:34,  1.11s/it]Loading train:  33%|███▎      | 93/285 [01:53<03:31,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:54<03:39,  1.15s/it]Loading train:  33%|███▎      | 95/285 [01:56<03:36,  1.14s/it]Loading train:  34%|███▎      | 96/285 [01:57<03:35,  1.14s/it]Loading train:  34%|███▍      | 97/285 [01:58<03:27,  1.10s/it]Loading train:  34%|███▍      | 98/285 [01:59<03:34,  1.15s/it]Loading train:  35%|███▍      | 99/285 [02:00<03:44,  1.21s/it]Loading train:  35%|███▌      | 100/285 [02:02<03:52,  1.26s/it]Loading train:  35%|███▌      | 101/285 [02:03<03:35,  1.17s/it]Loading train:  36%|███▌      | 102/285 [02:04<03:28,  1.14s/it]Loading train:  36%|███▌      | 103/285 [02:05<03:32,  1.17s/it]Loading train:  36%|███▋      | 104/285 [02:06<03:29,  1.16s/it]Loading train:  37%|███▋      | 105/285 [02:07<03:29,  1.17s/it]Loading train:  37%|███▋      | 106/285 [02:09<03:33,  1.19s/it]Loading train:  38%|███▊      | 107/285 [02:10<03:23,  1.14s/it]Loading train:  38%|███▊      | 108/285 [02:11<03:18,  1.12s/it]Loading train:  38%|███▊      | 109/285 [02:12<03:10,  1.08s/it]Loading train:  39%|███▊      | 110/285 [02:13<03:10,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:14<03:10,  1.10s/it]Loading train:  39%|███▉      | 112/285 [02:15<03:19,  1.15s/it]Loading train:  40%|███▉      | 113/285 [02:17<03:36,  1.26s/it]Loading train:  40%|████      | 114/285 [02:18<03:24,  1.20s/it]Loading train:  40%|████      | 115/285 [02:19<03:24,  1.20s/it]Loading train:  41%|████      | 116/285 [02:20<03:19,  1.18s/it]Loading train:  41%|████      | 117/285 [02:21<03:09,  1.13s/it]Loading train:  41%|████▏     | 118/285 [02:22<03:06,  1.12s/it]Loading train:  42%|████▏     | 119/285 [02:23<03:00,  1.09s/it]Loading train:  42%|████▏     | 120/285 [02:24<03:11,  1.16s/it]Loading train:  42%|████▏     | 121/285 [02:26<03:22,  1.24s/it]Loading train:  43%|████▎     | 122/285 [02:27<03:29,  1.29s/it]Loading train:  43%|████▎     | 123/285 [02:29<03:28,  1.29s/it]Loading train:  44%|████▎     | 124/285 [02:29<03:10,  1.18s/it]Loading train:  44%|████▍     | 125/285 [02:31<03:02,  1.14s/it]Loading train:  44%|████▍     | 126/285 [02:32<02:57,  1.11s/it]Loading train:  45%|████▍     | 127/285 [02:33<02:57,  1.12s/it]Loading train:  45%|████▍     | 128/285 [02:34<02:53,  1.11s/it]Loading train:  45%|████▌     | 129/285 [02:35<02:51,  1.10s/it]Loading train:  46%|████▌     | 130/285 [02:36<02:55,  1.13s/it]Loading train:  46%|████▌     | 131/285 [02:37<02:48,  1.09s/it]Loading train:  46%|████▋     | 132/285 [02:38<02:44,  1.08s/it]Loading train:  47%|████▋     | 133/285 [02:39<02:40,  1.06s/it]Loading train:  47%|████▋     | 134/285 [02:40<02:37,  1.05s/it]Loading train:  47%|████▋     | 135/285 [02:41<02:40,  1.07s/it]Loading train:  48%|████▊     | 136/285 [02:42<02:36,  1.05s/it]Loading train:  48%|████▊     | 137/285 [02:43<02:29,  1.01s/it]Loading train:  48%|████▊     | 138/285 [02:44<02:35,  1.06s/it]Loading train:  49%|████▉     | 139/285 [02:45<02:27,  1.01s/it]Loading train:  49%|████▉     | 140/285 [02:46<02:29,  1.03s/it]Loading train:  49%|████▉     | 141/285 [02:48<02:40,  1.11s/it]Loading train:  50%|████▉     | 142/285 [02:49<02:32,  1.07s/it]Loading train:  50%|█████     | 143/285 [02:50<02:25,  1.03s/it]Loading train:  51%|█████     | 144/285 [02:50<02:17,  1.02it/s]Loading train:  51%|█████     | 145/285 [02:51<02:19,  1.00it/s]Loading train:  51%|█████     | 146/285 [02:53<02:26,  1.06s/it]Loading train:  52%|█████▏    | 147/285 [02:54<02:22,  1.03s/it]Loading train:  52%|█████▏    | 148/285 [02:55<02:21,  1.03s/it]Loading train:  52%|█████▏    | 149/285 [02:56<02:14,  1.01it/s]Loading train:  53%|█████▎    | 150/285 [02:57<02:14,  1.00it/s]Loading train:  53%|█████▎    | 151/285 [02:58<02:12,  1.01it/s]Loading train:  53%|█████▎    | 152/285 [02:58<02:06,  1.05it/s]Loading train:  54%|█████▎    | 153/285 [02:59<02:10,  1.01it/s]Loading train:  54%|█████▍    | 154/285 [03:00<02:05,  1.04it/s]Loading train:  54%|█████▍    | 155/285 [03:01<02:02,  1.06it/s]Loading train:  55%|█████▍    | 156/285 [03:02<01:59,  1.08it/s]Loading train:  55%|█████▌    | 157/285 [03:03<01:58,  1.08it/s]Loading train:  55%|█████▌    | 158/285 [03:04<02:02,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [03:05<02:04,  1.02it/s]Loading train:  56%|█████▌    | 160/285 [03:06<02:02,  1.02it/s]Loading train:  56%|█████▋    | 161/285 [03:07<02:02,  1.02it/s]Loading train:  57%|█████▋    | 162/285 [03:08<02:05,  1.02s/it]Loading train:  57%|█████▋    | 163/285 [03:09<01:57,  1.04it/s]Loading train:  58%|█████▊    | 164/285 [03:10<01:54,  1.06it/s]Loading train:  58%|█████▊    | 165/285 [03:11<02:01,  1.01s/it]Loading train:  58%|█████▊    | 166/285 [03:12<02:02,  1.03s/it]Loading train:  59%|█████▊    | 167/285 [03:13<02:01,  1.03s/it]Loading train:  59%|█████▉    | 168/285 [03:14<01:59,  1.02s/it]Loading train:  59%|█████▉    | 169/285 [03:15<01:52,  1.03it/s]Loading train:  60%|█████▉    | 170/285 [03:16<01:57,  1.02s/it]Loading train:  60%|██████    | 171/285 [03:17<01:52,  1.01it/s]Loading train:  60%|██████    | 172/285 [03:18<01:44,  1.08it/s]Loading train:  61%|██████    | 173/285 [03:19<01:44,  1.07it/s]Loading train:  61%|██████    | 174/285 [03:20<01:44,  1.06it/s]Loading train:  61%|██████▏   | 175/285 [03:21<01:46,  1.03it/s]Loading train:  62%|██████▏   | 176/285 [03:22<01:47,  1.01it/s]Loading train:  62%|██████▏   | 177/285 [03:23<01:51,  1.03s/it]Loading train:  62%|██████▏   | 178/285 [03:24<01:45,  1.02it/s]Loading train:  63%|██████▎   | 179/285 [03:25<01:43,  1.03it/s]Loading train:  63%|██████▎   | 180/285 [03:26<01:47,  1.02s/it]Loading train:  64%|██████▎   | 181/285 [03:27<01:42,  1.02it/s]Loading train:  64%|██████▍   | 182/285 [03:28<01:36,  1.06it/s]Loading train:  64%|██████▍   | 183/285 [03:29<01:41,  1.00it/s]Loading train:  65%|██████▍   | 184/285 [03:30<01:37,  1.03it/s]Loading train:  65%|██████▍   | 185/285 [03:31<01:31,  1.10it/s]Loading train:  65%|██████▌   | 186/285 [03:31<01:27,  1.13it/s]Loading train:  66%|██████▌   | 187/285 [03:32<01:29,  1.09it/s]Loading train:  66%|██████▌   | 188/285 [03:33<01:34,  1.03it/s]Loading train:  66%|██████▋   | 189/285 [03:34<01:32,  1.04it/s]Loading train:  67%|██████▋   | 190/285 [03:35<01:27,  1.09it/s]Loading train:  67%|██████▋   | 191/285 [03:36<01:26,  1.09it/s]Loading train:  67%|██████▋   | 192/285 [03:37<01:27,  1.06it/s]Loading train:  68%|██████▊   | 193/285 [03:38<01:24,  1.09it/s]Loading train:  68%|██████▊   | 194/285 [03:39<01:30,  1.01it/s]Loading train:  68%|██████▊   | 195/285 [03:40<01:24,  1.07it/s]Loading train:  69%|██████▉   | 196/285 [03:41<01:32,  1.04s/it]Loading train:  69%|██████▉   | 197/285 [03:42<01:31,  1.04s/it]Loading train:  69%|██████▉   | 198/285 [03:43<01:31,  1.05s/it]Loading train:  70%|██████▉   | 199/285 [03:44<01:29,  1.04s/it]Loading train:  70%|███████   | 200/285 [03:45<01:26,  1.01s/it]Loading train:  71%|███████   | 201/285 [03:46<01:25,  1.01s/it]Loading train:  71%|███████   | 202/285 [03:47<01:23,  1.01s/it]Loading train:  71%|███████   | 203/285 [03:49<01:27,  1.07s/it]Loading train:  72%|███████▏  | 204/285 [03:50<01:25,  1.05s/it]Loading train:  72%|███████▏  | 205/285 [03:51<01:22,  1.03s/it]Loading train:  72%|███████▏  | 206/285 [03:52<01:25,  1.08s/it]Loading train:  73%|███████▎  | 207/285 [03:53<01:20,  1.03s/it]Loading train:  73%|███████▎  | 208/285 [03:54<01:19,  1.03s/it]Loading train:  73%|███████▎  | 209/285 [03:55<01:19,  1.05s/it]Loading train:  74%|███████▎  | 210/285 [03:56<01:29,  1.19s/it]Loading train:  74%|███████▍  | 211/285 [03:57<01:25,  1.16s/it]Loading train:  74%|███████▍  | 212/285 [03:58<01:21,  1.11s/it]Loading train:  75%|███████▍  | 213/285 [03:59<01:20,  1.12s/it]Loading train:  75%|███████▌  | 214/285 [04:01<01:17,  1.10s/it]Loading train:  75%|███████▌  | 215/285 [04:02<01:14,  1.07s/it]Loading train:  76%|███████▌  | 216/285 [04:02<01:09,  1.01s/it]Loading train:  76%|███████▌  | 217/285 [04:03<01:08,  1.01s/it]Loading train:  76%|███████▋  | 218/285 [04:04<01:06,  1.01it/s]Loading train:  77%|███████▋  | 219/285 [04:05<01:02,  1.05it/s]Loading train:  77%|███████▋  | 220/285 [04:06<01:00,  1.07it/s]Loading train:  78%|███████▊  | 221/285 [04:07<00:59,  1.07it/s]Loading train:  78%|███████▊  | 222/285 [04:08<00:59,  1.07it/s]Loading train:  78%|███████▊  | 223/285 [04:09<00:57,  1.07it/s]Loading train:  79%|███████▊  | 224/285 [04:10<00:58,  1.05it/s]Loading train:  79%|███████▉  | 225/285 [04:11<00:58,  1.03it/s]Loading train:  79%|███████▉  | 226/285 [04:12<00:56,  1.05it/s]Loading train:  80%|███████▉  | 227/285 [04:13<00:56,  1.03it/s]Loading train:  80%|████████  | 228/285 [04:14<00:58,  1.02s/it]Loading train:  80%|████████  | 229/285 [04:15<00:57,  1.02s/it]Loading train:  81%|████████  | 230/285 [04:16<00:55,  1.00s/it]Loading train:  81%|████████  | 231/285 [04:17<00:51,  1.05it/s]Loading train:  81%|████████▏ | 232/285 [04:18<00:54,  1.02s/it]Loading train:  82%|████████▏ | 233/285 [04:19<00:53,  1.04s/it]Loading train:  82%|████████▏ | 234/285 [04:20<00:57,  1.13s/it]Loading train:  82%|████████▏ | 235/285 [04:22<00:56,  1.13s/it]Loading train:  83%|████████▎ | 236/285 [04:23<00:55,  1.13s/it]Loading train:  83%|████████▎ | 237/285 [04:24<00:55,  1.15s/it]Loading train:  84%|████████▎ | 238/285 [04:25<00:53,  1.14s/it]Loading train:  84%|████████▍ | 239/285 [04:26<00:54,  1.18s/it]Loading train:  84%|████████▍ | 240/285 [04:27<00:53,  1.18s/it]Loading train:  85%|████████▍ | 241/285 [04:28<00:49,  1.13s/it]Loading train:  85%|████████▍ | 242/285 [04:30<00:49,  1.16s/it]Loading train:  85%|████████▌ | 243/285 [04:31<00:53,  1.27s/it]Loading train:  86%|████████▌ | 244/285 [04:32<00:50,  1.23s/it]Loading train:  86%|████████▌ | 245/285 [04:33<00:47,  1.18s/it]Loading train:  86%|████████▋ | 246/285 [04:34<00:43,  1.12s/it]Loading train:  87%|████████▋ | 247/285 [04:35<00:40,  1.08s/it]Loading train:  87%|████████▋ | 248/285 [04:36<00:39,  1.06s/it]Loading train:  87%|████████▋ | 249/285 [04:37<00:37,  1.04s/it]Loading train:  88%|████████▊ | 250/285 [04:38<00:36,  1.03s/it]Loading train:  88%|████████▊ | 251/285 [04:39<00:34,  1.00s/it]Loading train:  88%|████████▊ | 252/285 [04:40<00:32,  1.03it/s]Loading train:  89%|████████▉ | 253/285 [04:41<00:30,  1.04it/s]Loading train:  89%|████████▉ | 254/285 [04:42<00:29,  1.07it/s]Loading train:  89%|████████▉ | 255/285 [04:43<00:26,  1.12it/s]Loading train:  90%|████████▉ | 256/285 [04:44<00:25,  1.13it/s]Loading train:  90%|█████████ | 257/285 [04:44<00:23,  1.17it/s]Loading train:  91%|█████████ | 258/285 [04:45<00:23,  1.17it/s]Loading train:  91%|█████████ | 259/285 [04:46<00:22,  1.14it/s]Loading train:  91%|█████████ | 260/285 [04:47<00:20,  1.20it/s]Loading train:  92%|█████████▏| 261/285 [04:48<00:20,  1.18it/s]Loading train:  92%|█████████▏| 262/285 [04:49<00:19,  1.16it/s]Loading train:  92%|█████████▏| 263/285 [04:50<00:18,  1.20it/s]Loading train:  93%|█████████▎| 264/285 [04:51<00:18,  1.13it/s]Loading train:  93%|█████████▎| 265/285 [04:51<00:17,  1.13it/s]Loading train:  93%|█████████▎| 266/285 [04:52<00:16,  1.14it/s]Loading train:  94%|█████████▎| 267/285 [04:53<00:15,  1.16it/s]Loading train:  94%|█████████▍| 268/285 [04:54<00:15,  1.07it/s]Loading train:  94%|█████████▍| 269/285 [04:55<00:15,  1.02it/s]Loading train:  95%|█████████▍| 270/285 [04:56<00:14,  1.01it/s]Loading train:  95%|█████████▌| 271/285 [04:57<00:14,  1.04s/it]Loading train:  95%|█████████▌| 272/285 [04:59<00:13,  1.05s/it]Loading train:  96%|█████████▌| 273/285 [05:00<00:12,  1.07s/it]Loading train:  96%|█████████▌| 274/285 [05:01<00:11,  1.07s/it]Loading train:  96%|█████████▋| 275/285 [05:02<00:10,  1.07s/it]Loading train:  97%|█████████▋| 276/285 [05:03<00:09,  1.04s/it]Loading train:  97%|█████████▋| 277/285 [05:04<00:08,  1.04s/it]Loading train:  98%|█████████▊| 278/285 [05:05<00:07,  1.03s/it]Loading train:  98%|█████████▊| 279/285 [05:06<00:06,  1.02s/it]Loading train:  98%|█████████▊| 280/285 [05:07<00:05,  1.04s/it]Loading train:  99%|█████████▊| 281/285 [05:08<00:04,  1.05s/it]Loading train:  99%|█████████▉| 282/285 [05:09<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [05:10<00:02,  1.08s/it]Loading train: 100%|█████████▉| 284/285 [05:11<00:01,  1.09s/it]Loading train: 100%|██████████| 285/285 [05:12<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:01, 246.08it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:00, 241.04it/s]concatenating: train:  26%|██▌       | 73/285 [00:00<00:00, 238.89it/s]concatenating: train:  36%|███▌      | 102/285 [00:00<00:00, 251.38it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:00, 231.57it/s]concatenating: train:  52%|█████▏    | 149/285 [00:00<00:00, 241.71it/s]concatenating: train:  62%|██████▏   | 177/285 [00:00<00:00, 250.50it/s]concatenating: train:  72%|███████▏  | 204/285 [00:00<00:00, 253.50it/s]concatenating: train:  80%|████████  | 229/285 [00:01<00:00, 191.91it/s]concatenating: train:  88%|████████▊ | 250/285 [00:01<00:00, 195.30it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 232.50it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.33s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.32s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 326.82it/s]
Epoch 00048: val_mDice did not improve from 0.56370
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
{'val_loss': [1160.7240351671612, 1183.3182120722765, 1142.2399199927986, 1209.5123952513966, 1143.0811106079784, 1201.7977765472242, 1314.0912438078299, 1238.0694286836592, 1383.9192194592354, 1320.2190780213425, 1373.2582544081704, 1398.9692423729923, 1418.45520769684, 1466.4300134754715, 1464.0899780955394, 1428.087583062369, 1469.1251848103614, 1416.0192318708537, 1506.8877069057698, 1585.4665554622031, 1555.9310705089035, 1525.6573254462728, 1572.89034266978, 1562.5737284228787, 1555.5598069515975, 1491.9700825440816, 1629.3537188482019, 1651.4292517294432, 1644.7265461330308, 1577.9524887340694, 1627.2267923195268, 1652.1074866609201, 1695.035811610728, 1673.2542063111034, 1631.661387182481, 1672.9856516236034, 1727.2363117580308, 1632.1548656271823, 1674.3011392774529, 1711.1967432458973, 1718.5311879419082, 1757.447239710632, 1762.4074127367755, 1749.9148958515188, 1749.6227659086942, 1690.4898572527497, 1706.9103587912448, 1816.7869838949023], 'val_acc': [0.9520561258886113, 0.9545964718530964, 0.9564812439779996, 0.9578707710990693, 0.9585779868690661, 0.9588220565678687, 0.9580916342788568, 0.9591462838583152, 0.9585797816681463, 0.9597252134504265, 0.9594063572377466, 0.9597733313810892, 0.9585708433023378, 0.9588647697890937, 0.9589022144924995, 0.9596111977566554, 0.959229974773343, 0.9595631254451901, 0.9578742997606373, 0.9602169004898498, 0.959596977886541, 0.959883764136437, 0.9598356748426426, 0.9593279711361038, 0.9595274698800881, 0.9599461282431746, 0.9586225238592265, 0.9591409191072986, 0.9598018207363577, 0.9596842803768606, 0.9597590875359221, 0.9598944816509438, 0.9594259525144566, 0.9592424591160353, 0.9597644296438335, 0.959938977017749, 0.9595506720702741, 0.9596610945030297, 0.9595631244462296, 0.9596789086331202, 0.9597590882018958, 0.9605215438251389, 0.9604182086843353, 0.9600690376825173, 0.9595933919512359, 0.9600601279535773, 0.9603006223726539, 0.9601402865441818], 'val_mDice': [0.4473930192726284, 0.4985569102804088, 0.5271788126263539, 0.5244698924059309, 0.5477455025278656, 0.5430662039271946, 0.531922497562856, 0.5545035136145586, 0.5361669216742063, 0.5536761556923723, 0.5462094120806156, 0.5511968868404793, 0.5529743512915499, 0.5470038745656359, 0.555582323220855, 0.5590065258175301, 0.548832593683424, 0.5636964257203001, 0.5472731217325733, 0.5418641400736803, 0.5392835121913995, 0.5530241028556611, 0.5423461548442947, 0.5511296176710608, 0.5534972035685065, 0.5595470507051692, 0.5400441165742927, 0.5455791713805173, 0.5491452083907313, 0.5597641962533556, 0.5526625106121574, 0.5509102484367413, 0.5453976752371762, 0.5442359668915498, 0.5575905169188643, 0.5553531017383384, 0.5473219704028615, 0.557298843587577, 0.5574727186610579, 0.543268840406194, 0.5525026777603107, 0.5450040002108952, 0.5519882029328267, 0.5481314987110693, 0.5533672273159027, 0.5597543704776125, 0.5536991401091634, 0.5437829109876515], 'loss': [1027.6715359974255, 499.0195113963716, 423.0370998055345, 384.98700011339423, 356.9146731906282, 338.6007014675004, 323.15135892942106, 310.6502744875068, 299.448211519503, 291.5244090280387, 283.36754635869596, 276.66822417370213, 269.635493247599, 263.90287136536824, 259.4190381101375, 255.56471224850762, 250.74125737288466, 247.50568699497822, 243.23091632591004, 237.6124206812227, 236.87980840169917, 232.37574705156416, 229.79989002735343, 227.4037093297633, 224.34864992368495, 222.1833409619522, 220.42120621943354, 218.11397979106397, 214.81347321090172, 212.74365535960675, 211.04213049972597, 209.57984374539603, 206.97183420465802, 205.37677449511582, 203.9933486659246, 201.6757313071964, 200.19042790491176, 199.46361406412618, 197.48239180203012, 196.28009885521303, 194.8457125606675, 193.209359257045, 192.74534491667865, 190.767259713605, 188.2583989956288, 188.341644078933, 186.32258001663774, 185.34672648064887], 'acc': [0.9366468554988068, 0.954991407007065, 0.9593003651173986, 0.9616932041257706, 0.9630540728205449, 0.9641195467066241, 0.9650446576046584, 0.9656630310966301, 0.9662606671941897, 0.9668224255546922, 0.9671371839780264, 0.9674917873061889, 0.9678469439080309, 0.9680237267364196, 0.9680589624404595, 0.9682871666026527, 0.9686273013991629, 0.9687490279323544, 0.9690285874318144, 0.9691648480776744, 0.9693944416828622, 0.9695526213273523, 0.9696578653210239, 0.9697796425640982, 0.9699828029295684, 0.9699889002532703, 0.97013709164154, 0.9701783071188331, 0.9703582799919653, 0.9705107808307873, 0.9704850090367427, 0.9705123458057439, 0.9704916254152601, 0.9706300244041274, 0.9707142542302041, 0.9710099828164696, 0.9709089927427662, 0.9709836185890686, 0.9711743964783267, 0.9711896444670703, 0.9712818297910818, 0.9712533989533588, 0.9714726943718076, 0.9715323143551782, 0.9716678846506348, 0.9716053630822521, 0.9716513505182484, 0.9717220672432175], 'mDice': [0.4599363881067788, 0.6516665049637008, 0.7011257265525785, 0.7269298772485705, 0.7461613003552255, 0.7583640810483864, 0.7693603981470309, 0.7780645870641714, 0.7858363323258156, 0.7912807600390813, 0.7971606261816805, 0.8021142497950081, 0.8067667888638034, 0.8108377900299414, 0.8142369105063922, 0.8168338321404587, 0.8201847808253667, 0.8227634931901371, 0.8258278576236074, 0.8293335300392786, 0.8305670859494128, 0.8337302090886515, 0.8353994315820129, 0.837357668333613, 0.8394975288132035, 0.8408007941846721, 0.842392484500682, 0.8437947938985135, 0.8460778685074721, 0.8476322746622258, 0.8490995615761328, 0.8500265254576244, 0.8518377385571348, 0.8531329087569338, 0.8540322017704738, 0.8556327681371079, 0.856754664063655, 0.8573687271182102, 0.8590635808975918, 0.8597816416825236, 0.8607428352737094, 0.8620606488303989, 0.8621758975745559, 0.8636623029258021, 0.8653638724842906, 0.8655411946176865, 0.866795936413018, 0.867706587404722]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 4  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 56, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 56, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 56, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 56, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 56, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 56, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 28, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 28, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 28, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 28, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 28, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 28, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 28, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 28, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 14, 80)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 14, 80)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 14, 160)  115360      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 14, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 14, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 14, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 14, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 14, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 10, 7, 160)   0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 10, 7, 160)   0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 10, 7, 320)   461120      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 10, 7, 320)   1280        conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 10, 7, 320)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 10, 7, 320)   921920      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 10, 7, 320)   1280        conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 10, 7, 320)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 10, 7, 320)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 20, 14, 160)  204960      dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 20, 14, 320)  0           conv2d_transpose_1[0][0]         
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 20, 14, 160)  460960      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 20, 14, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 20, 14, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 20, 14, 160)  230560      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 20, 14, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 20, 14, 160)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 14, 160)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 40, 28, 80)   51280       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 28, 160)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 40, 28, 80)   115280      concatenate_2[0][0]              
__________________________________________________________________________________________________2019-07-01 04:03:24.310246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-01 04:03:24.310325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-01 04:03:24.310338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-01 04:03:24.310346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-01 04:03:24.310720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

batch_normalization_11 (BatchNo (None, 40, 28, 80)   320         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 40, 28, 80)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 40, 28, 80)   57680       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 40, 28, 80)   320         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 40, 28, 80)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 28, 80)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 80, 56, 40)   12840       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 80, 56, 80)   0           conv2d_transpose_3[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 56, 40)   28840       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 56, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 56, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 56, 40)   14440       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 56, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 56, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 56, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 56, 13)   533         dropout_7[0][0]                  
==================================================================================================
Total params: 3,014,773
Trainable params: 3,011,253
Non-trainable params: 3,520
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [2.40062229e+01 1.18201001e+01 2.77420847e+01 3.44797912e+00
 1.00219785e+01 2.61335372e+00 3.13040004e+01 4.16624627e+01
 3.18192739e+01 4.90028027e+00 1.08801089e+02 7.17113750e+01
 8.70380757e-02]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 25s - loss: 1961.7675 - acc: 0.9150 - mDice: 0.3320 - val_loss: 1529.6396 - val_acc: 0.9355 - val_mDice: 0.4228

Epoch 00001: val_mDice improved from -inf to 0.42278, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 17s - loss: 861.1495 - acc: 0.9415 - mDice: 0.5912 - val_loss: 1683.5206 - val_acc: 0.9395 - val_mDice: 0.4569

Epoch 00002: val_mDice improved from 0.42278 to 0.45685, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 17s - loss: 697.9630 - acc: 0.9475 - mDice: 0.6603 - val_loss: 1823.1931 - val_acc: 0.9385 - val_mDice: 0.4663

Epoch 00003: val_mDice improved from 0.45685 to 0.46634, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 17s - loss: 619.4589 - acc: 0.9508 - mDice: 0.6964 - val_loss: 1958.9881 - val_acc: 0.9409 - val_mDice: 0.4652

Epoch 00004: val_mDice did not improve from 0.46634
Epoch 5/300
 - 18s - loss: 566.5531 - acc: 0.9532 - mDice: 0.7205 - val_loss: 1969.0193 - val_acc: 0.9414 - val_mDice: 0.4744

Epoch 00005: val_mDice improved from 0.46634 to 0.47443, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 532.1205 - acc: 0.9548 - mDice: 0.7373 - val_loss: 1953.5605 - val_acc: 0.9456 - val_mDice: 0.4834

Epoch 00006: val_mDice improved from 0.47443 to 0.48341, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 17s - loss: 503.8669 - acc: 0.9562 - mDice: 0.7506 - val_loss: 1992.2254 - val_acc: 0.9431 - val_mDice: 0.4840

Epoch 00007: val_mDice improved from 0.48341 to 0.48405, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 17s - loss: 481.2880 - acc: 0.9572 - mDice: 0.7613 - val_loss: 2045.8708 - val_acc: 0.9423 - val_mDice: 0.4861

Epoch 00008: val_mDice improved from 0.48405 to 0.48614, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 462.2788 - acc: 0.9581 - mDice: 0.7704 - val_loss: 2132.5982 - val_acc: 0.9414 - val_mDice: 0.4811

Epoch 00009: val_mDice did not improve from 0.48614
Epoch 10/300
 - 17s - loss: 447.3354 - acc: 0.9588 - mDice: 0.7779 - val_loss: 2128.2137 - val_acc: 0.9443 - val_mDice: 0.4912

Epoch 00010: val_mDice improved from 0.48614 to 0.49124, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 17s - loss: 432.8241 - acc: 0.9593 - mDice: 0.7845 - val_loss: 2093.1117 - val_acc: 0.9448 - val_mDice: 0.5010

Epoch 00011: val_mDice improved from 0.49124 to 0.50102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 17s - loss: 421.3207 - acc: 0.9598 - mDice: 0.7899 - val_loss: 2258.9369 - val_acc: 0.9443 - val_mDice: 0.4868

Epoch 00012: val_mDice did not improve from 0.50102
Epoch 13/300
 - 17s - loss: 413.9312 - acc: 0.9601 - mDice: 0.7935 - val_loss: 2103.5385 - val_acc: 0.9455 - val_mDice: 0.5058

Epoch 00013: val_mDice improved from 0.50102 to 0.50581, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 17s - loss: 402.7779 - acc: 0.9606 - mDice: 0.7994 - val_loss: 2093.4310 - val_acc: 0.9457 - val_mDice: 0.5102

Epoch 00014: val_mDice improved from 0.50581 to 0.51022, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 17s - loss: 395.5270 - acc: 0.9608 - mDice: 0.8030 - val_loss: 2198.9810 - val_acc: 0.9465 - val_mDice: 0.5052

Epoch 00015: val_mDice did not improve from 0.51022
Epoch 16/300
 - 18s - loss: 386.9270 - acc: 0.9612 - mDice: 0.8070 - val_loss: 2199.5299 - val_acc: 0.9468 - val_mDice: 0.5064

Epoch 00016: val_mDice did not improve from 0.51022
Epoch 17/300
 - 17s - loss: 379.9439 - acc: 0.9614 - mDice: 0.8105 - val_loss: 2171.6974 - val_acc: 0.9459 - val_mDice: 0.5092

Epoch 00017: val_mDice did not improve from 0.51022
Epoch 18/300
 - 17s - loss: 373.0967 - acc: 0.9617 - mDice: 0.8137 - val_loss: 2325.4264 - val_acc: 0.9451 - val_mDice: 0.5023

Epoch 00018: val_mDice did not improve from 0.51022
Epoch 19/300
 - 17s - loss: 366.7370 - acc: 0.9620 - mDice: 0.8170 - val_loss: 2225.4095 - val_acc: 0.9464 - val_mDice: 0.5109

Epoch 00019: val_mDice improved from 0.51022 to 0.51086, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 17s - loss: 361.9506 - acc: 0.9623 - mDice: 0.8191 - val_loss: 2186.4347 - val_acc: 0.9468 - val_mDice: 0.5143

Epoch 00020: val_mDice improved from 0.51086 to 0.51432, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 18s - loss: 355.7046 - acc: 0.9624 - mDice: 0.8225 - val_loss: 2319.8731 - val_acc: 0.9457 - val_mDice: 0.5076

Epoch 00021: val_mDice did not improve from 0.51432
Epoch 22/300
 - 17s - loss: 350.8129 - acc: 0.9627 - mDice: 0.8249 - val_loss: 2236.9981 - val_acc: 0.9466 - val_mDice: 0.5184

Epoch 00022: val_mDice improved from 0.51432 to 0.51842, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 17s - loss: 346.3131 - acc: 0.9628 - mDice: 0.8270 - val_loss: 2330.0981 - val_acc: 0.9450 - val_mDice: 0.5063

Epoch 00023: val_mDice did not improve from 0.51842
Epoch 24/300
 - 17s - loss: 342.6680 - acc: 0.9629 - mDice: 0.8288 - val_loss: 2277.7577 - val_acc: 0.9459 - val_mDice: 0.5139

Epoch 00024: val_mDice did not improve from 0.51842
Epoch 25/300
 - 18s - loss: 337.3386 - acc: 0.9631 - mDice: 0.8316 - val_loss: 2300.4290 - val_acc: 0.9468 - val_mDice: 0.5148

Epoch 00025: val_mDice did not improve from 0.51842
Epoch 26/300
 - 18s - loss: 333.4230 - acc: 0.9634 - mDice: 0.8334 - val_loss: 2227.2184 - val_acc: 0.9476 - val_mDice: 0.5203

Epoch 00026: val_mDice improved from 0.51842 to 0.52029, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 18s - loss: 329.2378 - acc: 0.9635 - mDice: 0.8356 - val_loss: 2261.6595 - val_acc: 0.9469 - val_mDice: 0.5224

Epoch 00027: val_mDice improved from 0.52029 to 0.52237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 18s - loss: 325.2252 - acc: 0.9636 - mDice: 0.8373 - val_loss: 2388.6300 - val_acc: 0.9461 - val_mDice: 0.5109

Epoch 00028: val_mDice did not improve from 0.52237
Epoch 29/300
 - 18s - loss: 319.5440 - acc: 0.9638 - mDice: 0.8404 - val_loss: 2283.4140 - val_acc: 0.9470 - val_mDice: 0.5219

Epoch 00029: val_mDice did not improve from 0.52237
Epoch 30/300
 - 18s - loss: 319.0344 - acc: 0.9640 - mDice: 0.8408 - val_loss: 2329.4114 - val_acc: 0.9470 - val_mDice: 0.5184

Epoch 00030: val_mDice did not improve from 0.52237
Epoch 31/300
 - 18s - loss: 315.0406 - acc: 0.9640 - mDice: 0.8425 - val_loss: 2392.3946 - val_acc: 0.9479 - val_mDice: 0.5142

Epoch 00031: val_mDice did not improve from 0.52237
Epoch 32/300
 - 18s - loss: 311.5542 - acc: 0.9641 - mDice: 0.8444 - val_loss: 2400.8029 - val_acc: 0.9473 - val_mDice: 0.5166

Epoch 00032: val_mDice did not improve from 0.52237
Epoch 33/300
 - 18s - loss: 310.7224 - acc: 0.9641 - mDice: 0.8448 - val_loss: 2311.7233 - val_acc: 0.9472 - val_mDice: 0.5224

Epoch 00033: val_mDice improved from 0.52237 to 0.52243, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 18s - loss: 306.5744 - acc: 0.9643 - mDice: 0.8468 - val_loss: 2310.0694 - val_acc: 0.9479 - val_mDice: 0.5283

Epoch 00034: val_mDice improved from 0.52243 to 0.52830, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 18s - loss: 303.7534 - acc: 0.9644 - mDice: 0.8483 - val_loss: 2433.5897 - val_acc: 0.9485 - val_mDice: 0.5178

Epoch 00035: val_mDice did not improve from 0.52830
Epoch 36/300
 - 18s - loss: 301.2743 - acc: 0.9644 - mDice: 0.8493 - val_loss: 2432.3042 - val_acc: 0.9476 - val_mDice: 0.5180

Epoch 00036: val_mDice did not improve from 0.52830
Epoch 37/300
 - 18s - loss: 298.7717 - acc: 0.9645 - mDice: 0.8509 - val_loss: 2416.5563 - val_acc: 0.9466 - val_mDice: 0.5197

Epoch 00037: val_mDice did not improve from 0.52830
Epoch 38/300
 - 18s - loss: 294.3590 - acc: 0.9647 - mDice: 0.8530 - val_loss: 2517.5960 - val_acc: 0.9463 - val_mDice: 0.5165

Epoch 00038: val_mDice did not improve from 0.52830
Epoch 39/300
 - 18s - loss: 292.3863 - acc: 0.9648 - mDice: 0.8539 - val_loss: 2478.9600 - val_acc: 0.9467 - val_mDice: 0.5208

Epoch 00039: val_mDice did not improve from 0.52830
Epoch 40/300
 - 18s - loss: 291.3032 - acc: 0.9648 - mDice: 0.8546 - val_loss: 2493.1118 - val_acc: 0.9475 - val_mDice: 0.5131

Epoch 00040: val_mDice did not improve from 0.52830
Epoch 41/300
 - 18s - loss: 288.1333 - acc: 0.9648 - mDice: 0.8559 - val_loss: 2467.3211 - val_acc: 0.9473 - val_mDice: 0.5181

Epoch 00041: val_mDice did not improve from 0.52830
Epoch 42/300
 - 18s - loss: 286.7379 - acc: 0.9648 - mDice: 0.8569 - val_loss: 2466.5333 - val_acc: 0.9465 - val_mDice: 0.5180

Epoch 00042: val_mDice did not improve from 0.52830
Epoch 43/300
 - 18s - loss: 284.2559 - acc: 0.9650 - mDice: 0.8581 - val_loss: 2511.3778 - val_acc: 0.9475 - val_mDice: 0.5148

Epoch 00043: val_mDice did not improve from 0.52830
Epoch 44/300
 - 18s - loss: 282.6436 - acc: 0.9649 - mDice: 0.8589 - val_loss: 2451.7397 - val_acc: 0.9477 - val_mDice: 0.5216

Epoch 00044: val_mDice did not improve from 0.52830
Epoch 45/300
 - 18s - loss: 279.6678 - acc: 0.9650 - mDice: 0.8603 - val_loss: 2440.4228 - val_acc: 0.9481 - val_mDice: 0.5272

Epoch 00045: val_mDice did not improve from 0.52830
Epoch 46/300
 - 18s - loss: 277.8983 - acc: 0.9650 - mDice: 0.8612 - val_loss: 2500.6896 - val_acc: 0.9466 - val_mDice: 0.5160

Epoch 00046: val_mDice did not improve from 0.52830
Epoch 47/300
 - 18s - loss: 275.3847 - acc: 0.9651 - mDice: 0.8624 - val_loss: 2607.9948 - val_acc: 0.9466 - val_mDice: 0.5097

Epoch 00047: val_mDice did not improve from 0.52830
Epoch 48/300
 - 18s - loss: 275.0420 - acc: 0.9652 - mDice: 0.8628 - val_loss: 2620.1864 - val_acc: 0.9452 - val_mDice: 0.5098

Epoch 00048: val_mDice did not improve from 0.52830
Epoch 49/300
 - 18s - loss: 272.4981 - acc: 0.9652 - mDice: 0.8640 - val_loss: 2549.3894 - val_acc: 0.9473 - val_mDice: 0.5159

Epoch 00049: val_mDice did not improve from 0.52830
Epoch 50/300
 - 18s - loss: 271.1909 - acc: 0.9653 - mDice: 0.8647 - val_loss: 2509.6993 - val_acc: 0.9470 - val_mDice: 0.5193

Epoch 00050: val_mDice did not improve from 0.52830
Epoch 51/300
 - 18s - loss: 269.5081 - acc: 0.9654 - mDice: 0.8656 - val_loss: 2567.6188 - val_acc: 0.9484 - val_mDice: 0.5144

Epoch 00051: val_mDice did not improve from 0.52830
Epoch 52/300
 - 18s - loss: 268.3650 - acc: 0.9655 - mDice: 0.8663 - val_loss: 2466.6472 - val_acc: 0.9476 - val_mDice: 0.5244

Epoch 00052: val_mDice did not improve from 0.52830
Epoch 53/300
 - 18s - loss: 265.1119 - acc: 0.9655 - mDice: 0.8675 - val_loss: 2461.2715 - val_acc: 0.9479 - val_mDice: 0.5255

Epoch 00053: val_mDice did not improve from 0.52830
Epoch 54/300
 - 18s - loss: 265.4888 - acc: 0.9656 - mDice: 0.8677 - val_loss: 2459.5628 - val_acc: 0.9469 - val_mDice: 0.5293

Epoch 00054: val_mDice improved from 0.52830 to 0.52934, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 55/300
 - 18s - loss: 262.0415 - acc: 0.9656 - mDice: 0.8692 - val_loss: 2537.9023 - val_acc: 0.9472 - val_mDice: 0.5256

Epoch 00055: val_mDice did not improve from 0.52934
Epoch 56/300
 - 18s - loss: 261.6610 - acc: 0.9657 - mDice: 0.8696 - val_loss: 2577.0756 - val_acc: 0.9480 - val_mDice: 0.5209

Epoch 00056: val_mDice did not improve from 0.52934
Epoch 57/300
 - 18s - loss: 260.3088 - acc: 0.9658 - mDice: 0.8703 - val_loss: 2444.4599 - val_acc: 0.9482 - val_mDice: 0.5318

Epoch 00057: val_mDice improved from 0.52934 to 0.53178, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 18s - loss: 257.3590 - acc: 0.9658 - mDice: 0.8718 - val_loss: 2546.5663 - val_acc: 0.9485 - val_mDice: 0.5275

Epoch 00058: val_mDice did not improve from 0.53178
Epoch 59/300
 - 18s - loss: 256.3948 - acc: 0.9657 - mDice: 0.8721 - val_loss: 2645.2009 - val_acc: 0.9474 - val_mDice: 0.5193

Epoch 00059: val_mDice did not improve from 0.53178
Epoch 60/300
 - 18s - loss: 255.9969 - acc: 0.9657 - mDice: 0.8725 - val_loss: 2551.3028 - val_acc: 0.9480 - val_mDice: 0.5270

Epoch 00060: val_mDice did not improve from 0.53178
Epoch 61/300
 - 18s - loss: 254.3856 - acc: 0.9659 - mDice: 0.8732 - val_loss: 2609.8041 - val_acc: 0.9479 - val_mDice: 0.5178

Epoch 00061: val_mDice did not improve from 0.53178
Epoch 62/300
 - 18s - loss: 253.1782 - acc: 0.9658 - mDice: 0.8739 - val_loss: 2586.4890 - val_acc: 0.9484 - val_mDice: 0.5236

Epoch 00062: val_mDice did not improve from 0.53178
Epoch 63/300
 - 18s - loss: 250.8817 - acc: 0.9658 - mDice: 0.8748 - val_loss: 2603.9235 - val_acc: 0.9472 - val_mDice: 0.5248

Epoch 00063: val_mDice did not improve from 0.53178
Epoch 64/300
 - 18s - loss: 249.6644 - acc: 0.9660 - mDice: 0.8755 - val_loss: 2585.9475 - val_acc: 0.9476 - val_mDice: 0.5276

Epoch 00064: val_mDice did not improve from 0.53178
Epoch 65/300
 - 18s - loss: 249.6193 - acc: 0.9660 - mDice: 0.8755 - val_loss: 2674.9208 - val_acc: 0.9464 - val_mDice: 0.5175

Epoch 00065: val_mDice did not improve from 0.53178
Epoch 66/300
 - 18s - loss: 247.7657 - acc: 0.9661 - mDice: 0.8764 - val_loss: 2712.5832 - val_acc: 0.9464 - val_mDice: 0.5170

Epoch 00066: val_mDice did not improve from 0.53178
Epoch 67/300
 - 18s - loss: 245.2920 - acc: 0.9661 - mDice: 0.8779 - val_loss: 2663.0185 - val_acc: 0.9485 - val_mDice: 0.5197

Epoch 00067: val_mDice did not improve from 0.53178
Epoch 68/300
 - 18s - loss: 245.3089 - acc: 0.9662 - mDice: 0.8780 - val_loss: 2686.1111 - val_acc: 0.9464 - val_mDice: 0.5219

Epoch 00068: val_mDice did not improve from 0.53178
Epoch 69/300
 - 18s - loss: 244.2789 - acc: 0.9662 - mDice: 0.8783 - val_loss: 2647.4397 - val_acc: 0.9475 - val_mDice: 0.5233

Epoch 00069: val_mDice did not improve from 0.53178
Epoch 70/300
 - 18s - loss: 242.7839 - acc: 0.9661 - mDice: 0.8790 - val_loss: 2726.3386 - val_acc: 0.9481 - val_mDice: 0.5149

Epoch 00070: val_mDice did not improve from 0.53178
Epoch 71/300
 - 18s - loss: 241.5326 - acc: 0.9662 - mDice: 0.8798 - val_loss: 2650.1788 - val_acc: 0.9485 - val_mDice: 0.5306

Epoch 00071: val_mDice did not improve from 0.53178
Epoch 72/300
 - 18s - loss: 241.2615 - acc: 0.9663 - mDice: 0.8798 - val_loss: 2709.2210 - val_acc: 0.9471 - val_mDice: 0.5236

Epoch 00072: val_mDice did not improve from 0.53178
Epoch 73/300
 - 18s - loss: 239.6409 - acc: 0.9662 - mDice: 0.8806 - val_loss: 2605.5113 - val_acc: 0.9474 - val_mDice: 0.5269

Epoch 00073: val_mDice did not improve from 0.53178
Epoch 74/300
 - 18s - loss: 237.8828 - acc: 0.9664 - mDice: 0.8816 - val_loss: 2672.0047 - val_acc: 0.9478 - val_mDice: 0.5277

Epoch 00074: val_mDice did not improve from 0.53178
Epoch 75/300
 - 17s - loss: 238.8813 - acc: 0.9664 - mDice: 0.8812 - val_loss: 2675.7489 - val_acc: 0.9481 - val_mDice: 0.5221

Epoch 00075: val_mDice did not improve from 0.53178
Epoch 76/300
 - 17s - loss: 238.1385 - acc: 0.9664 - mDice: 0.8814 - val_loss: 2731.1563 - val_acc: 0.9482 - val_mDice: 0.5238

Epoch 00076: val_mDice did not improve from 0.53178
Epoch 77/300
 - 17s - loss: 236.1441 - acc: 0.9665 - mDice: 0.8824 - val_loss: 2687.4993 - val_acc: 0.9475 - val_mDice: 0.5274

Epoch 00077: val_mDice did not improve from 0.53178
Epoch 78/300
 - 17s - loss: 233.9065 - acc: 0.9664 - mDice: 0.8834 - val_loss: 2669.1052 - val_acc: 0.9476 - val_mDice: 0.5264

Epoch 00078: val_mDice did not improve from 0.53178
Epoch 79/300
 - 17s - loss: 234.2051 - acc: 0.9665 - mDice: 0.8834 - val_loss: 2631.9440 - val_acc: 0.9482 - val_mDice: 0.5262

Epoch 00079: val_mDice did not improve from 0.53178
Epoch 80/300
 - 18s - loss: 232.0980 - acc: 0.9665 - mDice: 0.8846 - val_loss: 2780.3927 - val_acc: 0.9479 - val_mDice: 0.5267

Epoch 00080: val_mDice did not improve from 0.53178
Epoch 81/300
 - 17s - loss: 231.3791 - acc: 0.9665 - mDice: 0.8850 - val_loss: 2757.2280 - val_acc: 0.9469 - val_mDice: 0.5230

Epoch 00081: val_mDice did not improve from 0.53178
Epoch 82/300
 - 17s - loss: 230.3502 - acc: 0.9666 - mDice: 0.8855 - val_loss: 2762.8295 - val_acc: 0.9475 - val_mDice: 0.5229

Epoch 00082: val_mDice did not improve from 0.53178
Epoch 83/300
 - 17s - loss: 230.2488 - acc: 0.9667 - mDice: 0.8854 - val_loss: 2778.8704 - val_acc: 0.9463 - val_mDice: 0.5195

Epoch 00083: val_mDice did not improve from 0.53178
Epoch 84/300
 - 17s - loss: 228.7678 - acc: 0.9666 - mDice: 0.8861 - val_loss: 2630.3630 - val_acc: 0.9488 - val_mDice: 0.5352

Epoch 00084: val_mDice improved from 0.53178 to 0.53520, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 85/300
 - 17s - loss: 227.6303 - acc: 0.9668 - mDice: 0.8866 - val_loss: 2799.5908 - val_acc: 0.9467 - val_mDice: 0.5192

Epoch 00085: val_mDice did not improve from 0.53520
Epoch 86/300
 - 17s - loss: 227.4271 - acc: 0.9668 - mDice: 0.8869 - val_loss: 2740.7246 - val_acc: 0.9482 - val_mDice: 0.5190

Epoch 00086: val_mDice did not improve from 0.53520
Epoch 87/300
 - 18s - loss: 226.1535 - acc: 0.9669 - mDice: 0.8876 - val_loss: 2753.1126 - val_acc: 0.9476 - val_mDice: 0.5240

Epoch 00087: val_mDice did not improve from 0.53520
Epoch 88/300
 - 17s - loss: 225.1536 - acc: 0.9668 - mDice: 0.8881 - val_loss: 2707.9465 - val_acc: 0.9480 - val_mDice: 0.5281

Epoch 00088: val_mDice did not improve from 0.53520
Epoch 89/300
 - 17s - loss: 225.2287 - acc: 0.9669 - mDice: 0.8880 - val_loss: 2794.9155 - val_acc: 0.9468 - val_mDice: 0.5167

Epoch 00089: val_mDice did not improve from 0.53520
Epoch 90/300
 - 17s - loss: 225.0232 - acc: 0.9669 - mDice: 0.8882 - val_loss: 2785.4630 - val_acc: 0.9480 - val_mDice: 0.5188

Epoch 00090: val_mDice did not improve from 0.53520
Epoch 91/300
 - 17s - loss: 222.9220 - acc: 0.9669 - mDice: 0.8891 - val_loss: 2702.3083 - val_acc: 0.9489 - val_mDice: 0.5306

Epoch 00091: val_mDice did not improve from 0.53520
Epoch 92/300
 - 17s - loss: 222.6629 - acc: 0.9670 - mDice: 0.8892 - val_loss: 2888.9283 - val_acc: 0.9466 - val_mDice: 0.5154

Epoch 00092: val_mDice did not improve from 0.53520
Epoch 93/300
 - 18s - loss: 222.0348 - acc: 0.9670 - mDice: 0.8895 - val_loss: 2728.7707 - val_acc: 0.9487 - val_mDice: 0.5276

Epoch 00093: val_mDice did not improve from 0.53520
Epoch 94/300
 - 17s - loss: 220.9745 - acc: 0.9671 - mDice: 0.8901 - val_loss: 2827.1480 - val_acc: 0.9480 - val_mDice: 0.5222

Epoch 00094: val_mDice did not improve from 0.53520
Epoch 95/300
 - 17s - loss: 221.1691 - acc: 0.9670 - mDice: 0.8901 - val_loss: 2711.1198 - val_acc: 0.9481 - val_mDice: 0.5260

Epoch 00095: val_mDice did not improve from 0.53520
Epoch 96/300
 - 17s - loss: 219.8240 - acc: 0.9671 - mDice: 0.8909 - val_loss: 2689.0886 - val_acc: 0.9472 - val_mDice: 0.5363

Epoch 00096: val_mDice improved from 0.53520 to 0.53631, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 17s - loss: 218.4760 - acc: 0.9671 - mDice: 0.8915 - val_loss: 2707.9049 - val_acc: 0.9479 - val_mDice: 0.5337

Epoch 00097: val_mDice did not improve from 0.53631
Epoch 98/300
 - 17s - loss: 217.6553 - acc: 0.9671 - mDice: 0.8918 - val_loss: 2703.0232 - val_acc: 0.9492 - val_mDice: 0.5328

Epoch 00098: val_mDice did not improve from 0.53631
Epoch 99/300
 - 17s - loss: 216.0935 - acc: 0.9672 - mDice: 0.8926 - val_loss: 2759.8668 - val_acc: 0.9474 - val_mDice: 0.5272

Epoch 00099: val_mDice did not improve from 0.53631
Epoch 100/300
 - 18s - loss: 216.5135 - acc: 0.9672 - mDice: 0.8925 - val_loss: 2831.4100 - val_acc: 0.9477 - val_mDice: 0.5265

Epoch 00100: val_mDice did not improve from 0.53631
Epoch 101/300
 - 17s - loss: 215.7515 - acc: 0.9671 - mDice: 0.8928 - val_loss: 2767.8751 - val_acc: 0.9486 - val_mDice: 0.5248

Epoch 00101: val_mDice did not improve from 0.53631
Epoch 102/300
 - 17s - loss: 214.6209 - acc: 0.9671 - mDice: 0.8935 - val_loss: 2833.9906 - val_acc: 0.9475 - val_mDice: 0.5257

Epoch 00102: val_mDice did not improve from 0.53631
Epoch 103/300
 - 17s - loss: 214.5366 - acc: 0.9672 - mDice: 0.8936 - val_loss: 2730.6526 - val_acc: 0.9480 - val_mDice: 0.5295

Epoch 00103: val_mDice did not improve from 0.53631
Epoch 104/300
 - 17s - loss: 214.3238 - acc: 0.9671 - mDice: 0.8935 - val_loss: 2787.1492 - val_acc: 0.9472 - val_mDice: 0.5263

Epoch 00104: val_mDice did not improve from 0.53631
Epoch 105/300
 - 17s - loss: 213.6962 - acc: 0.9673 - mDice: 0.8937 - val_loss: 2806.5897 - val_acc: 0.9489 - val_mDice: 0.5255

Epoch 00105: val_mDice did not improve from 0.53631
Epoch 106/300
 - 18s - loss: 212.6339 - acc: 0.9672 - mDice: 0.8944 - val_loss: 2802.1736 - val_acc: 0.9481 - val_mDice: 0.5239

Epoch 00106: val_mDice did not improve from 0.53631
Epoch 107/300
 - 18s - loss: 212.1067 - acc: 0.9673 - mDice: 0.8947 - val_loss: 2855.7936 - val_acc: 0.9481 - val_mDice: 0.5233

Epoch 00107: val_mDice did not improve from 0.53631
Epoch 108/300
 - 17s - loss: 211.0235 - acc: 0.9674 - mDice: 0.8953 - val_loss: 2858.1906 - val_acc: 0.9487 - val_mDice: 0.5250

Epoch 00108: val_mDice did not improve from 0.53631
Epoch 109/300
 - 18s - loss: 210.9583 - acc: 0.9674 - mDice: 0.8953 - val_loss: 2850.0787 - val_acc: 0.9483 - val_mDice: 0.5238

Epoch 00109: val_mDice did not improve from 0.53631
Epoch 110/300
 - 18s - loss: 210.1717 - acc: 0.9674 - mDice: 0.8956 - val_loss: 2889.5084 - val_acc: 0.9474 - val_mDice: 0.5215

Epoch 00110: val_mDice did not improve from 0.53631
Epoch 111/300
 - 17s - loss: 208.4601 - acc: 0.9674 - mDice: 0.8965 - val_loss: 2923.7144 - val_acc: 0.9484 - val_mDice: 0.5207

Epoch 00111: val_mDice did not improve from 0.53631
Epoch 112/300
 - 17s - loss: 207.8790 - acc: 0.9674 - mDice: 0.8967 - val_loss: 2828.7925 - val_acc: 0.9487 - val_mDice: 0.5228

Epoch 00112: val_mDice did not improve from 0.53631
Epoch 113/300
 - 18s - loss: 208.4766 - acc: 0.9675 - mDice: 0.8966 - val_loss: 2841.4884 - val_acc: 0.9486 - val_mDice: 0.5302

Epoch 00113: val_mDice did not improve from 0.53631
Epoch 114/300
 - 18s - loss: 208.0315 - acc: 0.9675 - mDice: 0.8967 - val_loss: 2831.2933 - val_acc: 0.9486 - val_mDice: 0.5289

Epoch 00114: val_mDice did not improve from 0.53631
Epoch 115/300
 - 17s - loss: 206.0152 - acc: 0.9675 - mDice: 0.8977 - val_loss: 2763.0162 - val_acc: 0.9484 - val_mDice: 0.5346

Epoch 00115: val_mDice did not improve from 0.53631
Epoch 116/300
 - 17s - loss: 207.0409 - acc: 0.9674 - mDice: 0.8972 - val_loss: 2824.6929 - val_acc: 0.9487 - val_mDice: 0.5277

Epoch 00116: val_mDice did not improve from 0.53631
Epoch 117/300
 - 17s - loss: 206.3288 - acc: 0.9674 - mDice: 0.8976 - val_loss: 2884.3914 - val_acc: 0.9482 - val_mDice: 0.5233

Epoch 00117: val_mDice did not improve from 0.53631
Epoch 118/300
 - 18s - loss: 206.2272 - acc: 0.9675 - mDice: 0.8978 - val_loss: 2843.5355 - val_acc: 0.9468 - val_mDice: 0.5270

Epoch 00118: val_mDice did not improve from 0.53631
Epoch 119/300
 - 18s - loss: 205.4629 - acc: 0.9675 - mDice: 0.8982 - val_loss: 2840.7012 - val_acc: 0.9479 - val_mDice: 0.5295

Epoch 00119: val_mDice did not improve from 0.53631
Epoch 120/300
 - 18s - loss: 204.2987 - acc: 0.9675 - mDice: 0.8986 - val_loss: 2822.6755 - val_acc: 0.9485 - val_mDice: 0.5254

Epoch 00120: val_mDice did not improve from 0.53631
Epoch 121/300
 - 18s - loss: 203.6098 - acc: 0.9675 - mDice: 0.8991 - val_loss: 2840.2967 - val_acc: 0.9476 - val_mDice: 0.5314

Epoch 00121: val_mDice did not improve from 0.53631
Epoch 122/300
 - 18s - loss: 203.0961 - acc: 0.9677 - mDice: 0.8992 - val_loss: 2795.8518 - val_acc: 0.9486 - val_mDice: 0.5297

Epoch 00122: val_mDice did not improve from 0.53631
Epoch 123/300
 - 18s - loss: 202.7286 - acc: 0.9677 - mDice: 0.8996 - val_loss: 2757.4025 - val_acc: 0.9490 - val_mDice: 0.5384

Epoch 00123: val_mDice improved from 0.53631 to 0.53837, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_U-Net4_NL4_LS_MyBCE_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 124/300
 - 18s - loss: 202.1812 - acc: 0.9677 - mDice: 0.8997 - val_loss: 2816.4540 - val_acc: 0.9485 - val_mDice: 0.5333

Epoch 00124: val_mDice did not improve from 0.53837
Epoch 125/300
 - 18s - loss: 201.0750 - acc: 0.9677 - mDice: 0.9002 - val_loss: 2901.0067 - val_acc: 0.9481 - val_mDice: 0.5209

Epoch 00125: val_mDice did not improve from 0.53837
Epoch 126/300
 - 18s - loss: 201.1194 - acc: 0.9676 - mDice: 0.9004 - val_loss: 2867.4740 - val_acc: 0.9489 - val_mDice: 0.5317

Epoch 00126: val_mDice did not improve from 0.53837
Epoch 127/300
 - 18s - loss: 200.9366 - acc: 0.9676 - mDice: 0.9004 - val_loss: 2969.8952 - val_acc: 0.9468 - val_mDice: 0.5231

Epoch 00127: val_mDice did not improve from 0.53837
Epoch 128/300
 - 18s - loss: 200.7461 - acc: 0.9676 - mDice: 0.9006 - val_loss: 2853.2405 - val_acc: 0.9485 - val_mDice: 0.5288

Epoch 00128: val_mDice did not improve from 0.53837
Epoch 129/300
 - 18s - loss: 199.1284 - acc: 0.9677 - mDice: 0.9013 - val_loss: 2869.1644 - val_acc: 0.9482 - val_mDice: 0.5295

Epoch 00129: val_mDice did not improve from 0.53837
Epoch 130/300
 - 18s - loss: 198.6512 - acc: 0.9677 - mDice: 0.9016 - val_loss: 2874.5081 - val_acc: 0.9490 - val_mDice: 0.5311

Epoch 00130: val_mDice did not improve from 0.53837
Epoch 131/300
 - 18s - loss: 198.6169 - acc: 0.9677 - mDice: 0.9016 - val_loss: 2796.0885 - val_acc: 0.9494 - val_mDice: 0.5362

Epoch 00131: val_mDice did not improve from 0.53837
Epoch 132/300
 - 18s - loss: 197.7519 - acc: 0.9678 - mDice: 0.9018 - val_loss: 3026.9034 - val_acc: 0.9486 - val_mDice: 0.5135

Epoch 00132: val_mDice did not improve from 0.53837
Epoch 133/300
 - 18s - loss: 197.9399 - acc: 0.9677 - mDice: 0.9020 - val_loss: 2872.9635 - val_acc: 0.9481 - val_mDice: 0.5291

Epoch 00133: val_mDice did not improve from 0.53837
Epoch 134/300
 - 18s - loss: 196.8703 - acc: 0.9678 - mDice: 0.9024 - val_loss: 2890.4576 - val_acc: 0.9483 - val_mDice: 0.5241

Epoch 00134: val_mDice did not improve from 0.53837
Epoch 135/300
 - 18s - loss: 196.5144 - acc: 0.9678 - mDice: 0.9028 - val_loss: 2944.9192 - val_acc: 0.9479 - val_mDice: 0.5169

Epoch 00135: val_mDice did not improve from 0.53837
Epoch 136/300
 - 18s - loss: 195.0980 - acc: 0.9679 - mDice: 0.9033 - val_loss: 2875.0535 - val_acc: 0.9480 - val_mDice: 0.5272

Epoch 00136: val_mDice did not improve from 0.53837
Epoch 137/300
 - 18s - loss: 195.2794 - acc: 0.9679 - mDice: 0.9033 - val_loss: 2964.4402 - val_acc: 0.9479 - val_mDice: 0.5253

Epoch 00137: val_mDice did not improve from 0.53837
Epoch 138/300
 - 18s - loss: 194.0919 - acc: 0.9680 - mDice: 0.9039 - val_loss: 2974.9152 - val_acc: 0.9487 - val_mDice: 0.5269

Epoch 00138: val_mDice did not improve from 0.53837
Epoch 139/300
 - 18s - loss: 194.5974 - acc: 0.9679 - mDice: 0.9037 - val_loss: 2906.9783 - val_acc: 0.9490 - val_mDice: 0.5285

Epoch 00139: val_mDice did not improve from 0.53837
Epoch 140/300
 - 18s - loss: 193.5926 - acc: 0.9680 - mDice: 0.9041 - val_loss: 2901.9463 - val_acc: 0.9494 - val_mDice: 0.5235

Epoch 00140: val_mDice did not improve from 0.53837
Epoch 141/300
 - 18s - loss: 193.5708 - acc: 0.9680 - mDice: 0.9043 - val_loss: 2914.9372 - val_acc: 0.9481 - val_mDice: 0.5291

Epoch 00141: val_mDice did not improve from 0.53837
Epoch 142/300
 - 18s - loss: 193.1932 - acc: 0.9680 - mDice: 0.9043 - val_loss: 2999.5434 - val_acc: 0.9489 - val_mDice: 0.5233

Epoch 00142: val_mDice did not improve from 0.53837
Epoch 143/300
 - 18s - loss: 193.3133 - acc: 0.9680 - mDice: 0.9044 - val_loss: 2956.4495 - val_acc: 0.9487 - val_mDice: 0.5250

Epoch 00143: val_mDice did not improve from 0.53837
Epoch 144/300
 - 18s - loss: 191.9173 - acc: 0.9680 - mDice: 0.9049 - val_loss: 3033.7028 - val_acc: 0.9484 - val_mDice: 0.5148

Epoch 00144: val_mDice did not improve from 0.53837
Epoch 145/300
 - 18s - loss: 191.4973 - acc: 0.9682 - mDice: 0.9052 - val_loss: 2980.8645 - val_acc: 0.9485 - val_mDice: 0.5220

Epoch 00145: val_mDice did not improve from 0.53837
Epoch 146/300
 - 18s - loss: 191.1314 - acc: 0.9681 - mDice: 0.9053 - val_loss: 2968.3922 - val_acc: 0.9493 - val_mDice: 0.5277

Epoch 00146: val_mDice did not improve from 0.53837
Epoch 147/300
 - 18s - loss: 191.4059 - acc: 0.9680 - mDice: 0.9053 - val_loss: 3052.6045 - val_acc: 0.9483 - val_mDice: 0.5170

Epoch 00147: val_mDice did not improve from 0.53837
Epoch 148/300
 - 18s - loss: 191.1535 - acc: 0.9681 - mDice: 0.9055 - val_loss: 2981.7903 - val_acc: 0.9476 - val_mDice: 0.5223

Epoch 00148: val_mDice did not improve from 0.53837
Epoch 149/300
 - 18s - loss: 190.4561 - acc: 0.9680 - mDice: 0.9056 - val_loss: 2879.4729 - val_acc: 0.9488 - val_mDice: 0.5309

Epoch 00149: val_mDice did not improve from 0.53837
Epoch 150/300
 - 18s - loss: 189.6734 - acc: 0.9681 - mDice: 0.9062 - val_loss: 2958.3214 - val_acc: 0.9489 - val_mDice: 0.5251

Epoch 00150: val_mDice did not improve from 0.53837
Epoch 151/300
 - 18s - loss: 188.7324 - acc: 0.9681 - mDice: 0.9066 - val_loss: 2995.1012 - val_acc: 0.9491 - val_mDice: 0.5263

Epoch 00151: val_mDice did not improve from 0.53837
Epoch 152/300
 - 18s - loss: 189.2133 - acc: 0.9681 - mDice: 0.9064 - val_loss: 3032.9682 - val_acc: 0.9485 - val_mDice: 0.5220

Epoch 00152: val_mDice did not improve from 0.53837
Epoch 153/300
 - 18s - loss: 188.2400 - acc: 0.9681 - mDice: 0.9070 - val_loss: 2985.6067 - val_acc: 0.9489 - val_mDice: 0.5273

Epoch 00153: val_mDice did not improve from 0.53837
Restoring model weights from the end of the best epoch
Epoch 00153: early stopping
{'val_loss': [1529.6395926842322, 1683.5206228402944, 1823.1931076049805, 1958.988068800706, 1969.019315279447, 1953.560543353741, 1992.2254450871394, 2045.8707721416768, 2132.5981891338643, 2128.213702862079, 2093.111743046687, 2258.9368696946362, 2103.5384674072266, 2093.4309974083535, 2198.9809769850513, 2199.5299213115986, 2171.697370675894, 2325.426433269794, 2225.409494253305, 2186.434670668382, 2319.8730627206655, 2236.998090890738, 2330.0981275118315, 2277.7576927771934, 2300.429029611441, 2227.2183931790864, 2261.6595030564526, 2388.6299990140474, 2283.414043719952, 2329.4113927987905, 2392.3945611807017, 2400.802858205942, 2311.723340548002, 2310.0694392277646, 2433.589654775766, 2432.304159311148, 2416.556311387282, 2517.5960482083833, 2478.9600125826323, 2493.111801147461, 2467.321054311899, 2466.5332659207857, 2511.3778170072114, 2451.739708533654, 2440.4227875929614, 2500.689586345966, 2607.9947603665864, 2620.1864248422476, 2549.389393733098, 2509.6992880014272, 2567.6187661977915, 2466.64723440317, 2461.271462073693, 2459.562791090745, 2537.902251610389, 2577.0756260798526, 2444.459905771109, 2546.566341693585, 2645.200903085562, 2551.3027789776143, 2609.804135836088, 2586.488976111779, 2603.9234795203574, 2585.94750389686, 2674.9207845834585, 2712.58321087177, 2663.0185183011567, 2686.1111139150767, 2647.439744215745, 2726.338621873122, 2650.1787884051982, 2709.221034123347, 2605.5113161527192, 2672.004702054537, 2675.7489060621997, 2731.156272301307, 2687.499322744516, 2669.105241041917, 2631.9439673790566, 2780.3926837627705, 2757.227996826172, 2762.8294900747446, 2778.870415320763, 2630.363013634315, 2799.590794489934, 2740.7245506873496, 2753.112558218149, 2707.946461604192, 2794.915463961088, 2785.4630009577822, 2702.3082557091348, 2888.9283447265625, 2728.7707014817456, 2827.147951566256, 2711.1197650615986, 2689.0885948768027, 2707.9048731877256, 2703.023209791917, 2759.8668036827676, 2831.4100294846753, 2767.8751032902646, 2833.9905911959136, 2730.652609018179, 2787.149215698242, 2806.589662992037, 2802.173621544471, 2855.793637789213, 2858.190602229192, 2850.0787212665264, 2889.5084369365986, 2923.714356642503, 2828.792467557467, 2841.4884338378906, 2831.2933420034556, 2763.0162388728213, 2824.6928992638223, 2884.391406719501, 2843.5355201134316, 2840.701175396259, 2822.675457294171, 2840.2967271071216, 2795.851810161884, 2757.4024599515474, 2816.4540111835186, 2901.0067326472354, 2867.4740271935098, 2969.895237849309, 2853.240485558143, 2869.1643841083232, 2874.50807424692, 2796.0884915865386, 3026.903350830078, 2872.9634798490083, 2890.4576427753154, 2944.919163630559, 2875.053485576923, 2964.4402465820312, 2974.9151799128604, 2906.978285569411, 2901.946320753831, 2914.937218299279, 2999.5433537409854, 2956.449486365685, 3033.7027787428638, 2980.8644726093, 2968.3921508789062, 3052.6045191838193, 2981.790250338041, 2879.472919170673, 2958.3214205228364, 2995.1011716402495, 3032.9681701660156, 2985.60670705942], 'val_acc': [0.9354738776500409, 0.9394617264087384, 0.9385130474200616, 0.9408589418117816, 0.9414084118146163, 0.9456279919697688, 0.9430502836520855, 0.9423033916033231, 0.9414255756598252, 0.9443101699535663, 0.9448317197652963, 0.9443037555767939, 0.9455378812093002, 0.9456923879109896, 0.946473648914924, 0.9467741021743188, 0.9459048555447505, 0.9451128679972428, 0.9463663192895743, 0.9468363569333003, 0.9456966909078451, 0.9466238594972171, 0.9449540789310749, 0.9459349329654987, 0.9467741205142095, 0.9475982808149778, 0.9468578375302829, 0.9460894580070789, 0.9469801439688756, 0.9469823080759782, 0.9479094881277818, 0.9472677478423486, 0.9471948215594659, 0.9479202307187594, 0.9484846958747277, 0.9476154698775365, 0.9466367455629202, 0.9462740123271942, 0.946718346614104, 0.9474523755220267, 0.9472720783490401, 0.9465444982051849, 0.947533939893429, 0.9476777383914361, 0.9480619017894452, 0.9465787960932806, 0.9466109986488636, 0.9451901568816259, 0.9473192668878115, 0.9470166655687186, 0.9483924553944514, 0.9476476701406332, 0.9479266726053678, 0.946905071918781, 0.9471690379656278, 0.9479996562004089, 0.9482207206579355, 0.9485083497487582, 0.9473922275579892, 0.9479696337993329, 0.9478966570817507, 0.9483924278846154, 0.9472012496911563, 0.9475618302822113, 0.9464071072064913, 0.946407104914005, 0.9484610970203693, 0.9463685017365676, 0.9474609631758469, 0.9481284572527959, 0.9485405270869915, 0.9470746058684129, 0.9473857971338125, 0.9478386846872476, 0.9481262748058026, 0.9481799235710731, 0.9474673775526193, 0.9475725522408118, 0.9481842311529013, 0.947864443063736, 0.9468793204197516, 0.9475253224372864, 0.9462632949535663, 0.9488238463034997, 0.9466539437954242, 0.9481777732188885, 0.9476433556813461, 0.948014688033324, 0.946767671750142, 0.9479803167856656, 0.9488968069736774, 0.9466002789827493, 0.9487207921651694, 0.9479889227793767, 0.9481026667814988, 0.9472205409636865, 0.9479416838059058, 0.9491758415332208, 0.9474480450153351, 0.9477184919210581, 0.9486414010708148, 0.947475953744008, 0.9479674559373122, 0.9471583045445956, 0.9489440528246073, 0.9481134139574491, 0.9480897990556864, 0.9486864942770737, 0.9482786930524386, 0.9474072685608497, 0.9484267486975744, 0.9486993551254272, 0.9486285310525161, 0.9485812806166135, 0.9483516285052667, 0.948665011387605, 0.9481670879400693, 0.9468363500558413, 0.9479095339775085, 0.9484546872285696, 0.9475746682057014, 0.9486328042470492, 0.9490341888024256, 0.9484868668592893, 0.9481241152836726, 0.9489075472721686, 0.9467633664608002, 0.9484825661549201, 0.9482335906762344, 0.9490126898655524, 0.9493625737153567, 0.9485620099764603, 0.9481091338854569, 0.9482786792975205, 0.9478751925321726, 0.9480082255143386, 0.9479116682822888, 0.9486993413705093, 0.9489826605870173, 0.9493947166662949, 0.9481069422685183, 0.9489203920731177, 0.9486649792927963, 0.9484246487800891, 0.9485469460487366, 0.9493260910877814, 0.9482936904980586, 0.9475660851368537, 0.948765869324024, 0.9489204081205221, 0.949066345508282, 0.9484653747998751, 0.9488753607639899], 'val_mDice': [0.42277670995547223, 0.45685237044325244, 0.4663421717973856, 0.4652419649064541, 0.47443150413724094, 0.48340822842258674, 0.48404771891924053, 0.48613777928627455, 0.48106306676681226, 0.4912435214679975, 0.501023737856975, 0.4867580051605518, 0.5058128475569762, 0.5102232236128587, 0.5052435896717585, 0.5063896485819266, 0.5092121855570719, 0.5022731913396945, 0.5108632485453899, 0.5143169749241608, 0.507565606958591, 0.5184175532597762, 0.5063299760222435, 0.5138537161625348, 0.5148389287866079, 0.5202899758632367, 0.5223685468618686, 0.5108995128136414, 0.5218840238566582, 0.5184375480390512, 0.5142132903520877, 0.5166248034399289, 0.5224314039716353, 0.5283028225486095, 0.5178423426472224, 0.5179952093614981, 0.5196710363603555, 0.51645086103907, 0.5208068063052801, 0.5131163665881524, 0.5181335801115403, 0.5180355376349046, 0.5148189142346382, 0.5215729096761117, 0.5272497483170949, 0.5159923866964303, 0.5096727810226954, 0.509812727283973, 0.5159472485001271, 0.5193459838628769, 0.5143709131158315, 0.5244371398137166, 0.5254707451050098, 0.5293441065228902, 0.5255617734331351, 0.520941287279129, 0.5317802102519915, 0.5275189326359675, 0.5192549463648063, 0.5269938555474465, 0.5178086628707556, 0.523636710185271, 0.5247926938419158, 0.5275512744600956, 0.5174702474704156, 0.516960369852873, 0.5197186418450795, 0.5218961508228228, 0.5232798795287426, 0.5149361751973629, 0.5306441184992974, 0.5236133732474767, 0.526938340984858, 0.5276968341607314, 0.5220855368444552, 0.5237525125535635, 0.5273602421467121, 0.5264205852380166, 0.526240141919026, 0.5267151473806455, 0.5229935938349137, 0.5228826724565946, 0.5195260323010958, 0.5351951529200261, 0.5191612639106237, 0.5190098984883382, 0.523953496836699, 0.5281147286295891, 0.5166798950387881, 0.5188212354595845, 0.5306321734992357, 0.5153771174641756, 0.5275921116654689, 0.5222029961072482, 0.5259843210761364, 0.5363057963550091, 0.5336860578793746, 0.5328131862557851, 0.5271557982151325, 0.5265286478858727, 0.5248227572211852, 0.5256616605015901, 0.5295117357029364, 0.5263226960714047, 0.5255229335564834, 0.5238991041596119, 0.523305794940545, 0.5249612844334199, 0.5237885722174094, 0.521514164427152, 0.5207479028747632, 0.5228249270182389, 0.5301816096672645, 0.5289247838350443, 0.5346141122281551, 0.5276829368219926, 0.52327363508252, 0.5269812414279351, 0.5295011395445237, 0.5254332821529645, 0.5314183481610738, 0.5296909680160192, 0.5383731533701603, 0.5333105789927336, 0.5209116875552214, 0.5316989820163983, 0.5231072461375823, 0.528826827613207, 0.5295287227401366, 0.5310738301621034, 0.5361975210790451, 0.5135371409929715, 0.5291033258231786, 0.5241016562168415, 0.5168934693703284, 0.5271670437203004, 0.525259137726747, 0.5269228320282239, 0.5284573338352717, 0.5234618227069194, 0.5290688333603052, 0.5232822006711593, 0.5250479601896726, 0.5148082123352931, 0.5219848322180601, 0.5277402549982071, 0.5170090187054414, 0.5223093614555322, 0.5308751228910226, 0.525071247265889, 0.5262884265528276, 0.5219515424508315, 0.5273021637247159], 'loss': [1961.7674629389442, 861.1494565670158, 697.9629537344397, 619.4588646829365, 566.553112418078, 532.1204974737311, 503.86693381119795, 481.28796563609814, 462.27884817681917, 447.3354405275869, 432.8241344361489, 421.3207221906761, 413.9311789590297, 402.77787109223016, 395.52702148741463, 386.9269897902813, 379.9439224331821, 373.09671896801086, 366.73698652000604, 361.9505878249009, 355.7046375044221, 350.81293948633606, 346.31306465259394, 342.6680268468226, 337.3385916455452, 333.4229877679141, 329.23783047753574, 325.22523534138526, 319.5440004386223, 319.03437248961046, 315.0405573899001, 311.55416235307655, 310.7223546852169, 306.5743505936492, 303.7534055329002, 301.2742826762063, 298.7717213126266, 294.35903443756285, 292.38631443712177, 291.3031921337465, 288.133277252065, 286.7379047809289, 284.25589699214385, 282.6436097235584, 279.66784380608726, 277.89827317003284, 275.38474773747186, 275.04199463048235, 272.49814915377794, 271.19092423452133, 269.50812854677133, 268.364969027149, 265.11189286836145, 265.4887808666319, 262.04148102439905, 261.66102574415385, 260.30883253745395, 257.3589698167389, 256.39481606431127, 255.99690998474588, 254.38556859291623, 253.17816029828072, 250.8817415020183, 249.66439208308896, 249.61933255109864, 247.76566880762738, 245.29201071251146, 245.3089219089541, 244.27886683833364, 242.7839129900983, 241.5325658900771, 241.2614947098005, 239.64092542491233, 237.88279274646112, 238.88127355057517, 238.13846801614272, 236.14413324088878, 233.90646335144802, 234.20511298112342, 232.09803007414868, 231.37905292533853, 230.35024602872952, 230.24882144254258, 228.76775189900786, 227.6302762769041, 227.42714331750994, 226.15354179432282, 225.15362718682948, 225.22865211397456, 225.02320877014682, 222.9220259421142, 222.66288538637895, 222.03479875907416, 220.97454840176266, 221.1691354837605, 219.82404702705594, 218.47604490999782, 217.65531055577443, 216.093467960078, 216.5134633300072, 215.7514602645653, 214.62091023994748, 214.53661577787102, 214.32378447118484, 213.6962207138764, 212.63385190034083, 212.10666205400824, 211.02346273054775, 210.95825557327024, 210.1717363093861, 208.4600842975552, 207.87896621001886, 208.4765824449246, 208.03149709725287, 206.01516164673944, 207.04091949378457, 206.32880299022955, 206.2272440259399, 205.46285342651242, 204.29869623209711, 203.60978484125164, 203.09610984919752, 202.72864978497927, 202.18124962750147, 201.07496346137097, 201.1193502655353, 200.93663176322218, 200.74611104015142, 199.1283800701566, 198.65117240890984, 198.6168907564482, 197.7519329267708, 197.93985285939715, 196.87026921600958, 196.51437766189386, 195.09800003222034, 195.27936620166093, 194.091942559636, 194.59744640752464, 193.59258267449175, 193.5707816708234, 193.1931891514786, 193.31332665823115, 191.917251209068, 191.49729394248675, 191.13135088588396, 191.4059253795708, 191.1535015955827, 190.45611060308835, 189.67336767067013, 188.73244256154425, 189.21329643026462, 188.23997767187294], 'acc': [0.9149586503811123, 0.9414998235423704, 0.9475221618079593, 0.9508289590616744, 0.9532242057442852, 0.9548097414184538, 0.9561583089133663, 0.9571579286151296, 0.9581478243273013, 0.9587910788245915, 0.9592917083506544, 0.9597744925440121, 0.960070557170146, 0.9605652223837878, 0.9608396953469128, 0.9612123859574035, 0.9614099672081878, 0.961739696887304, 0.9620196838270284, 0.9622777318543287, 0.9623903567023815, 0.9626766685892886, 0.9628299112184938, 0.9629171147762514, 0.9631418759704329, 0.9633779297738698, 0.9634771781478719, 0.9636120580388954, 0.9637960137822229, 0.9639776864307322, 0.9640005156638316, 0.9641098698753499, 0.9640634244937117, 0.9642815771087954, 0.9643598025073581, 0.9644428481587755, 0.9644635802791599, 0.9647254757387308, 0.9647654906240961, 0.9648287151172725, 0.9648407147036898, 0.9647969471883875, 0.9649951280806982, 0.9649289040221155, 0.9649828606499282, 0.9650297774706096, 0.9650995809906777, 0.9651693293477275, 0.9652462400359266, 0.9653368581048262, 0.9653825773300527, 0.9654679905441451, 0.9654888639994942, 0.9655504786450408, 0.9655874069245178, 0.9656964740244806, 0.9657592203062333, 0.9657947075198764, 0.9657145901369695, 0.9657273551123307, 0.9658519610381925, 0.9658110173087404, 0.9658443644941046, 0.9660477921673153, 0.9659795735327177, 0.966142449065195, 0.9661347105100038, 0.9661544293624211, 0.96615105711819, 0.9661315612980749, 0.9662298576853586, 0.9662863896098247, 0.966208592910647, 0.9663621632032351, 0.9664150283398866, 0.9663600429149062, 0.9664721711913478, 0.9664257538722119, 0.9664702007364415, 0.9664577849289703, 0.9665011226179898, 0.9666488069587778, 0.9666603142997716, 0.9665860562958665, 0.9667555853294335, 0.9667538733134067, 0.9668629206899104, 0.9668315503305476, 0.9668779071545146, 0.9668721859881461, 0.9669178236314734, 0.9669682570052611, 0.9669888448222673, 0.9670572932340623, 0.9669922603998393, 0.9670626456904848, 0.9671443711564647, 0.9671207836146374, 0.9671848022738782, 0.9671695877636511, 0.967130723891636, 0.9670981357076297, 0.9672447706097816, 0.9671244427065651, 0.9672551650430602, 0.9672438431564517, 0.9672615455435528, 0.9673859071909672, 0.9674433237136669, 0.967435728230512, 0.9674099100358392, 0.9673900680382358, 0.967514035645242, 0.9674605314641226, 0.9675108666658775, 0.9673774050388743, 0.9674202030538183, 0.9674991739529543, 0.967529580050659, 0.9674826810954297, 0.9675349722123614, 0.9676595579859935, 0.9676602579489039, 0.9676574171551433, 0.9676666213480362, 0.9676166794225979, 0.9676203425438721, 0.9676053547050024, 0.9677464944030222, 0.9677293010108928, 0.9676712084320059, 0.9677651834523097, 0.9677027670437588, 0.9677733364639979, 0.9678200466336222, 0.9678542395310022, 0.967875135964071, 0.9679719342480042, 0.9679238635884828, 0.9679946797773383, 0.9679552535338781, 0.9679649328873253, 0.9679774902221583, 0.9679749801371531, 0.9681790887589363, 0.9680732350216178, 0.9680468621403927, 0.9680705801165105, 0.9679981769368096, 0.9680995817203358, 0.9680816330043832, 0.9680560667840447, 0.9681180709679057], 'mDice': [0.3320347756905979, 0.5912028270751516, 0.6603370461749336, 0.6964288321652228, 0.7205420896640444, 0.7372553028942067, 0.7505591055525193, 0.7612695206765109, 0.770424469550971, 0.7778661127274276, 0.7844779393247031, 0.7899306620232659, 0.7935446144073836, 0.7993558051785584, 0.8030363604018227, 0.8069731877165219, 0.8105173641813205, 0.8137217491994339, 0.8170155803897576, 0.8191313182945941, 0.8225028669494419, 0.8248985932727125, 0.8269525920730185, 0.828786723829004, 0.8316490683819022, 0.8334247080435186, 0.8356064387510307, 0.8372896357753735, 0.840351042888882, 0.8408368332386237, 0.842497957376144, 0.8444354218452891, 0.8448333222631004, 0.8467860295578397, 0.8482579213990438, 0.8492553029719572, 0.8508820622035259, 0.85296455399748, 0.8538813276131698, 0.8545982865382196, 0.8558923553949923, 0.8568654704234658, 0.8580557911156135, 0.8589134904980539, 0.8603288974146732, 0.861192138814227, 0.8624030208715179, 0.8627734986671297, 0.8639546419260831, 0.8646809173545021, 0.8656191304360414, 0.8663172617968319, 0.8674695273007699, 0.8677373591751715, 0.8691882754695885, 0.8696366620549723, 0.8703235865936589, 0.8718245549581483, 0.872128217365209, 0.8724953251044205, 0.8732142332602194, 0.8739096707857085, 0.87478171093684, 0.8754933798630871, 0.875541247362186, 0.8764287377375689, 0.8778640093491612, 0.8779715960518104, 0.8782543764720816, 0.8790146049500656, 0.8797608407828065, 0.8798028020789281, 0.8806350469853093, 0.8816407969667938, 0.881239622999005, 0.881411320282768, 0.8824089729597919, 0.8834180654518985, 0.8833798471493639, 0.8846407834865462, 0.8849636587359573, 0.8854920311320655, 0.8854034502743949, 0.8861357900012983, 0.8866270101456298, 0.8868651893606575, 0.8876409067622104, 0.8880890002882174, 0.8880139487284219, 0.8882059075345767, 0.8890752872175741, 0.8892099647232607, 0.8894946755248551, 0.8901454000623422, 0.8901350406563437, 0.8909401126005966, 0.891503700006825, 0.8917551432150179, 0.8926227659929792, 0.8925108378260908, 0.8927677322454276, 0.8934813586590112, 0.8935931930680079, 0.893476987637069, 0.8937423711089997, 0.8943700901445929, 0.8946948443118314, 0.8953217065368402, 0.8953013555662532, 0.8956248950201856, 0.8964986951217258, 0.8967477086009679, 0.8966460069321095, 0.8967469419147172, 0.8977327978744022, 0.8972192261202093, 0.8976249997162636, 0.8978411850372517, 0.8982179171812773, 0.8985921631909973, 0.8991269739002009, 0.8991832606721868, 0.8995779645868435, 0.8997038199674442, 0.9002242216179537, 0.9003673946682645, 0.9004478534901922, 0.900604692396396, 0.9012851191822545, 0.9016345717981052, 0.9016052586867627, 0.901836915802474, 0.90198957630929, 0.9023750553785913, 0.902811386307524, 0.9033148218859147, 0.9033437938056045, 0.9039218673393382, 0.9036947082991663, 0.9040635704092683, 0.9042671604986771, 0.904320714626103, 0.9043714089619215, 0.9048545125950573, 0.9052340804095815, 0.9053111111096414, 0.9052682658474482, 0.9054967987573664, 0.9056106780844729, 0.9062140170667902, 0.9066420343653759, 0.906371281033324, 0.9070102736473435]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.22s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.99s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.78s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:15,  1.32s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:42,  1.42s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:40,  1.42s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:09,  1.53s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<06:54,  1.48s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:13,  1.55s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:30,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:38,  1.65s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:30,  1.63s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:45,  1.69s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:56,  1.74s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<08:02,  1.77s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<08:14,  1.82s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:25,  1.87s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:25,  1.87s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:22,  1.87s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:22,  1.88s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:16,  1.86s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<08:13,  1.85s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:18,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:10,  1.86s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<08:04,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:58,  1.83s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:52,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:50,  1.81s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:54,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:49,  1.82s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:44,  1.81s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:37,  1.79s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:28,  1.76s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:26,  1.76s/it]predicting train subjects:  11%|█         | 32/285 [00:56<07:17,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:16,  1.73s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:10,  1.72s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:06,  1.70s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:03,  1.70s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:02,  1.70s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<06:59,  1.70s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<06:52,  1.68s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<06:47,  1.67s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:51,  1.68s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:54,  1.70s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:51,  1.70s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<06:48,  1.70s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:48,  1.70s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<06:34,  1.65s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:16,  1.58s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:12,  1.57s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:14,  1.59s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:06,  1.56s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<05:57,  1.53s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<05:53,  1.52s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<05:54,  1.53s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<05:49,  1.51s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<05:49,  1.52s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<05:46,  1.51s/it]predicting train subjects:  20%|██        | 57/285 [01:36<05:42,  1.50s/it]predicting train subjects:  20%|██        | 58/285 [01:37<05:35,  1.48s/it]predicting train subjects:  21%|██        | 59/285 [01:39<05:39,  1.50s/it]predicting train subjects:  21%|██        | 60/285 [01:41<05:49,  1.55s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<05:43,  1.53s/it]predicting train subjects:  22%|██▏       | 62/285 [01:44<05:40,  1.53s/it]predicting train subjects:  22%|██▏       | 63/285 [01:45<05:34,  1.51s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<05:37,  1.53s/it]predicting train subjects:  23%|██▎       | 65/285 [01:48<05:47,  1.58s/it]predicting train subjects:  23%|██▎       | 66/285 [01:50<05:46,  1.58s/it]predicting train subjects:  24%|██▎       | 67/285 [01:51<05:36,  1.54s/it]predicting train subjects:  24%|██▍       | 68/285 [01:53<05:28,  1.51s/it]predicting train subjects:  24%|██▍       | 69/285 [01:54<05:23,  1.50s/it]predicting train subjects:  25%|██▍       | 70/285 [01:56<05:25,  1.52s/it]predicting train subjects:  25%|██▍       | 71/285 [01:57<05:25,  1.52s/it]predicting train subjects:  25%|██▌       | 72/285 [01:59<05:26,  1.53s/it]predicting train subjects:  26%|██▌       | 73/285 [02:00<05:23,  1.53s/it]predicting train subjects:  26%|██▌       | 74/285 [02:02<05:19,  1.51s/it]predicting train subjects:  26%|██▋       | 75/285 [02:03<05:12,  1.49s/it]predicting train subjects:  27%|██▋       | 76/285 [02:05<05:10,  1.49s/it]predicting train subjects:  27%|██▋       | 77/285 [02:06<05:11,  1.50s/it]predicting train subjects:  27%|██▋       | 78/285 [02:08<05:15,  1.52s/it]predicting train subjects:  28%|██▊       | 79/285 [02:09<05:12,  1.52s/it]predicting train subjects:  28%|██▊       | 80/285 [02:11<05:12,  1.53s/it]predicting train subjects:  28%|██▊       | 81/285 [02:13<05:12,  1.53s/it]predicting train subjects:  29%|██▉       | 82/285 [02:14<05:07,  1.51s/it]predicting train subjects:  29%|██▉       | 83/285 [02:16<05:04,  1.51s/it]predicting train subjects:  29%|██▉       | 84/285 [02:17<05:01,  1.50s/it]predicting train subjects:  30%|██▉       | 85/285 [02:19<05:08,  1.54s/it]predicting train subjects:  30%|███       | 86/285 [02:20<05:17,  1.60s/it]predicting train subjects:  31%|███       | 87/285 [02:22<05:21,  1.63s/it]predicting train subjects:  31%|███       | 88/285 [02:24<05:27,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:25<05:26,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:27<05:24,  1.67s/it]predicting train subjects:  32%|███▏      | 91/285 [02:29<05:21,  1.66s/it]predicting train subjects:  32%|███▏      | 92/285 [02:30<05:20,  1.66s/it]predicting train subjects:  33%|███▎      | 93/285 [02:32<05:18,  1.66s/it]predicting train subjects:  33%|███▎      | 94/285 [02:34<05:17,  1.66s/it]predicting train subjects:  33%|███▎      | 95/285 [02:35<05:16,  1.67s/it]predicting train subjects:  34%|███▎      | 96/285 [02:37<05:16,  1.67s/it]predicting train subjects:  34%|███▍      | 97/285 [02:39<05:16,  1.68s/it]predicting train subjects:  34%|███▍      | 98/285 [02:41<05:14,  1.68s/it]predicting train subjects:  35%|███▍      | 99/285 [02:42<05:13,  1.68s/it]predicting train subjects:  35%|███▌      | 100/285 [02:44<05:12,  1.69s/it]predicting train subjects:  35%|███▌      | 101/285 [02:46<05:10,  1.69s/it]predicting train subjects:  36%|███▌      | 102/285 [02:47<05:09,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:49<05:07,  1.69s/it]predicting train subjects:  36%|███▋      | 104/285 [02:51<05:04,  1.68s/it]predicting train subjects:  37%|███▋      | 105/285 [02:52<05:02,  1.68s/it]predicting train subjects:  37%|███▋      | 106/285 [02:54<04:59,  1.67s/it]predicting train subjects:  38%|███▊      | 107/285 [02:56<04:58,  1.68s/it]predicting train subjects:  38%|███▊      | 108/285 [02:57<04:56,  1.68s/it]predicting train subjects:  38%|███▊      | 109/285 [02:59<04:52,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:01<04:49,  1.65s/it]predicting train subjects:  39%|███▉      | 111/285 [03:02<04:48,  1.66s/it]predicting train subjects:  39%|███▉      | 112/285 [03:04<04:47,  1.66s/it]predicting train subjects:  40%|███▉      | 113/285 [03:06<04:47,  1.67s/it]predicting train subjects:  40%|████      | 114/285 [03:07<04:43,  1.66s/it]predicting train subjects:  40%|████      | 115/285 [03:09<04:41,  1.66s/it]predicting train subjects:  41%|████      | 116/285 [03:11<04:42,  1.67s/it]predicting train subjects:  41%|████      | 117/285 [03:12<04:42,  1.68s/it]predicting train subjects:  41%|████▏     | 118/285 [03:14<04:40,  1.68s/it]predicting train subjects:  42%|████▏     | 119/285 [03:16<04:38,  1.68s/it]predicting train subjects:  42%|████▏     | 120/285 [03:17<04:38,  1.69s/it]predicting train subjects:  42%|████▏     | 121/285 [03:19<04:27,  1.63s/it]predicting train subjects:  43%|████▎     | 122/285 [03:20<04:14,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:22<04:01,  1.49s/it]predicting train subjects:  44%|████▎     | 124/285 [03:23<03:58,  1.48s/it]predicting train subjects:  44%|████▍     | 125/285 [03:25<03:59,  1.49s/it]predicting train subjects:  44%|████▍     | 126/285 [03:26<03:58,  1.50s/it]predicting train subjects:  45%|████▍     | 127/285 [03:28<03:56,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:29<03:56,  1.51s/it]predicting train subjects:  45%|████▌     | 129/285 [03:31<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 130/285 [03:32<03:55,  1.52s/it]predicting train subjects:  46%|████▌     | 131/285 [03:34<03:55,  1.53s/it]predicting train subjects:  46%|████▋     | 132/285 [03:35<03:53,  1.53s/it]predicting train subjects:  47%|████▋     | 133/285 [03:37<03:49,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [03:38<03:46,  1.50s/it]predicting train subjects:  47%|████▋     | 135/285 [03:40<03:47,  1.51s/it]predicting train subjects:  48%|████▊     | 136/285 [03:41<03:44,  1.51s/it]predicting train subjects:  48%|████▊     | 137/285 [03:43<03:42,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:44<03:39,  1.49s/it]predicting train subjects:  49%|████▉     | 139/285 [03:46<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:47<03:34,  1.48s/it]predicting train subjects:  49%|████▉     | 141/285 [03:49<03:31,  1.47s/it]predicting train subjects:  50%|████▉     | 142/285 [03:50<03:26,  1.44s/it]predicting train subjects:  50%|█████     | 143/285 [03:51<03:21,  1.42s/it]predicting train subjects:  51%|█████     | 144/285 [03:53<03:17,  1.40s/it]predicting train subjects:  51%|█████     | 145/285 [03:54<03:16,  1.41s/it]predicting train subjects:  51%|█████     | 146/285 [03:55<03:11,  1.38s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:57<03:10,  1.38s/it]predicting train subjects:  52%|█████▏    | 148/285 [03:58<03:10,  1.39s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:00<03:08,  1.38s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:01<03:06,  1.38s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:02<03:04,  1.38s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:04<03:02,  1.37s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:05<03:01,  1.38s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:07<03:01,  1.38s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:08<02:59,  1.38s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:09<02:58,  1.38s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:11<02:59,  1.40s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:12<02:57,  1.40s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:13<02:54,  1.38s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:15<02:51,  1.37s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:16<02:48,  1.36s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:17<02:45,  1.34s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:19<02:42,  1.33s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:20<02:40,  1.33s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:21<02:39,  1.33s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:23<02:39,  1.34s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:24<02:37,  1.33s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:25<02:34,  1.32s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:27<02:34,  1.33s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:28<02:33,  1.33s/it]predicting train subjects:  60%|██████    | 171/285 [04:29<02:34,  1.35s/it]predicting train subjects:  60%|██████    | 172/285 [04:31<02:32,  1.35s/it]predicting train subjects:  61%|██████    | 173/285 [04:32<02:30,  1.34s/it]predicting train subjects:  61%|██████    | 174/285 [04:33<02:27,  1.33s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:35<02:27,  1.34s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:36<02:27,  1.36s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:38<02:29,  1.38s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:39<02:25,  1.36s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:40<02:23,  1.36s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:42<02:20,  1.34s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:43<02:17,  1.32s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:44<02:15,  1.31s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:45<02:14,  1.31s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:47<02:11,  1.30s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:48<02:09,  1.29s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:49<02:07,  1.28s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:51<02:05,  1.28s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:52<02:03,  1.28s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:53<02:02,  1.28s/it]predicting train subjects:  67%|██████▋   | 190/285 [04:54<02:01,  1.28s/it]predicting train subjects:  67%|██████▋   | 191/285 [04:56<02:01,  1.29s/it]predicting train subjects:  67%|██████▋   | 192/285 [04:57<02:01,  1.30s/it]predicting train subjects:  68%|██████▊   | 193/285 [04:58<01:57,  1.27s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:00<01:56,  1.28s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:01<01:55,  1.28s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:02<02:01,  1.37s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:04<02:08,  1.46s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:06<02:09,  1.49s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:07<02:08,  1.50s/it]predicting train subjects:  70%|███████   | 200/285 [05:09<02:09,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:10<02:07,  1.52s/it]predicting train subjects:  71%|███████   | 202/285 [05:12<02:06,  1.52s/it]predicting train subjects:  71%|███████   | 203/285 [05:13<02:04,  1.52s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:15<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:16<02:03,  1.54s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:18<02:03,  1.56s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:20<02:06,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:21<02:04,  1.62s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:23<02:02,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:25<02:00,  1.61s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:26<01:58,  1.60s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:28<01:56,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:29<01:52,  1.57s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:31<01:47,  1.51s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:32<01:43,  1.48s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:33<01:39,  1.44s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:35<01:35,  1.41s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:36<01:32,  1.39s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:37<01:30,  1.38s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:39<01:30,  1.39s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:40<01:28,  1.38s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:42<01:26,  1.37s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:43<01:24,  1.36s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:44<01:24,  1.39s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:46<01:23,  1.38s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:47<01:21,  1.38s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:48<01:20,  1.38s/it]predicting train subjects:  80%|████████  | 228/285 [05:50<01:18,  1.37s/it]predicting train subjects:  80%|████████  | 229/285 [05:51<01:16,  1.36s/it]predicting train subjects:  81%|████████  | 230/285 [05:52<01:14,  1.36s/it]predicting train subjects:  81%|████████  | 231/285 [05:54<01:13,  1.35s/it]predicting train subjects:  81%|████████▏ | 232/285 [05:56<01:18,  1.47s/it]predicting train subjects:  82%|████████▏ | 233/285 [05:57<01:20,  1.54s/it]predicting train subjects:  82%|████████▏ | 234/285 [05:59<01:20,  1.58s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:01<01:20,  1.62s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:02<01:19,  1.62s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:04<01:18,  1.64s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:06<01:18,  1.68s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:07<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:09<01:15,  1.69s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:11<01:14,  1.69s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:13<01:13,  1.70s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:14<01:11,  1.70s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:16<01:10,  1.73s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:18<01:08,  1.72s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:19<01:06,  1.71s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:21<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:23<01:03,  1.71s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:25<01:01,  1.70s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:26<00:55,  1.58s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:27<00:51,  1.51s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:28<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:30<00:45,  1.41s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:31<00:42,  1.38s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:32<00:40,  1.36s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:34<00:39,  1.34s/it]predicting train subjects:  90%|█████████ | 257/285 [06:35<00:37,  1.33s/it]predicting train subjects:  91%|█████████ | 258/285 [06:36<00:36,  1.35s/it]predicting train subjects:  91%|█████████ | 259/285 [06:38<00:34,  1.33s/it]predicting train subjects:  91%|█████████ | 260/285 [06:39<00:33,  1.34s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:40<00:31,  1.32s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:42<00:30,  1.33s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:43<00:29,  1.33s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:44<00:27,  1.32s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:46<00:26,  1.35s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:47<00:26,  1.37s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:49<00:24,  1.37s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:50<00:25,  1.49s/it]predicting train subjects:  94%|█████████▍| 269/285 [06:52<00:24,  1.56s/it]predicting train subjects:  95%|█████████▍| 270/285 [06:54<00:24,  1.61s/it]predicting train subjects:  95%|█████████▌| 271/285 [06:56<00:24,  1.72s/it]predicting train subjects:  95%|█████████▌| 272/285 [06:57<00:22,  1.73s/it]predicting train subjects:  96%|█████████▌| 273/285 [06:59<00:20,  1.73s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:01<00:19,  1.75s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:03<00:17,  1.75s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:04<00:15,  1.73s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:06<00:13,  1.72s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:08<00:12,  1.72s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:10<00:10,  1.73s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:11<00:08,  1.75s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:13<00:06,  1.74s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:15<00:05,  1.74s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:17<00:03,  1.77s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:18<00:01,  1.76s/it]predicting train subjects: 100%|██████████| 285/285 [07:20<00:00,  1.75s/it]

