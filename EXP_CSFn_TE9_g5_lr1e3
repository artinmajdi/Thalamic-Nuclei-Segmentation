2020-01-21 17:28:16.421524: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-21 17:28:18.000301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-21 17:28:18.000374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 17:28:18.412912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 17:28:18.412983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 17:28:18.412997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 17:28:18.413476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<04:37,  1.13s/it]Loading train:   1%|          | 2/247 [00:01<04:13,  1.04s/it]Loading train:   1%|          | 3/247 [00:02<03:41,  1.10it/s]Loading train:   2%|▏         | 4/247 [00:03<03:17,  1.23it/s]Loading train:   2%|▏         | 5/247 [00:03<03:00,  1.34it/s]Loading train:   2%|▏         | 6/247 [00:04<02:44,  1.47it/s]Loading train:   3%|▎         | 7/247 [00:04<02:28,  1.62it/s]Loading train:   3%|▎         | 8/247 [00:05<02:22,  1.68it/s]Loading train:   4%|▎         | 9/247 [00:05<02:16,  1.74it/s]Loading train:   4%|▍         | 10/247 [00:06<02:09,  1.83it/s]Loading train:   4%|▍         | 11/247 [00:06<02:05,  1.89it/s]Loading train:   5%|▍         | 12/247 [00:07<02:05,  1.87it/s]Loading train:   5%|▌         | 13/247 [00:07<02:05,  1.87it/s]Loading train:   6%|▌         | 14/247 [00:08<02:04,  1.87it/s]Loading train:   6%|▌         | 15/247 [00:08<02:07,  1.82it/s]Loading train:   6%|▋         | 16/247 [00:09<02:05,  1.84it/s]Loading train:   7%|▋         | 17/247 [00:10<02:02,  1.87it/s]Loading train:   7%|▋         | 18/247 [00:10<02:04,  1.85it/s]Loading train:   8%|▊         | 19/247 [00:11<02:06,  1.81it/s]Loading train:   8%|▊         | 20/247 [00:11<02:04,  1.82it/s]Loading train:   9%|▊         | 21/247 [00:12<01:59,  1.89it/s]Loading train:   9%|▉         | 22/247 [00:12<02:06,  1.78it/s]Loading train:   9%|▉         | 23/247 [00:13<02:04,  1.80it/s]Loading train:  10%|▉         | 24/247 [00:13<01:55,  1.93it/s]Loading train:  10%|█         | 25/247 [00:14<02:06,  1.76it/s]Loading train:  11%|█         | 26/247 [00:15<02:06,  1.75it/s]Loading train:  11%|█         | 27/247 [00:15<02:07,  1.73it/s]Loading train:  11%|█▏        | 28/247 [00:16<02:06,  1.73it/s]Loading train:  12%|█▏        | 29/247 [00:16<02:07,  1.71it/s]Loading train:  12%|█▏        | 30/247 [00:17<02:04,  1.75it/s]Loading train:  13%|█▎        | 31/247 [00:17<02:04,  1.73it/s]Loading train:  13%|█▎        | 32/247 [00:18<02:01,  1.77it/s]Loading train:  13%|█▎        | 33/247 [00:19<01:58,  1.80it/s]Loading train:  14%|█▍        | 34/247 [00:19<01:54,  1.86it/s]Loading train:  14%|█▍        | 35/247 [00:20<01:53,  1.86it/s]Loading train:  15%|█▍        | 36/247 [00:20<01:49,  1.92it/s]Loading train:  15%|█▍        | 37/247 [00:21<01:53,  1.85it/s]Loading train:  15%|█▌        | 38/247 [00:21<01:53,  1.85it/s]Loading train:  16%|█▌        | 39/247 [00:22<01:50,  1.88it/s]Loading train:  16%|█▌        | 40/247 [00:22<01:48,  1.90it/s]Loading train:  17%|█▋        | 41/247 [00:23<01:50,  1.87it/s]Loading train:  17%|█▋        | 42/247 [00:23<01:56,  1.75it/s]Loading train:  17%|█▋        | 43/247 [00:24<01:54,  1.78it/s]Loading train:  18%|█▊        | 44/247 [00:24<01:52,  1.81it/s]Loading train:  18%|█▊        | 45/247 [00:25<01:47,  1.88it/s]Loading train:  19%|█▊        | 46/247 [00:26<01:51,  1.80it/s]Loading train:  19%|█▉        | 47/247 [00:26<01:46,  1.88it/s]Loading train:  19%|█▉        | 48/247 [00:27<01:44,  1.90it/s]Loading train:  20%|█▉        | 49/247 [00:27<01:49,  1.80it/s]Loading train:  20%|██        | 50/247 [00:28<01:45,  1.87it/s]Loading train:  21%|██        | 51/247 [00:28<01:47,  1.82it/s]Loading train:  21%|██        | 52/247 [00:29<01:46,  1.82it/s]Loading train:  21%|██▏       | 53/247 [00:29<01:48,  1.80it/s]Loading train:  22%|██▏       | 54/247 [00:30<01:46,  1.81it/s]Loading train:  22%|██▏       | 55/247 [00:31<01:51,  1.72it/s]Loading train:  23%|██▎       | 56/247 [00:31<01:47,  1.77it/s]Loading train:  23%|██▎       | 57/247 [00:32<01:47,  1.77it/s]Loading train:  23%|██▎       | 58/247 [00:32<01:49,  1.72it/s]Loading train:  24%|██▍       | 59/247 [00:33<01:47,  1.75it/s]Loading train:  24%|██▍       | 60/247 [00:33<01:47,  1.73it/s]Loading train:  25%|██▍       | 61/247 [00:34<01:44,  1.77it/s]Loading train:  25%|██▌       | 62/247 [00:35<01:42,  1.80it/s]Loading train:  26%|██▌       | 63/247 [00:35<01:43,  1.78it/s]Loading train:  26%|██▌       | 64/247 [00:36<01:42,  1.79it/s]Loading train:  26%|██▋       | 65/247 [00:36<01:41,  1.79it/s]Loading train:  27%|██▋       | 66/247 [00:37<01:37,  1.86it/s]Loading train:  27%|██▋       | 67/247 [00:37<01:35,  1.88it/s]Loading train:  28%|██▊       | 68/247 [00:38<01:33,  1.91it/s]Loading train:  28%|██▊       | 69/247 [00:38<01:39,  1.79it/s]Loading train:  28%|██▊       | 70/247 [00:39<01:41,  1.75it/s]Loading train:  29%|██▊       | 71/247 [00:39<01:39,  1.77it/s]Loading train:  29%|██▉       | 72/247 [00:40<01:36,  1.81it/s]Loading train:  30%|██▉       | 73/247 [00:41<01:38,  1.77it/s]Loading train:  30%|██▉       | 74/247 [00:41<01:38,  1.75it/s]Loading train:  30%|███       | 75/247 [00:42<01:39,  1.72it/s]Loading train:  31%|███       | 76/247 [00:42<01:41,  1.69it/s]Loading train:  31%|███       | 77/247 [00:43<01:39,  1.70it/s]Loading train:  32%|███▏      | 78/247 [00:44<01:53,  1.49it/s]Loading train:  32%|███▏      | 79/247 [00:44<01:50,  1.52it/s]Loading train:  32%|███▏      | 80/247 [00:45<01:34,  1.77it/s]Loading train:  33%|███▎      | 81/247 [00:45<01:27,  1.90it/s]Loading train:  33%|███▎      | 82/247 [00:46<01:29,  1.84it/s]Loading train:  34%|███▎      | 83/247 [00:46<01:28,  1.86it/s]Loading train:  34%|███▍      | 84/247 [00:47<01:30,  1.80it/s]Loading train:  34%|███▍      | 85/247 [00:48<01:29,  1.81it/s]Loading train:  35%|███▍      | 86/247 [00:48<01:23,  1.94it/s]Loading train:  35%|███▌      | 87/247 [00:49<01:25,  1.87it/s]Loading train:  36%|███▌      | 88/247 [00:49<01:20,  1.96it/s]Loading train:  36%|███▌      | 89/247 [00:50<01:24,  1.88it/s]Loading train:  36%|███▋      | 90/247 [00:50<01:29,  1.76it/s]Loading train:  37%|███▋      | 91/247 [00:51<01:26,  1.80it/s]Loading train:  37%|███▋      | 92/247 [00:51<01:20,  1.93it/s]Loading train:  38%|███▊      | 93/247 [00:52<01:18,  1.97it/s]Loading train:  38%|███▊      | 94/247 [00:52<01:16,  1.99it/s]Loading train:  38%|███▊      | 95/247 [00:53<01:17,  1.95it/s]Loading train:  39%|███▉      | 96/247 [00:53<01:18,  1.92it/s]Loading train:  39%|███▉      | 97/247 [00:54<01:18,  1.91it/s]Loading train:  40%|███▉      | 98/247 [00:54<01:16,  1.95it/s]Loading train:  40%|████      | 99/247 [00:55<01:16,  1.94it/s]Loading train:  40%|████      | 100/247 [00:55<01:15,  1.95it/s]Loading train:  41%|████      | 101/247 [00:56<01:18,  1.86it/s]Loading train:  41%|████▏     | 102/247 [00:57<01:27,  1.66it/s]Loading train:  42%|████▏     | 103/247 [00:57<01:29,  1.60it/s]Loading train:  42%|████▏     | 104/247 [00:58<01:33,  1.52it/s]Loading train:  43%|████▎     | 105/247 [00:59<01:34,  1.50it/s]Loading train:  43%|████▎     | 106/247 [00:59<01:33,  1.51it/s]Loading train:  43%|████▎     | 107/247 [01:00<01:36,  1.45it/s]Loading train:  44%|████▎     | 108/247 [01:01<01:33,  1.48it/s]Loading train:  44%|████▍     | 109/247 [01:01<01:32,  1.50it/s]Loading train:  45%|████▍     | 110/247 [01:02<01:33,  1.47it/s]Loading train:  45%|████▍     | 111/247 [01:03<01:36,  1.41it/s]Loading train:  45%|████▌     | 112/247 [01:04<01:38,  1.37it/s]Loading train:  46%|████▌     | 113/247 [01:04<01:36,  1.39it/s]Loading train:  46%|████▌     | 114/247 [01:05<01:31,  1.46it/s]Loading train:  47%|████▋     | 115/247 [01:06<01:31,  1.44it/s]Loading train:  47%|████▋     | 116/247 [01:06<01:25,  1.53it/s]Loading train:  47%|████▋     | 117/247 [01:07<01:26,  1.50it/s]Loading train:  48%|████▊     | 118/247 [01:07<01:21,  1.59it/s]Loading train:  48%|████▊     | 119/247 [01:08<01:20,  1.58it/s]Loading train:  49%|████▊     | 120/247 [01:09<01:20,  1.58it/s]Loading train:  49%|████▉     | 121/247 [01:09<01:17,  1.63it/s]Loading train:  49%|████▉     | 122/247 [01:10<01:13,  1.69it/s]Loading train:  50%|████▉     | 123/247 [01:10<01:13,  1.70it/s]Loading train:  50%|█████     | 124/247 [01:11<01:11,  1.72it/s]Loading train:  51%|█████     | 125/247 [01:12<01:10,  1.73it/s]Loading train:  51%|█████     | 126/247 [01:12<01:10,  1.73it/s]Loading train:  51%|█████▏    | 127/247 [01:13<01:10,  1.69it/s]Loading train:  52%|█████▏    | 128/247 [01:13<01:08,  1.74it/s]Loading train:  52%|█████▏    | 129/247 [01:14<01:07,  1.76it/s]Loading train:  53%|█████▎    | 130/247 [01:14<01:06,  1.77it/s]Loading train:  53%|█████▎    | 131/247 [01:15<01:08,  1.70it/s]Loading train:  53%|█████▎    | 132/247 [01:16<01:08,  1.69it/s]Loading train:  54%|█████▍    | 133/247 [01:16<01:09,  1.63it/s]Loading train:  54%|█████▍    | 134/247 [01:17<01:08,  1.65it/s]Loading train:  55%|█████▍    | 135/247 [01:18<01:09,  1.61it/s]Loading train:  55%|█████▌    | 136/247 [01:18<01:04,  1.72it/s]Loading train:  55%|█████▌    | 137/247 [01:19<01:02,  1.76it/s]Loading train:  56%|█████▌    | 138/247 [01:19<01:00,  1.81it/s]Loading train:  56%|█████▋    | 139/247 [01:20<01:00,  1.79it/s]Loading train:  57%|█████▋    | 140/247 [01:20<00:58,  1.84it/s]Loading train:  57%|█████▋    | 141/247 [01:21<00:55,  1.90it/s]Loading train:  57%|█████▋    | 142/247 [01:21<00:55,  1.88it/s]Loading train:  58%|█████▊    | 143/247 [01:22<00:52,  1.97it/s]Loading train:  58%|█████▊    | 144/247 [01:22<00:53,  1.94it/s]Loading train:  59%|█████▊    | 145/247 [01:23<00:51,  1.98it/s]Loading train:  59%|█████▉    | 146/247 [01:23<00:49,  2.05it/s]Loading train:  60%|█████▉    | 147/247 [01:24<00:50,  1.99it/s]Loading train:  60%|█████▉    | 148/247 [01:24<00:49,  2.00it/s]Loading train:  60%|██████    | 149/247 [01:25<00:51,  1.89it/s]Loading train:  61%|██████    | 150/247 [01:25<00:50,  1.93it/s]Loading train:  61%|██████    | 151/247 [01:26<00:48,  2.00it/s]Loading train:  62%|██████▏   | 152/247 [01:26<00:47,  2.02it/s]Loading train:  62%|██████▏   | 153/247 [01:27<00:47,  1.99it/s]Loading train:  62%|██████▏   | 154/247 [01:27<00:49,  1.90it/s]Loading train:  63%|██████▎   | 155/247 [01:28<00:50,  1.83it/s]Loading train:  63%|██████▎   | 156/247 [01:28<00:48,  1.86it/s]Loading train:  64%|██████▎   | 157/247 [01:29<00:49,  1.82it/s]Loading train:  64%|██████▍   | 158/247 [01:30<00:51,  1.74it/s]Loading train:  64%|██████▍   | 159/247 [01:30<00:51,  1.71it/s]Loading train:  65%|██████▍   | 160/247 [01:31<00:47,  1.84it/s]Loading train:  65%|██████▌   | 161/247 [01:31<00:49,  1.75it/s]Loading train:  66%|██████▌   | 162/247 [01:32<00:46,  1.82it/s]Loading train:  66%|██████▌   | 163/247 [01:32<00:47,  1.78it/s]Loading train:  66%|██████▋   | 164/247 [01:33<00:46,  1.80it/s]Loading train:  67%|██████▋   | 165/247 [01:34<00:46,  1.77it/s]Loading train:  67%|██████▋   | 166/247 [01:34<00:46,  1.74it/s]Loading train:  68%|██████▊   | 167/247 [01:35<00:46,  1.72it/s]Loading train:  68%|██████▊   | 168/247 [01:35<00:44,  1.76it/s]Loading train:  68%|██████▊   | 169/247 [01:36<00:46,  1.68it/s]Loading train:  69%|██████▉   | 170/247 [01:37<00:46,  1.65it/s]Loading train:  69%|██████▉   | 171/247 [01:37<00:44,  1.69it/s]Loading train:  70%|██████▉   | 172/247 [01:38<00:44,  1.70it/s]Loading train:  70%|███████   | 173/247 [01:38<00:43,  1.69it/s]Loading train:  70%|███████   | 174/247 [01:39<00:42,  1.73it/s]Loading train:  71%|███████   | 175/247 [01:39<00:40,  1.76it/s]Loading train:  71%|███████▏  | 176/247 [01:40<00:40,  1.76it/s]Loading train:  72%|███████▏  | 177/247 [01:40<00:38,  1.80it/s]Loading train:  72%|███████▏  | 178/247 [01:41<00:38,  1.79it/s]Loading train:  72%|███████▏  | 179/247 [01:42<00:38,  1.76it/s]Loading train:  73%|███████▎  | 180/247 [01:42<00:38,  1.75it/s]Loading train:  73%|███████▎  | 181/247 [01:43<00:36,  1.79it/s]Loading train:  74%|███████▎  | 182/247 [01:43<00:36,  1.76it/s]Loading train:  74%|███████▍  | 183/247 [01:44<00:37,  1.70it/s]Loading train:  74%|███████▍  | 184/247 [01:45<00:36,  1.75it/s]Loading train:  75%|███████▍  | 185/247 [01:45<00:36,  1.69it/s]Loading train:  75%|███████▌  | 186/247 [01:46<00:37,  1.65it/s]Loading train:  76%|███████▌  | 187/247 [01:46<00:34,  1.76it/s]Loading train:  76%|███████▌  | 188/247 [01:47<00:34,  1.73it/s]Loading train:  77%|███████▋  | 189/247 [01:47<00:33,  1.72it/s]Loading train:  77%|███████▋  | 190/247 [01:48<00:33,  1.72it/s]Loading train:  77%|███████▋  | 191/247 [01:49<00:33,  1.68it/s]Loading train:  78%|███████▊  | 192/247 [01:49<00:31,  1.73it/s]Loading train:  78%|███████▊  | 193/247 [01:50<00:31,  1.73it/s]Loading train:  79%|███████▊  | 194/247 [01:50<00:31,  1.71it/s]Loading train:  79%|███████▉  | 195/247 [01:51<00:30,  1.70it/s]Loading train:  79%|███████▉  | 196/247 [01:52<00:29,  1.72it/s]Loading train:  80%|███████▉  | 197/247 [01:52<00:27,  1.82it/s]Loading train:  80%|████████  | 198/247 [01:53<00:26,  1.85it/s]Loading train:  81%|████████  | 199/247 [01:53<00:26,  1.79it/s]Loading train:  81%|████████  | 200/247 [01:54<00:26,  1.80it/s]Loading train:  81%|████████▏ | 201/247 [01:54<00:26,  1.77it/s]Loading train:  82%|████████▏ | 202/247 [01:55<00:24,  1.84it/s]Loading train:  82%|████████▏ | 203/247 [01:55<00:23,  1.86it/s]Loading train:  83%|████████▎ | 204/247 [01:56<00:24,  1.79it/s]Loading train:  83%|████████▎ | 205/247 [01:56<00:21,  1.92it/s]Loading train:  83%|████████▎ | 206/247 [01:57<00:22,  1.85it/s]Loading train:  84%|████████▍ | 207/247 [01:58<00:22,  1.81it/s]Loading train:  84%|████████▍ | 208/247 [01:58<00:22,  1.71it/s]Loading train:  85%|████████▍ | 209/247 [01:59<00:23,  1.65it/s]Loading train:  85%|████████▌ | 210/247 [01:59<00:21,  1.75it/s]Loading train:  85%|████████▌ | 211/247 [02:00<00:19,  1.84it/s]Loading train:  86%|████████▌ | 212/247 [02:00<00:18,  1.84it/s]Loading train:  86%|████████▌ | 213/247 [02:01<00:19,  1.78it/s]Loading train:  87%|████████▋ | 214/247 [02:02<00:18,  1.77it/s]Loading train:  87%|████████▋ | 215/247 [02:02<00:17,  1.79it/s]Loading train:  87%|████████▋ | 216/247 [02:03<00:17,  1.73it/s]Loading train:  88%|████████▊ | 217/247 [02:03<00:17,  1.71it/s]Loading train:  88%|████████▊ | 218/247 [02:04<00:16,  1.75it/s]Loading train:  89%|████████▊ | 219/247 [02:04<00:15,  1.78it/s]Loading train:  89%|████████▉ | 220/247 [02:05<00:15,  1.71it/s]Loading train:  89%|████████▉ | 221/247 [02:06<00:14,  1.76it/s]Loading train:  90%|████████▉ | 222/247 [02:06<00:13,  1.84it/s]Loading train:  90%|█████████ | 223/247 [02:07<00:13,  1.84it/s]Loading train:  91%|█████████ | 224/247 [02:07<00:12,  1.82it/s]Loading train:  91%|█████████ | 225/247 [02:08<00:12,  1.77it/s]Loading train:  91%|█████████▏| 226/247 [02:08<00:12,  1.75it/s]Loading train:  92%|█████████▏| 227/247 [02:09<00:11,  1.75it/s]Loading train:  92%|█████████▏| 228/247 [02:09<00:10,  1.79it/s]Loading train:  93%|█████████▎| 229/247 [02:10<00:10,  1.73it/s]Loading train:  93%|█████████▎| 230/247 [02:11<00:10,  1.62it/s]Loading train:  94%|█████████▎| 231/247 [02:11<00:09,  1.65it/s]Loading train:  94%|█████████▍| 232/247 [02:12<00:09,  1.58it/s]Loading train:  94%|█████████▍| 233/247 [02:13<00:09,  1.53it/s]Loading train:  95%|█████████▍| 234/247 [02:13<00:08,  1.57it/s]Loading train:  95%|█████████▌| 235/247 [02:14<00:07,  1.56it/s]Loading train:  96%|█████████▌| 236/247 [02:15<00:06,  1.59it/s]Loading train:  96%|█████████▌| 237/247 [02:15<00:06,  1.58it/s]Loading train:  96%|█████████▋| 238/247 [02:16<00:05,  1.52it/s]Loading train:  97%|█████████▋| 239/247 [02:17<00:05,  1.52it/s]Loading train:  97%|█████████▋| 240/247 [02:17<00:04,  1.53it/s]Loading train:  98%|█████████▊| 241/247 [02:18<00:03,  1.58it/s]Loading train:  98%|█████████▊| 242/247 [02:18<00:03,  1.62it/s]Loading train:  98%|█████████▊| 243/247 [02:19<00:02,  1.53it/s]Loading train:  99%|█████████▉| 244/247 [02:20<00:01,  1.63it/s]Loading train:  99%|█████████▉| 245/247 [02:20<00:01,  1.64it/s]Loading train: 100%|█████████▉| 246/247 [02:21<00:00,  1.64it/s]Loading train: 100%|██████████| 247/247 [02:22<00:00,  1.61it/s]Loading train: 100%|██████████| 247/247 [02:22<00:00,  1.74it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:04, 49.42it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:04, 49.21it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:04, 49.07it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:04, 49.09it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 49.16it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 49.33it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 49.48it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 49.41it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:04, 49.27it/s]concatenating: train:  20%|██        | 50/247 [00:01<00:04, 49.02it/s]concatenating: train:  22%|██▏       | 55/247 [00:01<00:03, 48.92it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 46.83it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 47.57it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 48.12it/s]concatenating: train:  30%|███       | 75/247 [00:01<00:03, 48.38it/s]concatenating: train:  32%|███▏      | 80/247 [00:01<00:03, 48.59it/s]concatenating: train:  35%|███▍      | 86/247 [00:01<00:03, 49.19it/s]concatenating: train:  37%|███▋      | 92/247 [00:01<00:03, 49.53it/s]concatenating: train:  40%|███▉      | 98/247 [00:02<00:02, 49.81it/s]concatenating: train:  42%|████▏     | 103/247 [00:02<00:03, 47.72it/s]concatenating: train:  44%|████▎     | 108/247 [00:02<00:03, 45.81it/s]concatenating: train:  46%|████▌     | 113/247 [00:02<00:02, 44.77it/s]concatenating: train:  48%|████▊     | 118/247 [00:02<00:02, 44.56it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 45.53it/s]concatenating: train:  52%|█████▏    | 128/247 [00:02<00:02, 45.31it/s]concatenating: train:  54%|█████▍    | 133/247 [00:02<00:02, 45.98it/s]concatenating: train:  56%|█████▋    | 139/247 [00:02<00:02, 47.73it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:02, 49.62it/s]concatenating: train:  61%|██████    | 151/247 [00:03<00:01, 51.41it/s]concatenating: train:  64%|██████▎   | 157/247 [00:03<00:01, 51.30it/s]concatenating: train:  66%|██████▌   | 163/247 [00:03<00:01, 50.93it/s]concatenating: train:  68%|██████▊   | 169/247 [00:03<00:01, 50.60it/s]concatenating: train:  71%|███████   | 175/247 [00:03<00:01, 49.87it/s]concatenating: train:  73%|███████▎  | 181/247 [00:03<00:01, 48.03it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:01, 48.22it/s]concatenating: train:  77%|███████▋  | 191/247 [00:03<00:01, 48.34it/s]concatenating: train:  79%|███████▉  | 196/247 [00:04<00:01, 48.69it/s]concatenating: train:  81%|████████▏ | 201/247 [00:04<00:00, 48.14it/s]concatenating: train:  83%|████████▎ | 206/247 [00:04<00:00, 47.70it/s]concatenating: train:  85%|████████▌ | 211/247 [00:04<00:00, 47.54it/s]concatenating: train:  87%|████████▋ | 216/247 [00:04<00:00, 47.22it/s]concatenating: train:  89%|████████▉ | 221/247 [00:04<00:00, 46.42it/s]concatenating: train:  91%|█████████▏| 226/247 [00:04<00:00, 45.30it/s]concatenating: train:  94%|█████████▎| 231/247 [00:04<00:00, 42.87it/s]concatenating: train:  96%|█████████▌| 236/247 [00:04<00:00, 42.94it/s]concatenating: train:  98%|█████████▊| 241/247 [00:05<00:00, 42.84it/s]concatenating: train: 100%|█████████▉| 246/247 [00:05<00:00, 42.51it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 47.40it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:02,  1.34it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.34it/s]Loading test:  60%|██████    | 3/5 [00:02<00:01,  1.42it/s]Loading test:  80%|████████  | 4/5 [00:02<00:00,  1.44it/s]Loading test: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]Loading test: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 66.31it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<02:26,  1.68it/s]Loading trainS:   1%|          | 2/247 [00:01<02:29,  1.64it/s]Loading trainS:   1%|          | 3/247 [00:01<02:31,  1.62it/s]Loading trainS:   2%|▏         | 4/247 [00:02<02:29,  1.63it/s]Loading trainS:   2%|▏         | 5/247 [00:03<02:27,  1.64it/s]Loading trainS:   2%|▏         | 6/247 [00:03<02:25,  1.65it/s]Loading trainS:   3%|▎         | 7/247 [00:04<02:24,  1.66it/s]Loading trainS:   3%|▎         | 8/247 [00:04<02:19,  1.72it/s]Loading trainS:   4%|▎         | 9/247 [00:05<02:22,  1.67it/s]Loading trainS:   4%|▍         | 10/247 [00:06<02:25,  1.63it/s]Loading trainS:   4%|▍         | 11/247 [00:06<02:00,  1.96it/s]Loading trainS:   5%|▍         | 12/247 [00:06<01:41,  2.32it/s]Loading trainS:   5%|▌         | 13/247 [00:07<01:53,  2.06it/s]Loading trainS:   6%|▌         | 14/247 [00:07<02:01,  1.92it/s]Loading trainS:   6%|▌         | 15/247 [00:08<02:05,  1.85it/s]Loading trainS:   6%|▋         | 16/247 [00:09<02:10,  1.77it/s]Loading trainS:   7%|▋         | 17/247 [00:09<02:05,  1.83it/s]Loading trainS:   7%|▋         | 18/247 [00:10<02:07,  1.79it/s]Loading trainS:   8%|▊         | 19/247 [00:10<02:10,  1.75it/s]Loading trainS:   8%|▊         | 20/247 [00:11<02:11,  1.73it/s]Loading trainS:   9%|▊         | 21/247 [00:11<02:08,  1.76it/s]Loading trainS:   9%|▉         | 22/247 [00:12<02:06,  1.78it/s]Loading trainS:   9%|▉         | 23/247 [00:13<02:07,  1.75it/s]Loading trainS:  10%|▉         | 24/247 [00:13<02:07,  1.75it/s]Loading trainS:  10%|█         | 25/247 [00:14<02:04,  1.79it/s]Loading trainS:  11%|█         | 26/247 [00:14<02:03,  1.79it/s]Loading trainS:  11%|█         | 27/247 [00:15<02:05,  1.75it/s]Loading trainS:  11%|█▏        | 28/247 [00:15<02:02,  1.79it/s]Loading trainS:  12%|█▏        | 29/247 [00:16<01:55,  1.89it/s]Loading trainS:  12%|█▏        | 30/247 [00:16<02:01,  1.78it/s]Loading trainS:  13%|█▎        | 31/247 [00:17<01:59,  1.81it/s]Loading trainS:  13%|█▎        | 32/247 [00:18<02:01,  1.78it/s]Loading trainS:  13%|█▎        | 33/247 [00:18<02:05,  1.70it/s]Loading trainS:  14%|█▍        | 34/247 [00:19<02:01,  1.76it/s]Loading trainS:  14%|█▍        | 35/247 [00:19<02:05,  1.69it/s]Loading trainS:  15%|█▍        | 36/247 [00:20<02:07,  1.65it/s]Loading trainS:  15%|█▍        | 37/247 [00:21<02:03,  1.69it/s]Loading trainS:  15%|█▌        | 38/247 [00:21<02:04,  1.68it/s]Loading trainS:  16%|█▌        | 39/247 [00:22<02:07,  1.64it/s]Loading trainS:  16%|█▌        | 40/247 [00:22<02:03,  1.68it/s]Loading trainS:  17%|█▋        | 41/247 [00:23<02:01,  1.70it/s]Loading trainS:  17%|█▋        | 42/247 [00:24<02:04,  1.65it/s]Loading trainS:  17%|█▋        | 43/247 [00:24<02:06,  1.62it/s]Loading trainS:  18%|█▊        | 44/247 [00:25<01:58,  1.71it/s]Loading trainS:  18%|█▊        | 45/247 [00:25<01:57,  1.72it/s]Loading trainS:  19%|█▊        | 46/247 [00:26<01:57,  1.72it/s]Loading trainS:  19%|█▉        | 47/247 [00:26<01:57,  1.70it/s]Loading trainS:  19%|█▉        | 48/247 [00:27<01:56,  1.71it/s]Loading trainS:  20%|█▉        | 49/247 [00:28<01:54,  1.73it/s]Loading trainS:  20%|██        | 50/247 [00:28<01:53,  1.73it/s]Loading trainS:  21%|██        | 51/247 [00:29<01:45,  1.87it/s]Loading trainS:  21%|██        | 52/247 [00:29<01:48,  1.80it/s]Loading trainS:  21%|██▏       | 53/247 [00:30<01:47,  1.80it/s]Loading trainS:  22%|██▏       | 54/247 [00:30<01:53,  1.71it/s]Loading trainS:  22%|██▏       | 55/247 [00:31<01:54,  1.68it/s]Loading trainS:  23%|██▎       | 56/247 [00:32<01:50,  1.74it/s]Loading trainS:  23%|██▎       | 57/247 [00:32<01:46,  1.78it/s]Loading trainS:  23%|██▎       | 58/247 [00:33<01:47,  1.75it/s]Loading trainS:  24%|██▍       | 59/247 [00:33<01:48,  1.73it/s]Loading trainS:  24%|██▍       | 60/247 [00:34<01:49,  1.72it/s]Loading trainS:  25%|██▍       | 61/247 [00:34<01:44,  1.78it/s]Loading trainS:  25%|██▌       | 62/247 [00:35<01:48,  1.70it/s]Loading trainS:  26%|██▌       | 63/247 [00:36<01:45,  1.75it/s]Loading trainS:  26%|██▌       | 64/247 [00:36<01:42,  1.78it/s]Loading trainS:  26%|██▋       | 65/247 [00:37<01:46,  1.71it/s]Loading trainS:  27%|██▋       | 66/247 [00:37<01:44,  1.73it/s]Loading trainS:  27%|██▋       | 67/247 [00:38<01:44,  1.72it/s]Loading trainS:  28%|██▊       | 68/247 [00:38<01:42,  1.75it/s]Loading trainS:  28%|██▊       | 69/247 [00:39<01:39,  1.78it/s]Loading trainS:  28%|██▊       | 70/247 [00:40<01:35,  1.85it/s]Loading trainS:  29%|██▊       | 71/247 [00:40<01:35,  1.84it/s]Loading trainS:  29%|██▉       | 72/247 [00:41<01:38,  1.77it/s]Loading trainS:  30%|██▉       | 73/247 [00:41<01:36,  1.79it/s]Loading trainS:  30%|██▉       | 74/247 [00:42<01:36,  1.80it/s]Loading trainS:  30%|███       | 75/247 [00:42<01:33,  1.84it/s]Loading trainS:  31%|███       | 76/247 [00:43<01:38,  1.73it/s]Loading trainS:  31%|███       | 77/247 [00:44<01:39,  1.70it/s]Loading trainS:  32%|███▏      | 78/247 [00:44<01:46,  1.59it/s]Loading trainS:  32%|███▏      | 79/247 [00:45<01:47,  1.56it/s]Loading trainS:  32%|███▏      | 80/247 [00:45<01:35,  1.74it/s]Loading trainS:  33%|███▎      | 81/247 [00:46<01:34,  1.75it/s]Loading trainS:  33%|███▎      | 82/247 [00:46<01:29,  1.84it/s]Loading trainS:  34%|███▎      | 83/247 [00:47<01:27,  1.87it/s]Loading trainS:  34%|███▍      | 84/247 [00:47<01:25,  1.92it/s]Loading trainS:  34%|███▍      | 85/247 [00:48<01:27,  1.85it/s]Loading trainS:  35%|███▍      | 86/247 [00:49<01:32,  1.74it/s]Loading trainS:  35%|███▌      | 87/247 [00:49<01:33,  1.71it/s]Loading trainS:  36%|███▌      | 88/247 [00:50<01:32,  1.71it/s]Loading trainS:  36%|███▌      | 89/247 [00:50<01:33,  1.69it/s]Loading trainS:  36%|███▋      | 90/247 [00:51<01:32,  1.70it/s]Loading trainS:  37%|███▋      | 91/247 [00:52<01:32,  1.68it/s]Loading trainS:  37%|███▋      | 92/247 [00:52<01:32,  1.68it/s]Loading trainS:  38%|███▊      | 93/247 [00:53<01:28,  1.74it/s]Loading trainS:  38%|███▊      | 94/247 [00:53<01:28,  1.72it/s]Loading trainS:  38%|███▊      | 95/247 [00:54<01:26,  1.75it/s]Loading trainS:  39%|███▉      | 96/247 [00:54<01:26,  1.74it/s]Loading trainS:  39%|███▉      | 97/247 [00:55<01:27,  1.72it/s]Loading trainS:  40%|███▉      | 98/247 [00:56<01:27,  1.70it/s]Loading trainS:  40%|████      | 99/247 [00:56<01:29,  1.65it/s]Loading trainS:  40%|████      | 100/247 [00:57<01:32,  1.58it/s]Loading trainS:  41%|████      | 101/247 [00:58<01:36,  1.51it/s]Loading trainS:  41%|████▏     | 102/247 [00:58<01:34,  1.53it/s]Loading trainS:  42%|████▏     | 103/247 [00:59<01:35,  1.50it/s]Loading trainS:  42%|████▏     | 104/247 [01:00<01:34,  1.51it/s]Loading trainS:  43%|████▎     | 105/247 [01:00<01:35,  1.48it/s]Loading trainS:  43%|████▎     | 106/247 [01:01<01:35,  1.48it/s]Loading trainS:  43%|████▎     | 107/247 [01:02<01:32,  1.51it/s]Loading trainS:  44%|████▎     | 108/247 [01:02<01:32,  1.51it/s]Loading trainS:  44%|████▍     | 109/247 [01:03<01:32,  1.49it/s]Loading trainS:  45%|████▍     | 110/247 [01:04<01:33,  1.47it/s]Loading trainS:  45%|████▍     | 111/247 [01:04<01:32,  1.48it/s]Loading trainS:  45%|████▌     | 112/247 [01:05<01:31,  1.48it/s]Loading trainS:  46%|████▌     | 113/247 [01:06<01:32,  1.46it/s]Loading trainS:  46%|████▌     | 114/247 [01:07<01:29,  1.48it/s]Loading trainS:  47%|████▋     | 115/247 [01:07<01:30,  1.46it/s]Loading trainS:  47%|████▋     | 116/247 [01:08<01:30,  1.45it/s]Loading trainS:  47%|████▋     | 117/247 [01:09<01:35,  1.37it/s]Loading trainS:  48%|████▊     | 118/247 [01:09<01:29,  1.43it/s]Loading trainS:  48%|████▊     | 119/247 [01:10<01:26,  1.48it/s]Loading trainS:  49%|████▊     | 120/247 [01:11<01:23,  1.53it/s]Loading trainS:  49%|████▉     | 121/247 [01:11<01:22,  1.53it/s]Loading trainS:  49%|████▉     | 122/247 [01:12<01:17,  1.61it/s]Loading trainS:  50%|████▉     | 123/247 [01:12<01:14,  1.67it/s]Loading trainS:  50%|█████     | 124/247 [01:13<01:14,  1.66it/s]Loading trainS:  51%|█████     | 125/247 [01:14<01:13,  1.67it/s]Loading trainS:  51%|█████     | 126/247 [01:14<01:10,  1.71it/s]Loading trainS:  51%|█████▏    | 127/247 [01:15<01:11,  1.67it/s]Loading trainS:  52%|█████▏    | 128/247 [01:15<01:10,  1.68it/s]Loading trainS:  52%|█████▏    | 129/247 [01:16<01:12,  1.63it/s]Loading trainS:  53%|█████▎    | 130/247 [01:17<01:09,  1.69it/s]Loading trainS:  53%|█████▎    | 131/247 [01:17<01:09,  1.67it/s]Loading trainS:  53%|█████▎    | 132/247 [01:18<01:08,  1.67it/s]Loading trainS:  54%|█████▍    | 133/247 [01:18<01:08,  1.66it/s]Loading trainS:  54%|█████▍    | 134/247 [01:19<01:07,  1.68it/s]Loading trainS:  55%|█████▍    | 135/247 [01:20<01:07,  1.65it/s]Loading trainS:  55%|█████▌    | 136/247 [01:20<01:03,  1.76it/s]Loading trainS:  55%|█████▌    | 137/247 [01:21<00:59,  1.84it/s]Loading trainS:  56%|█████▌    | 138/247 [01:21<00:59,  1.84it/s]Loading trainS:  56%|█████▋    | 139/247 [01:22<01:00,  1.79it/s]Loading trainS:  57%|█████▋    | 140/247 [01:22<00:56,  1.89it/s]Loading trainS:  57%|█████▋    | 141/247 [01:23<00:53,  1.99it/s]Loading trainS:  57%|█████▋    | 142/247 [01:23<00:51,  2.04it/s]Loading trainS:  58%|█████▊    | 143/247 [01:24<00:51,  2.03it/s]Loading trainS:  58%|█████▊    | 144/247 [01:24<00:50,  2.03it/s]Loading trainS:  59%|█████▊    | 145/247 [01:24<00:49,  2.05it/s]Loading trainS:  59%|█████▉    | 146/247 [01:25<00:48,  2.06it/s]Loading trainS:  60%|█████▉    | 147/247 [01:25<00:48,  2.08it/s]Loading trainS:  60%|█████▉    | 148/247 [01:26<00:48,  2.02it/s]Loading trainS:  60%|██████    | 149/247 [01:26<00:46,  2.12it/s]Loading trainS:  61%|██████    | 150/247 [01:27<00:46,  2.09it/s]Loading trainS:  61%|██████    | 151/247 [01:27<00:45,  2.09it/s]Loading trainS:  62%|██████▏   | 152/247 [01:28<00:47,  2.01it/s]Loading trainS:  62%|██████▏   | 153/247 [01:28<00:45,  2.08it/s]Loading trainS:  62%|██████▏   | 154/247 [01:29<00:48,  1.92it/s]Loading trainS:  63%|██████▎   | 155/247 [01:30<00:50,  1.83it/s]Loading trainS:  63%|██████▎   | 156/247 [01:30<00:52,  1.73it/s]Loading trainS:  64%|██████▎   | 157/247 [01:31<00:48,  1.84it/s]Loading trainS:  64%|██████▍   | 158/247 [01:31<00:49,  1.81it/s]Loading trainS:  64%|██████▍   | 159/247 [01:32<00:50,  1.74it/s]Loading trainS:  65%|██████▍   | 160/247 [01:32<00:49,  1.75it/s]Loading trainS:  65%|██████▌   | 161/247 [01:33<00:49,  1.74it/s]Loading trainS:  66%|██████▌   | 162/247 [01:34<00:48,  1.76it/s]Loading trainS:  66%|██████▌   | 163/247 [01:34<00:46,  1.79it/s]Loading trainS:  66%|██████▋   | 164/247 [01:35<00:48,  1.73it/s]Loading trainS:  67%|██████▋   | 165/247 [01:35<00:45,  1.79it/s]Loading trainS:  67%|██████▋   | 166/247 [01:36<00:46,  1.74it/s]Loading trainS:  68%|██████▊   | 167/247 [01:36<00:43,  1.82it/s]Loading trainS:  68%|██████▊   | 168/247 [01:37<00:42,  1.85it/s]Loading trainS:  68%|██████▊   | 169/247 [01:37<00:42,  1.85it/s]Loading trainS:  69%|██████▉   | 170/247 [01:38<00:43,  1.77it/s]Loading trainS:  69%|██████▉   | 171/247 [01:39<00:43,  1.76it/s]Loading trainS:  70%|██████▉   | 172/247 [01:39<00:43,  1.72it/s]Loading trainS:  70%|███████   | 173/247 [01:40<00:45,  1.62it/s]Loading trainS:  70%|███████   | 174/247 [01:41<00:44,  1.64it/s]Loading trainS:  71%|███████   | 175/247 [01:41<00:44,  1.60it/s]Loading trainS:  71%|███████▏  | 176/247 [01:42<00:43,  1.63it/s]Loading trainS:  72%|███████▏  | 177/247 [01:42<00:41,  1.68it/s]Loading trainS:  72%|███████▏  | 178/247 [01:43<00:40,  1.68it/s]Loading trainS:  72%|███████▏  | 179/247 [01:44<00:42,  1.61it/s]Loading trainS:  73%|███████▎  | 180/247 [01:44<00:41,  1.61it/s]Loading trainS:  73%|███████▎  | 181/247 [01:45<00:38,  1.72it/s]Loading trainS:  74%|███████▎  | 182/247 [01:45<00:37,  1.75it/s]Loading trainS:  74%|███████▍  | 183/247 [01:46<00:37,  1.72it/s]Loading trainS:  74%|███████▍  | 184/247 [01:46<00:35,  1.80it/s]Loading trainS:  75%|███████▍  | 185/247 [01:47<00:35,  1.76it/s]Loading trainS:  75%|███████▌  | 186/247 [01:48<00:36,  1.69it/s]Loading trainS:  76%|███████▌  | 187/247 [01:48<00:33,  1.79it/s]Loading trainS:  76%|███████▌  | 188/247 [01:49<00:32,  1.79it/s]Loading trainS:  77%|███████▋  | 189/247 [01:49<00:31,  1.82it/s]Loading trainS:  77%|███████▋  | 190/247 [01:50<00:31,  1.78it/s]Loading trainS:  77%|███████▋  | 191/247 [01:50<00:32,  1.71it/s]Loading trainS:  78%|███████▊  | 192/247 [01:51<00:31,  1.74it/s]Loading trainS:  78%|███████▊  | 193/247 [01:52<00:31,  1.73it/s]Loading trainS:  79%|███████▊  | 194/247 [01:52<00:31,  1.69it/s]Loading trainS:  79%|███████▉  | 195/247 [01:53<00:30,  1.71it/s]Loading trainS:  79%|███████▉  | 196/247 [01:53<00:29,  1.70it/s]Loading trainS:  80%|███████▉  | 197/247 [01:54<00:29,  1.71it/s]Loading trainS:  80%|████████  | 198/247 [01:55<00:29,  1.66it/s]Loading trainS:  81%|████████  | 199/247 [01:55<00:28,  1.70it/s]Loading trainS:  81%|████████  | 200/247 [01:56<00:27,  1.71it/s]Loading trainS:  81%|████████▏ | 201/247 [01:56<00:27,  1.70it/s]Loading trainS:  82%|████████▏ | 202/247 [01:57<00:26,  1.71it/s]Loading trainS:  82%|████████▏ | 203/247 [01:57<00:26,  1.69it/s]Loading trainS:  83%|████████▎ | 204/247 [01:58<00:24,  1.75it/s]Loading trainS:  83%|████████▎ | 205/247 [01:59<00:24,  1.72it/s]Loading trainS:  83%|████████▎ | 206/247 [01:59<00:24,  1.70it/s]Loading trainS:  84%|████████▍ | 207/247 [02:00<00:23,  1.73it/s]Loading trainS:  84%|████████▍ | 208/247 [02:00<00:22,  1.70it/s]Loading trainS:  85%|████████▍ | 209/247 [02:01<00:22,  1.68it/s]Loading trainS:  85%|████████▌ | 210/247 [02:02<00:22,  1.67it/s]Loading trainS:  85%|████████▌ | 211/247 [02:02<00:21,  1.71it/s]Loading trainS:  86%|████████▌ | 212/247 [02:03<00:20,  1.67it/s]Loading trainS:  86%|████████▌ | 213/247 [02:03<00:20,  1.70it/s]Loading trainS:  87%|████████▋ | 214/247 [02:04<00:20,  1.64it/s]Loading trainS:  87%|████████▋ | 215/247 [02:05<00:20,  1.59it/s]Loading trainS:  87%|████████▋ | 216/247 [02:05<00:19,  1.62it/s]Loading trainS:  88%|████████▊ | 217/247 [02:06<00:18,  1.63it/s]Loading trainS:  88%|████████▊ | 218/247 [02:06<00:17,  1.61it/s]Loading trainS:  89%|████████▊ | 219/247 [02:07<00:17,  1.59it/s]Loading trainS:  89%|████████▉ | 220/247 [02:08<00:17,  1.54it/s]Loading trainS:  89%|████████▉ | 221/247 [02:08<00:16,  1.56it/s]Loading trainS:  90%|████████▉ | 222/247 [02:09<00:15,  1.61it/s]Loading trainS:  90%|█████████ | 223/247 [02:10<00:14,  1.60it/s]Loading trainS:  91%|█████████ | 224/247 [02:10<00:14,  1.62it/s]Loading trainS:  91%|█████████ | 225/247 [02:11<00:13,  1.59it/s]Loading trainS:  91%|█████████▏| 226/247 [02:12<00:13,  1.58it/s]Loading trainS:  92%|█████████▏| 227/247 [02:12<00:12,  1.56it/s]Loading trainS:  92%|█████████▏| 228/247 [02:13<00:12,  1.55it/s]Loading trainS:  93%|█████████▎| 229/247 [02:13<00:11,  1.56it/s]Loading trainS:  93%|█████████▎| 230/247 [02:14<00:11,  1.53it/s]Loading trainS:  94%|█████████▎| 231/247 [02:15<00:10,  1.51it/s]Loading trainS:  94%|█████████▍| 232/247 [02:15<00:09,  1.52it/s]Loading trainS:  94%|█████████▍| 233/247 [02:16<00:09,  1.54it/s]Loading trainS:  95%|█████████▍| 234/247 [02:17<00:08,  1.50it/s]Loading trainS:  95%|█████████▌| 235/247 [02:17<00:07,  1.51it/s]Loading trainS:  96%|█████████▌| 236/247 [02:18<00:07,  1.52it/s]Loading trainS:  96%|█████████▌| 237/247 [02:19<00:06,  1.48it/s]Loading trainS:  96%|█████████▋| 238/247 [02:20<00:06,  1.50it/s]Loading trainS:  97%|█████████▋| 239/247 [02:20<00:05,  1.51it/s]Loading trainS:  97%|█████████▋| 240/247 [02:21<00:04,  1.47it/s]Loading trainS:  98%|█████████▊| 241/247 [02:22<00:04,  1.46it/s]Loading trainS:  98%|█████████▊| 242/247 [02:22<00:03,  1.45it/s]Loading trainS:  98%|█████████▊| 243/247 [02:23<00:02,  1.48it/s]Loading trainS:  99%|█████████▉| 244/247 [02:24<00:02,  1.49it/s]Loading trainS:  99%|█████████▉| 245/247 [02:24<00:01,  1.47it/s]Loading trainS: 100%|█████████▉| 246/247 [02:25<00:00,  1.49it/s]Loading trainS: 100%|██████████| 247/247 [02:26<00:00,  1.49it/s]Loading trainS: 100%|██████████| 247/247 [02:26<00:00,  1.69it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:03,  1.31it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.35it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:01,  1.48it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.51it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]----------+++ 
CrossVal ['b']
CrossVal ['b']
(0/5) test vimp2_ANON911_CSFn2
(1/5) test vimp2_D_CSFn2
(2/5) test vimp2_F_CSFn2
(3/5) test vimp2_G_CSFn2
(4/5) test vimp2_J_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97300229 0.02699771]
Train on 15751 samples, validate on 333 samples
Epoch 1/300
 - 78s - loss: 0.0951 - acc: 0.9900 - mDice: 0.8150 - val_loss: 0.2151 - val_acc: 0.9895 - val_mDice: 0.3917

Epoch 00001: val_mDice improved from -inf to 0.39174, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 73s - loss: 0.0639 - acc: 0.9932 - mDice: 0.8757 - val_loss: 0.2337 - val_acc: 0.9924 - val_mDice: 0.4480

Epoch 00002: val_mDice improved from 0.39174 to 0.44799, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 73s - loss: 0.0571 - acc: 0.9939 - mDice: 0.8890 - val_loss: 0.1039 - val_acc: 0.9899 - val_mDice: 0.4118

Epoch 00003: val_mDice did not improve from 0.44799
Epoch 4/300
 - 73s - loss: 0.0519 - acc: 0.9944 - mDice: 0.8991 - val_loss: 0.1354 - val_acc: 0.9913 - val_mDice: 0.4753

Epoch 00004: val_mDice improved from 0.44799 to 0.47526, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 73s - loss: 0.0484 - acc: 0.9947 - mDice: 0.9060 - val_loss: 0.1159 - val_acc: 0.9906 - val_mDice: 0.4543

Epoch 00005: val_mDice did not improve from 0.47526
Epoch 6/300
 - 73s - loss: 0.0474 - acc: 0.9947 - mDice: 0.9079 - val_loss: 0.1173 - val_acc: 0.9919 - val_mDice: 0.4517

Epoch 00006: val_mDice did not improve from 0.47526
Epoch 7/300
 - 73s - loss: 0.0442 - acc: 0.9951 - mDice: 0.9142 - val_loss: 0.0413 - val_acc: 0.9879 - val_mDice: 0.3660

Epoch 00007: val_mDice did not improve from 0.47526
Epoch 8/300
 - 73s - loss: 0.0422 - acc: 0.9951 - mDice: 0.9181 - val_loss: -2.5043e-02 - val_acc: 0.9911 - val_mDice: 0.4374

Epoch 00008: val_mDice did not improve from 0.47526
Epoch 9/300
 - 73s - loss: 0.0406 - acc: 0.9953 - mDice: 0.9210 - val_loss: 0.1265 - val_acc: 0.9923 - val_mDice: 0.4687

Epoch 00009: val_mDice did not improve from 0.47526
Epoch 10/300
 - 73s - loss: 0.0399 - acc: 0.9953 - mDice: 0.9226 - val_loss: 0.0502 - val_acc: 0.9921 - val_mDice: 0.4656

Epoch 00010: val_mDice did not improve from 0.47526
Epoch 11/300
 - 73s - loss: 0.0381 - acc: 0.9955 - mDice: 0.9261 - val_loss: 0.1374 - val_acc: 0.9918 - val_mDice: 0.4703

Epoch 00011: val_mDice did not improve from 0.47526
Epoch 12/300
 - 73s - loss: 0.0400 - acc: 0.9955 - mDice: 0.9222 - val_loss: 0.1454 - val_acc: 0.9919 - val_mDice: 0.4588

Epoch 00012: val_mDice did not improve from 0.47526
Epoch 13/300
 - 73s - loss: 0.0374 - acc: 0.9957 - mDice: 0.9274 - val_loss: 0.0890 - val_acc: 0.9924 - val_mDice: 0.4565

Epoch 00013: val_mDice did not improve from 0.47526
Epoch 14/300
 - 73s - loss: 0.0362 - acc: 0.9957 - mDice: 0.9296 - val_loss: 0.0789 - val_acc: 0.9927 - val_mDice: 0.4559

Epoch 00014: val_mDice did not improve from 0.47526
Epoch 15/300
 - 73s - loss: 0.0352 - acc: 0.9958 - mDice: 0.9316 - val_loss: -4.9538e-03 - val_acc: 0.9925 - val_mDice: 0.4561

Epoch 00015: val_mDice did not improve from 0.47526
Epoch 16/300
 - 73s - loss: 0.0376 - acc: 0.9956 - mDice: 0.9270 - val_loss: 0.0850 - val_acc: 0.9920 - val_mDice: 0.4561

Epoch 00016: val_mDice did not improve from 0.47526
Epoch 17/300
 - 73s - loss: 0.0340 - acc: 0.9959 - mDice: 0.9341 - val_loss: 0.0222 - val_acc: 0.9919 - val_mDice: 0.4616

Epoch 00017: val_mDice did not improve from 0.47526
Epoch 18/300
 - 72s - loss: 0.0342 - acc: 0.9959 - mDice: 0.9336 - val_loss: 0.0430 - val_acc: 0.9921 - val_mDice: 0.4731

Epoch 00018: val_mDice did not improve from 0.47526
Epoch 19/300
 - 72s - loss: 0.0343 - acc: 0.9959 - mDice: 0.9335 - val_loss: 0.1175 - val_acc: 0.9902 - val_mDice: 0.4524

Epoch 00019: val_mDice did not improve from 0.47526

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 20/300
 - 72s - loss: 0.0333 - acc: 0.9961 - mDice: 0.9352 - val_loss: 0.0488 - val_acc: 0.9926 - val_mDice: 0.4712

Epoch 00020: val_mDice did not improve from 0.47526
Epoch 21/300
 - 73s - loss: 0.0320 - acc: 0.9961 - mDice: 0.9379 - val_loss: 0.0484 - val_acc: 0.9923 - val_mDice: 0.4693

Epoch 00021: val_mDice did not improve from 0.47526
Epoch 22/300
 - 73s - loss: 0.0308 - acc: 0.9962 - mDice: 0.9403 - val_loss: 0.0096 - val_acc: 0.9912 - val_mDice: 0.4475

Epoch 00022: val_mDice did not improve from 0.47526
Epoch 23/300
 - 73s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9389 - val_loss: 0.1124 - val_acc: 0.9913 - val_mDice: 0.4621

Epoch 00023: val_mDice did not improve from 0.47526
Epoch 24/300
 - 73s - loss: 0.0296 - acc: 0.9962 - mDice: 0.9427 - val_loss: 0.1089 - val_acc: 0.9916 - val_mDice: 0.4689

Epoch 00024: val_mDice did not improve from 0.47526
Epoch 25/300
 - 74s - loss: 0.0293 - acc: 0.9962 - mDice: 0.9431 - val_loss: 0.0787 - val_acc: 0.9919 - val_mDice: 0.4704

Epoch 00025: val_mDice did not improve from 0.47526
Epoch 26/300
 - 74s - loss: 0.0312 - acc: 0.9962 - mDice: 0.9394 - val_loss: 0.0812 - val_acc: 0.9919 - val_mDice: 0.4638

Epoch 00026: val_mDice did not improve from 0.47526
Epoch 27/300
 - 73s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9413 - val_loss: -9.7249e-03 - val_acc: 0.9896 - val_mDice: 0.4064

Epoch 00027: val_mDice did not improve from 0.47526
Epoch 28/300
 - 73s - loss: 0.0299 - acc: 0.9963 - mDice: 0.9421 - val_loss: 0.0123 - val_acc: 0.9928 - val_mDice: 0.4819

Epoch 00028: val_mDice improved from 0.47526 to 0.48189, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 29/300
 - 74s - loss: 0.0297 - acc: 0.9963 - mDice: 0.9424 - val_loss: 0.0809 - val_acc: 0.9921 - val_mDice: 0.4669

Epoch 00029: val_mDice did not improve from 0.48189
Epoch 30/300
 - 73s - loss: 0.0294 - acc: 0.9963 - mDice: 0.9430 - val_loss: 0.1025 - val_acc: 0.9922 - val_mDice: 0.4812

Epoch 00030: val_mDice did not improve from 0.48189
Epoch 31/300
 - 74s - loss: 0.0302 - acc: 0.9963 - mDice: 0.9414 - val_loss: -6.3995e-03 - val_acc: 0.9917 - val_mDice: 0.4599

Epoch 00031: val_mDice did not improve from 0.48189
Epoch 32/300
 - 73s - loss: 0.0290 - acc: 0.9963 - mDice: 0.9438 - val_loss: 0.0518 - val_acc: 0.9920 - val_mDice: 0.4640

Epoch 00032: val_mDice did not improve from 0.48189
Epoch 33/300
 - 73s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9437 - val_loss: 0.0754 - val_acc: 0.9925 - val_mDice: 0.4748

Epoch 00033: val_mDice did not improve from 0.48189
Epoch 34/300
 - 73s - loss: 0.0281 - acc: 0.9964 - mDice: 0.9456 - val_loss: -3.1868e-02 - val_acc: 0.9913 - val_mDice: 0.4588

Epoch 00034: val_mDice did not improve from 0.48189
Epoch 35/300
 - 73s - loss: 0.0279 - acc: 0.9964 - mDice: 0.9459 - val_loss: 0.0823 - val_acc: 0.9919 - val_mDice: 0.4619

Epoch 00035: val_mDice did not improve from 0.48189
Epoch 36/300
 - 73s - loss: 0.0283 - acc: 0.9964 - mDice: 0.9451 - val_loss: 0.0518 - val_acc: 0.9925 - val_mDice: 0.4627

Epoch 00036: val_mDice did not improve from 0.48189
Epoch 37/300
 - 72s - loss: 0.0277 - acc: 0.9964 - mDice: 0.9464 - val_loss: 0.1072 - val_acc: 0.9908 - val_mDice: 0.4681

Epoch 00037: val_mDice did not improve from 0.48189
Epoch 38/300
 - 73s - loss: 0.0275 - acc: 0.9964 - mDice: 0.9468 - val_loss: 0.0576 - val_acc: 0.9918 - val_mDice: 0.4609

Epoch 00038: val_mDice did not improve from 0.48189
Epoch 39/300
 - 73s - loss: 0.0281 - acc: 0.9964 - mDice: 0.9456 - val_loss: 0.0522 - val_acc: 0.9917 - val_mDice: 0.4647

Epoch 00039: val_mDice did not improve from 0.48189
Epoch 40/300
 - 73s - loss: 0.0272 - acc: 0.9964 - mDice: 0.9473 - val_loss: 0.0805 - val_acc: 0.9923 - val_mDice: 0.4570

Epoch 00040: val_mDice did not improve from 0.48189
Epoch 41/300
 - 74s - loss: 0.0282 - acc: 0.9964 - mDice: 0.9452 - val_loss: -6.6518e-03 - val_acc: 0.9929 - val_mDice: 0.4773

Epoch 00041: val_mDice did not improve from 0.48189
Epoch 42/300
 - 74s - loss: 0.0285 - acc: 0.9965 - mDice: 0.9447 - val_loss: 0.0178 - val_acc: 0.9927 - val_mDice: 0.4719

Epoch 00042: val_mDice did not improve from 0.48189
Epoch 43/300
 - 73s - loss: 0.0274 - acc: 0.9965 - mDice: 0.9469 - val_loss: 0.1096 - val_acc: 0.9907 - val_mDice: 0.4732

Epoch 00043: val_mDice did not improve from 0.48189

Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 44/300
 - 74s - loss: 0.0264 - acc: 0.9965 - mDice: 0.9489 - val_loss: 0.0603 - val_acc: 0.9926 - val_mDice: 0.4841

Epoch 00044: val_mDice improved from 0.48189 to 0.48413, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 45/300
 - 74s - loss: 0.0260 - acc: 0.9965 - mDice: 0.9497 - val_loss: -8.4342e-03 - val_acc: 0.9926 - val_mDice: 0.4627

Epoch 00045: val_mDice did not improve from 0.48413
Epoch 46/300
 - 74s - loss: 0.0257 - acc: 0.9966 - mDice: 0.9503 - val_loss: 0.0460 - val_acc: 0.9925 - val_mDice: 0.4681

Epoch 00046: val_mDice did not improve from 0.48413
Epoch 47/300
 - 73s - loss: 0.0256 - acc: 0.9966 - mDice: 0.9504 - val_loss: -1.4352e-03 - val_acc: 0.9918 - val_mDice: 0.4491

Epoch 00047: val_mDice did not improve from 0.48413
Epoch 48/300
 - 73s - loss: 0.0259 - acc: 0.9966 - mDice: 0.9497 - val_loss: 0.0307 - val_acc: 0.9924 - val_mDice: 0.4670

Epoch 00048: val_mDice did not improve from 0.48413
Epoch 49/300
 - 73s - loss: 0.0252 - acc: 0.9966 - mDice: 0.9513 - val_loss: 0.1162 - val_acc: 0.9921 - val_mDice: 0.4754

Epoch 00049: val_mDice did not improve from 0.48413
Epoch 50/300
 - 74s - loss: 0.0258 - acc: 0.9966 - mDice: 0.9500 - val_loss: 0.1057 - val_acc: 0.9923 - val_mDice: 0.4748

Epoch 00050: val_mDice did not improve from 0.48413
Epoch 51/300
 - 74s - loss: 0.0251 - acc: 0.9966 - mDice: 0.9514 - val_loss: 0.0248 - val_acc: 0.9924 - val_mDice: 0.4617

Epoch 00051: val_mDice did not improve from 0.48413
Epoch 52/300
 - 74s - loss: 0.0252 - acc: 0.9966 - mDice: 0.9512 - val_loss: 0.0980 - val_acc: 0.9919 - val_mDice: 0.4666

Epoch 00052: val_mDice did not improve from 0.48413
Epoch 53/300
 - 74s - loss: 0.0250 - acc: 0.9966 - mDice: 0.9516 - val_loss: 0.0505 - val_acc: 0.9923 - val_mDice: 0.4678

Epoch 00053: val_mDice did not improve from 0.48413
Epoch 54/300
 - 74s - loss: 0.0247 - acc: 0.9966 - mDice: 0.9523 - val_loss: 0.0800 - val_acc: 0.9924 - val_mDice: 0.4661

Epoch 00054: val_mDice did not improve from 0.48413
Epoch 55/300
 - 74s - loss: 0.0254 - acc: 0.9966 - mDice: 0.9507 - val_loss: 0.0502 - val_acc: 0.9923 - val_mDice: 0.4658

Epoch 00055: val_mDice did not improve from 0.48413
Epoch 56/300
 - 74s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9496 - val_loss: 0.0852 - val_acc: 0.9916 - val_mDice: 0.4692

Epoch 00056: val_mDice did not improve from 0.48413
Epoch 57/300
 - 74s - loss: 0.0247 - acc: 0.9966 - mDice: 0.9521 - val_loss: 0.0514 - val_acc: 0.9922 - val_mDice: 0.4698

Epoch 00057: val_mDice did not improve from 0.48413
Epoch 58/300
 - 74s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9501 - val_loss: 0.0789 - val_acc: 0.9922 - val_mDice: 0.4703

Epoch 00058: val_mDice did not improve from 0.48413
Epoch 59/300
 - 73s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9510 - val_loss: 0.0227 - val_acc: 0.9904 - val_mDice: 0.4260

Epoch 00059: val_mDice did not improve from 0.48413

Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 60/300
 - 73s - loss: 0.0244 - acc: 0.9967 - mDice: 0.9527 - val_loss: 0.0406 - val_acc: 0.9926 - val_mDice: 0.4654

Epoch 00060: val_mDice did not improve from 0.48413
Epoch 61/300
 - 73s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9536 - val_loss: 0.0107 - val_acc: 0.9923 - val_mDice: 0.4533

Epoch 00061: val_mDice did not improve from 0.48413
Epoch 62/300
 - 72s - loss: 0.0241 - acc: 0.9967 - mDice: 0.9534 - val_loss: 0.0573 - val_acc: 0.9925 - val_mDice: 0.4654

Epoch 00062: val_mDice did not improve from 0.48413
Epoch 63/300
 - 73s - loss: 0.0243 - acc: 0.9967 - mDice: 0.9529 - val_loss: 0.0510 - val_acc: 0.9927 - val_mDice: 0.4679

Epoch 00063: val_mDice did not improve from 0.48413
Epoch 64/300
 - 73s - loss: 0.0241 - acc: 0.9967 - mDice: 0.9534 - val_loss: 0.0892 - val_acc: 0.9924 - val_mDice: 0.4683

Epoch 00064: val_mDice did not improve from 0.48413
Epoch 65/300
 - 73s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9536 - val_loss: 0.0548 - val_acc: 0.9925 - val_mDice: 0.4627

Epoch 00065: val_mDice did not improve from 0.48413
Epoch 66/300
 - 72s - loss: 0.0239 - acc: 0.9967 - mDice: 0.9537 - val_loss: 0.0741 - val_acc: 0.9926 - val_mDice: 0.4691

Epoch 00066: val_mDice did not improve from 0.48413
Epoch 67/300
 - 72s - loss: 0.0243 - acc: 0.9967 - mDice: 0.9530 - val_loss: 0.0790 - val_acc: 0.9925 - val_mDice: 0.4661

Epoch 00067: val_mDice did not improve from 0.48413
Epoch 68/300
 - 73s - loss: 0.0238 - acc: 0.9967 - mDice: 0.9539 - val_loss: 0.0511 - val_acc: 0.9928 - val_mDice: 0.4649

Epoch 00068: val_mDice did not improve from 0.48413
Epoch 69/300
 - 73s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9535 - val_loss: 0.0509 - val_acc: 0.9927 - val_mDice: 0.4659

Epoch 00069: val_mDice did not improve from 0.48413
Epoch 70/300
 - 73s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9535 - val_loss: 0.0533 - val_acc: 0.9928 - val_mDice: 0.4624

Epoch 00070: val_mDice did not improve from 0.48413
Epoch 71/300
 - 73s - loss: 0.0233 - acc: 0.9967 - mDice: 0.9550 - val_loss: 0.0567 - val_acc: 0.9925 - val_mDice: 0.4610

Epoch 00071: val_mDice did not improve from 0.48413
Epoch 72/300
 - 73s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9535 - val_loss: 0.0016 - val_acc: 0.9925 - val_mDice: 0.4612

Epoch 00072: val_mDice did not improve from 0.48413
Epoch 73/300
 - 72s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9536 - val_loss: 0.0513 - val_acc: 0.9925 - val_mDice: 0.4653

Epoch 00073: val_mDice did not improve from 0.48413
Epoch 74/300
 - 72s - loss: 0.0235 - acc: 0.9967 - mDice: 0.9545 - val_loss: -6.9711e-03 - val_acc: 0.9928 - val_mDice: 0.4627

Epoch 00074: val_mDice did not improve from 0.48413

Epoch 00074: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 75/300
 - 73s - loss: 0.0238 - acc: 0.9967 - mDice: 0.9539 - val_loss: 0.0241 - val_acc: 0.9928 - val_mDice: 0.4672

Epoch 00075: val_mDice did not improve from 0.48413
Epoch 76/300
 - 72s - loss: 0.0236 - acc: 0.9968 - mDice: 0.9544 - val_loss: 0.0508 - val_acc: 0.9926 - val_mDice: 0.4643

Epoch 00076: val_mDice did not improve from 0.48413
Epoch 77/300
 - 72s - loss: 0.0236 - acc: 0.9967 - mDice: 0.9544 - val_loss: 0.0791 - val_acc: 0.9927 - val_mDice: 0.4679

Epoch 00077: val_mDice did not improve from 0.48413
Epoch 78/300
 - 72s - loss: 0.0233 - acc: 0.9967 - mDice: 0.9550 - val_loss: 0.0197 - val_acc: 0.9928 - val_mDice: 0.4663

Epoch 00078: val_mDice did not improve from 0.48413
Epoch 79/300
 - 72s - loss: 0.0232 - acc: 0.9967 - mDice: 0.9550 - val_loss: 0.0802 - val_acc: 0.9925 - val_mDice: 0.4658

Epoch 00079: val_mDice did not improve from 0.48413
Epoch 80/300
 - 72s - loss: 0.0230 - acc: 0.9968 - mDice: 0.9555 - val_loss: 0.0200 - val_acc: 0.9928 - val_mDice: 0.4660

Epoch 00080: val_mDice did not improve from 0.48413
Epoch 81/300
 - 71s - loss: 0.0239 - acc: 0.9967 - mDice: 0.9536 - val_loss: 0.0214 - val_acc: 0.9927 - val_mDice: 0.4629

Epoch 00081: val_mDice did not improve from 0.48413
Epoch 82/300
 - 72s - loss: 0.0235 - acc: 0.9968 - mDice: 0.9545 - val_loss: 0.0419 - val_acc: 0.9926 - val_mDice: 0.4662

Epoch 00082: val_mDice did not improve from 0.48413
Epoch 83/300
 - 72s - loss: 0.0231 - acc: 0.9968 - mDice: 0.9553 - val_loss: 0.0508 - val_acc: 0.9926 - val_mDice: 0.4643

Epoch 00083: val_mDice did not improve from 0.48413
Epoch 84/300
 - 72s - loss: 0.0238 - acc: 0.9967 - mDice: 0.9538 - val_loss: 0.0498 - val_acc: 0.9927 - val_mDice: 0.4662

Epoch 00084: val_mDice did not improve from 0.48413
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
{'val_loss': [0.21508032732360713, 0.23371332794338376, 0.10388985956395352, 0.13535518854766995, 0.11590379355727015, 0.11726066165858202, 0.041331008210912484, -0.025043318221518944, 0.12647291847893424, 0.05023386000512956, 0.13743654851082926, 0.14544080815336727, 0.08896650400784639, 0.07891951219455616, -0.0049538425318113675, 0.08500302535993559, 0.022176174743397458, 0.04297684280721991, 0.11754239683931654, 0.04877058544137457, 0.04840198418757579, 0.009582858185868364, 0.11241460387950188, 0.1089029116584016, 0.07874796022702982, 0.08117442369998039, -0.009724938833677733, 0.012250752912627326, 0.08093500186552156, 0.1025440391298529, -0.006399536633992696, 0.05176622964240409, 0.07542512769455666, -0.03186766140990787, 0.08225306788006344, 0.05179115149888906, 0.10722684403797528, 0.057622140771275886, 0.05222228035196528, 0.0804969041465639, -0.00665181978149815, 0.01777380364793199, 0.10955717913560323, 0.060328715422131994, -0.008434170046010174, 0.0459787096973654, -0.0014351901707348523, 0.03069120614199309, 0.11619049793965108, 0.10569228039489494, 0.024782670868767634, 0.09795629333805393, 0.05049634418330035, 0.07999775753364907, 0.05018966105786172, 0.08519618222126374, 0.051409518217539286, 0.07888584653357486, 0.022716862706092744, 0.040617251091891224, 0.010684344637859333, 0.05726518524480654, 0.05097062129516143, 0.08920906023220257, 0.05480639542545284, 0.074093185163833, 0.0790170653535797, 0.05106040884603609, 0.05089016621177261, 0.05328507972014201, 0.05672539649782954, 0.0015918422300178368, 0.05132924883931249, -0.006971059260783611, 0.02413858473300934, 0.05084127608362261, 0.07912107680115972, 0.019745586602179496, 0.08021049487877178, 0.020019108155468205, 0.021448570731523876, 0.0418527710276681, 0.0507879437985005, 0.049842720633154515], 'val_acc': [0.9894600068484699, 0.9923922940417453, 0.9899317427082462, 0.9912767188327091, 0.9906148960640481, 0.9918853216343098, 0.9879383736544544, 0.991109884895004, 0.9922662132137172, 0.9920960249485554, 0.991820125250487, 0.9918893973032633, 0.9924047626890578, 0.9927003193903972, 0.9924543813184217, 0.992013564696899, 0.9919152886301905, 0.9921168794145098, 0.9902455065701459, 0.9925754324451939, 0.9922590194879709, 0.9912273400538677, 0.9912688091352537, 0.9915542939045766, 0.991942370260084, 0.9919097666983848, 0.9896198904908097, 0.9927520895147467, 0.9921461196991058, 0.9922240263706928, 0.9917196869492173, 0.9920008615688519, 0.9924553371406533, 0.9912608976478692, 0.9918531995635849, 0.9925238968015792, 0.9908066619265903, 0.9917743370697663, 0.9917021850207904, 0.9923119960246501, 0.9928578009476533, 0.9927137384901533, 0.9906637879821273, 0.9926041948186742, 0.9925617681251274, 0.9925473788837055, 0.9917791376600752, 0.9923795944935566, 0.9920617478029864, 0.9923112764730826, 0.99238438434429, 0.9919342225020354, 0.992279635893332, 0.9924251320841793, 0.9923237433304658, 0.9916060693987139, 0.9922000538479459, 0.9921530735743297, 0.9904382318347782, 0.9925751943846006, 0.9922568626231976, 0.9925090350188293, 0.9926801773162933, 0.9923795927036274, 0.9925114281542666, 0.9926300807758136, 0.9925447458977456, 0.9927719845786109, 0.9927027143157638, 0.9927652741337681, 0.9925279653108156, 0.9925473842534933, 0.9925416314208114, 0.9927540101088561, 0.9927686338310127, 0.992591011989582, 0.9926804207466744, 0.9927928462042823, 0.9925437900755141, 0.9927758221869712, 0.9926770664192177, 0.9926454222596085, 0.9926358318185663, 0.9927278843011942], 'val_mDice': [0.3917432480209225, 0.44799050669861934, 0.4117506727248145, 0.4752559613089662, 0.45425892127929507, 0.4516575358494803, 0.3659690180989178, 0.43744438627102883, 0.4686932928032345, 0.46558436375480516, 0.47027817068694233, 0.45882874512457633, 0.4565326171415346, 0.45587845104674524, 0.45608562895575083, 0.4560750901878059, 0.4616245088187066, 0.47313601874911393, 0.4523512716586883, 0.4711815061511936, 0.46926111161887823, 0.447471516581627, 0.4621413009459371, 0.468945215951215, 0.47035878104669554, 0.46384237180869503, 0.4063775541590047, 0.4818914615893149, 0.4669205082843343, 0.48117437990041106, 0.45988818692104955, 0.46396652678469635, 0.474768071113764, 0.458830002102408, 0.4618567259641023, 0.4627480603458899, 0.4680779549347757, 0.4608572832680679, 0.46474130653505297, 0.45704114977997523, 0.47732483651544955, 0.4718568831592709, 0.47321259774066304, 0.484133654528552, 0.46274516331563303, 0.46814129405372495, 0.44906590223401877, 0.46695196570397857, 0.47541395858959395, 0.4748186128991502, 0.4616856269885201, 0.4665779758681048, 0.4678456299566292, 0.46613909371264345, 0.46582176050803326, 0.4692397900932544, 0.46976697136152973, 0.4702813574322709, 0.42598061632734163, 0.4653819080151327, 0.4533256046675347, 0.4653920391966049, 0.46791438225869303, 0.46834339250673557, 0.46266080761278, 0.4690608805095827, 0.4661250944520618, 0.46487549627507413, 0.4659341559843258, 0.46243793579998677, 0.46097581786615355, 0.46124720521112755, 0.4652864756705883, 0.4627448626354829, 0.46721467172150855, 0.4642971776699157, 0.4679190261742553, 0.46631747070146173, 0.46576425645748687, 0.46601655255599606, 0.46292703011417274, 0.4661879629725852, 0.46429169808959153, 0.46619205212639514], 'loss': [0.09510065400424847, 0.06390362798705963, 0.0570628417148627, 0.0518597948305963, 0.04836670982274591, 0.04740919054791962, 0.044163885791902203, 0.042169159563388015, 0.040647692580570015, 0.03987725283310804, 0.03805150902692828, 0.040038131480632934, 0.037386944699488736, 0.0362464776247859, 0.03522403429337255, 0.03759499764765613, 0.03397658629728782, 0.034203230575957866, 0.034252344820281604, 0.0333272229754034, 0.03196437445343672, 0.030772846716940194, 0.03149316549531982, 0.02957283918758883, 0.029337955498633314, 0.031218379964889645, 0.03026111195972326, 0.029857527621435245, 0.029688315324257777, 0.02939308977423755, 0.030169549115907048, 0.028965372443918152, 0.029004996902041568, 0.028079129479724744, 0.027923428769543332, 0.028287639078333465, 0.027663369150125718, 0.02746858083136944, 0.028062419197792614, 0.0272188466381674, 0.02823469102757294, 0.028479249342026298, 0.027384800406821033, 0.026393223209771933, 0.02598091270664625, 0.025654104872511557, 0.02558968123515654, 0.025944506685534444, 0.025177665138523146, 0.02578368177433467, 0.02512097460876517, 0.02516431777933334, 0.02501064200744456, 0.024656229087734412, 0.02541943662174618, 0.025986833587637946, 0.0247412477731402, 0.025747866764816964, 0.025305609379781328, 0.024406915845950287, 0.023982504540364345, 0.024081954228886347, 0.0243459018167863, 0.02405546440312873, 0.02398053618220933, 0.023921520831009582, 0.02427518368145752, 0.023837084804563004, 0.02401714293050521, 0.02401388810385705, 0.023258805287261968, 0.024007909292720946, 0.023951592229523814, 0.023522955449972672, 0.023771648153139518, 0.02356070362664837, 0.023555596770426485, 0.02326593988774716, 0.023241856398487703, 0.023013494919689185, 0.023931589399275043, 0.023495662859277674, 0.023104216818067506, 0.023844833727201108], 'acc': [0.9899897593845224, 0.9932411805568184, 0.9938708306887696, 0.9944056700421972, 0.9946778804550064, 0.9946915217410435, 0.9950694458029489, 0.9951247396291109, 0.9953072263009132, 0.9953477830139389, 0.9955120832569962, 0.995488833407812, 0.9956525898261279, 0.9956635818595879, 0.995773393883341, 0.9956151755732072, 0.9958850045740305, 0.9959141284304946, 0.9959034510025425, 0.9960940366404055, 0.9961282931186383, 0.9961629871504396, 0.9962375483568279, 0.9962388355159342, 0.9962351872923866, 0.9962421857427471, 0.9962652034210361, 0.9962884841113006, 0.9963022681177476, 0.9963499861825845, 0.9963374583503646, 0.9963211756828482, 0.9963649095682771, 0.9964035712993756, 0.9963831226717184, 0.9964055773091918, 0.99638559112745, 0.9964460288257525, 0.9964127993744128, 0.9964331659610124, 0.9964352193222932, 0.9964612410958703, 0.9964515722847676, 0.9965014032625514, 0.9965457052293258, 0.996558034653119, 0.9965917392046775, 0.9965892406987596, 0.9965762825596788, 0.9965905893962275, 0.9966130952185415, 0.9966124907106636, 0.9966289671131425, 0.9966436128004507, 0.9966468204241633, 0.9966323774933066, 0.9966461666046147, 0.9966535764257913, 0.9966504278882906, 0.996671246658105, 0.9966866171826984, 0.9966976285949525, 0.9966980702051639, 0.9966930839593248, 0.9966860288257077, 0.9967052459595703, 0.996714342155878, 0.9967114546323048, 0.9967123407779002, 0.9967121588382317, 0.9967185235176379, 0.9967066596276525, 0.9967176362027306, 0.9967127205659364, 0.9967461223110654, 0.9967633062760404, 0.9967497754578333, 0.9967435116420041, 0.9967417681938459, 0.996757544685444, 0.9967460971386892, 0.9967630991337224, 0.9967836534649249, 0.9967424836766341], 'mDice': [0.81501736407025, 0.8756672283553538, 0.8890050464974881, 0.8991245257896845, 0.9059561243072993, 0.9078606424100981, 0.9141506895126994, 0.918104526020445, 0.9210473238146196, 0.9225613288929043, 0.9261299261334782, 0.9221634460467323, 0.9273711073762628, 0.9296428688283451, 0.9316320076642052, 0.9269747990940073, 0.9340584519651003, 0.9335939447566916, 0.933502110218095, 0.9352472776248466, 0.9379469869280761, 0.9402994432643696, 0.9388519023858997, 0.9426766088686854, 0.943133453514211, 0.9393827045283979, 0.9412647840992003, 0.9420693554686604, 0.9423993860424212, 0.94297448623885, 0.941424423051663, 0.943838897095613, 0.9437371659571009, 0.9455687246332622, 0.9458878155466367, 0.9451400128143355, 0.9463980509836586, 0.9467655529363459, 0.9455864766341725, 0.9472628211900928, 0.9452416391314896, 0.9447253963605358, 0.9469228349453411, 0.948868144119318, 0.9496753562458674, 0.9503208322454184, 0.9504317711303442, 0.9497245659745539, 0.9512594399145842, 0.9500443623880456, 0.9513617207092615, 0.9512140998975958, 0.9515798510418916, 0.9522734861677847, 0.9507393209027999, 0.9496046478415616, 0.9521008396964551, 0.9500881894286735, 0.9509628540260077, 0.9527467434107028, 0.9535885123924697, 0.9533839104258971, 0.9528582780355574, 0.9534396474175693, 0.9535875043281108, 0.9536985319520956, 0.9529909550193817, 0.9538658736100402, 0.9535066543757049, 0.9535101042286676, 0.9550122942336287, 0.9535238324373565, 0.9536355759603895, 0.9544879023018099, 0.9539308950080773, 0.9543951353295085, 0.9543998192608617, 0.9549867679607935, 0.9550197560721659, 0.9554865061233978, 0.9536474721294442, 0.9545083429410597, 0.9553016506409344, 0.9538268398901038], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.22it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:01,  1.54it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.83it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.09it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.46it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.59it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:38,  6.45it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:37,  6.55it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:36,  6.61it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:37,  6.55it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:37,  6.51it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:37,  6.49it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:37,  6.47it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:37,  6.42it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:37,  6.43it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:36,  6.45it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:36,  6.48it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:36,  6.49it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:36,  6.50it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:35,  6.48it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:35,  6.48it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:35,  6.43it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:35,  6.39it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:35,  6.37it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:35,  6.36it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:35,  6.36it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:35,  6.36it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:35,  6.34it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:35,  6.39it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:34,  6.44it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:34,  6.51it/s]predicting train subjects:  11%|█         | 26/247 [00:04<00:33,  6.51it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:33,  6.57it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:33,  6.50it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:33,  6.53it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:33,  6.46it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:33,  6.47it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:33,  6.50it/s]predicting train subjects:  13%|█▎        | 33/247 [00:05<00:33,  6.48it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:32,  6.56it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:32,  6.58it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:31,  6.60it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:31,  6.57it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:31,  6.63it/s]predicting train subjects:  16%|█▌        | 39/247 [00:06<00:31,  6.66it/s]predicting train subjects:  16%|█▌        | 40/247 [00:06<00:31,  6.66it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:30,  6.70it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:30,  6.71it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:30,  6.71it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:30,  6.69it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:30,  6.67it/s]predicting train subjects:  19%|█▊        | 46/247 [00:07<00:30,  6.66it/s]predicting train subjects:  19%|█▉        | 47/247 [00:07<00:29,  6.71it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:29,  6.74it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:29,  6.72it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:29,  6.70it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:30,  6.50it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:30,  6.39it/s]predicting train subjects:  21%|██▏       | 53/247 [00:08<00:29,  6.48it/s]predicting train subjects:  22%|██▏       | 54/247 [00:08<00:29,  6.55it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:29,  6.50it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:29,  6.58it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:28,  6.62it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:28,  6.67it/s]predicting train subjects:  24%|██▍       | 59/247 [00:09<00:29,  6.44it/s]predicting train subjects:  24%|██▍       | 60/247 [00:09<00:29,  6.42it/s]predicting train subjects:  25%|██▍       | 61/247 [00:09<00:29,  6.40it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:29,  6.32it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:29,  6.33it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:29,  6.19it/s]predicting train subjects:  26%|██▋       | 65/247 [00:10<00:29,  6.21it/s]predicting train subjects:  27%|██▋       | 66/247 [00:10<00:29,  6.20it/s]predicting train subjects:  27%|██▋       | 67/247 [00:10<00:29,  6.20it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:28,  6.23it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:28,  6.26it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:28,  6.26it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:28,  6.28it/s]predicting train subjects:  29%|██▉       | 72/247 [00:11<00:27,  6.29it/s]predicting train subjects:  30%|██▉       | 73/247 [00:11<00:27,  6.30it/s]predicting train subjects:  30%|██▉       | 74/247 [00:11<00:27,  6.28it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:27,  6.30it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:27,  6.29it/s]predicting train subjects:  31%|███       | 77/247 [00:12<00:35,  4.80it/s]predicting train subjects:  32%|███▏      | 78/247 [00:12<00:37,  4.45it/s]predicting train subjects:  32%|███▏      | 79/247 [00:12<00:34,  4.83it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:37,  4.40it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:33,  4.90it/s]predicting train subjects:  33%|███▎      | 82/247 [00:13<00:31,  5.28it/s]predicting train subjects:  34%|███▎      | 83/247 [00:13<00:29,  5.57it/s]predicting train subjects:  34%|███▍      | 84/247 [00:13<00:28,  5.81it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:27,  6.00it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:26,  6.15it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:25,  6.24it/s]predicting train subjects:  36%|███▌      | 88/247 [00:14<00:25,  6.32it/s]predicting train subjects:  36%|███▌      | 89/247 [00:14<00:24,  6.33it/s]predicting train subjects:  36%|███▋      | 90/247 [00:14<00:24,  6.39it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:24,  6.39it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:24,  6.35it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:24,  6.35it/s]predicting train subjects:  38%|███▊      | 94/247 [00:14<00:23,  6.38it/s]predicting train subjects:  38%|███▊      | 95/247 [00:15<00:23,  6.39it/s]predicting train subjects:  39%|███▉      | 96/247 [00:15<00:23,  6.44it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:23,  6.45it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:23,  6.41it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:23,  6.43it/s]predicting train subjects:  40%|████      | 100/247 [00:15<00:24,  6.09it/s]predicting train subjects:  41%|████      | 101/247 [00:16<00:25,  5.84it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:25,  5.75it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:25,  5.56it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:25,  5.53it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:25,  5.52it/s]predicting train subjects:  43%|████▎     | 106/247 [00:17<00:25,  5.53it/s]predicting train subjects:  43%|████▎     | 107/247 [00:17<00:25,  5.52it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:25,  5.52it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:25,  5.47it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:24,  5.49it/s]predicting train subjects:  45%|████▍     | 111/247 [00:17<00:24,  5.51it/s]predicting train subjects:  45%|████▌     | 112/247 [00:18<00:24,  5.53it/s]predicting train subjects:  46%|████▌     | 113/247 [00:18<00:24,  5.56it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:24,  5.45it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:24,  5.47it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:23,  5.49it/s]predicting train subjects:  47%|████▋     | 117/247 [00:19<00:23,  5.45it/s]predicting train subjects:  48%|████▊     | 118/247 [00:19<00:23,  5.54it/s]predicting train subjects:  48%|████▊     | 119/247 [00:19<00:22,  5.66it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:22,  5.76it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:21,  5.86it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:21,  5.91it/s]predicting train subjects:  50%|████▉     | 123/247 [00:20<00:20,  5.95it/s]predicting train subjects:  50%|█████     | 124/247 [00:20<00:20,  5.99it/s]predicting train subjects:  51%|█████     | 125/247 [00:20<00:20,  5.94it/s]predicting train subjects:  51%|█████     | 126/247 [00:20<00:20,  5.96it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:20,  5.98it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:20,  5.95it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:21<00:19,  5.95it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:21<00:19,  5.95it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:21<00:19,  5.99it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:21<00:19,  5.97it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:21<00:18,  6.00it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:18,  6.04it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:22<00:18,  6.03it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:22<00:17,  6.34it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:22<00:16,  6.56it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:22<00:16,  6.78it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:22<00:15,  6.95it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:22<00:15,  7.08it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:14,  7.13it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:14,  7.21it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:23<00:14,  7.28it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:23<00:14,  7.33it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:23<00:13,  7.35it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:23<00:13,  7.38it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:23<00:13,  7.32it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:13,  7.33it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:13,  7.32it/s]predicting train subjects:  61%|██████    | 150/247 [00:24<00:13,  7.36it/s]predicting train subjects:  61%|██████    | 151/247 [00:24<00:13,  7.34it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:24<00:12,  7.38it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:24<00:12,  7.36it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:24<00:13,  7.12it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:24<00:14,  6.52it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:24<00:13,  6.56it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:25<00:13,  6.60it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:25<00:13,  6.60it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:25<00:13,  6.63it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:25<00:13,  6.62it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:25<00:13,  6.61it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:25<00:12,  6.59it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:26<00:12,  6.62it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:26<00:12,  6.61it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:26<00:12,  6.58it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:26<00:12,  6.60it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:26<00:12,  6.61it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:26<00:11,  6.63it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:26<00:11,  6.67it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:27<00:11,  6.65it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:27<00:11,  6.58it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:27<00:11,  6.58it/s]predicting train subjects:  70%|███████   | 173/247 [00:27<00:14,  5.01it/s]predicting train subjects:  70%|███████   | 174/247 [00:27<00:13,  5.41it/s]predicting train subjects:  71%|███████   | 175/247 [00:28<00:14,  5.04it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:28<00:13,  5.29it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:28<00:12,  5.52it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:28<00:11,  5.77it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:28<00:11,  5.98it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:28<00:10,  6.13it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:29<00:10,  6.24it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:29<00:10,  6.36it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:29<00:09,  6.41it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:29<00:09,  6.45it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:29<00:09,  6.50it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:29<00:09,  6.53it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:29<00:09,  6.50it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:30<00:09,  6.50it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:30<00:08,  6.53it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:30<00:08,  6.48it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:30<00:08,  6.49it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:30<00:08,  6.49it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:30<00:08,  6.48it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:31<00:07,  6.63it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:31<00:07,  6.57it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:31<00:07,  6.52it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:31<00:07,  6.62it/s]predicting train subjects:  80%|████████  | 198/247 [00:31<00:07,  6.64it/s]predicting train subjects:  81%|████████  | 199/247 [00:31<00:07,  6.69it/s]predicting train subjects:  81%|████████  | 200/247 [00:31<00:06,  6.73it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:32<00:06,  6.75it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:32<00:06,  6.80it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:32<00:06,  6.88it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:32<00:06,  6.91it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:32<00:06,  6.93it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:32<00:05,  6.95it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:32<00:05,  6.91it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:33<00:05,  6.92it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:33<00:05,  6.94it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:33<00:05,  6.86it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:33<00:05,  6.91it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:33<00:05,  6.80it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:33<00:05,  6.73it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:33<00:04,  6.67it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:34<00:04,  6.67it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:34<00:04,  6.68it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:34<00:04,  6.66it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:34<00:04,  6.63it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:34<00:04,  6.66it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:34<00:04,  6.56it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:35<00:03,  6.54it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:35<00:03,  6.59it/s]predicting train subjects:  90%|█████████ | 223/247 [00:35<00:03,  6.55it/s]predicting train subjects:  91%|█████████ | 224/247 [00:35<00:03,  6.58it/s]predicting train subjects:  91%|█████████ | 225/247 [00:35<00:03,  6.57it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:35<00:03,  6.59it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:35<00:03,  6.50it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:36<00:02,  6.47it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:36<00:02,  6.43it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:36<00:02,  6.23it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:36<00:02,  6.08it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:36<00:02,  5.95it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:36<00:02,  5.87it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:37<00:02,  5.87it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:37<00:02,  5.83it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:37<00:01,  5.67it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:37<00:01,  5.75it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:37<00:01,  5.65it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:38<00:01,  5.51it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:38<00:01,  5.51it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:38<00:01,  5.60it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:38<00:00,  5.62it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:38<00:00,  5.70it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:38<00:00,  5.74it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:39<00:00,  5.64it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:39<00:00,  5.70it/s]predicting train subjects: 100%|██████████| 247/247 [00:39<00:00,  5.74it/s]predicting train subjects: 100%|██████████| 247/247 [00:39<00:00,  6.27it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  5.44it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  5.52it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  5.87it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  6.11it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  5.98it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.04it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:38,  6.46it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:37,  6.55it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:36,  6.62it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:37,  6.50it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:37,  6.47it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:37,  6.48it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:01<00:36,  6.50it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:01<00:37,  6.45it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:36,  6.48it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:36,  6.48it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:36,  6.49it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:36,  6.48it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:02<00:36,  6.46it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:02<00:36,  6.44it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:02<00:36,  6.34it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:02<00:36,  6.29it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:36,  6.30it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:36,  6.33it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:35,  6.38it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:03<00:35,  6.42it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:03<00:35,  6.44it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:03<00:35,  6.39it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:03<00:34,  6.49it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:03<00:34,  6.55it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:33,  6.57it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:04<00:33,  6.58it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:04<00:33,  6.63it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:04<00:33,  6.62it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:04<00:32,  6.67it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:04<00:32,  6.69it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:04<00:33,  6.38it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:04<00:33,  6.49it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:05<00:32,  6.54it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:05<00:32,  6.55it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:05<00:32,  6.61it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:05<00:32,  6.56it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:05<00:31,  6.61it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:05<00:31,  6.65it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:05<00:31,  6.59it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:06<00:31,  6.59it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:06<00:31,  6.61it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:06<00:30,  6.61it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:06<00:30,  6.65it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:06<00:30,  6.68it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:06<00:30,  6.70it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:07<00:29,  6.72it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:07<00:29,  6.73it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:07<00:29,  6.65it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:07<00:30,  6.58it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:07<00:29,  6.59it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:07<00:29,  6.64it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:07<00:29,  6.64it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:08<00:29,  6.65it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:08<00:29,  6.52it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:08<00:29,  6.56it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:08<00:28,  6.62it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:08<00:28,  6.59it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:08<00:28,  6.62it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:09<00:28,  6.54it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:09<00:28,  6.50it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:09<00:28,  6.44it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:09<00:28,  6.42it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:09<00:28,  6.41it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:09<00:28,  6.37it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:09<00:28,  6.34it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:10<00:28,  6.34it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:10<00:28,  6.34it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:10<00:28,  6.33it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:10<00:28,  6.35it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:10<00:27,  6.35it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:10<00:27,  6.36it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:11<00:27,  6.29it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:11<00:27,  6.31it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:11<00:27,  6.22it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:11<00:27,  6.15it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:11<00:28,  6.06it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:11<00:27,  6.18it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:12<00:29,  5.74it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:12<00:29,  5.71it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:12<00:27,  6.14it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:12<00:26,  6.22it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:12<00:26,  6.19it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:12<00:26,  6.12it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:13<00:26,  6.23it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:13<00:25,  6.31it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:13<00:25,  6.38it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:13<00:24,  6.42it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:13<00:25,  6.33it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:13<00:24,  6.39it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:13<00:24,  6.44it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:14<00:24,  6.49it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:14<00:23,  6.51it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:14<00:23,  6.53it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:14<00:23,  6.47it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:14<00:23,  6.50it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:14<00:23,  6.52it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:15<00:22,  6.52it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:15<00:22,  6.50it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:15<00:22,  6.53it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:15<00:23,  6.18it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:15<00:24,  5.95it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:15<00:24,  5.83it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:16<00:25,  5.75it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:16<00:25,  5.63it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:16<00:25,  5.51it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:16<00:25,  5.46it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:16<00:25,  5.42it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:17<00:25,  5.43it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:17<00:25,  5.45it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:17<00:25,  5.43it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:17<00:24,  5.47it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:17<00:24,  5.44it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:17<00:25,  5.30it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:18<00:25,  5.27it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:18<00:24,  5.33it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:18<00:24,  5.32it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:18<00:24,  5.35it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:18<00:23,  5.54it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:19<00:22,  5.68it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:19<00:21,  5.79it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:19<00:22,  5.73it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:19<00:21,  5.80it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:19<00:21,  5.88it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:19<00:21,  5.83it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:20<00:20,  5.89it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:20<00:20,  5.93it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:20<00:20,  5.96it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:20<00:20,  5.93it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:20<00:19,  5.95it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:20<00:19,  5.98it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:21<00:19,  6.01it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:21<00:18,  6.05it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:21<00:18,  6.09it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:21<00:18,  6.11it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:21<00:18,  6.11it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:21<00:17,  6.41it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:21<00:16,  6.69it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:22<00:15,  6.93it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:22<00:15,  7.06it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:22<00:14,  7.17it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:22<00:14,  7.27it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:22<00:14,  7.33it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:22<00:14,  7.38it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:22<00:13,  7.43it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:23<00:13,  7.45it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:23<00:13,  7.38it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:23<00:13,  7.35it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:23<00:13,  7.33it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:23<00:13,  7.37it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:23<00:13,  7.37it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:23<00:13,  7.38it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:23<00:12,  7.38it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:24<00:12,  7.39it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:24<00:13,  7.15it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:24<00:13,  7.02it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:24<00:13,  6.92it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:24<00:13,  6.73it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:24<00:13,  6.73it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:25<00:13,  6.73it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:25<00:12,  6.73it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:25<00:12,  6.71it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:25<00:12,  6.70it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:25<00:12,  6.70it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:25<00:12,  6.65it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:25<00:12,  6.52it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:26<00:12,  6.51it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:26<00:12,  6.55it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:26<00:12,  6.51it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:26<00:12,  6.35it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:26<00:12,  6.41it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:26<00:11,  6.34it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:27<00:11,  6.38it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:27<00:11,  6.50it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:27<00:11,  6.52it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:27<00:11,  6.14it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:27<00:11,  6.24it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:27<00:11,  6.34it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:27<00:10,  6.43it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:28<00:10,  6.49it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:28<00:10,  6.52it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:28<00:10,  6.55it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:28<00:09,  6.56it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:28<00:09,  6.57it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:28<00:09,  6.57it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:29<00:09,  6.48it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:29<00:09,  6.51it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:29<00:09,  6.56it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:29<00:08,  6.59it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:29<00:08,  6.59it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:29<00:08,  6.61it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:29<00:08,  6.59it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:30<00:08,  6.57it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:30<00:08,  6.53it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:30<00:08,  6.61it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:30<00:07,  6.52it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:30<00:07,  6.61it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:30<00:07,  6.71it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:30<00:07,  6.79it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:31<00:07,  6.82it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:31<00:06,  6.85it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:31<00:06,  6.85it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:31<00:06,  6.89it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:31<00:06,  6.78it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:31<00:06,  6.85it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:32<00:06,  6.90it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:32<00:05,  6.92it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:32<00:05,  6.93it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:32<00:05,  6.94it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:32<00:05,  6.90it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:32<00:05,  6.93it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:32<00:05,  6.96it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:33<00:05,  6.88it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:33<00:04,  6.82it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:33<00:04,  6.80it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:33<00:04,  6.79it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:33<00:04,  6.77it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:33<00:04,  6.70it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:33<00:04,  6.52it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:34<00:04,  6.54it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:34<00:04,  6.57it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:34<00:03,  6.59it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:34<00:03,  6.51it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:34<00:03,  6.59it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:34<00:03,  6.61it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:34<00:03,  6.49it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:35<00:03,  6.57it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:35<00:03,  6.57it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:35<00:02,  6.46it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:35<00:02,  6.52it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:35<00:02,  6.29it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:35<00:02,  6.15it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:36<00:02,  6.05it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:36<00:02,  5.98it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:36<00:02,  5.95it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:36<00:02,  5.88it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:36<00:01,  5.80it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:36<00:01,  5.79it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:37<00:01,  5.79it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:37<00:01,  5.75it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:37<00:01,  5.73it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:37<00:01,  5.78it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:37<00:00,  5.81it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:38<00:00,  5.83it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:38<00:00,  5.83it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:38<00:00,  5.83it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:38<00:00,  5.80it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:38<00:00,  5.78it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:38<00:00,  6.38it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 69.81it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 80.17it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 81.34it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 82.72it/s]saving BB  train1-THALAMUS:  14%|█▍        | 35/247 [00:00<00:02, 81.03it/s]saving BB  train1-THALAMUS:  18%|█▊        | 44/247 [00:00<00:02, 83.51it/s]saving BB  train1-THALAMUS:  22%|██▏       | 54/247 [00:00<00:02, 85.50it/s]saving BB  train1-THALAMUS:  26%|██▌       | 63/247 [00:00<00:02, 85.00it/s]saving BB  train1-THALAMUS:  29%|██▊       | 71/247 [00:00<00:02, 79.35it/s]saving BB  train1-THALAMUS:  32%|███▏      | 79/247 [00:00<00:02, 79.05it/s]saving BB  train1-THALAMUS:  36%|███▌      | 88/247 [00:01<00:01, 80.50it/s]saving BB  train1-THALAMUS:  39%|███▉      | 97/247 [00:01<00:01, 80.71it/s]saving BB  train1-THALAMUS:  43%|████▎     | 105/247 [00:01<00:01, 78.64it/s]saving BB  train1-THALAMUS:  46%|████▌     | 113/247 [00:01<00:01, 76.29it/s]saving BB  train1-THALAMUS:  49%|████▉     | 121/247 [00:01<00:01, 75.63it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 129/247 [00:01<00:01, 76.01it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 137/247 [00:01<00:01, 76.96it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 147/247 [00:01<00:01, 80.27it/s]saving BB  train1-THALAMUS:  64%|██████▎   | 157/247 [00:01<00:01, 82.91it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 167/247 [00:02<00:00, 85.27it/s]saving BB  train1-THALAMUS:  71%|███████▏  | 176/247 [00:02<00:00, 85.37it/s]saving BB  train1-THALAMUS:  75%|███████▍  | 185/247 [00:02<00:00, 84.52it/s]saving BB  train1-THALAMUS:  79%|███████▊  | 194/247 [00:02<00:00, 84.69it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 203/247 [00:02<00:00, 85.25it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 212/247 [00:02<00:00, 85.88it/s]saving BB  train1-THALAMUS:  90%|████████▉ | 222/247 [00:02<00:00, 87.18it/s]saving BB  train1-THALAMUS:  94%|█████████▎| 231/247 [00:02<00:00, 85.09it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 240/247 [00:02<00:00, 81.29it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 81.96it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 65.90it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 83.96it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 84.23it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 85.52it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 37/247 [00:00<00:02, 87.28it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▉        | 47/247 [00:00<00:02, 88.99it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 57/247 [00:00<00:02, 90.63it/s]saving BB  train1-THALAMUS Sagittal:  27%|██▋       | 66/247 [00:00<00:02, 88.25it/s]saving BB  train1-THALAMUS Sagittal:  30%|███       | 75/247 [00:00<00:01, 86.45it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▍      | 84/247 [00:00<00:01, 85.77it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 93/247 [00:01<00:01, 84.61it/s]saving BB  train1-THALAMUS Sagittal:  41%|████▏     | 102/247 [00:01<00:01, 82.50it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 111/247 [00:01<00:01, 80.21it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 119/247 [00:01<00:01, 79.49it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████▏    | 127/247 [00:01<00:01, 78.90it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 135/247 [00:01<00:01, 78.31it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 144/247 [00:01<00:01, 81.17it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 154/247 [00:01<00:01, 82.63it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▋   | 164/247 [00:01<00:00, 85.13it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 174/247 [00:02<00:00, 87.22it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 183/247 [00:02<00:00, 84.16it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 192/247 [00:02<00:00, 83.18it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████▏ | 201/247 [00:02<00:00, 83.14it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▌ | 210/247 [00:02<00:00, 83.65it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▊ | 219/247 [00:02<00:00, 85.19it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 228/247 [00:02<00:00, 85.51it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 237/247 [00:02<00:00, 83.19it/s]saving BB  train1-THALAMUS Sagittal: 100%|█████████▉| 246/247 [00:02<00:00, 80.78it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:02<00:00, 83.90it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:31,  1.16it/s]Loading train:   1%|          | 2/247 [00:01<03:22,  1.21it/s]Loading train:   1%|          | 3/247 [00:02<03:13,  1.26it/s]Loading train:   2%|▏         | 4/247 [00:03<03:20,  1.21it/s]Loading train:   2%|▏         | 5/247 [00:03<03:00,  1.34it/s]Loading train:   2%|▏         | 6/247 [00:04<02:44,  1.46it/s]Loading train:   3%|▎         | 7/247 [00:04<02:32,  1.58it/s]Loading train:   3%|▎         | 8/247 [00:05<02:23,  1.66it/s]Loading train:   4%|▎         | 9/247 [00:05<02:18,  1.72it/s]Loading train:   4%|▍         | 10/247 [00:06<02:15,  1.74it/s]Loading train:   4%|▍         | 11/247 [00:06<02:11,  1.80it/s]Loading train:   5%|▍         | 12/247 [00:07<02:09,  1.82it/s]Loading train:   5%|▌         | 13/247 [00:08<02:08,  1.82it/s]Loading train:   6%|▌         | 14/247 [00:08<02:05,  1.86it/s]Loading train:   6%|▌         | 15/247 [00:09<02:06,  1.83it/s]Loading train:   6%|▋         | 16/247 [00:09<02:07,  1.81it/s]Loading train:   7%|▋         | 17/247 [00:10<02:05,  1.84it/s]Loading train:   7%|▋         | 18/247 [00:10<02:02,  1.86it/s]Loading train:   8%|▊         | 19/247 [00:11<02:01,  1.88it/s]Loading train:   8%|▊         | 20/247 [00:11<02:00,  1.88it/s]Loading train:   9%|▊         | 21/247 [00:12<02:00,  1.88it/s]Loading train:   9%|▉         | 22/247 [00:12<01:58,  1.89it/s]Loading train:   9%|▉         | 23/247 [00:13<01:57,  1.91it/s]Loading train:  10%|▉         | 24/247 [00:13<01:55,  1.93it/s]Loading train:  10%|█         | 25/247 [00:14<01:54,  1.94it/s]Loading train:  11%|█         | 26/247 [00:14<01:53,  1.94it/s]Loading train:  11%|█         | 27/247 [00:15<01:52,  1.96it/s]Loading train:  11%|█▏        | 28/247 [00:15<01:53,  1.93it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:52,  1.94it/s]Loading train:  12%|█▏        | 30/247 [00:16<01:51,  1.94it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:52,  1.93it/s]Loading train:  13%|█▎        | 32/247 [00:18<01:52,  1.92it/s]Loading train:  13%|█▎        | 33/247 [00:18<01:52,  1.91it/s]Loading train:  14%|█▍        | 34/247 [00:19<01:52,  1.90it/s]Loading train:  14%|█▍        | 35/247 [00:19<01:50,  1.92it/s]Loading train:  15%|█▍        | 36/247 [00:20<01:48,  1.95it/s]Loading train:  15%|█▍        | 37/247 [00:20<01:45,  1.99it/s]Loading train:  15%|█▌        | 38/247 [00:21<01:43,  2.01it/s]Loading train:  16%|█▌        | 39/247 [00:21<01:43,  2.02it/s]Loading train:  16%|█▌        | 40/247 [00:22<01:43,  1.99it/s]Loading train:  17%|█▋        | 41/247 [00:22<01:42,  2.01it/s]Loading train:  17%|█▋        | 42/247 [00:23<01:43,  1.97it/s]Loading train:  17%|█▋        | 43/247 [00:23<01:44,  1.95it/s]Loading train:  18%|█▊        | 44/247 [00:24<01:45,  1.92it/s]Loading train:  18%|█▊        | 45/247 [00:24<01:43,  1.94it/s]Loading train:  19%|█▊        | 46/247 [00:25<01:41,  1.97it/s]Loading train:  19%|█▉        | 47/247 [00:25<01:41,  1.98it/s]Loading train:  19%|█▉        | 48/247 [00:26<01:39,  1.99it/s]Loading train:  20%|█▉        | 49/247 [00:26<01:39,  2.00it/s]Loading train:  20%|██        | 50/247 [00:27<01:36,  2.03it/s]Loading train:  21%|██        | 51/247 [00:27<01:38,  2.00it/s]Loading train:  21%|██        | 52/247 [00:28<01:36,  2.01it/s]Loading train:  21%|██▏       | 53/247 [00:28<01:35,  2.02it/s]Loading train:  22%|██▏       | 54/247 [00:29<01:35,  2.02it/s]Loading train:  22%|██▏       | 55/247 [00:29<01:34,  2.04it/s]Loading train:  23%|██▎       | 56/247 [00:30<01:33,  2.05it/s]Loading train:  23%|██▎       | 57/247 [00:30<01:33,  2.03it/s]Loading train:  23%|██▎       | 58/247 [00:31<01:34,  2.01it/s]Loading train:  24%|██▍       | 59/247 [00:31<01:37,  1.93it/s]Loading train:  24%|██▍       | 60/247 [00:32<01:41,  1.84it/s]Loading train:  25%|██▍       | 61/247 [00:32<01:48,  1.72it/s]Loading train:  25%|██▌       | 62/247 [00:33<01:48,  1.71it/s]Loading train:  26%|██▌       | 63/247 [00:34<01:45,  1.74it/s]Loading train:  26%|██▌       | 64/247 [00:34<01:45,  1.74it/s]Loading train:  26%|██▋       | 65/247 [00:35<01:45,  1.72it/s]Loading train:  27%|██▋       | 66/247 [00:35<01:44,  1.73it/s]Loading train:  27%|██▋       | 67/247 [00:36<01:44,  1.72it/s]Loading train:  28%|██▊       | 68/247 [00:36<01:44,  1.72it/s]Loading train:  28%|██▊       | 69/247 [00:37<01:43,  1.72it/s]Loading train:  28%|██▊       | 70/247 [00:38<01:44,  1.70it/s]Loading train:  29%|██▊       | 71/247 [00:38<01:42,  1.72it/s]Loading train:  29%|██▉       | 72/247 [00:39<01:42,  1.71it/s]Loading train:  30%|██▉       | 73/247 [00:39<01:40,  1.74it/s]Loading train:  30%|██▉       | 74/247 [00:40<01:39,  1.74it/s]Loading train:  30%|███       | 75/247 [00:40<01:37,  1.76it/s]Loading train:  31%|███       | 76/247 [00:41<01:36,  1.77it/s]Loading train:  31%|███       | 77/247 [00:42<01:48,  1.57it/s]Loading train:  32%|███▏      | 78/247 [00:43<02:04,  1.36it/s]Loading train:  32%|███▏      | 79/247 [00:44<02:11,  1.28it/s]Loading train:  32%|███▏      | 80/247 [00:44<02:06,  1.32it/s]Loading train:  33%|███▎      | 81/247 [00:45<02:05,  1.32it/s]Loading train:  33%|███▎      | 82/247 [00:46<01:55,  1.42it/s]Loading train:  34%|███▎      | 83/247 [00:46<01:47,  1.52it/s]Loading train:  34%|███▍      | 84/247 [00:47<01:41,  1.60it/s]Loading train:  34%|███▍      | 85/247 [00:47<01:37,  1.67it/s]Loading train:  35%|███▍      | 86/247 [00:48<01:35,  1.68it/s]Loading train:  35%|███▌      | 87/247 [00:48<01:32,  1.73it/s]Loading train:  36%|███▌      | 88/247 [00:49<01:29,  1.78it/s]Loading train:  36%|███▌      | 89/247 [00:50<01:28,  1.78it/s]Loading train:  36%|███▋      | 90/247 [00:50<01:25,  1.83it/s]Loading train:  37%|███▋      | 91/247 [00:51<01:23,  1.87it/s]Loading train:  37%|███▋      | 92/247 [00:51<01:21,  1.89it/s]Loading train:  38%|███▊      | 93/247 [00:52<01:22,  1.87it/s]Loading train:  38%|███▊      | 94/247 [00:52<01:22,  1.85it/s]Loading train:  38%|███▊      | 95/247 [00:53<01:21,  1.86it/s]Loading train:  39%|███▉      | 96/247 [00:53<01:20,  1.87it/s]Loading train:  39%|███▉      | 97/247 [00:54<01:20,  1.87it/s]Loading train:  40%|███▉      | 98/247 [00:54<01:20,  1.85it/s]Loading train:  40%|████      | 99/247 [00:55<01:18,  1.88it/s]Loading train:  40%|████      | 100/247 [00:55<01:20,  1.83it/s]Loading train:  41%|████      | 101/247 [00:56<01:20,  1.81it/s]Loading train:  41%|████▏     | 102/247 [00:57<01:21,  1.78it/s]Loading train:  42%|████▏     | 103/247 [00:57<01:21,  1.77it/s]Loading train:  42%|████▏     | 104/247 [00:58<01:20,  1.77it/s]Loading train:  43%|████▎     | 105/247 [00:58<01:19,  1.78it/s]Loading train:  43%|████▎     | 106/247 [00:59<01:19,  1.77it/s]Loading train:  43%|████▎     | 107/247 [00:59<01:19,  1.76it/s]Loading train:  44%|████▎     | 108/247 [01:00<01:18,  1.77it/s]Loading train:  44%|████▍     | 109/247 [01:01<01:17,  1.78it/s]Loading train:  45%|████▍     | 110/247 [01:01<01:17,  1.77it/s]Loading train:  45%|████▍     | 111/247 [01:02<01:18,  1.74it/s]Loading train:  45%|████▌     | 112/247 [01:02<01:17,  1.73it/s]Loading train:  46%|████▌     | 113/247 [01:03<01:17,  1.74it/s]Loading train:  46%|████▌     | 114/247 [01:03<01:17,  1.73it/s]Loading train:  47%|████▋     | 115/247 [01:04<01:16,  1.73it/s]Loading train:  47%|████▋     | 116/247 [01:05<01:14,  1.76it/s]Loading train:  47%|████▋     | 117/247 [01:05<01:13,  1.76it/s]Loading train:  48%|████▊     | 118/247 [01:06<01:15,  1.71it/s]Loading train:  48%|████▊     | 119/247 [01:06<01:15,  1.71it/s]Loading train:  49%|████▊     | 120/247 [01:07<01:14,  1.70it/s]Loading train:  49%|████▉     | 121/247 [01:08<01:14,  1.70it/s]Loading train:  49%|████▉     | 122/247 [01:08<01:14,  1.68it/s]Loading train:  50%|████▉     | 123/247 [01:09<01:12,  1.70it/s]Loading train:  50%|█████     | 124/247 [01:09<01:12,  1.71it/s]Loading train:  51%|█████     | 125/247 [01:10<01:11,  1.71it/s]Loading train:  51%|█████     | 126/247 [01:10<01:11,  1.69it/s]Loading train:  51%|█████▏    | 127/247 [01:11<01:10,  1.71it/s]Loading train:  52%|█████▏    | 128/247 [01:12<01:09,  1.72it/s]Loading train:  52%|█████▏    | 129/247 [01:12<01:07,  1.74it/s]Loading train:  53%|█████▎    | 130/247 [01:13<01:07,  1.73it/s]Loading train:  53%|█████▎    | 131/247 [01:13<01:07,  1.71it/s]Loading train:  53%|█████▎    | 132/247 [01:14<01:06,  1.73it/s]Loading train:  54%|█████▍    | 133/247 [01:15<01:06,  1.73it/s]Loading train:  54%|█████▍    | 134/247 [01:15<01:05,  1.72it/s]Loading train:  55%|█████▍    | 135/247 [01:16<01:05,  1.70it/s]Loading train:  55%|█████▌    | 136/247 [01:16<01:02,  1.79it/s]Loading train:  55%|█████▌    | 137/247 [01:17<00:59,  1.84it/s]Loading train:  56%|█████▌    | 138/247 [01:17<00:56,  1.92it/s]Loading train:  56%|█████▋    | 139/247 [01:18<00:56,  1.93it/s]Loading train:  57%|█████▋    | 140/247 [01:18<00:54,  1.97it/s]Loading train:  57%|█████▋    | 141/247 [01:19<00:53,  1.97it/s]Loading train:  57%|█████▋    | 142/247 [01:19<00:52,  1.98it/s]Loading train:  58%|█████▊    | 143/247 [01:20<00:52,  1.99it/s]Loading train:  58%|█████▊    | 144/247 [01:20<00:51,  1.99it/s]Loading train:  59%|█████▊    | 145/247 [01:21<00:51,  1.96it/s]Loading train:  59%|█████▉    | 146/247 [01:21<00:51,  1.98it/s]Loading train:  60%|█████▉    | 147/247 [01:22<00:50,  1.98it/s]Loading train:  60%|█████▉    | 148/247 [01:22<00:49,  1.98it/s]Loading train:  60%|██████    | 149/247 [01:23<00:49,  2.00it/s]Loading train:  61%|██████    | 150/247 [01:23<00:48,  2.00it/s]Loading train:  61%|██████    | 151/247 [01:24<00:47,  2.01it/s]Loading train:  62%|██████▏   | 152/247 [01:24<00:47,  2.00it/s]Loading train:  62%|██████▏   | 153/247 [01:25<00:47,  2.00it/s]Loading train:  62%|██████▏   | 154/247 [01:25<00:47,  1.96it/s]Loading train:  63%|██████▎   | 155/247 [01:26<00:46,  1.98it/s]Loading train:  63%|██████▎   | 156/247 [01:26<00:45,  2.01it/s]Loading train:  64%|██████▎   | 157/247 [01:27<00:45,  1.99it/s]Loading train:  64%|██████▍   | 158/247 [01:27<00:44,  2.00it/s]Loading train:  64%|██████▍   | 159/247 [01:28<00:43,  2.02it/s]Loading train:  65%|██████▍   | 160/247 [01:28<00:43,  2.00it/s]Loading train:  65%|██████▌   | 161/247 [01:29<00:43,  1.99it/s]Loading train:  66%|██████▌   | 162/247 [01:29<00:42,  1.98it/s]Loading train:  66%|██████▌   | 163/247 [01:30<00:42,  2.00it/s]Loading train:  66%|██████▋   | 164/247 [01:30<00:41,  1.99it/s]Loading train:  67%|██████▋   | 165/247 [01:31<00:41,  1.96it/s]Loading train:  67%|██████▋   | 166/247 [01:31<00:40,  1.98it/s]Loading train:  68%|██████▊   | 167/247 [01:32<00:40,  1.96it/s]Loading train:  68%|██████▊   | 168/247 [01:32<00:40,  1.95it/s]Loading train:  68%|██████▊   | 169/247 [01:33<00:39,  1.99it/s]Loading train:  69%|██████▉   | 170/247 [01:33<00:38,  2.00it/s]Loading train:  69%|██████▉   | 171/247 [01:34<00:38,  2.00it/s]Loading train:  70%|██████▉   | 172/247 [01:35<00:45,  1.66it/s]Loading train:  70%|███████   | 173/247 [01:35<00:47,  1.54it/s]Loading train:  70%|███████   | 174/247 [01:36<00:49,  1.48it/s]Loading train:  71%|███████   | 175/247 [01:37<00:53,  1.35it/s]Loading train:  71%|███████▏  | 176/247 [01:38<00:48,  1.46it/s]Loading train:  72%|███████▏  | 177/247 [01:38<00:44,  1.56it/s]Loading train:  72%|███████▏  | 178/247 [01:39<00:42,  1.63it/s]Loading train:  72%|███████▏  | 179/247 [01:39<00:40,  1.70it/s]Loading train:  73%|███████▎  | 180/247 [01:40<00:38,  1.74it/s]Loading train:  73%|███████▎  | 181/247 [01:40<00:37,  1.77it/s]Loading train:  74%|███████▎  | 182/247 [01:41<00:36,  1.78it/s]Loading train:  74%|███████▍  | 183/247 [01:41<00:35,  1.80it/s]Loading train:  74%|███████▍  | 184/247 [01:42<00:34,  1.83it/s]Loading train:  75%|███████▍  | 185/247 [01:42<00:33,  1.83it/s]Loading train:  75%|███████▌  | 186/247 [01:43<00:33,  1.84it/s]Loading train:  76%|███████▌  | 187/247 [01:44<00:33,  1.81it/s]Loading train:  76%|███████▌  | 188/247 [01:44<00:32,  1.82it/s]Loading train:  77%|███████▋  | 189/247 [01:45<00:31,  1.81it/s]Loading train:  77%|███████▋  | 190/247 [01:45<00:31,  1.80it/s]Loading train:  77%|███████▋  | 191/247 [01:46<00:30,  1.81it/s]Loading train:  78%|███████▊  | 192/247 [01:46<00:30,  1.82it/s]Loading train:  78%|███████▊  | 193/247 [01:47<00:29,  1.81it/s]Loading train:  79%|███████▊  | 194/247 [01:47<00:29,  1.81it/s]Loading train:  79%|███████▉  | 195/247 [01:48<00:28,  1.82it/s]Loading train:  79%|███████▉  | 196/247 [01:48<00:27,  1.83it/s]Loading train:  80%|███████▉  | 197/247 [01:49<00:27,  1.85it/s]Loading train:  80%|████████  | 198/247 [01:50<00:26,  1.85it/s]Loading train:  81%|████████  | 199/247 [01:50<00:25,  1.85it/s]Loading train:  81%|████████  | 200/247 [01:51<00:25,  1.87it/s]Loading train:  81%|████████▏ | 201/247 [01:51<00:24,  1.88it/s]Loading train:  82%|████████▏ | 202/247 [01:52<00:23,  1.88it/s]Loading train:  82%|████████▏ | 203/247 [01:52<00:23,  1.87it/s]Loading train:  83%|████████▎ | 204/247 [01:53<00:22,  1.87it/s]Loading train:  83%|████████▎ | 205/247 [01:53<00:22,  1.88it/s]Loading train:  83%|████████▎ | 206/247 [01:54<00:21,  1.88it/s]Loading train:  84%|████████▍ | 207/247 [01:54<00:21,  1.88it/s]Loading train:  84%|████████▍ | 208/247 [01:55<00:20,  1.89it/s]Loading train:  85%|████████▍ | 209/247 [01:55<00:20,  1.87it/s]Loading train:  85%|████████▌ | 210/247 [01:56<00:19,  1.86it/s]Loading train:  85%|████████▌ | 211/247 [01:56<00:19,  1.86it/s]Loading train:  86%|████████▌ | 212/247 [01:57<00:18,  1.87it/s]Loading train:  86%|████████▌ | 213/247 [01:58<00:18,  1.88it/s]Loading train:  87%|████████▋ | 214/247 [01:58<00:17,  1.91it/s]Loading train:  87%|████████▋ | 215/247 [01:59<00:16,  1.92it/s]Loading train:  87%|████████▋ | 216/247 [01:59<00:16,  1.91it/s]Loading train:  88%|████████▊ | 217/247 [02:00<00:15,  1.91it/s]Loading train:  88%|████████▊ | 218/247 [02:00<00:15,  1.93it/s]Loading train:  89%|████████▊ | 219/247 [02:01<00:14,  1.94it/s]Loading train:  89%|████████▉ | 220/247 [02:03<00:27,  1.01s/it]Loading train:  89%|████████▉ | 221/247 [02:07<00:50,  1.94s/it]Loading train:  90%|████████▉ | 222/247 [02:11<01:04,  2.59s/it]Loading train:  90%|█████████ | 223/247 [02:16<01:17,  3.24s/it]Loading train:  91%|█████████ | 224/247 [02:23<01:40,  4.36s/it]Loading train:  91%|█████████ | 225/247 [02:28<01:41,  4.60s/it]Loading train:  91%|█████████▏| 226/247 [02:33<01:38,  4.71s/it]Loading train:  92%|█████████▏| 227/247 [02:38<01:36,  4.81s/it]Loading train:  92%|█████████▏| 228/247 [02:43<01:31,  4.84s/it]Loading train:  93%|█████████▎| 229/247 [02:48<01:31,  5.08s/it]Loading train:  93%|█████████▎| 230/247 [02:57<01:42,  6.04s/it]Loading train:  94%|█████████▎| 231/247 [03:05<01:47,  6.73s/it]Loading train:  94%|█████████▍| 232/247 [03:12<01:42,  6.86s/it]Loading train:  94%|█████████▍| 233/247 [03:18<01:30,  6.43s/it]Loading train:  95%|█████████▍| 234/247 [03:24<01:21,  6.30s/it]Loading train:  95%|█████████▌| 235/247 [03:30<01:14,  6.18s/it]Loading train:  96%|█████████▌| 236/247 [03:35<01:07,  6.10s/it]Loading train:  96%|█████████▌| 237/247 [03:41<01:00,  6.07s/it]Loading train:  96%|█████████▋| 238/247 [03:47<00:53,  5.99s/it]Loading train:  97%|█████████▋| 239/247 [03:53<00:47,  5.88s/it]Loading train:  97%|█████████▋| 240/247 [03:59<00:40,  5.81s/it]Loading train:  98%|█████████▊| 241/247 [04:04<00:34,  5.79s/it]Loading train:  98%|█████████▊| 242/247 [04:10<00:28,  5.72s/it]Loading train:  98%|█████████▊| 243/247 [04:15<00:22,  5.64s/it]Loading train:  99%|█████████▉| 244/247 [04:21<00:16,  5.53s/it]Loading train:  99%|█████████▉| 245/247 [04:26<00:11,  5.54s/it]Loading train: 100%|█████████▉| 246/247 [04:31<00:05,  5.49s/it]Loading train: 100%|██████████| 247/247 [04:37<00:00,  5.41s/it]Loading train: 100%|██████████| 247/247 [04:37<00:00,  1.12s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 52.44it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 52.74it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 53.11it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:04, 53.29it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 52.77it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:04, 52.18it/s]concatenating: train:  17%|█▋        | 42/247 [00:00<00:03, 52.31it/s]concatenating: train:  19%|█▉        | 48/247 [00:00<00:03, 53.03it/s]concatenating: train:  22%|██▏       | 54/247 [00:01<00:03, 53.40it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 53.20it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 52.01it/s]concatenating: train:  29%|██▉       | 72/247 [00:01<00:03, 50.85it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:03, 50.95it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:03, 51.89it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:02, 52.79it/s]concatenating: train:  39%|███▉      | 96/247 [00:01<00:02, 53.15it/s]concatenating: train:  41%|████▏     | 102/247 [00:01<00:02, 53.60it/s]concatenating: train:  44%|████▎     | 108/247 [00:02<00:02, 53.94it/s]concatenating: train:  46%|████▌     | 114/247 [00:02<00:02, 54.00it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:02, 53.06it/s]concatenating: train:  51%|█████     | 126/247 [00:02<00:02, 51.07it/s]concatenating: train:  53%|█████▎    | 132/247 [00:02<00:02, 50.19it/s]concatenating: train:  56%|█████▌    | 138/247 [00:02<00:02, 49.79it/s]concatenating: train:  58%|█████▊    | 144/247 [00:02<00:02, 49.96it/s]concatenating: train:  61%|██████    | 150/247 [00:02<00:01, 50.46it/s]concatenating: train:  63%|██████▎   | 156/247 [00:02<00:01, 51.46it/s]concatenating: train:  66%|██████▌   | 162/247 [00:03<00:01, 52.63it/s]concatenating: train:  68%|██████▊   | 168/247 [00:03<00:01, 53.60it/s]concatenating: train:  70%|███████   | 174/247 [00:03<00:01, 53.07it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 50.92it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:01, 50.01it/s]concatenating: train:  78%|███████▊  | 192/247 [00:03<00:01, 48.88it/s]concatenating: train:  80%|███████▉  | 197/247 [00:03<00:01, 47.57it/s]concatenating: train:  82%|████████▏ | 202/247 [00:03<00:00, 46.52it/s]concatenating: train:  84%|████████▍ | 207/247 [00:04<00:00, 45.72it/s]concatenating: train:  86%|████████▌ | 212/247 [00:04<00:00, 45.59it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 45.79it/s]concatenating: train:  90%|████████▉ | 222/247 [00:04<00:00, 44.77it/s]concatenating: train:  92%|█████████▏| 227/247 [00:04<00:00, 43.60it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 43.43it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 43.31it/s]concatenating: train:  98%|█████████▊| 242/247 [00:04<00:00, 43.12it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 44.94it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 49.85it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:14<00:58, 14.55s/it]Loading test:  40%|████      | 2/5 [00:28<00:42, 14.24s/it]Loading test:  60%|██████    | 3/5 [00:38<00:26, 13.23s/it]Loading test:  80%|████████  | 4/5 [00:47<00:11, 11.72s/it]Loading test: 100%|██████████| 5/5 [01:00<00:00, 12.30s/it]Loading test: 100%|██████████| 5/5 [01:00<00:00, 12.15s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00, 37.81it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 41.79it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 52, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 26, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 26, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 26, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 26, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 26, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 26, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 26, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 26, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 13, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 13, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 13, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 13, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 13, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 13, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 13, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 13, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 13, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 13, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 26, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 26, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 26, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 26, 80)   320         conv2d_7[0][0]                   2020-01-21 19:27:18.581538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 19:27:18.581635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 19:27:18.581650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 19:27:18.581658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 19:27:18.581980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 26, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 26, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 26, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 26, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 26, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 26, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 52, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 52, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 52, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 52, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 52, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 52, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 52, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 52, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 52, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 52, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.23041735e-02 3.14262850e-02 7.86499814e-02 9.57948248e-03
 2.85439478e-02 7.22430610e-03 8.59641913e-02 1.15068972e-01
 9.00085481e-02 1.30547657e-02 2.93859674e-01 1.84079299e-01
 2.36373332e-04]
Train on 9409 samples, validate on 195 samples
Epoch 1/300
 - 30s - loss: 0.5559 - acc: 0.9066 - mDice: 0.4015 - val_loss: 0.6757 - val_acc: 0.9430 - val_mDice: 0.2702

Epoch 00001: val_mDice improved from -inf to 0.27024, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 25s - loss: 0.3914 - acc: 0.9410 - mDice: 0.5782 - val_loss: 0.6558 - val_acc: 0.9450 - val_mDice: 0.2915

Epoch 00002: val_mDice improved from 0.27024 to 0.29154, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 25s - loss: 0.3540 - acc: 0.9454 - mDice: 0.6186 - val_loss: 0.6473 - val_acc: 0.9479 - val_mDice: 0.3005

Epoch 00003: val_mDice improved from 0.29154 to 0.30046, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 24s - loss: 0.3340 - acc: 0.9477 - mDice: 0.6401 - val_loss: 0.6594 - val_acc: 0.9471 - val_mDice: 0.2869

Epoch 00004: val_mDice did not improve from 0.30046
Epoch 5/300
 - 25s - loss: 0.3236 - acc: 0.9492 - mDice: 0.6513 - val_loss: 0.6390 - val_acc: 0.9475 - val_mDice: 0.3065

Epoch 00005: val_mDice improved from 0.30046 to 0.30650, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 24s - loss: 0.3109 - acc: 0.9508 - mDice: 0.6650 - val_loss: 0.6413 - val_acc: 0.9476 - val_mDice: 0.3044

Epoch 00006: val_mDice did not improve from 0.30650
Epoch 7/300
 - 24s - loss: 0.3046 - acc: 0.9517 - mDice: 0.6718 - val_loss: 0.6449 - val_acc: 0.9488 - val_mDice: 0.3002

Epoch 00007: val_mDice did not improve from 0.30650
Epoch 8/300
 - 24s - loss: 0.2931 - acc: 0.9528 - mDice: 0.6843 - val_loss: 0.6583 - val_acc: 0.9472 - val_mDice: 0.2804

Epoch 00008: val_mDice did not improve from 0.30650
Epoch 9/300
 - 24s - loss: 0.2949 - acc: 0.9527 - mDice: 0.6823 - val_loss: 0.6040 - val_acc: 0.9442 - val_mDice: 0.2887

Epoch 00009: val_mDice did not improve from 0.30650
Epoch 10/300
 - 25s - loss: 0.2817 - acc: 0.9540 - mDice: 0.6965 - val_loss: 0.6322 - val_acc: 0.9469 - val_mDice: 0.2939

Epoch 00010: val_mDice did not improve from 0.30650
Epoch 11/300
 - 24s - loss: 0.2844 - acc: 0.9538 - mDice: 0.6936 - val_loss: 0.6425 - val_acc: 0.9423 - val_mDice: 0.2638

Epoch 00011: val_mDice did not improve from 0.30650
Epoch 12/300
 - 24s - loss: 0.2760 - acc: 0.9547 - mDice: 0.7026 - val_loss: 0.4532 - val_acc: 0.9475 - val_mDice: 0.2909

Epoch 00012: val_mDice did not improve from 0.30650
Epoch 13/300
 - 24s - loss: 0.2765 - acc: 0.9546 - mDice: 0.7021 - val_loss: 0.6189 - val_acc: 0.9487 - val_mDice: 0.2794

Epoch 00013: val_mDice did not improve from 0.30650
Epoch 14/300
 - 24s - loss: 0.2721 - acc: 0.9556 - mDice: 0.7069 - val_loss: 0.6299 - val_acc: 0.9465 - val_mDice: 0.2878

Epoch 00014: val_mDice did not improve from 0.30650
Epoch 15/300
 - 24s - loss: 0.2610 - acc: 0.9564 - mDice: 0.7188 - val_loss: 0.4523 - val_acc: 0.9467 - val_mDice: 0.2906

Epoch 00015: val_mDice did not improve from 0.30650
Epoch 16/300
 - 24s - loss: 0.2579 - acc: 0.9567 - mDice: 0.7222 - val_loss: 0.4033 - val_acc: 0.9487 - val_mDice: 0.2894

Epoch 00016: val_mDice did not improve from 0.30650
Epoch 17/300
 - 23s - loss: 0.2657 - acc: 0.9562 - mDice: 0.7138 - val_loss: 0.5504 - val_acc: 0.9432 - val_mDice: 0.2755

Epoch 00017: val_mDice did not improve from 0.30650
Epoch 18/300
 - 24s - loss: 0.2580 - acc: 0.9568 - mDice: 0.7221 - val_loss: 0.3401 - val_acc: 0.9484 - val_mDice: 0.2884

Epoch 00018: val_mDice did not improve from 0.30650
Epoch 19/300
 - 23s - loss: 0.2592 - acc: 0.9572 - mDice: 0.7208 - val_loss: 0.3981 - val_acc: 0.9485 - val_mDice: 0.2786

Epoch 00019: val_mDice did not improve from 0.30650
Epoch 20/300
 - 23s - loss: 0.2523 - acc: 0.9574 - mDice: 0.7282 - val_loss: 0.4289 - val_acc: 0.9486 - val_mDice: 0.2914

Epoch 00020: val_mDice did not improve from 0.30650

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 21/300
 - 24s - loss: 0.2386 - acc: 0.9587 - mDice: 0.7430 - val_loss: 0.4525 - val_acc: 0.9475 - val_mDice: 0.2782

Epoch 00021: val_mDice did not improve from 0.30650
Epoch 22/300
 - 23s - loss: 0.2367 - acc: 0.9590 - mDice: 0.7450 - val_loss: 0.3496 - val_acc: 0.9480 - val_mDice: 0.2848

Epoch 00022: val_mDice did not improve from 0.30650
Epoch 23/300
 - 24s - loss: 0.2371 - acc: 0.9592 - mDice: 0.7447 - val_loss: 0.4057 - val_acc: 0.9475 - val_mDice: 0.2856

Epoch 00023: val_mDice did not improve from 0.30650
Epoch 24/300
 - 23s - loss: 0.2368 - acc: 0.9596 - mDice: 0.7449 - val_loss: 0.2325 - val_acc: 0.9477 - val_mDice: 0.2667

Epoch 00024: val_mDice did not improve from 0.30650
Epoch 25/300
 - 23s - loss: 0.2330 - acc: 0.9596 - mDice: 0.7491 - val_loss: 0.4175 - val_acc: 0.9481 - val_mDice: 0.2748

Epoch 00025: val_mDice did not improve from 0.30650
Epoch 26/300
 - 24s - loss: 0.2296 - acc: 0.9598 - mDice: 0.7527 - val_loss: 0.4219 - val_acc: 0.9484 - val_mDice: 0.2798

Epoch 00026: val_mDice did not improve from 0.30650
Epoch 27/300
 - 23s - loss: 0.2265 - acc: 0.9600 - mDice: 0.7561 - val_loss: 0.4807 - val_acc: 0.9445 - val_mDice: 0.2647

Epoch 00027: val_mDice did not improve from 0.30650
Epoch 28/300
 - 24s - loss: 0.2269 - acc: 0.9602 - mDice: 0.7557 - val_loss: 0.2933 - val_acc: 0.9480 - val_mDice: 0.2823

Epoch 00028: val_mDice did not improve from 0.30650
Epoch 29/300
 - 23s - loss: 0.2256 - acc: 0.9603 - mDice: 0.7571 - val_loss: 0.4161 - val_acc: 0.9481 - val_mDice: 0.2822

Epoch 00029: val_mDice did not improve from 0.30650
Epoch 30/300
 - 24s - loss: 0.2264 - acc: 0.9602 - mDice: 0.7562 - val_loss: 0.3665 - val_acc: 0.9461 - val_mDice: 0.2786

Epoch 00030: val_mDice did not improve from 0.30650
Epoch 31/300
 - 23s - loss: 0.2229 - acc: 0.9606 - mDice: 0.7600 - val_loss: 0.3881 - val_acc: 0.9460 - val_mDice: 0.2780

Epoch 00031: val_mDice did not improve from 0.30650
Epoch 32/300
 - 23s - loss: 0.2264 - acc: 0.9604 - mDice: 0.7562 - val_loss: 0.4693 - val_acc: 0.9471 - val_mDice: 0.2719

Epoch 00032: val_mDice did not improve from 0.30650
Epoch 33/300
 - 24s - loss: 0.2229 - acc: 0.9606 - mDice: 0.7600 - val_loss: 0.3416 - val_acc: 0.9470 - val_mDice: 0.2764

Epoch 00033: val_mDice did not improve from 0.30650
Epoch 34/300
 - 23s - loss: 0.2226 - acc: 0.9605 - mDice: 0.7603 - val_loss: 0.3296 - val_acc: 0.9463 - val_mDice: 0.2843

Epoch 00034: val_mDice did not improve from 0.30650
Epoch 35/300
 - 24s - loss: 0.2200 - acc: 0.9606 - mDice: 0.7631 - val_loss: 0.3170 - val_acc: 0.9454 - val_mDice: 0.2676

Epoch 00035: val_mDice did not improve from 0.30650

Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 36/300
 - 23s - loss: 0.2156 - acc: 0.9610 - mDice: 0.7678 - val_loss: 0.2943 - val_acc: 0.9469 - val_mDice: 0.2830

Epoch 00036: val_mDice did not improve from 0.30650
Epoch 37/300
 - 24s - loss: 0.2146 - acc: 0.9615 - mDice: 0.7689 - val_loss: 0.3227 - val_acc: 0.9469 - val_mDice: 0.2797

Epoch 00037: val_mDice did not improve from 0.30650
Epoch 38/300
 - 24s - loss: 0.2145 - acc: 0.9616 - mDice: 0.7690 - val_loss: 0.2181 - val_acc: 0.9474 - val_mDice: 0.2754

Epoch 00038: val_mDice did not improve from 0.30650
Epoch 39/300
 - 24s - loss: 0.2111 - acc: 0.9617 - mDice: 0.7727 - val_loss: 0.2576 - val_acc: 0.9473 - val_mDice: 0.2828

Epoch 00039: val_mDice did not improve from 0.30650
Epoch 40/300
 - 24s - loss: 0.2124 - acc: 0.9618 - mDice: 0.7713 - val_loss: 0.3154 - val_acc: 0.9470 - val_mDice: 0.2776

Epoch 00040: val_mDice did not improve from 0.30650
Epoch 41/300
 - 23s - loss: 0.2094 - acc: 0.9618 - mDice: 0.7746 - val_loss: 0.2659 - val_acc: 0.9478 - val_mDice: 0.2834

Epoch 00041: val_mDice did not improve from 0.30650
Epoch 42/300
 - 24s - loss: 0.2117 - acc: 0.9618 - mDice: 0.7720 - val_loss: 0.2688 - val_acc: 0.9486 - val_mDice: 0.2822

Epoch 00042: val_mDice did not improve from 0.30650
Epoch 43/300
 - 23s - loss: 0.2108 - acc: 0.9619 - mDice: 0.7731 - val_loss: 0.1988 - val_acc: 0.9463 - val_mDice: 0.2775

Epoch 00043: val_mDice did not improve from 0.30650
Epoch 44/300
 - 23s - loss: 0.2087 - acc: 0.9620 - mDice: 0.7753 - val_loss: 0.3234 - val_acc: 0.9468 - val_mDice: 0.2774

Epoch 00044: val_mDice did not improve from 0.30650
Epoch 45/300
 - 23s - loss: 0.2105 - acc: 0.9620 - mDice: 0.7733 - val_loss: 0.2464 - val_acc: 0.9466 - val_mDice: 0.2781

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.62s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.45s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.29s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.16s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:18,  3.12it/s]Loading train:   1%|          | 2/247 [00:00<01:16,  3.21it/s]Loading train:   1%|          | 3/247 [00:00<01:13,  3.33it/s]Loading train:   2%|▏         | 4/247 [00:01<01:13,  3.30it/s]Loading train:   2%|▏         | 5/247 [00:01<01:12,  3.32it/s]Loading train:   2%|▏         | 6/247 [00:01<01:12,  3.34it/s]Loading train:   3%|▎         | 7/247 [00:02<01:11,  3.34it/s]Loading train:   3%|▎         | 8/247 [00:02<01:11,  3.34it/s]Loading train:   4%|▎         | 9/247 [00:02<01:10,  3.36it/s]Loading train:   4%|▍         | 10/247 [00:02<01:10,  3.38it/s]Loading train:   4%|▍         | 11/247 [00:03<01:09,  3.40it/s]Loading train:   5%|▍         | 12/247 [00:03<01:08,  3.43it/s]Loading train:   5%|▌         | 13/247 [00:03<01:07,  3.44it/s]Loading train:   6%|▌         | 14/247 [00:04<01:07,  3.44it/s]Loading train:   6%|▌         | 15/247 [00:04<01:07,  3.43it/s]Loading train:   6%|▋         | 16/247 [00:04<01:07,  3.42it/s]Loading train:   7%|▋         | 17/247 [00:05<01:07,  3.42it/s]Loading train:   7%|▋         | 18/247 [00:05<01:07,  3.41it/s]Loading train:   8%|▊         | 19/247 [00:05<01:06,  3.41it/s]Loading train:   8%|▊         | 20/247 [00:05<01:06,  3.41it/s]Loading train:   9%|▊         | 21/247 [00:06<01:06,  3.42it/s]Loading train:   9%|▉         | 22/247 [00:06<01:05,  3.41it/s]Loading train:   9%|▉         | 23/247 [00:06<01:03,  3.55it/s]Loading train:  10%|▉         | 24/247 [00:06<01:01,  3.64it/s]Loading train:  10%|█         | 25/247 [00:07<01:00,  3.70it/s]Loading train:  11%|█         | 26/247 [00:07<00:58,  3.75it/s]Loading train:  11%|█         | 27/247 [00:07<00:58,  3.76it/s]Loading train:  11%|█▏        | 28/247 [00:08<00:57,  3.78it/s]Loading train:  12%|█▏        | 29/247 [00:08<00:57,  3.78it/s]Loading train:  12%|█▏        | 30/247 [00:08<00:57,  3.79it/s]Loading train:  13%|█▎        | 31/247 [00:08<00:56,  3.81it/s]Loading train:  13%|█▎        | 32/247 [00:09<00:56,  3.81it/s]Loading train:  13%|█▎        | 33/247 [00:09<00:56,  3.78it/s]Loading train:  14%|█▍        | 34/247 [00:09<00:57,  3.72it/s]Loading train:  14%|█▍        | 35/247 [00:09<00:56,  3.74it/s]Loading train:  15%|█▍        | 36/247 [00:10<00:55,  3.78it/s]Loading train:  15%|█▍        | 37/247 [00:10<00:55,  3.80it/s]Loading train:  15%|█▌        | 38/247 [00:10<00:54,  3.81it/s]Loading train:  16%|█▌        | 39/247 [00:10<00:53,  3.85it/s]Loading train:  16%|█▌        | 40/247 [00:11<00:53,  3.89it/s]Loading train:  17%|█▋        | 41/247 [00:11<00:53,  3.83it/s]Loading train:  17%|█▋        | 42/247 [00:11<00:53,  3.81it/s]Loading train:  17%|█▋        | 43/247 [00:11<00:53,  3.79it/s]Loading train:  18%|█▊        | 44/247 [00:12<00:53,  3.78it/s]Loading train:  18%|█▊        | 45/247 [00:12<00:53,  3.79it/s]Loading train:  19%|█▊        | 46/247 [00:12<00:53,  3.78it/s]Loading train:  19%|█▉        | 47/247 [00:13<00:52,  3.78it/s]Loading train:  19%|█▉        | 48/247 [00:13<00:52,  3.77it/s]Loading train:  20%|█▉        | 49/247 [00:13<00:52,  3.79it/s]Loading train:  20%|██        | 50/247 [00:13<00:52,  3.78it/s]Loading train:  21%|██        | 51/247 [00:14<00:51,  3.78it/s]Loading train:  21%|██        | 52/247 [00:14<00:51,  3.76it/s]Loading train:  21%|██▏       | 53/247 [00:14<00:51,  3.77it/s]Loading train:  22%|██▏       | 54/247 [00:14<00:51,  3.77it/s]Loading train:  22%|██▏       | 55/247 [00:15<00:50,  3.77it/s]Loading train:  23%|██▎       | 56/247 [00:15<00:50,  3.77it/s]Loading train:  23%|██▎       | 57/247 [00:15<00:50,  3.74it/s]Loading train:  23%|██▎       | 58/247 [00:15<00:50,  3.75it/s]Loading train:  24%|██▍       | 59/247 [00:16<00:51,  3.68it/s]Loading train:  24%|██▍       | 60/247 [00:16<00:51,  3.63it/s]Loading train:  25%|██▍       | 61/247 [00:16<00:51,  3.60it/s]Loading train:  25%|██▌       | 62/247 [00:17<00:51,  3.58it/s]Loading train:  26%|██▌       | 63/247 [00:17<00:51,  3.56it/s]Loading train:  26%|██▌       | 64/247 [00:17<00:51,  3.55it/s]Loading train:  26%|██▋       | 65/247 [00:17<00:51,  3.54it/s]Loading train:  27%|██▋       | 66/247 [00:18<00:51,  3.53it/s]Loading train:  27%|██▋       | 67/247 [00:18<00:51,  3.53it/s]Loading train:  28%|██▊       | 68/247 [00:18<00:50,  3.52it/s]Loading train:  28%|██▊       | 69/247 [00:19<00:50,  3.51it/s]Loading train:  28%|██▊       | 70/247 [00:19<00:50,  3.52it/s]Loading train:  29%|██▊       | 71/247 [00:19<00:50,  3.52it/s]Loading train:  29%|██▉       | 72/247 [00:19<00:49,  3.51it/s]Loading train:  30%|██▉       | 73/247 [00:20<00:49,  3.51it/s]Loading train:  30%|██▉       | 74/247 [00:20<00:49,  3.50it/s]Loading train:  30%|███       | 75/247 [00:20<00:49,  3.51it/s]Loading train:  31%|███       | 76/247 [00:21<00:48,  3.49it/s]Loading train:  31%|███       | 77/247 [00:21<00:50,  3.38it/s]Loading train:  32%|███▏      | 78/247 [00:21<00:52,  3.24it/s]Loading train:  32%|███▏      | 79/247 [00:22<00:52,  3.23it/s]Loading train:  32%|███▏      | 80/247 [00:22<00:50,  3.34it/s]Loading train:  33%|███▎      | 81/247 [00:22<00:49,  3.35it/s]Loading train:  33%|███▎      | 82/247 [00:22<00:49,  3.34it/s]Loading train:  34%|███▎      | 83/247 [00:23<00:49,  3.34it/s]Loading train:  34%|███▍      | 84/247 [00:23<00:49,  3.32it/s]Loading train:  34%|███▍      | 85/247 [00:23<00:48,  3.31it/s]Loading train:  35%|███▍      | 86/247 [00:24<00:48,  3.32it/s]Loading train:  35%|███▌      | 87/247 [00:24<00:48,  3.31it/s]Loading train:  36%|███▌      | 88/247 [00:24<00:47,  3.32it/s]Loading train:  36%|███▌      | 89/247 [00:25<00:47,  3.32it/s]Loading train:  36%|███▋      | 90/247 [00:25<00:47,  3.33it/s]Loading train:  37%|███▋      | 91/247 [00:25<00:47,  3.31it/s]Loading train:  37%|███▋      | 92/247 [00:25<00:46,  3.33it/s]Loading train:  38%|███▊      | 93/247 [00:26<00:46,  3.29it/s]Loading train:  38%|███▊      | 94/247 [00:26<00:46,  3.31it/s]Loading train:  38%|███▊      | 95/247 [00:26<00:45,  3.32it/s]Loading train:  39%|███▉      | 96/247 [00:27<00:45,  3.33it/s]Loading train:  39%|███▉      | 97/247 [00:27<00:45,  3.33it/s]Loading train:  40%|███▉      | 98/247 [00:27<00:44,  3.34it/s]Loading train:  40%|████      | 99/247 [00:28<00:44,  3.34it/s]Loading train:  40%|████      | 100/247 [00:28<00:45,  3.26it/s]Loading train:  41%|████      | 101/247 [00:28<00:45,  3.20it/s]Loading train:  41%|████▏     | 102/247 [00:29<00:45,  3.19it/s]Loading train:  42%|████▏     | 103/247 [00:29<00:45,  3.17it/s]Loading train:  42%|████▏     | 104/247 [00:29<00:45,  3.17it/s]Loading train:  43%|████▎     | 105/247 [00:29<00:44,  3.16it/s]Loading train:  43%|████▎     | 106/247 [00:30<00:44,  3.16it/s]Loading train:  43%|████▎     | 107/247 [00:30<00:44,  3.14it/s]Loading train:  44%|████▎     | 108/247 [00:30<00:44,  3.13it/s]Loading train:  44%|████▍     | 109/247 [00:31<00:43,  3.14it/s]Loading train:  45%|████▍     | 110/247 [00:31<00:43,  3.14it/s]Loading train:  45%|████▍     | 111/247 [00:31<00:43,  3.13it/s]Loading train:  45%|████▌     | 112/247 [00:32<00:42,  3.15it/s]Loading train:  46%|████▌     | 113/247 [00:32<00:42,  3.14it/s]Loading train:  46%|████▌     | 114/247 [00:32<00:42,  3.15it/s]Loading train:  47%|████▋     | 115/247 [00:33<00:41,  3.15it/s]Loading train:  47%|████▋     | 116/247 [00:33<00:41,  3.13it/s]Loading train:  47%|████▋     | 117/247 [00:33<00:41,  3.14it/s]Loading train:  48%|████▊     | 118/247 [00:34<00:40,  3.19it/s]Loading train:  48%|████▊     | 119/247 [00:34<00:39,  3.25it/s]Loading train:  49%|████▊     | 120/247 [00:34<00:38,  3.28it/s]Loading train:  49%|████▉     | 121/247 [00:34<00:38,  3.32it/s]Loading train:  49%|████▉     | 122/247 [00:35<00:37,  3.30it/s]Loading train:  50%|████▉     | 123/247 [00:35<00:37,  3.31it/s]Loading train:  50%|█████     | 124/247 [00:35<00:37,  3.29it/s]Loading train:  51%|█████     | 125/247 [00:36<00:37,  3.29it/s]Loading train:  51%|█████     | 126/247 [00:36<00:36,  3.31it/s]Loading train:  51%|█████▏    | 127/247 [00:36<00:36,  3.33it/s]Loading train:  52%|█████▏    | 128/247 [00:37<00:35,  3.32it/s]Loading train:  52%|█████▏    | 129/247 [00:37<00:35,  3.33it/s]Loading train:  53%|█████▎    | 130/247 [00:37<00:34,  3.34it/s]Loading train:  53%|█████▎    | 131/247 [00:37<00:34,  3.34it/s]Loading train:  53%|█████▎    | 132/247 [00:38<00:34,  3.33it/s]Loading train:  54%|█████▍    | 133/247 [00:38<00:34,  3.33it/s]Loading train:  54%|█████▍    | 134/247 [00:38<00:33,  3.33it/s]Loading train:  55%|█████▍    | 135/247 [00:39<00:33,  3.32it/s]Loading train:  55%|█████▌    | 136/247 [00:39<00:33,  3.34it/s]Loading train:  55%|█████▌    | 137/247 [00:39<00:32,  3.41it/s]Loading train:  56%|█████▌    | 138/247 [00:40<00:31,  3.47it/s]Loading train:  56%|█████▋    | 139/247 [00:40<00:30,  3.50it/s]Loading train:  57%|█████▋    | 140/247 [00:40<00:30,  3.49it/s]Loading train:  57%|█████▋    | 141/247 [00:40<00:29,  3.54it/s]Loading train:  57%|█████▋    | 142/247 [00:41<00:29,  3.60it/s]Loading train:  58%|█████▊    | 143/247 [00:41<00:28,  3.66it/s]Loading train:  58%|█████▊    | 144/247 [00:41<00:27,  3.68it/s]Loading train:  59%|█████▊    | 145/247 [00:41<00:27,  3.71it/s]Loading train:  59%|█████▉    | 146/247 [00:42<00:27,  3.73it/s]Loading train:  60%|█████▉    | 147/247 [00:42<00:26,  3.73it/s]Loading train:  60%|█████▉    | 148/247 [00:42<00:26,  3.74it/s]Loading train:  60%|██████    | 149/247 [00:43<00:26,  3.75it/s]Loading train:  61%|██████    | 150/247 [00:43<00:25,  3.76it/s]Loading train:  61%|██████    | 151/247 [00:43<00:25,  3.76it/s]Loading train:  62%|██████▏   | 152/247 [00:43<00:25,  3.74it/s]Loading train:  62%|██████▏   | 153/247 [00:44<00:24,  3.76it/s]Loading train:  62%|██████▏   | 154/247 [00:44<00:25,  3.71it/s]Loading train:  63%|██████▎   | 155/247 [00:44<00:25,  3.66it/s]Loading train:  63%|██████▎   | 156/247 [00:44<00:24,  3.67it/s]Loading train:  64%|██████▎   | 157/247 [00:45<00:24,  3.66it/s]Loading train:  64%|██████▍   | 158/247 [00:45<00:24,  3.63it/s]Loading train:  64%|██████▍   | 159/247 [00:45<00:24,  3.63it/s]Loading train:  65%|██████▍   | 160/247 [00:46<00:24,  3.62it/s]Loading train:  65%|██████▌   | 161/247 [00:46<00:23,  3.62it/s]Loading train:  66%|██████▌   | 162/247 [00:46<00:23,  3.62it/s]Loading train:  66%|██████▌   | 163/247 [00:46<00:23,  3.63it/s]Loading train:  66%|██████▋   | 164/247 [00:47<00:22,  3.63it/s]Loading train:  67%|██████▋   | 165/247 [00:47<00:23,  3.56it/s]Loading train:  67%|██████▋   | 166/247 [00:47<00:22,  3.58it/s]Loading train:  68%|██████▊   | 167/247 [00:47<00:22,  3.57it/s]Loading train:  68%|██████▊   | 168/247 [00:48<00:22,  3.55it/s]Loading train:  68%|██████▊   | 169/247 [00:48<00:21,  3.55it/s]Loading train:  69%|██████▉   | 170/247 [00:48<00:21,  3.55it/s]Loading train:  69%|██████▉   | 171/247 [00:49<00:21,  3.56it/s]Loading train:  70%|██████▉   | 172/247 [00:49<00:21,  3.51it/s]Loading train:  70%|███████   | 173/247 [00:49<00:20,  3.59it/s]Loading train:  70%|███████   | 174/247 [00:49<00:20,  3.58it/s]Loading train:  71%|███████   | 175/247 [00:50<00:21,  3.40it/s]Loading train:  71%|███████▏  | 176/247 [00:50<00:20,  3.47it/s]Loading train:  72%|███████▏  | 177/247 [00:50<00:19,  3.51it/s]Loading train:  72%|███████▏  | 178/247 [00:51<00:19,  3.53it/s]Loading train:  72%|███████▏  | 179/247 [00:51<00:19,  3.53it/s]Loading train:  73%|███████▎  | 180/247 [00:51<00:18,  3.55it/s]Loading train:  73%|███████▎  | 181/247 [00:51<00:18,  3.57it/s]Loading train:  74%|███████▎  | 182/247 [00:52<00:18,  3.60it/s]Loading train:  74%|███████▍  | 183/247 [00:52<00:17,  3.62it/s]Loading train:  74%|███████▍  | 184/247 [00:52<00:17,  3.61it/s]Loading train:  75%|███████▍  | 185/247 [00:53<00:17,  3.63it/s]Loading train:  75%|███████▌  | 186/247 [00:53<00:16,  3.63it/s]Loading train:  76%|███████▌  | 187/247 [00:53<00:16,  3.61it/s]Loading train:  76%|███████▌  | 188/247 [00:53<00:16,  3.53it/s]Loading train:  77%|███████▋  | 189/247 [00:54<00:16,  3.53it/s]Loading train:  77%|███████▋  | 190/247 [00:54<00:16,  3.52it/s]Loading train:  77%|███████▋  | 191/247 [00:54<00:15,  3.54it/s]Loading train:  78%|███████▊  | 192/247 [00:55<00:15,  3.55it/s]Loading train:  78%|███████▊  | 193/247 [00:55<00:15,  3.54it/s]Loading train:  79%|███████▊  | 194/247 [00:55<00:14,  3.62it/s]Loading train:  79%|███████▉  | 195/247 [00:55<00:13,  3.72it/s]Loading train:  79%|███████▉  | 196/247 [00:56<00:13,  3.77it/s]Loading train:  80%|███████▉  | 197/247 [00:56<00:13,  3.79it/s]Loading train:  80%|████████  | 198/247 [00:56<00:13,  3.73it/s]Loading train:  81%|████████  | 199/247 [00:56<00:12,  3.76it/s]Loading train:  81%|████████  | 200/247 [00:57<00:12,  3.78it/s]Loading train:  81%|████████▏ | 201/247 [00:57<00:12,  3.81it/s]Loading train:  82%|████████▏ | 202/247 [00:57<00:11,  3.79it/s]Loading train:  82%|████████▏ | 203/247 [00:57<00:11,  3.79it/s]Loading train:  83%|████████▎ | 204/247 [00:58<00:11,  3.76it/s]Loading train:  83%|████████▎ | 205/247 [00:58<00:11,  3.76it/s]Loading train:  83%|████████▎ | 206/247 [00:58<00:10,  3.76it/s]Loading train:  84%|████████▍ | 207/247 [00:58<00:10,  3.77it/s]Loading train:  84%|████████▍ | 208/247 [00:59<00:10,  3.80it/s]Loading train:  85%|████████▍ | 209/247 [00:59<00:09,  3.82it/s]Loading train:  85%|████████▌ | 210/247 [00:59<00:09,  3.83it/s]Loading train:  85%|████████▌ | 211/247 [01:00<00:09,  3.85it/s]Loading train:  86%|████████▌ | 212/247 [01:00<00:09,  3.73it/s]Loading train:  86%|████████▌ | 213/247 [01:00<00:09,  3.70it/s]Loading train:  87%|████████▋ | 214/247 [01:00<00:08,  3.69it/s]Loading train:  87%|████████▋ | 215/247 [01:01<00:08,  3.56it/s]Loading train:  87%|████████▋ | 216/247 [01:01<00:08,  3.57it/s]Loading train:  88%|████████▊ | 217/247 [01:01<00:08,  3.61it/s]Loading train:  88%|████████▊ | 218/247 [01:01<00:08,  3.55it/s]Loading train:  89%|████████▊ | 219/247 [01:02<00:07,  3.51it/s]Loading train:  89%|████████▉ | 220/247 [01:02<00:07,  3.52it/s]Loading train:  89%|████████▉ | 221/247 [01:02<00:07,  3.52it/s]Loading train:  90%|████████▉ | 222/247 [01:03<00:07,  3.51it/s]Loading train:  90%|█████████ | 223/247 [01:03<00:06,  3.55it/s]Loading train:  91%|█████████ | 224/247 [01:03<00:06,  3.56it/s]Loading train:  91%|█████████ | 225/247 [01:03<00:06,  3.52it/s]Loading train:  91%|█████████▏| 226/247 [01:04<00:06,  3.46it/s]Loading train:  92%|█████████▏| 227/247 [01:04<00:05,  3.48it/s]Loading train:  92%|█████████▏| 228/247 [01:04<00:05,  3.53it/s]Loading train:  93%|█████████▎| 229/247 [01:05<00:05,  3.58it/s]Loading train:  93%|█████████▎| 230/247 [01:05<00:04,  3.45it/s]Loading train:  94%|█████████▎| 231/247 [01:05<00:04,  3.35it/s]Loading train:  94%|█████████▍| 232/247 [01:06<00:04,  3.29it/s]Loading train:  94%|█████████▍| 233/247 [01:06<00:04,  3.25it/s]Loading train:  95%|█████████▍| 234/247 [01:06<00:04,  3.22it/s]Loading train:  95%|█████████▌| 235/247 [01:07<00:03,  3.19it/s]Loading train:  96%|█████████▌| 236/247 [01:07<00:03,  3.11it/s]Loading train:  96%|█████████▌| 237/247 [01:07<00:03,  3.10it/s]Loading train:  96%|█████████▋| 238/247 [01:08<00:02,  3.09it/s]Loading train:  97%|█████████▋| 239/247 [01:08<00:02,  3.11it/s]Loading train:  97%|█████████▋| 240/247 [01:08<00:02,  3.11it/s]Loading train:  98%|█████████▊| 241/247 [01:08<00:01,  3.12it/s]Loading train:  98%|█████████▊| 242/247 [01:09<00:01,  3.11it/s]Loading train:  98%|█████████▊| 243/247 [01:09<00:01,  3.12it/s]Loading train:  99%|█████████▉| 244/247 [01:09<00:00,  3.13it/s]Loading train:  99%|█████████▉| 245/247 [01:10<00:00,  3.13it/s]Loading train: 100%|█████████▉| 246/247 [01:10<00:00,  3.14it/s]Loading train: 100%|██████████| 247/247 [01:10<00:00,  3.14it/s]Loading train: 100%|██████████| 247/247 [01:10<00:00,  3.48it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 43.48it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:05, 43.40it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:05, 43.49it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:05, 43.59it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 44.60it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 45.42it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 46.57it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 46.89it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:04, 47.24it/s]concatenating: train:  20%|██        | 50/247 [00:01<00:04, 47.82it/s]concatenating: train:  22%|██▏       | 55/247 [00:01<00:03, 48.01it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 47.51it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 46.24it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 45.36it/s]concatenating: train:  30%|███       | 75/247 [00:01<00:03, 45.11it/s]concatenating: train:  32%|███▏      | 80/247 [00:01<00:03, 44.14it/s]concatenating: train:  34%|███▍      | 85/247 [00:01<00:03, 43.58it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:03, 42.76it/s]concatenating: train:  38%|███▊      | 95/247 [00:02<00:03, 42.14it/s]concatenating: train:  40%|████      | 100/247 [00:02<00:03, 42.20it/s]concatenating: train:  43%|████▎     | 105/247 [00:02<00:03, 42.11it/s]concatenating: train:  45%|████▍     | 110/247 [00:02<00:03, 41.99it/s]concatenating: train:  47%|████▋     | 115/247 [00:02<00:03, 41.70it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:02, 42.33it/s]concatenating: train:  51%|█████     | 125/247 [00:02<00:02, 42.75it/s]concatenating: train:  53%|█████▎    | 130/247 [00:02<00:02, 43.27it/s]concatenating: train:  55%|█████▍    | 135/247 [00:03<00:02, 43.55it/s]concatenating: train:  57%|█████▋    | 140/247 [00:03<00:02, 45.09it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:02, 46.15it/s]concatenating: train:  61%|██████    | 150/247 [00:03<00:02, 47.21it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 47.36it/s]concatenating: train:  65%|██████▍   | 160/247 [00:03<00:01, 47.40it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 47.28it/s]concatenating: train:  69%|██████▉   | 170/247 [00:03<00:01, 47.19it/s]concatenating: train:  71%|███████   | 175/247 [00:03<00:01, 47.11it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 47.46it/s]concatenating: train:  75%|███████▍  | 185/247 [00:04<00:01, 47.49it/s]concatenating: train:  77%|███████▋  | 190/247 [00:04<00:01, 47.79it/s]concatenating: train:  79%|███████▉  | 195/247 [00:04<00:01, 48.22it/s]concatenating: train:  81%|████████▏ | 201/247 [00:04<00:00, 49.10it/s]concatenating: train:  84%|████████▍ | 207/247 [00:04<00:00, 49.58it/s]concatenating: train:  86%|████████▌ | 213/247 [00:04<00:00, 49.98it/s]concatenating: train:  89%|████████▊ | 219/247 [00:04<00:00, 49.38it/s]concatenating: train:  91%|█████████ | 224/247 [00:04<00:00, 49.17it/s]concatenating: train:  93%|█████████▎| 229/247 [00:04<00:00, 48.99it/s]concatenating: train:  95%|█████████▍| 234/247 [00:05<00:00, 46.46it/s]concatenating: train:  97%|█████████▋| 239/247 [00:05<00:00, 45.02it/s]concatenating: train:  99%|█████████▉| 244/247 [00:05<00:00, 44.13it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 45.66it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  2.59it/s]Loading test:  40%|████      | 2/5 [00:00<00:01,  2.68it/s]Loading test:  60%|██████    | 3/5 [00:01<00:00,  2.82it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  2.95it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  2.90it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  2.94it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 225.38it/s]
Epoch 00045: val_mDice did not improve from 0.30650
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
{'val_loss': [0.6757210859885583, 0.6558318993984125, 0.6473178634276757, 0.6594348702675257, 0.6389927206895291, 0.6413463216561538, 0.6448750771009005, 0.6582753963959522, 0.6039971128488199, 0.632245774452503, 0.6425216518915616, 0.45319440502386826, 0.618896606640938, 0.6298565558898144, 0.45233070850372314, 0.4033407675914275, 0.550407390563916, 0.34006058367399067, 0.39812031923196256, 0.42893245281317294, 0.45245918593345547, 0.34956062470491117, 0.40565634690798247, 0.23251409608966264, 0.4174911887981953, 0.421867678180719, 0.4807462833630733, 0.2933229909588893, 0.41606935476645446, 0.3664529231878427, 0.38807457675918555, 0.4692923487761082, 0.3416005827438755, 0.32960611027784836, 0.31698481757671404, 0.29426370056955, 0.32268940702749366, 0.21807172541052866, 0.2576160420639775, 0.31537682085465163, 0.26586811039119196, 0.2688304855941962, 0.19881437566035834, 0.32339039187018687, 0.24642962093154588], 'val_acc': [0.9429933260648679, 0.9449574993206904, 0.9479195979925302, 0.9470555064005729, 0.9474887358836639, 0.947567391089904, 0.9488294858198899, 0.9472210468390049, 0.9442166777757498, 0.9469474997275915, 0.942317083860055, 0.9474558585729355, 0.948669814146482, 0.9465107581554315, 0.9466939033606113, 0.9487214699769632, 0.9431788325309753, 0.9483551703966581, 0.9484737469599798, 0.948629895846049, 0.9474570292692918, 0.9480135226861025, 0.9475016395250956, 0.9476695305261856, 0.9480616603142176, 0.9483868708977332, 0.9444526617343609, 0.9479994391783689, 0.9481321007777483, 0.9460998360927289, 0.9460364396755512, 0.9471153861437088, 0.9470226428447626, 0.946306471641247, 0.9453954131175311, 0.9468570962930337, 0.9468981822331747, 0.9473807154557644, 0.9472562731840671, 0.9469979818050678, 0.9477763741444318, 0.9486381197587038, 0.9463053040015392, 0.9468113076992524, 0.9466281609657483], 'val_mDice': [0.27023777556725037, 0.2915409883627525, 0.30046378458157563, 0.28685874625658375, 0.30649714706799924, 0.30443611358984923, 0.3002269894648821, 0.28044796066406447, 0.28866289441402143, 0.2938644595635243, 0.26381385517426026, 0.29090487078214305, 0.2794246658300742, 0.2878412241354967, 0.29057592229965407, 0.28944843319746166, 0.27546313366828823, 0.2884495281256162, 0.2785738622530913, 0.2914379384273138, 0.27818429393646044, 0.28476013319614607, 0.2856410707418735, 0.266654508236127, 0.27481971795742327, 0.2797715228337508, 0.26466225202266985, 0.28226843858376527, 0.2821589704507437, 0.2785607133156214, 0.27800748287103116, 0.2718828381636204, 0.2763679123077637, 0.2843058120745879, 0.26755205006935656, 0.2829641783848787, 0.27965065913322645, 0.2753778073268059, 0.2827864870046958, 0.27763275190805775, 0.283355665130493, 0.2821878588352448, 0.2775381620113666, 0.2774471166806343, 0.27809190902954495], 'loss': [0.5559281178483143, 0.3913725054293209, 0.3539527318520454, 0.3340011308291777, 0.32361983829761415, 0.3109108564045087, 0.30460758344762723, 0.29306587828043124, 0.29490691201696234, 0.281722289423264, 0.2843987639949481, 0.27603454748341805, 0.2765201169184613, 0.272063647443879, 0.2610261597349814, 0.2579277864816605, 0.2656673816976898, 0.25798672722736293, 0.2591569904839401, 0.2522938667283528, 0.23862260657664833, 0.2367476246691191, 0.23705946767079308, 0.23683278681190706, 0.2329779166634423, 0.2296016593170237, 0.22645913993011108, 0.22688577831969756, 0.22558254455675011, 0.22636023026962618, 0.22285213707794305, 0.22635368191482588, 0.22286862647898303, 0.22258287005919125, 0.21998698614598688, 0.21562098417237507, 0.21460792832159695, 0.2144857394554648, 0.21114403511135138, 0.2123799953720169, 0.20937395199558437, 0.2117200395590644, 0.2107509293374023, 0.2086983885268043, 0.21049715197197827], 'acc': [0.9065820685066088, 0.9409837273320403, 0.945426491251001, 0.9477351884467402, 0.9492492335726267, 0.950802331491996, 0.9517493725063723, 0.9527556617792867, 0.9526812317191712, 0.9539735158098683, 0.9538446068130247, 0.9546772885086914, 0.9546156326254011, 0.9556401693259685, 0.956436792910194, 0.9566985541290071, 0.9562105082125121, 0.9568475130159526, 0.957234753661815, 0.957403884049062, 0.9587401353992353, 0.9589715802285633, 0.9592057009320518, 0.9595990486816007, 0.9595535233266829, 0.959789833482539, 0.9599669690542133, 0.960157706033336, 0.9602917009109974, 0.9602174884594643, 0.9605808359350962, 0.960379028037778, 0.9606059934282318, 0.9604595415028898, 0.9606403272619966, 0.9610354996586545, 0.9614725222317974, 0.9615517961116106, 0.961739076724505, 0.9618094923050526, 0.961772337972402, 0.9618253576437514, 0.9619225386935195, 0.961951883582408, 0.9619998649730352], 'mDice': [0.401494421002297, 0.5782027198418457, 0.6185744460159412, 0.6401071897068951, 0.6513038941898867, 0.6650143019298347, 0.6718186968849422, 0.6842765335145241, 0.6822777225267039, 0.696507297973347, 0.6936266188578951, 0.7026425176883608, 0.7021136104091344, 0.7069075935856672, 0.7188291727755374, 0.7221583370663734, 0.7137885337707556, 0.7221016909062818, 0.7208304772507259, 0.7282493988871385, 0.7430104048235129, 0.7450385939392024, 0.7446884744630279, 0.7449177236064916, 0.749087430697494, 0.7527443500466701, 0.7561385357325433, 0.7556630451489944, 0.7570823725142303, 0.7562431582597228, 0.7600203211711183, 0.7562455029223573, 0.7600048150883457, 0.7603193467970114, 0.7631208680871823, 0.7678386428579411, 0.7689153749766163, 0.76904287261225, 0.7726577768189986, 0.7713156331927202, 0.7745794234335112, 0.7720333046570558, 0.7730751797653483, 0.7752909739144944, 0.7733467239947891], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________2020-01-21 19:47:28.391403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 19:47:28.391500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 19:47:28.391514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 19:47:28.391522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 19:47:28.391825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [0.97426102 0.02573898]
Train on 25213 samples, validate on 542 samples
Epoch 1/300
 - 67s - loss: 0.0757 - acc: 0.9919 - mDice: 0.8527 - val_loss: -5.6698e-02 - val_acc: 0.9936 - val_mDice: 0.5037

Epoch 00001: val_mDice improved from -inf to 0.50368, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 63s - loss: 0.0502 - acc: 0.9944 - mDice: 0.9024 - val_loss: -3.4286e-02 - val_acc: 0.9933 - val_mDice: 0.5034

Epoch 00002: val_mDice did not improve from 0.50368
Epoch 3/300
 - 64s - loss: 0.0454 - acc: 0.9949 - mDice: 0.9118 - val_loss: -3.6546e-02 - val_acc: 0.9926 - val_mDice: 0.4802

Epoch 00003: val_mDice did not improve from 0.50368
Epoch 4/300
 - 64s - loss: 0.0423 - acc: 0.9952 - mDice: 0.9178 - val_loss: -6.4878e-02 - val_acc: 0.9935 - val_mDice: 0.4987

Epoch 00004: val_mDice did not improve from 0.50368
Epoch 5/300
 - 64s - loss: 0.0399 - acc: 0.9954 - mDice: 0.9225 - val_loss: -8.8339e-02 - val_acc: 0.9935 - val_mDice: 0.4933

Epoch 00005: val_mDice did not improve from 0.50368
Epoch 6/300
 - 64s - loss: 0.0384 - acc: 0.9955 - mDice: 0.9254 - val_loss: -7.1347e-02 - val_acc: 0.9943 - val_mDice: 0.5099

Epoch 00006: val_mDice improved from 0.50368 to 0.50989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 7/300
 - 63s - loss: 0.0377 - acc: 0.9957 - mDice: 0.9268 - val_loss: -4.4168e-02 - val_acc: 0.9931 - val_mDice: 0.4868

Epoch 00007: val_mDice did not improve from 0.50989
Epoch 8/300
 - 64s - loss: 0.0362 - acc: 0.9958 - mDice: 0.9296 - val_loss: -5.6670e-02 - val_acc: 0.9936 - val_mDice: 0.4897

Epoch 00008: val_mDice did not improve from 0.50989
Epoch 9/300
 - 64s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9321 - val_loss: -4.4041e-02 - val_acc: 0.9936 - val_mDice: 0.4899

Epoch 00009: val_mDice did not improve from 0.50989
Epoch 10/300
 - 64s - loss: 0.0343 - acc: 0.9959 - mDice: 0.9334 - val_loss: -8.0884e-02 - val_acc: 0.9940 - val_mDice: 0.4941

Epoch 00010: val_mDice did not improve from 0.50989
Epoch 11/300
 - 65s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9341 - val_loss: -7.7850e-02 - val_acc: 0.9938 - val_mDice: 0.4901

Epoch 00011: val_mDice did not improve from 0.50989
Epoch 12/300
 - 64s - loss: 0.0334 - acc: 0.9960 - mDice: 0.9352 - val_loss: -5.5275e-02 - val_acc: 0.9932 - val_mDice: 0.4905

Epoch 00012: val_mDice did not improve from 0.50989
Epoch 13/300
 - 63s - loss: 0.0327 - acc: 0.9961 - mDice: 0.9365 - val_loss: -4.9742e-02 - val_acc: 0.9938 - val_mDice: 0.4965

Epoch 00013: val_mDice did not improve from 0.50989
Epoch 14/300
 - 64s - loss: 0.0325 - acc: 0.9961 - mDice: 0.9370 - val_loss: -4.9488e-02 - val_acc: 0.9931 - val_mDice: 0.4681

Epoch 00014: val_mDice did not improve from 0.50989
Epoch 15/300
 - 65s - loss: 0.0317 - acc: 0.9962 - mDice: 0.9385 - val_loss: -4.3283e-02 - val_acc: 0.9930 - val_mDice: 0.4809

Epoch 00015: val_mDice did not improve from 0.50989
Epoch 16/300
 - 64s - loss: 0.0313 - acc: 0.9962 - mDice: 0.9393 - val_loss: -6.1029e-02 - val_acc: 0.9936 - val_mDice: 0.4909

Epoch 00016: val_mDice did not improve from 0.50989
Epoch 17/300
 - 64s - loss: 0.0309 - acc: 0.9962 - mDice: 0.9401 - val_loss: 3.2222e-04 - val_acc: 0.9934 - val_mDice: 0.5016

Epoch 00017: val_mDice did not improve from 0.50989
Epoch 18/300
 - 63s - loss: 0.0308 - acc: 0.9962 - mDice: 0.9402 - val_loss: -4.2242e-02 - val_acc: 0.9930 - val_mDice: 0.4911

Epoch 00018: val_mDice did not improve from 0.50989
Epoch 19/300
 - 63s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9406 - val_loss: -7.6346e-02 - val_acc: 0.9929 - val_mDice: 0.4851

Epoch 00019: val_mDice did not improve from 0.50989
Epoch 20/300
 - 63s - loss: 0.0302 - acc: 0.9963 - mDice: 0.9414 - val_loss: -8.0436e-02 - val_acc: 0.9935 - val_mDice: 0.4930

Epoch 00020: val_mDice did not improve from 0.50989
Epoch 21/300
 - 63s - loss: 0.0298 - acc: 0.9963 - mDice: 0.9423 - val_loss: -8.0435e-02 - val_acc: 0.9927 - val_mDice: 0.4953

Epoch 00021: val_mDice did not improve from 0.50989

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 22/300
 - 64s - loss: 0.0288 - acc: 0.9964 - mDice: 0.9442 - val_loss: -6.3643e-02 - val_acc: 0.9934 - val_mDice: 0.4982

Epoch 00022: val_mDice did not improve from 0.50989
Epoch 23/300
 - 63s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9452 - val_loss: -6.6078e-02 - val_acc: 0.9938 - val_mDice: 0.5018

Epoch 00023: val_mDice did not improve from 0.50989
Epoch 24/300
 - 64s - loss: 0.0280 - acc: 0.9965 - mDice: 0.9456 - val_loss: -7.8003e-02 - val_acc: 0.9931 - val_mDice: 0.4848

Epoch 00024: val_mDice did not improve from 0.50989
Epoch 25/300
 - 64s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9464 - val_loss: -5.5542e-02 - val_acc: 0.9932 - val_mDice: 0.4842

Epoch 00025: val_mDice did not improve from 0.50989
Epoch 26/300
 - 64s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9463 - val_loss: -7.1021e-02 - val_acc: 0.9926 - val_mDice: 0.4747

Epoch 00026: val_mDice did not improve from 0.50989
Epoch 27/300
 - 63s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9466 - val_loss: -7.7354e-02 - val_acc: 0.9932 - val_mDice: 0.4825

Epoch 00027: val_mDice did not improve from 0.50989
Epoch 28/300
 - 63s - loss: 0.0273 - acc: 0.9965 - mDice: 0.9470 - val_loss: -8.4717e-02 - val_acc: 0.9933 - val_mDice: 0.4870

Epoch 00028: val_mDice did not improve from 0.50989
Epoch 29/300
 - 63s - loss: 0.0272 - acc: 0.9965 - mDice: 0.9474 - val_loss: -8.8769e-02 - val_acc: 0.9930 - val_mDice: 0.4791

Epoch 00029: val_mDice did not improve from 0.50989
Epoch 30/300
 - 63s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9468 - val_loss: -5.3282e-02 - val_acc: 0.9935 - val_mDice: 0.4836

Epoch 00030: val_mDice did not improve from 0.50989
Epoch 31/300
 - 63s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9479 - val_loss: -8.4274e-02 - val_acc: 0.9930 - val_mDice: 0.4747

Epoch 00031: val_mDice did not improve from 0.50989
Epoch 32/300
 - 63s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9483 - val_loss: -7.6144e-02 - val_acc: 0.9917 - val_mDice: 0.4489

Epoch 00032: val_mDice did not improve from 0.50989
Epoch 33/300
 - 63s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9483 - val_loss: -6.7018e-02 - val_acc: 0.9927 - val_mDice: 0.4677

Epoch 00033: val_mDice did not improve from 0.50989
Epoch 34/300
 - 63s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9468 - val_loss: -5.4340e-02 - val_acc: 0.9930 - val_mDice: 0.4779

Epoch 00034: val_mDice did not improve from 0.50989
Epoch 35/300
 - 64s - loss: 0.0268 - acc: 0.9966 - mDice: 0.9480 - val_loss: -6.6428e-02 - val_acc: 0.9936 - val_mDice: 0.5018

Epoch 00035: val_mDice did not improve from 0.50989
Epoch 36/300
 - 64s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9488 - val_loss: -9.3239e-02 - val_acc: 0.9933 - val_mDice: 0.4862

Epoch 00036: val_mDice did not improve from 0.50989

Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 37/300
 - 63s - loss: 0.0259 - acc: 0.9966 - mDice: 0.9499 - val_loss: -8.9728e-02 - val_acc: 0.9936 - val_mDice: 0.4983

Epoch 00037: val_mDice did not improve from 0.50989
Epoch 38/300
 - 64s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9495 - val_loss: -7.5271e-02 - val_acc: 0.9934 - val_mDice: 0.4844

Epoch 00038: val_mDice did not improve from 0.50989
Epoch 39/300
 - 63s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9503 - val_loss: -6.5714e-02 - val_acc: 0.9935 - val_mDice: 0.4859

Epoch 00039: val_mDice did not improve from 0.50989
Epoch 40/300
 - 64s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9506 - val_loss: -5.4854e-02 - val_acc: 0.9932 - val_mDice: 0.4792

Epoch 00040: val_mDice did not improve from 0.50989
Epoch 41/300
 - 64s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9495 - val_loss: -7.7523e-02 - val_acc: 0.9937 - val_mDice: 0.4912

Epoch 00041: val_mDice did not improve from 0.50989
Epoch 42/300
 - 64s - loss: 0.0258 - acc: 0.9967 - mDice: 0.9499 - val_loss: -6.5800e-02 - val_acc: 0.9938 - val_mDice: 0.4920

Epoch 00042: val_mDice did not improve from 0.50989
Epoch 43/300
 - 64s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9508 - val_loss: -5.7249e-02 - val_acc: 0.9935 - val_mDice: 0.4848

Epoch 00043: val_mDice did not improve from 0.50989
Epoch 44/300
 - 64s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: -8.0416e-02 - val_acc: 0.9935 - val_mDice: 0.4934

Epoch 00044: val_mDice did not improve from 0.50989
Epoch 45/300
 - 64s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9511 - val_loss: -6.2199e-02 - val_acc: 0.9936 - val_mDice: 0.4864

Epoch 00045: val_mDice did not improve from 0.50989
Epoch 46/300
 - 64s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9505 - val_loss: -5.0130e-02 - val_acc: 0.9934 - val_mDice: 0.4813

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.32it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.67it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.09it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.62it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.94it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.15it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:51,  4.77it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:48,  5.03it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:49,  4.91it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:46,  5.27it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:43,  5.58it/s]predicting train subjects:   2%|▏         | 6/247 [00:01<00:41,  5.81it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:40,  5.97it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:39,  6.06it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:38,  6.18it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:37,  6.28it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:37,  6.34it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:36,  6.41it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:36,  6.39it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:36,  6.38it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:36,  6.41it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:36,  6.41it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:36,  6.39it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:35,  6.40it/s]predicting train subjects:   8%|▊         | 19/247 [00:03<00:35,  6.40it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:35,  6.39it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:35,  6.39it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:35,  6.38it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:33,  6.63it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:32,  6.83it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:31,  6.95it/s]predicting train subjects:  11%|█         | 26/247 [00:04<00:31,  7.03it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:31,  7.08it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:30,  7.17it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:30,  7.21it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:30,  7.20it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:29,  7.21it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:29,  7.22it/s]predicting train subjects:  13%|█▎        | 33/247 [00:05<00:29,  7.25it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:29,  7.30it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:29,  7.27it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:29,  7.21it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:29,  7.13it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:28,  7.21it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:28,  7.22it/s]predicting train subjects:  16%|█▌        | 40/247 [00:06<00:28,  7.17it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:29,  6.93it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:29,  6.96it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:29,  6.82it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:29,  6.77it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:29,  6.85it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:28,  6.93it/s]predicting train subjects:  19%|█▉        | 47/247 [00:07<00:28,  7.00it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:28,  6.92it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:28,  6.91it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:28,  6.90it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:28,  6.93it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:28,  6.90it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:28,  6.86it/s]predicting train subjects:  22%|██▏       | 54/247 [00:08<00:28,  6.86it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:27,  6.93it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:27,  6.98it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:27,  7.00it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:26,  7.02it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:27,  6.82it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:27,  6.69it/s]predicting train subjects:  25%|██▍       | 61/247 [00:09<00:28,  6.57it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:28,  6.50it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:28,  6.44it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:28,  6.41it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:28,  6.39it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:28,  6.34it/s]predicting train subjects:  27%|██▋       | 67/247 [00:10<00:28,  6.33it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:29,  6.13it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:28,  6.18it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:28,  6.16it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:28,  6.18it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:28,  6.20it/s]predicting train subjects:  30%|██▉       | 73/247 [00:11<00:28,  6.12it/s]predicting train subjects:  30%|██▉       | 74/247 [00:11<00:28,  6.12it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:28,  6.12it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:27,  6.14it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:30,  5.51it/s]predicting train subjects:  32%|███▏      | 78/247 [00:12<00:33,  5.01it/s]predicting train subjects:  32%|███▏      | 79/247 [00:12<00:34,  4.82it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:31,  5.33it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:31,  5.22it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:30,  5.36it/s]predicting train subjects:  34%|███▎      | 83/247 [00:12<00:29,  5.61it/s]predicting train subjects:  34%|███▍      | 84/247 [00:13<00:28,  5.81it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:28,  5.70it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:28,  5.68it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:27,  5.85it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:26,  5.95it/s]predicting train subjects:  36%|███▌      | 89/247 [00:13<00:26,  5.96it/s]predicting train subjects:  36%|███▋      | 90/247 [00:14<00:26,  6.01it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:25,  6.07it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:25,  6.15it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:25,  6.14it/s]predicting train subjects:  38%|███▊      | 94/247 [00:14<00:24,  6.12it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:24,  6.18it/s]predicting train subjects:  39%|███▉      | 96/247 [00:15<00:24,  6.09it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:24,  6.16it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:24,  6.20it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:23,  6.20it/s]predicting train subjects:  40%|████      | 100/247 [00:15<00:24,  6.08it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:24,  5.93it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:25,  5.80it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:24,  5.79it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:24,  5.76it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:24,  5.72it/s]predicting train subjects:  43%|████▎     | 106/247 [00:16<00:25,  5.58it/s]predicting train subjects:  43%|████▎     | 107/247 [00:16<00:25,  5.56it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:25,  5.56it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:24,  5.56it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:24,  5.60it/s]predicting train subjects:  45%|████▍     | 111/247 [00:17<00:24,  5.63it/s]predicting train subjects:  45%|████▌     | 112/247 [00:17<00:24,  5.57it/s]predicting train subjects:  46%|████▌     | 113/247 [00:18<00:24,  5.50it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:24,  5.48it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:24,  5.48it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:24,  5.36it/s]predicting train subjects:  47%|████▋     | 117/247 [00:18<00:24,  5.34it/s]predicting train subjects:  48%|████▊     | 118/247 [00:18<00:23,  5.40it/s]predicting train subjects:  48%|████▊     | 119/247 [00:19<00:22,  5.57it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:22,  5.59it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:22,  5.66it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:21,  5.74it/s]predicting train subjects:  50%|████▉     | 123/247 [00:19<00:21,  5.79it/s]predicting train subjects:  50%|█████     | 124/247 [00:20<00:21,  5.83it/s]predicting train subjects:  51%|█████     | 125/247 [00:20<00:20,  5.89it/s]predicting train subjects:  51%|█████     | 126/247 [00:20<00:20,  5.93it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:20,  5.97it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:19,  6.04it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:20<00:19,  6.08it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:20<00:19,  6.09it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:21<00:18,  6.13it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:21<00:18,  6.10it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:21<00:18,  6.07it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:19,  5.90it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:21<00:18,  6.00it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:21<00:17,  6.29it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:22<00:16,  6.54it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:22<00:16,  6.72it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:22<00:15,  6.81it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:22<00:15,  6.89it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:15,  6.92it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:15,  6.94it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:22<00:14,  6.97it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:23<00:14,  7.01it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:23<00:14,  7.03it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:23<00:14,  7.05it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:23<00:14,  7.06it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:13,  7.10it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:13,  7.18it/s]predicting train subjects:  61%|██████    | 150/247 [00:23<00:13,  7.20it/s]predicting train subjects:  61%|██████    | 151/247 [00:24<00:13,  7.18it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:24<00:13,  7.17it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:24<00:13,  7.16it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:24<00:13,  7.05it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:24<00:13,  6.94it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:24<00:13,  6.79it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:24<00:13,  6.73it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:25<00:13,  6.75it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:25<00:13,  6.69it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:25<00:13,  6.61it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:25<00:13,  6.59it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:25<00:13,  6.54it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:25<00:12,  6.57it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:26<00:12,  6.56it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:26<00:12,  6.57it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:26<00:12,  6.57it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:26<00:12,  6.63it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:26<00:11,  6.63it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:26<00:11,  6.59it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:26<00:11,  6.54it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:27<00:11,  6.56it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:27<00:11,  6.57it/s]predicting train subjects:  70%|███████   | 173/247 [00:27<00:12,  5.79it/s]predicting train subjects:  70%|███████   | 174/247 [00:27<00:12,  6.01it/s]predicting train subjects:  71%|███████   | 175/247 [00:27<00:13,  5.46it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:27<00:12,  5.79it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:28<00:11,  6.01it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:28<00:11,  6.14it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:28<00:10,  6.26it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:28<00:10,  6.36it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:28<00:10,  6.44it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:28<00:10,  6.49it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:29<00:09,  6.52it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:29<00:09,  6.55it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:29<00:09,  6.59it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:29<00:09,  6.56it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:29<00:09,  6.47it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:29<00:09,  6.46it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:29<00:08,  6.50it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:30<00:08,  6.46it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:30<00:08,  6.50it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:30<00:08,  6.55it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:30<00:08,  6.56it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:30<00:07,  6.74it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:30<00:07,  6.87it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:30<00:07,  6.96it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:31<00:07,  7.08it/s]predicting train subjects:  80%|████████  | 198/247 [00:31<00:06,  7.04it/s]predicting train subjects:  81%|████████  | 199/247 [00:31<00:06,  7.09it/s]predicting train subjects:  81%|████████  | 200/247 [00:31<00:06,  7.10it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:31<00:06,  7.17it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:31<00:06,  7.26it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:31<00:06,  7.21it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:32<00:06,  7.14it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:32<00:05,  7.10it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:32<00:05,  7.17it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:32<00:05,  7.21it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:32<00:05,  7.13it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:32<00:05,  7.16it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:32<00:05,  7.12it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:33<00:05,  7.12it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:33<00:04,  7.04it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:33<00:04,  6.98it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:33<00:04,  6.86it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:33<00:04,  6.86it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:33<00:04,  6.78it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:33<00:04,  6.77it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:34<00:04,  6.80it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:34<00:04,  6.81it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:34<00:03,  6.84it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:34<00:03,  6.83it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:34<00:03,  6.86it/s]predicting train subjects:  90%|█████████ | 223/247 [00:34<00:03,  6.82it/s]predicting train subjects:  91%|█████████ | 224/247 [00:34<00:03,  6.83it/s]predicting train subjects:  91%|█████████ | 225/247 [00:35<00:03,  6.72it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:35<00:03,  6.76it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:35<00:02,  6.78it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:35<00:02,  6.78it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:35<00:02,  6.83it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:35<00:02,  6.49it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:36<00:02,  6.24it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:36<00:02,  6.10it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:36<00:02,  6.03it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:36<00:02,  5.99it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:36<00:02,  5.94it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:36<00:01,  5.82it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:37<00:01,  5.85it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:37<00:01,  5.77it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:37<00:01,  5.65it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:37<00:01,  5.72it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:37<00:01,  5.71it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:37<00:00,  5.74it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:38<00:00,  5.75it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:38<00:00,  5.78it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:38<00:00,  5.78it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:38<00:00,  5.76it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  5.81it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  6.36it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 66.75it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/247 [00:00<00:03, 79.44it/s]saving BB  train1-THALAMUS:   7%|▋         | 17/247 [00:00<00:02, 80.41it/s]saving BB  train1-THALAMUS:  11%|█         | 26/247 [00:00<00:02, 81.93it/s]saving BB  train1-THALAMUS:  14%|█▍        | 35/247 [00:00<00:02, 84.19it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 87.19it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 88.46it/s]saving BB  train1-THALAMUS:  26%|██▌       | 64/247 [00:00<00:02, 86.49it/s]saving BB  train1-THALAMUS:  30%|██▉       | 73/247 [00:00<00:02, 83.74it/s]saving BB  train1-THALAMUS:  33%|███▎      | 82/247 [00:00<00:01, 82.87it/s]saving BB  train1-THALAMUS:  37%|███▋      | 91/247 [00:01<00:01, 82.67it/s]saving BB  train1-THALAMUS:  40%|████      | 100/247 [00:01<00:01, 80.17it/s]saving BB  train1-THALAMUS:  44%|████▎     | 108/247 [00:01<00:01, 77.14it/s]saving BB  train1-THALAMUS:  47%|████▋     | 116/247 [00:01<00:01, 76.82it/s]saving BB  train1-THALAMUS:  50%|█████     | 124/247 [00:01<00:01, 77.02it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 132/247 [00:01<00:01, 76.87it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 141/247 [00:01<00:01, 78.16it/s]saving BB  train1-THALAMUS:  60%|██████    | 149/247 [00:01<00:01, 77.91it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 158/247 [00:01<00:01, 80.49it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 167/247 [00:02<00:00, 82.34it/s]saving BB  train1-THALAMUS:  71%|███████▏  | 176/247 [00:02<00:00, 83.33it/s]saving BB  train1-THALAMUS:  75%|███████▍  | 185/247 [00:02<00:00, 81.74it/s]saving BB  train1-THALAMUS:  79%|███████▊  | 194/247 [00:02<00:00, 77.50it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 202/247 [00:02<00:00, 77.81it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 211/247 [00:02<00:00, 78.79it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 220/247 [00:02<00:00, 81.54it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 229/247 [00:02<00:00, 83.88it/s]saving BB  train1-THALAMUS:  96%|█████████▋| 238/247 [00:02<00:00, 80.86it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 76.37it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 80.73it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<04:11,  1.02s/it]Loading train:   1%|          | 2/247 [00:01<03:58,  1.03it/s]Loading train:   1%|          | 3/247 [00:02<03:44,  1.09it/s]Loading train:   2%|▏         | 4/247 [00:03<03:51,  1.05it/s]Loading train:   2%|▏         | 5/247 [00:04<03:34,  1.13it/s]Loading train:   2%|▏         | 6/247 [00:05<03:18,  1.22it/s]Loading train:   3%|▎         | 7/247 [00:05<03:09,  1.26it/s]Loading train:   3%|▎         | 8/247 [00:06<03:03,  1.30it/s]Loading train:   4%|▎         | 9/247 [00:07<02:56,  1.35it/s]Loading train:   4%|▍         | 10/247 [00:07<02:49,  1.39it/s]Loading train:   4%|▍         | 11/247 [00:08<02:46,  1.41it/s]Loading train:   5%|▍         | 12/247 [00:09<02:44,  1.43it/s]Loading train:   5%|▌         | 13/247 [00:09<02:42,  1.44it/s]Loading train:   6%|▌         | 14/247 [00:10<02:39,  1.46it/s]Loading train:   6%|▌         | 15/247 [00:11<02:37,  1.47it/s]Loading train:   6%|▋         | 16/247 [00:11<02:34,  1.50it/s]Loading train:   7%|▋         | 17/247 [00:12<02:36,  1.47it/s]Loading train:   7%|▋         | 18/247 [00:13<02:34,  1.48it/s]Loading train:   8%|▊         | 19/247 [00:13<02:32,  1.49it/s]Loading train:   8%|▊         | 20/247 [00:14<02:31,  1.50it/s]Loading train:   9%|▊         | 21/247 [00:15<02:31,  1.49it/s]Loading train:   9%|▉         | 22/247 [00:15<02:29,  1.51it/s]Loading train:   9%|▉         | 23/247 [00:16<02:24,  1.55it/s]Loading train:  10%|▉         | 24/247 [00:17<02:19,  1.59it/s]Loading train:  10%|█         | 25/247 [00:17<02:15,  1.64it/s]Loading train:  11%|█         | 26/247 [00:18<02:12,  1.67it/s]Loading train:  11%|█         | 27/247 [00:18<02:11,  1.67it/s]Loading train:  11%|█▏        | 28/247 [00:19<02:09,  1.69it/s]Loading train:  12%|█▏        | 29/247 [00:20<02:08,  1.70it/s]Loading train:  12%|█▏        | 30/247 [00:20<02:06,  1.71it/s]Loading train:  13%|█▎        | 31/247 [00:21<02:04,  1.74it/s]Loading train:  13%|█▎        | 32/247 [00:21<02:03,  1.74it/s]Loading train:  13%|█▎        | 33/247 [00:22<02:02,  1.75it/s]Loading train:  14%|█▍        | 34/247 [00:22<02:02,  1.73it/s]Loading train:  14%|█▍        | 35/247 [00:23<02:03,  1.71it/s]Loading train:  15%|█▍        | 36/247 [00:24<02:05,  1.68it/s]Loading train:  15%|█▍        | 37/247 [00:24<02:05,  1.67it/s]Loading train:  15%|█▌        | 38/247 [00:25<02:04,  1.68it/s]Loading train:  16%|█▌        | 39/247 [00:25<02:03,  1.68it/s]Loading train:  16%|█▌        | 40/247 [00:26<02:03,  1.68it/s]Loading train:  17%|█▋        | 41/247 [00:27<02:03,  1.67it/s]Loading train:  17%|█▋        | 42/247 [00:27<02:03,  1.67it/s]Loading train:  17%|█▋        | 43/247 [00:28<02:02,  1.66it/s]Loading train:  18%|█▊        | 44/247 [00:28<02:01,  1.67it/s]Loading train:  18%|█▊        | 45/247 [00:29<02:00,  1.68it/s]Loading train:  19%|█▊        | 46/247 [00:30<01:59,  1.68it/s]Loading train:  19%|█▉        | 47/247 [00:30<01:59,  1.68it/s]Loading train:  19%|█▉        | 48/247 [00:31<02:02,  1.63it/s]Loading train:  20%|█▉        | 49/247 [00:31<02:02,  1.62it/s]Loading train:  20%|██        | 50/247 [00:32<02:03,  1.60it/s]Loading train:  21%|██        | 51/247 [00:33<02:03,  1.59it/s]Loading train:  21%|██        | 52/247 [00:33<02:04,  1.57it/s]Loading train:  21%|██▏       | 53/247 [00:34<02:04,  1.56it/s]Loading train:  22%|██▏       | 54/247 [00:35<02:03,  1.56it/s]Loading train:  22%|██▏       | 55/247 [00:35<02:02,  1.57it/s]Loading train:  23%|██▎       | 56/247 [00:36<02:00,  1.59it/s]Loading train:  23%|██▎       | 57/247 [00:37<01:58,  1.61it/s]Loading train:  23%|██▎       | 58/247 [00:37<01:57,  1.60it/s]Loading train:  24%|██▍       | 59/247 [00:38<02:05,  1.50it/s]Loading train:  24%|██▍       | 60/247 [00:39<02:06,  1.48it/s]Loading train:  25%|██▍       | 61/247 [00:39<02:06,  1.47it/s]Loading train:  25%|██▌       | 62/247 [00:40<02:07,  1.46it/s]Loading train:  26%|██▌       | 63/247 [00:41<02:06,  1.45it/s]Loading train:  26%|██▌       | 64/247 [00:41<02:06,  1.44it/s]Loading train:  26%|██▋       | 65/247 [00:42<02:04,  1.46it/s]Loading train:  27%|██▋       | 66/247 [00:43<02:04,  1.46it/s]Loading train:  27%|██▋       | 67/247 [00:43<02:02,  1.47it/s]Loading train:  28%|██▊       | 68/247 [00:44<02:01,  1.48it/s]Loading train:  28%|██▊       | 69/247 [00:45<02:00,  1.48it/s]Loading train:  28%|██▊       | 70/247 [00:45<01:59,  1.48it/s]Loading train:  29%|██▊       | 71/247 [00:46<01:59,  1.47it/s]Loading train:  29%|██▉       | 72/247 [00:47<01:59,  1.47it/s]Loading train:  30%|██▉       | 73/247 [00:47<01:57,  1.48it/s]Loading train:  30%|██▉       | 74/247 [00:48<01:57,  1.47it/s]Loading train:  30%|███       | 75/247 [00:49<02:00,  1.42it/s]Loading train:  31%|███       | 76/247 [00:50<01:58,  1.44it/s]Loading train:  31%|███       | 77/247 [00:51<02:14,  1.27it/s]Loading train:  32%|███▏      | 78/247 [00:52<02:28,  1.14it/s]Loading train:  32%|███▏      | 79/247 [00:53<02:36,  1.07it/s]Loading train:  32%|███▏      | 80/247 [00:54<02:30,  1.11it/s]Loading train:  33%|███▎      | 81/247 [00:54<02:29,  1.11it/s]Loading train:  33%|███▎      | 82/247 [00:55<02:18,  1.19it/s]Loading train:  34%|███▎      | 83/247 [00:56<02:11,  1.25it/s]Loading train:  34%|███▍      | 84/247 [00:57<02:08,  1.27it/s]Loading train:  34%|███▍      | 85/247 [00:57<02:03,  1.31it/s]Loading train:  35%|███▍      | 86/247 [00:58<01:59,  1.34it/s]Loading train:  35%|███▌      | 87/247 [00:59<01:57,  1.36it/s]Loading train:  36%|███▌      | 88/247 [00:59<01:55,  1.38it/s]Loading train:  36%|███▌      | 89/247 [01:00<01:55,  1.37it/s]Loading train:  36%|███▋      | 90/247 [01:01<01:56,  1.35it/s]Loading train:  37%|███▋      | 91/247 [01:02<01:53,  1.38it/s]Loading train:  37%|███▋      | 92/247 [01:02<01:50,  1.40it/s]Loading train:  38%|███▊      | 93/247 [01:03<01:49,  1.41it/s]Loading train:  38%|███▊      | 94/247 [01:04<01:48,  1.41it/s]Loading train:  38%|███▊      | 95/247 [01:04<01:47,  1.42it/s]Loading train:  39%|███▉      | 96/247 [01:05<01:49,  1.38it/s]Loading train:  39%|███▉      | 97/247 [01:06<01:46,  1.41it/s]Loading train:  40%|███▉      | 98/247 [01:07<01:46,  1.40it/s]Loading train:  40%|████      | 99/247 [01:07<01:45,  1.40it/s]Loading train:  40%|████      | 100/247 [01:08<01:46,  1.38it/s]Loading train:  41%|████      | 101/247 [01:09<01:46,  1.37it/s]Loading train:  41%|████▏     | 102/247 [01:10<01:46,  1.36it/s]Loading train:  42%|████▏     | 103/247 [01:10<01:45,  1.36it/s]Loading train:  42%|████▏     | 104/247 [01:11<01:45,  1.36it/s]Loading train:  43%|████▎     | 105/247 [01:12<01:44,  1.35it/s]Loading train:  43%|████▎     | 106/247 [01:13<01:43,  1.36it/s]Loading train:  43%|████▎     | 107/247 [01:13<01:41,  1.39it/s]Loading train:  44%|████▎     | 108/247 [01:14<01:39,  1.39it/s]Loading train:  44%|████▍     | 109/247 [01:15<01:39,  1.39it/s]Loading train:  45%|████▍     | 110/247 [01:15<01:38,  1.39it/s]Loading train:  45%|████▍     | 111/247 [01:16<01:37,  1.39it/s]Loading train:  45%|████▌     | 112/247 [01:17<01:35,  1.41it/s]Loading train:  46%|████▌     | 113/247 [01:17<01:35,  1.40it/s]Loading train:  46%|████▌     | 114/247 [01:18<01:34,  1.40it/s]Loading train:  47%|████▋     | 115/247 [01:19<01:32,  1.42it/s]Loading train:  47%|████▋     | 116/247 [01:20<01:31,  1.42it/s]Loading train:  47%|████▋     | 117/247 [01:20<01:31,  1.43it/s]Loading train:  48%|████▊     | 118/247 [01:21<01:31,  1.42it/s]Loading train:  48%|████▊     | 119/247 [01:22<01:30,  1.42it/s]Loading train:  49%|████▊     | 120/247 [01:22<01:29,  1.41it/s]Loading train:  49%|████▉     | 121/247 [01:23<01:29,  1.41it/s]Loading train:  49%|████▉     | 122/247 [01:24<01:30,  1.39it/s]Loading train:  50%|████▉     | 123/247 [01:25<01:28,  1.40it/s]Loading train:  50%|█████     | 124/247 [01:25<01:27,  1.40it/s]Loading train:  51%|█████     | 125/247 [01:26<01:26,  1.41it/s]Loading train:  51%|█████     | 126/247 [01:27<01:26,  1.41it/s]Loading train:  51%|█████▏    | 127/247 [01:27<01:25,  1.40it/s]Loading train:  52%|█████▏    | 128/247 [01:28<01:24,  1.41it/s]Loading train:  52%|█████▏    | 129/247 [01:29<01:24,  1.40it/s]Loading train:  53%|█████▎    | 130/247 [01:30<01:23,  1.39it/s]Loading train:  53%|█████▎    | 131/247 [01:30<01:23,  1.39it/s]Loading train:  53%|█████▎    | 132/247 [01:31<01:22,  1.39it/s]Loading train:  54%|█████▍    | 133/247 [01:32<01:22,  1.38it/s]Loading train:  54%|█████▍    | 134/247 [01:32<01:21,  1.39it/s]Loading train:  55%|█████▍    | 135/247 [01:33<01:20,  1.39it/s]Loading train:  55%|█████▌    | 136/247 [01:34<01:17,  1.44it/s]Loading train:  55%|█████▌    | 137/247 [01:34<01:14,  1.48it/s]Loading train:  56%|█████▌    | 138/247 [01:35<01:12,  1.51it/s]Loading train:  56%|█████▋    | 139/247 [01:36<01:10,  1.52it/s]Loading train:  57%|█████▋    | 140/247 [01:36<01:10,  1.52it/s]Loading train:  57%|█████▋    | 141/247 [01:37<01:08,  1.55it/s]Loading train:  57%|█████▋    | 142/247 [01:38<01:06,  1.58it/s]Loading train:  58%|█████▊    | 143/247 [01:38<01:05,  1.59it/s]Loading train:  58%|█████▊    | 144/247 [01:39<01:05,  1.58it/s]Loading train:  59%|█████▊    | 145/247 [01:39<01:04,  1.59it/s]Loading train:  59%|█████▉    | 146/247 [01:40<01:03,  1.60it/s]Loading train:  60%|█████▉    | 147/247 [01:41<01:02,  1.60it/s]Loading train:  60%|█████▉    | 148/247 [01:41<01:01,  1.61it/s]Loading train:  60%|██████    | 149/247 [01:42<01:00,  1.61it/s]Loading train:  61%|██████    | 150/247 [01:43<01:00,  1.59it/s]Loading train:  61%|██████    | 151/247 [01:43<00:59,  1.62it/s]Loading train:  62%|██████▏   | 152/247 [01:44<00:58,  1.63it/s]Loading train:  62%|██████▏   | 153/247 [01:44<00:57,  1.63it/s]Loading train:  62%|██████▏   | 154/247 [01:45<00:56,  1.64it/s]Loading train:  63%|██████▎   | 155/247 [01:46<00:54,  1.68it/s]Loading train:  63%|██████▎   | 156/247 [01:46<00:53,  1.70it/s]Loading train:  64%|██████▎   | 157/247 [01:47<00:53,  1.69it/s]Loading train:  64%|██████▍   | 158/247 [01:47<00:52,  1.69it/s]Loading train:  64%|██████▍   | 159/247 [01:48<00:51,  1.70it/s]Loading train:  65%|██████▍   | 160/247 [01:48<00:50,  1.72it/s]Loading train:  65%|██████▌   | 161/247 [01:49<00:50,  1.71it/s]Loading train:  66%|██████▌   | 162/247 [01:50<00:49,  1.73it/s]Loading train:  66%|██████▌   | 163/247 [01:50<00:49,  1.71it/s]Loading train:  66%|██████▋   | 164/247 [01:51<00:48,  1.72it/s]Loading train:  67%|██████▋   | 165/247 [01:51<00:47,  1.71it/s]Loading train:  67%|██████▋   | 166/247 [01:52<00:47,  1.72it/s]Loading train:  68%|██████▊   | 167/247 [01:53<00:46,  1.71it/s]Loading train:  68%|██████▊   | 168/247 [01:53<00:46,  1.68it/s]Loading train:  68%|██████▊   | 169/247 [01:54<00:45,  1.70it/s]Loading train:  69%|██████▉   | 170/247 [01:54<00:45,  1.68it/s]Loading train:  69%|██████▉   | 171/247 [01:55<00:44,  1.70it/s]Loading train:  70%|██████▉   | 172/247 [01:56<00:51,  1.44it/s]Loading train:  70%|███████   | 173/247 [01:57<00:54,  1.35it/s]Loading train:  70%|███████   | 174/247 [01:58<00:56,  1.28it/s]Loading train:  71%|███████   | 175/247 [01:59<01:02,  1.15it/s]Loading train:  71%|███████▏  | 176/247 [01:59<00:56,  1.26it/s]Loading train:  72%|███████▏  | 177/247 [02:00<00:51,  1.35it/s]Loading train:  72%|███████▏  | 178/247 [02:01<00:49,  1.39it/s]Loading train:  72%|███████▏  | 179/247 [02:01<00:46,  1.45it/s]Loading train:  73%|███████▎  | 180/247 [02:02<00:45,  1.48it/s]Loading train:  73%|███████▎  | 181/247 [02:02<00:44,  1.49it/s]Loading train:  74%|███████▎  | 182/247 [02:03<00:42,  1.52it/s]Loading train:  74%|███████▍  | 183/247 [02:04<00:42,  1.51it/s]Loading train:  74%|███████▍  | 184/247 [02:04<00:41,  1.53it/s]Loading train:  75%|███████▍  | 185/247 [02:05<00:40,  1.54it/s]Loading train:  75%|███████▌  | 186/247 [02:06<00:39,  1.55it/s]Loading train:  76%|███████▌  | 187/247 [02:06<00:39,  1.54it/s]Loading train:  76%|███████▌  | 188/247 [02:07<00:38,  1.52it/s]Loading train:  77%|███████▋  | 189/247 [02:08<00:37,  1.55it/s]Loading train:  77%|███████▋  | 190/247 [02:08<00:36,  1.55it/s]Loading train:  77%|███████▋  | 191/247 [02:09<00:36,  1.54it/s]Loading train:  78%|███████▊  | 192/247 [02:10<00:35,  1.54it/s]Loading train:  78%|███████▊  | 193/247 [02:10<00:34,  1.55it/s]Loading train:  79%|███████▊  | 194/247 [02:11<00:33,  1.56it/s]Loading train:  79%|███████▉  | 195/247 [02:12<00:32,  1.58it/s]Loading train:  79%|███████▉  | 196/247 [02:12<00:32,  1.59it/s]Loading train:  80%|███████▉  | 197/247 [02:13<00:31,  1.58it/s]Loading train:  80%|████████  | 198/247 [02:13<00:30,  1.60it/s]Loading train:  81%|████████  | 199/247 [02:14<00:29,  1.62it/s]Loading train:  81%|████████  | 200/247 [02:15<00:29,  1.61it/s]Loading train:  81%|████████▏ | 201/247 [02:15<00:28,  1.61it/s]Loading train:  82%|████████▏ | 202/247 [02:16<00:27,  1.61it/s]Loading train:  82%|████████▏ | 203/247 [02:16<00:27,  1.61it/s]Loading train:  83%|████████▎ | 204/247 [02:17<00:26,  1.61it/s]Loading train:  83%|████████▎ | 205/247 [02:18<00:26,  1.60it/s]Loading train:  83%|████████▎ | 206/247 [02:18<00:25,  1.60it/s]Loading train:  84%|████████▍ | 207/247 [02:19<00:24,  1.60it/s]Loading train:  84%|████████▍ | 208/247 [02:20<00:24,  1.61it/s]Loading train:  85%|████████▍ | 209/247 [02:20<00:23,  1.63it/s]Loading train:  85%|████████▌ | 210/247 [02:21<00:22,  1.64it/s]Loading train:  85%|████████▌ | 211/247 [02:21<00:21,  1.65it/s]Loading train:  86%|████████▌ | 212/247 [02:22<00:21,  1.65it/s]Loading train:  86%|████████▌ | 213/247 [02:23<00:20,  1.66it/s]Loading train:  87%|████████▋ | 214/247 [02:23<00:19,  1.66it/s]Loading train:  87%|████████▋ | 215/247 [02:24<00:19,  1.64it/s]Loading train:  87%|████████▋ | 216/247 [02:24<00:18,  1.65it/s]Loading train:  88%|████████▊ | 217/247 [02:25<00:18,  1.66it/s]Loading train:  88%|████████▊ | 218/247 [02:26<00:17,  1.66it/s]Loading train:  89%|████████▊ | 219/247 [02:26<00:17,  1.64it/s]Loading train:  89%|████████▉ | 220/247 [02:27<00:16,  1.63it/s]Loading train:  89%|████████▉ | 221/247 [02:27<00:15,  1.65it/s]Loading train:  90%|████████▉ | 222/247 [02:28<00:15,  1.66it/s]Loading train:  90%|█████████ | 223/247 [02:29<00:14,  1.66it/s]Loading train:  91%|█████████ | 224/247 [02:29<00:13,  1.67it/s]Loading train:  91%|█████████ | 225/247 [02:31<00:19,  1.13it/s]Loading train:  91%|█████████▏| 226/247 [02:32<00:23,  1.13s/it]Loading train:  92%|█████████▏| 227/247 [02:36<00:34,  1.73s/it]Loading train:  92%|█████████▏| 228/247 [02:39<00:41,  2.21s/it]Loading train:  93%|█████████▎| 229/247 [02:42<00:45,  2.54s/it]Loading train:  93%|█████████▎| 230/247 [02:47<00:56,  3.30s/it]Loading train:  94%|█████████▎| 231/247 [02:52<01:00,  3.77s/it]Loading train:  94%|█████████▍| 232/247 [02:58<01:03,  4.24s/it]Loading train:  94%|█████████▍| 233/247 [03:03<01:02,  4.48s/it]Loading train:  95%|█████████▍| 234/247 [03:08<01:01,  4.72s/it]Loading train:  95%|█████████▌| 235/247 [03:13<00:56,  4.74s/it]Loading train:  96%|█████████▌| 236/247 [03:18<00:53,  4.86s/it]Loading train:  96%|█████████▌| 237/247 [03:23<00:50,  5.03s/it]Loading train:  96%|█████████▋| 238/247 [03:28<00:45,  5.08s/it]Loading train:  97%|█████████▋| 239/247 [03:33<00:40,  5.08s/it]Loading train:  97%|█████████▋| 240/247 [03:39<00:35,  5.10s/it]Loading train:  98%|█████████▊| 241/247 [03:44<00:30,  5.16s/it]Loading train:  98%|█████████▊| 242/247 [03:49<00:25,  5.15s/it]Loading train:  98%|█████████▊| 243/247 [03:54<00:20,  5.17s/it]Loading train:  99%|█████████▉| 244/247 [03:59<00:15,  5.15s/it]Loading train:  99%|█████████▉| 245/247 [04:05<00:10,  5.20s/it]Loading train: 100%|█████████▉| 246/247 [04:10<00:05,  5.26s/it]Loading train: 100%|██████████| 247/247 [04:15<00:00,  5.18s/it]Loading train: 100%|██████████| 247/247 [04:15<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 45.19it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:05, 45.71it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:04, 47.46it/s]concatenating: train:   9%|▉         | 22/247 [00:00<00:04, 48.52it/s]concatenating: train:  11%|█▏        | 28/247 [00:00<00:04, 51.21it/s]concatenating: train:  14%|█▍        | 34/247 [00:00<00:03, 53.48it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:03, 54.96it/s]concatenating: train:  19%|█▊        | 46/247 [00:00<00:03, 55.07it/s]concatenating: train:  21%|██        | 52/247 [00:00<00:03, 55.14it/s]concatenating: train:  23%|██▎       | 58/247 [00:01<00:03, 55.46it/s]concatenating: train:  26%|██▌       | 64/247 [00:01<00:03, 54.24it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 53.91it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:03, 53.78it/s]concatenating: train:  33%|███▎      | 82/247 [00:01<00:03, 53.00it/s]concatenating: train:  36%|███▌      | 88/247 [00:01<00:03, 51.50it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:03, 49.93it/s]concatenating: train:  40%|████      | 99/247 [00:01<00:02, 49.49it/s]concatenating: train:  43%|████▎     | 105/247 [00:02<00:02, 50.48it/s]concatenating: train:  45%|████▍     | 111/247 [00:02<00:02, 51.16it/s]concatenating: train:  47%|████▋     | 117/247 [00:02<00:02, 51.54it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 50.59it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 50.02it/s]concatenating: train:  55%|█████▍    | 135/247 [00:02<00:02, 49.92it/s]concatenating: train:  57%|█████▋    | 140/247 [00:02<00:02, 49.90it/s]concatenating: train:  59%|█████▉    | 146/247 [00:02<00:02, 50.33it/s]concatenating: train:  62%|██████▏   | 152/247 [00:02<00:01, 50.25it/s]concatenating: train:  64%|██████▍   | 158/247 [00:03<00:01, 52.77it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 55.36it/s]concatenating: train:  70%|██████▉   | 172/247 [00:03<00:01, 56.59it/s]concatenating: train:  72%|███████▏  | 178/247 [00:03<00:01, 55.68it/s]concatenating: train:  74%|███████▍  | 184/247 [00:03<00:01, 54.97it/s]concatenating: train:  77%|███████▋  | 190/247 [00:03<00:01, 54.55it/s]concatenating: train:  79%|███████▉  | 196/247 [00:03<00:00, 53.48it/s]concatenating: train:  82%|████████▏ | 202/247 [00:03<00:00, 53.07it/s]concatenating: train:  84%|████████▍ | 208/247 [00:03<00:00, 52.86it/s]concatenating: train:  87%|████████▋ | 214/247 [00:04<00:00, 53.43it/s]concatenating: train:  89%|████████▉ | 220/247 [00:04<00:00, 54.00it/s]concatenating: train:  91%|█████████▏| 226/247 [00:04<00:00, 54.67it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 54.06it/s]concatenating: train:  96%|█████████▋| 238/247 [00:04<00:00, 51.41it/s]concatenating: train:  99%|█████████▉| 244/247 [00:04<00:00, 50.94it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 52.52it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:13<00:55, 13.80s/it]Loading test:  40%|████      | 2/5 [00:25<00:39, 13.32s/it]Loading test:  60%|██████    | 3/5 [00:35<00:24, 12.11s/it]Loading test:  80%|████████  | 4/5 [00:42<00:10, 10.57s/it]Loading test: 100%|██████████| 5/5 [00:53<00:00, 10.84s/it]Loading test: 100%|██████████| 5/5 [00:53<00:00, 10.74s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 58.23it/s]
Epoch 00046: val_mDice did not improve from 0.50989
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
{'val_loss': [-0.056697541469797434, -0.034285616198369055, -0.036545954342257936, -0.064877912072238, -0.08833937385425357, -0.07134706397777994, -0.04416825663559551, -0.05667036837757294, -0.0440410510860246, -0.08088414516726103, -0.07785049680194292, -0.055274831247945556, -0.04974231038696211, -0.049487632084156755, -0.043283426673649865, -0.06102886680527367, 0.00032221660622811405, -0.04224180526399084, -0.07634620615916939, -0.0804357327988227, -0.08043502224437425, -0.06364312872455569, -0.06607808623586633, -0.07800312887368607, -0.0555424764752388, -0.07102080940430455, -0.07735438449686304, -0.08471724215028911, -0.0887690338261453, -0.053282248522962594, -0.08427436869742685, -0.07614400097584813, -0.06701777446533921, -0.05434034341375766, -0.0664275419997993, -0.09323888035607954, -0.08972835197110017, -0.0752707823726084, -0.06571427974643743, -0.054853614845838936, -0.07752301994834879, -0.0657999584815599, -0.05724944067067326, -0.08041634581075824, -0.06219935040522326, -0.05013043807331486], 'val_acc': [0.9935653629778056, 0.9933165333807689, 0.9925702502366801, 0.9934844403249311, 0.9934660101728686, 0.9942628637890975, 0.9931286093933556, 0.9936116643497425, 0.9936350465260748, 0.993961432543188, 0.9938135239470929, 0.9932203213667078, 0.9938148732994755, 0.9930876977329325, 0.9930321796353893, 0.9936082970172276, 0.9933689007899857, 0.9929723825401926, 0.9929330522723744, 0.9934963568550195, 0.9927395131315252, 0.9933776688311813, 0.9937539522938182, 0.993065896949205, 0.9932407804960695, 0.9926446537689969, 0.9932396521867422, 0.9932931485651164, 0.9929645158267989, 0.9934819714609547, 0.99303510268236, 0.9916812337632549, 0.9927069153293032, 0.9930499411597024, 0.9936399875531777, 0.9932785414681663, 0.9936107702800708, 0.9934284713435437, 0.9935397384791357, 0.9932156013826603, 0.9937018081270901, 0.9937595802039678, 0.9934828699294931, 0.9935042220288097, 0.9935889650974766, 0.9933954292557776], 'val_mDice': [0.5036767507467321, 0.5034106535445408, 0.48019710722004794, 0.49866013476329535, 0.493254402026919, 0.5098899088222603, 0.48678002179328805, 0.4896716339492002, 0.4899226365494112, 0.4941476475287068, 0.49006748573366565, 0.4905013177145231, 0.4965026330244057, 0.468133759798269, 0.4808608655271385, 0.4908816087509873, 0.5015657303298091, 0.49114335617016164, 0.48508237538742405, 0.4929583692902568, 0.49528300157332333, 0.4981926363992515, 0.5017904139972701, 0.4847766002605762, 0.4842229371691102, 0.47469925891429293, 0.48252076254229703, 0.4869659470456113, 0.47907336584096466, 0.4836006511514888, 0.47473696627520107, 0.44887707255973147, 0.46772544749933415, 0.477884207814382, 0.5017838206458356, 0.4862441369968147, 0.4982711006354582, 0.48437607247389214, 0.4858538799840146, 0.47915794312734006, 0.4912095833088639, 0.49201722129684533, 0.48477821244524855, 0.4934303891394851, 0.4863587285759704, 0.4812821429823288], 'loss': [0.07573268807204331, 0.05020879428306689, 0.045366461305471145, 0.04233762504800292, 0.03992775678741026, 0.03842267363096879, 0.03770157968336496, 0.036234941010988064, 0.03499804338698054, 0.03429535640887445, 0.03394861328144631, 0.033378279616225366, 0.032712795465330013, 0.0324705280031116, 0.03170788495384025, 0.03129166165853688, 0.03089110483052507, 0.030822856226808252, 0.030628079196752686, 0.03022636020050704, 0.029776563542944407, 0.02876321826559669, 0.028284639889598295, 0.02804772521963162, 0.027676185520979526, 0.02772317357780639, 0.027521805316109323, 0.027345852837352445, 0.027154676500649205, 0.027451894633929705, 0.026907889971260094, 0.026680660927229018, 0.026675498181076302, 0.027416208981096507, 0.026831355831971347, 0.026426347621736467, 0.025856998998151533, 0.02603234648609967, 0.025663942631709506, 0.025508810086932662, 0.026029698224758556, 0.025822728848658754, 0.025383045847316727, 0.025423206036412266, 0.02523359775127141, 0.025558573827670527], 'acc': [0.9919322800883098, 0.9944055738067257, 0.9948951502621342, 0.9951719726318266, 0.995396236501398, 0.9955461823552101, 0.9956553213108311, 0.9957509150335044, 0.9958518914529967, 0.9959136558388489, 0.9959585270182653, 0.9960060891512956, 0.9960622392987541, 0.9960873944919273, 0.9961618775392437, 0.9961701690268877, 0.9962183072491053, 0.9962314888873369, 0.9962609643640746, 0.996268039108935, 0.9963165445334, 0.9964073981395468, 0.996459285440257, 0.9964784925541799, 0.996492728201489, 0.9965005511734102, 0.9965259923166339, 0.9965333037377727, 0.9965454079203371, 0.996538608778106, 0.9965553766831106, 0.9965769863136227, 0.9965793771352857, 0.9965845770820368, 0.996589477230167, 0.996619943059366, 0.9966448283850808, 0.9966489939585051, 0.996662823148614, 0.9966939662244486, 0.9966904437514066, 0.9967059111319033, 0.9967101445510302, 0.9967082842161431, 0.9967201327013298, 0.9967126187407095], 'mDice': [0.8527181352103813, 0.9024281986682753, 0.9118465620075035, 0.9177531461961937, 0.9224533154713574, 0.9253851349349157, 0.9267651493464336, 0.9296463457811727, 0.9320626735535957, 0.9334326940761201, 0.9341037434658432, 0.9352133787170508, 0.936514569615843, 0.9369847445714357, 0.9384724992707745, 0.9392988870278451, 0.9400785530837596, 0.9402072511405629, 0.940576761354606, 0.9413747242657975, 0.9422541167434118, 0.9442163232922417, 0.9451501174300835, 0.9456175560353224, 0.946353584027974, 0.9462565990960599, 0.9466439634933875, 0.9469896379534825, 0.947365295942312, 0.9467766404972535, 0.9478527725189694, 0.9482939900828246, 0.948301429869196, 0.9468201414927943, 0.9479884887230523, 0.9487822245294788, 0.9498988585026154, 0.9495441937505222, 0.9502776627623235, 0.9505763071364329, 0.9495309936538341, 0.9499454298470185, 0.9508190343490895, 0.9507371390848844, 0.9511158360548136, 0.9504598769486099], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   2020-01-21 20:45:33.596086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 20:45:33.596185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 20:45:33.596199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 20:45:33.596207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 20:45:33.596519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights from thalamus:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights from thalamus:   2%|▏         | 1/44 [00:00<00:07,  5.46it/s]loading the weights from thalamus:   7%|▋         | 3/44 [00:00<00:06,  6.45it/s]loading the weights from thalamus:   9%|▉         | 4/44 [00:00<00:06,  6.02it/s]loading the weights from thalamus:  18%|█▊        | 8/44 [00:00<00:04,  7.63it/s]loading the weights from thalamus:  20%|██        | 9/44 [00:00<00:05,  6.66it/s]loading the weights from thalamus:  25%|██▌       | 11/44 [00:01<00:04,  7.57it/s]loading the weights from thalamus:  27%|██▋       | 12/44 [00:01<00:04,  6.76it/s]loading the weights from thalamus:  39%|███▊      | 17/44 [00:01<00:03,  8.74it/s]loading the weights from thalamus:  43%|████▎     | 19/44 [00:01<00:02,  9.18it/s]loading the weights from thalamus:  48%|████▊     | 21/44 [00:02<00:03,  7.29it/s]loading the weights from thalamus:  57%|█████▋    | 25/44 [00:02<00:02,  8.98it/s]loading the weights from thalamus:  61%|██████▏   | 27/44 [00:02<00:01,  9.42it/s]loading the weights from thalamus:  66%|██████▌   | 29/44 [00:02<00:01,  9.60it/s]loading the weights from thalamus:  70%|███████   | 31/44 [00:03<00:01,  7.48it/s]loading the weights from thalamus:  80%|███████▉  | 35/44 [00:03<00:00,  9.24it/s]loading the weights from thalamus:  84%|████████▍ | 37/44 [00:03<00:00,  9.37it/s]loading the weights from thalamus:  89%|████████▊ | 39/44 [00:03<00:00,  8.74it/s]loading the weights from thalamus:  93%|█████████▎| 41/44 [00:04<00:00,  6.85it/s]loading the weights from thalamus: 100%|██████████| 44/44 [00:04<00:00, 10.50it/s]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Thalamus /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [6.23730166e-02 3.14610095e-02 7.87368859e-02 9.59006736e-03
 2.85754875e-02 7.23244061e-03 8.58308015e-02 1.15196118e-01
 9.01080033e-02 1.30691906e-02 2.94184375e-01 1.83387092e-01
 2.55512200e-04]
Train on 15390 samples, validate on 310 samples
Epoch 1/300
 - 37s - loss: 0.5868 - acc: 0.8838 - mDice: 0.3673 - val_loss: 0.6783 - val_acc: 0.9322 - val_mDice: 0.2108

Epoch 00001: val_mDice improved from -inf to 0.21085, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 33s - loss: 0.4408 - acc: 0.9361 - mDice: 0.5246 - val_loss: 0.5548 - val_acc: 0.9329 - val_mDice: 0.2043

Epoch 00002: val_mDice did not improve from 0.21085
Epoch 3/300
 - 33s - loss: 0.4074 - acc: 0.9402 - mDice: 0.5606 - val_loss: 0.0955 - val_acc: 0.9391 - val_mDice: 0.2173

Epoch 00003: val_mDice improved from 0.21085 to 0.21731, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 32s - loss: 0.3861 - acc: 0.9425 - mDice: 0.5836 - val_loss: -3.9985e-02 - val_acc: 0.9393 - val_mDice: 0.2220

Epoch 00004: val_mDice improved from 0.21731 to 0.22197, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 33s - loss: 0.3739 - acc: 0.9440 - mDice: 0.5968 - val_loss: -6.0667e-02 - val_acc: 0.9438 - val_mDice: 0.2228

Epoch 00005: val_mDice improved from 0.22197 to 0.22275, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 32s - loss: 0.3649 - acc: 0.9453 - mDice: 0.6065 - val_loss: -7.5694e-02 - val_acc: 0.9390 - val_mDice: 0.2294

Epoch 00006: val_mDice improved from 0.22275 to 0.22940, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 33s - loss: 0.3531 - acc: 0.9462 - mDice: 0.6192 - val_loss: -1.2436e-01 - val_acc: 0.9428 - val_mDice: 0.2360

Epoch 00007: val_mDice improved from 0.22940 to 0.23598, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 32s - loss: 0.3486 - acc: 0.9469 - mDice: 0.6241 - val_loss: -3.6737e-02 - val_acc: 0.9441 - val_mDice: 0.2248

Epoch 00008: val_mDice did not improve from 0.23598
Epoch 9/300
 - 33s - loss: 0.3436 - acc: 0.9471 - mDice: 0.6296 - val_loss: 0.0060 - val_acc: 0.9307 - val_mDice: 0.2256

Epoch 00009: val_mDice did not improve from 0.23598
Epoch 10/300
 - 33s - loss: 0.3380 - acc: 0.9477 - mDice: 0.6356 - val_loss: -1.5107e-01 - val_acc: 0.9415 - val_mDice: 0.2306

Epoch 00010: val_mDice did not improve from 0.23598
Epoch 11/300
 - 33s - loss: 0.3315 - acc: 0.9485 - mDice: 0.6426 - val_loss: -1.3281e-01 - val_acc: 0.9435 - val_mDice: 0.2347

Epoch 00011: val_mDice did not improve from 0.23598
Epoch 12/300
 - 33s - loss: 0.3310 - acc: 0.9488 - mDice: 0.6432 - val_loss: -1.3201e-01 - val_acc: 0.9402 - val_mDice: 0.2294

Epoch 00012: val_mDice did not improve from 0.23598
Epoch 13/300
 - 32s - loss: 0.3271 - acc: 0.9490 - mDice: 0.6474 - val_loss: -1.4548e-01 - val_acc: 0.9411 - val_mDice: 0.2272

Epoch 00013: val_mDice did not improve from 0.23598
Epoch 14/300
 - 33s - loss: 0.3272 - acc: 0.9494 - mDice: 0.6473 - val_loss: -1.3582e-01 - val_acc: 0.9415 - val_mDice: 0.2288

Epoch 00014: val_mDice did not improve from 0.23598
Epoch 15/300
 - 32s - loss: 0.3228 - acc: 0.9498 - mDice: 0.6521 - val_loss: -9.7301e-02 - val_acc: 0.9405 - val_mDice: 0.2215

Epoch 00015: val_mDice did not improve from 0.23598
Epoch 16/300
 - 33s - loss: 0.3202 - acc: 0.9500 - mDice: 0.6548 - val_loss: -1.0739e-01 - val_acc: 0.9423 - val_mDice: 0.2334

Epoch 00016: val_mDice did not improve from 0.23598
Epoch 17/300
 - 33s - loss: 0.3230 - acc: 0.9498 - mDice: 0.6518 - val_loss: -1.2471e-01 - val_acc: 0.9416 - val_mDice: 0.2306

Epoch 00017: val_mDice did not improve from 0.23598
Epoch 18/300
 - 32s - loss: 0.3123 - acc: 0.9507 - mDice: 0.6634 - val_loss: -1.6874e-01 - val_acc: 0.9417 - val_mDice: 0.2326

Epoch 00018: val_mDice did not improve from 0.23598
Epoch 19/300
 - 32s - loss: 0.3147 - acc: 0.9503 - mDice: 0.6589 - val_loss: -1.2662e-01 - val_acc: 0.9420 - val_mDice: 0.2252

Epoch 00019: val_mDice did not improve from 0.23598
Epoch 20/300
 - 32s - loss: 0.3369 - acc: 0.9464 - mDice: 0.6092 - val_loss: -1.7877e-01 - val_acc: 0.9446 - val_mDice: 0.2295

Epoch 00020: val_mDice did not improve from 0.23598
Epoch 21/300
 - 32s - loss: 0.3063 - acc: 0.9466 - mDice: 0.6213 - val_loss: -1.9262e-01 - val_acc: 0.9436 - val_mDice: 0.2219

Epoch 00021: val_mDice did not improve from 0.23598
Epoch 22/300
 - 32s - loss: 0.3000 - acc: 0.9470 - mDice: 0.6182 - val_loss: -2.3128e-01 - val_acc: 0.9477 - val_mDice: 0.2346

Epoch 00022: val_mDice did not improve from 0.23598

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 23/300
 - 32s - loss: 0.2807 - acc: 0.9485 - mDice: 0.6344 - val_loss: -2.0040e-01 - val_acc: 0.9441 - val_mDice: 0.2262

Epoch 00023: val_mDice did not improve from 0.23598
Epoch 24/300
 - 33s - loss: 0.2710 - acc: 0.9489 - mDice: 0.6402 - val_loss: -2.0090e-01 - val_acc: 0.9450 - val_mDice: 0.2312

Epoch 00024: val_mDice did not improve from 0.23598
Epoch 25/300
 - 32s - loss: 0.2687 - acc: 0.9492 - mDice: 0.6420 - val_loss: -2.1313e-01 - val_acc: 0.9462 - val_mDice: 0.2275

Epoch 00025: val_mDice did not improve from 0.23598
Epoch 26/300
 - 33s - loss: 0.2680 - acc: 0.9490 - mDice: 0.6389 - val_loss: -2.1793e-01 - val_acc: 0.9457 - val_mDice: 0.2250

Epoch 00026: val_mDice did not improve from 0.23598
Epoch 27/300
 - 32s - loss: 0.2670 - acc: 0.9490 - mDice: 0.6373 - val_loss: -2.1181e-01 - val_acc: 0.9459 - val_mDice: 0.2245

Epoch 00027: val_mDice did not improve from 0.23598
Epoch 28/300
 - 33s - loss: 0.2631 - acc: 0.9490 - mDice: 0.6388 - val_loss: -2.1192e-01 - val_acc: 0.9448 - val_mDice: 0.2265

Epoch 00028: val_mDice did not improve from 0.23598
Epoch 29/300
 - 33s - loss: 0.2619 - acc: 0.9493 - mDice: 0.6350 - val_loss: -1.8861e-01 - val_acc: 0.9439 - val_mDice: 0.2300

Epoch 00029: val_mDice did not improve from 0.23598
Epoch 30/300
 - 33s - loss: 0.2556 - acc: 0.9494 - mDice: 0.6409 - val_loss: -2.2274e-01 - val_acc: 0.9464 - val_mDice: 0.2215

Epoch 00030: val_mDice did not improve from 0.23598
Epoch 31/300
 - 33s - loss: 0.2504 - acc: 0.9498 - mDice: 0.6474 - val_loss: -1.6460e-01 - val_acc: 0.9387 - val_mDice: 0.2069

Epoch 00031: val_mDice did not improve from 0.23598
Epoch 32/300
 - 33s - loss: 0.2611 - acc: 0.9489 - mDice: 0.6332 - val_loss: -1.8872e-01 - val_acc: 0.9420 - val_mDice: 0.1949

Epoch 00032: val_mDice did not improve from 0.23598
Epoch 33/300
 - 32s - loss: 0.2573 - acc: 0.9491 - mDice: 0.6324 - val_loss: -1.9786e-01 - val_acc: 0.9417 - val_mDice: 0.2230

Epoch 00033: val_mDice did not improve from 0.23598
Epoch 34/300
 - 33s - loss: 0.2515 - acc: 0.9496 - mDice: 0.6416 - val_loss: -1.9868e-01 - val_acc: 0.9453 - val_mDice: 0.2278

Epoch 00034: val_mDice did not improve from 0.23598
Epoch 35/300
 - 33s - loss: 0.2459 - acc: 0.9495 - mDice: 0.6407 - val_loss: -2.1281e-01 - val_acc: 0.9464 - val_mDice: 0.2274

Epoch 00035: val_mDice did not improve from 0.23598
Epoch 36/300
 - 32s - loss: 0.2447 - acc: 0.9495 - mDice: 0.6404 - val_loss: -2.0054e-01 - val_acc: 0.9436 - val_mDice: 0.2295

Epoch 00036: val_mDice did not improve from 0.23598
Epoch 37/300
 - 33s - loss: 0.2462 - acc: 0.9497 - mDice: 0.6440 - val_loss: -2.1667e-01 - val_acc: 0.9431 - val_mDice: 0.2258

Epoch 00037: val_mDice did not improve from 0.23598

Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 38/300
 - 33s - loss: 0.2346 - acc: 0.9501 - mDice: 0.6528 - val_loss: -2.3454e-01 - val_acc: 0.9440 - val_mDice: 0.2188

Epoch 00038: val_mDice did not improve from 0.23598
Epoch 39/300
 - 32s - loss: 0.2367 - acc: 0.9504 - mDice: 0.6553 - val_loss: -2.2955e-01 - val_acc: 0.9435 - val_mDice: 0.2276

Epoch 00039: val_mDice did not improve from 0.23598
Epoch 40/300
 - 32s - loss: 0.2325 - acc: 0.9507 - mDice: 0.6536 - val_loss: -2.2621e-01 - val_acc: 0.9442 - val_mDice: 0.2258

Epoch 00040: val_mDice did not improve from 0.23598
Epoch 41/300
 - 32s - loss: 0.2299 - acc: 0.9507 - mDice: 0.6591 - val_loss: -2.3961e-01 - val_acc: 0.9456 - val_mDice: 0.2253

Epoch 00041: val_mDice did not improve from 0.23598
Epoch 42/300
 - 32s - loss: 0.2278 - acc: 0.9505 - mDice: 0.6552 - val_loss: -2.2513e-01 - val_acc: 0.9428 - val_mDice: 0.2260

Epoch 00042: val_mDice did not improve from 0.23598
Epoch 43/300
 - 33s - loss: 0.2320 - acc: 0.9502 - mDice: 0.6475 - val_loss: -2.2423e-01 - val_acc: 0.9432 - val_mDice: 0.2238

Epoch 00043: val_mDice did not improve from 0.23598
Epoch 44/300
 - 32s - loss: 0.2241 - acc: 0.9506 - mDice: 0.6544 - val_loss: -2.4240e-01 - val_acc: 0.9451 - val_mDice: 0.2243

Epoch 00044: val_mDice did not improve from 0.23598
Epoch 45/300
 - 32s - loss: 0.2271 - acc: 0.9507 - mDice: 0.6593 - val_loss: -2.3098e-01 - val_acc: 0.9440 - val_mDice: 0.2285

Epoch 00045: val_mDice did not improve from 0.23598
Epoch 46/300
 - 33s - loss: 0.2273 - acc: 0.9503 - mDice: 0.6505 - val_loss: -2.3249e-01 - val_acc: 0.9442 - val_mDice: 0.2273

Epoch 00046: val_mDice did not improve from 0.23598
Epoch 47/300
 - 33s - loss: 0.2232 - acc: 0.9506 - mDice: 0.6531 - val_loss: -2.2654e-01 - val_acc: 0.9444 - val_mDice: 0.2178

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:07,  1.85s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.64s/it]predicting test subjects:  60%|██████    | 3/5 [00:04<00:02,  1.45s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.29s/it]predicting test subjects: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]predicting test subjects: 100%|██████████| 5/5 [00:06<00:00,  1.22s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:05,  3.76it/s]Loading train:   1%|          | 2/247 [00:00<01:04,  3.81it/s]Loading train:   1%|          | 3/247 [00:00<01:03,  3.87it/s]Loading train:   2%|▏         | 4/247 [00:01<01:03,  3.84it/s]Loading train:   2%|▏         | 5/247 [00:01<01:00,  3.97it/s]Loading train:   2%|▏         | 6/247 [00:01<00:58,  4.10it/s]Loading train:   3%|▎         | 7/247 [00:01<00:58,  4.13it/s]Loading train:   3%|▎         | 8/247 [00:01<00:58,  4.12it/s]Loading train:   4%|▎         | 9/247 [00:02<00:57,  4.14it/s]Loading train:   4%|▍         | 10/247 [00:02<00:56,  4.17it/s]Loading train:   4%|▍         | 11/247 [00:02<00:56,  4.19it/s]Loading train:   5%|▍         | 12/247 [00:02<00:55,  4.22it/s]Loading train:   5%|▌         | 13/247 [00:03<00:54,  4.26it/s]Loading train:   6%|▌         | 14/247 [00:03<00:54,  4.27it/s]Loading train:   6%|▌         | 15/247 [00:03<00:54,  4.29it/s]Loading train:   6%|▋         | 16/247 [00:03<00:57,  3.99it/s]Loading train:   7%|▋         | 17/247 [00:04<00:57,  3.99it/s]Loading train:   7%|▋         | 18/247 [00:04<00:55,  4.10it/s]Loading train:   8%|▊         | 19/247 [00:04<00:56,  4.03it/s]Loading train:   8%|▊         | 20/247 [00:04<00:55,  4.09it/s]Loading train:   9%|▊         | 21/247 [00:05<00:55,  4.10it/s]Loading train:   9%|▉         | 22/247 [00:05<00:54,  4.13it/s]Loading train:   9%|▉         | 23/247 [00:05<00:54,  4.11it/s]Loading train:  10%|▉         | 24/247 [00:05<00:54,  4.06it/s]Loading train:  10%|█         | 25/247 [00:06<00:56,  3.90it/s]Loading train:  11%|█         | 26/247 [00:06<00:54,  4.02it/s]Loading train:  11%|█         | 27/247 [00:06<00:53,  4.12it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:52,  4.15it/s]Loading train:  12%|█▏        | 29/247 [00:07<00:54,  4.02it/s]Loading train:  12%|█▏        | 30/247 [00:07<00:53,  4.07it/s]Loading train:  13%|█▎        | 31/247 [00:07<00:54,  4.00it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:53,  4.03it/s]Loading train:  13%|█▎        | 33/247 [00:08<00:52,  4.05it/s]Loading train:  14%|█▍        | 34/247 [00:08<00:52,  4.08it/s]Loading train:  14%|█▍        | 35/247 [00:08<00:51,  4.15it/s]Loading train:  15%|█▍        | 36/247 [00:08<00:50,  4.15it/s]Loading train:  15%|█▍        | 37/247 [00:09<00:51,  4.08it/s]Loading train:  15%|█▌        | 38/247 [00:09<00:50,  4.11it/s]Loading train:  16%|█▌        | 39/247 [00:09<00:50,  4.09it/s]Loading train:  16%|█▌        | 40/247 [00:09<00:51,  4.04it/s]Loading train:  17%|█▋        | 41/247 [00:10<00:51,  4.00it/s]Loading train:  17%|█▋        | 42/247 [00:10<00:50,  4.09it/s]Loading train:  17%|█▋        | 43/247 [00:10<00:51,  3.97it/s]Loading train:  18%|█▊        | 44/247 [00:10<00:50,  4.04it/s]Loading train:  18%|█▊        | 45/247 [00:11<00:49,  4.08it/s]Loading train:  19%|█▊        | 46/247 [00:11<00:50,  3.98it/s]Loading train:  19%|█▉        | 47/247 [00:11<00:49,  4.04it/s]Loading train:  19%|█▉        | 48/247 [00:11<00:48,  4.09it/s]Loading train:  20%|█▉        | 49/247 [00:12<00:48,  4.10it/s]Loading train:  20%|██        | 50/247 [00:12<00:47,  4.17it/s]Loading train:  21%|██        | 51/247 [00:12<00:47,  4.11it/s]Loading train:  21%|██        | 52/247 [00:12<00:46,  4.16it/s]Loading train:  21%|██▏       | 53/247 [00:12<00:47,  4.11it/s]Loading train:  22%|██▏       | 54/247 [00:13<00:46,  4.19it/s]Loading train:  22%|██▏       | 55/247 [00:13<00:45,  4.18it/s]Loading train:  23%|██▎       | 56/247 [00:13<00:44,  4.26it/s]Loading train:  23%|██▎       | 57/247 [00:13<00:45,  4.16it/s]Loading train:  23%|██▎       | 58/247 [00:14<00:44,  4.22it/s]Loading train:  24%|██▍       | 59/247 [00:14<00:45,  4.13it/s]Loading train:  24%|██▍       | 60/247 [00:14<00:45,  4.15it/s]Loading train:  25%|██▍       | 61/247 [00:14<00:45,  4.07it/s]Loading train:  25%|██▌       | 62/247 [00:15<00:44,  4.14it/s]Loading train:  26%|██▌       | 63/247 [00:15<00:44,  4.15it/s]Loading train:  26%|██▌       | 64/247 [00:15<00:43,  4.21it/s]Loading train:  26%|██▋       | 65/247 [00:15<00:43,  4.20it/s]Loading train:  27%|██▋       | 66/247 [00:16<00:42,  4.24it/s]Loading train:  27%|██▋       | 67/247 [00:16<00:42,  4.22it/s]Loading train:  28%|██▊       | 68/247 [00:16<00:42,  4.23it/s]Loading train:  28%|██▊       | 69/247 [00:16<00:44,  4.04it/s]Loading train:  28%|██▊       | 70/247 [00:17<00:43,  4.03it/s]Loading train:  29%|██▊       | 71/247 [00:17<00:43,  4.08it/s]Loading train:  29%|██▉       | 72/247 [00:17<00:42,  4.08it/s]Loading train:  30%|██▉       | 73/247 [00:17<00:43,  4.03it/s]Loading train:  30%|██▉       | 74/247 [00:18<00:42,  4.03it/s]Loading train:  30%|███       | 75/247 [00:18<00:42,  4.03it/s]Loading train:  31%|███       | 76/247 [00:18<00:42,  4.01it/s]Loading train:  31%|███       | 77/247 [00:18<00:43,  3.92it/s]Loading train:  32%|███▏      | 78/247 [00:19<00:45,  3.71it/s]Loading train:  32%|███▏      | 79/247 [00:19<00:45,  3.71it/s]Loading train:  32%|███▏      | 80/247 [00:19<00:42,  3.93it/s]Loading train:  33%|███▎      | 81/247 [00:19<00:42,  3.94it/s]Loading train:  33%|███▎      | 82/247 [00:20<00:41,  4.01it/s]Loading train:  34%|███▎      | 83/247 [00:20<00:40,  4.03it/s]Loading train:  34%|███▍      | 84/247 [00:20<00:40,  4.05it/s]Loading train:  34%|███▍      | 85/247 [00:20<00:39,  4.13it/s]Loading train:  35%|███▍      | 86/247 [00:21<00:38,  4.14it/s]Loading train:  35%|███▌      | 87/247 [00:21<00:38,  4.17it/s]Loading train:  36%|███▌      | 88/247 [00:21<00:37,  4.19it/s]Loading train:  36%|███▌      | 89/247 [00:21<00:37,  4.19it/s]Loading train:  36%|███▋      | 90/247 [00:22<00:37,  4.21it/s]Loading train:  37%|███▋      | 91/247 [00:22<00:37,  4.18it/s]Loading train:  37%|███▋      | 92/247 [00:22<00:36,  4.22it/s]Loading train:  38%|███▊      | 93/247 [00:22<00:36,  4.27it/s]Loading train:  38%|███▊      | 94/247 [00:22<00:35,  4.30it/s]Loading train:  38%|███▊      | 95/247 [00:23<00:35,  4.29it/s]Loading train:  39%|███▉      | 96/247 [00:23<00:34,  4.32it/s]Loading train:  39%|███▉      | 97/247 [00:23<00:34,  4.32it/s]Loading train:  40%|███▉      | 98/247 [00:23<00:34,  4.30it/s]Loading train:  40%|████      | 99/247 [00:24<00:34,  4.25it/s]Loading train:  40%|████      | 100/247 [00:24<00:36,  4.00it/s]Loading train:  41%|████      | 101/247 [00:24<00:38,  3.78it/s]Loading train:  41%|████▏     | 102/247 [00:24<00:39,  3.63it/s]Loading train:  42%|████▏     | 103/247 [00:25<00:40,  3.55it/s]Loading train:  42%|████▏     | 104/247 [00:25<00:40,  3.54it/s]Loading train:  43%|████▎     | 105/247 [00:25<00:39,  3.58it/s]Loading train:  43%|████▎     | 106/247 [00:26<00:39,  3.59it/s]Loading train:  43%|████▎     | 107/247 [00:26<00:39,  3.55it/s]Loading train:  44%|████▎     | 108/247 [00:26<00:38,  3.58it/s]Loading train:  44%|████▍     | 109/247 [00:26<00:39,  3.48it/s]Loading train:  45%|████▍     | 110/247 [00:27<00:39,  3.46it/s]Loading train:  45%|████▍     | 111/247 [00:27<00:39,  3.44it/s]Loading train:  45%|████▌     | 112/247 [00:27<00:38,  3.51it/s]Loading train:  46%|████▌     | 113/247 [00:28<00:38,  3.49it/s]Loading train:  46%|████▌     | 114/247 [00:28<00:37,  3.55it/s]Loading train:  47%|████▋     | 115/247 [00:28<00:37,  3.50it/s]Loading train:  47%|████▋     | 116/247 [00:29<00:37,  3.47it/s]Loading train:  47%|████▋     | 117/247 [00:29<00:36,  3.56it/s]Loading train:  48%|████▊     | 118/247 [00:29<00:34,  3.70it/s]Loading train:  48%|████▊     | 119/247 [00:29<00:33,  3.83it/s]Loading train:  49%|████▊     | 120/247 [00:29<00:32,  3.91it/s]Loading train:  49%|████▉     | 121/247 [00:30<00:31,  3.99it/s]Loading train:  49%|████▉     | 122/247 [00:30<00:31,  4.00it/s]Loading train:  50%|████▉     | 123/247 [00:30<00:30,  4.06it/s]Loading train:  50%|█████     | 124/247 [00:30<00:30,  4.03it/s]Loading train:  51%|█████     | 125/247 [00:31<00:29,  4.07it/s]Loading train:  51%|█████     | 126/247 [00:31<00:30,  4.00it/s]Loading train:  51%|█████▏    | 127/247 [00:31<00:29,  4.06it/s]Loading train:  52%|█████▏    | 128/247 [00:31<00:29,  4.05it/s]Loading train:  52%|█████▏    | 129/247 [00:32<00:29,  4.05it/s]Loading train:  53%|█████▎    | 130/247 [00:32<00:29,  4.03it/s]Loading train:  53%|█████▎    | 131/247 [00:32<00:28,  4.05it/s]Loading train:  53%|█████▎    | 132/247 [00:32<00:28,  4.08it/s]Loading train:  54%|█████▍    | 133/247 [00:33<00:28,  4.05it/s]Loading train:  54%|█████▍    | 134/247 [00:33<00:27,  4.08it/s]Loading train:  55%|█████▍    | 135/247 [00:33<00:27,  4.11it/s]Loading train:  55%|█████▌    | 136/247 [00:33<00:25,  4.28it/s]Loading train:  55%|█████▌    | 137/247 [00:34<00:24,  4.45it/s]Loading train:  56%|█████▌    | 138/247 [00:34<00:23,  4.59it/s]Loading train:  56%|█████▋    | 139/247 [00:34<00:23,  4.64it/s]Loading train:  57%|█████▋    | 140/247 [00:34<00:22,  4.70it/s]Loading train:  57%|█████▋    | 141/247 [00:34<00:22,  4.77it/s]Loading train:  57%|█████▋    | 142/247 [00:35<00:21,  4.81it/s]Loading train:  58%|█████▊    | 143/247 [00:35<00:21,  4.83it/s]Loading train:  58%|█████▊    | 144/247 [00:35<00:21,  4.85it/s]Loading train:  59%|█████▊    | 145/247 [00:35<00:20,  4.86it/s]Loading train:  59%|█████▉    | 146/247 [00:35<00:20,  4.88it/s]Loading train:  60%|█████▉    | 147/247 [00:36<00:20,  4.87it/s]Loading train:  60%|█████▉    | 148/247 [00:36<00:20,  4.88it/s]Loading train:  60%|██████    | 149/247 [00:36<00:20,  4.88it/s]Loading train:  61%|██████    | 150/247 [00:36<00:19,  4.86it/s]Loading train:  61%|██████    | 151/247 [00:36<00:20,  4.78it/s]Loading train:  62%|██████▏   | 152/247 [00:37<00:19,  4.78it/s]Loading train:  62%|██████▏   | 153/247 [00:37<00:19,  4.77it/s]Loading train:  62%|██████▏   | 154/247 [00:37<00:20,  4.60it/s]Loading train:  63%|██████▎   | 155/247 [00:37<00:20,  4.56it/s]Loading train:  63%|██████▎   | 156/247 [00:38<00:20,  4.54it/s]Loading train:  64%|██████▎   | 157/247 [00:38<00:19,  4.50it/s]Loading train:  64%|██████▍   | 158/247 [00:38<00:19,  4.50it/s]Loading train:  64%|██████▍   | 159/247 [00:38<00:19,  4.49it/s]Loading train:  65%|██████▍   | 160/247 [00:38<00:19,  4.48it/s]Loading train:  65%|██████▌   | 161/247 [00:39<00:19,  4.43it/s]Loading train:  66%|██████▌   | 162/247 [00:39<00:19,  4.41it/s]Loading train:  66%|██████▌   | 163/247 [00:39<00:19,  4.39it/s]Loading train:  66%|██████▋   | 164/247 [00:39<00:19,  4.35it/s]Loading train:  67%|██████▋   | 165/247 [00:40<00:18,  4.35it/s]Loading train:  67%|██████▋   | 166/247 [00:40<00:19,  4.25it/s]Loading train:  68%|██████▊   | 167/247 [00:40<00:18,  4.24it/s]Loading train:  68%|██████▊   | 168/247 [00:40<00:18,  4.19it/s]Loading train:  68%|██████▊   | 169/247 [00:41<00:18,  4.20it/s]Loading train:  69%|██████▉   | 170/247 [00:41<00:18,  4.15it/s]Loading train:  69%|██████▉   | 171/247 [00:41<00:18,  4.18it/s]Loading train:  70%|██████▉   | 172/247 [00:41<00:18,  4.12it/s]Loading train:  70%|███████   | 173/247 [00:42<00:17,  4.18it/s]Loading train:  70%|███████   | 174/247 [00:42<00:17,  4.15it/s]Loading train:  71%|███████   | 175/247 [00:42<00:17,  4.01it/s]Loading train:  71%|███████▏  | 176/247 [00:42<00:17,  4.10it/s]Loading train:  72%|███████▏  | 177/247 [00:43<00:16,  4.16it/s]Loading train:  72%|███████▏  | 178/247 [00:43<00:16,  4.22it/s]Loading train:  72%|███████▏  | 179/247 [00:43<00:15,  4.25it/s]Loading train:  73%|███████▎  | 180/247 [00:43<00:15,  4.28it/s]Loading train:  73%|███████▎  | 181/247 [00:43<00:15,  4.31it/s]Loading train:  74%|███████▎  | 182/247 [00:44<00:15,  4.32it/s]Loading train:  74%|███████▍  | 183/247 [00:44<00:14,  4.34it/s]Loading train:  74%|███████▍  | 184/247 [00:44<00:14,  4.35it/s]Loading train:  75%|███████▍  | 185/247 [00:44<00:14,  4.35it/s]Loading train:  75%|███████▌  | 186/247 [00:45<00:13,  4.37it/s]Loading train:  76%|███████▌  | 187/247 [00:45<00:13,  4.36it/s]Loading train:  76%|███████▌  | 188/247 [00:45<00:13,  4.36it/s]Loading train:  77%|███████▋  | 189/247 [00:45<00:13,  4.37it/s]Loading train:  77%|███████▋  | 190/247 [00:46<00:13,  4.34it/s]Loading train:  77%|███████▋  | 191/247 [00:46<00:12,  4.36it/s]Loading train:  78%|███████▊  | 192/247 [00:46<00:12,  4.37it/s]Loading train:  78%|███████▊  | 193/247 [00:46<00:12,  4.39it/s]Loading train:  79%|███████▊  | 194/247 [00:46<00:11,  4.43it/s]Loading train:  79%|███████▉  | 195/247 [00:47<00:11,  4.45it/s]Loading train:  79%|███████▉  | 196/247 [00:47<00:11,  4.45it/s]Loading train:  80%|███████▉  | 197/247 [00:47<00:11,  4.45it/s]Loading train:  80%|████████  | 198/247 [00:47<00:10,  4.46it/s]Loading train:  81%|████████  | 199/247 [00:48<00:10,  4.48it/s]Loading train:  81%|████████  | 200/247 [00:48<00:10,  4.47it/s]Loading train:  81%|████████▏ | 201/247 [00:48<00:10,  4.49it/s]Loading train:  82%|████████▏ | 202/247 [00:48<00:10,  4.50it/s]Loading train:  82%|████████▏ | 203/247 [00:48<00:09,  4.52it/s]Loading train:  83%|████████▎ | 204/247 [00:49<00:09,  4.54it/s]Loading train:  83%|████████▎ | 205/247 [00:49<00:09,  4.55it/s]Loading train:  83%|████████▎ | 206/247 [00:49<00:09,  4.55it/s]Loading train:  84%|████████▍ | 207/247 [00:49<00:08,  4.52it/s]Loading train:  84%|████████▍ | 208/247 [00:50<00:08,  4.55it/s]Loading train:  85%|████████▍ | 209/247 [00:50<00:08,  4.55it/s]Loading train:  85%|████████▌ | 210/247 [00:50<00:08,  4.53it/s]Loading train:  85%|████████▌ | 211/247 [00:50<00:07,  4.52it/s]Loading train:  86%|████████▌ | 212/247 [00:50<00:07,  4.46it/s]Loading train:  86%|████████▌ | 213/247 [00:51<00:07,  4.42it/s]Loading train:  87%|████████▋ | 214/247 [00:51<00:07,  4.39it/s]Loading train:  87%|████████▋ | 215/247 [00:51<00:07,  4.35it/s]Loading train:  87%|████████▋ | 216/247 [00:51<00:07,  4.36it/s]Loading train:  88%|████████▊ | 217/247 [00:52<00:06,  4.35it/s]Loading train:  88%|████████▊ | 218/247 [00:52<00:06,  4.33it/s]Loading train:  89%|████████▊ | 219/247 [00:52<00:06,  4.31it/s]Loading train:  89%|████████▉ | 220/247 [00:52<00:06,  4.31it/s]Loading train:  89%|████████▉ | 221/247 [00:53<00:06,  4.28it/s]Loading train:  90%|████████▉ | 222/247 [00:53<00:05,  4.30it/s]Loading train:  90%|█████████ | 223/247 [00:53<00:05,  4.28it/s]Loading train:  91%|█████████ | 224/247 [00:53<00:05,  4.31it/s]Loading train:  91%|█████████ | 225/247 [00:53<00:05,  4.31it/s]Loading train:  91%|█████████▏| 226/247 [00:54<00:04,  4.28it/s]Loading train:  92%|█████████▏| 227/247 [00:54<00:04,  4.31it/s]Loading train:  92%|█████████▏| 228/247 [00:54<00:04,  4.30it/s]Loading train:  93%|█████████▎| 229/247 [00:54<00:04,  4.25it/s]Loading train:  93%|█████████▎| 230/247 [00:55<00:04,  4.16it/s]Loading train:  94%|█████████▎| 231/247 [00:55<00:03,  4.10it/s]Loading train:  94%|█████████▍| 232/247 [00:55<00:03,  4.06it/s]Loading train:  94%|█████████▍| 233/247 [00:55<00:03,  4.04it/s]Loading train:  95%|█████████▍| 234/247 [00:56<00:03,  3.98it/s]Loading train:  95%|█████████▌| 235/247 [00:56<00:03,  3.95it/s]Loading train:  96%|█████████▌| 236/247 [00:56<00:02,  3.95it/s]Loading train:  96%|█████████▌| 237/247 [00:56<00:02,  3.95it/s]Loading train:  96%|█████████▋| 238/247 [00:57<00:02,  3.95it/s]Loading train:  97%|█████████▋| 239/247 [00:57<00:02,  3.95it/s]Loading train:  97%|█████████▋| 240/247 [00:57<00:01,  3.96it/s]Loading train:  98%|█████████▊| 241/247 [00:57<00:01,  3.97it/s]Loading train:  98%|█████████▊| 242/247 [00:58<00:01,  3.98it/s]Loading train:  98%|█████████▊| 243/247 [00:58<00:01,  3.97it/s]Loading train:  99%|█████████▉| 244/247 [00:58<00:00,  3.95it/s]Loading train:  99%|█████████▉| 245/247 [00:58<00:00,  3.95it/s]Loading train: 100%|█████████▉| 246/247 [00:59<00:00,  3.96it/s]Loading train: 100%|██████████| 247/247 [00:59<00:00,  3.97it/s]Loading train: 100%|██████████| 247/247 [00:59<00:00,  4.16it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 47.07it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:05, 47.12it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:04, 47.18it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:04, 47.17it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 46.99it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 46.87it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 46.87it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 46.91it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:04, 47.03it/s]concatenating: train:  20%|██        | 50/247 [00:01<00:04, 46.70it/s]concatenating: train:  22%|██▏       | 55/247 [00:01<00:04, 46.80it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 46.93it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 47.13it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 46.54it/s]concatenating: train:  30%|███       | 75/247 [00:01<00:03, 46.87it/s]concatenating: train:  32%|███▏      | 80/247 [00:01<00:03, 47.12it/s]concatenating: train:  34%|███▍      | 85/247 [00:01<00:03, 47.87it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:03, 48.06it/s]concatenating: train:  38%|███▊      | 95/247 [00:02<00:03, 48.58it/s]concatenating: train:  40%|████      | 100/247 [00:02<00:03, 48.28it/s]concatenating: train:  43%|████▎     | 105/247 [00:02<00:03, 46.28it/s]concatenating: train:  45%|████▍     | 110/247 [00:02<00:03, 44.56it/s]concatenating: train:  47%|████▋     | 115/247 [00:02<00:03, 43.71it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:02, 44.20it/s]concatenating: train:  51%|█████     | 125/247 [00:02<00:02, 44.86it/s]concatenating: train:  53%|█████▎    | 130/247 [00:02<00:02, 45.43it/s]concatenating: train:  55%|█████▍    | 135/247 [00:02<00:02, 46.11it/s]concatenating: train:  57%|█████▋    | 141/247 [00:03<00:02, 48.40it/s]concatenating: train:  60%|█████▉    | 147/247 [00:03<00:02, 49.83it/s]concatenating: train:  62%|██████▏   | 153/247 [00:03<00:01, 51.23it/s]concatenating: train:  64%|██████▍   | 159/247 [00:03<00:01, 50.78it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 50.15it/s]concatenating: train:  69%|██████▉   | 171/247 [00:03<00:01, 49.67it/s]concatenating: train:  71%|███████▏  | 176/247 [00:03<00:01, 49.42it/s]concatenating: train:  73%|███████▎  | 181/247 [00:03<00:01, 49.45it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:01, 49.05it/s]concatenating: train:  78%|███████▊  | 192/247 [00:04<00:01, 49.38it/s]concatenating: train:  80%|████████  | 198/247 [00:04<00:00, 49.86it/s]concatenating: train:  83%|████████▎ | 204/247 [00:04<00:00, 50.15it/s]concatenating: train:  85%|████████▌ | 210/247 [00:04<00:00, 50.22it/s]concatenating: train:  87%|████████▋ | 216/247 [00:04<00:00, 49.88it/s]concatenating: train:  89%|████████▉ | 221/247 [00:04<00:00, 49.57it/s]concatenating: train:  91%|█████████▏| 226/247 [00:04<00:00, 47.74it/s]concatenating: train:  94%|█████████▎| 231/247 [00:04<00:00, 47.73it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 49.79it/s]concatenating: train:  99%|█████████▉| 244/247 [00:05<00:00, 53.77it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 48.58it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  3.35it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.43it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.66it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  3.80it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.74it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.79it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 296.83it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<01:01,  4.02it/s]Loading trainS:   1%|          | 2/247 [00:00<01:01,  4.01it/s]Loading trainS:   1%|          | 3/247 [00:00<01:00,  4.00it/s]Loading trainS:   2%|▏         | 4/247 [00:01<01:00,  3.99it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:59,  4.05it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:58,  4.10it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:58,  4.14it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:57,  4.16it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:57,  4.17it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:56,  4.19it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:56,  4.19it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:56,  4.20it/s]Loading trainS:   5%|▌         | 13/247 [00:03<00:55,  4.19it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:55,  4.20it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:55,  4.18it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:55,  4.20it/s]Loading trainS:   7%|▋         | 17/247 [00:04<00:54,  4.20it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:54,  4.22it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:54,  4.21it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:55,  4.13it/s]Loading trainS:   9%|▊         | 21/247 [00:05<00:54,  4.12it/s]Loading trainS:   9%|▉         | 22/247 [00:05<00:54,  4.14it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:53,  4.19it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:53,  4.16it/s]Loading trainS:  10%|█         | 25/247 [00:06<00:53,  4.17it/s]Loading trainS:  11%|█         | 26/247 [00:06<00:52,  4.19it/s]Loading trainS:  11%|█         | 27/247 [00:06<00:53,  4.10it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:52,  4.15it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:52,  4.17it/s]Loading trainS:  12%|█▏        | 30/247 [00:07<00:51,  4.21it/s]Loading trainS:  13%|█▎        | 31/247 [00:07<00:51,  4.23it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:50,  4.23it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:50,  4.25it/s]Loading trainS:  14%|█▍        | 34/247 [00:08<00:49,  4.27it/s]Loading trainS:  14%|█▍        | 35/247 [00:08<00:49,  4.28it/s]Loading trainS:  15%|█▍        | 36/247 [00:08<00:49,  4.30it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:48,  4.31it/s]Loading trainS:  15%|█▌        | 38/247 [00:09<00:48,  4.29it/s]Loading trainS:  16%|█▌        | 39/247 [00:09<00:48,  4.30it/s]Loading trainS:  16%|█▌        | 40/247 [00:09<00:48,  4.31it/s]Loading trainS:  17%|█▋        | 41/247 [00:09<00:47,  4.32it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:47,  4.34it/s]Loading trainS:  17%|█▋        | 43/247 [00:10<00:46,  4.35it/s]Loading trainS:  18%|█▊        | 44/247 [00:10<00:46,  4.34it/s]Loading trainS:  18%|█▊        | 45/247 [00:10<00:46,  4.34it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:46,  4.35it/s]Loading trainS:  19%|█▉        | 47/247 [00:11<00:46,  4.32it/s]Loading trainS:  19%|█▉        | 48/247 [00:11<00:46,  4.32it/s]Loading trainS:  20%|█▉        | 49/247 [00:11<00:45,  4.32it/s]Loading trainS:  20%|██        | 50/247 [00:11<00:45,  4.33it/s]Loading trainS:  21%|██        | 51/247 [00:12<00:45,  4.33it/s]Loading trainS:  21%|██        | 52/247 [00:12<00:45,  4.33it/s]Loading trainS:  21%|██▏       | 53/247 [00:12<00:44,  4.34it/s]Loading trainS:  22%|██▏       | 54/247 [00:12<00:44,  4.34it/s]Loading trainS:  22%|██▏       | 55/247 [00:12<00:44,  4.32it/s]Loading trainS:  23%|██▎       | 56/247 [00:13<00:44,  4.30it/s]Loading trainS:  23%|██▎       | 57/247 [00:13<00:44,  4.29it/s]Loading trainS:  23%|██▎       | 58/247 [00:13<00:43,  4.33it/s]Loading trainS:  24%|██▍       | 59/247 [00:13<00:43,  4.30it/s]Loading trainS:  24%|██▍       | 60/247 [00:14<00:44,  4.23it/s]Loading trainS:  25%|██▍       | 61/247 [00:14<00:44,  4.20it/s]Loading trainS:  25%|██▌       | 62/247 [00:14<00:44,  4.20it/s]Loading trainS:  26%|██▌       | 63/247 [00:14<00:44,  4.18it/s]Loading trainS:  26%|██▌       | 64/247 [00:15<00:43,  4.17it/s]Loading trainS:  26%|██▋       | 65/247 [00:15<00:44,  4.13it/s]Loading trainS:  27%|██▋       | 66/247 [00:15<00:43,  4.17it/s]Loading trainS:  27%|██▋       | 67/247 [00:15<00:42,  4.20it/s]Loading trainS:  28%|██▊       | 68/247 [00:16<00:42,  4.21it/s]Loading trainS:  28%|██▊       | 69/247 [00:16<00:42,  4.21it/s]Loading trainS:  28%|██▊       | 70/247 [00:16<00:42,  4.17it/s]Loading trainS:  29%|██▊       | 71/247 [00:16<00:42,  4.18it/s]Loading trainS:  29%|██▉       | 72/247 [00:17<00:41,  4.18it/s]Loading trainS:  30%|██▉       | 73/247 [00:17<00:41,  4.18it/s]Loading trainS:  30%|██▉       | 74/247 [00:17<00:41,  4.19it/s]Loading trainS:  30%|███       | 75/247 [00:17<00:41,  4.19it/s]Loading trainS:  31%|███       | 76/247 [00:18<00:40,  4.19it/s]Loading trainS:  31%|███       | 77/247 [00:18<00:41,  4.15it/s]Loading trainS:  32%|███▏      | 78/247 [00:18<00:43,  3.89it/s]Loading trainS:  32%|███▏      | 79/247 [00:18<00:43,  3.89it/s]Loading trainS:  32%|███▏      | 80/247 [00:19<00:40,  4.10it/s]Loading trainS:  33%|███▎      | 81/247 [00:19<00:40,  4.08it/s]Loading trainS:  33%|███▎      | 82/247 [00:19<00:39,  4.15it/s]Loading trainS:  34%|███▎      | 83/247 [00:19<00:39,  4.18it/s]Loading trainS:  34%|███▍      | 84/247 [00:19<00:38,  4.21it/s]Loading trainS:  34%|███▍      | 85/247 [00:20<00:38,  4.23it/s]Loading trainS:  35%|███▍      | 86/247 [00:20<00:38,  4.23it/s]Loading trainS:  35%|███▌      | 87/247 [00:20<00:37,  4.23it/s]Loading trainS:  36%|███▌      | 88/247 [00:20<00:38,  4.17it/s]Loading trainS:  36%|███▌      | 89/247 [00:21<00:37,  4.16it/s]Loading trainS:  36%|███▋      | 90/247 [00:21<00:38,  4.05it/s]Loading trainS:  37%|███▋      | 91/247 [00:21<00:37,  4.12it/s]Loading trainS:  37%|███▋      | 92/247 [00:21<00:37,  4.17it/s]Loading trainS:  38%|███▊      | 93/247 [00:22<00:36,  4.19it/s]Loading trainS:  38%|███▊      | 94/247 [00:22<00:36,  4.21it/s]Loading trainS:  38%|███▊      | 95/247 [00:22<00:35,  4.24it/s]Loading trainS:  39%|███▉      | 96/247 [00:22<00:35,  4.22it/s]Loading trainS:  39%|███▉      | 97/247 [00:23<00:36,  4.12it/s]Loading trainS:  40%|███▉      | 98/247 [00:23<00:35,  4.17it/s]Loading trainS:  40%|████      | 99/247 [00:23<00:34,  4.23it/s]Loading trainS:  40%|████      | 100/247 [00:23<00:36,  4.07it/s]Loading trainS:  41%|████      | 101/247 [00:24<00:36,  3.98it/s]Loading trainS:  41%|████▏     | 102/247 [00:24<00:37,  3.92it/s]Loading trainS:  42%|████▏     | 103/247 [00:24<00:37,  3.87it/s]Loading trainS:  42%|████▏     | 104/247 [00:24<00:37,  3.83it/s]Loading trainS:  43%|████▎     | 105/247 [00:25<00:37,  3.79it/s]Loading trainS:  43%|████▎     | 106/247 [00:25<00:37,  3.77it/s]Loading trainS:  43%|████▎     | 107/247 [00:25<00:37,  3.74it/s]Loading trainS:  44%|████▎     | 108/247 [00:25<00:37,  3.71it/s]Loading trainS:  44%|████▍     | 109/247 [00:26<00:37,  3.69it/s]Loading trainS:  45%|████▍     | 110/247 [00:26<00:37,  3.70it/s]Loading trainS:  45%|████▍     | 111/247 [00:26<00:36,  3.71it/s]Loading trainS:  45%|████▌     | 112/247 [00:27<00:36,  3.72it/s]Loading trainS:  46%|████▌     | 113/247 [00:27<00:36,  3.72it/s]Loading trainS:  46%|████▌     | 114/247 [00:27<00:35,  3.71it/s]Loading trainS:  47%|████▋     | 115/247 [00:27<00:35,  3.72it/s]Loading trainS:  47%|████▋     | 116/247 [00:28<00:35,  3.74it/s]Loading trainS:  47%|████▋     | 117/247 [00:28<00:35,  3.70it/s]Loading trainS:  48%|████▊     | 118/247 [00:28<00:33,  3.85it/s]Loading trainS:  48%|████▊     | 119/247 [00:28<00:32,  3.94it/s]Loading trainS:  49%|████▊     | 120/247 [00:29<00:31,  4.02it/s]Loading trainS:  49%|████▉     | 121/247 [00:29<00:30,  4.07it/s]Loading trainS:  49%|████▉     | 122/247 [00:29<00:30,  4.08it/s]Loading trainS:  50%|████▉     | 123/247 [00:29<00:30,  4.09it/s]Loading trainS:  50%|█████     | 124/247 [00:30<00:30,  4.08it/s]Loading trainS:  51%|█████     | 125/247 [00:30<00:29,  4.12it/s]Loading trainS:  51%|█████     | 126/247 [00:30<00:29,  4.13it/s]Loading trainS:  51%|█████▏    | 127/247 [00:30<00:28,  4.14it/s]Loading trainS:  52%|█████▏    | 128/247 [00:31<00:28,  4.14it/s]Loading trainS:  52%|█████▏    | 129/247 [00:31<00:28,  4.14it/s]Loading trainS:  53%|█████▎    | 130/247 [00:31<00:28,  4.10it/s]Loading trainS:  53%|█████▎    | 131/247 [00:31<00:28,  4.03it/s]Loading trainS:  53%|█████▎    | 132/247 [00:32<00:28,  4.03it/s]Loading trainS:  54%|█████▍    | 133/247 [00:32<00:28,  4.07it/s]Loading trainS:  54%|█████▍    | 134/247 [00:32<00:27,  4.10it/s]Loading trainS:  55%|█████▍    | 135/247 [00:32<00:27,  4.12it/s]Loading trainS:  55%|█████▌    | 136/247 [00:32<00:25,  4.33it/s]Loading trainS:  55%|█████▌    | 137/247 [00:33<00:24,  4.50it/s]Loading trainS:  56%|█████▌    | 138/247 [00:33<00:23,  4.63it/s]Loading trainS:  56%|█████▋    | 139/247 [00:33<00:22,  4.72it/s]Loading trainS:  57%|█████▋    | 140/247 [00:33<00:22,  4.79it/s]Loading trainS:  57%|█████▋    | 141/247 [00:33<00:21,  4.84it/s]Loading trainS:  57%|█████▋    | 142/247 [00:34<00:21,  4.88it/s]Loading trainS:  58%|█████▊    | 143/247 [00:34<00:21,  4.90it/s]Loading trainS:  58%|█████▊    | 144/247 [00:34<00:21,  4.90it/s]Loading trainS:  59%|█████▊    | 145/247 [00:34<00:20,  4.91it/s]Loading trainS:  59%|█████▉    | 146/247 [00:34<00:20,  4.93it/s]Loading trainS:  60%|█████▉    | 147/247 [00:35<00:20,  4.94it/s]Loading trainS:  60%|█████▉    | 148/247 [00:35<00:19,  4.95it/s]Loading trainS:  60%|██████    | 149/247 [00:35<00:19,  4.93it/s]Loading trainS:  61%|██████    | 150/247 [00:35<00:19,  4.94it/s]Loading trainS:  61%|██████    | 151/247 [00:35<00:19,  4.90it/s]Loading trainS:  62%|██████▏   | 152/247 [00:36<00:19,  4.90it/s]Loading trainS:  62%|██████▏   | 153/247 [00:36<00:19,  4.92it/s]Loading trainS:  62%|██████▏   | 154/247 [00:36<00:19,  4.71it/s]Loading trainS:  63%|██████▎   | 155/247 [00:36<00:20,  4.59it/s]Loading trainS:  63%|██████▎   | 156/247 [00:37<00:20,  4.52it/s]Loading trainS:  64%|██████▎   | 157/247 [00:37<00:20,  4.45it/s]Loading trainS:  64%|██████▍   | 158/247 [00:37<00:20,  4.36it/s]Loading trainS:  64%|██████▍   | 159/247 [00:37<00:20,  4.40it/s]Loading trainS:  65%|██████▍   | 160/247 [00:38<00:19,  4.42it/s]Loading trainS:  65%|██████▌   | 161/247 [00:38<00:19,  4.44it/s]Loading trainS:  66%|██████▌   | 162/247 [00:38<00:19,  4.45it/s]Loading trainS:  66%|██████▌   | 163/247 [00:38<00:18,  4.45it/s]Loading trainS:  66%|██████▋   | 164/247 [00:38<00:18,  4.44it/s]Loading trainS:  67%|██████▋   | 165/247 [00:39<00:18,  4.44it/s]Loading trainS:  67%|██████▋   | 166/247 [00:39<00:18,  4.44it/s]Loading trainS:  68%|██████▊   | 167/247 [00:39<00:17,  4.45it/s]Loading trainS:  68%|██████▊   | 168/247 [00:39<00:17,  4.45it/s]Loading trainS:  68%|██████▊   | 169/247 [00:40<00:17,  4.43it/s]Loading trainS:  69%|██████▉   | 170/247 [00:40<00:17,  4.43it/s]Loading trainS:  69%|██████▉   | 171/247 [00:40<00:17,  4.42it/s]Loading trainS:  70%|██████▉   | 172/247 [00:40<00:17,  4.27it/s]Loading trainS:  70%|███████   | 173/247 [00:40<00:17,  4.24it/s]Loading trainS:  70%|███████   | 174/247 [00:41<00:17,  4.16it/s]Loading trainS:  71%|███████   | 175/247 [00:41<00:17,  4.02it/s]Loading trainS:  71%|███████▏  | 176/247 [00:41<00:17,  4.13it/s]Loading trainS:  72%|███████▏  | 177/247 [00:41<00:16,  4.20it/s]Loading trainS:  72%|███████▏  | 178/247 [00:42<00:16,  4.24it/s]Loading trainS:  72%|███████▏  | 179/247 [00:42<00:15,  4.29it/s]Loading trainS:  73%|███████▎  | 180/247 [00:42<00:15,  4.27it/s]Loading trainS:  73%|███████▎  | 181/247 [00:42<00:15,  4.28it/s]Loading trainS:  74%|███████▎  | 182/247 [00:43<00:15,  4.26it/s]Loading trainS:  74%|███████▍  | 183/247 [00:43<00:14,  4.27it/s]Loading trainS:  74%|███████▍  | 184/247 [00:43<00:14,  4.27it/s]Loading trainS:  75%|███████▍  | 185/247 [00:43<00:14,  4.28it/s]Loading trainS:  75%|███████▌  | 186/247 [00:44<00:14,  4.29it/s]Loading trainS:  76%|███████▌  | 187/247 [00:44<00:13,  4.33it/s]Loading trainS:  76%|███████▌  | 188/247 [00:44<00:13,  4.35it/s]Loading trainS:  77%|███████▋  | 189/247 [00:44<00:13,  4.34it/s]Loading trainS:  77%|███████▋  | 190/247 [00:44<00:13,  4.33it/s]Loading trainS:  77%|███████▋  | 191/247 [00:45<00:12,  4.31it/s]Loading trainS:  78%|███████▊  | 192/247 [00:45<00:12,  4.27it/s]Loading trainS:  78%|███████▊  | 193/247 [00:45<00:12,  4.26it/s]Loading trainS:  79%|███████▊  | 194/247 [00:45<00:12,  4.30it/s]Loading trainS:  79%|███████▉  | 195/247 [00:46<00:11,  4.35it/s]Loading trainS:  79%|███████▉  | 196/247 [00:46<00:11,  4.38it/s]Loading trainS:  80%|███████▉  | 197/247 [00:46<00:11,  4.39it/s]Loading trainS:  80%|████████  | 198/247 [00:46<00:11,  4.40it/s]Loading trainS:  81%|████████  | 199/247 [00:47<00:10,  4.37it/s]Loading trainS:  81%|████████  | 200/247 [00:47<00:10,  4.36it/s]Loading trainS:  81%|████████▏ | 201/247 [00:47<00:10,  4.41it/s]Loading trainS:  82%|████████▏ | 202/247 [00:47<00:10,  4.43it/s]Loading trainS:  82%|████████▏ | 203/247 [00:47<00:09,  4.43it/s]Loading trainS:  83%|████████▎ | 204/247 [00:48<00:09,  4.43it/s]Loading trainS:  83%|████████▎ | 205/247 [00:48<00:09,  4.43it/s]Loading trainS:  83%|████████▎ | 206/247 [00:48<00:09,  4.42it/s]Loading trainS:  84%|████████▍ | 207/247 [00:48<00:09,  4.41it/s]Loading trainS:  84%|████████▍ | 208/247 [00:49<00:08,  4.34it/s]Loading trainS:  85%|████████▍ | 209/247 [00:49<00:08,  4.38it/s]Loading trainS:  85%|████████▌ | 210/247 [00:49<00:08,  4.38it/s]Loading trainS:  85%|████████▌ | 211/247 [00:49<00:08,  4.39it/s]Loading trainS:  86%|████████▌ | 212/247 [00:50<00:08,  4.32it/s]Loading trainS:  86%|████████▌ | 213/247 [00:50<00:07,  4.31it/s]Loading trainS:  87%|████████▋ | 214/247 [00:50<00:07,  4.30it/s]Loading trainS:  87%|████████▋ | 215/247 [00:50<00:07,  4.26it/s]Loading trainS:  87%|████████▋ | 216/247 [00:50<00:07,  4.27it/s]Loading trainS:  88%|████████▊ | 217/247 [00:51<00:06,  4.29it/s]Loading trainS:  88%|████████▊ | 218/247 [00:51<00:06,  4.31it/s]Loading trainS:  89%|████████▊ | 219/247 [00:51<00:06,  4.32it/s]Loading trainS:  89%|████████▉ | 220/247 [00:51<00:06,  4.29it/s]Loading trainS:  89%|████████▉ | 221/247 [00:52<00:06,  4.27it/s]Loading trainS:  90%|████████▉ | 222/247 [00:52<00:05,  4.27it/s]Loading trainS:  90%|█████████ | 223/247 [00:52<00:05,  4.28it/s]Loading trainS:  91%|█████████ | 224/247 [00:52<00:05,  4.22it/s]Loading trainS:  91%|█████████ | 225/247 [00:53<00:05,  4.21it/s]Loading trainS:  91%|█████████▏| 226/247 [00:53<00:05,  4.17it/s]Loading trainS:  92%|█████████▏| 227/247 [00:53<00:04,  4.19it/s]Loading trainS:  92%|█████████▏| 228/247 [00:53<00:04,  4.23it/s]Loading trainS:  93%|█████████▎| 229/247 [00:54<00:04,  4.24it/s]Loading trainS:  93%|█████████▎| 230/247 [00:54<00:04,  4.09it/s]Loading trainS:  94%|█████████▎| 231/247 [00:54<00:03,  4.01it/s]Loading trainS:  94%|█████████▍| 232/247 [00:54<00:03,  3.94it/s]Loading trainS:  94%|█████████▍| 233/247 [00:55<00:03,  3.87it/s]Loading trainS:  95%|█████████▍| 234/247 [00:55<00:03,  3.86it/s]Loading trainS:  95%|█████████▌| 235/247 [00:55<00:03,  3.81it/s]Loading trainS:  96%|█████████▌| 236/247 [00:55<00:02,  3.82it/s]Loading trainS:  96%|█████████▌| 237/247 [00:56<00:02,  3.84it/s]Loading trainS:  96%|█████████▋| 238/247 [00:56<00:02,  3.85it/s]Loading trainS:  97%|█████████▋| 239/247 [00:56<00:02,  3.84it/s]Loading trainS:  97%|█████████▋| 240/247 [00:56<00:01,  3.89it/s]Loading trainS:  98%|█████████▊| 241/247 [00:57<00:01,  3.89it/s]Loading trainS:  98%|█████████▊| 242/247 [00:57<00:01,  3.90it/s]Loading trainS:  98%|█████████▊| 243/247 [00:57<00:01,  3.93it/s]Loading trainS:  99%|█████████▉| 244/247 [00:57<00:00,  3.96it/s]Loading trainS:  99%|█████████▉| 245/247 [00:58<00:00,  3.95it/s]Loading trainS: 100%|█████████▉| 246/247 [00:58<00:00,  3.96it/s]Loading trainS: 100%|██████████| 247/247 [00:58<00:00,  3.92it/s]Loading trainS: 100%|██████████| 247/247 [00:58<00:00,  4.21it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:03,  1.11it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.14it/s]Loading testS:  60%|██████    | 3/5 [00:02<00:01,  1.27it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.33it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.44it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.41it/s]
Epoch 00047: val_mDice did not improve from 0.23598
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
{'val_loss': [0.6782922360204882, 0.554810655693854, 0.0955200653763548, -0.039984802805608316, -0.06066663124628605, -0.07569422022319369, -0.12436360367123157, -0.03673731182671843, 0.0060308312456454, -0.1510684644172509, -0.13280881163213523, -0.1320088395788785, -0.14548127651740347, -0.13582247171190479, -0.09730057722903908, -0.10738898086692056, -0.12471048491856744, -0.1687447414883683, -0.12661791922930146, -0.17877493747660228, -0.1926242374785004, -0.23127900214204866, -0.20040050136946863, -0.2009015385542185, -0.2131300690553842, -0.2179347045340335, -0.21180960914540675, -0.21192354468568678, -0.18861194643672677, -0.2227417465389496, -0.1645982120666773, -0.18872164065889532, -0.19786224706519034, -0.19867922993557108, -0.21281172419267316, -0.20054342530127015, -0.21666752353250499, -0.2345417902294186, -0.229550140181316, -0.22621127390753357, -0.23961013576556597, -0.22512982034822926, -0.22423380410539046, -0.2423955459793609, -0.23098160797024087, -0.23248671995656145, -0.2265394486096357], 'val_acc': [0.9321585509084886, 0.9329313981917596, 0.9390780098976628, 0.9392886700168732, 0.9437590452932543, 0.9389500637208262, 0.9428492073089846, 0.9441338392996019, 0.9306748913180444, 0.9414611727960648, 0.9435341723503605, 0.94021919081288, 0.9411161099710772, 0.9415141632480006, 0.9404647427220498, 0.9423387069855967, 0.9415723200767271, 0.9417429181837267, 0.9419962283103697, 0.9446236568112527, 0.9435962073264583, 0.9477396126716368, 0.9440575876543599, 0.9449816480759652, 0.9462210497548503, 0.9456911702309886, 0.9458540120432454, 0.9447528950629696, 0.9439050843638759, 0.946436878173582, 0.9386760727051766, 0.9420453367694732, 0.9417054383985458, 0.9453021595554967, 0.946381309340077, 0.9435755302829127, 0.9430559873580933, 0.9440175256421489, 0.9434527485601364, 0.9441661527079921, 0.9456045800639737, 0.94283111633793, 0.9432395062138957, 0.9451005478059092, 0.9440317346203712, 0.9442488608821746, 0.9444026600929999], 'val_mDice': [0.21084866552583634, 0.20430524226638577, 0.21730682181735192, 0.22197375302353212, 0.22275405028654682, 0.22939511016011238, 0.2359809065538068, 0.2247742532241729, 0.22563938580213055, 0.23061342921949202, 0.23473213420760247, 0.22938660736526212, 0.2271910333825696, 0.22875987882575682, 0.22148096621517213, 0.23337043797777546, 0.23060558303709952, 0.23263498804261606, 0.22516275569796562, 0.22945723141874036, 0.22192819740983746, 0.23460274934768677, 0.22615681071915933, 0.23124243763666, 0.22752248928431543, 0.22502352537647372, 0.22447574535204518, 0.22646600008010864, 0.23000728975861304, 0.2215304617439547, 0.20688039497021707, 0.19485577520343564, 0.22300926043141273, 0.2278240411992996, 0.2273850291967392, 0.2294728173123252, 0.22580286728278284, 0.21884936683120265, 0.22764592761954955, 0.22578756042545842, 0.22531021963204106, 0.22599509466559656, 0.22379882874027376, 0.22427573715967516, 0.22846969385300914, 0.2273020524411432, 0.2178048481864314], 'loss': [0.5867739170111953, 0.4407947849847807, 0.40741774681870857, 0.3861297219701213, 0.3739172435372274, 0.36487127656553997, 0.35313323925384227, 0.3485972122026001, 0.34355726764525896, 0.3379987352772763, 0.3315257905868062, 0.3310153919760479, 0.3270739432741404, 0.32720975920587025, 0.32277664091968167, 0.32024140419744684, 0.3229906425857947, 0.31225771764371985, 0.3146795970499709, 0.33686261206303736, 0.3063375903311645, 0.29996038989912505, 0.2807345848501484, 0.27104613809017897, 0.26873162409921236, 0.2680065651509555, 0.26698585665137875, 0.263090960509879, 0.2618928498668987, 0.25564555934363464, 0.2503908878907269, 0.26105406381373786, 0.25733419915195554, 0.25145928594796624, 0.24594750046540026, 0.24466817107979302, 0.2462197427269945, 0.2346243725546779, 0.2366649322018095, 0.2325128896661993, 0.2298759071079529, 0.2277895299726256, 0.2319674953515596, 0.2241269670302185, 0.22711058204127943, 0.22729580303754832, 0.22317595477510954], 'acc': [0.8838168368895694, 0.9361070237661663, 0.9401706536146167, 0.9425393566828102, 0.9439635968115362, 0.9453022688375502, 0.9462114563617248, 0.9469488541207738, 0.9470844839671124, 0.9477007526945495, 0.948500940867877, 0.9487964625944171, 0.9490162812323443, 0.9493604323320222, 0.9497692990101646, 0.9499693072562562, 0.9497991597753132, 0.9506534172235331, 0.9502847699316544, 0.9464159414239949, 0.9466106653833173, 0.9470070626845679, 0.9484911535838116, 0.9489093394617201, 0.9491527182394378, 0.9489934000587835, 0.9489927480869901, 0.9489589063977173, 0.9492768149936718, 0.9493806858663826, 0.9497750528916823, 0.9488952562668015, 0.9490616310332176, 0.9495937101944768, 0.949450583485832, 0.9494568303546943, 0.9496509815052471, 0.9501425286947403, 0.9503870002630084, 0.9507254749788255, 0.9507123547145653, 0.9505477515500114, 0.9501833471096205, 0.9506203302165919, 0.9507311764981082, 0.9503205645541388, 0.9505512396029794], 'mDice': [0.36732020394911696, 0.5245571377952816, 0.5605860636209496, 0.5835797708285483, 0.5967652286857347, 0.6065372480944893, 0.6192226168433903, 0.6241287754254344, 0.629589545234912, 0.6356032932246173, 0.642595630775728, 0.6431528604247494, 0.647422018242471, 0.6472657369358963, 0.6520616631565194, 0.6547952518593265, 0.6517976123919497, 0.6633590138756353, 0.6588677745929703, 0.6091575127015104, 0.6213225839469555, 0.6182279015532401, 0.6343559061187363, 0.6402303531543243, 0.6419567882027077, 0.6389435892410291, 0.6373486650733687, 0.6387939607074619, 0.6349580317367742, 0.6409314095809369, 0.6474152140856718, 0.6332244764798024, 0.6323847033862869, 0.6415823140339545, 0.64069918361556, 0.6404419384698267, 0.6439638939129989, 0.6527856032595842, 0.655333541987235, 0.6535655165779816, 0.6591051580109637, 0.6551505732915864, 0.6475084879767825, 0.6544248952812929, 0.659256032258369, 0.650504678177942, 0.6530538753033304], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     2020-01-21 21:14:13.626605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 21:14:13.626686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 21:14:13.626699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 21:14:13.626708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 21:14:13.627024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97300229 0.02699771]
Train on 15751 samples, validate on 333 samples
Epoch 1/300
 - 45s - loss: 0.2118 - acc: 0.9833 - mDice: 0.5852 - val_loss: 0.2151 - val_acc: 0.9876 - val_mDice: 0.3966

Epoch 00001: val_mDice improved from -inf to 0.39663, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 42s - loss: 0.0853 - acc: 0.9911 - mDice: 0.8340 - val_loss: 0.1453 - val_acc: 0.9874 - val_mDice: 0.4034

Epoch 00002: val_mDice improved from 0.39663 to 0.40337, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 40s - loss: 0.0753 - acc: 0.9920 - mDice: 0.8536 - val_loss: 0.1173 - val_acc: 0.9916 - val_mDice: 0.4235

Epoch 00003: val_mDice improved from 0.40337 to 0.42352, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 40s - loss: 0.0723 - acc: 0.9925 - mDice: 0.8592 - val_loss: 0.0646 - val_acc: 0.9910 - val_mDice: 0.4083

Epoch 00004: val_mDice did not improve from 0.42352
Epoch 5/300
 - 40s - loss: 0.0649 - acc: 0.9930 - mDice: 0.8738 - val_loss: 0.1164 - val_acc: 0.9908 - val_mDice: 0.4349

Epoch 00005: val_mDice improved from 0.42352 to 0.43487, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 40s - loss: 0.0636 - acc: 0.9932 - mDice: 0.8763 - val_loss: 0.1383 - val_acc: 0.9915 - val_mDice: 0.4420

Epoch 00006: val_mDice improved from 0.43487 to 0.44201, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 7/300
 - 40s - loss: 0.0623 - acc: 0.9934 - mDice: 0.8788 - val_loss: 0.2311 - val_acc: 0.9619 - val_mDice: 0.3651

Epoch 00007: val_mDice did not improve from 0.44201
Epoch 8/300
 - 40s - loss: 0.0579 - acc: 0.9936 - mDice: 0.8875 - val_loss: 0.1655 - val_acc: 0.9917 - val_mDice: 0.4574

Epoch 00008: val_mDice improved from 0.44201 to 0.45736, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 9/300
 - 40s - loss: 0.0583 - acc: 0.9937 - mDice: 0.8866 - val_loss: 0.1042 - val_acc: 0.9920 - val_mDice: 0.4341

Epoch 00009: val_mDice did not improve from 0.45736
Epoch 10/300
 - 40s - loss: 0.0562 - acc: 0.9939 - mDice: 0.8906 - val_loss: 0.0354 - val_acc: 0.9908 - val_mDice: 0.4146

Epoch 00010: val_mDice did not improve from 0.45736
Epoch 11/300
 - 40s - loss: 0.0566 - acc: 0.9939 - mDice: 0.8898 - val_loss: 0.0752 - val_acc: 0.9921 - val_mDice: 0.4503

Epoch 00011: val_mDice did not improve from 0.45736
Epoch 12/300
 - 40s - loss: 0.0534 - acc: 0.9941 - mDice: 0.8962 - val_loss: 0.1978 - val_acc: 0.9776 - val_mDice: 0.4188

Epoch 00012: val_mDice did not improve from 0.45736
Epoch 13/300
 - 40s - loss: 0.0528 - acc: 0.9942 - mDice: 0.8974 - val_loss: 0.1172 - val_acc: 0.9907 - val_mDice: 0.4611

Epoch 00013: val_mDice improved from 0.45736 to 0.46111, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 14/300
 - 41s - loss: 0.0514 - acc: 0.9942 - mDice: 0.9001 - val_loss: 0.1243 - val_acc: 0.9916 - val_mDice: 0.4364

Epoch 00014: val_mDice did not improve from 0.46111
Epoch 15/300
 - 41s - loss: 0.0523 - acc: 0.9943 - mDice: 0.8984 - val_loss: 0.0106 - val_acc: 0.9909 - val_mDice: 0.4447

Epoch 00015: val_mDice did not improve from 0.46111
Epoch 16/300
 - 40s - loss: 0.0508 - acc: 0.9944 - mDice: 0.9013 - val_loss: 0.2233 - val_acc: 0.9890 - val_mDice: 0.4542

Epoch 00016: val_mDice did not improve from 0.46111
Epoch 17/300
 - 40s - loss: 0.0498 - acc: 0.9945 - mDice: 0.9031 - val_loss: 0.1988 - val_acc: 0.9816 - val_mDice: 0.4240

Epoch 00017: val_mDice did not improve from 0.46111
Epoch 18/300
 - 40s - loss: 0.0493 - acc: 0.9946 - mDice: 0.9042 - val_loss: 0.1255 - val_acc: 0.9916 - val_mDice: 0.4557

Epoch 00018: val_mDice did not improve from 0.46111
Epoch 19/300
 - 40s - loss: 0.0493 - acc: 0.9946 - mDice: 0.9041 - val_loss: 0.1031 - val_acc: 0.9920 - val_mDice: 0.4630

Epoch 00019: val_mDice improved from 0.46111 to 0.46295, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 20/300
 - 40s - loss: 0.0474 - acc: 0.9946 - mDice: 0.9079 - val_loss: 0.2024 - val_acc: 0.9832 - val_mDice: 0.4305

Epoch 00020: val_mDice did not improve from 0.46295
Epoch 21/300
 - 40s - loss: 0.0477 - acc: 0.9947 - mDice: 0.9074 - val_loss: 0.1970 - val_acc: 0.9923 - val_mDice: 0.4603

Epoch 00021: val_mDice did not improve from 0.46295
Epoch 22/300
 - 40s - loss: 0.0490 - acc: 0.9946 - mDice: 0.9047 - val_loss: 0.0906 - val_acc: 0.9914 - val_mDice: 0.4552

Epoch 00022: val_mDice did not improve from 0.46295
Epoch 23/300
 - 40s - loss: 0.0463 - acc: 0.9948 - mDice: 0.9101 - val_loss: 0.0132 - val_acc: 0.9880 - val_mDice: 0.3611

Epoch 00023: val_mDice did not improve from 0.46295
Epoch 24/300
 - 40s - loss: 0.0458 - acc: 0.9948 - mDice: 0.9110 - val_loss: 0.0781 - val_acc: 0.9925 - val_mDice: 0.4654

Epoch 00024: val_mDice improved from 0.46295 to 0.46542, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 25/300
 - 40s - loss: 0.0465 - acc: 0.9948 - mDice: 0.9096 - val_loss: 0.2164 - val_acc: 0.9907 - val_mDice: 0.4573

Epoch 00025: val_mDice did not improve from 0.46542
Epoch 26/300
 - 40s - loss: 0.0455 - acc: 0.9948 - mDice: 0.9115 - val_loss: 0.0796 - val_acc: 0.9919 - val_mDice: 0.4547

Epoch 00026: val_mDice did not improve from 0.46542
Epoch 27/300
 - 40s - loss: 0.0451 - acc: 0.9949 - mDice: 0.9125 - val_loss: 0.0561 - val_acc: 0.9911 - val_mDice: 0.4421

Epoch 00027: val_mDice did not improve from 0.46542
Epoch 28/300
 - 40s - loss: 0.0441 - acc: 0.9949 - mDice: 0.9144 - val_loss: 0.0280 - val_acc: 0.9916 - val_mDice: 0.4593

Epoch 00028: val_mDice did not improve from 0.46542
Epoch 29/300
 - 43s - loss: 0.0450 - acc: 0.9950 - mDice: 0.9126 - val_loss: 0.1323 - val_acc: 0.9914 - val_mDice: 0.4715

Epoch 00029: val_mDice improved from 0.46542 to 0.47153, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 30/300
 - 40s - loss: 0.0450 - acc: 0.9949 - mDice: 0.9126 - val_loss: 0.0843 - val_acc: 0.9889 - val_mDice: 0.3885

Epoch 00030: val_mDice did not improve from 0.47153
Epoch 31/300
 - 40s - loss: 0.0435 - acc: 0.9951 - mDice: 0.9154 - val_loss: 0.0459 - val_acc: 0.9918 - val_mDice: 0.4557

Epoch 00031: val_mDice did not improve from 0.47153
Epoch 32/300
 - 41s - loss: 0.0450 - acc: 0.9950 - mDice: 0.9125 - val_loss: 0.0882 - val_acc: 0.9895 - val_mDice: 0.4093

Epoch 00032: val_mDice did not improve from 0.47153
Epoch 33/300
 - 41s - loss: 0.0425 - acc: 0.9951 - mDice: 0.9176 - val_loss: 0.0996 - val_acc: 0.9903 - val_mDice: 0.4300

Epoch 00033: val_mDice did not improve from 0.47153
Epoch 34/300
 - 41s - loss: 0.0431 - acc: 0.9951 - mDice: 0.9164 - val_loss: 0.1235 - val_acc: 0.9919 - val_mDice: 0.4621

Epoch 00034: val_mDice did not improve from 0.47153
Epoch 35/300
 - 40s - loss: 0.0425 - acc: 0.9951 - mDice: 0.9175 - val_loss: 0.0683 - val_acc: 0.9921 - val_mDice: 0.4617

Epoch 00035: val_mDice did not improve from 0.47153
Epoch 36/300
 - 40s - loss: 0.0432 - acc: 0.9951 - mDice: 0.9160 - val_loss: 0.2028 - val_acc: 0.9901 - val_mDice: 0.4700

Epoch 00036: val_mDice did not improve from 0.47153
Epoch 37/300
 - 40s - loss: 0.0418 - acc: 0.9952 - mDice: 0.9189 - val_loss: 0.1175 - val_acc: 0.9902 - val_mDice: 0.4570

Epoch 00037: val_mDice did not improve from 0.47153
Epoch 38/300
 - 40s - loss: 0.0411 - acc: 0.9952 - mDice: 0.9202 - val_loss: 0.0894 - val_acc: 0.9914 - val_mDice: 0.4490

Epoch 00038: val_mDice did not improve from 0.47153
Epoch 39/300
 - 40s - loss: 0.0423 - acc: 0.9952 - mDice: 0.9178 - val_loss: 0.0896 - val_acc: 0.9917 - val_mDice: 0.4594

Epoch 00039: val_mDice did not improve from 0.47153
Epoch 40/300
 - 40s - loss: 0.0415 - acc: 0.9952 - mDice: 0.9194 - val_loss: 0.1070 - val_acc: 0.9929 - val_mDice: 0.4729

Epoch 00040: val_mDice improved from 0.47153 to 0.47293, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 41/300
 - 40s - loss: 0.0407 - acc: 0.9952 - mDice: 0.9211 - val_loss: 0.0898 - val_acc: 0.9918 - val_mDice: 0.4647

Epoch 00041: val_mDice did not improve from 0.47293
Epoch 42/300
 - 40s - loss: 0.0414 - acc: 0.9952 - mDice: 0.9196 - val_loss: 0.0648 - val_acc: 0.9923 - val_mDice: 0.4724

Epoch 00042: val_mDice did not improve from 0.47293
Epoch 43/300
 - 40s - loss: 0.0405 - acc: 0.9953 - mDice: 0.9214 - val_loss: 0.1103 - val_acc: 0.9929 - val_mDice: 0.4882

Epoch 00043: val_mDice improved from 0.47293 to 0.48821, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 44/300
 - 40s - loss: 0.0413 - acc: 0.9953 - mDice: 0.9199 - val_loss: 0.1688 - val_acc: 0.9908 - val_mDice: 0.4664

Epoch 00044: val_mDice did not improve from 0.48821
Epoch 45/300
 - 40s - loss: 0.0413 - acc: 0.9953 - mDice: 0.9199 - val_loss: -1.7933e-02 - val_acc: 0.9883 - val_mDice: 0.3986

Epoch 00045: val_mDice did not improve from 0.48821
Epoch 46/300
 - 40s - loss: 0.0413 - acc: 0.9952 - mDice: 0.9198 - val_loss: 0.1803 - val_acc: 0.9889 - val_mDice: 0.4500

Epoch 00046: val_mDice did not improve from 0.48821
Epoch 47/300
 - 40s - loss: 0.0397 - acc: 0.9953 - mDice: 0.9230 - val_loss: 0.0902 - val_acc: 0.9925 - val_mDice: 0.4672

Epoch 00047: val_mDice did not improve from 0.48821
Epoch 48/300
 - 40s - loss: 0.0399 - acc: 0.9953 - mDice: 0.9225 - val_loss: 0.1198 - val_acc: 0.9929 - val_mDice: 0.4829

Epoch 00048: val_mDice did not improve from 0.48821
Epoch 49/300
 - 40s - loss: 0.0396 - acc: 0.9954 - mDice: 0.9230 - val_loss: 0.1167 - val_acc: 0.9903 - val_mDice: 0.4545

Epoch 00049: val_mDice did not improve from 0.48821
Epoch 50/300
 - 40s - loss: 0.0398 - acc: 0.9953 - mDice: 0.9227 - val_loss: 0.0829 - val_acc: 0.9921 - val_mDice: 0.4614

Epoch 00050: val_mDice did not improve from 0.48821
Epoch 51/300
 - 41s - loss: 0.0396 - acc: 0.9954 - mDice: 0.9231 - val_loss: 0.0428 - val_acc: 0.9923 - val_mDice: 0.4806

Epoch 00051: val_mDice did not improve from 0.48821
Epoch 52/300
 - 41s - loss: 0.0402 - acc: 0.9953 - mDice: 0.9219 - val_loss: 0.1014 - val_acc: 0.9911 - val_mDice: 0.4479

Epoch 00052: val_mDice did not improve from 0.48821
Epoch 53/300
 - 40s - loss: 0.0397 - acc: 0.9954 - mDice: 0.9229 - val_loss: 0.0528 - val_acc: 0.9923 - val_mDice: 0.4620

Epoch 00053: val_mDice did not improve from 0.48821
Epoch 54/300
 - 40s - loss: 0.0396 - acc: 0.9954 - mDice: 0.9232 - val_loss: 0.0532 - val_acc: 0.9916 - val_mDice: 0.4601

Epoch 00054: val_mDice did not improve from 0.48821
Epoch 55/300
 - 40s - loss: 0.0394 - acc: 0.9954 - mDice: 0.9235 - val_loss: -3.2672e-02 - val_acc: 0.9891 - val_mDice: 0.4043

Epoch 00055: val_mDice did not improve from 0.48821
Epoch 56/300
 - 40s - loss: 0.0389 - acc: 0.9954 - mDice: 0.9245 - val_loss: 0.1867 - val_acc: 0.9888 - val_mDice: 0.4462

Epoch 00056: val_mDice did not improve from 0.48821
Epoch 57/300
 - 41s - loss: 0.0394 - acc: 0.9954 - mDice: 0.9235 - val_loss: 0.0570 - val_acc: 0.9932 - val_mDice: 0.4742

Epoch 00057: val_mDice did not improve from 0.48821
Epoch 58/300
 - 41s - loss: 0.0389 - acc: 0.9955 - mDice: 0.9244 - val_loss: 0.0615 - val_acc: 0.9923 - val_mDice: 0.4748

Epoch 00058: val_mDice did not improve from 0.48821

Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 59/300
 - 42s - loss: 0.0379 - acc: 0.9956 - mDice: 0.9264 - val_loss: 0.0495 - val_acc: 0.9926 - val_mDice: 0.4757

Epoch 00059: val_mDice did not improve from 0.48821
Epoch 60/300
 - 41s - loss: 0.0367 - acc: 0.9956 - mDice: 0.9287 - val_loss: -1.1613e-02 - val_acc: 0.9912 - val_mDice: 0.4550

Epoch 00060: val_mDice did not improve from 0.48821
Epoch 61/300
 - 41s - loss: 0.0366 - acc: 0.9956 - mDice: 0.9289 - val_loss: 0.0312 - val_acc: 0.9927 - val_mDice: 0.4784

Epoch 00061: val_mDice did not improve from 0.48821
Epoch 62/300
 - 42s - loss: 0.0381 - acc: 0.9956 - mDice: 0.9260 - val_loss: 0.0497 - val_acc: 0.9926 - val_mDice: 0.4665

Epoch 00062: val_mDice did not improve from 0.48821
Epoch 63/300
 - 42s - loss: 0.0365 - acc: 0.9957 - mDice: 0.9291 - val_loss: 0.0496 - val_acc: 0.9925 - val_mDice: 0.4677

Epoch 00063: val_mDice did not improve from 0.48821
Epoch 64/300
 - 41s - loss: 0.0362 - acc: 0.9957 - mDice: 0.9298 - val_loss: 0.0489 - val_acc: 0.9925 - val_mDice: 0.4681

Epoch 00064: val_mDice did not improve from 0.48821
Epoch 65/300
 - 41s - loss: 0.0364 - acc: 0.9957 - mDice: 0.9294 - val_loss: 0.0483 - val_acc: 0.9921 - val_mDice: 0.4695

Epoch 00065: val_mDice did not improve from 0.48821
Epoch 66/300
 - 41s - loss: 0.0371 - acc: 0.9957 - mDice: 0.9280 - val_loss: 0.0550 - val_acc: 0.9927 - val_mDice: 0.4848

Epoch 00066: val_mDice did not improve from 0.48821
Epoch 67/300
 - 41s - loss: 0.0363 - acc: 0.9957 - mDice: 0.9296 - val_loss: 0.0441 - val_acc: 0.9923 - val_mDice: 0.4778

Epoch 00067: val_mDice did not improve from 0.48821
Epoch 68/300
 - 42s - loss: 0.0359 - acc: 0.9957 - mDice: 0.9304 - val_loss: 0.1035 - val_acc: 0.9927 - val_mDice: 0.4789

Epoch 00068: val_mDice did not improve from 0.48821
Epoch 69/300
 - 42s - loss: 0.0360 - acc: 0.9957 - mDice: 0.9302 - val_loss: 0.0489 - val_acc: 0.9922 - val_mDice: 0.4765

Epoch 00069: val_mDice did not improve from 0.48821
Epoch 70/300
 - 42s - loss: 0.0358 - acc: 0.9957 - mDice: 0.9305 - val_loss: -4.2063e-03 - val_acc: 0.9914 - val_mDice: 0.4487

Epoch 00070: val_mDice did not improve from 0.48821
Epoch 71/300
 - 41s - loss: 0.0362 - acc: 0.9957 - mDice: 0.9297 - val_loss: 0.0142 - val_acc: 0.9931 - val_mDice: 0.4807

Epoch 00071: val_mDice did not improve from 0.48821
Epoch 72/300
 - 40s - loss: 0.0352 - acc: 0.9957 - mDice: 0.9318 - val_loss: 0.0503 - val_acc: 0.9924 - val_mDice: 0.4653

Epoch 00072: val_mDice did not improve from 0.48821
Epoch 73/300
 - 41s - loss: 0.0360 - acc: 0.9957 - mDice: 0.9301 - val_loss: 0.1441 - val_acc: 0.9922 - val_mDice: 0.4768

Epoch 00073: val_mDice did not improve from 0.48821

Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 74/300
 - 40s - loss: 0.0344 - acc: 0.9958 - mDice: 0.9334 - val_loss: 0.0794 - val_acc: 0.9922 - val_mDice: 0.4697

Epoch 00074: val_mDice did not improve from 0.48821
Epoch 75/300
 - 40s - loss: 0.0348 - acc: 0.9958 - mDice: 0.9324 - val_loss: 0.0760 - val_acc: 0.9924 - val_mDice: 0.4756

Epoch 00075: val_mDice did not improve from 0.48821
Epoch 76/300
 - 40s - loss: 0.0348 - acc: 0.9958 - mDice: 0.9326 - val_loss: 0.0748 - val_acc: 0.9927 - val_mDice: 0.4834

Epoch 00076: val_mDice did not improve from 0.48821
Epoch 77/300
 - 40s - loss: 0.0343 - acc: 0.9958 - mDice: 0.9335 - val_loss: 0.0656 - val_acc: 0.9924 - val_mDice: 0.4737

Epoch 00077: val_mDice did not improve from 0.48821
Epoch 78/300
 - 40s - loss: 0.0343 - acc: 0.9958 - mDice: 0.9334 - val_loss: 0.0246 - val_acc: 0.9921 - val_mDice: 0.4585

Epoch 00078: val_mDice did not improve from 0.48821
Epoch 79/300
 - 40s - loss: 0.0347 - acc: 0.9958 - mDice: 0.9326 - val_loss: 0.0577 - val_acc: 0.9923 - val_mDice: 0.4706

Epoch 00079: val_mDice did not improve from 0.48821
Epoch 80/300
 - 41s - loss: 0.0344 - acc: 0.9958 - mDice: 0.9332 - val_loss: 0.0546 - val_acc: 0.9917 - val_mDice: 0.4733

Epoch 00080: val_mDice did not improve from 0.48821
Epoch 81/300
 - 41s - loss: 0.0341 - acc: 0.9958 - mDice: 0.9339 - val_loss: 0.0527 - val_acc: 0.9925 - val_mDice: 0.4795

Epoch 00081: val_mDice did not improve from 0.48821
Epoch 82/300
 - 41s - loss: 0.0348 - acc: 0.9958 - mDice: 0.9324 - val_loss: 0.0540 - val_acc: 0.9920 - val_mDice: 0.4693

Epoch 00082: val_mDice did not improve from 0.48821
Epoch 83/300
 - 41s - loss: 0.0344 - acc: 0.9958 - mDice: 0.9333 - val_loss: 0.0456 - val_acc: 0.9925 - val_mDice: 0.4760

Epoch 00083: val_mDice did not improve from 0.48821
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
{'val_loss': [0.21510598640721124, 0.14530651289242524, 0.11733863129093125, 0.0645752472204489, 0.11637385270080051, 0.13831136973054559, 0.23106766991071157, 0.16553370059431494, 0.10415548426252944, 0.035409034148708836, 0.07516906712506269, 0.19782127578695258, 0.11721219784683651, 0.12430187701820969, 0.010619615873058996, 0.22326262859073845, 0.19876283384837187, 0.1254534324905178, 0.10312478660463213, 0.2023993358239755, 0.19700065675798478, 0.09062914805369335, 0.013214920913134967, 0.07813288056635642, 0.2163775358740632, 0.0796451721194986, 0.05609446678970669, 0.02796702127198915, 0.13227059448266532, 0.08432606404071098, 0.045858635200752514, 0.08820634476236396, 0.0995502011912005, 0.12351090906260608, 0.06832018042648877, 0.20281431615889609, 0.11753821511705359, 0.08935283697224236, 0.08959682804865164, 0.10696881812614005, 0.0898469630572889, 0.06483690355633114, 0.11030149907321185, 0.16883443264631895, -0.017933183067195765, 0.18031555673739574, 0.09021135193628592, 0.11976990877866028, 0.11674861578611999, 0.08287657819710695, 0.042830396163928974, 0.101377242186048, 0.05277141919723144, 0.05316653516557482, -0.032672197253138455, 0.18672634790967535, 0.05696405358500667, 0.061518564193814365, 0.04953687765576818, -0.011612954440417591, 0.0311661341168859, 0.04968394987933986, 0.04960035883986556, 0.04888617795508903, 0.048315884562226026, 0.05497754331644591, 0.04409817456304132, 0.10347045259969728, 0.04888804798369651, -0.00420626335673862, 0.014179350243316399, 0.05026599236794778, 0.14406360345738786, 0.07941895705443602, 0.075974989492256, 0.07482479436619503, 0.06559235237919174, 0.024601426881712837, 0.05766060500889569, 0.054560265607304044, 0.05272991615193742, 0.054024292989536093, 0.04558414502723797], 'val_acc': [0.9875510079008681, 0.9874325969197728, 0.9916465790780099, 0.9910415668745298, 0.990786287161681, 0.9915111422896743, 0.9619116278382035, 0.9916988396429801, 0.9919869573982628, 0.9908049811830034, 0.9920828385396047, 0.9776495827568902, 0.9907301943581384, 0.9915921652281249, 0.990914528434341, 0.9889666987611009, 0.9816269845933886, 0.9915588492745752, 0.9919744941207381, 0.9832202919252642, 0.9922930567830175, 0.9914238957671432, 0.9880026124261163, 0.9924872175709263, 0.9907079007890489, 0.9918872422284192, 0.9910878329663664, 0.9915533327125572, 0.9913555795365984, 0.9888988622316011, 0.9917721819949221, 0.9894573702826515, 0.9902984848967543, 0.9919085692357015, 0.9921149659801174, 0.9900949770981843, 0.9901918212214748, 0.9914243772581175, 0.9916969190488707, 0.9928611588549685, 0.9918110198802776, 0.9922832318612406, 0.992941931203321, 0.9908049829729326, 0.9882955254019201, 0.9889496765337191, 0.9924613316137869, 0.9929366634414719, 0.9902963334017688, 0.9921022539024238, 0.9922611781426737, 0.9910928626676222, 0.9922995309571963, 0.991625005060488, 0.9890565836393798, 0.988811839450229, 0.9931941035989527, 0.9923472325723093, 0.9925502606698343, 0.9912031348403152, 0.992692647753535, 0.9925675155880215, 0.9925145426312009, 0.9924776307097426, 0.9920617424331986, 0.992679695825319, 0.9923179887078546, 0.9926641198607894, 0.9922276187587429, 0.9914260544218458, 0.993053878749813, 0.9924337649130607, 0.992226181445537, 0.9922038896663768, 0.9923870191201791, 0.9927161369953785, 0.9924373537212521, 0.9921209515036047, 0.9922530268047665, 0.9917307111236068, 0.9925461832109514, 0.9920476055718042, 0.9925241330722431], 'val_mDice': [0.3966283286969225, 0.40337125393184453, 0.4235156923085004, 0.40825054899708296, 0.4348717043707679, 0.4420114730907095, 0.36514941518516464, 0.4573631904146693, 0.43414903206152244, 0.4145511505459701, 0.45030646764480314, 0.41879366244281735, 0.4611079972069543, 0.43638396247460676, 0.4446921871231125, 0.45424206859177657, 0.4240134656044447, 0.4557322244563982, 0.4629502461121247, 0.4305194933582713, 0.4602817703295756, 0.4551694530982513, 0.36114208713487106, 0.4654168769403979, 0.4573362000711687, 0.4547211970831897, 0.4421187896988085, 0.45928089067824257, 0.471532773506176, 0.3885315853106725, 0.4557456845814759, 0.4092686388686344, 0.4299967458566746, 0.4620739012710504, 0.46167953907548487, 0.4699734793053017, 0.45701450190029413, 0.4490287964408462, 0.4593522708028407, 0.47292836536247806, 0.46472768385981295, 0.4724114582882271, 0.48820586422005213, 0.46639347353855054, 0.3985934585959346, 0.45002100257520095, 0.4672270859717517, 0.4829342150920862, 0.4544651644831989, 0.4613675921925314, 0.48056793015998406, 0.4479488108430181, 0.4620138193304478, 0.46009889820869593, 0.4043334231407077, 0.44621340237615, 0.4741615934756163, 0.47481079683041216, 0.47567379658107645, 0.45496019707860175, 0.478371285327204, 0.46653185628477606, 0.46771078373308295, 0.46805802766267246, 0.4694992890050103, 0.48476371231737797, 0.4777852891085742, 0.47889898511561546, 0.4765074559160181, 0.448650389283269, 0.48071585931219496, 0.4653422865602784, 0.47679816168528777, 0.4696962801185814, 0.4756329123590802, 0.4833892591901728, 0.4737121909409314, 0.4585494455677253, 0.4705617722269293, 0.4732856959910006, 0.47952671353523435, 0.4692705821346592, 0.4759720849382269], 'loss': [0.2118374436495834, 0.0853105229448874, 0.0752585742677721, 0.07233137092880351, 0.06491192343079713, 0.06360947225640429, 0.06228669511008721, 0.05787172587638688, 0.05828684276171726, 0.056248940477771736, 0.056636300724836754, 0.053406316111764565, 0.052788321276247205, 0.05140155404437179, 0.05225652703863652, 0.05079486537479944, 0.04983670664044775, 0.049275095931394286, 0.049336779158074974, 0.0474054944629889, 0.0476558114807081, 0.049021990930161456, 0.04627043899789885, 0.04579322085869622, 0.04654319485034892, 0.04554269001201012, 0.045057586973171054, 0.04409854203646134, 0.0449581932091772, 0.04499511923076887, 0.04353195808780102, 0.04501351491340523, 0.04245202578417377, 0.04306060331097543, 0.04248252863426389, 0.043232718268452534, 0.04176960843141916, 0.04109629285190985, 0.042297943263846755, 0.04149312527643204, 0.040650291853568325, 0.0413851854065306, 0.04046793696116087, 0.041259851870283415, 0.04126107954394665, 0.04131347116012663, 0.03967426270464096, 0.03992845250870582, 0.03964764765085292, 0.03983673173112344, 0.03963424545792533, 0.040212693294679, 0.03973574671213396, 0.03957821914097081, 0.039403560034669126, 0.038908714836880895, 0.03939454947722979, 0.03891280356849703, 0.037883324455771396, 0.036720356844310256, 0.03664261728863846, 0.038080724127579776, 0.03652939124717674, 0.036181787514821304, 0.03637124503705549, 0.03705689227775531, 0.03626234633689017, 0.035860742704541815, 0.03598300651360085, 0.03580742749355913, 0.03620882548401753, 0.03518738108289468, 0.036046852865534565, 0.03435191096510102, 0.034828911309514404, 0.03476088916519, 0.03429911425890041, 0.03433463116099619, 0.03471937801155103, 0.03442593065226058, 0.034073371364725075, 0.034835450747158256, 0.03440492445760648], 'acc': [0.9832967841302045, 0.9910536706958466, 0.9920421431582434, 0.9924896263628186, 0.9930390656187409, 0.9931870376592242, 0.9934248178847275, 0.9936260002301645, 0.9937236038293319, 0.9938956211274877, 0.9939397460437565, 0.9941141005357359, 0.9941647307856576, 0.9942197312885493, 0.9943172684412716, 0.9943630290019324, 0.9945209950698716, 0.9945500030660469, 0.9945652960149169, 0.9946001883983824, 0.9946545543961884, 0.9946188871296359, 0.9948043800385731, 0.9948225781755761, 0.9947829129324891, 0.9948461984318102, 0.9949348583598946, 0.9949330493432212, 0.9949893359759219, 0.9949467112530482, 0.9950502702345372, 0.9949612149616459, 0.9950944903948732, 0.995078705025585, 0.9951209997980944, 0.9950863265111767, 0.9951587892034289, 0.9952146859291917, 0.9951729736557597, 0.9952245477032838, 0.9952268639516622, 0.995219053752717, 0.9952998079501911, 0.9952787211581446, 0.9952704406384021, 0.995245193305163, 0.9953267884159094, 0.9953380340425168, 0.995350672036048, 0.9953392246974233, 0.9953609699976194, 0.9953432122523214, 0.9953620182991815, 0.9953678158546401, 0.9954045574125142, 0.9954421850970628, 0.995422293879359, 0.9954692917879434, 0.9955861070452626, 0.9956317013365512, 0.9956363086760683, 0.9956173391904038, 0.9956527936459344, 0.9956754908343132, 0.995681485954326, 0.9956576173763094, 0.995689392449341, 0.9956991373792572, 0.9956728053595496, 0.9956980982505513, 0.9957238414970082, 0.9957216677154997, 0.9956941152215345, 0.9957519627004932, 0.9957912823948192, 0.9958145582148419, 0.9957904053577491, 0.9957989197777579, 0.995813134072145, 0.9957958030425195, 0.995815891726389, 0.995832001059466, 0.9958302640709058], 'mDice': [0.585223902695165, 0.8340299423088036, 0.8535917704535172, 0.8592086254056343, 0.8737554935797927, 0.8762827238525347, 0.8788049659094257, 0.88752673174584, 0.8866469133963404, 0.8906258629277489, 0.8898296961085304, 0.8961997330699616, 0.8974042854723979, 0.900144193113573, 0.8983907682896721, 0.9012867519306188, 0.9031189502381897, 0.9042223190460559, 0.9040934449017642, 0.9079374735729708, 0.9074081513898485, 0.9046947464917351, 0.9100971923208366, 0.9110424001192973, 0.909564248255855, 0.9115307178847578, 0.9124500808106718, 0.91436670644799, 0.9126136676219674, 0.9125676545469811, 0.9154380798627442, 0.9125225736950172, 0.9175677339346944, 0.9163594104533619, 0.9174957618275322, 0.9160090917163816, 0.9189034266083151, 0.9202164101998743, 0.917836666156372, 0.9194221257383911, 0.9211042733595384, 0.9196354568697114, 0.9214260581409914, 0.9198551303348453, 0.9198544034995122, 0.9197624195008783, 0.923001282766644, 0.9224913091055893, 0.9230405265554898, 0.9226687899521968, 0.9230598738273585, 0.9219100959005374, 0.9228544075423503, 0.9231664844031834, 0.9234957554841237, 0.9244705807685125, 0.9235076706838278, 0.9244495324123989, 0.9264374672155609, 0.9287397147102906, 0.9288927639532025, 0.9260195273647959, 0.9291056159049562, 0.9297900443288699, 0.92940770374859, 0.9280481150843409, 0.9296213968255301, 0.930420568909511, 0.9301933064857185, 0.9305245267967218, 0.929713144990181, 0.9317503782781175, 0.9300513041525763, 0.9334026106682499, 0.9324313697313689, 0.932556564316251, 0.9334809262104227, 0.9334130417459784, 0.9326368749276626, 0.933228273063181, 0.9339276200422794, 0.9323945703833426, 0.9332546104431818], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.53it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.96it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.41it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.85it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.37it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.58it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:30,  8.16it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:29,  8.30it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:29,  8.36it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:29,  8.24it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:29,  8.10it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:29,  8.12it/s]predicting train subjects:   3%|▎         | 7/247 [00:00<00:30,  8.00it/s]predicting train subjects:   3%|▎         | 8/247 [00:00<00:29,  8.09it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:29,  8.16it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:28,  8.21it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:29,  8.14it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:29,  8.04it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:29,  8.05it/s]predicting train subjects:   6%|▌         | 14/247 [00:01<00:29,  7.83it/s]predicting train subjects:   6%|▌         | 15/247 [00:01<00:30,  7.66it/s]predicting train subjects:   6%|▋         | 16/247 [00:01<00:29,  7.84it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:29,  7.93it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:30,  7.54it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:29,  7.65it/s]predicting train subjects:   8%|▊         | 20/247 [00:02<00:28,  7.84it/s]predicting train subjects:   9%|▊         | 21/247 [00:02<00:29,  7.54it/s]predicting train subjects:   9%|▉         | 22/247 [00:02<00:29,  7.72it/s]predicting train subjects:   9%|▉         | 23/247 [00:02<00:28,  8.00it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:27,  8.13it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:26,  8.26it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:26,  8.29it/s]predicting train subjects:  11%|█         | 27/247 [00:03<00:26,  8.40it/s]predicting train subjects:  11%|█▏        | 28/247 [00:03<00:25,  8.46it/s]predicting train subjects:  12%|█▏        | 29/247 [00:03<00:25,  8.48it/s]predicting train subjects:  12%|█▏        | 30/247 [00:03<00:25,  8.55it/s]predicting train subjects:  13%|█▎        | 31/247 [00:03<00:25,  8.60it/s]predicting train subjects:  13%|█▎        | 32/247 [00:03<00:25,  8.57it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:24,  8.57it/s]predicting train subjects:  14%|█▍        | 34/247 [00:04<00:24,  8.58it/s]predicting train subjects:  14%|█▍        | 35/247 [00:04<00:24,  8.61it/s]predicting train subjects:  15%|█▍        | 36/247 [00:04<00:24,  8.62it/s]predicting train subjects:  15%|█▍        | 37/247 [00:04<00:24,  8.63it/s]predicting train subjects:  15%|█▌        | 38/247 [00:04<00:24,  8.60it/s]predicting train subjects:  16%|█▌        | 39/247 [00:04<00:24,  8.63it/s]predicting train subjects:  16%|█▌        | 40/247 [00:04<00:23,  8.66it/s]predicting train subjects:  17%|█▋        | 41/247 [00:04<00:23,  8.61it/s]predicting train subjects:  17%|█▋        | 42/247 [00:05<00:23,  8.64it/s]predicting train subjects:  17%|█▋        | 43/247 [00:05<00:25,  7.96it/s]predicting train subjects:  18%|█▊        | 44/247 [00:05<00:25,  8.07it/s]predicting train subjects:  18%|█▊        | 45/247 [00:05<00:24,  8.19it/s]predicting train subjects:  19%|█▊        | 46/247 [00:05<00:24,  8.26it/s]predicting train subjects:  19%|█▉        | 47/247 [00:05<00:23,  8.36it/s]predicting train subjects:  19%|█▉        | 48/247 [00:05<00:23,  8.48it/s]predicting train subjects:  20%|█▉        | 49/247 [00:05<00:23,  8.51it/s]predicting train subjects:  20%|██        | 50/247 [00:06<00:23,  8.50it/s]predicting train subjects:  21%|██        | 51/247 [00:06<00:22,  8.55it/s]predicting train subjects:  21%|██        | 52/247 [00:06<00:22,  8.57it/s]predicting train subjects:  21%|██▏       | 53/247 [00:06<00:22,  8.57it/s]predicting train subjects:  22%|██▏       | 54/247 [00:06<00:22,  8.60it/s]predicting train subjects:  22%|██▏       | 55/247 [00:06<00:22,  8.64it/s]predicting train subjects:  23%|██▎       | 56/247 [00:06<00:22,  8.67it/s]predicting train subjects:  23%|██▎       | 57/247 [00:06<00:21,  8.67it/s]predicting train subjects:  23%|██▎       | 58/247 [00:06<00:21,  8.70it/s]predicting train subjects:  24%|██▍       | 59/247 [00:07<00:22,  8.51it/s]predicting train subjects:  24%|██▍       | 60/247 [00:07<00:22,  8.37it/s]predicting train subjects:  25%|██▍       | 61/247 [00:07<00:22,  8.24it/s]predicting train subjects:  25%|██▌       | 62/247 [00:07<00:22,  8.18it/s]predicting train subjects:  26%|██▌       | 63/247 [00:07<00:24,  7.56it/s]predicting train subjects:  26%|██▌       | 64/247 [00:07<00:23,  7.67it/s]predicting train subjects:  26%|██▋       | 65/247 [00:07<00:24,  7.47it/s]predicting train subjects:  27%|██▋       | 66/247 [00:08<00:23,  7.58it/s]predicting train subjects:  27%|██▋       | 67/247 [00:08<00:23,  7.72it/s]predicting train subjects:  28%|██▊       | 68/247 [00:08<00:22,  7.78it/s]predicting train subjects:  28%|██▊       | 69/247 [00:08<00:22,  7.84it/s]predicting train subjects:  28%|██▊       | 70/247 [00:08<00:23,  7.69it/s]predicting train subjects:  29%|██▊       | 71/247 [00:08<00:22,  7.79it/s]predicting train subjects:  29%|██▉       | 72/247 [00:08<00:22,  7.83it/s]predicting train subjects:  30%|██▉       | 73/247 [00:08<00:22,  7.87it/s]predicting train subjects:  30%|██▉       | 74/247 [00:09<00:21,  7.90it/s]predicting train subjects:  30%|███       | 75/247 [00:09<00:21,  7.94it/s]predicting train subjects:  31%|███       | 76/247 [00:09<00:21,  7.86it/s]predicting train subjects:  31%|███       | 77/247 [00:09<00:25,  6.64it/s]predicting train subjects:  32%|███▏      | 78/247 [00:09<00:27,  6.25it/s]predicting train subjects:  32%|███▏      | 79/247 [00:09<00:25,  6.56it/s]predicting train subjects:  32%|███▏      | 80/247 [00:09<00:26,  6.36it/s]predicting train subjects:  33%|███▎      | 81/247 [00:10<00:24,  6.83it/s]predicting train subjects:  33%|███▎      | 82/247 [00:10<00:23,  6.96it/s]predicting train subjects:  34%|███▎      | 83/247 [00:10<00:22,  7.31it/s]predicting train subjects:  34%|███▍      | 84/247 [00:10<00:21,  7.53it/s]predicting train subjects:  34%|███▍      | 85/247 [00:10<00:21,  7.67it/s]predicting train subjects:  35%|███▍      | 86/247 [00:10<00:20,  7.79it/s]predicting train subjects:  35%|███▌      | 87/247 [00:10<00:20,  7.87it/s]predicting train subjects:  36%|███▌      | 88/247 [00:10<00:19,  7.97it/s]predicting train subjects:  36%|███▌      | 89/247 [00:11<00:19,  7.97it/s]predicting train subjects:  36%|███▋      | 90/247 [00:11<00:19,  7.96it/s]predicting train subjects:  37%|███▋      | 91/247 [00:11<00:19,  8.02it/s]predicting train subjects:  37%|███▋      | 92/247 [00:11<00:19,  7.93it/s]predicting train subjects:  38%|███▊      | 93/247 [00:11<00:19,  7.89it/s]predicting train subjects:  38%|███▊      | 94/247 [00:11<00:19,  7.87it/s]predicting train subjects:  38%|███▊      | 95/247 [00:11<00:19,  7.72it/s]predicting train subjects:  39%|███▉      | 96/247 [00:12<00:19,  7.85it/s]predicting train subjects:  39%|███▉      | 97/247 [00:12<00:19,  7.85it/s]predicting train subjects:  40%|███▉      | 98/247 [00:12<00:18,  7.87it/s]predicting train subjects:  40%|████      | 99/247 [00:12<00:18,  7.92it/s]predicting train subjects:  40%|████      | 100/247 [00:12<00:19,  7.56it/s]predicting train subjects:  41%|████      | 101/247 [00:12<00:19,  7.34it/s]predicting train subjects:  41%|████▏     | 102/247 [00:12<00:20,  7.24it/s]predicting train subjects:  42%|████▏     | 103/247 [00:12<00:20,  7.12it/s]predicting train subjects:  42%|████▏     | 104/247 [00:13<00:20,  6.93it/s]predicting train subjects:  43%|████▎     | 105/247 [00:13<00:20,  6.85it/s]predicting train subjects:  43%|████▎     | 106/247 [00:13<00:20,  6.82it/s]predicting train subjects:  43%|████▎     | 107/247 [00:13<00:20,  6.77it/s]predicting train subjects:  44%|████▎     | 108/247 [00:13<00:20,  6.80it/s]predicting train subjects:  44%|████▍     | 109/247 [00:13<00:20,  6.84it/s]predicting train subjects:  45%|████▍     | 110/247 [00:14<00:19,  6.86it/s]predicting train subjects:  45%|████▍     | 111/247 [00:14<00:19,  6.89it/s]predicting train subjects:  45%|████▌     | 112/247 [00:14<00:19,  6.92it/s]predicting train subjects:  46%|████▌     | 113/247 [00:14<00:19,  6.93it/s]predicting train subjects:  46%|████▌     | 114/247 [00:14<00:19,  6.94it/s]predicting train subjects:  47%|████▋     | 115/247 [00:14<00:19,  6.92it/s]predicting train subjects:  47%|████▋     | 116/247 [00:14<00:18,  6.93it/s]predicting train subjects:  47%|████▋     | 117/247 [00:15<00:18,  6.92it/s]predicting train subjects:  48%|████▊     | 118/247 [00:15<00:18,  7.07it/s]predicting train subjects:  48%|████▊     | 119/247 [00:15<00:18,  7.10it/s]predicting train subjects:  49%|████▊     | 120/247 [00:15<00:17,  7.21it/s]predicting train subjects:  49%|████▉     | 121/247 [00:15<00:17,  7.30it/s]predicting train subjects:  49%|████▉     | 122/247 [00:15<00:17,  7.35it/s]predicting train subjects:  50%|████▉     | 123/247 [00:15<00:16,  7.39it/s]predicting train subjects:  50%|█████     | 124/247 [00:15<00:16,  7.31it/s]predicting train subjects:  51%|█████     | 125/247 [00:16<00:16,  7.37it/s]predicting train subjects:  51%|█████     | 126/247 [00:16<00:16,  7.41it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:16<00:16,  7.33it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:16<00:16,  7.32it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:16<00:16,  7.33it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:16<00:15,  7.39it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:16<00:15,  7.41it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:17<00:15,  7.27it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:17<00:15,  7.30it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:17<00:15,  7.37it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:17<00:15,  7.42it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:17<00:14,  7.88it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:17<00:13,  8.20it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:17<00:12,  8.48it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:17<00:12,  8.70it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:17<00:12,  8.85it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:18<00:11,  8.98it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:18<00:11,  9.07it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:18<00:11,  9.13it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:18<00:11,  9.12it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:18<00:11,  9.13it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:18<00:11,  9.16it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:18<00:11,  8.65it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:18<00:11,  8.79it/s]predicting train subjects:  60%|██████    | 149/247 [00:18<00:11,  8.88it/s]predicting train subjects:  61%|██████    | 150/247 [00:19<00:10,  8.96it/s]predicting train subjects:  61%|██████    | 151/247 [00:19<00:10,  9.05it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:19<00:10,  9.13it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:19<00:10,  9.12it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:19<00:10,  8.81it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:19<00:10,  8.66it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:19<00:10,  8.53it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:19<00:10,  8.44it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:20<00:10,  8.40it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:20<00:10,  8.31it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:20<00:10,  8.31it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:20<00:10,  8.28it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:20<00:10,  8.27it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:20<00:10,  8.15it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:20<00:10,  8.18it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:20<00:10,  8.16it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:21<00:09,  8.18it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:21<00:09,  8.22it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:21<00:09,  8.21it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:21<00:09,  8.19it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:21<00:09,  8.23it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:21<00:09,  8.15it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:21<00:09,  8.11it/s]predicting train subjects:  70%|███████   | 173/247 [00:21<00:11,  6.63it/s]predicting train subjects:  70%|███████   | 174/247 [00:22<00:10,  7.05it/s]predicting train subjects:  71%|███████   | 175/247 [00:22<00:11,  6.14it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:22<00:10,  6.62it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:22<00:09,  7.04it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:22<00:09,  7.33it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:22<00:09,  7.55it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:22<00:08,  7.72it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:23<00:08,  7.87it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:23<00:08,  7.97it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:23<00:08,  7.94it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:23<00:07,  8.02it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:23<00:07,  7.86it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:23<00:07,  7.97it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:23<00:07,  8.06it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:23<00:07,  8.12it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:24<00:07,  8.15it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:24<00:06,  8.16it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:24<00:06,  8.17it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:24<00:06,  8.20it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:24<00:06,  8.17it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:24<00:06,  8.32it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:24<00:06,  8.41it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:24<00:06,  8.50it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:24<00:05,  8.55it/s]predicting train subjects:  80%|████████  | 198/247 [00:25<00:05,  8.62it/s]predicting train subjects:  81%|████████  | 199/247 [00:25<00:05,  8.67it/s]predicting train subjects:  81%|████████  | 200/247 [00:25<00:05,  8.68it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:25<00:05,  8.73it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:25<00:05,  8.71it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:25<00:05,  8.75it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:25<00:04,  8.80it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:25<00:04,  8.81it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:25<00:04,  8.76it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:26<00:04,  8.73it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:26<00:04,  8.74it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:26<00:04,  8.75it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:26<00:04,  8.74it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:26<00:04,  8.70it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:26<00:04,  8.59it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:26<00:03,  8.56it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:26<00:03,  8.53it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:27<00:03,  8.50it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:27<00:03,  8.50it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:27<00:03,  8.52it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:27<00:03,  8.53it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:27<00:03,  8.51it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:27<00:03,  8.54it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:27<00:03,  8.55it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:27<00:02,  8.41it/s]predicting train subjects:  90%|█████████ | 223/247 [00:27<00:02,  8.38it/s]predicting train subjects:  91%|█████████ | 224/247 [00:28<00:02,  8.22it/s]predicting train subjects:  91%|█████████ | 225/247 [00:28<00:02,  8.33it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:28<00:02,  8.39it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:28<00:02,  8.38it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:28<00:02,  8.26it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:28<00:02,  8.27it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:28<00:02,  7.94it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:28<00:02,  7.69it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:29<00:01,  7.62it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:29<00:01,  7.53it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:29<00:01,  7.44it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:29<00:01,  7.41it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:29<00:01,  7.39it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:29<00:01,  7.23it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:29<00:01,  7.16it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:30<00:01,  7.20it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:30<00:00,  7.19it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:30<00:00,  7.01it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:30<00:00,  7.06it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:30<00:00,  7.10it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:30<00:00,  7.18it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:30<00:00,  7.24it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:31<00:00,  7.27it/s]predicting train subjects: 100%|██████████| 247/247 [00:31<00:00,  7.25it/s]predicting train subjects: 100%|██████████| 247/247 [00:31<00:00,  7.91it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  6.56it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  6.72it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  7.14it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  7.44it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.32it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.40it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:30,  8.12it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:29,  8.21it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:30,  8.03it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:30,  7.99it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:30,  8.01it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:29,  8.06it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:00<00:29,  8.07it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:00<00:29,  8.10it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:29,  8.12it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:29,  8.11it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:29,  8.13it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:29,  8.07it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:29,  8.07it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:01<00:28,  8.04it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:01<00:28,  8.08it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:01<00:28,  8.05it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:28,  8.04it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:28,  8.08it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:28,  8.06it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:02<00:28,  8.06it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:02<00:28,  8.06it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:02<00:27,  8.09it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:02<00:27,  8.22it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:02<00:26,  8.36it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:26,  8.45it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:25,  8.53it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:03<00:26,  8.40it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:03<00:25,  8.44it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:03<00:25,  8.48it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:03<00:25,  8.53it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:03<00:25,  8.56it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:03<00:25,  8.50it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:04<00:25,  8.51it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:04<00:24,  8.54it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:04<00:25,  8.47it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:04<00:24,  8.51it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:04<00:24,  8.56it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:04<00:24,  8.61it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:04<00:24,  8.58it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:04<00:24,  8.59it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:04<00:23,  8.64it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:05<00:23,  8.66it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:05<00:23,  8.68it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:05<00:23,  8.67it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:05<00:23,  8.67it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:05<00:23,  8.63it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:05<00:23,  8.61it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:05<00:23,  8.61it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:05<00:23,  8.57it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:05<00:22,  8.58it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:06<00:22,  8.57it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:06<00:22,  8.59it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:06<00:22,  8.58it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:06<00:22,  8.55it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:06<00:22,  8.54it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:06<00:22,  8.50it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:06<00:22,  8.52it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:06<00:22,  8.54it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:07<00:22,  8.29it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:07<00:22,  8.16it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:07<00:22,  8.09it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:07<00:23,  8.01it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:07<00:23,  7.97it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:07<00:23,  7.86it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:07<00:23,  7.86it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:07<00:23,  7.85it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:08<00:22,  7.87it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:08<00:22,  7.92it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:08<00:22,  7.85it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:08<00:22,  7.84it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:08<00:22,  7.89it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:08<00:22,  7.91it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:08<00:22,  7.69it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:08<00:22,  7.73it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:09<00:22,  7.76it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:09<00:21,  7.78it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:09<00:21,  7.77it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:09<00:22,  7.36it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:09<00:22,  7.38it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:09<00:21,  7.63it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:09<00:21,  7.83it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:10<00:21,  7.80it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:10<00:20,  7.91it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:10<00:20,  8.01it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:10<00:20,  8.04it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:10<00:19,  8.09it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:10<00:19,  8.10it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:10<00:19,  8.14it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:10<00:19,  8.12it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:10<00:19,  8.09it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:11<00:19,  8.13it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:11<00:18,  8.18it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:11<00:18,  8.15it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:11<00:18,  8.11it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:11<00:18,  8.16it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:11<00:18,  8.19it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:11<00:18,  8.14it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:11<00:18,  8.21it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:12<00:17,  8.23it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:12<00:18,  7.81it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:12<00:19,  7.56it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:12<00:19,  7.29it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:12<00:19,  7.21it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:12<00:20,  7.13it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:12<00:20,  7.05it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:13<00:20,  6.98it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:13<00:20,  6.92it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:13<00:20,  6.89it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:13<00:20,  6.85it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:13<00:19,  6.87it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:13<00:19,  6.88it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:13<00:19,  6.92it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:14<00:19,  6.90it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:14<00:19,  6.93it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:14<00:19,  6.93it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:14<00:18,  6.94it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:14<00:18,  6.87it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:14<00:18,  7.01it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:14<00:17,  7.17it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:15<00:17,  7.24it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:15<00:17,  7.29it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:15<00:16,  7.37it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:15<00:16,  7.42it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:15<00:16,  7.38it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:15<00:16,  7.37it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:15<00:16,  7.41it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:16<00:16,  7.39it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:16<00:16,  7.43it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:16<00:15,  7.47it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:16<00:15,  7.49it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:16<00:15,  7.55it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:16<00:15,  7.55it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:16<00:15,  7.53it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:16<00:15,  7.53it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:17<00:15,  7.30it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:17<00:14,  7.82it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:17<00:13,  8.07it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:17<00:12,  8.46it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:17<00:12,  8.60it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:17<00:12,  8.76it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:17<00:11,  8.92it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:17<00:11,  9.07it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:17<00:11,  9.15it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:18<00:11,  9.17it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:18<00:11,  9.19it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:18<00:10,  9.19it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:18<00:10,  9.23it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:18<00:10,  9.25it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:18<00:10,  9.32it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:18<00:10,  9.32it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:18<00:10,  9.38it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:18<00:10,  9.35it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:19<00:10,  9.35it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:19<00:10,  9.05it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:19<00:10,  8.82it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:19<00:10,  8.69it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:19<00:10,  8.53it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:19<00:10,  8.46it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:19<00:10,  8.18it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:19<00:10,  8.17it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:20<00:10,  8.18it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:20<00:10,  8.18it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:20<00:10,  8.25it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:20<00:10,  8.27it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:20<00:09,  8.24it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:20<00:09,  8.17it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:20<00:09,  8.25it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:20<00:09,  8.18it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:21<00:09,  8.26it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:21<00:09,  8.36it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:21<00:08,  8.46it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:21<00:08,  8.39it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:21<00:08,  8.57it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:21<00:08,  8.49it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:21<00:08,  8.11it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:21<00:08,  8.15it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:21<00:08,  8.16it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:22<00:08,  8.15it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:22<00:08,  8.21it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:22<00:08,  8.20it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:22<00:08,  8.23it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:22<00:07,  8.17it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:22<00:07,  8.20it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:22<00:07,  8.22it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:22<00:07,  8.26it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:23<00:07,  8.30it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:23<00:07,  8.35it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:23<00:07,  8.38it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:23<00:06,  8.35it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:23<00:06,  8.36it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:23<00:06,  8.34it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:23<00:06,  8.36it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:23<00:06,  8.35it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:24<00:06,  8.44it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:24<00:06,  8.55it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:24<00:06,  8.50it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:24<00:06,  8.16it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:24<00:06,  8.16it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:24<00:05,  8.34it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:24<00:05,  8.53it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:24<00:05,  8.47it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:24<00:05,  8.61it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:25<00:05,  8.44it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:25<00:05,  8.51it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:25<00:04,  8.58it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:25<00:04,  8.65it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:25<00:04,  8.67it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:25<00:04,  8.48it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:25<00:04,  8.58it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:25<00:04,  8.61it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:26<00:04,  8.69it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:26<00:04,  8.58it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:26<00:03,  8.55it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:26<00:03,  8.49it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:26<00:03,  8.52it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:26<00:03,  8.54it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:26<00:03,  8.57it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:26<00:03,  8.57it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:26<00:03,  8.54it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:27<00:03,  8.52it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:27<00:03,  8.40it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:27<00:02,  8.43it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:27<00:02,  8.47it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:27<00:02,  8.50it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:27<00:02,  8.44it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:27<00:02,  8.23it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:27<00:02,  8.28it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:28<00:02,  8.35it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:28<00:02,  8.39it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:28<00:02,  7.93it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:28<00:02,  7.70it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:28<00:01,  7.57it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:28<00:01,  7.41it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:28<00:01,  7.34it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:28<00:01,  7.34it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:29<00:01,  7.36it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:29<00:01,  7.34it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:29<00:01,  7.32it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:29<00:01,  7.25it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:29<00:00,  7.24it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:29<00:00,  7.23it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:29<00:00,  7.18it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:30<00:00,  7.13it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:30<00:00,  7.14it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:30<00:00,  7.15it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:30<00:00,  7.09it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  6.97it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  8.05it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 70.29it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 84.98it/s]saving BB  train1-THALAMUS:   7%|▋         | 17/247 [00:00<00:02, 83.34it/s]saving BB  train1-THALAMUS:  11%|█         | 26/247 [00:00<00:02, 83.88it/s]saving BB  train1-THALAMUS:  14%|█▍        | 35/247 [00:00<00:02, 85.46it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 86.92it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 89.22it/s]saving BB  train1-THALAMUS:  26%|██▌       | 64/247 [00:00<00:02, 87.42it/s]saving BB  train1-THALAMUS:  30%|██▉       | 73/247 [00:00<00:02, 83.00it/s]saving BB  train1-THALAMUS:  33%|███▎      | 81/247 [00:00<00:02, 78.97it/s]saving BB  train1-THALAMUS:  36%|███▌      | 89/247 [00:01<00:02, 77.15it/s]saving BB  train1-THALAMUS:  40%|███▉      | 98/247 [00:01<00:01, 78.54it/s]saving BB  train1-THALAMUS:  43%|████▎     | 106/247 [00:01<00:01, 76.68it/s]saving BB  train1-THALAMUS:  46%|████▌     | 114/247 [00:01<00:01, 75.19it/s]saving BB  train1-THALAMUS:  49%|████▉     | 122/247 [00:01<00:01, 73.65it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 130/247 [00:01<00:01, 72.06it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 138/247 [00:01<00:01, 72.49it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 147/247 [00:01<00:01, 74.80it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 156/247 [00:01<00:01, 76.80it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 165/247 [00:02<00:01, 79.77it/s]saving BB  train1-THALAMUS:  70%|███████   | 174/247 [00:02<00:00, 81.73it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 183/247 [00:02<00:00, 78.48it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 191/247 [00:02<00:00, 77.01it/s]saving BB  train1-THALAMUS:  81%|████████  | 199/247 [00:02<00:00, 77.14it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 208/247 [00:02<00:00, 77.04it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 217/247 [00:02<00:00, 79.43it/s]saving BB  train1-THALAMUS:  91%|█████████▏| 226/247 [00:02<00:00, 80.70it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 235/247 [00:02<00:00, 78.66it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 243/247 [00:03<00:00, 75.26it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 78.65it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 68.08it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 80.91it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 80.54it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 26/247 [00:00<00:02, 79.98it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 35/247 [00:00<00:02, 81.16it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 44/247 [00:00<00:02, 82.95it/s]saving BB  train1-THALAMUS Sagittal:  21%|██▏       | 53/247 [00:00<00:02, 83.80it/s]saving BB  train1-THALAMUS Sagittal:  25%|██▍       | 61/247 [00:00<00:02, 82.38it/s]saving BB  train1-THALAMUS Sagittal:  28%|██▊       | 69/247 [00:00<00:02, 79.19it/s]saving BB  train1-THALAMUS Sagittal:  31%|███       | 77/247 [00:00<00:02, 74.20it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▍      | 85/247 [00:01<00:02, 74.83it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 93/247 [00:01<00:02, 74.93it/s]saving BB  train1-THALAMUS Sagittal:  41%|████      | 101/247 [00:01<00:01, 74.83it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▍     | 109/247 [00:01<00:01, 73.62it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 117/247 [00:01<00:01, 71.68it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 125/247 [00:01<00:01, 71.63it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 133/247 [00:01<00:01, 71.54it/s]saving BB  train1-THALAMUS Sagittal:  57%|█████▋    | 141/247 [00:01<00:01, 73.83it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████    | 150/247 [00:01<00:01, 76.51it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 159/247 [00:02<00:01, 78.59it/s]saving BB  train1-THALAMUS Sagittal:  68%|██████▊   | 168/247 [00:02<00:00, 80.36it/s]saving BB  train1-THALAMUS Sagittal:  72%|███████▏  | 177/247 [00:02<00:00, 79.63it/s]saving BB  train1-THALAMUS Sagittal:  75%|███████▍  | 185/247 [00:02<00:00, 78.18it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 193/247 [00:02<00:00, 76.64it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 202/247 [00:02<00:00, 78.25it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▌ | 211/247 [00:02<00:00, 78.64it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 220/247 [00:02<00:00, 80.50it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 229/247 [00:02<00:00, 82.46it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▋| 238/247 [00:03<00:00, 81.13it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 79.45it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 77.99it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:51,  1.06it/s]Loading train:   1%|          | 2/247 [00:01<03:38,  1.12it/s]Loading train:   1%|          | 3/247 [00:02<03:25,  1.19it/s]Loading train:   2%|▏         | 4/247 [00:03<03:29,  1.16it/s]Loading train:   2%|▏         | 5/247 [00:03<03:09,  1.28it/s]Loading train:   2%|▏         | 6/247 [00:04<02:48,  1.43it/s]Loading train:   3%|▎         | 7/247 [00:04<02:36,  1.53it/s]Loading train:   3%|▎         | 8/247 [00:05<02:27,  1.62it/s]Loading train:   4%|▎         | 9/247 [00:06<02:22,  1.67it/s]Loading train:   4%|▍         | 10/247 [00:06<02:17,  1.73it/s]Loading train:   4%|▍         | 11/247 [00:07<02:16,  1.72it/s]Loading train:   5%|▍         | 12/247 [00:07<02:16,  1.73it/s]Loading train:   5%|▌         | 13/247 [00:08<02:12,  1.76it/s]Loading train:   6%|▌         | 14/247 [00:08<02:11,  1.78it/s]Loading train:   6%|▌         | 15/247 [00:09<02:09,  1.80it/s]Loading train:   6%|▋         | 16/247 [00:09<02:07,  1.81it/s]Loading train:   7%|▋         | 17/247 [00:10<02:04,  1.84it/s]Loading train:   7%|▋         | 18/247 [00:11<02:05,  1.83it/s]Loading train:   8%|▊         | 19/247 [00:11<02:03,  1.85it/s]Loading train:   8%|▊         | 20/247 [00:12<02:02,  1.86it/s]Loading train:   9%|▊         | 21/247 [00:12<02:01,  1.87it/s]Loading train:   9%|▉         | 22/247 [00:13<02:00,  1.86it/s]Loading train:   9%|▉         | 23/247 [00:13<02:00,  1.86it/s]Loading train:  10%|▉         | 24/247 [00:14<01:57,  1.91it/s]Loading train:  10%|█         | 25/247 [00:14<01:55,  1.92it/s]Loading train:  11%|█         | 26/247 [00:15<01:54,  1.93it/s]Loading train:  11%|█         | 27/247 [00:15<01:54,  1.92it/s]Loading train:  11%|█▏        | 28/247 [00:16<01:52,  1.95it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:51,  1.96it/s]Loading train:  12%|█▏        | 30/247 [00:17<01:48,  2.01it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:46,  2.03it/s]Loading train:  13%|█▎        | 32/247 [00:18<01:45,  2.03it/s]Loading train:  13%|█▎        | 33/247 [00:18<01:46,  2.01it/s]Loading train:  14%|█▍        | 34/247 [00:19<01:44,  2.04it/s]Loading train:  14%|█▍        | 35/247 [00:19<01:45,  2.01it/s]Loading train:  15%|█▍        | 36/247 [00:20<01:45,  2.01it/s]Loading train:  15%|█▍        | 37/247 [00:20<01:45,  2.00it/s]Loading train:  15%|█▌        | 38/247 [00:21<01:44,  2.00it/s]Loading train:  16%|█▌        | 39/247 [00:21<01:43,  2.01it/s]Loading train:  16%|█▌        | 40/247 [00:22<01:43,  1.99it/s]Loading train:  17%|█▋        | 41/247 [00:22<01:42,  2.01it/s]Loading train:  17%|█▋        | 42/247 [00:23<01:39,  2.05it/s]Loading train:  17%|█▋        | 43/247 [00:23<01:36,  2.11it/s]Loading train:  18%|█▊        | 44/247 [00:24<01:36,  2.11it/s]Loading train:  18%|█▊        | 45/247 [00:24<01:35,  2.10it/s]Loading train:  19%|█▊        | 46/247 [00:25<01:37,  2.07it/s]Loading train:  19%|█▉        | 47/247 [00:25<01:36,  2.07it/s]Loading train:  19%|█▉        | 48/247 [00:25<01:35,  2.09it/s]Loading train:  20%|█▉        | 49/247 [00:26<01:36,  2.06it/s]Loading train:  20%|██        | 50/247 [00:26<01:36,  2.04it/s]Loading train:  21%|██        | 51/247 [00:27<01:35,  2.06it/s]Loading train:  21%|██        | 52/247 [00:27<01:34,  2.07it/s]Loading train:  21%|██▏       | 53/247 [00:28<01:32,  2.10it/s]Loading train:  22%|██▏       | 54/247 [00:28<01:30,  2.13it/s]Loading train:  22%|██▏       | 55/247 [00:29<01:30,  2.12it/s]Loading train:  23%|██▎       | 56/247 [00:29<01:30,  2.11it/s]Loading train:  23%|██▎       | 57/247 [00:30<01:30,  2.11it/s]Loading train:  23%|██▎       | 58/247 [00:30<01:30,  2.10it/s]Loading train:  24%|██▍       | 59/247 [00:31<01:35,  1.97it/s]Loading train:  24%|██▍       | 60/247 [00:31<01:35,  1.97it/s]Loading train:  25%|██▍       | 61/247 [00:32<01:34,  1.96it/s]Loading train:  25%|██▌       | 62/247 [00:32<01:34,  1.96it/s]Loading train:  26%|██▌       | 63/247 [00:33<01:35,  1.93it/s]Loading train:  26%|██▌       | 64/247 [00:33<01:34,  1.94it/s]Loading train:  26%|██▋       | 65/247 [00:34<01:34,  1.93it/s]Loading train:  27%|██▋       | 66/247 [00:34<01:34,  1.92it/s]Loading train:  27%|██▋       | 67/247 [00:35<01:34,  1.91it/s]Loading train:  28%|██▊       | 68/247 [00:36<01:32,  1.94it/s]Loading train:  28%|██▊       | 69/247 [00:36<01:31,  1.95it/s]Loading train:  28%|██▊       | 70/247 [00:37<01:33,  1.90it/s]Loading train:  29%|██▊       | 71/247 [00:37<01:34,  1.87it/s]Loading train:  29%|██▉       | 72/247 [00:38<01:32,  1.90it/s]Loading train:  30%|██▉       | 73/247 [00:38<01:32,  1.89it/s]Loading train:  30%|██▉       | 74/247 [00:39<01:31,  1.90it/s]Loading train:  30%|███       | 75/247 [00:39<01:30,  1.91it/s]Loading train:  31%|███       | 76/247 [00:40<01:29,  1.90it/s]Loading train:  31%|███       | 77/247 [00:41<01:45,  1.61it/s]Loading train:  32%|███▏      | 78/247 [00:42<02:00,  1.40it/s]Loading train:  32%|███▏      | 79/247 [00:42<02:03,  1.36it/s]Loading train:  32%|███▏      | 80/247 [00:43<02:01,  1.38it/s]Loading train:  33%|███▎      | 81/247 [00:44<02:04,  1.33it/s]Loading train:  33%|███▎      | 82/247 [00:44<01:55,  1.42it/s]Loading train:  34%|███▎      | 83/247 [00:45<01:46,  1.53it/s]Loading train:  34%|███▍      | 84/247 [00:45<01:40,  1.62it/s]Loading train:  34%|███▍      | 85/247 [00:46<01:36,  1.68it/s]Loading train:  35%|███▍      | 86/247 [00:47<01:34,  1.71it/s]Loading train:  35%|███▌      | 87/247 [00:47<01:32,  1.74it/s]Loading train:  36%|███▌      | 88/247 [00:48<01:30,  1.77it/s]Loading train:  36%|███▌      | 89/247 [00:48<01:28,  1.78it/s]Loading train:  36%|███▋      | 90/247 [00:49<01:28,  1.77it/s]Loading train:  37%|███▋      | 91/247 [00:49<01:28,  1.76it/s]Loading train:  37%|███▋      | 92/247 [00:50<01:30,  1.72it/s]Loading train:  38%|███▊      | 93/247 [00:51<01:27,  1.75it/s]Loading train:  38%|███▊      | 94/247 [00:51<01:27,  1.76it/s]Loading train:  38%|███▊      | 95/247 [00:52<01:25,  1.77it/s]Loading train:  39%|███▉      | 96/247 [00:52<01:25,  1.78it/s]Loading train:  39%|███▉      | 97/247 [00:53<01:23,  1.80it/s]Loading train:  40%|███▉      | 98/247 [00:53<01:21,  1.82it/s]Loading train:  40%|████      | 99/247 [00:54<01:23,  1.76it/s]Loading train:  40%|████      | 100/247 [00:55<01:28,  1.65it/s]Loading train:  41%|████      | 101/247 [00:55<01:29,  1.64it/s]Loading train:  41%|████▏     | 102/247 [00:56<01:28,  1.64it/s]Loading train:  42%|████▏     | 103/247 [00:56<01:26,  1.66it/s]Loading train:  42%|████▏     | 104/247 [00:57<01:24,  1.69it/s]Loading train:  43%|████▎     | 105/247 [00:58<01:24,  1.68it/s]Loading train:  43%|████▎     | 106/247 [00:58<01:24,  1.67it/s]Loading train:  43%|████▎     | 107/247 [00:59<01:23,  1.68it/s]Loading train:  44%|████▎     | 108/247 [00:59<01:23,  1.67it/s]Loading train:  44%|████▍     | 109/247 [01:00<01:22,  1.67it/s]Loading train:  45%|████▍     | 110/247 [01:01<01:22,  1.66it/s]Loading train:  45%|████▍     | 111/247 [01:01<01:21,  1.67it/s]Loading train:  45%|████▌     | 112/247 [01:02<01:20,  1.68it/s]Loading train:  46%|████▌     | 113/247 [01:02<01:21,  1.65it/s]Loading train:  46%|████▌     | 114/247 [01:03<01:20,  1.64it/s]Loading train:  47%|████▋     | 115/247 [01:04<01:21,  1.61it/s]Loading train:  47%|████▋     | 116/247 [01:04<01:20,  1.62it/s]Loading train:  47%|████▋     | 117/247 [01:05<01:19,  1.64it/s]Loading train:  48%|████▊     | 118/247 [01:05<01:19,  1.63it/s]Loading train:  48%|████▊     | 119/247 [01:06<01:16,  1.68it/s]Loading train:  49%|████▊     | 120/247 [01:07<01:13,  1.72it/s]Loading train:  49%|████▉     | 121/247 [01:08<01:42,  1.23it/s]Loading train:  49%|████▉     | 122/247 [01:09<01:55,  1.08it/s]Loading train:  50%|████▉     | 123/247 [01:11<02:41,  1.30s/it]Loading train:  50%|█████     | 124/247 [01:14<03:44,  1.83s/it]Loading train:  51%|█████     | 125/247 [01:18<04:36,  2.27s/it]Loading train:  51%|█████     | 126/247 [01:21<05:05,  2.53s/it]Loading train:  51%|█████▏    | 127/247 [01:24<05:21,  2.68s/it]Loading train:  52%|█████▏    | 128/247 [01:27<05:35,  2.82s/it]Loading train:  52%|█████▏    | 129/247 [01:30<05:37,  2.86s/it]Loading train:  53%|█████▎    | 130/247 [01:33<05:34,  2.86s/it]Loading train:  53%|█████▎    | 131/247 [01:36<05:35,  2.89s/it]Loading train:  53%|█████▎    | 132/247 [01:39<05:42,  2.97s/it]Loading train:  54%|█████▍    | 133/247 [01:42<05:38,  2.97s/it]Loading train:  54%|█████▍    | 134/247 [01:45<05:34,  2.96s/it]Loading train:  55%|█████▍    | 135/247 [01:48<05:39,  3.03s/it]Loading train:  55%|█████▌    | 136/247 [01:49<04:13,  2.28s/it]Loading train:  55%|█████▌    | 137/247 [01:49<03:11,  1.74s/it]Loading train:  56%|█████▌    | 138/247 [01:50<02:29,  1.37s/it]Loading train:  56%|█████▋    | 139/247 [01:50<01:58,  1.10s/it]Loading train:  57%|█████▋    | 140/247 [01:50<01:37,  1.09it/s]Loading train:  57%|█████▋    | 141/247 [01:51<01:37,  1.09it/s]Loading train:  57%|█████▋    | 142/247 [01:52<01:36,  1.09it/s]Loading train:  58%|█████▊    | 143/247 [01:53<01:34,  1.10it/s]Loading train:  58%|█████▊    | 144/247 [01:54<01:32,  1.12it/s]Loading train:  59%|█████▊    | 145/247 [01:55<01:29,  1.14it/s]Loading train:  59%|█████▉    | 146/247 [01:56<01:30,  1.12it/s]Loading train:  60%|█████▉    | 147/247 [01:57<01:28,  1.13it/s]Loading train:  60%|█████▉    | 148/247 [01:58<01:30,  1.10it/s]Loading train:  60%|██████    | 149/247 [01:59<01:28,  1.11it/s]Loading train:  61%|██████    | 150/247 [01:59<01:28,  1.10it/s]Loading train:  61%|██████    | 151/247 [02:00<01:26,  1.12it/s]Loading train:  62%|██████▏   | 152/247 [02:01<01:26,  1.10it/s]Loading train:  62%|██████▏   | 153/247 [02:02<01:24,  1.11it/s]Loading train:  62%|██████▏   | 154/247 [02:05<02:06,  1.36s/it]Loading train:  63%|██████▎   | 155/247 [02:07<02:42,  1.76s/it]Loading train:  63%|██████▎   | 156/247 [02:10<03:06,  2.04s/it]Loading train:  64%|██████▎   | 157/247 [02:13<03:25,  2.28s/it]Loading train:  64%|██████▍   | 158/247 [02:16<03:38,  2.46s/it]Loading train:  64%|██████▍   | 159/247 [02:18<03:41,  2.52s/it]Loading train:  65%|██████▍   | 160/247 [02:21<03:45,  2.59s/it]Loading train:  65%|██████▌   | 161/247 [02:24<03:47,  2.65s/it]Loading train:  66%|██████▌   | 162/247 [02:27<03:52,  2.73s/it]Loading train:  66%|██████▌   | 163/247 [02:30<03:53,  2.79s/it]Loading train:  66%|██████▋   | 164/247 [02:33<03:57,  2.86s/it]Loading train:  67%|██████▋   | 165/247 [02:35<03:50,  2.81s/it]Loading train:  67%|██████▋   | 166/247 [02:38<03:49,  2.84s/it]Loading train:  68%|██████▊   | 167/247 [02:41<03:50,  2.88s/it]Loading train:  68%|██████▊   | 168/247 [02:44<03:47,  2.88s/it]Loading train:  68%|██████▊   | 169/247 [02:47<03:42,  2.85s/it]Loading train:  69%|██████▉   | 170/247 [02:50<03:37,  2.83s/it]Loading train:  69%|██████▉   | 171/247 [02:52<03:29,  2.76s/it]Loading train:  70%|██████▉   | 172/247 [03:00<05:10,  4.14s/it]Loading train:  70%|███████   | 173/247 [03:05<05:26,  4.41s/it]Loading train:  70%|███████   | 174/247 [03:10<05:39,  4.65s/it]Loading train:  71%|███████   | 175/247 [03:18<06:53,  5.74s/it]Loading train:  71%|███████▏  | 176/247 [03:21<05:44,  4.85s/it]Loading train:  72%|███████▏  | 177/247 [03:24<04:52,  4.17s/it]Loading train:  72%|███████▏  | 178/247 [03:26<04:12,  3.67s/it]Loading train:  72%|███████▏  | 179/247 [03:29<03:47,  3.35s/it]Loading train:  73%|███████▎  | 180/247 [03:31<03:29,  3.12s/it]Loading train:  73%|███████▎  | 181/247 [03:34<03:18,  3.00s/it]Loading train:  74%|███████▎  | 182/247 [03:37<03:08,  2.91s/it]Loading train:  74%|███████▍  | 183/247 [03:39<02:56,  2.75s/it]Loading train:  74%|███████▍  | 184/247 [03:42<02:53,  2.75s/it]Loading train:  75%|███████▍  | 185/247 [03:45<02:49,  2.73s/it]Loading train:  75%|███████▌  | 186/247 [03:47<02:46,  2.73s/it]Loading train:  76%|███████▌  | 187/247 [03:50<02:46,  2.77s/it]Loading train:  76%|███████▌  | 188/247 [03:53<02:42,  2.75s/it]Loading train:  77%|███████▋  | 189/247 [03:56<02:43,  2.81s/it]Loading train:  77%|███████▋  | 190/247 [03:58<02:36,  2.74s/it]Loading train:  77%|███████▋  | 191/247 [04:01<02:36,  2.80s/it]Loading train:  78%|███████▊  | 192/247 [04:04<02:33,  2.80s/it]Loading train:  78%|███████▊  | 193/247 [04:07<02:30,  2.78s/it]Loading train:  79%|███████▊  | 194/247 [04:08<02:03,  2.33s/it]Loading train:  79%|███████▉  | 195/247 [04:09<01:38,  1.90s/it]Loading train:  79%|███████▉  | 196/247 [04:10<01:21,  1.59s/it]Loading train:  80%|███████▉  | 197/247 [04:11<01:08,  1.38s/it]Loading train:  80%|████████  | 198/247 [04:12<00:59,  1.22s/it]Loading train:  81%|████████  | 199/247 [04:13<00:54,  1.13s/it]Loading train:  81%|████████  | 200/247 [04:13<00:50,  1.06s/it]Loading train:  81%|████████▏ | 201/247 [04:14<00:47,  1.03s/it]Loading train:  82%|████████▏ | 202/247 [04:15<00:44,  1.00it/s]Loading train:  82%|████████▏ | 203/247 [04:16<00:42,  1.04it/s]Loading train:  83%|████████▎ | 204/247 [04:17<00:40,  1.06it/s]Loading train:  83%|████████▎ | 205/247 [04:18<00:39,  1.05it/s]Loading train:  83%|████████▎ | 206/247 [04:19<00:40,  1.01it/s]Loading train:  84%|████████▍ | 207/247 [04:20<00:39,  1.00it/s]Loading train:  84%|████████▍ | 208/247 [04:21<00:37,  1.03it/s]Loading train:  85%|████████▍ | 209/247 [04:22<00:36,  1.05it/s]Loading train:  85%|████████▌ | 210/247 [04:23<00:34,  1.07it/s]Loading train:  85%|████████▌ | 211/247 [04:24<00:33,  1.08it/s]Loading train:  86%|████████▌ | 212/247 [04:26<00:47,  1.36s/it]Loading train:  86%|████████▌ | 213/247 [04:29<00:57,  1.69s/it]Loading train:  87%|████████▋ | 214/247 [04:31<01:03,  1.92s/it]Loading train:  87%|████████▋ | 215/247 [04:34<01:12,  2.26s/it]Loading train:  87%|████████▋ | 216/247 [04:38<01:28,  2.85s/it]Loading train:  88%|████████▊ | 217/247 [04:43<01:36,  3.23s/it]Loading train:  88%|████████▊ | 218/247 [04:46<01:33,  3.23s/it]Loading train:  89%|████████▊ | 219/247 [04:50<01:35,  3.41s/it]Loading train:  89%|████████▉ | 220/247 [04:53<01:34,  3.51s/it]Loading train:  89%|████████▉ | 221/247 [04:57<01:34,  3.64s/it]Loading train:  90%|████████▉ | 222/247 [05:01<01:32,  3.70s/it]Loading train:  90%|█████████ | 223/247 [05:05<01:31,  3.82s/it]Loading train:  91%|█████████ | 224/247 [05:09<01:29,  3.90s/it]Loading train:  91%|█████████ | 225/247 [05:13<01:26,  3.93s/it]Loading train:  91%|█████████▏| 226/247 [05:17<01:22,  3.93s/it]Loading train:  92%|█████████▏| 227/247 [05:21<01:19,  3.97s/it]Loading train:  92%|█████████▏| 228/247 [05:25<01:14,  3.90s/it]Loading train:  93%|█████████▎| 229/247 [05:29<01:08,  3.82s/it]Loading train:  93%|█████████▎| 230/247 [05:34<01:15,  4.42s/it]Loading train:  94%|█████████▎| 231/247 [05:41<01:18,  4.93s/it]Loading train:  94%|█████████▍| 232/247 [05:46<01:18,  5.22s/it]Loading train:  94%|█████████▍| 233/247 [05:52<01:15,  5.37s/it]Loading train:  95%|█████████▍| 234/247 [05:58<01:11,  5.47s/it]Loading train:  95%|█████████▌| 235/247 [06:04<01:07,  5.60s/it]Loading train:  96%|█████████▌| 236/247 [06:09<01:01,  5.60s/it]Loading train:  96%|█████████▌| 237/247 [06:15<00:55,  5.60s/it]Loading train:  96%|█████████▋| 238/247 [06:21<00:50,  5.60s/it]Loading train:  97%|█████████▋| 239/247 [06:26<00:45,  5.66s/it]Loading train:  97%|█████████▋| 240/247 [06:32<00:39,  5.62s/it]Loading train:  98%|█████████▊| 241/247 [06:37<00:33,  5.52s/it]Loading train:  98%|█████████▊| 242/247 [06:43<00:27,  5.54s/it]Loading train:  98%|█████████▊| 243/247 [06:48<00:22,  5.54s/it]Loading train:  99%|█████████▉| 244/247 [06:54<00:16,  5.50s/it]Loading train:  99%|█████████▉| 245/247 [06:59<00:10,  5.47s/it]Loading train: 100%|█████████▉| 246/247 [07:05<00:05,  5.49s/it]Loading train: 100%|██████████| 247/247 [07:10<00:00,  5.46s/it]Loading train: 100%|██████████| 247/247 [07:10<00:00,  1.74s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 53.48it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 53.88it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 53.01it/s]concatenating: train:   9%|▉         | 23/247 [00:00<00:04, 51.93it/s]concatenating: train:  12%|█▏        | 29/247 [00:00<00:04, 52.68it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 53.00it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 50.60it/s]concatenating: train:  19%|█▊        | 46/247 [00:00<00:03, 52.09it/s]concatenating: train:  21%|██        | 52/247 [00:00<00:03, 54.14it/s]concatenating: train:  24%|██▍       | 59/247 [00:01<00:03, 55.83it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 56.07it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:03, 56.40it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:03, 56.05it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:03, 54.18it/s]concatenating: train:  36%|███▌      | 89/247 [00:01<00:03, 52.55it/s]concatenating: train:  38%|███▊      | 95/247 [00:01<00:02, 51.30it/s]concatenating: train:  41%|████      | 101/247 [00:01<00:02, 50.77it/s]concatenating: train:  43%|████▎     | 107/247 [00:02<00:02, 50.51it/s]concatenating: train:  46%|████▌     | 113/247 [00:02<00:02, 50.65it/s]concatenating: train:  48%|████▊     | 119/247 [00:02<00:02, 50.60it/s]concatenating: train:  51%|█████     | 125/247 [00:02<00:02, 51.71it/s]concatenating: train:  53%|█████▎    | 131/247 [00:02<00:02, 50.88it/s]concatenating: train:  55%|█████▌    | 137/247 [00:02<00:02, 49.16it/s]concatenating: train:  57%|█████▋    | 142/247 [00:02<00:02, 47.95it/s]concatenating: train:  60%|█████▉    | 147/247 [00:02<00:02, 47.15it/s]concatenating: train:  62%|██████▏   | 152/247 [00:02<00:02, 46.29it/s]concatenating: train:  64%|██████▎   | 157/247 [00:03<00:01, 46.41it/s]concatenating: train:  66%|██████▌   | 162/247 [00:03<00:01, 45.81it/s]concatenating: train:  68%|██████▊   | 167/247 [00:03<00:01, 44.39it/s]concatenating: train:  70%|██████▉   | 172/247 [00:03<00:01, 44.24it/s]concatenating: train:  72%|███████▏  | 177/247 [00:03<00:01, 44.58it/s]concatenating: train:  74%|███████▎  | 182/247 [00:03<00:01, 43.89it/s]concatenating: train:  76%|███████▌  | 187/247 [00:03<00:01, 43.46it/s]concatenating: train:  78%|███████▊  | 192/247 [00:03<00:01, 43.14it/s]concatenating: train:  80%|███████▉  | 197/247 [00:03<00:01, 44.24it/s]concatenating: train:  82%|████████▏ | 202/247 [00:04<00:00, 45.43it/s]concatenating: train:  84%|████████▍ | 207/247 [00:04<00:00, 46.21it/s]concatenating: train:  86%|████████▌ | 212/247 [00:04<00:00, 46.54it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 47.42it/s]concatenating: train:  90%|█████████ | 223/247 [00:04<00:00, 48.15it/s]concatenating: train:  93%|█████████▎| 229/247 [00:04<00:00, 48.88it/s]concatenating: train:  95%|█████████▍| 234/247 [00:04<00:00, 47.08it/s]concatenating: train:  97%|█████████▋| 239/247 [00:04<00:00, 45.97it/s]concatenating: train:  99%|█████████▉| 244/247 [00:04<00:00, 45.74it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 49.01it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:15<01:03, 15.90s/it]Loading test:  40%|████      | 2/5 [00:32<00:47, 15.97s/it]Loading test:  60%|██████    | 3/5 [00:41<00:28, 14.16s/it]Loading test:  80%|████████  | 4/5 [00:49<00:12, 12.20s/it]Loading test: 100%|██████████| 5/5 [01:02<00:00, 12.34s/it]Loading test: 100%|██████████| 5/5 [01:02<00:00, 12.46s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 58.16it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 40)   0           batch_normalization_7[0][0]      2020-01-21 22:23:36.769711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 22:23:36.769809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 22:23:36.769823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 22:23:36.769832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 22:23:36.770146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

loading the weights from thalamus:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights from thalamus:   2%|▏         | 1/44 [00:00<00:08,  5.35it/s]loading the weights from thalamus:   7%|▋         | 3/44 [00:00<00:06,  6.32it/s]loading the weights from thalamus:   9%|▉         | 4/44 [00:00<00:06,  5.92it/s]loading the weights from thalamus:  18%|█▊        | 8/44 [00:00<00:04,  7.54it/s]loading the weights from thalamus:  20%|██        | 9/44 [00:00<00:05,  6.59it/s]loading the weights from thalamus:  25%|██▌       | 11/44 [00:01<00:04,  7.45it/s]loading the weights from thalamus:  27%|██▋       | 12/44 [00:01<00:05,  6.25it/s]loading the weights from thalamus:  39%|███▊      | 17/44 [00:01<00:03,  8.06it/s]loading the weights from thalamus:  43%|████▎     | 19/44 [00:01<00:03,  8.25it/s]loading the weights from thalamus:  48%|████▊     | 21/44 [00:02<00:03,  6.73it/s]loading the weights from thalamus:  57%|█████▋    | 25/44 [00:02<00:02,  8.30it/s]loading the weights from thalamus:  61%|██████▏   | 27/44 [00:02<00:02,  8.43it/s]loading the weights from thalamus:  66%|██████▌   | 29/44 [00:02<00:01,  8.47it/s]loading the weights from thalamus:  70%|███████   | 31/44 [00:03<00:02,  6.37it/s]loading the weights from thalamus:  80%|███████▉  | 35/44 [00:03<00:01,  7.85it/s]loading the weights from thalamus:  84%|████████▍ | 37/44 [00:03<00:00,  7.96it/s]loading the weights from thalamus:  89%|████████▊ | 39/44 [00:04<00:00,  7.97it/s]loading the weights from thalamus:  91%|█████████ | 40/44 [00:04<00:00,  6.32it/s]loading the weights from thalamus:  93%|█████████▎| 41/44 [00:04<00:00,  5.39it/s]loading the weights from thalamus: 100%|██████████| 44/44 [00:04<00:00,  9.56it/s]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Thalamus /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [6.23445678e-02 3.14466599e-02 7.87009733e-02 9.58569325e-03
 2.85624540e-02 7.22898990e-03 8.58961989e-02 1.15143576e-01
 9.00669043e-02 1.30632297e-02 2.94050195e-01 1.83647930e-01
 2.62628510e-04]
Train on 9011 samples, validate on 184 samples
Epoch 1/300
 - 25s - loss: 0.7526 - acc: 0.7789 - mDice: 0.1890 - val_loss: 0.7106 - val_acc: 0.9072 - val_mDice: 0.2326

Epoch 00001: val_mDice improved from -inf to 0.23257, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 20s - loss: 0.5449 - acc: 0.9213 - mDice: 0.4123 - val_loss: 0.6436 - val_acc: 0.9307 - val_mDice: 0.2865

Epoch 00002: val_mDice improved from 0.23257 to 0.28649, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 0.4657 - acc: 0.9278 - mDice: 0.4979 - val_loss: 0.5766 - val_acc: 0.9346 - val_mDice: 0.2894

Epoch 00003: val_mDice improved from 0.28649 to 0.28939, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 0.4329 - acc: 0.9310 - mDice: 0.5334 - val_loss: 0.5764 - val_acc: 0.9303 - val_mDice: 0.3075

Epoch 00004: val_mDice improved from 0.28939 to 0.30746, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 20s - loss: 0.4140 - acc: 0.9330 - mDice: 0.5539 - val_loss: 0.5092 - val_acc: 0.9332 - val_mDice: 0.2978

Epoch 00005: val_mDice did not improve from 0.30746
Epoch 6/300
 - 20s - loss: 0.3976 - acc: 0.9345 - mDice: 0.5716 - val_loss: 0.4644 - val_acc: 0.9337 - val_mDice: 0.3104

Epoch 00006: val_mDice improved from 0.30746 to 0.31041, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 20s - loss: 0.3857 - acc: 0.9357 - mDice: 0.5844 - val_loss: 0.4473 - val_acc: 0.9304 - val_mDice: 0.3092

Epoch 00007: val_mDice did not improve from 0.31041
Epoch 8/300
 - 20s - loss: 0.3783 - acc: 0.9366 - mDice: 0.5925 - val_loss: 0.3809 - val_acc: 0.9423 - val_mDice: 0.3155

Epoch 00008: val_mDice improved from 0.31041 to 0.31550, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 21s - loss: 0.3704 - acc: 0.9375 - mDice: 0.6010 - val_loss: 0.3970 - val_acc: 0.9271 - val_mDice: 0.3184

Epoch 00009: val_mDice improved from 0.31550 to 0.31844, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 20s - loss: 0.3637 - acc: 0.9383 - mDice: 0.6083 - val_loss: 0.3077 - val_acc: 0.9388 - val_mDice: 0.3133

Epoch 00010: val_mDice did not improve from 0.31844
Epoch 11/300
 - 20s - loss: 0.3611 - acc: 0.9387 - mDice: 0.6110 - val_loss: 0.3547 - val_acc: 0.9320 - val_mDice: 0.3201

Epoch 00011: val_mDice improved from 0.31844 to 0.32010, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 0.3551 - acc: 0.9391 - mDice: 0.6175 - val_loss: 0.3331 - val_acc: 0.9342 - val_mDice: 0.3236

Epoch 00012: val_mDice improved from 0.32010 to 0.32363, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 0.3486 - acc: 0.9398 - mDice: 0.6246 - val_loss: 0.3392 - val_acc: 0.9342 - val_mDice: 0.3147

Epoch 00013: val_mDice did not improve from 0.32363
Epoch 14/300
 - 20s - loss: 0.3469 - acc: 0.9400 - mDice: 0.6265 - val_loss: 0.3690 - val_acc: 0.9262 - val_mDice: 0.3161

Epoch 00014: val_mDice did not improve from 0.32363
Epoch 15/300
 - 20s - loss: 0.3434 - acc: 0.9405 - mDice: 0.6303 - val_loss: 0.3089 - val_acc: 0.9348 - val_mDice: 0.3086

Epoch 00015: val_mDice did not improve from 0.32363
Epoch 16/300
 - 19s - loss: 0.3414 - acc: 0.9408 - mDice: 0.6324 - val_loss: 0.2821 - val_acc: 0.9361 - val_mDice: 0.3196

Epoch 00016: val_mDice did not improve from 0.32363
Epoch 17/300
 - 19s - loss: 0.3383 - acc: 0.9410 - mDice: 0.6357 - val_loss: 0.2798 - val_acc: 0.9355 - val_mDice: 0.3254

Epoch 00017: val_mDice improved from 0.32363 to 0.32542, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 20s - loss: 0.3358 - acc: 0.9413 - mDice: 0.6384 - val_loss: 0.3073 - val_acc: 0.9400 - val_mDice: 0.2923

Epoch 00018: val_mDice did not improve from 0.32542
Epoch 19/300
 - 19s - loss: 0.3334 - acc: 0.9416 - mDice: 0.6410 - val_loss: 0.3085 - val_acc: 0.9294 - val_mDice: 0.3242

Epoch 00019: val_mDice did not improve from 0.32542
Epoch 20/300
 - 19s - loss: 0.3322 - acc: 0.9417 - mDice: 0.6424 - val_loss: 0.3685 - val_acc: 0.9214 - val_mDice: 0.3146

Epoch 00020: val_mDice did not improve from 0.32542
Epoch 21/300
 - 20s - loss: 0.3303 - acc: 0.9422 - mDice: 0.6444 - val_loss: 0.3169 - val_acc: 0.9411 - val_mDice: 0.3265

Epoch 00021: val_mDice improved from 0.32542 to 0.32649, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 20s - loss: 0.3232 - acc: 0.9426 - mDice: 0.6521 - val_loss: 0.2825 - val_acc: 0.9368 - val_mDice: 0.3279

Epoch 00022: val_mDice improved from 0.32649 to 0.32791, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 19s - loss: 0.3235 - acc: 0.9428 - mDice: 0.6517 - val_loss: 0.3164 - val_acc: 0.9370 - val_mDice: 0.3303

Epoch 00023: val_mDice improved from 0.32791 to 0.33026, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 20s - loss: 0.3258 - acc: 0.9428 - mDice: 0.6493 - val_loss: 0.3043 - val_acc: 0.9389 - val_mDice: 0.3274

Epoch 00024: val_mDice did not improve from 0.33026
Epoch 25/300
 - 20s - loss: 0.3180 - acc: 0.9432 - mDice: 0.6577 - val_loss: 0.2965 - val_acc: 0.9313 - val_mDice: 0.3190

Epoch 00025: val_mDice did not improve from 0.33026
Epoch 26/300
 - 19s - loss: 0.3200 - acc: 0.9433 - mDice: 0.6555 - val_loss: 0.3346 - val_acc: 0.9328 - val_mDice: 0.3259

Epoch 00026: val_mDice did not improve from 0.33026
Epoch 27/300
 - 19s - loss: 0.3168 - acc: 0.9435 - mDice: 0.6590 - val_loss: 0.3029 - val_acc: 0.9311 - val_mDice: 0.3232

Epoch 00027: val_mDice did not improve from 0.33026
Epoch 28/300
 - 20s - loss: 0.3164 - acc: 0.9438 - mDice: 0.6594 - val_loss: 0.2863 - val_acc: 0.9389 - val_mDice: 0.3148

Epoch 00028: val_mDice did not improve from 0.33026
Epoch 29/300
 - 20s - loss: 0.3102 - acc: 0.9440 - mDice: 0.6662 - val_loss: 0.2225 - val_acc: 0.9406 - val_mDice: 0.3262

Epoch 00029: val_mDice did not improve from 0.33026
Epoch 30/300
 - 19s - loss: 0.3142 - acc: 0.9441 - mDice: 0.6618 - val_loss: 0.2402 - val_acc: 0.9408 - val_mDice: 0.3302

Epoch 00030: val_mDice did not improve from 0.33026
Epoch 31/300
 - 19s - loss: 0.3092 - acc: 0.9444 - mDice: 0.6672 - val_loss: 0.2074 - val_acc: 0.9430 - val_mDice: 0.3247

Epoch 00031: val_mDice did not improve from 0.33026
Epoch 32/300
 - 20s - loss: 0.3090 - acc: 0.9445 - mDice: 0.6674 - val_loss: 0.3766 - val_acc: 0.9338 - val_mDice: 0.3171

Epoch 00032: val_mDice did not improve from 0.33026
Epoch 33/300
 - 20s - loss: 0.3092 - acc: 0.9444 - mDice: 0.6672 - val_loss: 0.2495 - val_acc: 0.9413 - val_mDice: 0.3217

Epoch 00033: val_mDice did not improve from 0.33026
Epoch 34/300
 - 20s - loss: 0.3087 - acc: 0.9444 - mDice: 0.6677 - val_loss: 0.1971 - val_acc: 0.9432 - val_mDice: 0.3313

Epoch 00034: val_mDice improved from 0.33026 to 0.33126, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 19s - loss: 0.3078 - acc: 0.9448 - mDice: 0.6687 - val_loss: 0.2343 - val_acc: 0.9397 - val_mDice: 0.3002

Epoch 00035: val_mDice did not improve from 0.33126
Epoch 36/300
 - 20s - loss: 0.3033 - acc: 0.9450 - mDice: 0.6735 - val_loss: 0.2506 - val_acc: 0.9394 - val_mDice: 0.3279

Epoch 00036: val_mDice did not improve from 0.33126
Epoch 37/300
 - 20s - loss: 0.3051 - acc: 0.9451 - mDice: 0.6716 - val_loss: 0.2613 - val_acc: 0.9396 - val_mDice: 0.3337

Epoch 00037: val_mDice improved from 0.33126 to 0.33369, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 19s - loss: 0.3025 - acc: 0.9450 - mDice: 0.6745 - val_loss: 0.2479 - val_acc: 0.9401 - val_mDice: 0.3105

Epoch 00038: val_mDice did not improve from 0.33369
Epoch 39/300
 - 19s - loss: 0.3014 - acc: 0.9454 - mDice: 0.6756 - val_loss: 0.2311 - val_acc: 0.9363 - val_mDice: 0.3322

Epoch 00039: val_mDice did not improve from 0.33369
Epoch 40/300
 - 20s - loss: 0.3007 - acc: 0.9454 - mDice: 0.6764 - val_loss: 0.2940 - val_acc: 0.9349 - val_mDice: 0.3314

Epoch 00040: val_mDice did not improve from 0.33369
Epoch 41/300
 - 20s - loss: 0.3017 - acc: 0.9455 - mDice: 0.6753 - val_loss: 0.2565 - val_acc: 0.9356 - val_mDice: 0.3289

Epoch 00041: val_mDice did not improve from 0.33369
Epoch 42/300
 - 20s - loss: 0.3019 - acc: 0.9455 - mDice: 0.6751 - val_loss: 0.3367 - val_acc: 0.9342 - val_mDice: 0.3168

Epoch 00042: val_mDice did not improve from 0.33369
Epoch 43/300
 - 20s - loss: 0.2991 - acc: 0.9456 - mDice: 0.6781 - val_loss: 0.2799 - val_acc: 0.9355 - val_mDice: 0.3301

Epoch 00043: val_mDice did not improve from 0.33369
Epoch 44/300
 - 20s - loss: 0.2958 - acc: 0.9458 - mDice: 0.6817 - val_loss: 0.2494 - val_acc: 0.9299 - val_mDice: 0.2253

Epoch 00044: val_mDice did not improve from 0.33369
Epoch 45/300
 - 20s - loss: 0.2962 - acc: 0.9459 - mDice: 0.6812 - val_loss: 0.2365 - val_acc: 0.9336 - val_mDice: 0.3344

Epoch 00045: val_mDice improved from 0.33369 to 0.33442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 46/300
 - 20s - loss: 0.2960 - acc: 0.9459 - mDice: 0.6814 - val_loss: 0.3002 - val_acc: 0.9374 - val_mDice: 0.3103

Epoch 00046: val_mDice did not improve from 0.33442
Epoch 47/300
 - 19s - loss: 0.2963 - acc: 0.9461 - mDice: 0.6811 - val_loss: 0.1784 - val_acc: 0.9414 - val_mDice: 0.3139

Epoch 00047: val_mDice did not improve from 0.33442
Epoch 48/300
 - 20s - loss: 0.2952 - acc: 0.9462 - mDice: 0.6823 - val_loss: 0.1741 - val_acc: 0.9429 - val_mDice: 0.3174

Epoch 00048: val_mDice did not improve from 0.33442
Epoch 49/300
 - 19s - loss: 0.2940 - acc: 0.9463 - mDice: 0.6836 - val_loss: 0.2750 - val_acc: 0.9332 - val_mDice: 0.3297

Epoch 00049: val_mDice did not improve from 0.33442
Epoch 50/300
 - 20s - loss: 0.2946 - acc: 0.9463 - mDice: 0.6829 - val_loss: 0.2654 - val_acc: 0.9363 - val_mDice: 0.3327

Epoch 00050: val_mDice did not improve from 0.33442
Epoch 51/300
 - 20s - loss: 0.2934 - acc: 0.9463 - mDice: 0.6843 - val_loss: 0.1853 - val_acc: 0.9413 - val_mDice: 0.3175

Epoch 00051: val_mDice did not improve from 0.33442
Epoch 52/300
 - 21s - loss: 0.2915 - acc: 0.9467 - mDice: 0.6863 - val_loss: 0.1982 - val_acc: 0.9399 - val_mDice: 0.3329

Epoch 00052: val_mDice did not improve from 0.33442

Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 53/300
 - 20s - loss: 0.2884 - acc: 0.9472 - mDice: 0.6896 - val_loss: 0.1952 - val_acc: 0.9393 - val_mDice: 0.3362

Epoch 00053: val_mDice improved from 0.33442 to 0.33619, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 54/300
 - 20s - loss: 0.2834 - acc: 0.9473 - mDice: 0.6950 - val_loss: 0.2414 - val_acc: 0.9403 - val_mDice: 0.3378

Epoch 00054: val_mDice improved from 0.33619 to 0.33784, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 55/300
 - 20s - loss: 0.2848 - acc: 0.9473 - mDice: 0.6935 - val_loss: 0.1995 - val_acc: 0.9431 - val_mDice: 0.3357

Epoch 00055: val_mDice did not improve from 0.33784
Epoch 56/300
 - 20s - loss: 0.2830 - acc: 0.9474 - mDice: 0.6954 - val_loss: 0.1699 - val_acc: 0.9437 - val_mDice: 0.3278

Epoch 00056: val_mDice did not improve from 0.33784
Epoch 57/300
 - 20s - loss: 0.2835 - acc: 0.9476 - mDice: 0.6949 - val_loss: 0.2498 - val_acc: 0.9356 - val_mDice: 0.3356

Epoch 00057: val_mDice did not improve from 0.33784
Epoch 58/300
 - 20s - loss: 0.2849 - acc: 0.9475 - mDice: 0.6934 - val_loss: 0.1600 - val_acc: 0.9395 - val_mDice: 0.3306

Epoch 00058: val_mDice did not improve from 0.33784
Epoch 59/300
 - 20s - loss: 0.2825 - acc: 0.9476 - mDice: 0.6960 - val_loss: 0.2195 - val_acc: 0.9395 - val_mDice: 0.3372

Epoch 00059: val_mDice did not improve from 0.33784
Epoch 60/300
 - 20s - loss: 0.2781 - acc: 0.9477 - mDice: 0.7008 - val_loss: 0.1784 - val_acc: 0.9425 - val_mDice: 0.3348

Epoch 00060: val_mDice did not improve from 0.33784
Epoch 61/300
 - 19s - loss: 0.2786 - acc: 0.9478 - mDice: 0.7002 - val_loss: 0.1569 - val_acc: 0.9440 - val_mDice: 0.3261

Epoch 00061: val_mDice did not improve from 0.33784
Epoch 62/300
 - 19s - loss: 0.2804 - acc: 0.9478 - mDice: 0.6983 - val_loss: 0.3081 - val_acc: 0.9319 - val_mDice: 0.3278

Epoch 00062: val_mDice did not improve from 0.33784
Epoch 63/300
 - 20s - loss: 0.2794 - acc: 0.9477 - mDice: 0.6994 - val_loss: 0.3019 - val_acc: 0.9333 - val_mDice: 0.2822

Epoch 00063: val_mDice did not improve from 0.33784
Epoch 64/300
 - 20s - loss: 0.2791 - acc: 0.9478 - mDice: 0.6997 - val_loss: 0.2476 - val_acc: 0.9377 - val_mDice: 0.3365

Epoch 00064: val_mDice did not improve from 0.33784
Epoch 65/300
 - 19s - loss: 0.2764 - acc: 0.9479 - mDice: 0.7026 - val_loss: 0.2459 - val_acc: 0.9360 - val_mDice: 0.3354

Epoch 00065: val_mDice did not improve from 0.33784
Epoch 66/300
 - 20s - loss: 0.2784 - acc: 0.9479 - mDice: 0.7005 - val_loss: 0.1919 - val_acc: 0.9411 - val_mDice: 0.3331

Epoch 00066: val_mDice did not improve from 0.33784
Epoch 67/300
 - 19s - loss: 0.2791 - acc: 0.9480 - mDice: 0.6997 - val_loss: 0.2368 - val_acc: 0.9404 - val_mDice: 0.3343

Epoch 00067: val_mDice did not improve from 0.33784
Epoch 68/300
 - 19s - loss: 0.2797 - acc: 0.9481 - mDice: 0.6991 - val_loss: 0.1845 - val_acc: 0.9394 - val_mDice: 0.3317

Epoch 00068: val_mDice did not improve from 0.33784
Epoch 69/300
 - 19s - loss: 0.2771 - acc: 0.9482 - mDice: 0.7018 - val_loss: 0.2175 - val_acc: 0.9402 - val_mDice: 0.3319

Epoch 00069: val_mDice did not improve from 0.33784

Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 70/300
 - 19s - loss: 0.2750 - acc: 0.9484 - mDice: 0.7041 - val_loss: 0.1822 - val_acc: 0.9439 - val_mDice: 0.3292

Epoch 00070: val_mDice did not improve from 0.33784
Epoch 71/300
 - 19s - loss: 0.2727 - acc: 0.9484 - mDice: 0.7066 - val_loss: 0.2082 - val_acc: 0.9389 - val_mDice: 0.3334

Epoch 00071: val_mDice did not improve from 0.33784
Epoch 72/300
 - 20s - loss: 0.2727 - acc: 0.9483 - mDice: 0.7066 - val_loss: 0.2148 - val_acc: 0.9347 - val_mDice: 0.3306

Epoch 00072: val_mDice did not improve from 0.33784
Epoch 73/300
 - 20s - loss: 0.2709 - acc: 0.9486 - mDice: 0.7085 - val_loss: 0.2003 - val_acc: 0.9406 - val_mDice: 0.3350

Epoch 00073: val_mDice did not improve from 0.33784
Epoch 74/300
 - 20s - loss: 0.2706 - acc: 0.9486 - mDice: 0.7088 - val_loss: 0.2039 - val_acc: 0.9398 - val_mDice: 0.3332

Epoch 00074: val_mDice did not improve from 0.33784
Epoch 75/300
 - 20s - loss: 0.2721 - acc: 0.9485 - mDice: 0.7073 - val_loss: 0.2066 - val_acc: 0.9425 - val_mDice: 0.3285

Epoch 00075: val_mDice did not improve from 0.33784
Epoch 76/300
 - 19s - loss: 0.2720 - acc: 0.9485 - mDice: 0.7074 - val_loss: 0.1863 - val_acc: 0.9421 - val_mDice: 0.3310

Epoch 00076: val_mDice did not improve from 0.33784
Epoch 77/300
 - 20s - loss: 0.2748 - acc: 0.9485 - mDice: 0.7043 - val_loss: 0.1742 - val_acc: 0.9394 - val_mDice: 0.3361

Epoch 00077: val_mDice did not improve from 0.33784
Epoch 78/300
 - 20s - loss: 0.2713 - acc: 0.9487 - mDice: 0.7081 - val_loss: 0.1828 - val_acc: 0.9418 - val_mDice: 0.3368

Epoch 00078: val_mDice did not improve from 0.33784
Epoch 79/300
 - 20s - loss: 0.2717 - acc: 0.9486 - mDice: 0.7076 - val_loss: 0.1872 - val_acc: 0.9434 - val_mDice: 0.3295

Epoch 00079: val_mDice did not improve from 0.33784
Epoch 80/300
 - 20s - loss: 0.2717 - acc: 0.9485 - mDice: 0.7077 - val_loss: 0.2107 - val_acc: 0.9392 - val_mDice: 0.3374

Epoch 00080: val_mDice did not improve from 0.33784
Epoch 81/300
 - 21s - loss: 0.2696 - acc: 0.9487 - mDice: 0.7099 - val_loss: 0.1666 - val_acc: 0.9416 - val_mDice: 0.3380

Epoch 00081: val_mDice improved from 0.33784 to 0.33804, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 82/300
 - 19s - loss: 0.2715 - acc: 0.9486 - mDice: 0.7079 - val_loss: 0.1524 - val_acc: 0.9412 - val_mDice: 0.3322

Epoch 00082: val_mDice did not improve from 0.33804
Epoch 83/300
 - 20s - loss: 0.2691 - acc: 0.9488 - mDice: 0.7105 - val_loss: 0.1952 - val_acc: 0.9391 - val_mDice: 0.3367

Epoch 00083: val_mDice did not improve from 0.33804
Epoch 84/300
 - 19s - loss: 0.2715 - acc: 0.9487 - mDice: 0.7079 - val_loss: 0.2040 - val_acc: 0.9401 - val_mDice: 0.3376

Epoch 00084: val_mDice did not improve from 0.33804

Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 85/300
 - 19s - loss: 0.2672 - acc: 0.9489 - mDice: 0.7126 - val_loss: 0.1889 - val_acc: 0.9394 - val_mDice: 0.3366

Epoch 00085: val_mDice did not improve from 0.33804
Epoch 86/300
 - 19s - loss: 0.2665 - acc: 0.9490 - mDice: 0.7133 - val_loss: 0.2032 - val_acc: 0.9403 - val_mDice: 0.3350

Epoch 00086: val_mDice did not improve from 0.33804
Epoch 87/300
 - 20s - loss: 0.2693 - acc: 0.9490 - mDice: 0.7103 - val_loss: 0.2159 - val_acc: 0.9392 - val_mDice: 0.3344

Epoch 00087: val_mDice did not improve from 0.33804
Epoch 88/300
 - 20s - loss: 0.2690 - acc: 0.9490 - mDice: 0.7106 - val_loss: 0.1898 - val_acc: 0.9419 - val_mDice: 0.3336

Epoch 00088: val_mDice did not improve from 0.33804
Epoch 89/300
 - 20s - loss: 0.2702 - acc: 0.9490 - mDice: 0.7093 - val_loss: 0.1815 - val_acc: 0.9389 - val_mDice: 0.3357

Epoch 00089: val_mDice did not improve from 0.33804
Epoch 90/300
 - 19s - loss: 0.2650 - acc: 0.9490 - mDice: 0.7149 - val_loss: 0.1972 - val_acc: 0.9397 - val_mDice: 0.3349

Epoch 00090: val_mDice did not improve from 0.33804
Epoch 91/300
 - 20s - loss: 0.2681 - acc: 0.9490 - mDice: 0.7116 - val_loss: 0.1871 - val_acc: 0.9395 - val_mDice: 0.3356

Epoch 00091: val_mDice did not improve from 0.33804
Epoch 92/300
 - 20s - loss: 0.2667 - acc: 0.9490 - mDice: 0.7131 - val_loss: 0.1888 - val_acc: 0.9392 - val_mDice: 0.3348

Epoch 00092: val_mDice did not improve from 0.33804
Epoch 93/300
 - 20s - loss: 0.2668 - acc: 0.9491 - mDice: 0.7130 - val_loss: 0.1678 - val_acc: 0.9416 - val_mDice: 0.3350

Epoch 00093: val_mDice did not improve from 0.33804
Epoch 94/300
 - 20s - loss: 0.2659 - acc: 0.9491 - mDice: 0.7139 - val_loss: 0.1846 - val_acc: 0.9401 - val_mDice: 0.3342

Epoch 00094: val_mDice did not improve from 0.33804
Epoch 95/300
 - 20s - loss: 0.2669 - acc: 0.9491 - mDice: 0.7128 - val_loss: 0.1802 - val_acc: 0.9409 - val_mDice: 0.3370

Epoch 00095: val_mDice did not improve from 0.33804
Epoch 96/300
 - 20s - loss: 0.2690 - acc: 0.9491 - mDice: 0.7106 - val_loss: 0.2148 - val_acc: 0.9383 - val_mDice: 0.3345

Epoch 00096: val_mDice did not improve from 0.33804
Epoch 97/300
 - 19s - loss: 0.2650 - acc: 0.9490 - mDice: 0.7149 - val_loss: 0.1728 - val_acc: 0.9409 - val_mDice: 0.3337

Epoch 00097: val_mDice did not improve from 0.33804
Epoch 98/300
 - 20s - loss: 0.2647 - acc: 0.9492 - mDice: 0.7152 - val_loss: 0.1962 - val_acc: 0.9397 - val_mDice: 0.3364

Epoch 00098: val_mDice did not improve from 0.33804
Epoch 99/300
 - 19s - loss: 0.2697 - acc: 0.9491 - mDice: 0.7098 - val_loss: 0.1747 - val_acc: 0.9408 - val_mDice: 0.3356

Epoch 00099: val_mDice did not improve from 0.33804

Epoch 00099: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 100/300
 - 19s - loss: 0.2668 - acc: 0.9492 - mDice: 0.7130 - val_loss: 0.1766 - val_acc: 0.9409 - val_mDice: 0.3366

Epoch 00100: val_mDice did not improve from 0.33804
Epoch 101/300
 - 19s - loss: 0.2667 - acc: 0.9492 - mDice: 0.7131 - val_loss: 0.1901 - val_acc: 0.9395 - val_mDice: 0.3347

Epoch 00101: val_mDice did not improve from 0.33804
Epoch 102/300
 - 19s - loss: 0.2683 - acc: 0.9492 - mDice: 0.7113 - val_loss: 0.1842 - val_acc: 0.9405 - val_mDice: 0.3354

Epoch 00102: val_mDice did not improve from 0.33804
Epoch 103/300
 - 20s - loss: 0.2673 - acc: 0.9492 - mDice: 0.7124 - val_loss: 0.1849 - val_acc: 0.9409 - val_mDice: 0.3344

Epoch 00103: val_mDice did not improve from 0.33804
Epoch 104/300
 - 20s - loss: 0.2653 - acc: 0.9493 - mDice: 0.7146 - val_loss: 0.1944 - val_acc: 0.9401 - val_mDice: 0.3359

Epoch 00104: val_mDice did not improve from 0.33804
Epoch 105/300
 - 20s - loss: 0.2658 - acc: 0.9493 - mDice: 0.7141 - val_loss: 0.1877 - val_acc: 0.9402 - val_mDice: 0.3358

Epoch 00105: val_mDice did not improve from 0.33804
Epoch 106/300
 - 20s - loss: 0.2670 - acc: 0.9492 - mDice: 0.7128 - val_loss: 0.1974 - val_acc: 0.9398 - val_mDice: 0.3346

Epoch 00106: val_mDice did not improve from 0.33804
Epoch 107/300
 - 20s - loss: 0.2675 - acc: 0.9492 - mDice: 0.7122 - val_loss: 0.2143 - val_acc: 0.9394 - val_mDice: 0.3365

Epoch 00107: val_mDice did not improve from 0.33804
Epoch 108/300
 - 19s - loss: 0.2675 - acc: 0.9492 - mDice: 0.7122 - val_loss: 0.1753 - val_acc: 0.9414 - val_mDice: 0.3355

Epoch 00108: val_mDice did not improve from 0.33804
Epoch 109/300
 - 20s - loss: 0.2676 - acc: 0.9492 - mDice: 0.7122 - val_loss: 0.2015 - val_acc: 0.9402 - val_mDice: 0.3351

Epoch 00109: val_mDice did not improve from 0.33804
Epoch 110/300
 - 20s - loss: 0.2665 - acc: 0.9493 - mDice: 0.7133 - val_loss: 0.1751 - val_acc: 0.9409 - val_mDice: 0.3345

Epoch 00110: val_mDice did not improve from 0.33804
Epoch 111/300
 - 20s - loss: 0.2668 - acc: 0.9492 - mDice: 0.7128 - val_loss: 0.1940 - val_acc: 0.9394 - val_mDice: 0.3355

Epoch 00111: val_mDice did not improve from 0.33804
Epoch 112/300
 - 21s - loss: 0.2662 - acc: 0.9493 - mDice: 0.7136 - val_loss: 0.1727 - val_acc: 0.9410 - val_mDice: 0.3353

Epoch 00112: val_mDice did not improve from 0.33804
Epoch 113/300
 - 20s - loss: 0.2654 - acc: 0.9493 - mDice: 0.7145 - val_loss: 0.1952 - val_acc: 0.9397 - val_mDice: 0.3359

Epoch 00113: val_mDice did not improve from 0.33804
Epoch 114/300
 - 20s - loss: 0.2667 - acc: 0.9492 - mDice: 0.7131 - val_loss: 0.2045 - val_acc: 0.9382 - val_mDice: 0.3353

Epoch 00114: val_mDice did not improve from 0.33804

Epoch 00114: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
Epoch 115/300
 - 21s - loss: 0.2679 - acc: 0.9493 - mDice: 0.7118 - val_loss: 0.2019 - val_acc: 0.9404 - val_mDice: 0.3374

Epoch 00115: val_mDice did not improve from 0.33804
Epoch 116/300
 - 20s - loss: 0.2649 - acc: 0.9493 - mDice: 0.7150 - val_loss: 0.2202 - val_acc: 0.9394 - val_mDice: 0.3363

Epoch 00116: val_mDice did not improve from 0.33804
Epoch 117/300
 - 20s - loss: 0.2659 - acc: 0.9493 - mDice: 0.7140 - val_loss: 0.2141 - val_acc: 0.9396 - val_mDice: 0.3356

Epoch 00117: val_mDice did not improve from 0.33804
Epoch 118/300
 - 21s - loss: 0.2658 - acc: 0.9493 - mDice: 0.7140 - val_loss: 0.2093 - val_acc: 0.9393 - val_mDice: 0.3359

Epoch 00118: val_mDice did not improve from 0.33804
Epoch 119/300
 - 20s - loss: 0.2659 - acc: 0.9493 - mDice: 0.7140 - val_loss: 0.1811 - val_acc: 0.9404 - val_mDice: 0.3358

Epoch 00119: val_mDice did not improve from 0.33804
Epoch 120/300
 - 20s - loss: 0.2659 - acc: 0.9493 - mDice: 0.7139 - val_loss: 0.1958 - val_acc: 0.9397 - val_mDice: 0.3374

Epoch 00120: val_mDice did not improve from 0.33804
Epoch 121/300
 - 20s - loss: 0.2659 - acc: 0.9494 - mDice: 0.7139 - val_loss: 0.1767 - val_acc: 0.9397 - val_mDice: 0.3351

Epoch 00121: val_mDice did not improve from 0.33804
Restoring model weights from the end of the best epoch
Epoch 00121: early stopping
{'val_loss': [0.7106320858001709, 0.6436437089806017, 0.5766095204845719, 0.5763729979162631, 0.509169663100139, 0.4644051850773394, 0.44725962874034175, 0.3808575085485759, 0.39697704124061955, 0.30772378789665905, 0.35466467299620097, 0.3331138728105504, 0.33919221502931224, 0.3690415629712136, 0.3089001340103214, 0.28213534848359617, 0.2797735034204695, 0.30731760902816185, 0.30854063043775765, 0.36847243862955464, 0.31693850967871107, 0.28252195846289396, 0.3164281324361977, 0.3042954177717152, 0.29653338711384847, 0.33461108350235486, 0.30292913001840527, 0.28632998199242615, 0.22249677465499743, 0.24020504716621793, 0.20744120418701484, 0.37656213650884834, 0.2494782843961097, 0.19712701993589493, 0.2342562498524785, 0.25060794931714947, 0.2613054111437953, 0.24785924419436767, 0.2311354340357787, 0.2940309235988104, 0.2564703501841944, 0.3367299607590489, 0.2798979594979597, 0.2493786568874898, 0.23652155956496362, 0.3001730560891978, 0.17841007309439388, 0.17409885889324156, 0.27499951023460395, 0.2653599814714297, 0.18527019434891964, 0.19819264536541278, 0.19521259694643642, 0.24143575532766787, 0.1994989303993466, 0.1698759704342355, 0.24977154997379883, 0.1599624282022452, 0.2195353422658113, 0.17844889078633455, 0.15694156327568318, 0.30806515078343777, 0.30187668699933135, 0.24760747272723718, 0.24593987575043802, 0.19187344836435563, 0.2368112320849753, 0.1844864659335302, 0.21751292724081356, 0.18218039585601375, 0.20824583961992807, 0.21477255969480408, 0.20034093570733524, 0.20389964688381398, 0.20657277228715626, 0.18629492854739985, 0.1741760550117444, 0.182812301148458, 0.18723876853271024, 0.2107168816677902, 0.16662058616234193, 0.15238776667873657, 0.1951657514968563, 0.2039574873836144, 0.18886988451096998, 0.2031567842780572, 0.21585428258264944, 0.18983150872847307, 0.18153096117353212, 0.19718429543401883, 0.18707058885268887, 0.18875197952856188, 0.16775329917183388, 0.18463952271470233, 0.18024473164595015, 0.21482548110772925, 0.1727571001316866, 0.1962297376619814, 0.17472923040875923, 0.17659391936562632, 0.19009231966312812, 0.18423954759845915, 0.18485700284414316, 0.19441314406045104, 0.18774346284487325, 0.19735324127554044, 0.21431029484728756, 0.17534405041647994, 0.20148380078456324, 0.1751268503823034, 0.19403205689994377, 0.1726879543705803, 0.19518570468315613, 0.20446253379644908, 0.20190736519820665, 0.2201791930154128, 0.21408688816059704, 0.2093454550966904, 0.1810634217184523, 0.19581986724844444, 0.1767244055827968], 'val_acc': [0.9071880255056464, 0.9307287251171859, 0.9345970924781717, 0.9303394115489462, 0.933163931188376, 0.9337230804173843, 0.9303812125454778, 0.9422893997119821, 0.9270863779213118, 0.9388221191323322, 0.9320469330186429, 0.9342417470786882, 0.9341568324876868, 0.9262345847876176, 0.9348139542600383, 0.9360981933448626, 0.9354854699062265, 0.940044940813728, 0.9294327445652174, 0.9213903066904648, 0.9410926997661591, 0.9368428613828577, 0.9370087793339854, 0.9388652320789255, 0.9313323031301084, 0.9328360155872677, 0.9311454840328383, 0.9388586995394334, 0.9405557590982189, 0.9407504200935364, 0.94302884651267, 0.9338472077380056, 0.9412912771753643, 0.9431516547565875, 0.9396948153557985, 0.9393708155207012, 0.9396177277616833, 0.940127243814261, 0.9362967681625615, 0.9349054137001866, 0.9355952091839003, 0.9341568305440571, 0.9355102997759114, 0.9299265858919724, 0.9335859158764714, 0.937449047098989, 0.9413984055104463, 0.9428511696017307, 0.9332188005032747, 0.9362980827041294, 0.9412925826466602, 0.9399025407822236, 0.9392702197251113, 0.9402735667384189, 0.9430562808461811, 0.9437303996604421, 0.935608279445897, 0.9394596543001092, 0.9395066888436027, 0.9424683898687363, 0.9440256532119669, 0.9319045297477556, 0.933323319191518, 0.9376829020355059, 0.9359518723643344, 0.9410522061845531, 0.9404029055781986, 0.9393512295640033, 0.940208247822264, 0.9439394273187803, 0.9389410005963367, 0.9347094550080921, 0.9405975685171459, 0.9397731999988141, 0.9424631498430086, 0.942137854254764, 0.9393851906061172, 0.941757686112238, 0.9434364515802135, 0.9392035979291667, 0.9415721653596215, 0.941215513193089, 0.9390677168317463, 0.9401207041481267, 0.939421771661095, 0.9402866370004156, 0.9392179684794467, 0.9418648027855417, 0.9389005037753478, 0.9396948127642922, 0.9395040746616281, 0.9391787738903709, 0.9416035174027734, 0.9400776080463243, 0.9408614641946295, 0.9382668804863225, 0.9408536261838415, 0.9396961201792178, 0.9407856833675633, 0.9409463852643967, 0.9395092997861945, 0.9404786838137585, 0.9409489903760992, 0.9400671487269194, 0.9402317618546279, 0.9397954085598821, 0.9393799719603165, 0.9413644477077152, 0.9401964895103289, 0.9409215651128603, 0.9394243793643039, 0.9409907997950263, 0.9396856731694677, 0.9381532189638718, 0.9404355702192887, 0.9393760471240334, 0.9396490882272306, 0.9392506259938945, 0.9404420943363853, 0.93967390967452, 0.9397366267183552], 'val_mDice': [0.2325690347561323, 0.2864903729258537, 0.2893947202693524, 0.3074642932244941, 0.29776927071288445, 0.3104086325602395, 0.3092397511936724, 0.3154955172668333, 0.3184374916448217, 0.31333335614560737, 0.3201042807346391, 0.3236288537306752, 0.3147393590973123, 0.31610986284035986, 0.30861051858443284, 0.3195684219751021, 0.32541806210318336, 0.2922980969204851, 0.32422053676260554, 0.31464206071003625, 0.3264941943242739, 0.32791079860180616, 0.3302612968760988, 0.3274205975720416, 0.3190142458466732, 0.325940381695071, 0.3232276569242063, 0.31478472556109016, 0.32624181279021763, 0.3301875430928624, 0.3246640652904044, 0.3171090316027403, 0.3217195634446714, 0.3312552639323732, 0.3002390289760154, 0.32788060160110827, 0.3336875371472991, 0.3104877686532943, 0.3321518233936766, 0.33135700845362054, 0.3288814537227154, 0.3168057488362013, 0.3301069694571197, 0.2253370043447079, 0.3344199999195078, 0.31031096090927074, 0.31393252394121623, 0.31744524512601935, 0.3296554015706415, 0.3327495197198637, 0.31753620213788486, 0.3328525404567304, 0.3361920874727809, 0.33784434928194335, 0.3357472995539074, 0.32780179267992143, 0.3355765509945543, 0.33058338515136554, 0.33717878924115846, 0.33479497201092867, 0.32611313154516014, 0.3278208867768231, 0.28223107661292685, 0.33649826887995005, 0.33543920626296947, 0.33313760858124003, 0.33428693230709305, 0.33171449079299753, 0.33192460263228935, 0.32915859280721, 0.33337337150443913, 0.33064064950398775, 0.3350382457720116, 0.33323169629211014, 0.3285138410232637, 0.33099530608919653, 0.3360777027581049, 0.33675046151746973, 0.32954795650489954, 0.33735200969259377, 0.3380394018376651, 0.33215473895762954, 0.3366678189486265, 0.33758297323694697, 0.33656299895728414, 0.3350232493277207, 0.33435514188655047, 0.3335666020765253, 0.33565380448556464, 0.3348904211155098, 0.3355593070306856, 0.3348192093620563, 0.3350163097290889, 0.3341985241631451, 0.33703233925225395, 0.33448763199798437, 0.33373625139179436, 0.3364123178888922, 0.3356066866887056, 0.33661397141606914, 0.3347291007395024, 0.33543060778449374, 0.3343791873565984, 0.3359097355733747, 0.33580739622044825, 0.33456056330191053, 0.3364887138747651, 0.33549168047366923, 0.3351320448614981, 0.33454711913414625, 0.3354905017287187, 0.33533132659352344, 0.3359032303054372, 0.3352995500090006, 0.33744743951145845, 0.3362744346908901, 0.33563430611368106, 0.3359067048067632, 0.3357542834609099, 0.3373521962405547, 0.3351152594322744], 'loss': [0.7526347062230812, 0.5448783140258696, 0.4657220317962603, 0.43294797309058025, 0.4140306788456055, 0.39761519910307336, 0.3857358159281784, 0.3782664117796177, 0.370425401199884, 0.36368560226454927, 0.3611183917531691, 0.35511845122721414, 0.3485917773644703, 0.3468695897503574, 0.34335467753816745, 0.34136564002861497, 0.33832559296444775, 0.33583684887556375, 0.33340386027515084, 0.332154549817877, 0.330301009349243, 0.3231657169268962, 0.32353729241471907, 0.3257612931670154, 0.31796838927052024, 0.3200441983699693, 0.3167762915860031, 0.3163966661605014, 0.31016115285476853, 0.3142196865407757, 0.30916744085623465, 0.3089843792525609, 0.30919557635202854, 0.30873739657213123, 0.30782164552079205, 0.3033287190376303, 0.3050760231831933, 0.30246164083758653, 0.301423876912093, 0.3007211693647421, 0.3016852748875559, 0.30191077649983616, 0.2991333791285161, 0.29578258443945005, 0.296249829172334, 0.29604837253744337, 0.2962775038748123, 0.2952308449499378, 0.29399611259086217, 0.29464410362663285, 0.29337249996063913, 0.29150564678368035, 0.2884175351914628, 0.2834171021458259, 0.2848371479582964, 0.2830473915868615, 0.2834978850531321, 0.28492994128751536, 0.28253157625199954, 0.2780965038289665, 0.2786127954188971, 0.28037409514979217, 0.2793802839248377, 0.27912744089271474, 0.27637405327244585, 0.27835462836774205, 0.27911193899197634, 0.2796657033725182, 0.2770938322918752, 0.27498432822569324, 0.2726944106795417, 0.27272941019159086, 0.27093403865713983, 0.2706075355554445, 0.2720628661501356, 0.2719723618549137, 0.27481899690038025, 0.27131328676294875, 0.2717166097708408, 0.2716745425012794, 0.26960398061811797, 0.2715204661151252, 0.2690618601845208, 0.2714827294758985, 0.26718771372343086, 0.26649675232934683, 0.26928295708565186, 0.2690018832075015, 0.2701612543833532, 0.26503610141982964, 0.2680907110509882, 0.2666564167882028, 0.26680020993113873, 0.2659420959329833, 0.2669436627501402, 0.269032127960926, 0.2649756349782782, 0.26470901148259185, 0.26973104467998926, 0.2667517904442326, 0.26666242051582306, 0.2682875579502299, 0.2673247285297213, 0.2652652900731732, 0.2658022798737547, 0.26695984813312673, 0.26748392275615085, 0.26754606868143604, 0.26756452864870856, 0.2664582052362863, 0.26684991336202213, 0.2662353904202833, 0.2653674728735982, 0.2666536459295986, 0.2678530417203295, 0.26489252870030733, 0.2658507150473122, 0.2658302415066826, 0.2658963532773785, 0.26593307148482875, 0.2659344430961192], 'acc': [0.7789089240273497, 0.921324764659595, 0.9277661698876045, 0.9310284769504638, 0.9329589684310386, 0.9344796261529708, 0.935659461367502, 0.9365767170210523, 0.9375102698915397, 0.9382745873225594, 0.938726705433777, 0.9390636875592119, 0.9398001802707139, 0.9400348822875526, 0.9405127709375716, 0.9407561169905213, 0.9410165895395466, 0.9413348430402403, 0.941592087056155, 0.9416620065324276, 0.9421702268491137, 0.942578249376657, 0.9427526609414215, 0.9427694671162754, 0.9431780751597377, 0.9433394969336506, 0.9435344790991661, 0.943837553054349, 0.9440205568360271, 0.9440905024071087, 0.9444132382485276, 0.9445472618356395, 0.9443972327245908, 0.9443866680311636, 0.944787433641942, 0.945039395724559, 0.9450913103184283, 0.9450233108578505, 0.9453923036871972, 0.9454428559600573, 0.9454713744707608, 0.9454778559450542, 0.945559701370804, 0.9458216934248552, 0.9459122074535401, 0.9459440598820175, 0.9461020666226577, 0.9462392382822321, 0.9463187889126214, 0.9463301258999451, 0.9463352482944095, 0.9466646262602171, 0.9472318283991126, 0.9473266646608292, 0.9472886771344011, 0.9473853795685312, 0.9476097324370492, 0.9474603955495134, 0.9476317401705433, 0.947711317041264, 0.9477645901593315, 0.9477984446913563, 0.9477004063948319, 0.947757095134876, 0.9478733792062631, 0.9479064318438162, 0.9480104447469477, 0.9480588898424859, 0.9481831507298621, 0.9484279098448299, 0.9483573501362228, 0.9483331544935577, 0.948622305627907, 0.9486121402941987, 0.9484544260204731, 0.948498042498163, 0.9485280532681337, 0.9486741099356547, 0.9485803678302703, 0.9485231189348896, 0.9487294918979369, 0.9486160082592708, 0.9488200052254685, 0.9487073761140741, 0.9488735994982039, 0.9489945245958594, 0.9490323262902055, 0.9489814269266201, 0.9490360866877787, 0.9490197350587, 0.9490090637767424, 0.949030378936147, 0.9490898401421561, 0.949060630565504, 0.9491389787246062, 0.9490519603353642, 0.9490179201763116, 0.9491824371186864, 0.9490992573254541, 0.9492141275079914, 0.9491887043443454, 0.9492351497109968, 0.9491722456306374, 0.9492560373984038, 0.9493137134548932, 0.9492402712786294, 0.9492304011569173, 0.9492059928663641, 0.9492480866441504, 0.9492717235337853, 0.949221252488873, 0.9492531036605661, 0.949280099623503, 0.9492037508493257, 0.9493340399815364, 0.9493046429522122, 0.9493133123687496, 0.9492866090116352, 0.94932497043798, 0.9493056824384314, 0.9493789104454368], 'mDice': [0.18896853492377488, 0.4122945596462428, 0.49794076986535646, 0.5333982462286883, 0.5538665731254051, 0.5716032500850805, 0.5844339399540971, 0.5925155662594671, 0.6009721668668017, 0.6082559837549908, 0.611026663303825, 0.617530613039617, 0.6245996723289086, 0.6264762265880363, 0.6302622107849073, 0.6324335124420942, 0.6357172046209358, 0.6383999556736284, 0.6410374976186083, 0.6423836989114736, 0.6443861221555414, 0.652100865334031, 0.6517160121442845, 0.6493055493370461, 0.6577373910937163, 0.6554715188027698, 0.6590134765679557, 0.6594082805864582, 0.6661567124419784, 0.661764290277628, 0.6672248063672463, 0.6674200159875524, 0.6672095620741975, 0.6677031100768649, 0.6686749072281797, 0.6735323382864622, 0.6716364187103386, 0.6744778649733686, 0.6755967557398435, 0.6763619089243005, 0.6752980627874439, 0.6750690624896727, 0.6780757793124992, 0.6816810855668627, 0.6811808197251727, 0.681393740858067, 0.6811366116212775, 0.682278554945698, 0.6836049031495598, 0.6829149992467825, 0.6842792423686128, 0.6863102281716036, 0.6896283896864221, 0.6950277744857205, 0.6935025241022144, 0.6954312005366883, 0.6949255785320565, 0.6933872187994863, 0.6959627278569985, 0.7007635955593057, 0.7002178780406287, 0.6983036977669835, 0.6993980620706693, 0.6996668978141449, 0.7026376116753366, 0.700457201861552, 0.6996706120745083, 0.69907005401784, 0.7018345484569802, 0.7041201159356371, 0.7066204090214189, 0.7065732479922291, 0.7084746680911512, 0.7088481693113833, 0.7072945723171412, 0.7073922128861123, 0.7043083988592291, 0.7081175366390322, 0.7076472609477836, 0.7077077526242391, 0.7099493974824947, 0.7078707301250217, 0.7105392137681481, 0.7078744089870657, 0.712566533518372, 0.7133094279248288, 0.7102956860453873, 0.7106020876509594, 0.7093095791292249, 0.7148741093671834, 0.7115639159088989, 0.713118508205127, 0.7129605586514755, 0.713905506248599, 0.7128137898511606, 0.7105671323909438, 0.7149465018921588, 0.7152372083598059, 0.7098053242900028, 0.7130075086996699, 0.7131157943946039, 0.7113472238958589, 0.7123922418640504, 0.7146390170923892, 0.7140539819776728, 0.7128049200048273, 0.7122431330894633, 0.7121713310827387, 0.7121591375969766, 0.7133258569445293, 0.7128326641611697, 0.7135720095346988, 0.7145290157596778, 0.713123125590623, 0.711807852089835, 0.7150453448480804, 0.714005118270466, 0.714030931658994, 0.7139535347334011, 0.7139157147627667, 0.7139073777226573], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.70s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.52s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.34s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.20s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_b/sd2/vimp*': No such file or directory

  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:00<00:01,  2.52it/s] 40%|████      | 2/5 [00:00<00:01,  2.62it/s] 60%|██████    | 3/5 [00:01<00:00,  2.81it/s] 80%|████████  | 4/5 [00:01<00:00,  3.04it/s]100%|██████████| 5/5 [00:01<00:00,  2.97it/s]100%|██████████| 5/5 [00:01<00:00,  3.01it/s]

CrossVal ['b']
Error in label values min 0.0 max 2.0      1-THALAMUS
2020-01-21 23:04:30.342452: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-21 23:04:34.094309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-21 23:04:34.094362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 23:04:34.531638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 23:04:34.531719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 23:04:34.531737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 23:04:34.532609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<04:19,  1.05s/it]Loading train:   1%|          | 2/247 [00:01<04:07,  1.01s/it]Loading train:   1%|          | 3/247 [00:02<03:36,  1.13it/s]Loading train:   2%|▏         | 4/247 [00:03<03:19,  1.22it/s]Loading train:   2%|▏         | 5/247 [00:03<03:00,  1.34it/s]Loading train:   2%|▏         | 6/247 [00:04<02:54,  1.38it/s]Loading train:   3%|▎         | 7/247 [00:05<02:46,  1.45it/s]Loading train:   3%|▎         | 8/247 [00:05<02:34,  1.55it/s]Loading train:   4%|▎         | 9/247 [00:06<02:22,  1.67it/s]Loading train:   4%|▍         | 10/247 [00:06<02:21,  1.67it/s]Loading train:   4%|▍         | 11/247 [00:07<02:21,  1.67it/s]Loading train:   5%|▍         | 12/247 [00:07<02:21,  1.67it/s]Loading train:   5%|▌         | 13/247 [00:08<02:21,  1.65it/s]Loading train:   6%|▌         | 14/247 [00:09<02:23,  1.62it/s]Loading train:   6%|▌         | 15/247 [00:09<02:18,  1.68it/s]Loading train:   6%|▋         | 16/247 [00:10<02:18,  1.67it/s]Loading train:   7%|▋         | 17/247 [00:10<02:13,  1.72it/s]Loading train:   7%|▋         | 18/247 [00:11<02:16,  1.68it/s]Loading train:   8%|▊         | 19/247 [00:12<02:13,  1.71it/s]Loading train:   8%|▊         | 20/247 [00:12<02:10,  1.74it/s]Loading train:   9%|▊         | 21/247 [00:13<02:09,  1.75it/s]Loading train:   9%|▉         | 22/247 [00:13<02:10,  1.72it/s]Loading train:   9%|▉         | 23/247 [00:14<02:08,  1.74it/s]Loading train:  10%|▉         | 24/247 [00:14<02:07,  1.75it/s]Loading train:  10%|█         | 25/247 [00:15<02:08,  1.73it/s]Loading train:  11%|█         | 26/247 [00:16<02:02,  1.80it/s]Loading train:  11%|█         | 27/247 [00:16<01:59,  1.84it/s]Loading train:  11%|█▏        | 28/247 [00:17<02:02,  1.79it/s]Loading train:  12%|█▏        | 29/247 [00:17<01:59,  1.83it/s]Loading train:  12%|█▏        | 30/247 [00:18<01:59,  1.82it/s]Loading train:  13%|█▎        | 31/247 [00:18<02:02,  1.76it/s]Loading train:  13%|█▎        | 32/247 [00:19<02:07,  1.69it/s]Loading train:  13%|█▎        | 33/247 [00:20<02:07,  1.67it/s]Loading train:  14%|█▍        | 34/247 [00:20<02:04,  1.71it/s]Loading train:  14%|█▍        | 35/247 [00:21<02:03,  1.71it/s]Loading train:  15%|█▍        | 36/247 [00:21<01:57,  1.79it/s]Loading train:  15%|█▍        | 37/247 [00:22<02:00,  1.75it/s]Loading train:  15%|█▌        | 38/247 [00:22<01:58,  1.76it/s]Loading train:  16%|█▌        | 39/247 [00:23<01:57,  1.77it/s]Loading train:  16%|█▌        | 40/247 [00:23<01:56,  1.77it/s]Loading train:  17%|█▋        | 41/247 [00:24<01:54,  1.81it/s]Loading train:  17%|█▋        | 42/247 [00:25<01:55,  1.78it/s]Loading train:  17%|█▋        | 43/247 [00:25<01:53,  1.79it/s]Loading train:  18%|█▊        | 44/247 [00:26<01:53,  1.79it/s]Loading train:  18%|█▊        | 45/247 [00:26<01:46,  1.89it/s]Loading train:  19%|█▊        | 46/247 [00:27<01:35,  2.10it/s]Loading train:  19%|█▉        | 47/247 [00:27<01:42,  1.95it/s]Loading train:  19%|█▉        | 48/247 [00:27<01:34,  2.12it/s]Loading train:  20%|█▉        | 49/247 [00:28<01:36,  2.05it/s]Loading train:  20%|██        | 50/247 [00:28<01:31,  2.15it/s]Loading train:  21%|██        | 51/247 [00:29<01:26,  2.26it/s]Loading train:  21%|██        | 52/247 [00:29<01:22,  2.38it/s]Loading train:  21%|██▏       | 53/247 [00:30<01:20,  2.42it/s]Loading train:  22%|██▏       | 54/247 [00:30<01:24,  2.28it/s]Loading train:  22%|██▏       | 55/247 [00:31<01:25,  2.25it/s]Loading train:  23%|██▎       | 56/247 [00:31<01:21,  2.34it/s]Loading train:  23%|██▎       | 57/247 [00:31<01:22,  2.29it/s]Loading train:  23%|██▎       | 58/247 [00:32<01:19,  2.37it/s]Loading train:  24%|██▍       | 59/247 [00:32<01:10,  2.68it/s]Loading train:  24%|██▍       | 60/247 [00:33<01:18,  2.40it/s]Loading train:  25%|██▍       | 61/247 [00:33<01:16,  2.44it/s]Loading train:  25%|██▌       | 62/247 [00:33<01:18,  2.35it/s]Loading train:  26%|██▌       | 63/247 [00:34<01:16,  2.39it/s]Loading train:  26%|██▌       | 64/247 [00:34<01:13,  2.48it/s]Loading train:  26%|██▋       | 65/247 [00:35<01:12,  2.50it/s]Loading train:  27%|██▋       | 66/247 [00:35<01:14,  2.43it/s]Loading train:  27%|██▋       | 67/247 [00:35<01:15,  2.40it/s]Loading train:  28%|██▊       | 68/247 [00:36<01:15,  2.38it/s]Loading train:  28%|██▊       | 69/247 [00:36<01:16,  2.34it/s]Loading train:  28%|██▊       | 70/247 [00:37<01:16,  2.32it/s]Loading train:  29%|██▊       | 71/247 [00:37<01:13,  2.40it/s]Loading train:  29%|██▉       | 72/247 [00:37<01:02,  2.78it/s]Loading train:  30%|██▉       | 73/247 [00:38<00:55,  3.14it/s]Loading train:  30%|██▉       | 74/247 [00:38<00:56,  3.06it/s]Loading train:  30%|███       | 75/247 [00:38<01:01,  2.82it/s]Loading train:  31%|███       | 76/247 [00:39<01:07,  2.54it/s]Loading train:  31%|███       | 77/247 [00:40<01:24,  2.01it/s]Loading train:  32%|███▏      | 78/247 [00:40<01:33,  1.80it/s]Loading train:  32%|███▏      | 79/247 [00:41<01:35,  1.76it/s]Loading train:  32%|███▏      | 80/247 [00:42<01:39,  1.68it/s]Loading train:  33%|███▎      | 81/247 [00:42<01:34,  1.76it/s]Loading train:  33%|███▎      | 82/247 [00:43<01:45,  1.57it/s]Loading train:  34%|███▎      | 83/247 [00:44<01:46,  1.53it/s]Loading train:  34%|███▍      | 84/247 [00:44<01:41,  1.61it/s]Loading train:  34%|███▍      | 85/247 [00:45<01:54,  1.42it/s]Loading train:  35%|███▍      | 86/247 [00:46<01:51,  1.44it/s]Loading train:  35%|███▌      | 87/247 [00:46<01:58,  1.35it/s]Loading train:  36%|███▌      | 88/247 [00:47<01:51,  1.43it/s]Loading train:  36%|███▌      | 89/247 [00:48<01:54,  1.38it/s]Loading train:  36%|███▋      | 90/247 [00:49<01:49,  1.43it/s]Loading train:  37%|███▋      | 91/247 [00:49<02:00,  1.30it/s]Loading train:  37%|███▋      | 92/247 [00:51<02:17,  1.13it/s]Loading train:  38%|███▊      | 93/247 [00:51<02:08,  1.20it/s]Loading train:  38%|███▊      | 94/247 [00:52<02:11,  1.17it/s]Loading train:  38%|███▊      | 95/247 [00:53<02:01,  1.25it/s]Loading train:  39%|███▉      | 96/247 [00:54<01:59,  1.26it/s]Loading train:  39%|███▉      | 97/247 [00:54<01:54,  1.31it/s]Loading train:  40%|███▉      | 98/247 [00:55<01:54,  1.30it/s]Loading train:  40%|████      | 99/247 [00:56<02:01,  1.22it/s]Loading train:  40%|████      | 100/247 [00:57<01:56,  1.26it/s]Loading train:  41%|████      | 101/247 [00:57<01:48,  1.35it/s]Loading train:  41%|████▏     | 102/247 [00:58<01:46,  1.36it/s]Loading train:  42%|████▏     | 103/247 [00:59<01:39,  1.45it/s]Loading train:  42%|████▏     | 104/247 [00:59<01:33,  1.53it/s]Loading train:  43%|████▎     | 105/247 [01:00<01:32,  1.53it/s]Loading train:  43%|████▎     | 106/247 [01:01<01:28,  1.60it/s]Loading train:  43%|████▎     | 107/247 [01:01<01:36,  1.45it/s]Loading train:  44%|████▎     | 108/247 [01:02<01:33,  1.49it/s]Loading train:  44%|████▍     | 109/247 [01:03<01:28,  1.56it/s]Loading train:  45%|████▍     | 110/247 [01:03<01:25,  1.61it/s]Loading train:  45%|████▍     | 111/247 [01:04<01:26,  1.58it/s]Loading train:  45%|████▌     | 112/247 [01:05<01:30,  1.49it/s]Loading train:  46%|████▌     | 113/247 [01:05<01:33,  1.43it/s]Loading train:  46%|████▌     | 114/247 [01:06<01:33,  1.42it/s]Loading train:  47%|████▋     | 115/247 [01:07<01:30,  1.46it/s]Loading train:  47%|████▋     | 116/247 [01:07<01:29,  1.46it/s]Loading train:  47%|████▋     | 117/247 [01:08<01:29,  1.46it/s]Loading train:  48%|████▊     | 118/247 [01:09<01:22,  1.57it/s]Loading train:  48%|████▊     | 119/247 [01:09<01:17,  1.65it/s]Loading train:  49%|████▊     | 120/247 [01:10<01:13,  1.72it/s]Loading train:  49%|████▉     | 121/247 [01:10<01:12,  1.75it/s]Loading train:  49%|████▉     | 122/247 [01:11<01:11,  1.76it/s]Loading train:  50%|████▉     | 123/247 [01:11<01:09,  1.78it/s]Loading train:  50%|█████     | 124/247 [01:12<01:08,  1.79it/s]Loading train:  51%|█████     | 125/247 [01:12<01:08,  1.79it/s]Loading train:  51%|█████     | 126/247 [01:13<01:06,  1.82it/s]Loading train:  51%|█████▏    | 127/247 [01:13<01:05,  1.83it/s]Loading train:  52%|█████▏    | 128/247 [01:14<01:00,  1.97it/s]Loading train:  52%|█████▏    | 129/247 [01:14<00:57,  2.05it/s]Loading train:  53%|█████▎    | 130/247 [01:15<00:56,  2.08it/s]Loading train:  53%|█████▎    | 131/247 [01:15<00:54,  2.11it/s]Loading train:  53%|█████▎    | 132/247 [01:16<00:51,  2.22it/s]Loading train:  54%|█████▍    | 133/247 [01:16<00:50,  2.28it/s]Loading train:  54%|█████▍    | 134/247 [01:16<00:49,  2.28it/s]Loading train:  55%|█████▍    | 135/247 [01:17<00:48,  2.29it/s]Loading train:  55%|█████▌    | 136/247 [01:17<00:49,  2.24it/s]Loading train:  55%|█████▌    | 137/247 [01:18<00:48,  2.29it/s]Loading train:  56%|█████▌    | 138/247 [01:18<00:49,  2.21it/s]Loading train:  56%|█████▋    | 139/247 [01:19<00:47,  2.29it/s]Loading train:  57%|█████▋    | 140/247 [01:19<00:46,  2.28it/s]Loading train:  57%|█████▋    | 141/247 [01:20<00:47,  2.21it/s]Loading train:  57%|█████▋    | 142/247 [01:20<00:46,  2.24it/s]Loading train:  58%|█████▊    | 143/247 [01:21<00:47,  2.20it/s]Loading train:  58%|█████▊    | 144/247 [01:21<00:46,  2.22it/s]Loading train:  59%|█████▊    | 145/247 [01:21<00:47,  2.15it/s]Loading train:  59%|█████▉    | 146/247 [01:22<00:46,  2.17it/s]Loading train:  60%|█████▉    | 147/247 [01:22<00:46,  2.16it/s]Loading train:  60%|█████▉    | 148/247 [01:23<00:45,  2.18it/s]Loading train:  60%|██████    | 149/247 [01:23<00:44,  2.19it/s]Loading train:  61%|██████    | 150/247 [01:24<00:43,  2.21it/s]Loading train:  61%|██████    | 151/247 [01:24<00:43,  2.18it/s]Loading train:  62%|██████▏   | 152/247 [01:25<00:42,  2.23it/s]Loading train:  62%|██████▏   | 153/247 [01:25<00:42,  2.19it/s]Loading train:  62%|██████▏   | 154/247 [01:26<00:43,  2.13it/s]Loading train:  63%|██████▎   | 155/247 [01:26<00:44,  2.07it/s]Loading train:  63%|██████▎   | 156/247 [01:27<00:43,  2.07it/s]Loading train:  64%|██████▎   | 157/247 [01:27<00:43,  2.05it/s]Loading train:  64%|██████▍   | 158/247 [01:28<00:44,  2.01it/s]Loading train:  64%|██████▍   | 159/247 [01:28<00:43,  2.01it/s]Loading train:  65%|██████▍   | 160/247 [01:29<00:42,  2.06it/s]Loading train:  65%|██████▌   | 161/247 [01:29<00:42,  2.04it/s]Loading train:  66%|██████▌   | 162/247 [01:30<00:42,  1.99it/s]Loading train:  66%|██████▌   | 163/247 [01:30<00:42,  1.96it/s]Loading train:  66%|██████▋   | 164/247 [01:31<00:41,  2.00it/s]Loading train:  67%|██████▋   | 165/247 [01:31<00:41,  2.00it/s]Loading train:  67%|██████▋   | 166/247 [01:32<00:40,  2.01it/s]Loading train:  68%|██████▊   | 167/247 [01:32<00:41,  1.95it/s]Loading train:  68%|██████▊   | 168/247 [01:33<00:40,  1.94it/s]Loading train:  68%|██████▊   | 169/247 [01:33<00:39,  1.96it/s]Loading train:  69%|██████▉   | 170/247 [01:34<00:39,  1.93it/s]Loading train:  69%|██████▉   | 171/247 [01:34<00:39,  1.91it/s]Loading train:  70%|██████▉   | 172/247 [01:35<00:38,  1.96it/s]Loading train:  70%|███████   | 173/247 [01:35<00:36,  2.00it/s]Loading train:  70%|███████   | 174/247 [01:36<00:35,  2.03it/s]Loading train:  71%|███████   | 175/247 [01:36<00:36,  1.96it/s]Loading train:  71%|███████▏  | 176/247 [01:37<00:34,  2.04it/s]Loading train:  72%|███████▏  | 177/247 [01:37<00:33,  2.10it/s]Loading train:  72%|███████▏  | 178/247 [01:38<00:32,  2.13it/s]Loading train:  72%|███████▏  | 179/247 [01:38<00:31,  2.19it/s]Loading train:  73%|███████▎  | 180/247 [01:38<00:30,  2.17it/s]Loading train:  73%|███████▎  | 181/247 [01:39<00:30,  2.20it/s]Loading train:  74%|███████▎  | 182/247 [01:39<00:29,  2.20it/s]Loading train:  74%|███████▍  | 183/247 [01:40<00:29,  2.20it/s]Loading train:  74%|███████▍  | 184/247 [01:40<00:28,  2.18it/s]Loading train:  75%|███████▍  | 185/247 [01:41<00:28,  2.17it/s]Loading train:  75%|███████▌  | 186/247 [01:41<00:27,  2.22it/s]Loading train:  76%|███████▌  | 187/247 [01:42<00:26,  2.24it/s]Loading train:  76%|███████▌  | 188/247 [01:42<00:26,  2.24it/s]Loading train:  77%|███████▋  | 189/247 [01:42<00:25,  2.25it/s]Loading train:  77%|███████▋  | 190/247 [01:43<00:25,  2.23it/s]Loading train:  77%|███████▋  | 191/247 [01:43<00:25,  2.18it/s]Loading train:  78%|███████▊  | 192/247 [01:44<00:24,  2.24it/s]Loading train:  78%|███████▊  | 193/247 [01:44<00:24,  2.23it/s]Loading train:  79%|███████▊  | 194/247 [01:45<00:23,  2.24it/s]Loading train:  79%|███████▉  | 195/247 [01:45<00:22,  2.27it/s]Loading train:  79%|███████▉  | 196/247 [01:46<00:22,  2.22it/s]Loading train:  80%|███████▉  | 197/247 [01:46<00:23,  2.17it/s]Loading train:  80%|████████  | 198/247 [01:47<00:22,  2.22it/s]Loading train:  81%|████████  | 199/247 [01:47<00:21,  2.26it/s]Loading train:  81%|████████  | 200/247 [01:47<00:20,  2.26it/s]Loading train:  81%|████████▏ | 201/247 [01:48<00:20,  2.22it/s]Loading train:  82%|████████▏ | 202/247 [01:48<00:20,  2.21it/s]Loading train:  82%|████████▏ | 203/247 [01:49<00:19,  2.20it/s]Loading train:  83%|████████▎ | 204/247 [01:49<00:19,  2.26it/s]Loading train:  83%|████████▎ | 205/247 [01:50<00:18,  2.30it/s]Loading train:  83%|████████▎ | 206/247 [01:50<00:18,  2.28it/s]Loading train:  84%|████████▍ | 207/247 [01:51<00:17,  2.27it/s]Loading train:  84%|████████▍ | 208/247 [01:51<00:16,  2.30it/s]Loading train:  85%|████████▍ | 209/247 [01:51<00:16,  2.34it/s]Loading train:  85%|████████▌ | 210/247 [01:52<00:16,  2.28it/s]Loading train:  85%|████████▌ | 211/247 [01:52<00:16,  2.24it/s]Loading train:  86%|████████▌ | 212/247 [01:53<00:15,  2.20it/s]Loading train:  86%|████████▌ | 213/247 [01:53<00:14,  2.28it/s]Loading train:  87%|████████▋ | 214/247 [01:54<00:15,  2.20it/s]Loading train:  87%|████████▋ | 215/247 [01:54<00:14,  2.15it/s]Loading train:  87%|████████▋ | 216/247 [01:55<00:14,  2.15it/s]Loading train:  88%|████████▊ | 217/247 [01:55<00:13,  2.21it/s]Loading train:  88%|████████▊ | 218/247 [01:56<00:13,  2.13it/s]Loading train:  89%|████████▊ | 219/247 [01:56<00:12,  2.16it/s]Loading train:  89%|████████▉ | 220/247 [01:56<00:12,  2.17it/s]Loading train:  89%|████████▉ | 221/247 [01:57<00:11,  2.18it/s]Loading train:  90%|████████▉ | 222/247 [01:57<00:11,  2.13it/s]Loading train:  90%|█████████ | 223/247 [01:58<00:11,  2.10it/s]Loading train:  91%|█████████ | 224/247 [01:58<00:11,  2.09it/s]Loading train:  91%|█████████ | 225/247 [01:59<00:10,  2.04it/s]Loading train:  91%|█████████▏| 226/247 [01:59<00:10,  2.05it/s]Loading train:  92%|█████████▏| 227/247 [02:00<00:09,  2.06it/s]Loading train:  92%|█████████▏| 228/247 [02:00<00:09,  2.03it/s]Loading train:  93%|█████████▎| 229/247 [02:01<00:08,  2.01it/s]Loading train:  93%|█████████▎| 230/247 [02:01<00:08,  1.94it/s]Loading train:  94%|█████████▎| 231/247 [02:02<00:08,  1.94it/s]Loading train:  94%|█████████▍| 232/247 [02:02<00:07,  1.96it/s]Loading train:  94%|█████████▍| 233/247 [02:03<00:07,  1.95it/s]Loading train:  95%|█████████▍| 234/247 [02:04<00:06,  1.90it/s]Loading train:  95%|█████████▌| 235/247 [02:04<00:06,  1.95it/s]Loading train:  96%|█████████▌| 236/247 [02:05<00:05,  1.94it/s]Loading train:  96%|█████████▌| 237/247 [02:05<00:05,  1.93it/s]Loading train:  96%|█████████▋| 238/247 [02:06<00:04,  1.99it/s]Loading train:  97%|█████████▋| 239/247 [02:06<00:04,  1.98it/s]Loading train:  97%|█████████▋| 240/247 [02:07<00:03,  1.95it/s]Loading train:  98%|█████████▊| 241/247 [02:07<00:03,  1.98it/s]Loading train:  98%|█████████▊| 242/247 [02:08<00:02,  1.90it/s]Loading train:  98%|█████████▊| 243/247 [02:08<00:02,  1.88it/s]Loading train:  99%|█████████▉| 244/247 [02:09<00:01,  1.90it/s]Loading train:  99%|█████████▉| 245/247 [02:09<00:01,  1.92it/s]Loading train: 100%|█████████▉| 246/247 [02:10<00:00,  1.92it/s]Loading train: 100%|██████████| 247/247 [02:10<00:00,  1.88it/s]Loading train: 100%|██████████| 247/247 [02:10<00:00,  1.89it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 47.95it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:04, 47.96it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:04, 47.85it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:04, 47.86it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 47.75it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 47.75it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 47.93it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 47.96it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:04, 47.94it/s]concatenating: train:  20%|██        | 50/247 [00:01<00:04, 48.02it/s]concatenating: train:  22%|██▏       | 55/247 [00:01<00:04, 47.62it/s]concatenating: train:  25%|██▍       | 61/247 [00:01<00:03, 48.74it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 48.70it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:03, 48.58it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:03, 49.27it/s]concatenating: train:  33%|███▎      | 82/247 [00:01<00:03, 48.27it/s]concatenating: train:  35%|███▌      | 87/247 [00:01<00:03, 46.94it/s]concatenating: train:  37%|███▋      | 92/247 [00:01<00:03, 45.58it/s]concatenating: train:  39%|███▉      | 97/247 [00:02<00:03, 44.61it/s]concatenating: train:  41%|████▏     | 102/247 [00:02<00:03, 44.21it/s]concatenating: train:  43%|████▎     | 107/247 [00:02<00:03, 43.78it/s]concatenating: train:  45%|████▌     | 112/247 [00:02<00:03, 43.90it/s]concatenating: train:  47%|████▋     | 117/247 [00:02<00:02, 44.02it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 46.19it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 47.95it/s]concatenating: train:  55%|█████▍    | 135/247 [00:02<00:02, 49.28it/s]concatenating: train:  57%|█████▋    | 140/247 [00:02<00:02, 49.26it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:02, 49.25it/s]concatenating: train:  61%|██████    | 150/247 [00:03<00:01, 49.14it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 48.60it/s]concatenating: train:  65%|██████▍   | 160/247 [00:03<00:01, 47.14it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 46.38it/s]concatenating: train:  69%|██████▉   | 170/247 [00:03<00:01, 46.04it/s]concatenating: train:  71%|███████   | 175/247 [00:03<00:01, 45.46it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 46.36it/s]concatenating: train:  75%|███████▍  | 185/247 [00:03<00:01, 47.39it/s]concatenating: train:  77%|███████▋  | 190/247 [00:04<00:01, 48.11it/s]concatenating: train:  79%|███████▉  | 196/247 [00:04<00:01, 47.97it/s]concatenating: train:  81%|████████▏ | 201/247 [00:04<00:00, 47.94it/s]concatenating: train:  84%|████████▍ | 207/247 [00:04<00:00, 48.80it/s]concatenating: train:  86%|████████▌ | 212/247 [00:04<00:00, 48.80it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 48.68it/s]concatenating: train:  90%|████████▉ | 222/247 [00:04<00:00, 48.68it/s]concatenating: train:  92%|█████████▏| 227/247 [00:04<00:00, 48.63it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 48.01it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 47.38it/s]concatenating: train:  98%|█████████▊| 242/247 [00:05<00:00, 46.85it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 46.49it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 47.43it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  2.14it/s]Loading test:  40%|████      | 2/5 [00:01<00:01,  1.81it/s]Loading test:  60%|██████    | 3/5 [00:01<00:01,  1.92it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  2.23it/s]Loading test: 100%|██████████| 5/5 [00:02<00:00,  2.23it/s]Loading test: 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 66.72it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<01:56,  2.11it/s]Loading trainS:   1%|          | 2/247 [00:00<01:56,  2.10it/s]Loading trainS:   1%|          | 3/247 [00:01<01:55,  2.12it/s]Loading trainS:   2%|▏         | 4/247 [00:01<01:56,  2.08it/s]Loading trainS:   2%|▏         | 5/247 [00:02<01:54,  2.12it/s]Loading trainS:   2%|▏         | 6/247 [00:02<01:53,  2.12it/s]Loading trainS:   3%|▎         | 7/247 [00:03<01:50,  2.17it/s]Loading trainS:   3%|▎         | 8/247 [00:03<01:49,  2.19it/s]Loading trainS:   4%|▎         | 9/247 [00:04<01:49,  2.18it/s]Loading trainS:   4%|▍         | 10/247 [00:04<01:50,  2.14it/s]Loading trainS:   4%|▍         | 11/247 [00:05<01:51,  2.11it/s]Loading trainS:   5%|▍         | 12/247 [00:05<01:50,  2.12it/s]Loading trainS:   5%|▌         | 13/247 [00:06<01:49,  2.14it/s]Loading trainS:   6%|▌         | 14/247 [00:06<01:46,  2.19it/s]Loading trainS:   6%|▌         | 15/247 [00:06<01:46,  2.18it/s]Loading trainS:   6%|▋         | 16/247 [00:07<01:45,  2.19it/s]Loading trainS:   7%|▋         | 17/247 [00:07<01:43,  2.22it/s]Loading trainS:   7%|▋         | 18/247 [00:08<01:45,  2.18it/s]Loading trainS:   8%|▊         | 19/247 [00:08<01:46,  2.14it/s]Loading trainS:   8%|▊         | 20/247 [00:09<01:43,  2.20it/s]Loading trainS:   9%|▊         | 21/247 [00:09<01:45,  2.14it/s]Loading trainS:   9%|▉         | 22/247 [00:10<01:41,  2.22it/s]Loading trainS:   9%|▉         | 23/247 [00:10<01:41,  2.20it/s]Loading trainS:  10%|▉         | 24/247 [00:11<01:43,  2.16it/s]Loading trainS:  10%|█         | 25/247 [00:11<01:43,  2.14it/s]Loading trainS:  11%|█         | 26/247 [00:12<01:44,  2.12it/s]Loading trainS:  11%|█         | 27/247 [00:12<01:43,  2.13it/s]Loading trainS:  11%|█▏        | 28/247 [00:13<01:45,  2.08it/s]Loading trainS:  12%|█▏        | 29/247 [00:13<01:41,  2.16it/s]Loading trainS:  12%|█▏        | 30/247 [00:13<01:40,  2.16it/s]Loading trainS:  13%|█▎        | 31/247 [00:14<01:43,  2.10it/s]Loading trainS:  13%|█▎        | 32/247 [00:14<01:40,  2.13it/s]Loading trainS:  13%|█▎        | 33/247 [00:15<01:39,  2.15it/s]Loading trainS:  14%|█▍        | 34/247 [00:15<01:38,  2.16it/s]Loading trainS:  14%|█▍        | 35/247 [00:16<01:35,  2.21it/s]Loading trainS:  15%|█▍        | 36/247 [00:16<01:38,  2.14it/s]Loading trainS:  15%|█▍        | 37/247 [00:17<01:37,  2.16it/s]Loading trainS:  15%|█▌        | 38/247 [00:17<01:36,  2.16it/s]Loading trainS:  16%|█▌        | 39/247 [00:18<01:35,  2.17it/s]Loading trainS:  16%|█▌        | 40/247 [00:18<01:37,  2.13it/s]Loading trainS:  17%|█▋        | 41/247 [00:19<01:34,  2.18it/s]Loading trainS:  17%|█▋        | 42/247 [00:19<01:36,  2.12it/s]Loading trainS:  17%|█▋        | 43/247 [00:20<01:36,  2.11it/s]Loading trainS:  18%|█▊        | 44/247 [00:20<01:34,  2.14it/s]Loading trainS:  18%|█▊        | 45/247 [00:20<01:32,  2.19it/s]Loading trainS:  19%|█▊        | 46/247 [00:21<01:31,  2.19it/s]Loading trainS:  19%|█▉        | 47/247 [00:21<01:30,  2.21it/s]Loading trainS:  19%|█▉        | 48/247 [00:22<01:28,  2.25it/s]Loading trainS:  20%|█▉        | 49/247 [00:22<01:28,  2.24it/s]Loading trainS:  20%|██        | 50/247 [00:23<01:27,  2.26it/s]Loading trainS:  21%|██        | 51/247 [00:23<01:27,  2.25it/s]Loading trainS:  21%|██        | 52/247 [00:23<01:26,  2.24it/s]Loading trainS:  21%|██▏       | 53/247 [00:24<01:29,  2.18it/s]Loading trainS:  22%|██▏       | 54/247 [00:24<01:30,  2.13it/s]Loading trainS:  22%|██▏       | 55/247 [00:25<01:28,  2.16it/s]Loading trainS:  23%|██▎       | 56/247 [00:25<01:28,  2.15it/s]Loading trainS:  23%|██▎       | 57/247 [00:26<01:28,  2.15it/s]Loading trainS:  23%|██▎       | 58/247 [00:26<01:25,  2.21it/s]Loading trainS:  24%|██▍       | 59/247 [00:27<01:27,  2.14it/s]Loading trainS:  24%|██▍       | 60/247 [00:27<01:29,  2.10it/s]Loading trainS:  25%|██▍       | 61/247 [00:28<01:26,  2.14it/s]Loading trainS:  25%|██▌       | 62/247 [00:28<01:25,  2.16it/s]Loading trainS:  26%|██▌       | 63/247 [00:29<01:22,  2.22it/s]Loading trainS:  26%|██▌       | 64/247 [00:29<01:23,  2.20it/s]Loading trainS:  26%|██▋       | 65/247 [00:29<01:19,  2.29it/s]Loading trainS:  27%|██▋       | 66/247 [00:30<01:19,  2.27it/s]Loading trainS:  27%|██▋       | 67/247 [00:30<01:19,  2.27it/s]Loading trainS:  28%|██▊       | 68/247 [00:31<01:16,  2.35it/s]Loading trainS:  28%|██▊       | 69/247 [00:31<01:16,  2.33it/s]Loading trainS:  28%|██▊       | 70/247 [00:32<01:19,  2.24it/s]Loading trainS:  29%|██▊       | 71/247 [00:32<01:21,  2.16it/s]Loading trainS:  29%|██▉       | 72/247 [00:33<01:20,  2.19it/s]Loading trainS:  30%|██▉       | 73/247 [00:33<01:20,  2.17it/s]Loading trainS:  30%|██▉       | 74/247 [00:34<01:20,  2.14it/s]Loading trainS:  30%|███       | 75/247 [00:34<01:18,  2.19it/s]Loading trainS:  31%|███       | 76/247 [00:34<01:18,  2.17it/s]Loading trainS:  31%|███       | 77/247 [00:35<01:24,  2.02it/s]Loading trainS:  32%|███▏      | 78/247 [00:36<01:25,  1.97it/s]Loading trainS:  32%|███▏      | 79/247 [00:36<01:22,  2.04it/s]Loading trainS:  32%|███▏      | 80/247 [00:36<01:17,  2.14it/s]Loading trainS:  33%|███▎      | 81/247 [00:37<01:17,  2.15it/s]Loading trainS:  33%|███▎      | 82/247 [00:37<01:18,  2.09it/s]Loading trainS:  34%|███▎      | 83/247 [00:38<01:22,  1.98it/s]Loading trainS:  34%|███▍      | 84/247 [00:39<01:24,  1.93it/s]Loading trainS:  34%|███▍      | 85/247 [00:39<01:25,  1.90it/s]Loading trainS:  35%|███▍      | 86/247 [00:40<01:24,  1.91it/s]Loading trainS:  35%|███▌      | 87/247 [00:40<01:24,  1.88it/s]Loading trainS:  36%|███▌      | 88/247 [00:41<01:23,  1.90it/s]Loading trainS:  36%|███▌      | 89/247 [00:41<01:22,  1.92it/s]Loading trainS:  36%|███▋      | 90/247 [00:42<01:20,  1.95it/s]Loading trainS:  37%|███▋      | 91/247 [00:42<01:20,  1.94it/s]Loading trainS:  37%|███▋      | 92/247 [00:43<01:18,  1.99it/s]Loading trainS:  38%|███▊      | 93/247 [00:43<01:17,  1.97it/s]Loading trainS:  38%|███▊      | 94/247 [00:44<01:17,  1.98it/s]Loading trainS:  38%|███▊      | 95/247 [00:44<01:16,  1.99it/s]Loading trainS:  39%|███▉      | 96/247 [00:45<01:16,  1.97it/s]Loading trainS:  39%|███▉      | 97/247 [00:45<01:16,  1.95it/s]Loading trainS:  40%|███▉      | 98/247 [00:46<01:15,  1.97it/s]Loading trainS:  40%|████      | 99/247 [00:46<01:15,  1.95it/s]Loading trainS:  40%|████      | 100/247 [00:47<01:15,  1.95it/s]Loading trainS:  41%|████      | 101/247 [00:47<01:13,  1.98it/s]Loading trainS:  41%|████▏     | 102/247 [00:48<01:13,  1.97it/s]Loading trainS:  42%|████▏     | 103/247 [00:48<01:12,  2.00it/s]Loading trainS:  42%|████▏     | 104/247 [00:49<01:12,  1.98it/s]Loading trainS:  43%|████▎     | 105/247 [00:49<01:10,  2.02it/s]Loading trainS:  43%|████▎     | 106/247 [00:50<01:08,  2.05it/s]Loading trainS:  43%|████▎     | 107/247 [00:50<01:09,  2.02it/s]Loading trainS:  44%|████▎     | 108/247 [00:51<01:11,  1.95it/s]Loading trainS:  44%|████▍     | 109/247 [00:51<01:11,  1.93it/s]Loading trainS:  45%|████▍     | 110/247 [00:52<01:10,  1.95it/s]Loading trainS:  45%|████▍     | 111/247 [00:52<01:10,  1.93it/s]Loading trainS:  45%|████▌     | 112/247 [00:53<01:08,  1.97it/s]Loading trainS:  46%|████▌     | 113/247 [00:53<01:15,  1.78it/s]Loading trainS:  46%|████▌     | 114/247 [00:54<01:11,  1.85it/s]Loading trainS:  47%|████▋     | 115/247 [00:54<01:08,  1.91it/s]Loading trainS:  47%|████▋     | 116/247 [00:55<01:09,  1.89it/s]Loading trainS:  47%|████▋     | 117/247 [00:56<01:08,  1.89it/s]Loading trainS:  48%|████▊     | 118/247 [00:56<01:02,  2.05it/s]Loading trainS:  48%|████▊     | 119/247 [00:56<01:00,  2.11it/s]Loading trainS:  49%|████▊     | 120/247 [00:57<00:57,  2.23it/s]Loading trainS:  49%|████▉     | 121/247 [00:57<00:54,  2.33it/s]Loading trainS:  49%|████▉     | 122/247 [00:58<00:52,  2.40it/s]Loading trainS:  50%|████▉     | 123/247 [00:58<00:52,  2.36it/s]Loading trainS:  50%|█████     | 124/247 [00:58<00:52,  2.35it/s]Loading trainS:  51%|█████     | 125/247 [00:59<00:49,  2.44it/s]Loading trainS:  51%|█████     | 126/247 [00:59<00:47,  2.55it/s]Loading trainS:  51%|█████▏    | 127/247 [01:00<00:47,  2.52it/s]Loading trainS:  52%|█████▏    | 128/247 [01:00<00:48,  2.46it/s]Loading trainS:  52%|█████▏    | 129/247 [01:00<00:47,  2.47it/s]Loading trainS:  53%|█████▎    | 130/247 [01:01<00:46,  2.53it/s]Loading trainS:  53%|█████▎    | 131/247 [01:01<00:46,  2.51it/s]Loading trainS:  53%|█████▎    | 132/247 [01:02<00:47,  2.44it/s]Loading trainS:  54%|█████▍    | 133/247 [01:02<00:46,  2.45it/s]Loading trainS:  54%|█████▍    | 134/247 [01:02<00:47,  2.39it/s]Loading trainS:  55%|█████▍    | 135/247 [01:03<00:46,  2.39it/s]Loading trainS:  55%|█████▌    | 136/247 [01:03<00:48,  2.29it/s]Loading trainS:  55%|█████▌    | 137/247 [01:04<00:54,  2.01it/s]Loading trainS:  56%|█████▌    | 138/247 [01:04<00:52,  2.07it/s]Loading trainS:  56%|█████▋    | 139/247 [01:05<00:49,  2.17it/s]Loading trainS:  57%|█████▋    | 140/247 [01:05<00:48,  2.21it/s]Loading trainS:  57%|█████▋    | 141/247 [01:06<00:48,  2.21it/s]Loading trainS:  57%|█████▋    | 142/247 [01:06<00:48,  2.18it/s]Loading trainS:  58%|█████▊    | 143/247 [01:07<00:48,  2.14it/s]Loading trainS:  58%|█████▊    | 144/247 [01:07<00:47,  2.15it/s]Loading trainS:  59%|█████▊    | 145/247 [01:08<00:47,  2.15it/s]Loading trainS:  59%|█████▉    | 146/247 [01:08<00:45,  2.24it/s]Loading trainS:  60%|█████▉    | 147/247 [01:08<00:44,  2.26it/s]Loading trainS:  60%|█████▉    | 148/247 [01:09<00:43,  2.27it/s]Loading trainS:  60%|██████    | 149/247 [01:09<00:44,  2.20it/s]Loading trainS:  61%|██████    | 150/247 [01:10<00:44,  2.20it/s]Loading trainS:  61%|██████    | 151/247 [01:10<00:43,  2.19it/s]Loading trainS:  62%|██████▏   | 152/247 [01:11<00:43,  2.18it/s]Loading trainS:  62%|██████▏   | 153/247 [01:11<00:44,  2.10it/s]Loading trainS:  62%|██████▏   | 154/247 [01:12<00:44,  2.07it/s]Loading trainS:  63%|██████▎   | 155/247 [01:12<00:44,  2.04it/s]Loading trainS:  63%|██████▎   | 156/247 [01:13<00:43,  2.08it/s]Loading trainS:  64%|██████▎   | 157/247 [01:13<00:44,  2.01it/s]Loading trainS:  64%|██████▍   | 158/247 [01:14<00:42,  2.10it/s]Loading trainS:  64%|██████▍   | 159/247 [01:14<00:42,  2.09it/s]Loading trainS:  65%|██████▍   | 160/247 [01:15<00:41,  2.10it/s]Loading trainS:  65%|██████▌   | 161/247 [01:15<00:43,  2.00it/s]Loading trainS:  66%|██████▌   | 162/247 [01:16<00:41,  2.04it/s]Loading trainS:  66%|██████▌   | 163/247 [01:16<00:41,  2.02it/s]Loading trainS:  66%|██████▋   | 164/247 [01:17<00:40,  2.07it/s]Loading trainS:  67%|██████▋   | 165/247 [01:17<00:40,  2.02it/s]Loading trainS:  67%|██████▋   | 166/247 [01:18<00:39,  2.03it/s]Loading trainS:  68%|██████▊   | 167/247 [01:18<00:40,  2.00it/s]Loading trainS:  68%|██████▊   | 168/247 [01:19<00:40,  1.95it/s]Loading trainS:  68%|██████▊   | 169/247 [01:19<00:40,  1.92it/s]Loading trainS:  69%|██████▉   | 170/247 [01:20<00:39,  1.93it/s]Loading trainS:  69%|██████▉   | 171/247 [01:20<00:38,  1.98it/s]Loading trainS:  70%|██████▉   | 172/247 [01:21<00:37,  2.03it/s]Loading trainS:  70%|███████   | 173/247 [01:21<00:37,  1.97it/s]Loading trainS:  70%|███████   | 174/247 [01:22<00:39,  1.84it/s]Loading trainS:  71%|███████   | 175/247 [01:22<00:39,  1.80it/s]Loading trainS:  71%|███████▏  | 176/247 [01:23<00:37,  1.89it/s]Loading trainS:  72%|███████▏  | 177/247 [01:23<00:35,  1.97it/s]Loading trainS:  72%|███████▏  | 178/247 [01:24<00:33,  2.04it/s]Loading trainS:  72%|███████▏  | 179/247 [01:24<00:32,  2.09it/s]Loading trainS:  73%|███████▎  | 180/247 [01:25<00:30,  2.19it/s]Loading trainS:  73%|███████▎  | 181/247 [01:25<00:32,  2.03it/s]Loading trainS:  74%|███████▎  | 182/247 [01:26<00:31,  2.05it/s]Loading trainS:  74%|███████▍  | 183/247 [01:26<00:29,  2.17it/s]Loading trainS:  74%|███████▍  | 184/247 [01:27<00:28,  2.23it/s]Loading trainS:  75%|███████▍  | 185/247 [01:27<00:28,  2.21it/s]Loading trainS:  75%|███████▌  | 186/247 [01:27<00:27,  2.24it/s]Loading trainS:  76%|███████▌  | 187/247 [01:28<00:26,  2.23it/s]Loading trainS:  76%|███████▌  | 188/247 [01:28<00:29,  2.00it/s]Loading trainS:  77%|███████▋  | 189/247 [01:29<00:27,  2.13it/s]Loading trainS:  77%|███████▋  | 190/247 [01:29<00:26,  2.13it/s]Loading trainS:  77%|███████▋  | 191/247 [01:30<00:25,  2.19it/s]Loading trainS:  78%|███████▊  | 192/247 [01:30<00:24,  2.23it/s]Loading trainS:  78%|███████▊  | 193/247 [01:31<00:24,  2.22it/s]Loading trainS:  79%|███████▊  | 194/247 [01:31<00:23,  2.26it/s]Loading trainS:  79%|███████▉  | 195/247 [01:32<00:23,  2.21it/s]Loading trainS:  79%|███████▉  | 196/247 [01:32<00:23,  2.20it/s]Loading trainS:  80%|███████▉  | 197/247 [01:32<00:22,  2.22it/s]Loading trainS:  80%|████████  | 198/247 [01:33<00:21,  2.32it/s]Loading trainS:  81%|████████  | 199/247 [01:33<00:20,  2.30it/s]Loading trainS:  81%|████████  | 200/247 [01:34<00:20,  2.26it/s]Loading trainS:  81%|████████▏ | 201/247 [01:34<00:20,  2.26it/s]Loading trainS:  82%|████████▏ | 202/247 [01:35<00:20,  2.25it/s]Loading trainS:  82%|████████▏ | 203/247 [01:35<00:19,  2.26it/s]Loading trainS:  83%|████████▎ | 204/247 [01:36<00:19,  2.26it/s]Loading trainS:  83%|████████▎ | 205/247 [01:36<00:19,  2.11it/s]Loading trainS:  83%|████████▎ | 206/247 [01:37<00:19,  2.10it/s]Loading trainS:  84%|████████▍ | 207/247 [01:37<00:18,  2.18it/s]Loading trainS:  84%|████████▍ | 208/247 [01:37<00:17,  2.23it/s]Loading trainS:  85%|████████▍ | 209/247 [01:38<00:16,  2.27it/s]Loading trainS:  85%|████████▌ | 210/247 [01:38<00:16,  2.22it/s]Loading trainS:  85%|████████▌ | 211/247 [01:39<00:16,  2.19it/s]Loading trainS:  86%|████████▌ | 212/247 [01:39<00:16,  2.18it/s]Loading trainS:  86%|████████▌ | 213/247 [01:40<00:16,  2.06it/s]Loading trainS:  87%|████████▋ | 214/247 [01:40<00:15,  2.08it/s]Loading trainS:  87%|████████▋ | 215/247 [01:41<00:15,  2.08it/s]Loading trainS:  87%|████████▋ | 216/247 [01:41<00:14,  2.08it/s]Loading trainS:  88%|████████▊ | 217/247 [01:42<00:13,  2.17it/s]Loading trainS:  88%|████████▊ | 218/247 [01:42<00:13,  2.18it/s]Loading trainS:  89%|████████▊ | 219/247 [01:43<00:12,  2.17it/s]Loading trainS:  89%|████████▉ | 220/247 [01:43<00:12,  2.20it/s]Loading trainS:  89%|████████▉ | 221/247 [01:43<00:12,  2.15it/s]Loading trainS:  90%|████████▉ | 222/247 [01:44<00:11,  2.09it/s]Loading trainS:  90%|█████████ | 223/247 [01:44<00:11,  2.06it/s]Loading trainS:  91%|█████████ | 224/247 [01:45<00:11,  2.08it/s]Loading trainS:  91%|█████████ | 225/247 [01:45<00:10,  2.10it/s]Loading trainS:  91%|█████████▏| 226/247 [01:46<00:09,  2.16it/s]Loading trainS:  92%|█████████▏| 227/247 [01:46<00:09,  2.11it/s]Loading trainS:  92%|█████████▏| 228/247 [01:47<00:08,  2.12it/s]Loading trainS:  93%|█████████▎| 229/247 [01:47<00:08,  2.09it/s]Loading trainS:  93%|█████████▎| 230/247 [01:48<00:08,  2.05it/s]Loading trainS:  94%|█████████▎| 231/247 [01:48<00:08,  1.98it/s]Loading trainS:  94%|█████████▍| 232/247 [01:49<00:07,  1.98it/s]Loading trainS:  94%|█████████▍| 233/247 [01:49<00:07,  1.98it/s]Loading trainS:  95%|█████████▍| 234/247 [01:50<00:06,  2.01it/s]Loading trainS:  95%|█████████▌| 235/247 [01:50<00:05,  2.04it/s]Loading trainS:  96%|█████████▌| 236/247 [01:51<00:05,  2.00it/s]Loading trainS:  96%|█████████▌| 237/247 [01:51<00:04,  2.03it/s]Loading trainS:  96%|█████████▋| 238/247 [01:52<00:04,  2.00it/s]Loading trainS:  97%|█████████▋| 239/247 [01:52<00:04,  1.96it/s]Loading trainS:  97%|█████████▋| 240/247 [01:53<00:03,  1.97it/s]Loading trainS:  98%|█████████▊| 241/247 [01:53<00:03,  1.94it/s]Loading trainS:  98%|█████████▊| 242/247 [01:54<00:02,  1.99it/s]Loading trainS:  98%|█████████▊| 243/247 [01:54<00:02,  2.00it/s]Loading trainS:  99%|█████████▉| 244/247 [01:55<00:01,  2.00it/s]Loading trainS:  99%|█████████▉| 245/247 [01:55<00:00,  2.02it/s]Loading trainS: 100%|█████████▉| 246/247 [01:56<00:00,  2.03it/s]Loading trainS: 100%|██████████| 247/247 [01:56<00:00,  1.93it/s]Loading trainS: 100%|██████████| 247/247 [01:56<00:00,  2.11it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:01,  2.35it/s]Loading testS:  40%|████      | 2/5 [00:01<00:01,  2.06it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:00,  2.03it/s]Loading testS:  80%|████████  | 4/5 [00:01<00:00,  2.30it/s]Loading testS: 100%|██████████| 5/5 [00:02<00:00,  2.23it/s]Loading testS: 100%|██████████| 5/5 [00:02<00:00,  2.13it/s]----------+++ 
CrossVal ['c']
CrossVal ['c']
(0/5) test vimp2_ANON972_CSFn2
(1/5) test vimp2_H_CSFn2
(2/5) test vimp2_I_CSFn2
(3/5) test vimp2_K_CSFn2
(4/5) test vimp2_ANON765_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97331515 0.02668485]
Train on 16036 samples, validate on 318 samples
Epoch 1/300
 - 76s - loss: 0.1006 - acc: 0.9894 - mDice: 0.8043 - val_loss: 0.0602 - val_acc: 0.9921 - val_mDice: 0.4436

Epoch 00001: val_mDice improved from -inf to 0.44363, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 71s - loss: 0.0637 - acc: 0.9933 - mDice: 0.8760 - val_loss: 0.0570 - val_acc: 0.9933 - val_mDice: 0.4850

Epoch 00002: val_mDice improved from 0.44363 to 0.48504, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 71s - loss: 0.0552 - acc: 0.9941 - mDice: 0.8926 - val_loss: 0.0715 - val_acc: 0.9939 - val_mDice: 0.5021

Epoch 00003: val_mDice improved from 0.48504 to 0.50210, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 73s - loss: 0.0516 - acc: 0.9944 - mDice: 0.8996 - val_loss: -2.2377e-03 - val_acc: 0.9928 - val_mDice: 0.4549

Epoch 00004: val_mDice did not improve from 0.50210
Epoch 5/300
 - 73s - loss: 0.0480 - acc: 0.9947 - mDice: 0.9067 - val_loss: -2.1600e-02 - val_acc: 0.9940 - val_mDice: 0.4961

Epoch 00005: val_mDice did not improve from 0.50210
Epoch 6/300
 - 73s - loss: 0.0450 - acc: 0.9950 - mDice: 0.9125 - val_loss: 0.1396 - val_acc: 0.9922 - val_mDice: 0.4890

Epoch 00006: val_mDice did not improve from 0.50210
Epoch 7/300
 - 73s - loss: 0.0431 - acc: 0.9952 - mDice: 0.9163 - val_loss: -1.0016e-02 - val_acc: 0.9935 - val_mDice: 0.4700

Epoch 00007: val_mDice did not improve from 0.50210
Epoch 8/300
 - 73s - loss: 0.0428 - acc: 0.9953 - mDice: 0.9167 - val_loss: -2.0994e-02 - val_acc: 0.9934 - val_mDice: 0.4921

Epoch 00008: val_mDice did not improve from 0.50210
Epoch 9/300
 - 73s - loss: 0.0408 - acc: 0.9954 - mDice: 0.9207 - val_loss: -2.6497e-02 - val_acc: 0.9934 - val_mDice: 0.5031

Epoch 00009: val_mDice improved from 0.50210 to 0.50307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 10/300
 - 73s - loss: 0.0399 - acc: 0.9955 - mDice: 0.9224 - val_loss: 0.0080 - val_acc: 0.9933 - val_mDice: 0.4969

Epoch 00010: val_mDice did not improve from 0.50307
Epoch 11/300
 - 73s - loss: 0.0381 - acc: 0.9956 - mDice: 0.9259 - val_loss: 0.0334 - val_acc: 0.9938 - val_mDice: 0.5088

Epoch 00011: val_mDice improved from 0.50307 to 0.50882, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 12/300
 - 74s - loss: 0.0387 - acc: 0.9957 - mDice: 0.9248 - val_loss: 0.0162 - val_acc: 0.9936 - val_mDice: 0.4825

Epoch 00012: val_mDice did not improve from 0.50882
Epoch 13/300
 - 74s - loss: 0.0377 - acc: 0.9957 - mDice: 0.9268 - val_loss: 0.0300 - val_acc: 0.9935 - val_mDice: 0.4971

Epoch 00013: val_mDice did not improve from 0.50882
Epoch 14/300
 - 73s - loss: 0.0365 - acc: 0.9958 - mDice: 0.9291 - val_loss: 0.0503 - val_acc: 0.9930 - val_mDice: 0.4753

Epoch 00014: val_mDice did not improve from 0.50882
Epoch 15/300
 - 73s - loss: 0.0369 - acc: 0.9958 - mDice: 0.9283 - val_loss: 0.0110 - val_acc: 0.9941 - val_mDice: 0.4910

Epoch 00015: val_mDice did not improve from 0.50882
Epoch 16/300
 - 73s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9305 - val_loss: 0.0019 - val_acc: 0.9940 - val_mDice: 0.4948

Epoch 00016: val_mDice did not improve from 0.50882
Epoch 17/300
 - 73s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9320 - val_loss: 0.0011 - val_acc: 0.9943 - val_mDice: 0.5128

Epoch 00017: val_mDice improved from 0.50882 to 0.51282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 18/300
 - 73s - loss: 0.0345 - acc: 0.9960 - mDice: 0.9330 - val_loss: 0.0634 - val_acc: 0.9940 - val_mDice: 0.5117

Epoch 00018: val_mDice did not improve from 0.51282
Epoch 19/300
 - 73s - loss: 0.0343 - acc: 0.9960 - mDice: 0.9334 - val_loss: -2.2513e-02 - val_acc: 0.9939 - val_mDice: 0.4950

Epoch 00019: val_mDice did not improve from 0.51282
Epoch 20/300
 - 74s - loss: 0.0330 - acc: 0.9961 - mDice: 0.9360 - val_loss: 0.0080 - val_acc: 0.9937 - val_mDice: 0.4854

Epoch 00020: val_mDice did not improve from 0.51282
Epoch 21/300
 - 73s - loss: 0.0337 - acc: 0.9961 - mDice: 0.9345 - val_loss: 0.0653 - val_acc: 0.9940 - val_mDice: 0.5079

Epoch 00021: val_mDice did not improve from 0.51282
Epoch 22/300
 - 74s - loss: 0.0321 - acc: 0.9961 - mDice: 0.9377 - val_loss: 0.0134 - val_acc: 0.9935 - val_mDice: 0.4862

Epoch 00022: val_mDice did not improve from 0.51282
Epoch 23/300
 - 73s - loss: 0.0330 - acc: 0.9961 - mDice: 0.9359 - val_loss: 0.0132 - val_acc: 0.9918 - val_mDice: 0.4248

Epoch 00023: val_mDice did not improve from 0.51282
Epoch 24/300
 - 73s - loss: 0.0323 - acc: 0.9961 - mDice: 0.9374 - val_loss: -2.0367e-02 - val_acc: 0.9940 - val_mDice: 0.4905

Epoch 00024: val_mDice did not improve from 0.51282
Epoch 25/300
 - 73s - loss: 0.0318 - acc: 0.9962 - mDice: 0.9382 - val_loss: -2.1082e-02 - val_acc: 0.9940 - val_mDice: 0.4924

Epoch 00025: val_mDice did not improve from 0.51282
Epoch 26/300
 - 73s - loss: 0.0311 - acc: 0.9962 - mDice: 0.9396 - val_loss: 0.0212 - val_acc: 0.9929 - val_mDice: 0.4707

Epoch 00026: val_mDice did not improve from 0.51282
Epoch 27/300
 - 73s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9388 - val_loss: 0.0112 - val_acc: 0.9939 - val_mDice: 0.4891

Epoch 00027: val_mDice did not improve from 0.51282
Epoch 28/300
 - 73s - loss: 0.0311 - acc: 0.9963 - mDice: 0.9397 - val_loss: -2.5213e-02 - val_acc: 0.9940 - val_mDice: 0.5010

Epoch 00028: val_mDice did not improve from 0.51282
Epoch 29/300
 - 74s - loss: 0.0304 - acc: 0.9963 - mDice: 0.9410 - val_loss: 0.0052 - val_acc: 0.9943 - val_mDice: 0.5022

Epoch 00029: val_mDice did not improve from 0.51282
Epoch 30/300
 - 73s - loss: 0.0305 - acc: 0.9963 - mDice: 0.9409 - val_loss: -7.8657e-03 - val_acc: 0.9929 - val_mDice: 0.4660

Epoch 00030: val_mDice did not improve from 0.51282
Epoch 31/300
 - 74s - loss: 0.0302 - acc: 0.9963 - mDice: 0.9413 - val_loss: -2.4251e-02 - val_acc: 0.9937 - val_mDice: 0.4984

Epoch 00031: val_mDice did not improve from 0.51282
Epoch 32/300
 - 74s - loss: 0.0310 - acc: 0.9963 - mDice: 0.9399 - val_loss: 0.0139 - val_acc: 0.9940 - val_mDice: 0.4848

Epoch 00032: val_mDice did not improve from 0.51282

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 33/300
 - 73s - loss: 0.0296 - acc: 0.9964 - mDice: 0.9426 - val_loss: -1.9357e-02 - val_acc: 0.9940 - val_mDice: 0.4885

Epoch 00033: val_mDice did not improve from 0.51282
Epoch 34/300
 - 73s - loss: 0.0280 - acc: 0.9965 - mDice: 0.9457 - val_loss: 0.0563 - val_acc: 0.9937 - val_mDice: 0.4823

Epoch 00034: val_mDice did not improve from 0.51282
Epoch 35/300
 - 73s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9467 - val_loss: -2.0203e-02 - val_acc: 0.9938 - val_mDice: 0.4902

Epoch 00035: val_mDice did not improve from 0.51282
Epoch 36/300
 - 73s - loss: 0.0269 - acc: 0.9965 - mDice: 0.9478 - val_loss: -2.5775e-02 - val_acc: 0.9941 - val_mDice: 0.5013

Epoch 00036: val_mDice did not improve from 0.51282
Epoch 37/300
 - 73s - loss: 0.0276 - acc: 0.9965 - mDice: 0.9465 - val_loss: -2.6359e-02 - val_acc: 0.9942 - val_mDice: 0.5024

Epoch 00037: val_mDice did not improve from 0.51282
Epoch 38/300
 - 73s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9466 - val_loss: -2.2162e-02 - val_acc: 0.9938 - val_mDice: 0.4942

Epoch 00038: val_mDice did not improve from 0.51282
Epoch 39/300
 - 73s - loss: 0.0274 - acc: 0.9965 - mDice: 0.9468 - val_loss: -2.1167e-02 - val_acc: 0.9937 - val_mDice: 0.4922

Epoch 00039: val_mDice did not improve from 0.51282
Epoch 40/300
 - 74s - loss: 0.0270 - acc: 0.9966 - mDice: 0.9476 - val_loss: 0.0072 - val_acc: 0.9941 - val_mDice: 0.5011

Epoch 00040: val_mDice did not improve from 0.51282
Epoch 41/300
 - 74s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9486 - val_loss: -2.3070e-02 - val_acc: 0.9940 - val_mDice: 0.4976

Epoch 00041: val_mDice did not improve from 0.51282
Epoch 42/300
 - 73s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9495 - val_loss: -2.5884e-02 - val_acc: 0.9941 - val_mDice: 0.5016

Epoch 00042: val_mDice did not improve from 0.51282
Epoch 43/300
 - 73s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9481 - val_loss: -2.7035e-02 - val_acc: 0.9941 - val_mDice: 0.5038

Epoch 00043: val_mDice did not improve from 0.51282
Epoch 44/300
 - 73s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9465 - val_loss: -9.2895e-03 - val_acc: 0.9934 - val_mDice: 0.4685

Epoch 00044: val_mDice did not improve from 0.51282
Epoch 45/300
 - 73s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9492 - val_loss: -2.4779e-02 - val_acc: 0.9939 - val_mDice: 0.4994

Epoch 00045: val_mDice did not improve from 0.51282
Epoch 46/300
 - 73s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9465 - val_loss: -1.7581e-02 - val_acc: 0.9936 - val_mDice: 0.4851

Epoch 00046: val_mDice did not improve from 0.51282
Epoch 47/300
 - 73s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9493 - val_loss: -5.6633e-03 - val_acc: 0.9939 - val_mDice: 0.4911

Epoch 00047: val_mDice did not improve from 0.51282

Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 48/300
 - 73s - loss: 0.0250 - acc: 0.9967 - mDice: 0.9516 - val_loss: 0.0072 - val_acc: 0.9939 - val_mDice: 0.4983

Epoch 00048: val_mDice did not improve from 0.51282
Epoch 49/300
 - 74s - loss: 0.0250 - acc: 0.9967 - mDice: 0.9515 - val_loss: 0.0027 - val_acc: 0.9941 - val_mDice: 0.4998

Epoch 00049: val_mDice did not improve from 0.51282
Epoch 50/300
 - 74s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9503 - val_loss: 0.0115 - val_acc: 0.9936 - val_mDice: 0.4896

Epoch 00050: val_mDice did not improve from 0.51282
Epoch 51/300
 - 73s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: 0.0046 - val_acc: 0.9941 - val_mDice: 0.5033

Epoch 00051: val_mDice did not improve from 0.51282
Epoch 52/300
 - 73s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9511 - val_loss: -2.4024e-02 - val_acc: 0.9939 - val_mDice: 0.4979

Epoch 00052: val_mDice did not improve from 0.51282
Epoch 53/300
 - 73s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9512 - val_loss: -1.9886e-02 - val_acc: 0.9937 - val_mDice: 0.4896

Epoch 00053: val_mDice did not improve from 0.51282
Epoch 54/300
 - 73s - loss: 0.0250 - acc: 0.9967 - mDice: 0.9516 - val_loss: 0.0033 - val_acc: 0.9940 - val_mDice: 0.5062

Epoch 00054: val_mDice did not improve from 0.51282
Epoch 55/300
 - 73s - loss: 0.0247 - acc: 0.9967 - mDice: 0.9521 - val_loss: -2.1387e-02 - val_acc: 0.9938 - val_mDice: 0.4926

Epoch 00055: val_mDice did not improve from 0.51282
Epoch 56/300
 - 73s - loss: 0.0250 - acc: 0.9968 - mDice: 0.9516 - val_loss: -2.2208e-02 - val_acc: 0.9937 - val_mDice: 0.4943

Epoch 00056: val_mDice did not improve from 0.51282
Epoch 57/300
 - 73s - loss: 0.0242 - acc: 0.9967 - mDice: 0.9530 - val_loss: -1.7318e-02 - val_acc: 0.9931 - val_mDice: 0.4848

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.08it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.38it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.76it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.09it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.63it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.77it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:39,  6.21it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:38,  6.42it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:37,  6.49it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:37,  6.50it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:36,  6.54it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:36,  6.56it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:36,  6.56it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:36,  6.58it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:35,  6.62it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:36,  6.57it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:35,  6.58it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:35,  6.60it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:35,  6.62it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:35,  6.62it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:35,  6.60it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:35,  6.57it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:35,  6.46it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:35,  6.48it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:34,  6.52it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:34,  6.56it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:34,  6.53it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:34,  6.50it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:33,  6.60it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:33,  6.69it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:32,  6.74it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:32,  6.75it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:32,  6.74it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:32,  6.76it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:32,  6.78it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:31,  6.82it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:31,  6.86it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:31,  6.80it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:31,  6.77it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:31,  6.82it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:30,  6.86it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:30,  6.89it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:30,  6.89it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:31,  6.73it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:31,  6.65it/s]predicting train subjects:  16%|█▌        | 40/247 [00:06<00:30,  6.69it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:30,  6.78it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:29,  6.86it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:29,  6.86it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:29,  6.87it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:29,  6.91it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:28,  6.94it/s]predicting train subjects:  19%|█▉        | 47/247 [00:07<00:28,  6.95it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:28,  6.96it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:28,  6.91it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:28,  6.94it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:28,  6.91it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:28,  6.84it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:28,  6.84it/s]predicting train subjects:  22%|██▏       | 54/247 [00:08<00:28,  6.85it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:28,  6.68it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:28,  6.73it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:28,  6.67it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:28,  6.64it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:28,  6.50it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:28,  6.49it/s]predicting train subjects:  25%|██▍       | 61/247 [00:09<00:29,  6.29it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:29,  6.30it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:29,  6.30it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:29,  6.30it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:28,  6.34it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:28,  6.29it/s]predicting train subjects:  27%|██▋       | 67/247 [00:10<00:28,  6.26it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:28,  6.27it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:28,  6.30it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:27,  6.35it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:27,  6.40it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:27,  6.45it/s]predicting train subjects:  30%|██▉       | 73/247 [00:11<00:26,  6.49it/s]predicting train subjects:  30%|██▉       | 74/247 [00:11<00:26,  6.48it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:26,  6.50it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:26,  6.53it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:27,  6.19it/s]predicting train subjects:  32%|███▏      | 78/247 [00:11<00:27,  6.08it/s]predicting train subjects:  32%|███▏      | 79/247 [00:12<00:34,  4.88it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:40,  4.15it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:39,  4.16it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:37,  4.40it/s]predicting train subjects:  34%|███▎      | 83/247 [00:13<00:35,  4.67it/s]predicting train subjects:  34%|███▍      | 84/247 [00:13<00:33,  4.91it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:31,  5.10it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:30,  5.24it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:29,  5.39it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:28,  5.48it/s]predicting train subjects:  36%|███▌      | 89/247 [00:14<00:28,  5.56it/s]predicting train subjects:  36%|███▋      | 90/247 [00:14<00:28,  5.60it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:28,  5.53it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:28,  5.46it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:28,  5.45it/s]predicting train subjects:  38%|███▊      | 94/247 [00:15<00:27,  5.47it/s]predicting train subjects:  38%|███▊      | 95/247 [00:15<00:27,  5.45it/s]predicting train subjects:  39%|███▉      | 96/247 [00:15<00:27,  5.49it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:27,  5.51it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:27,  5.52it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:26,  5.55it/s]predicting train subjects:  40%|████      | 100/247 [00:16<00:26,  5.63it/s]predicting train subjects:  41%|████      | 101/247 [00:16<00:25,  5.68it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:25,  5.66it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:25,  5.65it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:25,  5.70it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:24,  5.68it/s]predicting train subjects:  43%|████▎     | 106/247 [00:17<00:24,  5.66it/s]predicting train subjects:  43%|████▎     | 107/247 [00:17<00:24,  5.70it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:24,  5.73it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:24,  5.57it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:24,  5.64it/s]predicting train subjects:  45%|████▍     | 111/247 [00:18<00:23,  5.70it/s]predicting train subjects:  45%|████▌     | 112/247 [00:18<00:23,  5.68it/s]predicting train subjects:  46%|████▌     | 113/247 [00:18<00:23,  5.64it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:23,  5.66it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:23,  5.62it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:23,  5.59it/s]predicting train subjects:  47%|████▋     | 117/247 [00:19<00:23,  5.54it/s]predicting train subjects:  48%|████▊     | 118/247 [00:19<00:22,  5.78it/s]predicting train subjects:  48%|████▊     | 119/247 [00:19<00:21,  5.99it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:20,  6.13it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:19,  6.31it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:19,  6.46it/s]predicting train subjects:  50%|████▉     | 123/247 [00:20<00:18,  6.60it/s]predicting train subjects:  50%|█████     | 124/247 [00:20<00:18,  6.69it/s]predicting train subjects:  51%|█████     | 125/247 [00:20<00:18,  6.77it/s]predicting train subjects:  51%|█████     | 126/247 [00:20<00:17,  6.75it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:17,  6.81it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:17,  6.85it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:20<00:17,  6.75it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:21<00:17,  6.71it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:21<00:17,  6.70it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:21<00:16,  6.77it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:21<00:16,  6.82it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:16,  6.87it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:21<00:16,  6.81it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:21<00:16,  6.80it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:22<00:16,  6.79it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:22<00:16,  6.70it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:22<00:16,  6.74it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:22<00:16,  6.61it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:16,  6.61it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:15,  6.60it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:23<00:16,  6.49it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:23<00:15,  6.49it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:23<00:15,  6.50it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:23<00:15,  6.57it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:23<00:15,  6.55it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:15,  6.58it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:14,  6.58it/s]predicting train subjects:  61%|██████    | 150/247 [00:24<00:14,  6.62it/s]predicting train subjects:  61%|██████    | 151/247 [00:24<00:14,  6.69it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:24<00:14,  6.73it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:24<00:13,  6.78it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:24<00:14,  6.45it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:24<00:14,  6.24it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:25<00:15,  6.03it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:25<00:15,  5.67it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:25<00:15,  5.69it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:25<00:15,  5.68it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:25<00:15,  5.73it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:25<00:14,  5.74it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:26<00:14,  5.78it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:26<00:14,  5.77it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:26<00:14,  5.80it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:26<00:14,  5.80it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:26<00:14,  5.78it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:26<00:14,  5.71it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:27<00:13,  5.71it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:27<00:13,  5.70it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:27<00:13,  5.66it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:27<00:13,  5.65it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:27<00:12,  5.88it/s]predicting train subjects:  70%|███████   | 173/247 [00:28<00:15,  4.73it/s]predicting train subjects:  70%|███████   | 174/247 [00:28<00:14,  5.18it/s]predicting train subjects:  71%|███████   | 175/247 [00:28<00:14,  4.86it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:28<00:13,  5.24it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:28<00:12,  5.61it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:28<00:11,  5.87it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:29<00:11,  6.07it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:29<00:10,  6.26it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:29<00:10,  6.38it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:29<00:10,  6.42it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:29<00:10,  6.39it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:29<00:09,  6.43it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:30<00:09,  6.47it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:30<00:09,  6.52it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:30<00:09,  6.55it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:30<00:08,  6.57it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:30<00:08,  6.59it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:30<00:08,  6.59it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:30<00:08,  6.58it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:31<00:08,  6.55it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:31<00:08,  6.54it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:31<00:08,  6.42it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:31<00:07,  6.54it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:31<00:07,  6.61it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:31<00:07,  6.66it/s]predicting train subjects:  80%|████████  | 198/247 [00:32<00:07,  6.70it/s]predicting train subjects:  81%|████████  | 199/247 [00:32<00:07,  6.74it/s]predicting train subjects:  81%|████████  | 200/247 [00:32<00:06,  6.80it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:32<00:06,  6.85it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:32<00:06,  6.82it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:32<00:06,  6.86it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:32<00:06,  6.93it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:33<00:06,  6.91it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:33<00:05,  6.95it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:33<00:05,  6.99it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:33<00:05,  6.99it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:33<00:05,  7.02it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:33<00:05,  7.04it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:33<00:05,  7.00it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:34<00:05,  6.91it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:34<00:04,  6.88it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:34<00:04,  6.79it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:34<00:04,  6.79it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:34<00:04,  6.74it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:34<00:04,  6.54it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:34<00:04,  6.59it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:35<00:04,  6.67it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:35<00:04,  6.72it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:35<00:03,  6.63it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:35<00:03,  6.61it/s]predicting train subjects:  90%|█████████ | 223/247 [00:35<00:03,  6.64it/s]predicting train subjects:  91%|█████████ | 224/247 [00:35<00:03,  6.64it/s]predicting train subjects:  91%|█████████ | 225/247 [00:35<00:03,  6.64it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:36<00:03,  6.64it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:36<00:03,  6.63it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:36<00:02,  6.57it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:36<00:02,  6.52it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:36<00:02,  6.29it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:36<00:02,  6.15it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:37<00:02,  5.98it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:37<00:02,  5.89it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:37<00:02,  5.91it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:37<00:02,  5.93it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:37<00:01,  5.85it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:37<00:01,  5.79it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:38<00:01,  5.72it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:38<00:01,  5.72it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:38<00:01,  5.73it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:38<00:01,  5.77it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:38<00:00,  5.84it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:39<00:00,  5.85it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:39<00:00,  5.82it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:39<00:00,  5.79it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:39<00:00,  5.78it/s]predicting train subjects: 100%|██████████| 247/247 [00:39<00:00,  5.79it/s]predicting train subjects: 100%|██████████| 247/247 [00:39<00:00,  6.22it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  6.39it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  6.08it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  6.10it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  6.40it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.44it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.30it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:38,  6.46it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:37,  6.51it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:37,  6.54it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:37,  6.45it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:37,  6.44it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:37,  6.47it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:01<00:37,  6.47it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:01<00:36,  6.47it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:36,  6.52it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:36,  6.56it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:36,  6.50it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:36,  6.51it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:35,  6.55it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:02<00:35,  6.57it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:02<00:35,  6.56it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:02<00:35,  6.48it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:35,  6.43it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:35,  6.47it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:35,  6.44it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:03<00:35,  6.31it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:03<00:36,  6.27it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:03<00:35,  6.37it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:03<00:34,  6.47it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:03<00:33,  6.57it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:33,  6.67it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:32,  6.74it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:04<00:32,  6.79it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:04<00:32,  6.76it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:04<00:32,  6.77it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:04<00:32,  6.61it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:04<00:32,  6.62it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:04<00:32,  6.66it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:05<00:32,  6.69it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:05<00:31,  6.75it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:05<00:31,  6.80it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:05<00:31,  6.76it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:05<00:31,  6.73it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:05<00:31,  6.71it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:05<00:30,  6.72it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:06<00:30,  6.72it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:06<00:30,  6.71it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:06<00:30,  6.72it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:06<00:30,  6.70it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:06<00:30,  6.72it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:06<00:29,  6.74it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:06<00:29,  6.75it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:07<00:29,  6.79it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:07<00:29,  6.84it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:07<00:28,  6.87it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:07<00:28,  6.81it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:07<00:28,  6.78it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:07<00:28,  6.81it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:07<00:28,  6.85it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:08<00:28,  6.86it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:08<00:27,  6.88it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:08<00:27,  6.90it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:08<00:27,  6.86it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:08<00:27,  6.85it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:08<00:27,  6.74it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:09<00:28,  6.64it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:09<00:28,  6.52it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:09<00:29,  6.33it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:09<00:28,  6.35it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:09<00:29,  6.27it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:09<00:28,  6.33it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:09<00:29,  6.24it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:10<00:28,  6.29it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:10<00:28,  6.35it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:10<00:27,  6.38it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:10<00:27,  6.37it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:10<00:27,  6.41it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:10<00:27,  6.43it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:11<00:27,  6.42it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:11<00:27,  6.36it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:11<00:27,  6.31it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:11<00:27,  6.29it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:11<00:28,  5.95it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:11<00:28,  5.84it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:12<00:27,  6.12it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:12<00:26,  6.30it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:12<00:27,  6.12it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:12<00:28,  5.89it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:12<00:28,  5.79it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:12<00:28,  5.75it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:13<00:28,  5.71it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:13<00:30,  5.33it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:13<00:29,  5.41it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:13<00:29,  5.40it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:13<00:29,  5.44it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:14<00:28,  5.45it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:14<00:29,  5.36it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:14<00:28,  5.37it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:14<00:29,  5.30it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:14<00:29,  5.26it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:15<00:28,  5.31it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:15<00:28,  5.34it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:15<00:27,  5.40it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:15<00:28,  5.25it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:15<00:27,  5.29it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:15<00:27,  5.41it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:16<00:26,  5.46it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:16<00:26,  5.50it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:16<00:26,  5.54it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:16<00:25,  5.55it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:16<00:25,  5.56it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:17<00:25,  5.59it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:17<00:24,  5.63it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:17<00:24,  5.64it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:17<00:24,  5.57it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:17<00:24,  5.61it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:17<00:24,  5.64it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:18<00:23,  5.66it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:18<00:23,  5.69it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:18<00:23,  5.70it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:18<00:23,  5.69it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:18<00:23,  5.68it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:18<00:23,  5.63it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:19<00:22,  5.84it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:19<00:20,  6.13it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:19<00:20,  6.31it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:19<00:19,  6.46it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:19<00:18,  6.59it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:19<00:18,  6.64it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:19<00:18,  6.63it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:20<00:18,  6.72it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:20<00:17,  6.79it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:20<00:17,  6.76it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:20<00:17,  6.79it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:20<00:17,  6.84it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:20<00:17,  6.86it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:21<00:17,  6.81it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:21<00:17,  6.75it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:21<00:16,  6.73it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:21<00:16,  6.74it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:21<00:16,  6.70it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:21<00:16,  6.54it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:21<00:16,  6.56it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:22<00:16,  6.46it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:22<00:16,  6.52it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:22<00:16,  6.53it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:22<00:16,  6.48it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:22<00:16,  6.56it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:22<00:15,  6.62it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:22<00:15,  6.67it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:23<00:15,  6.62it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:23<00:15,  6.67it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:23<00:14,  6.67it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:23<00:14,  6.70it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:23<00:14,  6.70it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:23<00:14,  6.70it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:24<00:14,  6.69it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:24<00:14,  6.64it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:24<00:14,  6.59it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:24<00:14,  6.27it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:24<00:15,  5.97it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:24<00:15,  5.80it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:25<00:15,  5.74it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:25<00:15,  5.64it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:25<00:15,  5.66it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:25<00:15,  5.64it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:25<00:15,  5.64it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:25<00:15,  5.60it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:26<00:14,  5.60it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:26<00:14,  5.60it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:26<00:14,  5.59it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:26<00:14,  5.63it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:26<00:14,  5.69it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:27<00:13,  5.77it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:27<00:13,  5.81it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:27<00:13,  5.85it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:27<00:13,  5.76it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:27<00:12,  6.01it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:27<00:11,  6.29it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:27<00:11,  6.39it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:28<00:11,  6.22it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:28<00:11,  6.36it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:28<00:10,  6.47it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:28<00:10,  6.55it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:28<00:10,  6.56it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:28<00:10,  6.58it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:29<00:10,  6.51it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:29<00:09,  6.53it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:29<00:09,  6.55it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:29<00:09,  6.60it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:29<00:09,  6.61it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:29<00:09,  6.59it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:29<00:09,  6.62it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:30<00:08,  6.66it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:30<00:08,  6.67it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:30<00:08,  6.65it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:30<00:08,  6.67it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:30<00:08,  6.68it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:30<00:08,  6.61it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:31<00:07,  6.72it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:31<00:07,  6.60it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:31<00:07,  6.62it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:31<00:07,  6.63it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:31<00:07,  6.69it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:31<00:07,  6.69it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:31<00:07,  6.60it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:32<00:06,  6.69it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:32<00:06,  6.78it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:32<00:06,  6.73it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:32<00:06,  6.82it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:32<00:06,  6.88it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:32<00:05,  6.95it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:32<00:05,  7.01it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:33<00:05,  7.04it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:33<00:05,  7.07it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:33<00:05,  7.05it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:33<00:05,  7.06it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:33<00:05,  6.97it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:33<00:04,  6.93it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:33<00:04,  6.89it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:34<00:04,  6.84it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:34<00:04,  6.82it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:34<00:04,  6.65it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:34<00:04,  6.66it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:34<00:04,  6.71it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:34<00:04,  6.73it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:34<00:03,  6.76it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:35<00:03,  6.64it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:35<00:03,  6.56it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:35<00:03,  6.60it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:35<00:03,  6.64it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:35<00:03,  6.63it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:35<00:03,  6.63it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:36<00:02,  6.68it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:36<00:02,  6.73it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:36<00:02,  6.42it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:36<00:02,  6.29it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:36<00:02,  6.20it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:36<00:02,  6.09it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:37<00:02,  6.01it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:37<00:02,  5.96it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:37<00:01,  5.91it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:37<00:01,  5.88it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:37<00:01,  5.88it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:37<00:01,  5.88it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:38<00:01,  5.85it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:38<00:01,  5.80it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:38<00:00,  5.80it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:38<00:00,  5.77it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:38<00:00,  5.80it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:38<00:00,  5.75it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:39<00:00,  5.79it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:39<00:00,  5.84it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:39<00:00,  6.29it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 66.60it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 83.50it/s]saving BB  train1-THALAMUS:   7%|▋         | 17/247 [00:00<00:02, 81.69it/s]saving BB  train1-THALAMUS:  11%|█         | 26/247 [00:00<00:02, 82.87it/s]saving BB  train1-THALAMUS:  14%|█▍        | 35/247 [00:00<00:02, 84.49it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 85.99it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 88.54it/s]saving BB  train1-THALAMUS:  26%|██▌       | 64/247 [00:00<00:02, 87.02it/s]saving BB  train1-THALAMUS:  30%|██▉       | 73/247 [00:00<00:02, 84.48it/s]saving BB  train1-THALAMUS:  33%|███▎      | 82/247 [00:00<00:02, 81.58it/s]saving BB  train1-THALAMUS:  36%|███▋      | 90/247 [00:01<00:02, 77.72it/s]saving BB  train1-THALAMUS:  40%|███▉      | 98/247 [00:01<00:01, 75.27it/s]saving BB  train1-THALAMUS:  43%|████▎     | 106/247 [00:01<00:01, 74.35it/s]saving BB  train1-THALAMUS:  46%|████▌     | 114/247 [00:01<00:01, 74.96it/s]saving BB  train1-THALAMUS:  49%|████▉     | 122/247 [00:01<00:01, 74.57it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 130/247 [00:01<00:01, 75.07it/s]saving BB  train1-THALAMUS:  56%|█████▋    | 139/247 [00:01<00:01, 77.87it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 148/247 [00:01<00:01, 80.56it/s]saving BB  train1-THALAMUS:  64%|██████▎   | 157/247 [00:01<00:01, 80.99it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 166/247 [00:02<00:01, 78.27it/s]saving BB  train1-THALAMUS:  70%|███████   | 174/247 [00:02<00:00, 78.78it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 183/247 [00:02<00:00, 79.76it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 191/247 [00:02<00:00, 79.46it/s]saving BB  train1-THALAMUS:  81%|████████  | 200/247 [00:02<00:00, 80.75it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 209/247 [00:02<00:00, 80.93it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 218/247 [00:02<00:00, 83.45it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 228/247 [00:02<00:00, 85.46it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 237/247 [00:02<00:00, 83.87it/s]saving BB  train1-THALAMUS: 100%|█████████▉| 246/247 [00:03<00:00, 82.25it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 80.90it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 79.31it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/247 [00:00<00:03, 79.49it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 17/247 [00:00<00:02, 80.18it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 26/247 [00:00<00:02, 81.49it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 35/247 [00:00<00:02, 83.27it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 45/247 [00:00<00:02, 85.58it/s]saving BB  train1-THALAMUS Sagittal:  22%|██▏       | 54/247 [00:00<00:02, 86.41it/s]saving BB  train1-THALAMUS Sagittal:  25%|██▌       | 62/247 [00:00<00:02, 84.36it/s]saving BB  train1-THALAMUS Sagittal:  28%|██▊       | 70/247 [00:00<00:02, 81.38it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 78/247 [00:00<00:02, 79.93it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 86/247 [00:01<00:02, 77.36it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 94/247 [00:01<00:02, 74.20it/s]saving BB  train1-THALAMUS Sagittal:  41%|████▏     | 102/247 [00:01<00:01, 73.22it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 110/247 [00:01<00:01, 73.15it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 118/247 [00:01<00:01, 73.54it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████▏    | 127/247 [00:01<00:01, 75.57it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▌    | 136/247 [00:01<00:01, 77.72it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▊    | 145/247 [00:01<00:01, 80.18it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 154/247 [00:01<00:01, 81.88it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 163/247 [00:02<00:01, 79.39it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 171/247 [00:02<00:00, 78.16it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 180/247 [00:02<00:00, 79.01it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 189/247 [00:02<00:00, 80.31it/s]saving BB  train1-THALAMUS Sagittal:  80%|████████  | 198/247 [00:02<00:00, 81.08it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 207/247 [00:02<00:00, 82.19it/s]saving BB  train1-THALAMUS Sagittal:  87%|████████▋ | 216/247 [00:02<00:00, 80.73it/s]saving BB  train1-THALAMUS Sagittal:  91%|█████████ | 225/247 [00:02<00:00, 82.26it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▍| 234/247 [00:02<00:00, 82.51it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 243/247 [00:03<00:00, 81.47it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 80.09it/s]
Epoch 00057: val_mDice did not improve from 0.51282
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [0.06016526910119087, 0.057016351547256205, 0.07146961021723237, -0.0022377023157083764, -0.021599890347921622, 0.13956859909326025, -0.010016396360577277, -0.02099407806336505, -0.02649666467365229, 0.00801023653468246, 0.033432679590564104, 0.0161791130806665, 0.030014130632457493, 0.05032294712164117, 0.011036640583719098, 0.0018515916740369496, 0.0010541615152508958, 0.06343012893537306, -0.022513400271253765, 0.007956717514766837, 0.06534085047882308, 0.013377689153143446, 0.013178827065341878, -0.020366990294471476, -0.021081505565898224, 0.021212273845507664, 0.01120809976409816, -0.025213340918223064, 0.005163415376120394, -0.007865680838530918, -0.024250514805316925, 0.013913994127849364, -0.019357421581850113, 0.056330939274538985, -0.020203023914646054, -0.025775128050045396, -0.026359166317390947, -0.022162034826458624, -0.021167329366102158, 0.007169389078077281, -0.023070144718922908, -0.025883715716922807, -0.027035017901996396, -0.00928954559864488, -0.02477949838968193, -0.017581386714236542, -0.005663322483968435, 0.00717099962182015, 0.0026935912528127993, 0.011538940218259703, 0.004603527908055288, -0.024024432794477954, -0.019886399777430407, 0.003262861063645321, -0.02138714539180012, -0.02220833362460886, -0.017318449399006442], 'val_acc': [0.9921366066302894, 0.9932892479986515, 0.9939140096400518, 0.9927641329525402, 0.9940191799739622, 0.9922400225633345, 0.9935402566531919, 0.993386390449116, 0.9934323216384312, 0.9933379419944571, 0.9937937750756366, 0.9935869413351862, 0.9935041096225474, 0.9929576606120704, 0.9941381587172454, 0.994042528875219, 0.9943382147723024, 0.9939852952957153, 0.9938587872487195, 0.9937041638032446, 0.9939654645679882, 0.9934918119472528, 0.9917528108230926, 0.9939986013766354, 0.9940239483455442, 0.9929410950192865, 0.9939368562128559, 0.9939810273782262, 0.9942513700551207, 0.9929210131273329, 0.9936903591425914, 0.9940492971888129, 0.9939561789890505, 0.9936532100791451, 0.9938261490198051, 0.9940686349598866, 0.9941999076297449, 0.9937892616170008, 0.9936652558404695, 0.9940939781800756, 0.994032990257695, 0.9940784172441974, 0.9941389103355648, 0.9934448723523122, 0.9938828821452159, 0.9935560706276564, 0.993935596643004, 0.9938748542617701, 0.9940759149737328, 0.9936361376594447, 0.9941298796695733, 0.9939232989677094, 0.9936853377324231, 0.9940224469832655, 0.9937935239114102, 0.993718978743883, 0.9930502821064595], 'val_mDice': [0.44363405507163356, 0.4850418886767243, 0.5021027402392334, 0.4548608654677681, 0.4960884613061103, 0.4890005127673254, 0.4699950126357072, 0.4920833262632478, 0.5030739265230467, 0.49692941677270447, 0.508821724955016, 0.4824659224078294, 0.4970795487832723, 0.4753337153848612, 0.49101780444008747, 0.4947617776551337, 0.5128212776638883, 0.5116983928623222, 0.49498100934913325, 0.48541607532885517, 0.5078673147180546, 0.48616037171029447, 0.42482686241175505, 0.4904878102008652, 0.4923626498439033, 0.47067182366999816, 0.4890850884547024, 0.500956987434963, 0.5022085432267789, 0.46600507935450514, 0.49841002988740335, 0.48478418158707004, 0.4884916324894758, 0.482258506166111, 0.49022706893255125, 0.5013479981219994, 0.5023892893918656, 0.4941501922952304, 0.49224912820877675, 0.5011377892656729, 0.49764011640969785, 0.5015849849089891, 0.5037915584801128, 0.4685153643477638, 0.4994208951416256, 0.4851093274429909, 0.4910545753982832, 0.49833414783267854, 0.49983879398999725, 0.4895545518810644, 0.5033421563277455, 0.49788132544208624, 0.4896429532541419, 0.5061656386597352, 0.4926111164895244, 0.4942823637206599, 0.4847865176838149], 'loss': [0.10064962420619078, 0.06370609371564459, 0.055216636346087665, 0.05161426110617328, 0.0479664208818609, 0.0450208719738941, 0.04307278666908261, 0.04283674496178854, 0.040816299539235025, 0.03990627790692739, 0.03814015476449852, 0.03868880980116347, 0.03768005023969918, 0.036489360962768363, 0.03686428820330117, 0.035780103493878654, 0.03498095967457252, 0.0344850809928276, 0.03426821721008247, 0.03298535070947264, 0.03368955474169393, 0.03209438020989288, 0.03302438176534633, 0.03226752276096775, 0.0318116802563317, 0.03113411392865112, 0.03151519312789298, 0.03105759794897467, 0.03041306661010294, 0.030468900212922815, 0.03024294804414629, 0.030953622234710643, 0.029573981630427487, 0.027997375896860757, 0.027469253759895305, 0.026949902512755707, 0.0275701581344592, 0.027533927776735304, 0.027410282480446115, 0.027011674422520775, 0.02652236720861625, 0.026070563253187188, 0.026739503509959964, 0.02757799320051158, 0.02619578821473539, 0.027574759729375682, 0.026135036381262144, 0.02498110248638704, 0.025029219200996784, 0.02563199905753433, 0.025413706237076228, 0.025228267869626116, 0.025174275818393543, 0.02498963286035761, 0.024699333812655818, 0.02497169717748613, 0.024247675655555117], 'acc': [0.9893840390879426, 0.9932666921978373, 0.9940883977272231, 0.9944382609646646, 0.9947054989247526, 0.9949817223407943, 0.995171185658144, 0.9953082696506584, 0.9953754812471586, 0.9954817192487272, 0.9955991215541138, 0.99568205910539, 0.9956913573407686, 0.9958202284332165, 0.9957982321634766, 0.9957974454906998, 0.9959291034831345, 0.9959526181250744, 0.9960117322618333, 0.9960666560389271, 0.9960778202758402, 0.9961110115512168, 0.9960796120429045, 0.9961386032757482, 0.9961782933679059, 0.9962102150152853, 0.9962384386620459, 0.9962570496511209, 0.9962789710842483, 0.9962892654932892, 0.9962754768455793, 0.9963063374514828, 0.9964378029145217, 0.996461157602216, 0.9964803957781551, 0.9965230991237328, 0.9965146571197068, 0.9965649004231132, 0.9965370019480129, 0.9965647516196492, 0.9965642933968625, 0.9965887438718682, 0.9965646626958825, 0.9965708737630266, 0.9966128901312493, 0.9965924570152486, 0.996601630666661, 0.9966695460261594, 0.9966864494217039, 0.9966939561130341, 0.9966940796711284, 0.9967109442396513, 0.9966982174065381, 0.9967293071164012, 0.9967366689219086, 0.9967522541389527, 0.9967411793833452], 'mDice': [0.8042505997495399, 0.8760465239923922, 0.892582054520581, 0.8995964942162219, 0.9067410530388191, 0.9124850194913308, 0.9162731961839423, 0.916671083949694, 0.9206727654323535, 0.9224321955039514, 0.9259010855843521, 0.9247583272472214, 0.926765195570048, 0.9290800491423641, 0.928345602277985, 0.9305066102072616, 0.9320346189574072, 0.9330128146399135, 0.9334128794340933, 0.935950520308305, 0.9345360149481434, 0.9377030429696763, 0.9358706960868556, 0.9373515781975054, 0.9382303190420143, 0.9395716746464784, 0.9387990567051702, 0.9397001141442061, 0.9409784935424084, 0.9408606814457966, 0.941319034235767, 0.9398779799944744, 0.9425571016057803, 0.94569856189721, 0.9467368526451604, 0.947753380579852, 0.9465231605229101, 0.9465699624200509, 0.9468305310679065, 0.9476070395429463, 0.9485846362482077, 0.9494795560182613, 0.9481488972264853, 0.9464680487733733, 0.9492183290579932, 0.9464713956507461, 0.9493361819738996, 0.9516140770052817, 0.9515023677240259, 0.9502920300459796, 0.9507273223802138, 0.9510903065416931, 0.9512027569708011, 0.9515566455156669, 0.9521394102360489, 0.951587086181505, 0.9530325403874222], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:33,  1.15it/s]Loading train:   1%|          | 2/247 [00:01<03:22,  1.21it/s]Loading train:   1%|          | 3/247 [00:02<03:13,  1.26it/s]Loading train:   2%|▏         | 4/247 [00:03<03:19,  1.22it/s]Loading train:   2%|▏         | 5/247 [00:03<03:00,  1.34it/s]Loading train:   2%|▏         | 6/247 [00:04<02:43,  1.48it/s]Loading train:   3%|▎         | 7/247 [00:04<02:31,  1.59it/s]Loading train:   3%|▎         | 8/247 [00:05<02:22,  1.67it/s]Loading train:   4%|▎         | 9/247 [00:05<02:18,  1.71it/s]Loading train:   4%|▍         | 10/247 [00:06<02:15,  1.75it/s]Loading train:   4%|▍         | 11/247 [00:06<02:10,  1.81it/s]Loading train:   5%|▍         | 12/247 [00:07<02:08,  1.83it/s]Loading train:   5%|▌         | 13/247 [00:08<02:08,  1.83it/s]Loading train:   6%|▌         | 14/247 [00:08<02:08,  1.81it/s]Loading train:   6%|▌         | 15/247 [00:09<02:07,  1.81it/s]Loading train:   6%|▋         | 16/247 [00:09<02:03,  1.87it/s]Loading train:   7%|▋         | 17/247 [00:10<02:02,  1.88it/s]Loading train:   7%|▋         | 18/247 [00:10<01:59,  1.92it/s]Loading train:   8%|▊         | 19/247 [00:11<01:56,  1.95it/s]Loading train:   8%|▊         | 20/247 [00:11<01:56,  1.94it/s]Loading train:   9%|▊         | 21/247 [00:12<02:01,  1.86it/s]Loading train:   9%|▉         | 22/247 [00:12<02:01,  1.85it/s]Loading train:   9%|▉         | 23/247 [00:13<02:00,  1.87it/s]Loading train:  10%|▉         | 24/247 [00:13<01:55,  1.93it/s]Loading train:  10%|█         | 25/247 [00:14<01:53,  1.96it/s]Loading train:  11%|█         | 26/247 [00:14<01:49,  2.01it/s]Loading train:  11%|█         | 27/247 [00:15<01:48,  2.04it/s]Loading train:  11%|█▏        | 28/247 [00:15<01:51,  1.97it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:56,  1.88it/s]Loading train:  12%|█▏        | 30/247 [00:16<02:00,  1.80it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:59,  1.81it/s]Loading train:  13%|█▎        | 32/247 [00:18<01:54,  1.89it/s]Loading train:  13%|█▎        | 33/247 [00:18<01:53,  1.88it/s]Loading train:  14%|█▍        | 34/247 [00:19<01:53,  1.87it/s]Loading train:  14%|█▍        | 35/247 [00:19<01:50,  1.93it/s]Loading train:  15%|█▍        | 36/247 [00:20<01:46,  1.97it/s]Loading train:  15%|█▍        | 37/247 [00:20<01:45,  2.00it/s]Loading train:  15%|█▌        | 38/247 [00:21<01:43,  2.02it/s]Loading train:  16%|█▌        | 39/247 [00:21<01:41,  2.04it/s]Loading train:  16%|█▌        | 40/247 [00:21<01:42,  2.03it/s]Loading train:  17%|█▋        | 41/247 [00:22<01:40,  2.05it/s]Loading train:  17%|█▋        | 42/247 [00:22<01:38,  2.09it/s]Loading train:  17%|█▋        | 43/247 [00:23<01:39,  2.06it/s]Loading train:  18%|█▊        | 44/247 [00:23<01:39,  2.03it/s]Loading train:  18%|█▊        | 45/247 [00:24<01:40,  2.01it/s]Loading train:  19%|█▊        | 46/247 [00:24<01:39,  2.01it/s]Loading train:  19%|█▉        | 47/247 [00:25<01:38,  2.03it/s]Loading train:  19%|█▉        | 48/247 [00:25<01:36,  2.06it/s]Loading train:  20%|█▉        | 49/247 [00:26<01:37,  2.03it/s]Loading train:  20%|██        | 50/247 [00:26<01:36,  2.05it/s]Loading train:  21%|██        | 51/247 [00:27<01:35,  2.04it/s]Loading train:  21%|██        | 52/247 [00:27<01:35,  2.04it/s]Loading train:  21%|██▏       | 53/247 [00:28<01:35,  2.03it/s]Loading train:  22%|██▏       | 54/247 [00:28<01:34,  2.05it/s]Loading train:  22%|██▏       | 55/247 [00:29<01:33,  2.06it/s]Loading train:  23%|██▎       | 56/247 [00:29<01:33,  2.03it/s]Loading train:  23%|██▎       | 57/247 [00:30<01:33,  2.02it/s]Loading train:  23%|██▎       | 58/247 [00:30<01:33,  2.03it/s]Loading train:  24%|██▍       | 59/247 [00:31<01:38,  1.91it/s]Loading train:  24%|██▍       | 60/247 [00:31<01:40,  1.87it/s]Loading train:  25%|██▍       | 61/247 [00:32<01:41,  1.83it/s]Loading train:  25%|██▌       | 62/247 [00:33<01:42,  1.81it/s]Loading train:  26%|██▌       | 63/247 [00:33<01:43,  1.78it/s]Loading train:  26%|██▌       | 64/247 [00:34<01:44,  1.75it/s]Loading train:  26%|██▋       | 65/247 [00:34<01:46,  1.71it/s]Loading train:  27%|██▋       | 66/247 [00:35<01:44,  1.73it/s]Loading train:  27%|██▋       | 67/247 [00:36<01:43,  1.73it/s]Loading train:  28%|██▊       | 68/247 [00:36<01:44,  1.72it/s]Loading train:  28%|██▊       | 69/247 [00:37<01:44,  1.70it/s]Loading train:  28%|██▊       | 70/247 [00:37<01:44,  1.70it/s]Loading train:  29%|██▊       | 71/247 [00:38<01:41,  1.74it/s]Loading train:  29%|██▉       | 72/247 [00:38<01:42,  1.71it/s]Loading train:  30%|██▉       | 73/247 [00:39<01:40,  1.74it/s]Loading train:  30%|██▉       | 74/247 [00:40<01:37,  1.78it/s]Loading train:  30%|███       | 75/247 [00:40<01:35,  1.81it/s]Loading train:  31%|███       | 76/247 [00:41<01:36,  1.78it/s]Loading train:  31%|███       | 77/247 [00:42<01:58,  1.43it/s]Loading train:  32%|███▏      | 78/247 [00:43<02:08,  1.31it/s]Loading train:  32%|███▏      | 79/247 [00:43<02:09,  1.30it/s]Loading train:  32%|███▏      | 80/247 [00:44<02:06,  1.32it/s]Loading train:  33%|███▎      | 81/247 [00:45<02:18,  1.20it/s]Loading train:  33%|███▎      | 82/247 [00:46<02:07,  1.29it/s]Loading train:  34%|███▎      | 83/247 [00:46<01:57,  1.39it/s]Loading train:  34%|███▍      | 84/247 [00:47<01:50,  1.47it/s]Loading train:  34%|███▍      | 85/247 [00:48<01:46,  1.52it/s]Loading train:  35%|███▍      | 86/247 [00:48<01:45,  1.53it/s]Loading train:  35%|███▌      | 87/247 [00:49<01:43,  1.54it/s]Loading train:  36%|███▌      | 88/247 [00:49<01:42,  1.56it/s]Loading train:  36%|███▌      | 89/247 [00:50<01:40,  1.57it/s]Loading train:  36%|███▋      | 90/247 [00:51<01:39,  1.58it/s]Loading train:  37%|███▋      | 91/247 [00:51<01:37,  1.61it/s]Loading train:  37%|███▋      | 92/247 [00:52<01:37,  1.59it/s]Loading train:  38%|███▊      | 93/247 [00:53<01:37,  1.58it/s]Loading train:  38%|███▊      | 94/247 [00:53<01:36,  1.58it/s]Loading train:  38%|███▊      | 95/247 [00:54<01:35,  1.59it/s]Loading train:  39%|███▉      | 96/247 [00:54<01:36,  1.57it/s]Loading train:  39%|███▉      | 97/247 [00:55<01:35,  1.58it/s]Loading train:  40%|███▉      | 98/247 [00:56<01:32,  1.61it/s]Loading train:  40%|████      | 99/247 [00:56<01:30,  1.63it/s]Loading train:  40%|████      | 100/247 [00:57<01:30,  1.63it/s]Loading train:  41%|████      | 101/247 [00:58<01:29,  1.63it/s]Loading train:  41%|████▏     | 102/247 [00:58<01:28,  1.63it/s]Loading train:  42%|████▏     | 103/247 [00:59<01:27,  1.65it/s]Loading train:  42%|████▏     | 104/247 [00:59<01:25,  1.67it/s]Loading train:  43%|████▎     | 105/247 [01:00<01:23,  1.69it/s]Loading train:  43%|████▎     | 106/247 [01:00<01:22,  1.71it/s]Loading train:  43%|████▎     | 107/247 [01:01<01:20,  1.73it/s]Loading train:  44%|████▎     | 108/247 [01:02<01:19,  1.75it/s]Loading train:  44%|████▍     | 109/247 [01:02<01:19,  1.74it/s]Loading train:  45%|████▍     | 110/247 [01:03<01:17,  1.77it/s]Loading train:  45%|████▍     | 111/247 [01:03<01:15,  1.81it/s]Loading train:  45%|████▌     | 112/247 [01:04<01:15,  1.78it/s]Loading train:  46%|████▌     | 113/247 [01:04<01:17,  1.73it/s]Loading train:  46%|████▌     | 114/247 [01:05<01:18,  1.70it/s]Loading train:  47%|████▋     | 115/247 [01:06<01:19,  1.66it/s]Loading train:  47%|████▋     | 116/247 [01:06<01:19,  1.65it/s]Loading train:  47%|████▋     | 117/247 [01:07<01:19,  1.63it/s]Loading train:  48%|████▊     | 118/247 [01:07<01:17,  1.67it/s]Loading train:  48%|████▊     | 119/247 [01:08<01:13,  1.75it/s]Loading train:  49%|████▊     | 120/247 [01:09<01:11,  1.77it/s]Loading train:  49%|████▉     | 121/247 [01:09<01:10,  1.80it/s]Loading train:  49%|████▉     | 122/247 [01:10<01:08,  1.82it/s]Loading train:  50%|████▉     | 123/247 [01:10<01:07,  1.83it/s]Loading train:  50%|█████     | 124/247 [01:11<01:06,  1.84it/s]Loading train:  51%|█████     | 125/247 [01:11<01:09,  1.75it/s]Loading train:  51%|█████     | 126/247 [01:12<01:08,  1.76it/s]Loading train:  51%|█████▏    | 127/247 [01:12<01:07,  1.77it/s]Loading train:  52%|█████▏    | 128/247 [01:13<01:06,  1.79it/s]Loading train:  52%|█████▏    | 129/247 [01:14<01:05,  1.81it/s]Loading train:  53%|█████▎    | 130/247 [01:14<01:04,  1.82it/s]Loading train:  53%|█████▎    | 131/247 [01:15<01:02,  1.85it/s]Loading train:  53%|█████▎    | 132/247 [01:15<01:01,  1.86it/s]Loading train:  54%|█████▍    | 133/247 [01:16<01:01,  1.84it/s]Loading train:  54%|█████▍    | 134/247 [01:16<01:01,  1.84it/s]Loading train:  55%|█████▍    | 135/247 [01:17<01:00,  1.85it/s]Loading train:  55%|█████▌    | 136/247 [01:17<00:58,  1.90it/s]Loading train:  55%|█████▌    | 137/247 [01:18<00:57,  1.92it/s]Loading train:  56%|█████▌    | 138/247 [01:18<00:56,  1.95it/s]Loading train:  56%|█████▋    | 139/247 [01:19<00:54,  1.99it/s]Loading train:  57%|█████▋    | 140/247 [01:19<00:53,  2.00it/s]Loading train:  57%|█████▋    | 141/247 [01:20<00:53,  1.99it/s]Loading train:  57%|█████▋    | 142/247 [01:20<00:53,  1.98it/s]Loading train:  58%|█████▊    | 143/247 [01:21<00:53,  1.95it/s]Loading train:  58%|█████▊    | 144/247 [01:21<00:52,  1.96it/s]Loading train:  59%|█████▊    | 145/247 [01:22<00:52,  1.93it/s]Loading train:  59%|█████▉    | 146/247 [01:22<00:52,  1.93it/s]Loading train:  60%|█████▉    | 147/247 [01:23<00:51,  1.94it/s]Loading train:  60%|█████▉    | 148/247 [01:23<00:50,  1.96it/s]Loading train:  60%|██████    | 149/247 [01:24<00:49,  1.96it/s]Loading train:  61%|██████    | 150/247 [01:24<00:50,  1.94it/s]Loading train:  61%|██████    | 151/247 [01:25<00:49,  1.93it/s]Loading train:  62%|██████▏   | 152/247 [01:25<00:48,  1.95it/s]Loading train:  62%|██████▏   | 153/247 [01:26<00:48,  1.94it/s]Loading train:  62%|██████▏   | 154/247 [01:27<00:50,  1.83it/s]Loading train:  63%|██████▎   | 155/247 [01:27<00:51,  1.77it/s]Loading train:  63%|██████▎   | 156/247 [01:28<00:51,  1.77it/s]Loading train:  64%|██████▎   | 157/247 [01:28<00:51,  1.76it/s]Loading train:  64%|██████▍   | 158/247 [01:29<00:50,  1.75it/s]Loading train:  64%|██████▍   | 159/247 [01:29<00:50,  1.75it/s]Loading train:  65%|██████▍   | 160/247 [01:30<00:50,  1.73it/s]Loading train:  65%|██████▌   | 161/247 [01:31<00:49,  1.72it/s]Loading train:  66%|██████▌   | 162/247 [01:31<00:49,  1.70it/s]Loading train:  66%|██████▌   | 163/247 [01:32<00:49,  1.71it/s]Loading train:  66%|██████▋   | 164/247 [01:32<00:48,  1.72it/s]Loading train:  67%|██████▋   | 165/247 [01:33<00:47,  1.71it/s]Loading train:  67%|██████▋   | 166/247 [01:34<00:47,  1.72it/s]Loading train:  68%|██████▊   | 167/247 [01:34<00:46,  1.73it/s]Loading train:  68%|██████▊   | 168/247 [01:35<00:46,  1.71it/s]Loading train:  68%|██████▊   | 169/247 [01:35<00:44,  1.75it/s]Loading train:  69%|██████▉   | 170/247 [01:36<00:43,  1.78it/s]Loading train:  69%|██████▉   | 171/247 [01:36<00:43,  1.76it/s]Loading train:  70%|██████▉   | 172/247 [01:37<00:48,  1.55it/s]Loading train:  70%|███████   | 173/247 [01:38<00:50,  1.46it/s]Loading train:  70%|███████   | 174/247 [01:39<00:51,  1.42it/s]Loading train:  71%|███████   | 175/247 [01:40<00:54,  1.33it/s]Loading train:  71%|███████▏  | 176/247 [01:40<00:49,  1.43it/s]Loading train:  72%|███████▏  | 177/247 [01:41<00:46,  1.52it/s]Loading train:  72%|███████▏  | 178/247 [01:41<00:43,  1.59it/s]Loading train:  72%|███████▏  | 179/247 [01:42<00:40,  1.66it/s]Loading train:  73%|███████▎  | 180/247 [01:42<00:39,  1.70it/s]Loading train:  73%|███████▎  | 181/247 [01:43<00:38,  1.73it/s]Loading train:  74%|███████▎  | 182/247 [01:43<00:37,  1.75it/s]Loading train:  74%|███████▍  | 183/247 [01:44<00:36,  1.73it/s]Loading train:  74%|███████▍  | 184/247 [01:45<00:35,  1.77it/s]Loading train:  75%|███████▍  | 185/247 [01:45<00:34,  1.78it/s]Loading train:  75%|███████▌  | 186/247 [01:46<00:33,  1.80it/s]Loading train:  76%|███████▌  | 187/247 [01:46<00:33,  1.78it/s]Loading train:  76%|███████▌  | 188/247 [01:47<00:32,  1.80it/s]Loading train:  77%|███████▋  | 189/247 [01:47<00:31,  1.82it/s]Loading train:  77%|███████▋  | 190/247 [01:48<00:31,  1.82it/s]Loading train:  77%|███████▋  | 191/247 [01:48<00:30,  1.81it/s]Loading train:  78%|███████▊  | 192/247 [01:49<00:30,  1.79it/s]Loading train:  78%|███████▊  | 193/247 [01:50<00:29,  1.81it/s]Loading train:  79%|███████▊  | 194/247 [01:50<00:29,  1.79it/s]Loading train:  79%|███████▉  | 195/247 [01:51<00:28,  1.82it/s]Loading train:  79%|███████▉  | 196/247 [01:51<00:28,  1.82it/s]Loading train:  80%|███████▉  | 197/247 [01:52<00:27,  1.81it/s]Loading train:  80%|████████  | 198/247 [01:52<00:26,  1.84it/s]Loading train:  81%|████████  | 199/247 [01:53<00:25,  1.86it/s]Loading train:  81%|████████  | 200/247 [01:53<00:25,  1.86it/s]Loading train:  81%|████████▏ | 201/247 [01:54<00:24,  1.87it/s]Loading train:  82%|████████▏ | 202/247 [01:54<00:24,  1.87it/s]Loading train:  82%|████████▏ | 203/247 [01:55<00:23,  1.87it/s]Loading train:  83%|████████▎ | 204/247 [01:56<00:22,  1.88it/s]Loading train:  83%|████████▎ | 205/247 [01:56<00:21,  1.91it/s]Loading train:  83%|████████▎ | 206/247 [01:57<00:21,  1.89it/s]Loading train:  84%|████████▍ | 207/247 [01:57<00:21,  1.85it/s]Loading train:  84%|████████▍ | 208/247 [01:58<00:20,  1.87it/s]Loading train:  85%|████████▍ | 209/247 [01:58<00:20,  1.85it/s]Loading train:  85%|████████▌ | 210/247 [01:59<00:20,  1.83it/s]Loading train:  85%|████████▌ | 211/247 [01:59<00:19,  1.87it/s]Loading train:  86%|████████▌ | 212/247 [02:04<01:00,  1.72s/it]Loading train:  86%|████████▌ | 213/247 [02:14<02:22,  4.20s/it]Loading train:  87%|████████▋ | 214/247 [02:18<02:15,  4.09s/it]Loading train:  87%|████████▋ | 215/247 [02:21<02:06,  3.96s/it]Loading train:  87%|████████▋ | 216/247 [02:25<02:01,  3.93s/it]Loading train:  88%|████████▊ | 217/247 [02:29<01:54,  3.81s/it]Loading train:  88%|████████▊ | 218/247 [02:32<01:49,  3.77s/it]Loading train:  89%|████████▊ | 219/247 [02:36<01:45,  3.75s/it]Loading train:  89%|████████▉ | 220/247 [02:40<01:39,  3.69s/it]Loading train:  89%|████████▉ | 221/247 [02:43<01:35,  3.67s/it]Loading train:  90%|████████▉ | 222/247 [02:47<01:30,  3.64s/it]Loading train:  90%|█████████ | 223/247 [02:50<01:25,  3.58s/it]Loading train:  91%|█████████ | 224/247 [02:52<01:08,  2.96s/it]Loading train:  91%|█████████ | 225/247 [02:52<00:49,  2.23s/it]Loading train:  91%|█████████▏| 226/247 [02:53<00:36,  1.72s/it]Loading train:  92%|█████████▏| 227/247 [02:53<00:27,  1.36s/it]Loading train:  92%|█████████▏| 228/247 [02:54<00:21,  1.12s/it]Loading train:  93%|█████████▎| 229/247 [02:54<00:17,  1.05it/s]Loading train:  93%|█████████▎| 230/247 [02:55<00:14,  1.17it/s]Loading train:  94%|█████████▎| 231/247 [02:56<00:12,  1.27it/s]Loading train:  94%|█████████▍| 232/247 [02:56<00:11,  1.36it/s]Loading train:  94%|█████████▍| 233/247 [02:57<00:09,  1.43it/s]Loading train:  95%|█████████▍| 234/247 [02:58<00:08,  1.46it/s]Loading train:  95%|█████████▌| 235/247 [02:58<00:08,  1.47it/s]Loading train:  96%|█████████▌| 236/247 [02:59<00:07,  1.50it/s]Loading train:  96%|█████████▌| 237/247 [02:59<00:06,  1.54it/s]Loading train:  96%|█████████▋| 238/247 [03:00<00:05,  1.55it/s]Loading train:  97%|█████████▋| 239/247 [03:01<00:05,  1.56it/s]Loading train:  97%|█████████▋| 240/247 [03:01<00:04,  1.56it/s]Loading train:  98%|█████████▊| 241/247 [03:02<00:03,  1.55it/s]Loading train:  98%|█████████▊| 242/247 [03:03<00:03,  1.55it/s]Loading train:  98%|█████████▊| 243/247 [03:03<00:02,  1.57it/s]Loading train:  99%|█████████▉| 244/247 [03:04<00:01,  1.60it/s]Loading train:  99%|█████████▉| 245/247 [03:04<00:01,  1.62it/s]Loading train: 100%|█████████▉| 246/247 [03:05<00:00,  1.64it/s]Loading train: 100%|██████████| 247/247 [03:06<00:00,  1.65it/s]Loading train: 100%|██████████| 247/247 [03:06<00:00,  1.33it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 53.77it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 53.71it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 54.00it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:04, 54.79it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:03, 55.44it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:03, 54.90it/s]concatenating: train:  17%|█▋        | 42/247 [00:00<00:03, 56.18it/s]concatenating: train:  19%|█▉        | 48/247 [00:00<00:03, 56.94it/s]concatenating: train:  22%|██▏       | 54/247 [00:00<00:03, 57.30it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 56.65it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 54.53it/s]concatenating: train:  29%|██▉       | 72/247 [00:01<00:03, 53.54it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:03, 53.30it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:03, 53.21it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:02, 52.99it/s]concatenating: train:  39%|███▉      | 96/247 [00:01<00:02, 52.69it/s]concatenating: train:  41%|████▏     | 102/247 [00:01<00:02, 52.70it/s]concatenating: train:  44%|████▎     | 108/247 [00:01<00:02, 53.42it/s]concatenating: train:  46%|████▌     | 114/247 [00:02<00:02, 53.76it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:02, 53.14it/s]concatenating: train:  51%|█████     | 126/247 [00:02<00:02, 52.47it/s]concatenating: train:  53%|█████▎    | 132/247 [00:02<00:02, 51.98it/s]concatenating: train:  56%|█████▌    | 138/247 [00:02<00:02, 51.87it/s]concatenating: train:  58%|█████▊    | 144/247 [00:02<00:01, 52.68it/s]concatenating: train:  61%|██████    | 150/247 [00:02<00:01, 52.76it/s]concatenating: train:  63%|██████▎   | 156/247 [00:02<00:01, 53.01it/s]concatenating: train:  66%|██████▌   | 162/247 [00:03<00:01, 53.25it/s]concatenating: train:  68%|██████▊   | 168/247 [00:03<00:01, 53.32it/s]concatenating: train:  70%|███████   | 174/247 [00:03<00:01, 53.21it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 50.41it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:01, 48.19it/s]concatenating: train:  77%|███████▋  | 191/247 [00:03<00:01, 46.57it/s]concatenating: train:  79%|███████▉  | 196/247 [00:03<00:01, 44.96it/s]concatenating: train:  81%|████████▏ | 201/247 [00:03<00:01, 43.79it/s]concatenating: train:  83%|████████▎ | 206/247 [00:03<00:00, 42.84it/s]concatenating: train:  85%|████████▌ | 211/247 [00:04<00:00, 42.77it/s]concatenating: train:  87%|████████▋ | 216/247 [00:04<00:00, 43.75it/s]concatenating: train:  89%|████████▉ | 221/247 [00:04<00:00, 44.74it/s]concatenating: train:  91%|█████████▏| 226/247 [00:04<00:00, 44.82it/s]concatenating: train:  94%|█████████▎| 231/247 [00:04<00:00, 45.35it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 48.16it/s]concatenating: train:  98%|█████████▊| 243/247 [00:04<00:00, 50.56it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 51.35it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:05<00:23,  5.98s/it]Loading test:  40%|████      | 2/5 [00:20<00:25,  8.41s/it]Loading test:  60%|██████    | 3/5 [00:25<00:15,  7.53s/it]Loading test:  80%|████████  | 4/5 [00:29<00:06,  6.31s/it]Loading test: 100%|██████████| 5/5 [00:38<00:00,  7.15s/it]Loading test: 100%|██████████| 5/5 [00:38<00:00,  7.62s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 61.82it/s]
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________2020-01-22 00:29:39.045138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 00:29:39.045247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 00:29:39.045262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 00:29:39.045271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 00:29:39.045611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.52854343e-02 3.19650200e-02 7.71334061e-02 9.61673667e-03
 2.75335221e-02 7.05179230e-03 8.86411518e-02 1.14506162e-01
 8.20498434e-02 1.27674274e-02 2.89803635e-01 1.93391098e-01
 2.54771142e-04]
Train on 9577 samples, validate on 186 samples
Epoch 1/300
 - 28s - loss: 0.5435 - acc: 0.9122 - mDice: 0.4145 - val_loss: 0.6828 - val_acc: 0.9370 - val_mDice: 0.2625

Epoch 00001: val_mDice improved from -inf to 0.26247, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 23s - loss: 0.3851 - acc: 0.9381 - mDice: 0.5851 - val_loss: 0.6714 - val_acc: 0.9409 - val_mDice: 0.2747

Epoch 00002: val_mDice improved from 0.26247 to 0.27469, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 23s - loss: 0.3494 - acc: 0.9423 - mDice: 0.6236 - val_loss: 0.6520 - val_acc: 0.9369 - val_mDice: 0.2956

Epoch 00003: val_mDice improved from 0.27469 to 0.29557, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 23s - loss: 0.3286 - acc: 0.9448 - mDice: 0.6460 - val_loss: 0.6687 - val_acc: 0.9400 - val_mDice: 0.2742

Epoch 00004: val_mDice did not improve from 0.29557
Epoch 5/300
 - 23s - loss: 0.3227 - acc: 0.9465 - mDice: 0.6524 - val_loss: 0.6339 - val_acc: 0.9427 - val_mDice: 0.2846

Epoch 00005: val_mDice did not improve from 0.29557
Epoch 6/300
 - 23s - loss: 0.3069 - acc: 0.9480 - mDice: 0.6694 - val_loss: 0.5809 - val_acc: 0.9460 - val_mDice: 0.2947

Epoch 00006: val_mDice did not improve from 0.29557
Epoch 7/300
 - 22s - loss: 0.3038 - acc: 0.9489 - mDice: 0.6728 - val_loss: 0.6470 - val_acc: 0.9422 - val_mDice: 0.2872

Epoch 00007: val_mDice did not improve from 0.29557
Epoch 8/300
 - 23s - loss: 0.2947 - acc: 0.9492 - mDice: 0.6826 - val_loss: 0.6865 - val_acc: 0.9395 - val_mDice: 0.2529

Epoch 00008: val_mDice did not improve from 0.29557
Epoch 9/300
 - 22s - loss: 0.2874 - acc: 0.9505 - mDice: 0.6904 - val_loss: 0.5827 - val_acc: 0.9419 - val_mDice: 0.2863

Epoch 00009: val_mDice did not improve from 0.29557
Epoch 10/300
 - 23s - loss: 0.2870 - acc: 0.9505 - mDice: 0.6909 - val_loss: 0.4688 - val_acc: 0.9450 - val_mDice: 0.2828

Epoch 00010: val_mDice did not improve from 0.29557
Epoch 11/300
 - 22s - loss: 0.2752 - acc: 0.9516 - mDice: 0.7036 - val_loss: 0.4646 - val_acc: 0.9465 - val_mDice: 0.2964

Epoch 00011: val_mDice improved from 0.29557 to 0.29638, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 23s - loss: 0.2735 - acc: 0.9521 - mDice: 0.7055 - val_loss: 0.4411 - val_acc: 0.9423 - val_mDice: 0.2741

Epoch 00012: val_mDice did not improve from 0.29638
Epoch 13/300
 - 22s - loss: 0.2704 - acc: 0.9525 - mDice: 0.7088 - val_loss: 0.3625 - val_acc: 0.9442 - val_mDice: 0.2867

Epoch 00013: val_mDice did not improve from 0.29638
Epoch 14/300
 - 23s - loss: 0.2687 - acc: 0.9528 - mDice: 0.7106 - val_loss: 0.3262 - val_acc: 0.9453 - val_mDice: 0.2926

Epoch 00014: val_mDice did not improve from 0.29638
Epoch 15/300
 - 22s - loss: 0.2657 - acc: 0.9531 - mDice: 0.7139 - val_loss: 0.4732 - val_acc: 0.9438 - val_mDice: 0.2863

Epoch 00015: val_mDice did not improve from 0.29638
Epoch 16/300
 - 23s - loss: 0.2644 - acc: 0.9535 - mDice: 0.7153 - val_loss: 0.4002 - val_acc: 0.9428 - val_mDice: 0.2845

Epoch 00016: val_mDice did not improve from 0.29638
Epoch 17/300
 - 22s - loss: 0.2641 - acc: 0.9533 - mDice: 0.7155 - val_loss: 0.1599 - val_acc: 0.9455 - val_mDice: 0.2785

Epoch 00017: val_mDice did not improve from 0.29638
Epoch 18/300
 - 23s - loss: 0.2557 - acc: 0.9540 - mDice: 0.7246 - val_loss: 0.2674 - val_acc: 0.9436 - val_mDice: 0.2743

Epoch 00018: val_mDice did not improve from 0.29638

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 19/300
 - 22s - loss: 0.2463 - acc: 0.9554 - mDice: 0.7348 - val_loss: 0.1748 - val_acc: 0.9457 - val_mDice: 0.2876

Epoch 00019: val_mDice did not improve from 0.29638
Epoch 20/300
 - 22s - loss: 0.2450 - acc: 0.9557 - mDice: 0.7362 - val_loss: 0.1515 - val_acc: 0.9459 - val_mDice: 0.2858

Epoch 00020: val_mDice did not improve from 0.29638
Epoch 21/300
 - 23s - loss: 0.2384 - acc: 0.9561 - mDice: 0.7433 - val_loss: 0.1197 - val_acc: 0.9460 - val_mDice: 0.2831

Epoch 00021: val_mDice did not improve from 0.29638
Epoch 22/300
 - 22s - loss: 0.2356 - acc: 0.9563 - mDice: 0.7464 - val_loss: 0.1546 - val_acc: 0.9457 - val_mDice: 0.2861

Epoch 00022: val_mDice did not improve from 0.29638
Epoch 23/300
 - 22s - loss: 0.2338 - acc: 0.9565 - mDice: 0.7483 - val_loss: 0.1571 - val_acc: 0.9458 - val_mDice: 0.2832

Epoch 00023: val_mDice did not improve from 0.29638
Epoch 24/300
 - 23s - loss: 0.2342 - acc: 0.9566 - mDice: 0.7478 - val_loss: 0.1947 - val_acc: 0.9460 - val_mDice: 0.2867

Epoch 00024: val_mDice did not improve from 0.29638
Epoch 25/300
 - 22s - loss: 0.2308 - acc: 0.9569 - mDice: 0.7515 - val_loss: 0.1005 - val_acc: 0.9449 - val_mDice: 0.2875

Epoch 00025: val_mDice did not improve from 0.29638
Epoch 26/300
 - 22s - loss: 0.2289 - acc: 0.9570 - mDice: 0.7536 - val_loss: 0.1149 - val_acc: 0.9455 - val_mDice: 0.2887

Epoch 00026: val_mDice did not improve from 0.29638
Epoch 27/300
 - 23s - loss: 0.2312 - acc: 0.9570 - mDice: 0.7511 - val_loss: 0.2060 - val_acc: 0.9454 - val_mDice: 0.2960

Epoch 00027: val_mDice did not improve from 0.29638
Epoch 28/300
 - 22s - loss: 0.2299 - acc: 0.9568 - mDice: 0.7525 - val_loss: 0.1222 - val_acc: 0.9462 - val_mDice: 0.2823

Epoch 00028: val_mDice did not improve from 0.29638
Epoch 29/300
 - 22s - loss: 0.2287 - acc: 0.9573 - mDice: 0.7537 - val_loss: 0.0970 - val_acc: 0.9459 - val_mDice: 0.2763

Epoch 00029: val_mDice did not improve from 0.29638
Epoch 30/300
 - 23s - loss: 0.2276 - acc: 0.9572 - mDice: 0.7549 - val_loss: 0.0961 - val_acc: 0.9466 - val_mDice: 0.2808

Epoch 00030: val_mDice did not improve from 0.29638
Epoch 31/300
 - 23s - loss: 0.2264 - acc: 0.9573 - mDice: 0.7563 - val_loss: 0.1157 - val_acc: 0.9464 - val_mDice: 0.2845

Epoch 00031: val_mDice did not improve from 0.29638
Epoch 32/300
 - 22s - loss: 0.2283 - acc: 0.9574 - mDice: 0.7541 - val_loss: 0.0933 - val_acc: 0.9462 - val_mDice: 0.2897

Epoch 00032: val_mDice did not improve from 0.29638
Epoch 33/300
 - 22s - loss: 0.2254 - acc: 0.9577 - mDice: 0.7573 - val_loss: 0.1138 - val_acc: 0.9451 - val_mDice: 0.2853

Epoch 00033: val_mDice did not improve from 0.29638

Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 34/300
 - 22s - loss: 0.2174 - acc: 0.9581 - mDice: 0.7660 - val_loss: 0.0554 - val_acc: 0.9457 - val_mDice: 0.2820

Epoch 00034: val_mDice did not improve from 0.29638
Epoch 35/300
 - 22s - loss: 0.2174 - acc: 0.9583 - mDice: 0.7660 - val_loss: 0.0846 - val_acc: 0.9466 - val_mDice: 0.2895

Epoch 00035: val_mDice did not improve from 0.29638
Epoch 36/300
 - 22s - loss: 0.2164 - acc: 0.9585 - mDice: 0.7671 - val_loss: 0.0465 - val_acc: 0.9467 - val_mDice: 0.2812

Epoch 00036: val_mDice did not improve from 0.29638
Epoch 37/300
 - 23s - loss: 0.2164 - acc: 0.9586 - mDice: 0.7670 - val_loss: 0.0703 - val_acc: 0.9467 - val_mDice: 0.2814

Epoch 00037: val_mDice did not improve from 0.29638
Epoch 38/300
 - 22s - loss: 0.2166 - acc: 0.9586 - mDice: 0.7668 - val_loss: 0.0654 - val_acc: 0.9459 - val_mDice: 0.2729

Epoch 00038: val_mDice did not improve from 0.29638
Epoch 39/300
 - 22s - loss: 0.2160 - acc: 0.9587 - mDice: 0.7674 - val_loss: 0.0736 - val_acc: 0.9467 - val_mDice: 0.2839

Epoch 00039: val_mDice did not improve from 0.29638
Epoch 40/300
 - 22s - loss: 0.2176 - acc: 0.9586 - mDice: 0.7657 - val_loss: 0.0866 - val_acc: 0.9463 - val_mDice: 0.2893

Epoch 00040: val_mDice did not improve from 0.29638
Epoch 41/300
 - 23s - loss: 0.2099 - acc: 0.9589 - mDice: 0.7741 - val_loss: 0.0557 - val_acc: 0.9469 - val_mDice: 0.2851

Epoch 00041: val_mDice did not improve from 0.29638
Epoch 42/300
 - 22s - loss: 0.2117 - acc: 0.9590 - mDice: 0.7720 - val_loss: 0.0502 - val_acc: 0.9455 - val_mDice: 0.2808

Epoch 00042: val_mDice did not improve from 0.29638
Epoch 43/300
 - 22s - loss: 0.2113 - acc: 0.9589 - mDice: 0.7725 - val_loss: 0.0314 - val_acc: 0.9468 - val_mDice: 0.2808

Epoch 00043: val_mDice did not improve from 0.29638
Epoch 44/300
 - 22s - loss: 0.2130 - acc: 0.9590 - mDice: 0.7706 - val_loss: 0.0717 - val_acc: 0.9461 - val_mDice: 0.2820

Epoch 00044: val_mDice did not improve from 0.29638
Epoch 45/300
 - 22s - loss: 0.2114 - acc: 0.9589 - mDice: 0.7724 - val_loss: 0.0800 - val_acc: 0.9469 - val_mDice: 0.2854

Epoch 00045: val_mDice did not improve from 0.29638
Epoch 46/300
 - 22s - loss: 0.2084 - acc: 0.9591 - mDice: 0.7756 - val_loss: 0.0421 - val_acc: 0.9469 - val_mDice: 0.2835

Epoch 00046: val_mDice did not improve from 0.29638
Epoch 47/300
 - 22s - loss: 0.2092 - acc: 0.9590 - mDice: 0.7740 - val_loss: 0.0823 - val_acc: 0.9463 - val_mDice: 0.2817

Epoch 00047: val_mDice did not improve from 0.29638
Epoch 48/300
 - 23s - loss: 0.2119 - acc: 0.9579 - mDice: 0.7608 - val_loss: 0.0634 - val_acc: 0.9463 - val_mDice: 0.2778

Epoch 00048: val_mDice did not improve from 0.29638

Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 49/300
 - 22s - loss: 0.1991 - acc: 0.9583 - mDice: 0.7670 - val_loss: 0.0578 - val_acc: 0.9462 - val_mDice: 0.2796

Epoch 00049: val_mDice did not improve from 0.29638
Epoch 50/300
 - 22s - loss: 0.1918 - acc: 0.9586 - mDice: 0.7708 - val_loss: 0.0278 - val_acc: 0.9458 - val_mDice: 0.2776

Epoch 00050: val_mDice did not improve from 0.29638
Epoch 51/300
 - 22s - loss: 0.1928 - acc: 0.9586 - mDice: 0.7687 - val_loss: 0.0323 - val_acc: 0.9471 - val_mDice: 0.2843

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:05,  1.44s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:03,  1.33s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.24s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.10s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:19,  3.09it/s]Loading train:   1%|          | 2/247 [00:00<01:17,  3.18it/s]Loading train:   1%|          | 3/247 [00:00<01:14,  3.29it/s]Loading train:   2%|▏         | 4/247 [00:01<01:14,  3.26it/s]Loading train:   2%|▏         | 5/247 [00:01<01:13,  3.28it/s]Loading train:   2%|▏         | 6/247 [00:01<01:12,  3.33it/s]Loading train:   3%|▎         | 7/247 [00:02<01:11,  3.35it/s]Loading train:   3%|▎         | 8/247 [00:02<01:11,  3.35it/s]Loading train:   4%|▎         | 9/247 [00:02<01:10,  3.36it/s]Loading train:   4%|▍         | 10/247 [00:02<01:09,  3.39it/s]Loading train:   4%|▍         | 11/247 [00:03<01:09,  3.39it/s]Loading train:   5%|▍         | 12/247 [00:03<01:08,  3.41it/s]Loading train:   5%|▌         | 13/247 [00:03<01:08,  3.40it/s]Loading train:   6%|▌         | 14/247 [00:04<01:08,  3.39it/s]Loading train:   6%|▌         | 15/247 [00:04<01:09,  3.35it/s]Loading train:   6%|▋         | 16/247 [00:04<01:08,  3.36it/s]Loading train:   7%|▋         | 17/247 [00:05<01:08,  3.36it/s]Loading train:   7%|▋         | 18/247 [00:05<01:07,  3.39it/s]Loading train:   8%|▊         | 19/247 [00:05<01:06,  3.41it/s]Loading train:   8%|▊         | 20/247 [00:05<01:06,  3.44it/s]Loading train:   9%|▊         | 21/247 [00:06<01:05,  3.46it/s]Loading train:   9%|▉         | 22/247 [00:06<01:04,  3.51it/s]Loading train:   9%|▉         | 23/247 [00:06<01:01,  3.66it/s]Loading train:  10%|▉         | 24/247 [00:06<00:59,  3.78it/s]Loading train:  10%|█         | 25/247 [00:07<00:57,  3.86it/s]Loading train:  11%|█         | 26/247 [00:07<00:56,  3.89it/s]Loading train:  11%|█         | 27/247 [00:07<00:56,  3.92it/s]Loading train:  11%|█▏        | 28/247 [00:07<00:55,  3.95it/s]Loading train:  12%|█▏        | 29/247 [00:08<00:55,  3.92it/s]Loading train:  12%|█▏        | 30/247 [00:08<00:55,  3.90it/s]Loading train:  13%|█▎        | 31/247 [00:08<00:55,  3.89it/s]Loading train:  13%|█▎        | 32/247 [00:08<00:55,  3.89it/s]Loading train:  13%|█▎        | 33/247 [00:09<00:55,  3.87it/s]Loading train:  14%|█▍        | 34/247 [00:09<00:54,  3.88it/s]Loading train:  14%|█▍        | 35/247 [00:09<00:54,  3.88it/s]Loading train:  15%|█▍        | 36/247 [00:10<00:54,  3.87it/s]Loading train:  15%|█▍        | 37/247 [00:10<00:54,  3.86it/s]Loading train:  15%|█▌        | 38/247 [00:10<00:54,  3.86it/s]Loading train:  16%|█▌        | 39/247 [00:10<00:53,  3.86it/s]Loading train:  16%|█▌        | 40/247 [00:11<00:53,  3.86it/s]Loading train:  17%|█▋        | 41/247 [00:11<00:53,  3.82it/s]Loading train:  17%|█▋        | 42/247 [00:11<00:54,  3.78it/s]Loading train:  17%|█▋        | 43/247 [00:11<00:54,  3.74it/s]Loading train:  18%|█▊        | 44/247 [00:12<00:54,  3.70it/s]Loading train:  18%|█▊        | 45/247 [00:12<00:54,  3.68it/s]Loading train:  19%|█▊        | 46/247 [00:12<00:54,  3.68it/s]Loading train:  19%|█▉        | 47/247 [00:12<00:54,  3.67it/s]Loading train:  19%|█▉        | 48/247 [00:13<00:54,  3.68it/s]Loading train:  20%|█▉        | 49/247 [00:13<00:53,  3.73it/s]Loading train:  20%|██        | 50/247 [00:13<00:52,  3.75it/s]Loading train:  21%|██        | 51/247 [00:14<00:52,  3.76it/s]Loading train:  21%|██        | 52/247 [00:14<00:51,  3.78it/s]Loading train:  21%|██▏       | 53/247 [00:14<00:51,  3.78it/s]Loading train:  22%|██▏       | 54/247 [00:14<00:50,  3.79it/s]Loading train:  22%|██▏       | 55/247 [00:15<00:50,  3.79it/s]Loading train:  23%|██▎       | 56/247 [00:15<00:50,  3.78it/s]Loading train:  23%|██▎       | 57/247 [00:15<00:49,  3.80it/s]Loading train:  23%|██▎       | 58/247 [00:15<00:49,  3.79it/s]Loading train:  24%|██▍       | 59/247 [00:16<00:50,  3.72it/s]Loading train:  24%|██▍       | 60/247 [00:16<00:50,  3.68it/s]Loading train:  25%|██▍       | 61/247 [00:16<00:51,  3.64it/s]Loading train:  25%|██▌       | 62/247 [00:17<00:51,  3.62it/s]Loading train:  26%|██▌       | 63/247 [00:17<00:50,  3.61it/s]Loading train:  26%|██▌       | 64/247 [00:17<00:51,  3.52it/s]Loading train:  26%|██▋       | 65/247 [00:17<00:52,  3.48it/s]Loading train:  27%|██▋       | 66/247 [00:18<00:52,  3.42it/s]Loading train:  27%|██▋       | 67/247 [00:18<00:52,  3.40it/s]Loading train:  28%|██▊       | 68/247 [00:18<00:52,  3.43it/s]Loading train:  28%|██▊       | 69/247 [00:19<00:51,  3.44it/s]Loading train:  28%|██▊       | 70/247 [00:19<00:51,  3.46it/s]Loading train:  29%|██▊       | 71/247 [00:19<00:50,  3.46it/s]Loading train:  29%|██▉       | 72/247 [00:19<00:50,  3.48it/s]Loading train:  30%|██▉       | 73/247 [00:20<00:50,  3.47it/s]Loading train:  30%|██▉       | 74/247 [00:20<00:49,  3.48it/s]Loading train:  30%|███       | 75/247 [00:20<00:49,  3.50it/s]Loading train:  31%|███       | 76/247 [00:21<00:48,  3.51it/s]Loading train:  31%|███       | 77/247 [00:21<00:51,  3.30it/s]Loading train:  32%|███▏      | 78/247 [00:21<00:52,  3.23it/s]Loading train:  32%|███▏      | 79/247 [00:22<00:51,  3.25it/s]Loading train:  32%|███▏      | 80/247 [00:22<00:50,  3.33it/s]Loading train:  33%|███▎      | 81/247 [00:22<00:51,  3.21it/s]Loading train:  33%|███▎      | 82/247 [00:22<00:51,  3.20it/s]Loading train:  34%|███▎      | 83/247 [00:23<00:51,  3.17it/s]Loading train:  34%|███▍      | 84/247 [00:23<00:51,  3.15it/s]Loading train:  34%|███▍      | 85/247 [00:23<00:51,  3.13it/s]Loading train:  35%|███▍      | 86/247 [00:24<00:51,  3.13it/s]Loading train:  35%|███▌      | 87/247 [00:24<00:51,  3.11it/s]Loading train:  36%|███▌      | 88/247 [00:24<00:51,  3.06it/s]Loading train:  36%|███▌      | 89/247 [00:25<00:51,  3.05it/s]Loading train:  36%|███▋      | 90/247 [00:25<00:51,  3.03it/s]Loading train:  37%|███▋      | 91/247 [00:25<00:52,  3.00it/s]Loading train:  37%|███▋      | 92/247 [00:26<00:51,  2.99it/s]Loading train:  38%|███▊      | 93/247 [00:26<00:51,  2.98it/s]Loading train:  38%|███▊      | 94/247 [00:26<00:50,  3.02it/s]Loading train:  38%|███▊      | 95/247 [00:27<00:49,  3.04it/s]Loading train:  39%|███▉      | 96/247 [00:27<00:49,  3.05it/s]Loading train:  39%|███▉      | 97/247 [00:27<00:48,  3.08it/s]Loading train:  40%|███▉      | 98/247 [00:28<00:48,  3.10it/s]Loading train:  40%|████      | 99/247 [00:28<00:47,  3.12it/s]Loading train:  40%|████      | 100/247 [00:28<00:46,  3.18it/s]Loading train:  41%|████      | 101/247 [00:29<00:45,  3.22it/s]Loading train:  41%|████▏     | 102/247 [00:29<00:44,  3.25it/s]Loading train:  42%|████▏     | 103/247 [00:29<00:44,  3.27it/s]Loading train:  42%|████▏     | 104/247 [00:30<00:43,  3.27it/s]Loading train:  43%|████▎     | 105/247 [00:30<00:43,  3.28it/s]Loading train:  43%|████▎     | 106/247 [00:30<00:43,  3.27it/s]Loading train:  43%|████▎     | 107/247 [00:30<00:42,  3.28it/s]Loading train:  44%|████▎     | 108/247 [00:31<00:42,  3.29it/s]Loading train:  44%|████▍     | 109/247 [00:31<00:41,  3.30it/s]Loading train:  45%|████▍     | 110/247 [00:31<00:41,  3.31it/s]Loading train:  45%|████▍     | 111/247 [00:32<00:40,  3.32it/s]Loading train:  45%|████▌     | 112/247 [00:32<00:40,  3.32it/s]Loading train:  46%|████▌     | 113/247 [00:32<00:40,  3.33it/s]Loading train:  46%|████▌     | 114/247 [00:33<00:40,  3.31it/s]Loading train:  47%|████▋     | 115/247 [00:33<00:39,  3.32it/s]Loading train:  47%|████▋     | 116/247 [00:33<00:39,  3.31it/s]Loading train:  47%|████▋     | 117/247 [00:33<00:39,  3.32it/s]Loading train:  48%|████▊     | 118/247 [00:34<00:38,  3.39it/s]Loading train:  48%|████▊     | 119/247 [00:34<00:36,  3.46it/s]Loading train:  49%|████▊     | 120/247 [00:34<00:36,  3.50it/s]Loading train:  49%|████▉     | 121/247 [00:35<00:35,  3.54it/s]Loading train:  49%|████▉     | 122/247 [00:35<00:35,  3.55it/s]Loading train:  50%|████▉     | 123/247 [00:35<00:34,  3.57it/s]Loading train:  50%|█████     | 124/247 [00:35<00:34,  3.58it/s]Loading train:  51%|█████     | 125/247 [00:36<00:33,  3.60it/s]Loading train:  51%|█████     | 126/247 [00:36<00:33,  3.60it/s]Loading train:  51%|█████▏    | 127/247 [00:36<00:33,  3.59it/s]Loading train:  52%|█████▏    | 128/247 [00:37<00:33,  3.59it/s]Loading train:  52%|█████▏    | 129/247 [00:37<00:32,  3.61it/s]Loading train:  53%|█████▎    | 130/247 [00:37<00:32,  3.60it/s]Loading train:  53%|█████▎    | 131/247 [00:37<00:32,  3.60it/s]Loading train:  53%|█████▎    | 132/247 [00:38<00:31,  3.60it/s]Loading train:  54%|█████▍    | 133/247 [00:38<00:31,  3.61it/s]Loading train:  54%|█████▍    | 134/247 [00:38<00:31,  3.61it/s]Loading train:  55%|█████▍    | 135/247 [00:38<00:30,  3.63it/s]Loading train:  55%|█████▌    | 136/247 [00:39<00:30,  3.66it/s]Loading train:  55%|█████▌    | 137/247 [00:39<00:29,  3.72it/s]Loading train:  56%|█████▌    | 138/247 [00:39<00:29,  3.73it/s]Loading train:  56%|█████▋    | 139/247 [00:39<00:28,  3.77it/s]Loading train:  57%|█████▋    | 140/247 [00:40<00:28,  3.79it/s]Loading train:  57%|█████▋    | 141/247 [00:40<00:28,  3.77it/s]Loading train:  57%|█████▋    | 142/247 [00:40<00:27,  3.79it/s]Loading train:  58%|█████▊    | 143/247 [00:41<00:27,  3.79it/s]Loading train:  58%|█████▊    | 144/247 [00:41<00:27,  3.80it/s]Loading train:  59%|█████▊    | 145/247 [00:41<00:26,  3.79it/s]Loading train:  59%|█████▉    | 146/247 [00:41<00:26,  3.82it/s]Loading train:  60%|█████▉    | 147/247 [00:42<00:26,  3.81it/s]Loading train:  60%|█████▉    | 148/247 [00:42<00:26,  3.74it/s]Loading train:  60%|██████    | 149/247 [00:42<00:26,  3.69it/s]Loading train:  61%|██████    | 150/247 [00:42<00:26,  3.67it/s]Loading train:  61%|██████    | 151/247 [00:43<00:26,  3.67it/s]Loading train:  62%|██████▏   | 152/247 [00:43<00:26,  3.62it/s]Loading train:  62%|██████▏   | 153/247 [00:43<00:25,  3.62it/s]Loading train:  62%|██████▏   | 154/247 [00:44<00:27,  3.39it/s]Loading train:  63%|██████▎   | 155/247 [00:44<00:28,  3.27it/s]Loading train:  63%|██████▎   | 156/247 [00:44<00:28,  3.20it/s]Loading train:  64%|██████▎   | 157/247 [00:45<00:28,  3.14it/s]Loading train:  64%|██████▍   | 158/247 [00:45<00:28,  3.11it/s]Loading train:  64%|██████▍   | 159/247 [00:45<00:28,  3.10it/s]Loading train:  65%|██████▍   | 160/247 [00:46<00:28,  3.08it/s]Loading train:  65%|██████▌   | 161/247 [00:46<00:28,  3.04it/s]Loading train:  66%|██████▌   | 162/247 [00:46<00:27,  3.05it/s]Loading train:  66%|██████▌   | 163/247 [00:47<00:27,  3.04it/s]Loading train:  66%|██████▋   | 164/247 [00:47<00:27,  3.06it/s]Loading train:  67%|██████▋   | 165/247 [00:47<00:26,  3.06it/s]Loading train:  67%|██████▋   | 166/247 [00:48<00:26,  3.05it/s]Loading train:  68%|██████▊   | 167/247 [00:48<00:26,  3.04it/s]Loading train:  68%|██████▊   | 168/247 [00:48<00:25,  3.04it/s]Loading train:  68%|██████▊   | 169/247 [00:49<00:25,  3.04it/s]Loading train:  69%|██████▉   | 170/247 [00:49<00:25,  3.01it/s]Loading train:  69%|██████▉   | 171/247 [00:49<00:25,  3.03it/s]Loading train:  70%|██████▉   | 172/247 [00:49<00:23,  3.13it/s]Loading train:  70%|███████   | 173/247 [00:50<00:22,  3.26it/s]Loading train:  70%|███████   | 174/247 [00:50<00:22,  3.31it/s]Loading train:  71%|███████   | 175/247 [00:50<00:22,  3.19it/s]Loading train:  71%|███████▏  | 176/247 [00:51<00:21,  3.30it/s]Loading train:  72%|███████▏  | 177/247 [00:51<00:20,  3.38it/s]Loading train:  72%|███████▏  | 178/247 [00:51<00:20,  3.43it/s]Loading train:  72%|███████▏  | 179/247 [00:52<00:19,  3.45it/s]Loading train:  73%|███████▎  | 180/247 [00:52<00:19,  3.48it/s]Loading train:  73%|███████▎  | 181/247 [00:52<00:18,  3.49it/s]Loading train:  74%|███████▎  | 182/247 [00:52<00:18,  3.51it/s]Loading train:  74%|███████▍  | 183/247 [00:53<00:18,  3.52it/s]Loading train:  74%|███████▍  | 184/247 [00:53<00:17,  3.54it/s]Loading train:  75%|███████▍  | 185/247 [00:53<00:17,  3.54it/s]Loading train:  75%|███████▌  | 186/247 [00:53<00:17,  3.55it/s]Loading train:  76%|███████▌  | 187/247 [00:54<00:17,  3.52it/s]Loading train:  76%|███████▌  | 188/247 [00:54<00:16,  3.53it/s]Loading train:  77%|███████▋  | 189/247 [00:54<00:16,  3.55it/s]Loading train:  77%|███████▋  | 190/247 [00:55<00:15,  3.56it/s]Loading train:  77%|███████▋  | 191/247 [00:55<00:15,  3.58it/s]Loading train:  78%|███████▊  | 192/247 [00:55<00:15,  3.58it/s]Loading train:  78%|███████▊  | 193/247 [00:55<00:15,  3.56it/s]Loading train:  79%|███████▊  | 194/247 [00:56<00:14,  3.62it/s]Loading train:  79%|███████▉  | 195/247 [00:56<00:14,  3.67it/s]Loading train:  79%|███████▉  | 196/247 [00:56<00:13,  3.73it/s]Loading train:  80%|███████▉  | 197/247 [00:57<00:13,  3.78it/s]Loading train:  80%|████████  | 198/247 [00:57<00:12,  3.81it/s]Loading train:  81%|████████  | 199/247 [00:57<00:12,  3.82it/s]Loading train:  81%|████████  | 200/247 [00:57<00:12,  3.83it/s]Loading train:  81%|████████▏ | 201/247 [00:58<00:12,  3.82it/s]Loading train:  82%|████████▏ | 202/247 [00:58<00:11,  3.82it/s]Loading train:  82%|████████▏ | 203/247 [00:58<00:11,  3.83it/s]Loading train:  83%|████████▎ | 204/247 [00:58<00:11,  3.85it/s]Loading train:  83%|████████▎ | 205/247 [00:59<00:10,  3.85it/s]Loading train:  83%|████████▎ | 206/247 [00:59<00:10,  3.86it/s]Loading train:  84%|████████▍ | 207/247 [00:59<00:10,  3.84it/s]Loading train:  84%|████████▍ | 208/247 [00:59<00:10,  3.85it/s]Loading train:  85%|████████▍ | 209/247 [01:00<00:09,  3.86it/s]Loading train:  85%|████████▌ | 210/247 [01:00<00:09,  3.87it/s]Loading train:  85%|████████▌ | 211/247 [01:00<00:09,  3.85it/s]Loading train:  86%|████████▌ | 212/247 [01:00<00:09,  3.79it/s]Loading train:  86%|████████▌ | 213/247 [01:01<00:09,  3.71it/s]Loading train:  87%|████████▋ | 214/247 [01:01<00:08,  3.70it/s]Loading train:  87%|████████▋ | 215/247 [01:01<00:08,  3.68it/s]Loading train:  87%|████████▋ | 216/247 [01:02<00:08,  3.63it/s]Loading train:  88%|████████▊ | 217/247 [01:02<00:08,  3.63it/s]Loading train:  88%|████████▊ | 218/247 [01:02<00:08,  3.62it/s]Loading train:  89%|████████▊ | 219/247 [01:02<00:07,  3.60it/s]Loading train:  89%|████████▉ | 220/247 [01:03<00:07,  3.60it/s]Loading train:  89%|████████▉ | 221/247 [01:03<00:07,  3.62it/s]Loading train:  90%|████████▉ | 222/247 [01:03<00:06,  3.63it/s]Loading train:  90%|█████████ | 223/247 [01:03<00:06,  3.63it/s]Loading train:  91%|█████████ | 224/247 [01:04<00:06,  3.60it/s]Loading train:  91%|█████████ | 225/247 [01:04<00:06,  3.59it/s]Loading train:  91%|█████████▏| 226/247 [01:04<00:05,  3.60it/s]Loading train:  92%|█████████▏| 227/247 [01:05<00:05,  3.59it/s]Loading train:  92%|█████████▏| 228/247 [01:05<00:05,  3.60it/s]Loading train:  93%|█████████▎| 229/247 [01:05<00:04,  3.61it/s]Loading train:  93%|█████████▎| 230/247 [01:05<00:04,  3.45it/s]Loading train:  94%|█████████▎| 231/247 [01:06<00:04,  3.33it/s]Loading train:  94%|█████████▍| 232/247 [01:06<00:04,  3.27it/s]Loading train:  94%|█████████▍| 233/247 [01:06<00:04,  3.23it/s]Loading train:  95%|█████████▍| 234/247 [01:07<00:04,  3.20it/s]Loading train:  95%|█████████▌| 235/247 [01:07<00:03,  3.18it/s]Loading train:  96%|█████████▌| 236/247 [01:07<00:03,  3.17it/s]Loading train:  96%|█████████▌| 237/247 [01:08<00:03,  3.17it/s]Loading train:  96%|█████████▋| 238/247 [01:08<00:02,  3.16it/s]Loading train:  97%|█████████▋| 239/247 [01:08<00:02,  3.15it/s]Loading train:  97%|█████████▋| 240/247 [01:09<00:02,  3.14it/s]Loading train:  98%|█████████▊| 241/247 [01:09<00:01,  3.10it/s]Loading train:  98%|█████████▊| 242/247 [01:09<00:01,  3.12it/s]Loading train:  98%|█████████▊| 243/247 [01:10<00:01,  3.11it/s]Loading train:  99%|█████████▉| 244/247 [01:10<00:00,  3.12it/s]Loading train:  99%|█████████▉| 245/247 [01:10<00:00,  3.10it/s]Loading train: 100%|█████████▉| 246/247 [01:11<00:00,  3.10it/s]Loading train: 100%|██████████| 247/247 [01:11<00:00,  3.10it/s]Loading train: 100%|██████████| 247/247 [01:11<00:00,  3.46it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 46.86it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:05, 46.16it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:05, 45.61it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:05, 44.95it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 45.22it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 46.29it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:04, 47.96it/s]concatenating: train:  17%|█▋        | 41/247 [00:00<00:04, 48.44it/s]concatenating: train:  19%|█▊        | 46/247 [00:00<00:04, 48.29it/s]concatenating: train:  21%|██        | 51/247 [00:01<00:04, 47.88it/s]concatenating: train:  23%|██▎       | 56/247 [00:01<00:04, 47.60it/s]concatenating: train:  25%|██▍       | 61/247 [00:01<00:03, 46.96it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 46.07it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:03, 45.60it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:03, 45.26it/s]concatenating: train:  33%|███▎      | 81/247 [00:01<00:03, 44.25it/s]concatenating: train:  35%|███▍      | 86/247 [00:01<00:03, 42.73it/s]concatenating: train:  37%|███▋      | 91/247 [00:02<00:03, 41.63it/s]concatenating: train:  39%|███▉      | 96/247 [00:02<00:03, 40.46it/s]concatenating: train:  41%|████      | 101/247 [00:02<00:03, 39.92it/s]concatenating: train:  43%|████▎     | 106/247 [00:02<00:03, 40.21it/s]concatenating: train:  45%|████▍     | 111/247 [00:02<00:03, 40.29it/s]concatenating: train:  47%|████▋     | 116/247 [00:02<00:03, 40.77it/s]concatenating: train:  49%|████▉     | 121/247 [00:02<00:03, 41.59it/s]concatenating: train:  51%|█████     | 126/247 [00:02<00:02, 42.81it/s]concatenating: train:  53%|█████▎    | 131/247 [00:02<00:02, 43.69it/s]concatenating: train:  55%|█████▌    | 136/247 [00:03<00:02, 44.04it/s]concatenating: train:  57%|█████▋    | 141/247 [00:03<00:02, 44.97it/s]concatenating: train:  59%|█████▉    | 146/247 [00:03<00:02, 45.53it/s]concatenating: train:  61%|██████    | 151/247 [00:03<00:02, 46.49it/s]concatenating: train:  63%|██████▎   | 156/247 [00:03<00:02, 45.28it/s]concatenating: train:  65%|██████▌   | 161/247 [00:03<00:01, 43.29it/s]concatenating: train:  67%|██████▋   | 166/247 [00:03<00:01, 42.73it/s]concatenating: train:  69%|██████▉   | 171/247 [00:03<00:01, 42.33it/s]concatenating: train:  71%|███████▏  | 176/247 [00:03<00:01, 43.62it/s]concatenating: train:  73%|███████▎  | 181/247 [00:04<00:01, 45.10it/s]concatenating: train:  75%|███████▌  | 186/247 [00:04<00:01, 46.07it/s]concatenating: train:  77%|███████▋  | 191/247 [00:04<00:01, 46.26it/s]concatenating: train:  80%|███████▉  | 197/247 [00:04<00:01, 47.43it/s]concatenating: train:  82%|████████▏ | 203/247 [00:04<00:00, 48.54it/s]concatenating: train:  85%|████████▍ | 209/247 [00:04<00:00, 49.53it/s]concatenating: train:  87%|████████▋ | 214/247 [00:04<00:00, 49.59it/s]concatenating: train:  89%|████████▊ | 219/247 [00:04<00:00, 49.31it/s]concatenating: train:  91%|█████████ | 224/247 [00:04<00:00, 48.83it/s]concatenating: train:  93%|█████████▎| 229/247 [00:05<00:00, 48.59it/s]concatenating: train:  95%|█████████▍| 234/247 [00:05<00:00, 46.52it/s]concatenating: train:  97%|█████████▋| 239/247 [00:05<00:00, 45.26it/s]concatenating: train:  99%|█████████▉| 245/247 [00:05<00:00, 47.80it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 45.40it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  3.07it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.04it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.08it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  3.22it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.24it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.21it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 361.27it/s]
Epoch 00051: val_mDice did not improve from 0.29638
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [0.6828443414421492, 0.6714164140403912, 0.6519768949477903, 0.6687264884671857, 0.6338534470527403, 0.5808507752033972, 0.6469855420691992, 0.686537415750565, 0.582657015772276, 0.468824437308696, 0.464585853199805, 0.44107301244812624, 0.3625194861363339, 0.3261807487216047, 0.47315840246856855, 0.4002367580129254, 0.15989232423805422, 0.26740675784337026, 0.17483166953729046, 0.15148625203898997, 0.11973626971224784, 0.15458560163175228, 0.1570536817313843, 0.19471385658428234, 0.10050200410587813, 0.11485614663650913, 0.20604135064027643, 0.12222614338601469, 0.09701847911922522, 0.09612421611303924, 0.11568966503905993, 0.09329574322828682, 0.1137998821914837, 0.055447317960281524, 0.08459105915440027, 0.0465437708803082, 0.0703496082926229, 0.06535986967144473, 0.0736100458570065, 0.08658174267138845, 0.055719436496816654, 0.050205867101628616, 0.031367833500788096, 0.07167915004475783, 0.07997207932414548, 0.042053468335139496, 0.08229959801700647, 0.06339905089047808, 0.05777272681194928, 0.0278095383777894, 0.032300240360200405], 'val_acc': [0.9370253028408173, 0.9409308862942521, 0.9368866271870111, 0.9399868288347798, 0.942709663221913, 0.9459592046276215, 0.9421856390532627, 0.9395267944182119, 0.9419322891901898, 0.9450071498911868, 0.9464752475420634, 0.9422576376186904, 0.9442351005410635, 0.9452538298022363, 0.9437683987361128, 0.9427843350236134, 0.94546050922845, 0.9436430597818026, 0.9457298613363697, 0.9459032076661305, 0.9460498741877976, 0.9456805202268785, 0.9458298663939199, 0.9460192085594259, 0.9449084631858333, 0.9454925047454014, 0.9453658333388708, 0.9462125506452335, 0.9458658727266456, 0.9466232477977712, 0.9463965668473192, 0.9461578893405135, 0.9450791555066262, 0.9457031969101198, 0.9466099175073768, 0.9466765881866537, 0.9467072531741153, 0.9458831984509704, 0.9467192606259418, 0.9463392310245062, 0.9468779301130643, 0.9455085069902481, 0.9468259266627732, 0.946083221384274, 0.9469446116878141, 0.9469126046344798, 0.9463205593888477, 0.9462685642703887, 0.9462378947965561, 0.9458258658327082, 0.9470712786079735], 'val_mDice': [0.26247389902991636, 0.2746947178597091, 0.29557204274560817, 0.27415750880715667, 0.2845881907369501, 0.29468641590367084, 0.2872161081721706, 0.25285287361632114, 0.28631240902568705, 0.28275920646966146, 0.2963755858200853, 0.2740824164882783, 0.28673080935753803, 0.29257374717503465, 0.28626680165849705, 0.2844707470747732, 0.27854928562557824, 0.2743242233991623, 0.28764737561665554, 0.2857653124518292, 0.28305726598507613, 0.28613719928969616, 0.2832364073844366, 0.2867404494875221, 0.2874956066089292, 0.28874362933058895, 0.29597232162311515, 0.282339686427706, 0.27629023586069384, 0.2808165832632972, 0.28450296094180433, 0.2896881625056267, 0.2852536710680172, 0.2820261885482137, 0.2895371003817486, 0.28124245588657676, 0.2813736693432895, 0.2729255028309361, 0.28387651312094864, 0.28928214439781763, 0.28508453271401824, 0.28080856483629957, 0.2808477312967341, 0.2820443758560765, 0.28540239703430925, 0.2835159185592846, 0.2817092615189732, 0.27778407923316445, 0.2796196039485675, 0.27760311824980605, 0.28429543507355515], 'loss': [0.5435428566607551, 0.38505794720795605, 0.34941091799307833, 0.328574049459739, 0.32266965291252886, 0.3068725960207618, 0.3037799265653041, 0.29471711114700894, 0.28739693270442107, 0.2869569100093354, 0.275213100040234, 0.2734612330438026, 0.2703799151877614, 0.26868500923132044, 0.2656899324735072, 0.26435297313084544, 0.26413252367796075, 0.2557451519031819, 0.24625872372585136, 0.24496941168086445, 0.23841859327299156, 0.2355522029868145, 0.23379004292576724, 0.23420287698112102, 0.23077097307500505, 0.2288742987070475, 0.23116142885370294, 0.2298727492437465, 0.22873793817318294, 0.22763760039368713, 0.22635502194491933, 0.228336904318905, 0.22537204464206095, 0.21735338861887274, 0.2173895632920689, 0.21637954065237586, 0.21643124488882048, 0.21659697851321139, 0.21603870333031472, 0.21760977424235411, 0.20988929658502706, 0.21174875104820678, 0.21133003647371984, 0.21304010160689787, 0.2113680493094745, 0.20839457268336253, 0.2092260852840408, 0.21192787385604894, 0.19905392187671347, 0.1918241771056095, 0.19277550079631753], 'acc': [0.9122411229110802, 0.9380600243181354, 0.9422818870363696, 0.9448410317782533, 0.9464527844349552, 0.9479778881696367, 0.9488843874853166, 0.9492150154830246, 0.9504962700934627, 0.9505481931639699, 0.9515636944068776, 0.9520850793683256, 0.9524702718614648, 0.952839588906106, 0.9530756138953633, 0.9534641473666977, 0.9533151875797438, 0.9539653323781357, 0.9554263659057306, 0.9556830043681693, 0.9560919966779348, 0.956263332466772, 0.9564881174402794, 0.9566456500456006, 0.9568960739038452, 0.9569756303336933, 0.9570170391809596, 0.9567971213060343, 0.9573260160357342, 0.9572203311315718, 0.9573423052936951, 0.9574469042381987, 0.9577346726127067, 0.9581322169408453, 0.9583065820671365, 0.9585373507196275, 0.9585984420139058, 0.9585776978673275, 0.958679394687381, 0.9585500909401602, 0.9589278260501676, 0.9589764602599792, 0.9588820135791329, 0.9589500969395055, 0.9589490093554536, 0.9591363998735027, 0.9590325281965318, 0.9579007501043033, 0.958315127476205, 0.9586146009843409, 0.9586181234464499], 'mDice': [0.4145469502177818, 0.5851022938671522, 0.6235549408657336, 0.6460471809924837, 0.652383108772987, 0.6694273062037117, 0.672763014033902, 0.6825622891762367, 0.6904320565870264, 0.6909021898937634, 0.7036007709339863, 0.7054761386221382, 0.7088032803182451, 0.7106148105231782, 0.7138512412877126, 0.715286947191664, 0.7155354919383305, 0.7246015611964028, 0.7348052892354332, 0.7362006212607721, 0.7432879424734953, 0.7463775325309413, 0.748281233225061, 0.747817749741606, 0.7515303139349507, 0.7535893549043574, 0.7510970283353753, 0.7525010116105041, 0.7537100030856329, 0.7549213679919502, 0.756292761672921, 0.75414022628731, 0.7573300425849728, 0.7660133636755823, 0.7659706129147238, 0.7670532225492018, 0.7669970932342419, 0.7668159498331429, 0.7674188691937153, 0.7657268152109228, 0.7740635130329995, 0.7720446172482014, 0.7725082364524968, 0.7706437330536247, 0.7724468601239155, 0.7756364978441456, 0.7740324156212386, 0.760819164437243, 0.7670409897616752, 0.7707898341328562, 0.7687199581972651], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               2020-01-22 00:50:16.079807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 00:50:16.079881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 00:50:16.079895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 00:50:16.079903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 00:50:16.080189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [0.97436874 0.02563126]
Train on 25479 samples, validate on 528 samples
Epoch 1/300
 - 68s - loss: 0.0724 - acc: 0.9922 - mDice: 0.8592 - val_loss: 0.0099 - val_acc: 0.9938 - val_mDice: 0.4955

Epoch 00001: val_mDice improved from -inf to 0.49554, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 65s - loss: 0.0497 - acc: 0.9945 - mDice: 0.9035 - val_loss: 0.0196 - val_acc: 0.9939 - val_mDice: 0.5054

Epoch 00002: val_mDice improved from 0.49554 to 0.50540, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 3/300
 - 65s - loss: 0.0456 - acc: 0.9949 - mDice: 0.9113 - val_loss: 0.0126 - val_acc: 0.9941 - val_mDice: 0.5076

Epoch 00003: val_mDice improved from 0.50540 to 0.50765, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 4/300
 - 65s - loss: 0.0417 - acc: 0.9952 - mDice: 0.9190 - val_loss: -4.1709e-02 - val_acc: 0.9938 - val_mDice: 0.4924

Epoch 00004: val_mDice did not improve from 0.50765
Epoch 5/300
 - 64s - loss: 0.0395 - acc: 0.9954 - mDice: 0.9232 - val_loss: 0.0976 - val_acc: 0.9940 - val_mDice: 0.5061

Epoch 00005: val_mDice did not improve from 0.50765
Epoch 6/300
 - 64s - loss: 0.0384 - acc: 0.9956 - mDice: 0.9254 - val_loss: -1.0054e-02 - val_acc: 0.9942 - val_mDice: 0.5014

Epoch 00006: val_mDice did not improve from 0.50765
Epoch 7/300
 - 65s - loss: 0.0374 - acc: 0.9956 - mDice: 0.9274 - val_loss: -1.6779e-02 - val_acc: 0.9942 - val_mDice: 0.5013

Epoch 00007: val_mDice did not improve from 0.50765
Epoch 8/300
 - 65s - loss: 0.0359 - acc: 0.9958 - mDice: 0.9303 - val_loss: -3.0050e-02 - val_acc: 0.9940 - val_mDice: 0.5055

Epoch 00008: val_mDice did not improve from 0.50765
Epoch 9/300
 - 65s - loss: 0.0349 - acc: 0.9959 - mDice: 0.9323 - val_loss: 0.0351 - val_acc: 0.9940 - val_mDice: 0.5076

Epoch 00009: val_mDice did not improve from 0.50765
Epoch 10/300
 - 64s - loss: 0.0342 - acc: 0.9959 - mDice: 0.9337 - val_loss: 0.0529 - val_acc: 0.9942 - val_mDice: 0.5018

Epoch 00010: val_mDice did not improve from 0.50765
Epoch 11/300
 - 65s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9342 - val_loss: 0.0630 - val_acc: 0.9941 - val_mDice: 0.5061

Epoch 00011: val_mDice did not improve from 0.50765
Epoch 12/300
 - 66s - loss: 0.0335 - acc: 0.9960 - mDice: 0.9350 - val_loss: 0.0318 - val_acc: 0.9942 - val_mDice: 0.5050

Epoch 00012: val_mDice did not improve from 0.50765
Epoch 13/300
 - 67s - loss: 0.0327 - acc: 0.9961 - mDice: 0.9366 - val_loss: 0.0397 - val_acc: 0.9944 - val_mDice: 0.5111

Epoch 00013: val_mDice improved from 0.50765 to 0.51107, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 14/300
 - 65s - loss: 0.0322 - acc: 0.9961 - mDice: 0.9376 - val_loss: 0.0541 - val_acc: 0.9938 - val_mDice: 0.5043

Epoch 00014: val_mDice did not improve from 0.51107
Epoch 15/300
 - 64s - loss: 0.0319 - acc: 0.9961 - mDice: 0.9381 - val_loss: 0.0096 - val_acc: 0.9944 - val_mDice: 0.4989

Epoch 00015: val_mDice did not improve from 0.51107
Epoch 16/300
 - 64s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9390 - val_loss: 0.0419 - val_acc: 0.9943 - val_mDice: 0.5084

Epoch 00016: val_mDice did not improve from 0.51107
Epoch 17/300
 - 65s - loss: 0.0313 - acc: 0.9962 - mDice: 0.9392 - val_loss: -2.9925e-02 - val_acc: 0.9945 - val_mDice: 0.5067

Epoch 00017: val_mDice did not improve from 0.51107
Epoch 18/300
 - 65s - loss: 0.0307 - acc: 0.9962 - mDice: 0.9405 - val_loss: -5.0866e-02 - val_acc: 0.9946 - val_mDice: 0.5052

Epoch 00018: val_mDice did not improve from 0.51107
Epoch 19/300
 - 64s - loss: 0.0313 - acc: 0.9962 - mDice: 0.9393 - val_loss: 0.0074 - val_acc: 0.9943 - val_mDice: 0.5000

Epoch 00019: val_mDice did not improve from 0.51107
Epoch 20/300
 - 64s - loss: 0.0302 - acc: 0.9963 - mDice: 0.9415 - val_loss: 0.0153 - val_acc: 0.9942 - val_mDice: 0.4983

Epoch 00020: val_mDice did not improve from 0.51107
Epoch 21/300
 - 64s - loss: 0.0301 - acc: 0.9963 - mDice: 0.9416 - val_loss: 0.0062 - val_acc: 0.9944 - val_mDice: 0.5109

Epoch 00021: val_mDice did not improve from 0.51107
Epoch 22/300
 - 64s - loss: 0.0299 - acc: 0.9963 - mDice: 0.9420 - val_loss: -7.3354e-03 - val_acc: 0.9945 - val_mDice: 0.5042

Epoch 00022: val_mDice did not improve from 0.51107
Epoch 23/300
 - 64s - loss: 0.0297 - acc: 0.9963 - mDice: 0.9423 - val_loss: -1.6193e-02 - val_acc: 0.9943 - val_mDice: 0.5128

Epoch 00023: val_mDice improved from 0.51107 to 0.51280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 24/300
 - 64s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9429 - val_loss: -3.2108e-02 - val_acc: 0.9946 - val_mDice: 0.5066

Epoch 00024: val_mDice did not improve from 0.51280
Epoch 25/300
 - 64s - loss: 0.0292 - acc: 0.9964 - mDice: 0.9434 - val_loss: -3.8832e-02 - val_acc: 0.9945 - val_mDice: 0.5048

Epoch 00025: val_mDice did not improve from 0.51280
Epoch 26/300
 - 64s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9438 - val_loss: -1.4323e-02 - val_acc: 0.9944 - val_mDice: 0.5085

Epoch 00026: val_mDice did not improve from 0.51280
Epoch 27/300
 - 64s - loss: 0.0288 - acc: 0.9964 - mDice: 0.9441 - val_loss: -1.0917e-02 - val_acc: 0.9943 - val_mDice: 0.5034

Epoch 00027: val_mDice did not improve from 0.51280
Epoch 28/300
 - 64s - loss: 0.0288 - acc: 0.9964 - mDice: 0.9441 - val_loss: -1.1450e-02 - val_acc: 0.9944 - val_mDice: 0.5036

Epoch 00028: val_mDice did not improve from 0.51280
Epoch 29/300
 - 64s - loss: 0.0285 - acc: 0.9964 - mDice: 0.9448 - val_loss: -4.5090e-02 - val_acc: 0.9943 - val_mDice: 0.4948

Epoch 00029: val_mDice did not improve from 0.51280
Epoch 30/300
 - 64s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9451 - val_loss: -4.7170e-02 - val_acc: 0.9944 - val_mDice: 0.4989

Epoch 00030: val_mDice did not improve from 0.51280
Epoch 31/300
 - 64s - loss: 0.0284 - acc: 0.9965 - mDice: 0.9448 - val_loss: -1.1168e-02 - val_acc: 0.9943 - val_mDice: 0.5051

Epoch 00031: val_mDice did not improve from 0.51280
Epoch 32/300
 - 64s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9452 - val_loss: -5.3750e-02 - val_acc: 0.9944 - val_mDice: 0.5121

Epoch 00032: val_mDice did not improve from 0.51280
Epoch 33/300
 - 64s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9450 - val_loss: -3.1721e-02 - val_acc: 0.9945 - val_mDice: 0.5063

Epoch 00033: val_mDice did not improve from 0.51280
Epoch 34/300
 - 64s - loss: 0.0280 - acc: 0.9965 - mDice: 0.9458 - val_loss: -1.1747e-02 - val_acc: 0.9944 - val_mDice: 0.5054

Epoch 00034: val_mDice did not improve from 0.51280
Epoch 35/300
 - 64s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9463 - val_loss: -3.0167e-02 - val_acc: 0.9944 - val_mDice: 0.5028

Epoch 00035: val_mDice did not improve from 0.51280
Epoch 36/300
 - 64s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9462 - val_loss: 0.0234 - val_acc: 0.9941 - val_mDice: 0.4989

Epoch 00036: val_mDice did not improve from 0.51280
Epoch 37/300
 - 65s - loss: 0.0280 - acc: 0.9965 - mDice: 0.9456 - val_loss: -3.2578e-02 - val_acc: 0.9944 - val_mDice: 0.5078

Epoch 00037: val_mDice did not improve from 0.51280
Epoch 38/300
 - 64s - loss: 0.0281 - acc: 0.9966 - mDice: 0.9455 - val_loss: -1.1535e-02 - val_acc: 0.9943 - val_mDice: 0.5035

Epoch 00038: val_mDice did not improve from 0.51280

Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 39/300
 - 64s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9485 - val_loss: -3.3946e-02 - val_acc: 0.9944 - val_mDice: 0.5102

Epoch 00039: val_mDice did not improve from 0.51280
Epoch 40/300
 - 64s - loss: 0.0262 - acc: 0.9967 - mDice: 0.9491 - val_loss: -3.1250e-02 - val_acc: 0.9945 - val_mDice: 0.5110

Epoch 00040: val_mDice did not improve from 0.51280
Epoch 41/300
 - 64s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9495 - val_loss: -2.1174e-02 - val_acc: 0.9944 - val_mDice: 0.5067

Epoch 00041: val_mDice did not improve from 0.51280
Epoch 42/300
 - 64s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9502 - val_loss: -3.0913e-02 - val_acc: 0.9944 - val_mDice: 0.5083

Epoch 00042: val_mDice did not improve from 0.51280
Epoch 43/300
 - 64s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9503 - val_loss: 0.0403 - val_acc: 0.9943 - val_mDice: 0.5136

Epoch 00043: val_mDice improved from 0.51280 to 0.51361, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 44/300
 - 64s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9502 - val_loss: -3.1859e-02 - val_acc: 0.9945 - val_mDice: 0.5080

Epoch 00044: val_mDice did not improve from 0.51361
Epoch 45/300
 - 64s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9505 - val_loss: -4.8584e-02 - val_acc: 0.9944 - val_mDice: 0.5074

Epoch 00045: val_mDice did not improve from 0.51361
Epoch 46/300
 - 65s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9511 - val_loss: 0.0240 - val_acc: 0.9944 - val_mDice: 0.5111

Epoch 00046: val_mDice did not improve from 0.51361
Epoch 47/300
 - 66s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9504 - val_loss: -1.4131e-02 - val_acc: 0.9944 - val_mDice: 0.5096

Epoch 00047: val_mDice did not improve from 0.51361
Epoch 48/300
 - 65s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9512 - val_loss: 0.0012 - val_acc: 0.9943 - val_mDice: 0.5156

Epoch 00048: val_mDice improved from 0.51361 to 0.51563, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 49/300
 - 66s - loss: 0.0250 - acc: 0.9968 - mDice: 0.9515 - val_loss: -5.1669e-02 - val_acc: 0.9944 - val_mDice: 0.5080

Epoch 00049: val_mDice did not improve from 0.51563
Epoch 50/300
 - 66s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9517 - val_loss: -1.1612e-02 - val_acc: 0.9944 - val_mDice: 0.5036

Epoch 00050: val_mDice did not improve from 0.51563
Epoch 51/300
 - 66s - loss: 0.0252 - acc: 0.9968 - mDice: 0.9511 - val_loss: -1.4455e-02 - val_acc: 0.9945 - val_mDice: 0.5092

Epoch 00051: val_mDice did not improve from 0.51563
Epoch 52/300
 - 66s - loss: 0.0252 - acc: 0.9968 - mDice: 0.9512 - val_loss: -1.1623e-02 - val_acc: 0.9944 - val_mDice: 0.5005

Epoch 00052: val_mDice did not improve from 0.51563
Epoch 53/300
 - 65s - loss: 0.0252 - acc: 0.9968 - mDice: 0.9512 - val_loss: 0.0184 - val_acc: 0.9943 - val_mDice: 0.5164

Epoch 00053: val_mDice improved from 0.51563 to 0.51639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 54/300
 - 64s - loss: 0.0247 - acc: 0.9968 - mDice: 0.9521 - val_loss: 0.0258 - val_acc: 0.9944 - val_mDice: 0.5084

Epoch 00054: val_mDice did not improve from 0.51639
Epoch 55/300
 - 66s - loss: 0.0247 - acc: 0.9968 - mDice: 0.9522 - val_loss: -7.9120e-03 - val_acc: 0.9942 - val_mDice: 0.5048

Epoch 00055: val_mDice did not improve from 0.51639
Epoch 56/300
 - 65s - loss: 0.0247 - acc: 0.9968 - mDice: 0.9521 - val_loss: -4.5758e-02 - val_acc: 0.9943 - val_mDice: 0.5011

Epoch 00056: val_mDice did not improve from 0.51639
Epoch 57/300
 - 66s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9523 - val_loss: -3.3457e-02 - val_acc: 0.9943 - val_mDice: 0.5094

Epoch 00057: val_mDice did not improve from 0.51639
Epoch 58/300
 - 66s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9523 - val_loss: 0.0267 - val_acc: 0.9943 - val_mDice: 0.5030

Epoch 00058: val_mDice did not improve from 0.51639
Epoch 59/300
 - 66s - loss: 0.0245 - acc: 0.9968 - mDice: 0.9525 - val_loss: -3.3979e-02 - val_acc: 0.9944 - val_mDice: 0.5104

Epoch 00059: val_mDice did not improve from 0.51639
Epoch 60/300
 - 66s - loss: 0.0250 - acc: 0.9968 - mDice: 0.9516 - val_loss: 0.0141 - val_acc: 0.9942 - val_mDice: 0.5121

Epoch 00060: val_mDice did not improve from 0.51639
Epoch 61/300
 - 66s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9523 - val_loss: -3.4885e-02 - val_acc: 0.9944 - val_mDice: 0.5125

Epoch 00061: val_mDice did not improve from 0.51639
Epoch 62/300
 - 64s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9523 - val_loss: 0.0252 - val_acc: 0.9943 - val_mDice: 0.5077

Epoch 00062: val_mDice did not improve from 0.51639
Epoch 63/300
 - 64s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9528 - val_loss: -1.2957e-02 - val_acc: 0.9943 - val_mDice: 0.5063

Epoch 00063: val_mDice did not improve from 0.51639

Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 64/300
 - 64s - loss: 0.0241 - acc: 0.9968 - mDice: 0.9534 - val_loss: -3.3929e-02 - val_acc: 0.9943 - val_mDice: 0.5102

Epoch 00064: val_mDice did not improve from 0.51639
Epoch 65/300
 - 65s - loss: 0.0238 - acc: 0.9969 - mDice: 0.9538 - val_loss: 0.0082 - val_acc: 0.9944 - val_mDice: 0.5035

Epoch 00065: val_mDice did not improve from 0.51639
Epoch 66/300
 - 64s - loss: 0.0239 - acc: 0.9969 - mDice: 0.9538 - val_loss: -1.5183e-02 - val_acc: 0.9944 - val_mDice: 0.5020

Epoch 00066: val_mDice did not improve from 0.51639
Epoch 67/300
 - 64s - loss: 0.0241 - acc: 0.9969 - mDice: 0.9534 - val_loss: -1.1616e-02 - val_acc: 0.9944 - val_mDice: 0.5031

Epoch 00067: val_mDice did not improve from 0.51639
Epoch 68/300
 - 64s - loss: 0.0235 - acc: 0.9969 - mDice: 0.9545 - val_loss: -4.9176e-02 - val_acc: 0.9945 - val_mDice: 0.5034

Epoch 00068: val_mDice did not improve from 0.51639
Epoch 69/300
 - 64s - loss: 0.0237 - acc: 0.9969 - mDice: 0.9541 - val_loss: 0.0064 - val_acc: 0.9944 - val_mDice: 0.5055

Epoch 00069: val_mDice did not improve from 0.51639
Epoch 70/300
 - 64s - loss: 0.0235 - acc: 0.9969 - mDice: 0.9546 - val_loss: 0.0274 - val_acc: 0.9943 - val_mDice: 0.5105

Epoch 00070: val_mDice did not improve from 0.51639
Epoch 71/300
 - 64s - loss: 0.0237 - acc: 0.9969 - mDice: 0.9541 - val_loss: -3.1774e-02 - val_acc: 0.9944 - val_mDice: 0.5060

Epoch 00071: val_mDice did not improve from 0.51639
Epoch 72/300
 - 64s - loss: 0.0233 - acc: 0.9969 - mDice: 0.9548 - val_loss: -1.6887e-02 - val_acc: 0.9944 - val_mDice: 0.5073

Epoch 00072: val_mDice did not improve from 0.51639
Epoch 73/300
 - 64s - loss: 0.0236 - acc: 0.9969 - mDice: 0.9543 - val_loss: -3.0564e-02 - val_acc: 0.9944 - val_mDice: 0.5036

Epoch 00073: val_mDice did not improve from 0.51639
Epoch 74/300
 - 65s - loss: 0.0234 - acc: 0.9969 - mDice: 0.9547 - val_loss: 0.0114 - val_acc: 0.9944 - val_mDice: 0.5058

Epoch 00074: val_mDice did not improve from 0.51639
Epoch 75/300
 - 65s - loss: 0.0235 - acc: 0.9969 - mDice: 0.9545 - val_loss: -4.7574e-02 - val_acc: 0.9944 - val_mDice: 0.5040

Epoch 00075: val_mDice did not improve from 0.51639
Epoch 76/300
 - 66s - loss: 0.0234 - acc: 0.9969 - mDice: 0.9546 - val_loss: -3.2322e-02 - val_acc: 0.9943 - val_mDice: 0.5072

Epoch 00076: val_mDice did not improve from 0.51639
Epoch 77/300
 - 66s - loss: 0.0235 - acc: 0.9969 - mDice: 0.9545 - val_loss: 0.0584 - val_acc: 0.9945 - val_mDice: 0.5074

Epoch 00077: val_mDice did not improve from 0.51639
Epoch 78/300
 - 66s - loss: 0.0234 - acc: 0.9969 - mDice: 0.9548 - val_loss: -5.0105e-02 - val_acc: 0.9945 - val_mDice: 0.5047

Epoch 00078: val_mDice did not improve from 0.51639

Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 79/300
 - 66s - loss: 0.0230 - acc: 0.9969 - mDice: 0.9554 - val_loss: -2.8023e-02 - val_acc: 0.9945 - val_mDice: 0.5061

Epoch 00079: val_mDice did not improve from 0.51639
Epoch 80/300
 - 66s - loss: 0.0232 - acc: 0.9969 - mDice: 0.9552 - val_loss: -3.1342e-02 - val_acc: 0.9944 - val_mDice: 0.5051

Epoch 00080: val_mDice did not improve from 0.51639
Epoch 81/300
 - 64s - loss: 0.0231 - acc: 0.9970 - mDice: 0.9552 - val_loss: -3.2527e-02 - val_acc: 0.9944 - val_mDice: 0.5053

Epoch 00081: val_mDice did not improve from 0.51639
Epoch 82/300
 - 64s - loss: 0.0232 - acc: 0.9969 - mDice: 0.9552 - val_loss: 0.0206 - val_acc: 0.9944 - val_mDice: 0.5100

Epoch 00082: val_mDice did not improve from 0.51639
Epoch 83/300
 - 65s - loss: 0.0228 - acc: 0.9969 - mDice: 0.9558 - val_loss: 0.0049 - val_acc: 0.9944 - val_mDice: 0.5085

Epoch 00083: val_mDice did not improve from 0.51639
Epoch 84/300
 - 65s - loss: 0.0229 - acc: 0.9969 - mDice: 0.9556 - val_loss: -3.0283e-02 - val_acc: 0.9944 - val_mDice: 0.5030

Epoch 00084: val_mDice did not improve from 0.51639
Epoch 85/300
 - 66s - loss: 0.0228 - acc: 0.9969 - mDice: 0.9558 - val_loss: 0.0254 - val_acc: 0.9943 - val_mDice: 0.5054

Epoch 00085: val_mDice did not improve from 0.51639
Epoch 86/300
 - 65s - loss: 0.0228 - acc: 0.9969 - mDice: 0.9559 - val_loss: 0.0052 - val_acc: 0.9944 - val_mDice: 0.5077

Epoch 00086: val_mDice did not improve from 0.51639
Epoch 87/300
 - 67s - loss: 0.0226 - acc: 0.9970 - mDice: 0.9562 - val_loss: 0.0085 - val_acc: 0.9943 - val_mDice: 0.5049

Epoch 00087: val_mDice did not improve from 0.51639
Epoch 88/300
 - 66s - loss: 0.0226 - acc: 0.9969 - mDice: 0.9562 - val_loss: -1.3554e-02 - val_acc: 0.9943 - val_mDice: 0.5075

Epoch 00088: val_mDice did not improve from 0.51639
Epoch 89/300
 - 65s - loss: 0.0227 - acc: 0.9970 - mDice: 0.9560 - val_loss: 0.0618 - val_acc: 0.9944 - val_mDice: 0.5072

Epoch 00089: val_mDice did not improve from 0.51639
Epoch 90/300
 - 64s - loss: 0.0229 - acc: 0.9969 - mDice: 0.9557 - val_loss: -1.2127e-02 - val_acc: 0.9944 - val_mDice: 0.5046

Epoch 00090: val_mDice did not improve from 0.51639
Epoch 91/300
 - 65s - loss: 0.0226 - acc: 0.9970 - mDice: 0.9562 - val_loss: 0.0067 - val_acc: 0.9943 - val_mDice: 0.5052

Epoch 00091: val_mDice did not improve from 0.51639
Epoch 92/300
 - 65s - loss: 0.0226 - acc: 0.9970 - mDice: 0.9562 - val_loss: 0.0119 - val_acc: 0.9944 - val_mDice: 0.5066

Epoch 00092: val_mDice did not improve from 0.51639
Epoch 93/300
 - 65s - loss: 0.0225 - acc: 0.9970 - mDice: 0.9564 - val_loss: -3.0260e-02 - val_acc: 0.9943 - val_mDice: 0.5031

Epoch 00093: val_mDice did not improve from 0.51639
Restoring model weights from the end of the best epoch

Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 00093: early stopping
{'val_loss': [0.009929210032251749, 0.019595009980328155, 0.01257180306834705, -0.04170893045198737, 0.09758315116844395, -0.010053678048831043, -0.01677874901868177, -0.03004996698688377, 0.035120257486899696, 0.052945998243310234, 0.06296851655299013, 0.0317894627594135, 0.03967407311905514, 0.054093175059692425, 0.00962661855825872, 0.04192134362617225, -0.02992549476524194, -0.05086583483286879, 0.007443214089355685, 0.015257723375477573, 0.006171791136942126, -0.007335420274599032, -0.01619288150333997, -0.03210807038527547, -0.038832015470799175, -0.014323407868770037, -0.010916513108620138, -0.011449674821712753, -0.045089528670139385, -0.04717011106285182, -0.011167501635623701, -0.053749894187080136, -0.03172091154776739, -0.01174676375971599, -0.030166775467946674, 0.02340912872530294, -0.03257802554942442, -0.011535168540748682, -0.03394586093385111, -0.03125045691249949, -0.021173517106834686, -0.030912674822364792, 0.04032962676137686, -0.03185938132193052, -0.04858376534486359, 0.024024660416850536, -0.014131182720038023, 0.0012309814831524184, -0.051668862981552426, -0.011611666304595543, -0.014454700080960087, -0.011623067188669334, 0.018410769150112614, 0.025832735340703617, -0.007912043002292965, -0.045757716352289375, -0.033456690101460976, 0.02668071414033572, -0.0339791023765098, 0.014054382840792337, -0.03488547764154094, 0.025169984860853714, -0.012956526102215954, -0.033929248114652706, 0.008232826903236635, -0.015183312874851805, -0.011615723145730568, -0.049176460414221794, 0.006362386301837184, 0.027373816479336132, -0.03177366165839361, -0.01688676451643308, -0.0305638387799263, 0.011448113388861671, -0.04757431107149883, -0.03232172537933697, 0.058433612300591034, -0.0501053769310767, -0.028023047288033096, -0.03134248484716271, -0.03252716272166281, 0.02059697410599752, 0.004881901468968753, -0.030283259368981377, 0.025417980229990048, 0.005200054948077057, 0.008464525284414942, -0.01355416892152844, 0.061757871147358055, -0.012126977470788088, 0.0066699965038534365, 0.01185593121882641, -0.030260187122180607], 'val_acc': [0.9938248526869398, 0.9939406866377051, 0.9940673623121146, 0.9938280869162444, 0.9939508363604546, 0.9941681991472389, 0.9942295761270956, 0.9939644506031816, 0.9940339046897311, 0.994231883549329, 0.994104513616273, 0.9941589705871813, 0.9943947871074532, 0.9938419246763894, 0.9944127836462223, 0.9942810302882483, 0.9945039313399431, 0.9945583837953481, 0.9943283347017837, 0.9942362681031227, 0.994408633898605, 0.994469548039364, 0.9943354872591568, 0.9945567695028854, 0.9944677034562285, 0.9943562518015052, 0.9942858799388914, 0.9944026316657211, 0.9942690337246115, 0.994392248265671, 0.9942639582987988, 0.9944019419225779, 0.9944600880597577, 0.994427092147596, 0.9944307824427431, 0.9941273586768092, 0.9943707939801794, 0.9942842611309254, 0.9944358612551834, 0.9944566246686559, 0.9943604094512535, 0.9944469366561283, 0.9943068759007887, 0.9945094707337293, 0.9944070162195148, 0.994391557393652, 0.9943587917721632, 0.9943080318696571, 0.9943571774797006, 0.9943537118308472, 0.9944953925230287, 0.9943705591740031, 0.9943454100778608, 0.9943592534823851, 0.9942399606560216, 0.9943038742199088, 0.9943287964120056, 0.9942644211378965, 0.9943966350772164, 0.9942482657956354, 0.9944174041350683, 0.9942711063406684, 0.9943128724892935, 0.99431702788129, 0.9943518740209666, 0.9943680203322208, 0.9943772522789059, 0.9944524749210386, 0.9943652534575174, 0.9942639571699229, 0.9943869425491854, 0.9943594860308098, 0.9943611025810242, 0.9944003242434878, 0.9943534849268018, 0.9943387158440821, 0.9944697805877888, 0.9944783171469515, 0.9945156953551553, 0.9944411658427932, 0.9943855596762715, 0.9944319384116115, 0.994428020083543, 0.9944160156177752, 0.9943221044359785, 0.9944012465350556, 0.9943142587488348, 0.994326260956851, 0.9943841734167301, 0.9944164795857487, 0.9943290300893061, 0.9944047133127848, 0.9943191027550986], 'val_mDice': [0.49553590896899324, 0.5054034627911169, 0.5076476590792564, 0.4924199630378685, 0.5061111622946605, 0.5013733707142599, 0.5013377680500092, 0.5055452677223718, 0.5075685871821464, 0.5017772523316318, 0.5061275271388391, 0.5049661196994061, 0.5110729827235142, 0.5043454691203255, 0.49888013833852174, 0.5084275778834567, 0.5066936350230015, 0.505242995268744, 0.5000063392789013, 0.49832944257631284, 0.510862148507978, 0.5042163280119315, 0.5127971565745997, 0.5066058566997484, 0.5048005572153311, 0.5085426973969196, 0.5034227508374236, 0.5036337785693353, 0.49484295883413515, 0.4988767517492802, 0.5050660017877817, 0.5120607222797293, 0.5063401003170646, 0.5054344609405325, 0.5027903531762686, 0.49886265318050527, 0.5077640102687998, 0.5034961821210152, 0.51021534159328, 0.5110350863612962, 0.506718120622364, 0.5083478817885575, 0.5136129666458477, 0.5080033704694925, 0.507430419763268, 0.5111275605546931, 0.5095613150589281, 0.5156300753129252, 0.5079781345910195, 0.5035729372232736, 0.5091816057084184, 0.5004852331441021, 0.5163949368182909, 0.5084215626685005, 0.5047706549168762, 0.5011015786140254, 0.5094446810526829, 0.5030175961666938, 0.5104012555922522, 0.5120834555110019, 0.5124837470551339, 0.5076608197255568, 0.5062963802254561, 0.5102446980097077, 0.5034832005868807, 0.5019618405706503, 0.5031420842208194, 0.5033803025655674, 0.5055095780302178, 0.5104577654238903, 0.506009825564153, 0.5073197509133907, 0.5036021455783736, 0.5057729499160566, 0.5039640921379693, 0.5071908073274024, 0.5074464236950558, 0.5047438904699503, 0.506143579471179, 0.5051454088904641, 0.5052920894443796, 0.5099676883864132, 0.5084542681773504, 0.5029904503713954, 0.5053878363899209, 0.5076555792016516, 0.5049162905550364, 0.5075401531991006, 0.5072053808323813, 0.5046050666803212, 0.5051685905676674, 0.5066160070286556, 0.5030605458710907], 'loss': [0.07242775293302277, 0.049663665463291935, 0.045614447572026456, 0.04172473813524201, 0.03954843618889526, 0.03839652926587128, 0.03736458801063817, 0.035883617171163604, 0.03488828596589592, 0.034171607711306826, 0.03388981889696341, 0.03350618633577712, 0.03265344529058529, 0.03216071247439252, 0.03188496583732697, 0.031463746228403915, 0.03131092064791157, 0.03067727245653886, 0.03126606102701661, 0.03015686290231098, 0.030126503619562303, 0.029880778128369326, 0.029726749864682527, 0.029422177553850615, 0.029187018100065985, 0.02898704825046883, 0.02882391907758094, 0.028844949180708655, 0.028496032098458874, 0.0282892136058149, 0.028447691315061384, 0.028251679576829575, 0.028335832750957753, 0.027970511474013866, 0.027669891964776806, 0.027734262178576653, 0.028019911976248743, 0.028080832403675298, 0.026537814528513816, 0.026248111069925285, 0.02602707155739252, 0.025676685894034833, 0.025636161541965918, 0.025703120007751323, 0.025539804613334313, 0.025252237166811548, 0.025600781698392368, 0.02519212965477935, 0.025018374739245702, 0.02492035100938125, 0.025222580294354733, 0.025194575485140185, 0.02517720118385501, 0.024735908340521626, 0.02468804076125069, 0.02474860636629037, 0.02464340738839578, 0.0246239379928533, 0.024515189830781228, 0.02497018670868736, 0.02461565927052929, 0.024607144328627952, 0.024360839219167995, 0.024056465412693705, 0.023835823204805668, 0.023850020996568584, 0.02406239999328286, 0.023489393066062045, 0.02371297324207665, 0.023459197191368807, 0.023716696071364618, 0.023342247749264834, 0.02358043724560252, 0.023386710294772694, 0.023491766655705702, 0.023438473922677915, 0.02346743184593129, 0.023351140403056043, 0.023031088052587037, 0.02315304199110615, 0.02314791388505856, 0.023151579104009213, 0.0228228898249399, 0.022947000316306736, 0.022804320245715697, 0.02279968645421165, 0.02264474383272253, 0.02260573305708071, 0.022731082973686464, 0.022881508236721353, 0.022611798919245196, 0.022616586389391534, 0.0225490186995233], 'acc': [0.9922175576522262, 0.9944845025714102, 0.9949411915583692, 0.9952205507827987, 0.9954282190545284, 0.9955728031214442, 0.9956490953005372, 0.9957788840811763, 0.9958503601867245, 0.9959276556276238, 0.9959697867984735, 0.9960104886602815, 0.9960686867603623, 0.9961309254139052, 0.9961290987241894, 0.9961790196950527, 0.9961992693034412, 0.9962345631929482, 0.9961988152329694, 0.9963029886654499, 0.9963062123271845, 0.9963258687033796, 0.9963438816439053, 0.9963706877117531, 0.9963849613386653, 0.9964060289359429, 0.9964143258210858, 0.9964250171267354, 0.9964325622152818, 0.9964755262767666, 0.9964673014393435, 0.9964646378352872, 0.9964980862687037, 0.9965024227282658, 0.9965277846391312, 0.9965241604877082, 0.9965264938578435, 0.99656302603098, 0.9966497321420611, 0.9966582957707973, 0.996689419489724, 0.9966958605553957, 0.9966999970344618, 0.9967032579271679, 0.9967209840710756, 0.9967417354378625, 0.9967244075799626, 0.9967407415264924, 0.9967544942590121, 0.9967438494248201, 0.9967520220499875, 0.9967631821547419, 0.9967543020873116, 0.9967661704554457, 0.9967673325155916, 0.9967872049975158, 0.9967937750112478, 0.9967944445558206, 0.9968081056975772, 0.9968008474641329, 0.9968141782409641, 0.9968019184973023, 0.9968098079822769, 0.9968485495650117, 0.996870214855649, 0.9968634490231488, 0.996872777988718, 0.9968723859581685, 0.996872744549855, 0.9968943962721835, 0.996892812969855, 0.9968840006925027, 0.9968929907053428, 0.9968996177387226, 0.9968889258505715, 0.9968972501320014, 0.9968933106834938, 0.9969057430651701, 0.9969185865806389, 0.996928011092835, 0.9969530813833145, 0.996933811420857, 0.9969345861946827, 0.9969209871185813, 0.9969411221496202, 0.9969303775860192, 0.9969525557751043, 0.9969482046079634, 0.9969556780137308, 0.9969465831529543, 0.9969540043534839, 0.9969510822474121, 0.9969501698768992], 'mDice': [0.8591889622682309, 0.903481808682477, 0.9113331159288082, 0.9189550095410356, 0.9232037042311959, 0.9254270651762599, 0.92744290692086, 0.9303341253459105, 0.9322899832746673, 0.9336780051434778, 0.9342247188112333, 0.9349708476771768, 0.9366361163999593, 0.9375898191817417, 0.9381408324430285, 0.9389551337699444, 0.9392478677348648, 0.9404947972217195, 0.9393417619429305, 0.9415034020408842, 0.9415574444299909, 0.9420430074517948, 0.9423385689025481, 0.9429344515270096, 0.9433932943660212, 0.9437826213996121, 0.9441053512622387, 0.9440607579322703, 0.9447506938461999, 0.9451432517958921, 0.9448261310838166, 0.945218155218811, 0.9450354266077908, 0.9457615184219681, 0.9463487881787686, 0.9462232087296563, 0.945647330062072, 0.9455171310432365, 0.9485449335316745, 0.9491151230194593, 0.9495448061732961, 0.9502419737548571, 0.9503209388229404, 0.9501827294890419, 0.9505043949155045, 0.9510644715918426, 0.9503744507075488, 0.9511862006099104, 0.9515243110746009, 0.9517242629766006, 0.9511161564826179, 0.9511680932319577, 0.9512078167341432, 0.9520851308053336, 0.9521781151974714, 0.9520532937489479, 0.9522579109104009, 0.9522939239038983, 0.9525117386341413, 0.9516002220403615, 0.9523025886984129, 0.9523200714315395, 0.9528120041380143, 0.9533981973079961, 0.9538249854853607, 0.9537990447597997, 0.9533728877216762, 0.9545174806864456, 0.9540654322950295, 0.9545670943421328, 0.9540566742417858, 0.9548040359850894, 0.9543244590508123, 0.9547058191220461, 0.9544994142774258, 0.9546004012838217, 0.9545452215054977, 0.9547727586588711, 0.9554038523195995, 0.9551570365668381, 0.9551615866500648, 0.9551559901835429, 0.9558118318008606, 0.955568826749732, 0.9558499112009997, 0.9558611537168547, 0.9561647620005166, 0.9562404846592055, 0.9559868462554814, 0.9556901453943004, 0.956227271837765, 0.9562212704508003, 0.9563510938680566], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.35it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.70it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.09it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.58it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.04it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.19it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:41,  5.95it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:39,  6.21it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:43,  5.63it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:45,  5.30it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:43,  5.57it/s]predicting train subjects:   2%|▏         | 6/247 [00:01<00:41,  5.80it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:40,  5.94it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:40,  5.93it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:39,  6.01it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:39,  6.07it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:38,  6.13it/s]predicting train subjects:   5%|▍         | 12/247 [00:02<00:39,  6.02it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:38,  6.13it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:37,  6.18it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:37,  6.22it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:37,  6.24it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:36,  6.29it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:36,  6.29it/s]predicting train subjects:   8%|▊         | 19/247 [00:03<00:35,  6.34it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:35,  6.31it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:35,  6.37it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:35,  6.39it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:33,  6.63it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:33,  6.68it/s]predicting train subjects:  10%|█         | 25/247 [00:04<00:32,  6.79it/s]predicting train subjects:  11%|█         | 26/247 [00:04<00:32,  6.89it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:31,  7.01it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:31,  7.01it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:30,  7.06it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:31,  6.90it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:30,  7.02it/s]predicting train subjects:  13%|█▎        | 32/247 [00:05<00:31,  6.90it/s]predicting train subjects:  13%|█▎        | 33/247 [00:05<00:30,  6.97it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:31,  6.86it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:31,  6.75it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:30,  6.84it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:30,  6.97it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:30,  6.96it/s]predicting train subjects:  16%|█▌        | 39/247 [00:06<00:29,  7.02it/s]predicting train subjects:  16%|█▌        | 40/247 [00:06<00:29,  6.99it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:29,  6.87it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:30,  6.76it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:30,  6.79it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:29,  6.85it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:29,  6.88it/s]predicting train subjects:  19%|█▊        | 46/247 [00:07<00:29,  6.85it/s]predicting train subjects:  19%|█▉        | 47/247 [00:07<00:29,  6.85it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:28,  6.91it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:28,  6.94it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:28,  6.81it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:28,  6.87it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:28,  6.86it/s]predicting train subjects:  21%|██▏       | 53/247 [00:08<00:28,  6.89it/s]predicting train subjects:  22%|██▏       | 54/247 [00:08<00:28,  6.79it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:28,  6.75it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:28,  6.79it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:27,  6.81it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:27,  6.84it/s]predicting train subjects:  24%|██▍       | 59/247 [00:09<00:29,  6.45it/s]predicting train subjects:  24%|██▍       | 60/247 [00:09<00:29,  6.44it/s]predicting train subjects:  25%|██▍       | 61/247 [00:09<00:29,  6.34it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:29,  6.34it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:29,  6.34it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:29,  6.28it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:28,  6.29it/s]predicting train subjects:  27%|██▋       | 66/247 [00:10<00:28,  6.29it/s]predicting train subjects:  27%|██▋       | 67/247 [00:10<00:28,  6.31it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:28,  6.33it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:28,  6.35it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:28,  6.20it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:28,  6.24it/s]predicting train subjects:  29%|██▉       | 72/247 [00:11<00:28,  6.25it/s]predicting train subjects:  30%|██▉       | 73/247 [00:11<00:27,  6.32it/s]predicting train subjects:  30%|██▉       | 74/247 [00:11<00:27,  6.37it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:27,  6.27it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:28,  6.07it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:33,  5.14it/s]predicting train subjects:  32%|███▏      | 78/247 [00:12<00:34,  4.95it/s]predicting train subjects:  32%|███▏      | 79/247 [00:12<00:31,  5.37it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:30,  5.42it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:34,  4.83it/s]predicting train subjects:  33%|███▎      | 82/247 [00:13<00:34,  4.82it/s]predicting train subjects:  34%|███▎      | 83/247 [00:13<00:32,  4.98it/s]predicting train subjects:  34%|███▍      | 84/247 [00:13<00:31,  5.16it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:30,  5.28it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:30,  5.36it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:30,  5.32it/s]predicting train subjects:  36%|███▌      | 88/247 [00:14<00:29,  5.39it/s]predicting train subjects:  36%|███▌      | 89/247 [00:14<00:28,  5.46it/s]predicting train subjects:  36%|███▋      | 90/247 [00:14<00:29,  5.32it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:29,  5.37it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:28,  5.43it/s]predicting train subjects:  38%|███▊      | 93/247 [00:15<00:28,  5.33it/s]predicting train subjects:  38%|███▊      | 94/247 [00:15<00:28,  5.36it/s]predicting train subjects:  38%|███▊      | 95/247 [00:15<00:28,  5.41it/s]predicting train subjects:  39%|███▉      | 96/247 [00:15<00:27,  5.47it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:27,  5.48it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:27,  5.51it/s]predicting train subjects:  40%|████      | 99/247 [00:16<00:26,  5.50it/s]predicting train subjects:  40%|████      | 100/247 [00:16<00:26,  5.56it/s]predicting train subjects:  41%|████      | 101/247 [00:16<00:25,  5.64it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:25,  5.76it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:24,  5.88it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:24,  5.92it/s]predicting train subjects:  43%|████▎     | 105/247 [00:17<00:23,  5.94it/s]predicting train subjects:  43%|████▎     | 106/247 [00:17<00:23,  5.97it/s]predicting train subjects:  43%|████▎     | 107/247 [00:17<00:23,  6.02it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:22,  6.05it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:23,  6.00it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:22,  6.02it/s]predicting train subjects:  45%|████▍     | 111/247 [00:18<00:22,  6.06it/s]predicting train subjects:  45%|████▌     | 112/247 [00:18<00:22,  6.08it/s]predicting train subjects:  46%|████▌     | 113/247 [00:18<00:21,  6.11it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:21,  6.11it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:21,  6.13it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:21,  6.10it/s]predicting train subjects:  47%|████▋     | 117/247 [00:19<00:21,  6.08it/s]predicting train subjects:  48%|████▊     | 118/247 [00:19<00:21,  6.11it/s]predicting train subjects:  48%|████▊     | 119/247 [00:19<00:20,  6.30it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:19,  6.42it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:19,  6.56it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:18,  6.66it/s]predicting train subjects:  50%|████▉     | 123/247 [00:19<00:18,  6.70it/s]predicting train subjects:  50%|█████     | 124/247 [00:20<00:18,  6.77it/s]predicting train subjects:  51%|█████     | 125/247 [00:20<00:17,  6.81it/s]predicting train subjects:  51%|█████     | 126/247 [00:20<00:17,  6.84it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:17,  6.80it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:17,  6.76it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:20<00:17,  6.78it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:21<00:17,  6.77it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:21<00:17,  6.69it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:21<00:17,  6.68it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:21<00:17,  6.66it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:16,  6.67it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:21<00:16,  6.65it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:21<00:16,  6.80it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:22<00:15,  6.90it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:22<00:15,  6.98it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:22<00:15,  7.02it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:22<00:15,  7.06it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:14,  7.09it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:14,  7.14it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:22<00:14,  7.07it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:23<00:14,  7.09it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:23<00:14,  7.08it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:23<00:14,  7.07it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:23<00:14,  7.02it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:14,  6.99it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:13,  7.00it/s]predicting train subjects:  61%|██████    | 150/247 [00:23<00:14,  6.72it/s]predicting train subjects:  61%|██████    | 151/247 [00:24<00:14,  6.79it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:24<00:13,  6.86it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:24<00:13,  6.98it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:24<00:14,  6.47it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:24<00:14,  6.20it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:24<00:14,  6.08it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:25<00:14,  6.03it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:25<00:14,  5.98it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:25<00:14,  5.94it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:25<00:14,  5.94it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:25<00:14,  5.93it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:25<00:14,  5.86it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:26<00:14,  5.83it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:26<00:14,  5.81it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:26<00:14,  5.75it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:26<00:14,  5.75it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:26<00:13,  5.78it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:26<00:13,  5.80it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:27<00:13,  5.84it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:27<00:13,  5.88it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:27<00:12,  5.91it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:27<00:13,  5.77it/s]predicting train subjects:  70%|███████   | 173/247 [00:27<00:13,  5.35it/s]predicting train subjects:  70%|███████   | 174/247 [00:27<00:12,  5.78it/s]predicting train subjects:  71%|███████   | 175/247 [00:28<00:13,  5.33it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:28<00:12,  5.70it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:28<00:11,  6.00it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:28<00:11,  6.18it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:28<00:10,  6.36it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:28<00:10,  6.53it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:29<00:10,  6.45it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:29<00:09,  6.51it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:29<00:09,  6.60it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:29<00:09,  6.70it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:29<00:09,  6.78it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:29<00:08,  6.84it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:29<00:08,  6.81it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:30<00:08,  6.71it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:30<00:08,  6.69it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:30<00:08,  6.68it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:30<00:08,  6.74it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:30<00:08,  6.77it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:30<00:07,  6.80it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:31<00:07,  6.91it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:31<00:07,  7.05it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:31<00:07,  7.12it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:31<00:06,  7.15it/s]predicting train subjects:  80%|████████  | 198/247 [00:31<00:06,  7.26it/s]predicting train subjects:  81%|████████  | 199/247 [00:31<00:06,  7.29it/s]predicting train subjects:  81%|████████  | 200/247 [00:31<00:06,  7.30it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:31<00:06,  7.34it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:32<00:06,  7.39it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:32<00:05,  7.40it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:32<00:05,  7.49it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:32<00:05,  7.54it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:32<00:05,  7.56it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:32<00:05,  7.60it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:32<00:05,  7.61it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:33<00:05,  7.54it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:33<00:04,  7.57it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:33<00:04,  7.59it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:33<00:04,  7.44it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:33<00:04,  7.31it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:33<00:04,  7.23it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:33<00:04,  7.24it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:33<00:04,  7.23it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:34<00:04,  7.21it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:34<00:04,  7.21it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:34<00:03,  7.22it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:34<00:03,  7.18it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:34<00:03,  7.08it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:34<00:03,  7.11it/s]predicting train subjects:  90%|█████████ | 223/247 [00:34<00:03,  7.16it/s]predicting train subjects:  91%|█████████ | 224/247 [00:35<00:03,  7.20it/s]predicting train subjects:  91%|█████████ | 225/247 [00:35<00:03,  7.14it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:35<00:02,  7.14it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:35<00:02,  7.17it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:35<00:02,  7.16it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:35<00:02,  7.17it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:35<00:02,  6.75it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:36<00:02,  6.58it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:36<00:02,  6.45it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:36<00:02,  6.35it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:36<00:02,  6.27it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:36<00:01,  6.24it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:36<00:01,  6.18it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:37<00:01,  6.15it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:37<00:01,  6.16it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:37<00:01,  6.17it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:37<00:01,  6.18it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:37<00:00,  6.19it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:37<00:00,  6.19it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:38<00:00,  6.17it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:38<00:00,  6.14it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:38<00:00,  6.14it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:38<00:00,  6.16it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  6.15it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  6.38it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 74.46it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 81.10it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 82.10it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 83.28it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:02, 84.83it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 85.61it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 87.48it/s]saving BB  train1-THALAMUS:  26%|██▌       | 64/247 [00:00<00:02, 85.52it/s]saving BB  train1-THALAMUS:  29%|██▉       | 72/247 [00:00<00:02, 83.14it/s]saving BB  train1-THALAMUS:  32%|███▏      | 80/247 [00:00<00:02, 81.79it/s]saving BB  train1-THALAMUS:  36%|███▌      | 88/247 [00:01<00:02, 78.40it/s]saving BB  train1-THALAMUS:  39%|███▉      | 96/247 [00:01<00:01, 75.64it/s]saving BB  train1-THALAMUS:  42%|████▏     | 104/247 [00:01<00:01, 73.91it/s]saving BB  train1-THALAMUS:  45%|████▌     | 112/247 [00:01<00:01, 75.18it/s]saving BB  train1-THALAMUS:  49%|████▊     | 120/247 [00:01<00:01, 75.81it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 129/247 [00:01<00:01, 77.22it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 138/247 [00:01<00:01, 78.74it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 147/247 [00:01<00:01, 79.07it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 156/247 [00:01<00:01, 79.88it/s]saving BB  train1-THALAMUS:  66%|██████▋   | 164/247 [00:02<00:01, 78.75it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 172/247 [00:02<00:00, 77.97it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 180/247 [00:02<00:00, 77.54it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 188/247 [00:02<00:00, 77.50it/s]saving BB  train1-THALAMUS:  80%|███████▉  | 197/247 [00:02<00:00, 78.67it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 206/247 [00:02<00:00, 80.41it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 215/247 [00:02<00:00, 82.31it/s]saving BB  train1-THALAMUS:  91%|█████████ | 224/247 [00:02<00:00, 84.29it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 233/247 [00:02<00:00, 83.94it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 242/247 [00:03<00:00, 81.70it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 80.59it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<04:04,  1.01it/s]Loading train:   1%|          | 2/247 [00:01<03:52,  1.05it/s]Loading train:   1%|          | 3/247 [00:02<03:41,  1.10it/s]Loading train:   2%|▏         | 4/247 [00:03<03:46,  1.07it/s]Loading train:   2%|▏         | 5/247 [00:04<03:25,  1.18it/s]Loading train:   2%|▏         | 6/247 [00:04<03:13,  1.25it/s]Loading train:   3%|▎         | 7/247 [00:05<03:02,  1.32it/s]Loading train:   3%|▎         | 8/247 [00:06<02:53,  1.38it/s]Loading train:   4%|▎         | 9/247 [00:06<02:44,  1.45it/s]Loading train:   4%|▍         | 10/247 [00:07<02:37,  1.50it/s]Loading train:   4%|▍         | 11/247 [00:08<02:33,  1.53it/s]Loading train:   5%|▍         | 12/247 [00:08<02:30,  1.56it/s]Loading train:   5%|▌         | 13/247 [00:09<02:31,  1.54it/s]Loading train:   6%|▌         | 14/247 [00:10<02:31,  1.54it/s]Loading train:   6%|▌         | 15/247 [00:10<02:30,  1.55it/s]Loading train:   6%|▋         | 16/247 [00:11<02:28,  1.56it/s]Loading train:   7%|▋         | 17/247 [00:11<02:28,  1.55it/s]Loading train:   7%|▋         | 18/247 [00:12<02:28,  1.54it/s]Loading train:   8%|▊         | 19/247 [00:13<02:27,  1.54it/s]Loading train:   8%|▊         | 20/247 [00:13<02:27,  1.54it/s]Loading train:   9%|▊         | 21/247 [00:14<02:23,  1.57it/s]Loading train:   9%|▉         | 22/247 [00:15<02:21,  1.59it/s]Loading train:   9%|▉         | 23/247 [00:15<02:18,  1.62it/s]Loading train:  10%|▉         | 24/247 [00:16<02:15,  1.64it/s]Loading train:  10%|█         | 25/247 [00:16<02:15,  1.64it/s]Loading train:  11%|█         | 26/247 [00:17<02:12,  1.67it/s]Loading train:  11%|█         | 27/247 [00:18<02:11,  1.67it/s]Loading train:  11%|█▏        | 28/247 [00:18<02:08,  1.71it/s]Loading train:  12%|█▏        | 29/247 [00:19<02:06,  1.73it/s]Loading train:  12%|█▏        | 30/247 [00:19<02:05,  1.72it/s]Loading train:  13%|█▎        | 31/247 [00:20<02:04,  1.74it/s]Loading train:  13%|█▎        | 32/247 [00:20<02:01,  1.76it/s]Loading train:  13%|█▎        | 33/247 [00:21<02:00,  1.77it/s]Loading train:  14%|█▍        | 34/247 [00:22<02:00,  1.77it/s]Loading train:  14%|█▍        | 35/247 [00:22<02:02,  1.73it/s]Loading train:  15%|█▍        | 36/247 [00:23<02:04,  1.70it/s]Loading train:  15%|█▍        | 37/247 [00:23<02:05,  1.68it/s]Loading train:  15%|█▌        | 38/247 [00:24<02:03,  1.69it/s]Loading train:  16%|█▌        | 39/247 [00:25<02:02,  1.70it/s]Loading train:  16%|█▌        | 40/247 [00:25<02:00,  1.72it/s]Loading train:  17%|█▋        | 41/247 [00:26<02:01,  1.70it/s]Loading train:  17%|█▋        | 42/247 [00:26<02:00,  1.70it/s]Loading train:  17%|█▋        | 43/247 [00:27<02:01,  1.68it/s]Loading train:  18%|█▊        | 44/247 [00:28<02:01,  1.67it/s]Loading train:  18%|█▊        | 45/247 [00:28<01:59,  1.69it/s]Loading train:  19%|█▊        | 46/247 [00:29<01:58,  1.70it/s]Loading train:  19%|█▉        | 47/247 [00:29<01:56,  1.71it/s]Loading train:  19%|█▉        | 48/247 [00:30<01:55,  1.72it/s]Loading train:  20%|█▉        | 49/247 [00:30<01:54,  1.74it/s]Loading train:  20%|██        | 50/247 [00:31<01:52,  1.76it/s]Loading train:  21%|██        | 51/247 [00:32<01:50,  1.77it/s]Loading train:  21%|██        | 52/247 [00:32<01:52,  1.73it/s]Loading train:  21%|██▏       | 53/247 [00:33<01:54,  1.69it/s]Loading train:  22%|██▏       | 54/247 [00:33<01:56,  1.65it/s]Loading train:  22%|██▏       | 55/247 [00:34<01:57,  1.63it/s]Loading train:  23%|██▎       | 56/247 [00:35<01:57,  1.62it/s]Loading train:  23%|██▎       | 57/247 [00:35<01:58,  1.61it/s]Loading train:  23%|██▎       | 58/247 [00:36<01:56,  1.62it/s]Loading train:  24%|██▍       | 59/247 [00:37<01:59,  1.57it/s]Loading train:  24%|██▍       | 60/247 [00:37<01:59,  1.57it/s]Loading train:  25%|██▍       | 61/247 [00:38<01:59,  1.56it/s]Loading train:  25%|██▌       | 62/247 [00:39<01:59,  1.55it/s]Loading train:  26%|██▌       | 63/247 [00:39<01:59,  1.54it/s]Loading train:  26%|██▌       | 64/247 [00:40<01:58,  1.54it/s]Loading train:  26%|██▋       | 65/247 [00:40<01:56,  1.56it/s]Loading train:  27%|██▋       | 66/247 [00:41<01:59,  1.52it/s]Loading train:  27%|██▋       | 67/247 [00:42<02:00,  1.49it/s]Loading train:  28%|██▊       | 68/247 [00:43<02:00,  1.49it/s]Loading train:  28%|██▊       | 69/247 [00:43<01:57,  1.52it/s]Loading train:  28%|██▊       | 70/247 [00:44<01:56,  1.51it/s]Loading train:  29%|██▊       | 71/247 [00:44<01:56,  1.52it/s]Loading train:  29%|██▉       | 72/247 [00:45<01:54,  1.53it/s]Loading train:  30%|██▉       | 73/247 [00:46<01:52,  1.55it/s]Loading train:  30%|██▉       | 74/247 [00:46<01:56,  1.49it/s]Loading train:  30%|███       | 75/247 [00:47<01:56,  1.48it/s]Loading train:  31%|███       | 76/247 [00:48<01:54,  1.50it/s]Loading train:  31%|███       | 77/247 [00:49<02:17,  1.24it/s]Loading train:  32%|███▏      | 78/247 [00:50<02:23,  1.18it/s]Loading train:  32%|███▏      | 79/247 [00:51<02:24,  1.16it/s]Loading train:  32%|███▏      | 80/247 [00:52<02:21,  1.18it/s]Loading train:  33%|███▎      | 81/247 [00:53<02:30,  1.10it/s]Loading train:  33%|███▎      | 82/247 [00:53<02:27,  1.12it/s]Loading train:  34%|███▎      | 83/247 [00:54<02:19,  1.18it/s]Loading train:  34%|███▍      | 84/247 [00:55<02:14,  1.21it/s]Loading train:  34%|███▍      | 85/247 [00:56<02:10,  1.24it/s]Loading train:  35%|███▍      | 86/247 [00:57<02:08,  1.25it/s]Loading train:  35%|███▌      | 87/247 [00:57<02:05,  1.28it/s]Loading train:  36%|███▌      | 88/247 [00:58<02:02,  1.30it/s]Loading train:  36%|███▌      | 89/247 [00:59<02:02,  1.29it/s]Loading train:  36%|███▋      | 90/247 [01:00<02:02,  1.28it/s]Loading train:  37%|███▋      | 91/247 [01:00<02:02,  1.28it/s]Loading train:  37%|███▋      | 92/247 [01:01<02:02,  1.27it/s]Loading train:  38%|███▊      | 93/247 [01:02<02:01,  1.27it/s]Loading train:  38%|███▊      | 94/247 [01:03<02:03,  1.23it/s]Loading train:  38%|███▊      | 95/247 [01:04<02:01,  1.25it/s]Loading train:  39%|███▉      | 96/247 [01:04<02:02,  1.23it/s]Loading train:  39%|███▉      | 97/247 [01:05<02:02,  1.22it/s]Loading train:  40%|███▉      | 98/247 [01:06<02:03,  1.20it/s]Loading train:  40%|████      | 99/247 [01:07<02:01,  1.22it/s]Loading train:  40%|████      | 100/247 [01:08<01:55,  1.27it/s]Loading train:  41%|████      | 101/247 [01:08<01:50,  1.33it/s]Loading train:  41%|████▏     | 102/247 [01:09<01:46,  1.37it/s]Loading train:  42%|████▏     | 103/247 [01:10<01:43,  1.39it/s]Loading train:  42%|████▏     | 104/247 [01:10<01:40,  1.42it/s]Loading train:  43%|████▎     | 105/247 [01:11<01:40,  1.41it/s]Loading train:  43%|████▎     | 106/247 [01:12<01:39,  1.42it/s]Loading train:  43%|████▎     | 107/247 [01:12<01:37,  1.44it/s]Loading train:  44%|████▎     | 108/247 [01:13<01:35,  1.45it/s]Loading train:  44%|████▍     | 109/247 [01:14<01:32,  1.48it/s]Loading train:  45%|████▍     | 110/247 [01:14<01:30,  1.51it/s]Loading train:  45%|████▍     | 111/247 [01:15<01:29,  1.52it/s]Loading train:  45%|████▌     | 112/247 [01:16<01:28,  1.52it/s]Loading train:  46%|████▌     | 113/247 [01:16<01:27,  1.54it/s]Loading train:  46%|████▌     | 114/247 [01:17<01:26,  1.54it/s]Loading train:  47%|████▋     | 115/247 [01:18<01:25,  1.54it/s]Loading train:  47%|████▋     | 116/247 [01:18<01:26,  1.52it/s]Loading train:  47%|████▋     | 117/247 [01:19<01:25,  1.51it/s]Loading train:  48%|████▊     | 118/247 [01:20<01:24,  1.52it/s]Loading train:  48%|████▊     | 119/247 [01:20<01:22,  1.55it/s]Loading train:  49%|████▊     | 120/247 [01:21<01:20,  1.58it/s]Loading train:  49%|████▉     | 121/247 [01:22<01:20,  1.57it/s]Loading train:  49%|████▉     | 122/247 [01:22<01:19,  1.58it/s]Loading train:  50%|████▉     | 123/247 [01:23<01:18,  1.58it/s]Loading train:  50%|█████     | 124/247 [01:23<01:17,  1.59it/s]Loading train:  51%|█████     | 125/247 [01:24<01:17,  1.58it/s]Loading train:  51%|█████     | 126/247 [01:25<01:17,  1.56it/s]Loading train:  51%|█████▏    | 127/247 [01:25<01:18,  1.53it/s]Loading train:  52%|█████▏    | 128/247 [01:26<01:17,  1.53it/s]Loading train:  52%|█████▏    | 129/247 [01:27<01:17,  1.52it/s]Loading train:  53%|█████▎    | 130/247 [01:27<01:20,  1.45it/s]Loading train:  53%|█████▎    | 131/247 [01:28<01:19,  1.47it/s]Loading train:  53%|█████▎    | 132/247 [01:29<01:17,  1.48it/s]Loading train:  54%|█████▍    | 133/247 [01:29<01:16,  1.50it/s]Loading train:  54%|█████▍    | 134/247 [01:30<01:15,  1.50it/s]Loading train:  55%|█████▍    | 135/247 [01:31<01:14,  1.51it/s]Loading train:  55%|█████▌    | 136/247 [01:31<01:11,  1.55it/s]Loading train:  55%|█████▌    | 137/247 [01:32<01:09,  1.59it/s]Loading train:  56%|█████▌    | 138/247 [01:33<01:07,  1.61it/s]Loading train:  56%|█████▋    | 139/247 [01:33<01:06,  1.64it/s]Loading train:  57%|█████▋    | 140/247 [01:34<01:04,  1.67it/s]Loading train:  57%|█████▋    | 141/247 [01:34<01:02,  1.70it/s]Loading train:  57%|█████▋    | 142/247 [01:35<01:01,  1.71it/s]Loading train:  58%|█████▊    | 143/247 [01:35<00:59,  1.74it/s]Loading train:  58%|█████▊    | 144/247 [01:36<00:58,  1.75it/s]Loading train:  59%|█████▊    | 145/247 [01:37<00:58,  1.75it/s]Loading train:  59%|█████▉    | 146/247 [01:37<00:57,  1.74it/s]Loading train:  60%|█████▉    | 147/247 [01:38<00:57,  1.74it/s]Loading train:  60%|█████▉    | 148/247 [01:38<00:56,  1.74it/s]Loading train:  60%|██████    | 149/247 [01:39<00:55,  1.76it/s]Loading train:  61%|██████    | 150/247 [01:39<00:55,  1.73it/s]Loading train:  61%|██████    | 151/247 [01:40<00:55,  1.72it/s]Loading train:  62%|██████▏   | 152/247 [01:41<00:55,  1.73it/s]Loading train:  62%|██████▏   | 153/247 [01:41<00:54,  1.72it/s]Loading train:  62%|██████▏   | 154/247 [01:42<00:56,  1.64it/s]Loading train:  63%|██████▎   | 155/247 [01:42<00:56,  1.63it/s]Loading train:  63%|██████▎   | 156/247 [01:43<00:57,  1.58it/s]Loading train:  64%|██████▎   | 157/247 [01:44<00:57,  1.55it/s]Loading train:  64%|██████▍   | 158/247 [01:44<00:58,  1.53it/s]Loading train:  64%|██████▍   | 159/247 [01:45<00:57,  1.54it/s]Loading train:  65%|██████▍   | 160/247 [01:46<00:57,  1.52it/s]Loading train:  65%|██████▌   | 161/247 [01:46<00:56,  1.52it/s]Loading train:  66%|██████▌   | 162/247 [01:47<00:56,  1.50it/s]Loading train:  66%|██████▌   | 163/247 [01:48<00:56,  1.48it/s]Loading train:  66%|██████▋   | 164/247 [01:48<00:54,  1.52it/s]Loading train:  67%|██████▋   | 165/247 [01:49<00:53,  1.53it/s]Loading train:  67%|██████▋   | 166/247 [01:50<00:54,  1.50it/s]Loading train:  68%|██████▊   | 167/247 [01:50<00:53,  1.51it/s]Loading train:  68%|██████▊   | 168/247 [01:51<00:52,  1.51it/s]Loading train:  68%|██████▊   | 169/247 [01:52<00:52,  1.50it/s]Loading train:  69%|██████▉   | 170/247 [01:52<00:51,  1.49it/s]Loading train:  69%|██████▉   | 171/247 [01:53<00:51,  1.48it/s]Loading train:  70%|██████▉   | 172/247 [01:54<00:55,  1.35it/s]Loading train:  70%|███████   | 173/247 [01:55<00:57,  1.28it/s]Loading train:  70%|███████   | 174/247 [01:56<00:58,  1.25it/s]Loading train:  71%|███████   | 175/247 [01:57<01:01,  1.16it/s]Loading train:  71%|███████▏  | 176/247 [01:57<00:56,  1.25it/s]Loading train:  72%|███████▏  | 177/247 [01:58<00:52,  1.33it/s]Loading train:  72%|███████▏  | 178/247 [01:59<00:49,  1.40it/s]Loading train:  72%|███████▏  | 179/247 [01:59<00:47,  1.45it/s]Loading train:  73%|███████▎  | 180/247 [02:00<00:44,  1.49it/s]Loading train:  73%|███████▎  | 181/247 [02:01<00:43,  1.52it/s]Loading train:  74%|███████▎  | 182/247 [02:01<00:41,  1.57it/s]Loading train:  74%|███████▍  | 183/247 [02:02<00:40,  1.57it/s]Loading train:  74%|███████▍  | 184/247 [02:02<00:40,  1.57it/s]Loading train:  75%|███████▍  | 185/247 [02:03<00:39,  1.56it/s]Loading train:  75%|███████▌  | 186/247 [02:04<00:38,  1.57it/s]Loading train:  76%|███████▌  | 187/247 [02:04<00:37,  1.59it/s]Loading train:  76%|███████▌  | 188/247 [02:05<00:37,  1.57it/s]Loading train:  77%|███████▋  | 189/247 [02:06<00:36,  1.57it/s]Loading train:  77%|███████▋  | 190/247 [02:06<00:36,  1.57it/s]Loading train:  77%|███████▋  | 191/247 [02:07<00:35,  1.56it/s]Loading train:  78%|███████▊  | 192/247 [02:08<00:35,  1.57it/s]Loading train:  78%|███████▊  | 193/247 [02:08<00:34,  1.58it/s]Loading train:  79%|███████▊  | 194/247 [02:09<00:34,  1.55it/s]Loading train:  79%|███████▉  | 195/247 [02:09<00:33,  1.56it/s]Loading train:  79%|███████▉  | 196/247 [02:10<00:32,  1.58it/s]Loading train:  80%|███████▉  | 197/247 [02:11<00:31,  1.60it/s]Loading train:  80%|████████  | 198/247 [02:11<00:30,  1.62it/s]Loading train:  81%|████████  | 199/247 [02:12<00:29,  1.63it/s]Loading train:  81%|████████  | 200/247 [02:13<00:29,  1.62it/s]Loading train:  81%|████████▏ | 201/247 [02:13<00:28,  1.60it/s]Loading train:  82%|████████▏ | 202/247 [02:14<00:28,  1.58it/s]Loading train:  82%|████████▏ | 203/247 [02:14<00:27,  1.58it/s]Loading train:  83%|████████▎ | 204/247 [02:15<00:27,  1.57it/s]Loading train:  83%|████████▎ | 205/247 [02:16<00:26,  1.57it/s]Loading train:  83%|████████▎ | 206/247 [02:16<00:26,  1.57it/s]Loading train:  84%|████████▍ | 207/247 [02:17<00:25,  1.58it/s]Loading train:  84%|████████▍ | 208/247 [02:18<00:24,  1.59it/s]Loading train:  85%|████████▍ | 209/247 [02:18<00:23,  1.59it/s]Loading train:  85%|████████▌ | 210/247 [02:19<00:22,  1.61it/s]Loading train:  85%|████████▌ | 211/247 [02:19<00:22,  1.60it/s]Loading train:  86%|████████▌ | 212/247 [02:20<00:21,  1.61it/s]Loading train:  86%|████████▌ | 213/247 [02:21<00:20,  1.63it/s]Loading train:  87%|████████▋ | 214/247 [02:21<00:20,  1.65it/s]Loading train:  87%|████████▋ | 215/247 [02:22<00:19,  1.65it/s]Loading train:  87%|████████▋ | 216/247 [02:22<00:18,  1.67it/s]Loading train:  88%|████████▊ | 217/247 [02:23<00:17,  1.68it/s]Loading train:  88%|████████▊ | 218/247 [02:24<00:17,  1.66it/s]Loading train:  89%|████████▊ | 219/247 [02:24<00:16,  1.65it/s]Loading train:  89%|████████▉ | 220/247 [02:25<00:16,  1.65it/s]Loading train:  89%|████████▉ | 221/247 [02:26<00:15,  1.64it/s]Loading train:  90%|████████▉ | 222/247 [02:26<00:15,  1.64it/s]Loading train:  90%|█████████ | 223/247 [02:27<00:14,  1.64it/s]Loading train:  91%|█████████ | 224/247 [02:27<00:14,  1.63it/s]Loading train:  91%|█████████ | 225/247 [02:28<00:13,  1.64it/s]Loading train:  91%|█████████▏| 226/247 [02:29<00:12,  1.64it/s]Loading train:  92%|█████████▏| 227/247 [02:29<00:12,  1.64it/s]Loading train:  92%|█████████▏| 228/247 [02:30<00:11,  1.62it/s]Loading train:  93%|█████████▎| 229/247 [02:30<00:11,  1.62it/s]Loading train:  93%|█████████▎| 230/247 [02:31<00:10,  1.55it/s]Loading train:  94%|█████████▎| 231/247 [02:32<00:10,  1.47it/s]Loading train:  94%|█████████▍| 232/247 [02:33<00:10,  1.43it/s]Loading train:  94%|█████████▍| 233/247 [02:33<00:09,  1.42it/s]Loading train:  95%|█████████▍| 234/247 [02:34<00:09,  1.38it/s]Loading train:  95%|█████████▌| 235/247 [02:35<00:08,  1.34it/s]Loading train:  96%|█████████▌| 236/247 [02:36<00:08,  1.32it/s]Loading train:  96%|█████████▌| 237/247 [02:36<00:07,  1.32it/s]Loading train:  96%|█████████▋| 238/247 [02:37<00:06,  1.32it/s]Loading train:  97%|█████████▋| 239/247 [02:38<00:06,  1.31it/s]Loading train:  97%|█████████▋| 240/247 [02:39<00:05,  1.30it/s]Loading train:  98%|█████████▊| 241/247 [02:40<00:04,  1.30it/s]Loading train:  98%|█████████▊| 242/247 [02:40<00:03,  1.30it/s]Loading train:  98%|█████████▊| 243/247 [02:41<00:03,  1.31it/s]Loading train:  99%|█████████▉| 244/247 [02:42<00:02,  1.30it/s]Loading train:  99%|█████████▉| 245/247 [02:43<00:01,  1.29it/s]Loading train: 100%|█████████▉| 246/247 [02:43<00:00,  1.29it/s]Loading train: 100%|██████████| 247/247 [02:44<00:00,  1.29it/s]Loading train: 100%|██████████| 247/247 [02:44<00:00,  1.50it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 47.46it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:04, 48.15it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:04, 49.39it/s]concatenating: train:   9%|▊         | 21/247 [00:00<00:04, 49.44it/s]concatenating: train:  11%|█         | 27/247 [00:00<00:04, 51.80it/s]concatenating: train:  14%|█▍        | 34/247 [00:00<00:03, 54.09it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:03, 55.38it/s]concatenating: train:  19%|█▊        | 46/247 [00:00<00:03, 55.73it/s]concatenating: train:  21%|██        | 52/247 [00:00<00:03, 55.78it/s]concatenating: train:  23%|██▎       | 58/247 [00:01<00:03, 55.74it/s]concatenating: train:  26%|██▌       | 64/247 [00:01<00:03, 55.56it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 55.45it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:03, 54.95it/s]concatenating: train:  33%|███▎      | 82/247 [00:01<00:03, 53.81it/s]concatenating: train:  36%|███▌      | 88/247 [00:01<00:03, 50.80it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:03, 48.97it/s]concatenating: train:  40%|████      | 99/247 [00:01<00:03, 46.93it/s]concatenating: train:  43%|████▎     | 105/247 [00:02<00:02, 49.17it/s]concatenating: train:  45%|████▍     | 111/247 [00:02<00:02, 50.43it/s]concatenating: train:  47%|████▋     | 117/247 [00:02<00:02, 52.11it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 51.16it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 51.11it/s]concatenating: train:  55%|█████▍    | 135/247 [00:02<00:02, 48.47it/s]concatenating: train:  57%|█████▋    | 140/247 [00:02<00:02, 48.45it/s]concatenating: train:  59%|█████▉    | 146/247 [00:02<00:02, 49.18it/s]concatenating: train:  62%|██████▏   | 152/247 [00:02<00:01, 51.61it/s]concatenating: train:  64%|██████▍   | 158/247 [00:03<00:01, 53.18it/s]concatenating: train:  66%|██████▋   | 164/247 [00:03<00:01, 54.23it/s]concatenating: train:  69%|██████▉   | 170/247 [00:03<00:01, 54.91it/s]concatenating: train:  71%|███████▏  | 176/247 [00:03<00:01, 54.04it/s]concatenating: train:  74%|███████▎  | 182/247 [00:03<00:01, 53.91it/s]concatenating: train:  76%|███████▌  | 188/247 [00:03<00:01, 53.70it/s]concatenating: train:  79%|███████▊  | 194/247 [00:03<00:00, 53.39it/s]concatenating: train:  81%|████████  | 200/247 [00:03<00:00, 52.15it/s]concatenating: train:  83%|████████▎ | 206/247 [00:03<00:00, 51.86it/s]concatenating: train:  86%|████████▌ | 212/247 [00:04<00:00, 51.66it/s]concatenating: train:  88%|████████▊ | 218/247 [00:04<00:00, 52.56it/s]concatenating: train:  91%|█████████ | 224/247 [00:04<00:00, 52.90it/s]concatenating: train:  93%|█████████▎| 230/247 [00:04<00:00, 53.63it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 56.77it/s]concatenating: train:  99%|█████████▉| 244/247 [00:04<00:00, 59.04it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 53.23it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:11<00:46, 11.66s/it]Loading test:  40%|████      | 2/5 [00:24<00:36, 12.16s/it]Loading test:  60%|██████    | 3/5 [00:29<00:19,  9.89s/it]Loading test:  80%|████████  | 4/5 [00:33<00:08,  8.18s/it]Loading test: 100%|██████████| 5/5 [00:44<00:00,  8.85s/it]Loading test: 100%|██████████| 5/5 [00:44<00:00,  8.83s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 54.47it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      2020-01-22 02:38:15.693984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 02:38:15.694083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 02:38:15.694098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 02:38:15.694106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 02:38:15.694392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights from thalamus:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights from thalamus:   2%|▏         | 1/44 [00:00<00:07,  5.72it/s]loading the weights from thalamus:   7%|▋         | 3/44 [00:00<00:06,  6.59it/s]loading the weights from thalamus:   9%|▉         | 4/44 [00:00<00:06,  6.19it/s]loading the weights from thalamus:  18%|█▊        | 8/44 [00:00<00:04,  7.89it/s]loading the weights from thalamus:  20%|██        | 9/44 [00:00<00:05,  6.87it/s]loading the weights from thalamus:  25%|██▌       | 11/44 [00:01<00:04,  7.82it/s]loading the weights from thalamus:  27%|██▋       | 12/44 [00:01<00:04,  7.01it/s]loading the weights from thalamus:  39%|███▊      | 17/44 [00:01<00:02,  9.02it/s]loading the weights from thalamus:  43%|████▎     | 19/44 [00:01<00:02,  9.44it/s]loading the weights from thalamus:  48%|████▊     | 21/44 [00:02<00:03,  7.30it/s]loading the weights from thalamus:  57%|█████▋    | 25/44 [00:02<00:02,  9.03it/s]loading the weights from thalamus:  61%|██████▏   | 27/44 [00:02<00:01,  9.61it/s]loading the weights from thalamus:  66%|██████▌   | 29/44 [00:02<00:01,  9.64it/s]loading the weights from thalamus:  70%|███████   | 31/44 [00:03<00:01,  7.54it/s]loading the weights from thalamus:  80%|███████▉  | 35/44 [00:03<00:00,  9.07it/s]loading the weights from thalamus:  84%|████████▍ | 37/44 [00:03<00:00,  9.04it/s]loading the weights from thalamus:  89%|████████▊ | 39/44 [00:03<00:00,  8.92it/s]loading the weights from thalamus:  93%|█████████▎| 41/44 [00:04<00:00,  7.07it/s]loading the weights from thalamus: 100%|██████████| 44/44 [00:04<00:00, 10.59it/s]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Thalamus /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [6.53170019e-02 3.19804761e-02 7.71707025e-02 9.62138667e-03
 2.75468354e-02 7.05518474e-03 8.86666777e-02 1.14561529e-01
 8.20895171e-02 1.27736008e-02 2.89943765e-01 1.93020949e-01
 2.52374052e-04]
Train on 15606 samples, validate on 320 samples
Epoch 1/300
 - 35s - loss: 0.6024 - acc: 0.8733 - mDice: 0.3510 - val_loss: 0.6941 - val_acc: 0.9420 - val_mDice: 0.1983

Epoch 00001: val_mDice improved from -inf to 0.19829, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 31s - loss: 0.4409 - acc: 0.9363 - mDice: 0.5244 - val_loss: 0.6061 - val_acc: 0.9278 - val_mDice: 0.1283

Epoch 00002: val_mDice did not improve from 0.19829
Epoch 3/300
 - 30s - loss: 0.4049 - acc: 0.9421 - mDice: 0.5632 - val_loss: 0.3054 - val_acc: 0.9473 - val_mDice: 0.2091

Epoch 00003: val_mDice improved from 0.19829 to 0.20907, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 30s - loss: 0.3849 - acc: 0.9446 - mDice: 0.5847 - val_loss: 0.1654 - val_acc: 0.9462 - val_mDice: 0.1965

Epoch 00004: val_mDice did not improve from 0.20907
Epoch 5/300
 - 30s - loss: 0.3738 - acc: 0.9462 - mDice: 0.5968 - val_loss: 0.1111 - val_acc: 0.9481 - val_mDice: 0.2093

Epoch 00005: val_mDice improved from 0.20907 to 0.20931, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 30s - loss: 0.3594 - acc: 0.9474 - mDice: 0.6123 - val_loss: 0.0532 - val_acc: 0.9456 - val_mDice: 0.1862

Epoch 00006: val_mDice did not improve from 0.20931
Epoch 7/300
 - 31s - loss: 0.3523 - acc: 0.9482 - mDice: 0.6200 - val_loss: 0.0726 - val_acc: 0.9482 - val_mDice: 0.2165

Epoch 00007: val_mDice improved from 0.20931 to 0.21646, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 31s - loss: 0.3446 - acc: 0.9488 - mDice: 0.6283 - val_loss: 0.0591 - val_acc: 0.9439 - val_mDice: 0.2019

Epoch 00008: val_mDice did not improve from 0.21646
Epoch 9/300
 - 30s - loss: 0.3388 - acc: 0.9493 - mDice: 0.6346 - val_loss: -2.3235e-02 - val_acc: 0.9482 - val_mDice: 0.2110

Epoch 00009: val_mDice did not improve from 0.21646
Epoch 10/300
 - 30s - loss: 0.3331 - acc: 0.9499 - mDice: 0.6408 - val_loss: -5.9257e-02 - val_acc: 0.9460 - val_mDice: 0.2061

Epoch 00010: val_mDice did not improve from 0.21646
Epoch 11/300
 - 30s - loss: 0.3302 - acc: 0.9502 - mDice: 0.6439 - val_loss: -8.5617e-02 - val_acc: 0.9492 - val_mDice: 0.2068

Epoch 00011: val_mDice did not improve from 0.21646
Epoch 12/300
 - 30s - loss: 0.3273 - acc: 0.9504 - mDice: 0.6471 - val_loss: -1.0227e-01 - val_acc: 0.9487 - val_mDice: 0.2095

Epoch 00012: val_mDice did not improve from 0.21646
Epoch 13/300
 - 30s - loss: 0.3231 - acc: 0.9509 - mDice: 0.6516 - val_loss: -8.6212e-02 - val_acc: 0.9489 - val_mDice: 0.2133

Epoch 00013: val_mDice did not improve from 0.21646
Epoch 14/300
 - 30s - loss: 0.3195 - acc: 0.9511 - mDice: 0.6555 - val_loss: -9.6655e-02 - val_acc: 0.9480 - val_mDice: 0.2132

Epoch 00014: val_mDice did not improve from 0.21646
Epoch 15/300
 - 30s - loss: 0.3192 - acc: 0.9511 - mDice: 0.6557 - val_loss: -1.3371e-01 - val_acc: 0.9494 - val_mDice: 0.2164

Epoch 00015: val_mDice did not improve from 0.21646
Epoch 16/300
 - 30s - loss: 0.3218 - acc: 0.9490 - mDice: 0.6319 - val_loss: -1.5705e-01 - val_acc: 0.9486 - val_mDice: 0.2103

Epoch 00016: val_mDice did not improve from 0.21646
Epoch 17/300
 - 31s - loss: 0.3032 - acc: 0.9482 - mDice: 0.6250 - val_loss: -1.6004e-01 - val_acc: 0.9484 - val_mDice: 0.2055

Epoch 00017: val_mDice did not improve from 0.21646
Epoch 18/300
 - 30s - loss: 0.2899 - acc: 0.9480 - mDice: 0.6186 - val_loss: -1.6836e-01 - val_acc: 0.9493 - val_mDice: 0.2068

Epoch 00018: val_mDice did not improve from 0.21646
Epoch 19/300
 - 30s - loss: 0.2884 - acc: 0.9475 - mDice: 0.6169 - val_loss: -1.4850e-01 - val_acc: 0.9477 - val_mDice: 0.2033

Epoch 00019: val_mDice did not improve from 0.21646
Epoch 20/300
 - 30s - loss: 0.2862 - acc: 0.9475 - mDice: 0.6115 - val_loss: -1.6661e-01 - val_acc: 0.9490 - val_mDice: 0.1937

Epoch 00020: val_mDice did not improve from 0.21646
Epoch 21/300
 - 30s - loss: 0.2803 - acc: 0.9481 - mDice: 0.6214 - val_loss: -1.7560e-01 - val_acc: 0.9501 - val_mDice: 0.2095

Epoch 00021: val_mDice did not improve from 0.21646
Epoch 22/300
 - 31s - loss: 0.2851 - acc: 0.9472 - mDice: 0.6139 - val_loss: -1.7369e-01 - val_acc: 0.9489 - val_mDice: 0.2095

Epoch 00022: val_mDice did not improve from 0.21646

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 23/300
 - 30s - loss: 0.2678 - acc: 0.9485 - mDice: 0.6283 - val_loss: -1.9661e-01 - val_acc: 0.9501 - val_mDice: 0.2128

Epoch 00023: val_mDice did not improve from 0.21646
Epoch 24/300
 - 30s - loss: 0.2593 - acc: 0.9493 - mDice: 0.6393 - val_loss: -1.6118e-01 - val_acc: 0.9477 - val_mDice: 0.2048

Epoch 00024: val_mDice did not improve from 0.21646
Epoch 25/300
 - 30s - loss: 0.2526 - acc: 0.9501 - mDice: 0.6476 - val_loss: -1.9359e-01 - val_acc: 0.9503 - val_mDice: 0.2122

Epoch 00025: val_mDice did not improve from 0.21646
Epoch 26/300
 - 30s - loss: 0.2551 - acc: 0.9500 - mDice: 0.6447 - val_loss: -1.6708e-01 - val_acc: 0.9481 - val_mDice: 0.1978

Epoch 00026: val_mDice did not improve from 0.21646
Epoch 27/300
 - 30s - loss: 0.2552 - acc: 0.9501 - mDice: 0.6419 - val_loss: -7.9392e-02 - val_acc: 0.9426 - val_mDice: 0.1728

Epoch 00027: val_mDice did not improve from 0.21646
Epoch 28/300
 - 31s - loss: 0.2560 - acc: 0.9501 - mDice: 0.6419 - val_loss: -1.9617e-01 - val_acc: 0.9515 - val_mDice: 0.2131

Epoch 00028: val_mDice did not improve from 0.21646
Epoch 29/300
 - 30s - loss: 0.2478 - acc: 0.9505 - mDice: 0.6521 - val_loss: -2.1046e-01 - val_acc: 0.9500 - val_mDice: 0.2049

Epoch 00029: val_mDice did not improve from 0.21646
Epoch 30/300
 - 30s - loss: 0.2483 - acc: 0.9500 - mDice: 0.6451 - val_loss: -2.1997e-01 - val_acc: 0.9516 - val_mDice: 0.2136

Epoch 00030: val_mDice did not improve from 0.21646
Epoch 31/300
 - 31s - loss: 0.2453 - acc: 0.9503 - mDice: 0.6481 - val_loss: -2.2264e-01 - val_acc: 0.9511 - val_mDice: 0.2042

Epoch 00031: val_mDice did not improve from 0.21646
Epoch 32/300
 - 31s - loss: 0.2457 - acc: 0.9501 - mDice: 0.6482 - val_loss: -2.1271e-01 - val_acc: 0.9506 - val_mDice: 0.2113

Epoch 00032: val_mDice did not improve from 0.21646
Epoch 33/300
 - 31s - loss: 0.2422 - acc: 0.9505 - mDice: 0.6501 - val_loss: -2.2123e-01 - val_acc: 0.9515 - val_mDice: 0.2115

Epoch 00033: val_mDice did not improve from 0.21646
Epoch 34/300
 - 30s - loss: 0.2456 - acc: 0.9501 - mDice: 0.6396 - val_loss: -2.1832e-01 - val_acc: 0.9514 - val_mDice: 0.2071

Epoch 00034: val_mDice did not improve from 0.21646
Epoch 35/300
 - 31s - loss: 0.2427 - acc: 0.9498 - mDice: 0.6404 - val_loss: -2.3413e-01 - val_acc: 0.9494 - val_mDice: 0.1938

Epoch 00035: val_mDice did not improve from 0.21646
Epoch 36/300
 - 30s - loss: 0.2412 - acc: 0.9500 - mDice: 0.6436 - val_loss: -2.1371e-01 - val_acc: 0.9509 - val_mDice: 0.2082

Epoch 00036: val_mDice did not improve from 0.21646
Epoch 37/300
 - 30s - loss: 0.2406 - acc: 0.9495 - mDice: 0.6413 - val_loss: -2.1528e-01 - val_acc: 0.9500 - val_mDice: 0.2038

Epoch 00037: val_mDice did not improve from 0.21646

Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 38/300
 - 30s - loss: 0.2303 - acc: 0.9506 - mDice: 0.6503 - val_loss: -2.0869e-01 - val_acc: 0.9506 - val_mDice: 0.2032

Epoch 00038: val_mDice did not improve from 0.21646
Epoch 39/300
 - 30s - loss: 0.2320 - acc: 0.9507 - mDice: 0.6512 - val_loss: -2.1301e-01 - val_acc: 0.9515 - val_mDice: 0.2082

Epoch 00039: val_mDice did not improve from 0.21646
Epoch 40/300
 - 30s - loss: 0.2332 - acc: 0.9504 - mDice: 0.6459 - val_loss: -2.3152e-01 - val_acc: 0.9503 - val_mDice: 0.1994

Epoch 00040: val_mDice did not improve from 0.21646
Epoch 41/300
 - 30s - loss: 0.2290 - acc: 0.9506 - mDice: 0.6473 - val_loss: -2.2727e-01 - val_acc: 0.9516 - val_mDice: 0.2061

Epoch 00041: val_mDice did not improve from 0.21646
Epoch 42/300
 - 30s - loss: 0.2260 - acc: 0.9509 - mDice: 0.6535 - val_loss: -2.4387e-01 - val_acc: 0.9521 - val_mDice: 0.2087

Epoch 00042: val_mDice did not improve from 0.21646
Epoch 43/300
 - 31s - loss: 0.2218 - acc: 0.9509 - mDice: 0.6549 - val_loss: -2.1673e-01 - val_acc: 0.9513 - val_mDice: 0.2104

Epoch 00043: val_mDice did not improve from 0.21646
Epoch 44/300
 - 30s - loss: 0.2241 - acc: 0.9507 - mDice: 0.6552 - val_loss: -2.3123e-01 - val_acc: 0.9518 - val_mDice: 0.2051

Epoch 00044: val_mDice did not improve from 0.21646
Epoch 45/300
 - 31s - loss: 0.2250 - acc: 0.9509 - mDice: 0.6529 - val_loss: -2.2599e-01 - val_acc: 0.9509 - val_mDice: 0.2078

Epoch 00045: val_mDice did not improve from 0.21646
Epoch 46/300
 - 30s - loss: 0.2256 - acc: 0.9510 - mDice: 0.6564 - val_loss: -2.0937e-01 - val_acc: 0.9509 - val_mDice: 0.2068

Epoch 00046: val_mDice did not improve from 0.21646
Epoch 47/300
 - 30s - loss: 0.2171 - acc: 0.9512 - mDice: 0.6577 - val_loss: -2.2942e-01 - val_acc: 0.9517 - val_mDice: 0.2087

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.61s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.48s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.38s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.25s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:03,  3.90it/s]Loading train:   1%|          | 2/247 [00:00<01:01,  4.01it/s]Loading train:   1%|          | 3/247 [00:00<00:59,  4.07it/s]Loading train:   2%|▏         | 4/247 [00:00<00:59,  4.08it/s]Loading train:   2%|▏         | 5/247 [00:01<00:57,  4.18it/s]Loading train:   2%|▏         | 6/247 [00:01<00:56,  4.25it/s]Loading train:   3%|▎         | 7/247 [00:01<00:56,  4.28it/s]Loading train:   3%|▎         | 8/247 [00:01<00:55,  4.30it/s]Loading train:   4%|▎         | 9/247 [00:02<00:55,  4.33it/s]Loading train:   4%|▍         | 10/247 [00:02<00:54,  4.35it/s]Loading train:   4%|▍         | 11/247 [00:02<00:53,  4.39it/s]Loading train:   5%|▍         | 12/247 [00:02<00:53,  4.38it/s]Loading train:   5%|▌         | 13/247 [00:03<00:52,  4.42it/s]Loading train:   6%|▌         | 14/247 [00:03<00:52,  4.45it/s]Loading train:   6%|▌         | 15/247 [00:03<00:52,  4.45it/s]Loading train:   6%|▋         | 16/247 [00:03<00:51,  4.47it/s]Loading train:   7%|▋         | 17/247 [00:03<00:51,  4.47it/s]Loading train:   7%|▋         | 18/247 [00:04<00:51,  4.48it/s]Loading train:   8%|▊         | 19/247 [00:04<00:51,  4.46it/s]Loading train:   8%|▊         | 20/247 [00:04<00:50,  4.47it/s]Loading train:   9%|▊         | 21/247 [00:04<00:50,  4.46it/s]Loading train:   9%|▉         | 22/247 [00:05<00:50,  4.45it/s]Loading train:   9%|▉         | 23/247 [00:05<00:50,  4.47it/s]Loading train:  10%|▉         | 24/247 [00:05<00:49,  4.48it/s]Loading train:  10%|█         | 25/247 [00:05<00:49,  4.47it/s]Loading train:  11%|█         | 26/247 [00:05<00:49,  4.48it/s]Loading train:  11%|█         | 27/247 [00:06<00:48,  4.49it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:48,  4.51it/s]Loading train:  12%|█▏        | 29/247 [00:06<00:48,  4.52it/s]Loading train:  12%|█▏        | 30/247 [00:06<00:47,  4.54it/s]Loading train:  13%|█▎        | 31/247 [00:07<00:47,  4.53it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:47,  4.53it/s]Loading train:  13%|█▎        | 33/247 [00:07<00:47,  4.53it/s]Loading train:  14%|█▍        | 34/247 [00:07<00:47,  4.53it/s]Loading train:  14%|█▍        | 35/247 [00:07<00:46,  4.54it/s]Loading train:  15%|█▍        | 36/247 [00:08<00:46,  4.55it/s]Loading train:  15%|█▍        | 37/247 [00:08<00:45,  4.57it/s]Loading train:  15%|█▌        | 38/247 [00:08<00:45,  4.56it/s]Loading train:  16%|█▌        | 39/247 [00:08<00:45,  4.55it/s]Loading train:  16%|█▌        | 40/247 [00:08<00:45,  4.56it/s]Loading train:  17%|█▋        | 41/247 [00:09<00:45,  4.52it/s]Loading train:  17%|█▋        | 42/247 [00:09<00:45,  4.54it/s]Loading train:  17%|█▋        | 43/247 [00:09<00:44,  4.54it/s]Loading train:  18%|█▊        | 44/247 [00:09<00:44,  4.55it/s]Loading train:  18%|█▊        | 45/247 [00:10<00:44,  4.53it/s]Loading train:  19%|█▊        | 46/247 [00:10<00:44,  4.52it/s]Loading train:  19%|█▉        | 47/247 [00:10<00:44,  4.51it/s]Loading train:  19%|█▉        | 48/247 [00:10<00:44,  4.49it/s]Loading train:  20%|█▉        | 49/247 [00:10<00:44,  4.48it/s]Loading train:  20%|██        | 50/247 [00:11<00:43,  4.49it/s]Loading train:  21%|██        | 51/247 [00:11<00:43,  4.50it/s]Loading train:  21%|██        | 52/247 [00:11<00:43,  4.51it/s]Loading train:  21%|██▏       | 53/247 [00:11<00:42,  4.52it/s]Loading train:  22%|██▏       | 54/247 [00:12<00:42,  4.53it/s]Loading train:  22%|██▏       | 55/247 [00:12<00:42,  4.54it/s]Loading train:  23%|██▎       | 56/247 [00:12<00:41,  4.55it/s]Loading train:  23%|██▎       | 57/247 [00:12<00:41,  4.56it/s]Loading train:  23%|██▎       | 58/247 [00:12<00:41,  4.56it/s]Loading train:  24%|██▍       | 59/247 [00:13<00:41,  4.53it/s]Loading train:  24%|██▍       | 60/247 [00:13<00:41,  4.51it/s]Loading train:  25%|██▍       | 61/247 [00:13<00:41,  4.49it/s]Loading train:  25%|██▌       | 62/247 [00:13<00:41,  4.49it/s]Loading train:  26%|██▌       | 63/247 [00:14<00:41,  4.44it/s]Loading train:  26%|██▌       | 64/247 [00:14<00:41,  4.44it/s]Loading train:  26%|██▋       | 65/247 [00:14<00:40,  4.44it/s]Loading train:  27%|██▋       | 66/247 [00:14<00:40,  4.45it/s]Loading train:  27%|██▋       | 67/247 [00:14<00:40,  4.45it/s]Loading train:  28%|██▊       | 68/247 [00:15<00:40,  4.44it/s]Loading train:  28%|██▊       | 69/247 [00:15<00:40,  4.45it/s]Loading train:  28%|██▊       | 70/247 [00:15<00:40,  4.42it/s]Loading train:  29%|██▊       | 71/247 [00:15<00:39,  4.43it/s]Loading train:  29%|██▉       | 72/247 [00:16<00:39,  4.43it/s]Loading train:  30%|██▉       | 73/247 [00:16<00:39,  4.45it/s]Loading train:  30%|██▉       | 74/247 [00:16<00:38,  4.45it/s]Loading train:  30%|███       | 75/247 [00:16<00:38,  4.43it/s]Loading train:  31%|███       | 76/247 [00:17<00:38,  4.43it/s]Loading train:  31%|███       | 77/247 [00:17<00:41,  4.07it/s]Loading train:  32%|███▏      | 78/247 [00:17<00:42,  3.99it/s]Loading train:  32%|███▏      | 79/247 [00:17<00:40,  4.14it/s]Loading train:  32%|███▏      | 80/247 [00:18<00:39,  4.18it/s]Loading train:  33%|███▎      | 81/247 [00:18<00:40,  4.09it/s]Loading train:  33%|███▎      | 82/247 [00:18<00:41,  4.02it/s]Loading train:  34%|███▎      | 83/247 [00:18<00:41,  3.98it/s]Loading train:  34%|███▍      | 84/247 [00:19<00:41,  3.96it/s]Loading train:  34%|███▍      | 85/247 [00:19<00:41,  3.93it/s]Loading train:  35%|███▍      | 86/247 [00:19<00:41,  3.92it/s]Loading train:  35%|███▌      | 87/247 [00:19<00:40,  3.92it/s]Loading train:  36%|███▌      | 88/247 [00:20<00:40,  3.90it/s]Loading train:  36%|███▌      | 89/247 [00:20<00:40,  3.89it/s]Loading train:  36%|███▋      | 90/247 [00:20<00:40,  3.89it/s]Loading train:  37%|███▋      | 91/247 [00:20<00:40,  3.90it/s]Loading train:  37%|███▋      | 92/247 [00:21<00:39,  3.90it/s]Loading train:  38%|███▊      | 93/247 [00:21<00:39,  3.91it/s]Loading train:  38%|███▊      | 94/247 [00:21<00:39,  3.89it/s]Loading train:  38%|███▊      | 95/247 [00:21<00:38,  3.90it/s]Loading train:  39%|███▉      | 96/247 [00:22<00:38,  3.89it/s]Loading train:  39%|███▉      | 97/247 [00:22<00:38,  3.89it/s]Loading train:  40%|███▉      | 98/247 [00:22<00:38,  3.89it/s]Loading train:  40%|████      | 99/247 [00:22<00:37,  3.90it/s]Loading train:  40%|████      | 100/247 [00:23<00:37,  3.93it/s]Loading train:  41%|████      | 101/247 [00:23<00:36,  3.99it/s]Loading train:  41%|████▏     | 102/247 [00:23<00:36,  4.01it/s]Loading train:  42%|████▏     | 103/247 [00:23<00:35,  4.04it/s]Loading train:  42%|████▏     | 104/247 [00:24<00:35,  4.00it/s]Loading train:  43%|████▎     | 105/247 [00:24<00:35,  4.01it/s]Loading train:  43%|████▎     | 106/247 [00:24<00:35,  4.00it/s]Loading train:  43%|████▎     | 107/247 [00:24<00:34,  4.00it/s]Loading train:  44%|████▎     | 108/247 [00:25<00:34,  4.00it/s]Loading train:  44%|████▍     | 109/247 [00:25<00:34,  3.97it/s]Loading train:  45%|████▍     | 110/247 [00:25<00:34,  4.00it/s]Loading train:  45%|████▍     | 111/247 [00:25<00:34,  3.98it/s]Loading train:  45%|████▌     | 112/247 [00:26<00:33,  4.01it/s]Loading train:  46%|████▌     | 113/247 [00:26<00:33,  3.99it/s]Loading train:  46%|████▌     | 114/247 [00:26<00:33,  4.00it/s]Loading train:  47%|████▋     | 115/247 [00:26<00:33,  3.99it/s]Loading train:  47%|████▋     | 116/247 [00:27<00:32,  4.00it/s]Loading train:  47%|████▋     | 117/247 [00:27<00:32,  4.02it/s]Loading train:  48%|████▊     | 118/247 [00:27<00:30,  4.23it/s]Loading train:  48%|████▊     | 119/247 [00:27<00:29,  4.36it/s]Loading train:  49%|████▊     | 120/247 [00:28<00:28,  4.51it/s]Loading train:  49%|████▉     | 121/247 [00:28<00:27,  4.59it/s]Loading train:  49%|████▉     | 122/247 [00:28<00:26,  4.64it/s]Loading train:  50%|████▉     | 123/247 [00:28<00:26,  4.69it/s]Loading train:  50%|█████     | 124/247 [00:28<00:26,  4.70it/s]Loading train:  51%|█████     | 125/247 [00:29<00:26,  4.63it/s]Loading train:  51%|█████     | 126/247 [00:29<00:25,  4.67it/s]Loading train:  51%|█████▏    | 127/247 [00:29<00:25,  4.72it/s]Loading train:  52%|█████▏    | 128/247 [00:29<00:25,  4.74it/s]Loading train:  52%|█████▏    | 129/247 [00:29<00:24,  4.76it/s]Loading train:  53%|█████▎    | 130/247 [00:30<00:24,  4.79it/s]Loading train:  53%|█████▎    | 131/247 [00:30<00:24,  4.78it/s]Loading train:  53%|█████▎    | 132/247 [00:30<00:23,  4.82it/s]Loading train:  54%|█████▍    | 133/247 [00:30<00:23,  4.83it/s]Loading train:  54%|█████▍    | 134/247 [00:30<00:23,  4.83it/s]Loading train:  55%|█████▍    | 135/247 [00:31<00:23,  4.81it/s]Loading train:  55%|█████▌    | 136/247 [00:31<00:23,  4.71it/s]Loading train:  55%|█████▌    | 137/247 [00:31<00:23,  4.69it/s]Loading train:  56%|█████▌    | 138/247 [00:31<00:23,  4.58it/s]Loading train:  56%|█████▋    | 139/247 [00:32<00:23,  4.60it/s]Loading train:  57%|█████▋    | 140/247 [00:32<00:23,  4.58it/s]Loading train:  57%|█████▋    | 141/247 [00:32<00:23,  4.57it/s]Loading train:  57%|█████▋    | 142/247 [00:32<00:22,  4.58it/s]Loading train:  58%|█████▊    | 143/247 [00:32<00:23,  4.50it/s]Loading train:  58%|█████▊    | 144/247 [00:33<00:22,  4.48it/s]Loading train:  59%|█████▊    | 145/247 [00:33<00:23,  4.39it/s]Loading train:  59%|█████▉    | 146/247 [00:33<00:23,  4.37it/s]Loading train:  60%|█████▉    | 147/247 [00:33<00:22,  4.37it/s]Loading train:  60%|█████▉    | 148/247 [00:34<00:22,  4.35it/s]Loading train:  60%|██████    | 149/247 [00:34<00:22,  4.37it/s]Loading train:  61%|██████    | 150/247 [00:34<00:22,  4.35it/s]Loading train:  61%|██████    | 151/247 [00:34<00:22,  4.36it/s]Loading train:  62%|██████▏   | 152/247 [00:35<00:21,  4.34it/s]Loading train:  62%|██████▏   | 153/247 [00:35<00:21,  4.34it/s]Loading train:  62%|██████▏   | 154/247 [00:35<00:22,  4.20it/s]Loading train:  63%|██████▎   | 155/247 [00:35<00:22,  4.12it/s]Loading train:  63%|██████▎   | 156/247 [00:36<00:22,  4.07it/s]Loading train:  64%|██████▎   | 157/247 [00:36<00:22,  4.02it/s]Loading train:  64%|██████▍   | 158/247 [00:36<00:22,  3.98it/s]Loading train:  64%|██████▍   | 159/247 [00:36<00:22,  3.94it/s]Loading train:  65%|██████▍   | 160/247 [00:37<00:22,  3.94it/s]Loading train:  65%|██████▌   | 161/247 [00:37<00:21,  3.92it/s]Loading train:  66%|██████▌   | 162/247 [00:37<00:21,  3.96it/s]Loading train:  66%|██████▌   | 163/247 [00:37<00:21,  3.95it/s]Loading train:  66%|██████▋   | 164/247 [00:38<00:21,  3.92it/s]Loading train:  67%|██████▋   | 165/247 [00:38<00:21,  3.90it/s]Loading train:  67%|██████▋   | 166/247 [00:38<00:20,  3.89it/s]Loading train:  68%|██████▊   | 167/247 [00:38<00:20,  3.89it/s]Loading train:  68%|██████▊   | 168/247 [00:39<00:20,  3.90it/s]Loading train:  68%|██████▊   | 169/247 [00:39<00:20,  3.85it/s]Loading train:  69%|██████▉   | 170/247 [00:39<00:19,  3.88it/s]Loading train:  69%|██████▉   | 171/247 [00:39<00:19,  3.89it/s]Loading train:  70%|██████▉   | 172/247 [00:40<00:19,  3.89it/s]Loading train:  70%|███████   | 173/247 [00:40<00:18,  4.03it/s]Loading train:  70%|███████   | 174/247 [00:40<00:18,  4.04it/s]Loading train:  71%|███████   | 175/247 [00:40<00:18,  3.94it/s]Loading train:  71%|███████▏  | 176/247 [00:41<00:17,  4.05it/s]Loading train:  72%|███████▏  | 177/247 [00:41<00:16,  4.16it/s]Loading train:  72%|███████▏  | 178/247 [00:41<00:16,  4.23it/s]Loading train:  72%|███████▏  | 179/247 [00:41<00:15,  4.26it/s]Loading train:  73%|███████▎  | 180/247 [00:42<00:15,  4.30it/s]Loading train:  73%|███████▎  | 181/247 [00:42<00:15,  4.33it/s]Loading train:  74%|███████▎  | 182/247 [00:42<00:14,  4.34it/s]Loading train:  74%|███████▍  | 183/247 [00:42<00:14,  4.38it/s]Loading train:  74%|███████▍  | 184/247 [00:42<00:14,  4.42it/s]Loading train:  75%|███████▍  | 185/247 [00:43<00:13,  4.46it/s]Loading train:  75%|███████▌  | 186/247 [00:43<00:13,  4.48it/s]Loading train:  76%|███████▌  | 187/247 [00:43<00:13,  4.49it/s]Loading train:  76%|███████▌  | 188/247 [00:43<00:13,  4.49it/s]Loading train:  77%|███████▋  | 189/247 [00:44<00:12,  4.47it/s]Loading train:  77%|███████▋  | 190/247 [00:44<00:12,  4.48it/s]Loading train:  77%|███████▋  | 191/247 [00:44<00:12,  4.50it/s]Loading train:  78%|███████▊  | 192/247 [00:44<00:12,  4.53it/s]Loading train:  78%|███████▊  | 193/247 [00:44<00:11,  4.51it/s]Loading train:  79%|███████▊  | 194/247 [00:45<00:11,  4.56it/s]Loading train:  79%|███████▉  | 195/247 [00:45<00:11,  4.62it/s]Loading train:  79%|███████▉  | 196/247 [00:45<00:10,  4.67it/s]Loading train:  80%|███████▉  | 197/247 [00:45<00:10,  4.68it/s]Loading train:  80%|████████  | 198/247 [00:45<00:10,  4.70it/s]Loading train:  81%|████████  | 199/247 [00:46<00:10,  4.69it/s]Loading train:  81%|████████  | 200/247 [00:46<00:10,  4.68it/s]Loading train:  81%|████████▏ | 201/247 [00:46<00:09,  4.70it/s]Loading train:  82%|████████▏ | 202/247 [00:46<00:09,  4.73it/s]Loading train:  82%|████████▏ | 203/247 [00:47<00:09,  4.72it/s]Loading train:  83%|████████▎ | 204/247 [00:47<00:09,  4.73it/s]Loading train:  83%|████████▎ | 205/247 [00:47<00:08,  4.73it/s]Loading train:  83%|████████▎ | 206/247 [00:47<00:08,  4.70it/s]Loading train:  84%|████████▍ | 207/247 [00:47<00:08,  4.70it/s]Loading train:  84%|████████▍ | 208/247 [00:48<00:08,  4.70it/s]Loading train:  85%|████████▍ | 209/247 [00:48<00:08,  4.68it/s]Loading train:  85%|████████▌ | 210/247 [00:48<00:07,  4.70it/s]Loading train:  85%|████████▌ | 211/247 [00:48<00:07,  4.70it/s]Loading train:  86%|████████▌ | 212/247 [00:48<00:07,  4.58it/s]Loading train:  86%|████████▌ | 213/247 [00:49<00:07,  4.55it/s]Loading train:  87%|████████▋ | 214/247 [00:49<00:07,  4.54it/s]Loading train:  87%|████████▋ | 215/247 [00:49<00:07,  4.52it/s]Loading train:  87%|████████▋ | 216/247 [00:49<00:06,  4.51it/s]Loading train:  88%|████████▊ | 217/247 [00:50<00:06,  4.48it/s]Loading train:  88%|████████▊ | 218/247 [00:50<00:06,  4.46it/s]Loading train:  89%|████████▊ | 219/247 [00:50<00:06,  4.47it/s]Loading train:  89%|████████▉ | 220/247 [00:50<00:06,  4.48it/s]Loading train:  89%|████████▉ | 221/247 [00:50<00:05,  4.46it/s]Loading train:  90%|████████▉ | 222/247 [00:51<00:05,  4.48it/s]Loading train:  90%|█████████ | 223/247 [00:51<00:05,  4.44it/s]Loading train:  91%|█████████ | 224/247 [00:51<00:05,  4.45it/s]Loading train:  91%|█████████ | 225/247 [00:51<00:04,  4.47it/s]Loading train:  91%|█████████▏| 226/247 [00:52<00:04,  4.48it/s]Loading train:  92%|█████████▏| 227/247 [00:52<00:04,  4.46it/s]Loading train:  92%|█████████▏| 228/247 [00:52<00:04,  4.41it/s]Loading train:  93%|█████████▎| 229/247 [00:52<00:04,  4.34it/s]Loading train:  93%|█████████▎| 230/247 [00:53<00:04,  4.17it/s]Loading train:  94%|█████████▎| 231/247 [00:53<00:03,  4.12it/s]Loading train:  94%|█████████▍| 232/247 [00:53<00:03,  4.05it/s]Loading train:  94%|█████████▍| 233/247 [00:53<00:03,  4.06it/s]Loading train:  95%|█████████▍| 234/247 [00:54<00:03,  4.02it/s]Loading train:  95%|█████████▌| 235/247 [00:54<00:02,  4.01it/s]Loading train:  96%|█████████▌| 236/247 [00:54<00:02,  3.97it/s]Loading train:  96%|█████████▌| 237/247 [00:54<00:02,  3.96it/s]Loading train:  96%|█████████▋| 238/247 [00:55<00:02,  3.95it/s]Loading train:  97%|█████████▋| 239/247 [00:55<00:02,  3.96it/s]Loading train:  97%|█████████▋| 240/247 [00:55<00:01,  3.96it/s]Loading train:  98%|█████████▊| 241/247 [00:55<00:01,  3.97it/s]Loading train:  98%|█████████▊| 242/247 [00:56<00:01,  4.00it/s]Loading train:  98%|█████████▊| 243/247 [00:56<00:01,  3.99it/s]Loading train:  99%|█████████▉| 244/247 [00:56<00:00,  3.99it/s]Loading train:  99%|█████████▉| 245/247 [00:56<00:00,  4.02it/s]Loading train: 100%|█████████▉| 246/247 [00:57<00:00,  4.00it/s]Loading train: 100%|██████████| 247/247 [00:57<00:00,  4.01it/s]Loading train: 100%|██████████| 247/247 [00:57<00:00,  4.31it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 47.20it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:04, 47.60it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:04, 48.21it/s]concatenating: train:   9%|▊         | 21/247 [00:00<00:04, 49.03it/s]concatenating: train:  11%|█         | 27/247 [00:00<00:04, 49.34it/s]concatenating: train:  13%|█▎        | 32/247 [00:00<00:04, 49.53it/s]concatenating: train:  15%|█▍        | 37/247 [00:00<00:04, 49.23it/s]concatenating: train:  17%|█▋        | 42/247 [00:00<00:04, 48.79it/s]concatenating: train:  19%|█▉        | 47/247 [00:00<00:04, 48.77it/s]concatenating: train:  21%|██        | 52/247 [00:01<00:03, 48.79it/s]concatenating: train:  23%|██▎       | 57/247 [00:01<00:03, 48.75it/s]concatenating: train:  25%|██▌       | 62/247 [00:01<00:03, 48.39it/s]concatenating: train:  27%|██▋       | 67/247 [00:01<00:03, 48.16it/s]concatenating: train:  29%|██▉       | 72/247 [00:01<00:03, 47.70it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:03, 47.69it/s]concatenating: train:  33%|███▎      | 82/247 [00:01<00:03, 47.49it/s]concatenating: train:  35%|███▌      | 87/247 [00:01<00:03, 46.00it/s]concatenating: train:  37%|███▋      | 92/247 [00:01<00:03, 44.92it/s]concatenating: train:  39%|███▉      | 97/247 [00:02<00:03, 44.36it/s]concatenating: train:  41%|████▏     | 102/247 [00:02<00:03, 44.35it/s]concatenating: train:  43%|████▎     | 107/247 [00:02<00:03, 44.39it/s]concatenating: train:  45%|████▌     | 112/247 [00:02<00:03, 44.55it/s]concatenating: train:  47%|████▋     | 117/247 [00:02<00:02, 44.76it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 46.49it/s]concatenating: train:  52%|█████▏    | 128/247 [00:02<00:02, 45.44it/s]concatenating: train:  54%|█████▍    | 134/247 [00:02<00:02, 47.48it/s]concatenating: train:  56%|█████▋    | 139/247 [00:02<00:02, 47.39it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:02, 48.30it/s]concatenating: train:  61%|██████    | 150/247 [00:03<00:01, 48.66it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 48.50it/s]concatenating: train:  65%|██████▍   | 160/247 [00:03<00:01, 47.66it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 46.86it/s]concatenating: train:  69%|██████▉   | 170/247 [00:03<00:01, 46.46it/s]concatenating: train:  71%|███████   | 175/247 [00:03<00:01, 46.88it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 47.45it/s]concatenating: train:  75%|███████▍  | 185/247 [00:03<00:01, 48.15it/s]concatenating: train:  77%|███████▋  | 191/247 [00:04<00:01, 48.78it/s]concatenating: train:  80%|███████▉  | 197/247 [00:04<00:01, 49.34it/s]concatenating: train:  82%|████████▏ | 202/247 [00:04<00:00, 49.33it/s]concatenating: train:  84%|████████▍ | 207/247 [00:04<00:00, 49.48it/s]concatenating: train:  86%|████████▌ | 212/247 [00:04<00:00, 49.24it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 46.62it/s]concatenating: train:  90%|████████▉ | 222/247 [00:04<00:00, 44.84it/s]concatenating: train:  92%|█████████▏| 227/247 [00:04<00:00, 43.77it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 42.73it/s]concatenating: train:  96%|█████████▌| 237/247 [00:05<00:00, 41.12it/s]concatenating: train:  98%|█████████▊| 242/247 [00:05<00:00, 40.27it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 39.99it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 46.44it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  4.00it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.87it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.91it/s]Loading test:  80%|████████  | 4/5 [00:00<00:00,  4.15it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.14it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.08it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 388.54it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<01:01,  3.98it/s]Loading trainS:   1%|          | 2/247 [00:00<01:01,  3.98it/s]Loading trainS:   1%|          | 3/247 [00:00<01:01,  3.99it/s]Loading trainS:   2%|▏         | 4/247 [00:01<01:01,  3.98it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:59,  4.08it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:58,  4.15it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:56,  4.22it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:56,  4.26it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:55,  4.31it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:54,  4.35it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:54,  4.37it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:53,  4.36it/s]Loading trainS:   5%|▌         | 13/247 [00:03<00:54,  4.33it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:53,  4.36it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:54,  4.29it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:53,  4.33it/s]Loading trainS:   7%|▋         | 17/247 [00:03<00:52,  4.37it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:52,  4.40it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:51,  4.42it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:51,  4.44it/s]Loading trainS:   9%|▊         | 21/247 [00:04<00:51,  4.42it/s]Loading trainS:   9%|▉         | 22/247 [00:05<00:50,  4.42it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:50,  4.44it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:49,  4.47it/s]Loading trainS:  10%|█         | 25/247 [00:05<00:49,  4.48it/s]Loading trainS:  11%|█         | 26/247 [00:05<00:49,  4.49it/s]Loading trainS:  11%|█         | 27/247 [00:06<00:48,  4.51it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:49,  4.46it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:48,  4.47it/s]Loading trainS:  12%|█▏        | 30/247 [00:06<00:48,  4.49it/s]Loading trainS:  13%|█▎        | 31/247 [00:07<00:47,  4.52it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:47,  4.53it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:47,  4.53it/s]Loading trainS:  14%|█▍        | 34/247 [00:07<00:46,  4.54it/s]Loading trainS:  14%|█▍        | 35/247 [00:07<00:46,  4.54it/s]Loading trainS:  15%|█▍        | 36/247 [00:08<00:46,  4.54it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:46,  4.55it/s]Loading trainS:  15%|█▌        | 38/247 [00:08<00:45,  4.56it/s]Loading trainS:  16%|█▌        | 39/247 [00:08<00:45,  4.57it/s]Loading trainS:  16%|█▌        | 40/247 [00:09<00:45,  4.56it/s]Loading trainS:  17%|█▋        | 41/247 [00:09<00:45,  4.54it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:45,  4.55it/s]Loading trainS:  17%|█▋        | 43/247 [00:09<00:44,  4.55it/s]Loading trainS:  18%|█▊        | 44/247 [00:09<00:44,  4.54it/s]Loading trainS:  18%|█▊        | 45/247 [00:10<00:44,  4.55it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:44,  4.55it/s]Loading trainS:  19%|█▉        | 47/247 [00:10<00:44,  4.49it/s]Loading trainS:  19%|█▉        | 48/247 [00:10<00:44,  4.46it/s]Loading trainS:  20%|█▉        | 49/247 [00:11<00:44,  4.41it/s]Loading trainS:  20%|██        | 50/247 [00:11<00:45,  4.36it/s]Loading trainS:  21%|██        | 51/247 [00:11<00:45,  4.32it/s]Loading trainS:  21%|██        | 52/247 [00:11<00:45,  4.31it/s]Loading trainS:  21%|██▏       | 53/247 [00:12<00:45,  4.31it/s]Loading trainS:  22%|██▏       | 54/247 [00:12<00:44,  4.30it/s]Loading trainS:  22%|██▏       | 55/247 [00:12<00:44,  4.30it/s]Loading trainS:  23%|██▎       | 56/247 [00:12<00:44,  4.32it/s]Loading trainS:  23%|██▎       | 57/247 [00:12<00:43,  4.32it/s]Loading trainS:  23%|██▎       | 58/247 [00:13<00:43,  4.33it/s]Loading trainS:  24%|██▍       | 59/247 [00:13<00:43,  4.31it/s]Loading trainS:  24%|██▍       | 60/247 [00:13<00:43,  4.30it/s]Loading trainS:  25%|██▍       | 61/247 [00:13<00:43,  4.26it/s]Loading trainS:  25%|██▌       | 62/247 [00:14<00:43,  4.27it/s]Loading trainS:  26%|██▌       | 63/247 [00:14<00:43,  4.27it/s]Loading trainS:  26%|██▌       | 64/247 [00:14<00:42,  4.26it/s]Loading trainS:  26%|██▋       | 65/247 [00:14<00:42,  4.27it/s]Loading trainS:  27%|██▋       | 66/247 [00:15<00:42,  4.26it/s]Loading trainS:  27%|██▋       | 67/247 [00:15<00:42,  4.26it/s]Loading trainS:  28%|██▊       | 68/247 [00:15<00:42,  4.25it/s]Loading trainS:  28%|██▊       | 69/247 [00:15<00:41,  4.25it/s]Loading trainS:  28%|██▊       | 70/247 [00:16<00:42,  4.21it/s]Loading trainS:  29%|██▊       | 71/247 [00:16<00:41,  4.23it/s]Loading trainS:  29%|██▉       | 72/247 [00:16<00:41,  4.20it/s]Loading trainS:  30%|██▉       | 73/247 [00:16<00:40,  4.28it/s]Loading trainS:  30%|██▉       | 74/247 [00:16<00:40,  4.31it/s]Loading trainS:  30%|███       | 75/247 [00:17<00:39,  4.35it/s]Loading trainS:  31%|███       | 76/247 [00:17<00:39,  4.38it/s]Loading trainS:  31%|███       | 77/247 [00:17<00:41,  4.08it/s]Loading trainS:  32%|███▏      | 78/247 [00:17<00:42,  3.98it/s]Loading trainS:  32%|███▏      | 79/247 [00:18<00:40,  4.15it/s]Loading trainS:  32%|███▏      | 80/247 [00:18<00:39,  4.22it/s]Loading trainS:  33%|███▎      | 81/247 [00:18<00:40,  4.10it/s]Loading trainS:  33%|███▎      | 82/247 [00:18<00:40,  4.03it/s]Loading trainS:  34%|███▎      | 83/247 [00:19<00:41,  3.99it/s]Loading trainS:  34%|███▍      | 84/247 [00:19<00:41,  3.93it/s]Loading trainS:  34%|███▍      | 85/247 [00:19<00:41,  3.92it/s]Loading trainS:  35%|███▍      | 86/247 [00:19<00:42,  3.82it/s]Loading trainS:  35%|███▌      | 87/247 [00:20<00:41,  3.83it/s]Loading trainS:  36%|███▌      | 88/247 [00:20<00:41,  3.83it/s]Loading trainS:  36%|███▌      | 89/247 [00:20<00:41,  3.84it/s]Loading trainS:  36%|███▋      | 90/247 [00:20<00:40,  3.84it/s]Loading trainS:  37%|███▋      | 91/247 [00:21<00:40,  3.84it/s]Loading trainS:  37%|███▋      | 92/247 [00:21<00:40,  3.85it/s]Loading trainS:  38%|███▊      | 93/247 [00:21<00:40,  3.83it/s]Loading trainS:  38%|███▊      | 94/247 [00:22<00:40,  3.81it/s]Loading trainS:  38%|███▊      | 95/247 [00:22<00:39,  3.83it/s]Loading trainS:  39%|███▉      | 96/247 [00:22<00:39,  3.82it/s]Loading trainS:  39%|███▉      | 97/247 [00:22<00:39,  3.83it/s]Loading trainS:  40%|███▉      | 98/247 [00:23<00:39,  3.81it/s]Loading trainS:  40%|████      | 99/247 [00:23<00:38,  3.82it/s]Loading trainS:  40%|████      | 100/247 [00:23<00:37,  3.87it/s]Loading trainS:  41%|████      | 101/247 [00:23<00:37,  3.92it/s]Loading trainS:  41%|████▏     | 102/247 [00:24<00:36,  3.95it/s]Loading trainS:  42%|████▏     | 103/247 [00:24<00:36,  3.98it/s]Loading trainS:  42%|████▏     | 104/247 [00:24<00:35,  3.99it/s]Loading trainS:  43%|████▎     | 105/247 [00:24<00:35,  4.02it/s]Loading trainS:  43%|████▎     | 106/247 [00:25<00:34,  4.03it/s]Loading trainS:  43%|████▎     | 107/247 [00:25<00:34,  4.02it/s]Loading trainS:  44%|████▎     | 108/247 [00:25<00:34,  4.04it/s]Loading trainS:  44%|████▍     | 109/247 [00:25<00:34,  4.02it/s]Loading trainS:  45%|████▍     | 110/247 [00:26<00:34,  4.01it/s]Loading trainS:  45%|████▍     | 111/247 [00:26<00:34,  3.99it/s]Loading trainS:  45%|████▌     | 112/247 [00:26<00:33,  4.02it/s]Loading trainS:  46%|████▌     | 113/247 [00:26<00:33,  4.04it/s]Loading trainS:  46%|████▌     | 114/247 [00:27<00:32,  4.03it/s]Loading trainS:  47%|████▋     | 115/247 [00:27<00:33,  4.00it/s]Loading trainS:  47%|████▋     | 116/247 [00:27<00:33,  3.96it/s]Loading trainS:  47%|████▋     | 117/247 [00:27<00:32,  3.98it/s]Loading trainS:  48%|████▊     | 118/247 [00:28<00:30,  4.20it/s]Loading trainS:  48%|████▊     | 119/247 [00:28<00:29,  4.36it/s]Loading trainS:  49%|████▊     | 120/247 [00:28<00:28,  4.45it/s]Loading trainS:  49%|████▉     | 121/247 [00:28<00:28,  4.45it/s]Loading trainS:  49%|████▉     | 122/247 [00:28<00:27,  4.47it/s]Loading trainS:  50%|████▉     | 123/247 [00:29<00:27,  4.47it/s]Loading trainS:  50%|█████     | 124/247 [00:29<00:27,  4.50it/s]Loading trainS:  51%|█████     | 125/247 [00:29<00:26,  4.52it/s]Loading trainS:  51%|█████     | 126/247 [00:29<00:26,  4.54it/s]Loading trainS:  51%|█████▏    | 127/247 [00:30<00:26,  4.53it/s]Loading trainS:  52%|█████▏    | 128/247 [00:30<00:26,  4.50it/s]Loading trainS:  52%|█████▏    | 129/247 [00:30<00:26,  4.52it/s]Loading trainS:  53%|█████▎    | 130/247 [00:30<00:25,  4.54it/s]Loading trainS:  53%|█████▎    | 131/247 [00:30<00:25,  4.50it/s]Loading trainS:  53%|█████▎    | 132/247 [00:31<00:25,  4.51it/s]Loading trainS:  54%|█████▍    | 133/247 [00:31<00:25,  4.54it/s]Loading trainS:  54%|█████▍    | 134/247 [00:31<00:24,  4.56it/s]Loading trainS:  55%|█████▍    | 135/247 [00:31<00:24,  4.57it/s]Loading trainS:  55%|█████▌    | 136/247 [00:32<00:24,  4.50it/s]Loading trainS:  55%|█████▌    | 137/247 [00:32<00:24,  4.48it/s]Loading trainS:  56%|█████▌    | 138/247 [00:32<00:24,  4.45it/s]Loading trainS:  56%|█████▋    | 139/247 [00:32<00:24,  4.44it/s]Loading trainS:  57%|█████▋    | 140/247 [00:32<00:24,  4.34it/s]Loading trainS:  57%|█████▋    | 141/247 [00:33<00:24,  4.36it/s]Loading trainS:  57%|█████▋    | 142/247 [00:33<00:24,  4.37it/s]Loading trainS:  58%|█████▊    | 143/247 [00:33<00:23,  4.38it/s]Loading trainS:  58%|█████▊    | 144/247 [00:33<00:23,  4.40it/s]Loading trainS:  59%|█████▊    | 145/247 [00:34<00:23,  4.39it/s]Loading trainS:  59%|█████▉    | 146/247 [00:34<00:22,  4.39it/s]Loading trainS:  60%|█████▉    | 147/247 [00:34<00:22,  4.38it/s]Loading trainS:  60%|█████▉    | 148/247 [00:34<00:22,  4.33it/s]Loading trainS:  60%|██████    | 149/247 [00:34<00:22,  4.33it/s]Loading trainS:  61%|██████    | 150/247 [00:35<00:22,  4.31it/s]Loading trainS:  61%|██████    | 151/247 [00:35<00:22,  4.34it/s]Loading trainS:  62%|██████▏   | 152/247 [00:35<00:22,  4.31it/s]Loading trainS:  62%|██████▏   | 153/247 [00:35<00:21,  4.32it/s]Loading trainS:  62%|██████▏   | 154/247 [00:36<00:22,  4.16it/s]Loading trainS:  63%|██████▎   | 155/247 [00:36<00:22,  4.08it/s]Loading trainS:  63%|██████▎   | 156/247 [00:36<00:22,  4.00it/s]Loading trainS:  64%|██████▎   | 157/247 [00:36<00:22,  3.96it/s]Loading trainS:  64%|██████▍   | 158/247 [00:37<00:22,  3.94it/s]Loading trainS:  64%|██████▍   | 159/247 [00:37<00:22,  3.93it/s]Loading trainS:  65%|██████▍   | 160/247 [00:37<00:22,  3.93it/s]Loading trainS:  65%|██████▌   | 161/247 [00:37<00:22,  3.89it/s]Loading trainS:  66%|██████▌   | 162/247 [00:38<00:21,  3.87it/s]Loading trainS:  66%|██████▌   | 163/247 [00:38<00:21,  3.85it/s]Loading trainS:  66%|██████▋   | 164/247 [00:38<00:21,  3.82it/s]Loading trainS:  67%|██████▋   | 165/247 [00:39<00:21,  3.84it/s]Loading trainS:  67%|██████▋   | 166/247 [00:39<00:20,  3.87it/s]Loading trainS:  68%|██████▊   | 167/247 [00:39<00:20,  3.90it/s]Loading trainS:  68%|██████▊   | 168/247 [00:39<00:20,  3.91it/s]Loading trainS:  68%|██████▊   | 169/247 [00:40<00:20,  3.88it/s]Loading trainS:  69%|██████▉   | 170/247 [00:40<00:19,  3.85it/s]Loading trainS:  69%|██████▉   | 171/247 [00:40<00:19,  3.89it/s]Loading trainS:  70%|██████▉   | 172/247 [00:40<00:19,  3.92it/s]Loading trainS:  70%|███████   | 173/247 [00:41<00:18,  4.02it/s]Loading trainS:  70%|███████   | 174/247 [00:41<00:17,  4.06it/s]Loading trainS:  71%|███████   | 175/247 [00:41<00:18,  4.00it/s]Loading trainS:  71%|███████▏  | 176/247 [00:41<00:17,  4.14it/s]Loading trainS:  72%|███████▏  | 177/247 [00:42<00:16,  4.22it/s]Loading trainS:  72%|███████▏  | 178/247 [00:42<00:16,  4.24it/s]Loading trainS:  72%|███████▏  | 179/247 [00:42<00:15,  4.28it/s]Loading trainS:  73%|███████▎  | 180/247 [00:42<00:15,  4.34it/s]Loading trainS:  73%|███████▎  | 181/247 [00:42<00:15,  4.37it/s]Loading trainS:  74%|███████▎  | 182/247 [00:43<00:14,  4.40it/s]Loading trainS:  74%|███████▍  | 183/247 [00:43<00:14,  4.45it/s]Loading trainS:  74%|███████▍  | 184/247 [00:43<00:14,  4.48it/s]Loading trainS:  75%|███████▍  | 185/247 [00:43<00:13,  4.50it/s]Loading trainS:  75%|███████▌  | 186/247 [00:44<00:13,  4.53it/s]Loading trainS:  76%|███████▌  | 187/247 [00:44<00:13,  4.55it/s]Loading trainS:  76%|███████▌  | 188/247 [00:44<00:12,  4.55it/s]Loading trainS:  77%|███████▋  | 189/247 [00:44<00:12,  4.54it/s]Loading trainS:  77%|███████▋  | 190/247 [00:44<00:12,  4.54it/s]Loading trainS:  77%|███████▋  | 191/247 [00:45<00:12,  4.56it/s]Loading trainS:  78%|███████▊  | 192/247 [00:45<00:12,  4.47it/s]Loading trainS:  78%|███████▊  | 193/247 [00:45<00:12,  4.42it/s]Loading trainS:  79%|███████▊  | 194/247 [00:45<00:11,  4.44it/s]Loading trainS:  79%|███████▉  | 195/247 [00:46<00:11,  4.50it/s]Loading trainS:  79%|███████▉  | 196/247 [00:46<00:11,  4.55it/s]Loading trainS:  80%|███████▉  | 197/247 [00:46<00:10,  4.59it/s]Loading trainS:  80%|████████  | 198/247 [00:46<00:10,  4.63it/s]Loading trainS:  81%|████████  | 199/247 [00:46<00:10,  4.65it/s]Loading trainS:  81%|████████  | 200/247 [00:47<00:10,  4.65it/s]Loading trainS:  81%|████████▏ | 201/247 [00:47<00:09,  4.66it/s]Loading trainS:  82%|████████▏ | 202/247 [00:47<00:09,  4.66it/s]Loading trainS:  82%|████████▏ | 203/247 [00:47<00:09,  4.66it/s]Loading trainS:  83%|████████▎ | 204/247 [00:47<00:09,  4.66it/s]Loading trainS:  83%|████████▎ | 205/247 [00:48<00:09,  4.62it/s]Loading trainS:  83%|████████▎ | 206/247 [00:48<00:08,  4.64it/s]Loading trainS:  84%|████████▍ | 207/247 [00:48<00:08,  4.65it/s]Loading trainS:  84%|████████▍ | 208/247 [00:48<00:08,  4.66it/s]Loading trainS:  85%|████████▍ | 209/247 [00:49<00:08,  4.69it/s]Loading trainS:  85%|████████▌ | 210/247 [00:49<00:07,  4.70it/s]Loading trainS:  85%|████████▌ | 211/247 [00:49<00:07,  4.72it/s]Loading trainS:  86%|████████▌ | 212/247 [00:49<00:07,  4.64it/s]Loading trainS:  86%|████████▌ | 213/247 [00:49<00:07,  4.59it/s]Loading trainS:  87%|████████▋ | 214/247 [00:50<00:07,  4.55it/s]Loading trainS:  87%|████████▋ | 215/247 [00:50<00:07,  4.53it/s]Loading trainS:  87%|████████▋ | 216/247 [00:50<00:06,  4.53it/s]Loading trainS:  88%|████████▊ | 217/247 [00:50<00:06,  4.53it/s]Loading trainS:  88%|████████▊ | 218/247 [00:50<00:06,  4.51it/s]Loading trainS:  89%|████████▊ | 219/247 [00:51<00:06,  4.47it/s]Loading trainS:  89%|████████▉ | 220/247 [00:51<00:06,  4.46it/s]Loading trainS:  89%|████████▉ | 221/247 [00:51<00:05,  4.48it/s]Loading trainS:  90%|████████▉ | 222/247 [00:51<00:05,  4.48it/s]Loading trainS:  90%|█████████ | 223/247 [00:52<00:05,  4.48it/s]Loading trainS:  91%|█████████ | 224/247 [00:52<00:05,  4.49it/s]Loading trainS:  91%|█████████ | 225/247 [00:52<00:04,  4.50it/s]Loading trainS:  91%|█████████▏| 226/247 [00:52<00:04,  4.50it/s]Loading trainS:  92%|█████████▏| 227/247 [00:53<00:04,  4.50it/s]Loading trainS:  92%|█████████▏| 228/247 [00:53<00:04,  4.50it/s]Loading trainS:  93%|█████████▎| 229/247 [00:53<00:04,  4.50it/s]Loading trainS:  93%|█████████▎| 230/247 [00:53<00:03,  4.36it/s]Loading trainS:  94%|█████████▎| 231/247 [00:53<00:03,  4.23it/s]Loading trainS:  94%|█████████▍| 232/247 [00:54<00:03,  4.20it/s]Loading trainS:  94%|█████████▍| 233/247 [00:54<00:03,  4.12it/s]Loading trainS:  95%|█████████▍| 234/247 [00:54<00:03,  4.07it/s]Loading trainS:  95%|█████████▌| 235/247 [00:54<00:02,  4.04it/s]Loading trainS:  96%|█████████▌| 236/247 [00:55<00:02,  4.02it/s]Loading trainS:  96%|█████████▌| 237/247 [00:55<00:02,  4.03it/s]Loading trainS:  96%|█████████▋| 238/247 [00:55<00:02,  4.02it/s]Loading trainS:  97%|█████████▋| 239/247 [00:55<00:02,  4.00it/s]Loading trainS:  97%|█████████▋| 240/247 [00:56<00:01,  3.99it/s]Loading trainS:  98%|█████████▊| 241/247 [00:56<00:01,  4.00it/s]Loading trainS:  98%|█████████▊| 242/247 [00:56<00:01,  3.99it/s]Loading trainS:  98%|█████████▊| 243/247 [00:56<00:01,  4.00it/s]Loading trainS:  99%|█████████▉| 244/247 [00:57<00:00,  3.98it/s]Loading trainS:  99%|█████████▉| 245/247 [00:57<00:00,  3.99it/s]Loading trainS: 100%|█████████▉| 246/247 [00:57<00:00,  3.99it/s]Loading trainS: 100%|██████████| 247/247 [00:57<00:00,  3.97it/s]Loading trainS: 100%|██████████| 247/247 [00:57<00:00,  4.26it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:00,  4.16it/s]Loading testS:  40%|████      | 2/5 [00:00<00:00,  3.95it/s]Loading testS:  60%|██████    | 3/5 [00:00<00:00,  3.97it/s]Loading testS:  80%|████████  | 4/5 [00:00<00:00,  4.18it/s]Loading testS: 100%|██████████| 5/5 [00:01<00:00,  4.19it/s]Loading testS: 100%|██████████| 5/5 [00:01<00:00,  4.10it/s]
Epoch 00047: val_mDice did not improve from 0.21646
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
{'val_loss': [0.6940556429326534, 0.6061076633632183, 0.3054265649698209, 0.16540633473778144, 0.11109029239742085, 0.0531713156378828, 0.07257895288785221, 0.05908679953427054, -0.023235300954183913, -0.05925711337476969, -0.08561709412606433, -0.10227093640060048, -0.08621181837224867, -0.09665463947749231, -0.1337093074398581, -0.15705027890726342, -0.1600373956025578, -0.1683625824516639, -0.14850269611633848, -0.16661432292312384, -0.1755954126128927, -0.17369070324457425, -0.19661201161216013, -0.1611766681598965, -0.1935851330345031, -0.16708265815395862, -0.07939216052182019, -0.1961677658255212, -0.21045888531079981, -0.21996985081932507, -0.2226400201616343, -0.2127100176003296, -0.2212272843462415, -0.2183186132751871, -0.23413230956793996, -0.21370894109713845, -0.21528213427518494, -0.2086870181519771, -0.21300900989444926, -0.23151501172833377, -0.22726720172795467, -0.24387359654065222, -0.2167318138090195, -0.2312315164017491, -0.22599299237481318, -0.20937203895300627, -0.22942461573984474], 'val_acc': [0.9419633913785219, 0.9278094973415136, 0.947335734963417, 0.9462064281105995, 0.9480719156563282, 0.9455729126930237, 0.9481520466506481, 0.9439090099185705, 0.9482246618717909, 0.9459773153066635, 0.9491974636912346, 0.9487204514443874, 0.9489232804626226, 0.9479554742574692, 0.9494165703654289, 0.9486265499144793, 0.9483698923140764, 0.9492926187813282, 0.9476587567478418, 0.9489858765155077, 0.950113931670785, 0.9489420633763075, 0.9500575922429562, 0.9476612601429224, 0.950261665508151, 0.9480706639587879, 0.9425731133669615, 0.9515387155115604, 0.9500425718724728, 0.9516488946974277, 0.9510879907757044, 0.9506360162049532, 0.9514923840761185, 0.9513897206634283, 0.9494140669703484, 0.9508851654827595, 0.9499661978334188, 0.9506172332912683, 0.9514623377472162, 0.9502817038446665, 0.9516038168221712, 0.952063299715519, 0.951282050460577, 0.9517590645700693, 0.9509127121418715, 0.9508989434689283, 0.9516789391636848], 'val_mDice': [0.19829080626368523, 0.12828068491944578, 0.20906813722103834, 0.19651736284140497, 0.20931382779963315, 0.1861595466034487, 0.2164580684620887, 0.20185099041555077, 0.21104323992040008, 0.20612799329683185, 0.2068294114433229, 0.2094719564775005, 0.21332502970471978, 0.21316545736044645, 0.21641359117347747, 0.21026334760244936, 0.2054600539850071, 0.20675909239798784, 0.2032841225154698, 0.19366344972513616, 0.20946033473592252, 0.2094525502761826, 0.21283136191777885, 0.20484845829196274, 0.21220412629190832, 0.19783929106779397, 0.1727564228931442, 0.21314989030361176, 0.20485230721533298, 0.21358143503312021, 0.2042392442235723, 0.2113451132318005, 0.21145732642617077, 0.20708643668331206, 0.19379152858164161, 0.2082346574170515, 0.20380446477793157, 0.20316875306889415, 0.20821048854850233, 0.19939095492009073, 0.2061022148700431, 0.208735910942778, 0.21044964576140046, 0.20507235697004944, 0.20782428153324872, 0.20682632294483483, 0.20870657137129456], 'loss': [0.6024275061015699, 0.4408618543494226, 0.40492785201536513, 0.3849402173549628, 0.3737805798835026, 0.3594199735091219, 0.3523077191900752, 0.34461650498689755, 0.3387860870928118, 0.3331120995761461, 0.3301806910158991, 0.3272834991997791, 0.3231040637748724, 0.3194643272549834, 0.31917535822146764, 0.32176108014754695, 0.3031790573629724, 0.28990021578783287, 0.2883967090496899, 0.2862233439003031, 0.28034588607825656, 0.2851390516361326, 0.267844503700082, 0.2592687914630762, 0.2525699740518269, 0.25514145511033387, 0.2552422144260832, 0.25597125904357215, 0.24781192538479183, 0.24832341169537892, 0.24527848982304098, 0.2457370798851983, 0.2422287134865069, 0.24564511163659583, 0.2427391455800314, 0.2411820985592926, 0.24060064940972048, 0.23031292363703962, 0.23196789469828563, 0.23318859290709926, 0.22904556154397698, 0.22599186574676025, 0.22180629402847715, 0.22405856383477335, 0.22500106893535265, 0.22559744875909604, 0.21706441548003078], 'acc': [0.8733129733869063, 0.9362879109950948, 0.9421494234055873, 0.9446453040919975, 0.9461871535903625, 0.9473521088722744, 0.9482107937419993, 0.9487543520248503, 0.9493328256666943, 0.9498796953645315, 0.9501978501469359, 0.9503855407047039, 0.9508870227526628, 0.9511247475483655, 0.9511298563225856, 0.9490388772525222, 0.9482360548443265, 0.9479720927684196, 0.9475483219852421, 0.9475206972910137, 0.9480510605125569, 0.9472000255319502, 0.9485230194243592, 0.9492565519104215, 0.9500549079347357, 0.9500256156166684, 0.9500860740599778, 0.9501453766788593, 0.9504626086777821, 0.9500446647203199, 0.950337867514989, 0.9500978835481841, 0.9505167510453576, 0.950067410480666, 0.9497671469226795, 0.949972679336056, 0.9495449289899139, 0.9506129710838976, 0.9507080609257919, 0.9504382713519655, 0.9506453434717925, 0.9509447846338717, 0.9509164935714783, 0.9507413317756013, 0.950936390538407, 0.9510319938067517, 0.951231081096481], 'mDice': [0.35101248007461067, 0.5243957647066704, 0.5631567643160211, 0.584727444131833, 0.596770993096239, 0.6123079523113802, 0.6199928482178769, 0.6283300686735045, 0.6346399193159604, 0.6407736182579487, 0.6439378341543175, 0.6470901740352787, 0.6516036069440517, 0.6555307285573014, 0.6557033714553905, 0.6318964750036802, 0.6249609625554919, 0.6185608539965677, 0.6169409072545802, 0.6114984180519982, 0.621420402023008, 0.6138593380984076, 0.6283405917883683, 0.639298518212288, 0.6476009916521319, 0.6446763748513358, 0.641855323649241, 0.6419285201314442, 0.6521120458195855, 0.6450643382721126, 0.6480550163031755, 0.6482171066812898, 0.6501357259619592, 0.639638604387387, 0.6403711357018007, 0.6435899177140553, 0.6413411559561163, 0.6503006362248945, 0.6512245778073168, 0.6459346947709093, 0.6472940650121319, 0.6535405035311024, 0.6549068217161114, 0.6552203092898342, 0.6528778569554421, 0.656379758685304, 0.6577222861839414], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     2020-01-22 03:05:31.289164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 03:05:31.289250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 03:05:31.289263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 03:05:31.289271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 03:05:31.289590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97331515 0.02668485]
Train on 16036 samples, validate on 318 samples
Epoch 1/300
 - 45s - loss: 0.2269 - acc: 0.9825 - mDice: 0.5555 - val_loss: 0.1263 - val_acc: 0.9921 - val_mDice: 0.4373

Epoch 00001: val_mDice improved from -inf to 0.43729, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 42s - loss: 0.0876 - acc: 0.9910 - mDice: 0.8295 - val_loss: 0.0926 - val_acc: 0.9928 - val_mDice: 0.4539

Epoch 00002: val_mDice improved from 0.43729 to 0.45393, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 43s - loss: 0.0775 - acc: 0.9921 - mDice: 0.8491 - val_loss: 0.0899 - val_acc: 0.9927 - val_mDice: 0.4598

Epoch 00003: val_mDice improved from 0.45393 to 0.45977, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 42s - loss: 0.0699 - acc: 0.9927 - mDice: 0.8640 - val_loss: 0.1531 - val_acc: 0.9918 - val_mDice: 0.4535

Epoch 00004: val_mDice did not improve from 0.45977
Epoch 5/300
 - 42s - loss: 0.0672 - acc: 0.9929 - mDice: 0.8692 - val_loss: 0.0587 - val_acc: 0.9932 - val_mDice: 0.4613

Epoch 00005: val_mDice improved from 0.45977 to 0.46127, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 42s - loss: 0.0628 - acc: 0.9933 - mDice: 0.8778 - val_loss: 0.0800 - val_acc: 0.9934 - val_mDice: 0.4786

Epoch 00006: val_mDice improved from 0.46127 to 0.47863, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 7/300
 - 42s - loss: 0.0612 - acc: 0.9936 - mDice: 0.8809 - val_loss: 0.1094 - val_acc: 0.9929 - val_mDice: 0.4832

Epoch 00007: val_mDice improved from 0.47863 to 0.48318, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 42s - loss: 0.0585 - acc: 0.9938 - mDice: 0.8862 - val_loss: 0.0475 - val_acc: 0.9935 - val_mDice: 0.4898

Epoch 00008: val_mDice improved from 0.48318 to 0.48983, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 9/300
 - 42s - loss: 0.0554 - acc: 0.9940 - mDice: 0.8923 - val_loss: 0.0913 - val_acc: 0.9937 - val_mDice: 0.5019

Epoch 00009: val_mDice improved from 0.48983 to 0.50194, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 10/300
 - 42s - loss: 0.0553 - acc: 0.9941 - mDice: 0.8925 - val_loss: 0.0232 - val_acc: 0.9938 - val_mDice: 0.4710

Epoch 00010: val_mDice did not improve from 0.50194
Epoch 11/300
 - 42s - loss: 0.0541 - acc: 0.9942 - mDice: 0.8949 - val_loss: 0.0452 - val_acc: 0.9937 - val_mDice: 0.4854

Epoch 00011: val_mDice did not improve from 0.50194
Epoch 12/300
 - 42s - loss: 0.0527 - acc: 0.9943 - mDice: 0.8974 - val_loss: 0.0401 - val_acc: 0.9940 - val_mDice: 0.4953

Epoch 00012: val_mDice did not improve from 0.50194
Epoch 13/300
 - 42s - loss: 0.0510 - acc: 0.9945 - mDice: 0.9007 - val_loss: 0.0468 - val_acc: 0.9931 - val_mDice: 0.4823

Epoch 00013: val_mDice did not improve from 0.50194
Epoch 14/300
 - 42s - loss: 0.0503 - acc: 0.9945 - mDice: 0.9023 - val_loss: 0.0135 - val_acc: 0.9939 - val_mDice: 0.4857

Epoch 00014: val_mDice did not improve from 0.50194
Epoch 15/300
 - 42s - loss: 0.0496 - acc: 0.9946 - mDice: 0.9035 - val_loss: 0.0183 - val_acc: 0.9935 - val_mDice: 0.4767

Epoch 00015: val_mDice did not improve from 0.50194
Epoch 16/300
 - 42s - loss: 0.0503 - acc: 0.9946 - mDice: 0.9022 - val_loss: 0.0100 - val_acc: 0.9938 - val_mDice: 0.4927

Epoch 00016: val_mDice did not improve from 0.50194
Epoch 17/300
 - 42s - loss: 0.0506 - acc: 0.9945 - mDice: 0.9017 - val_loss: 0.2709 - val_acc: 0.9731 - val_mDice: 0.3474

Epoch 00017: val_mDice did not improve from 0.50194
Epoch 18/300
 - 42s - loss: 0.0506 - acc: 0.9946 - mDice: 0.9016 - val_loss: 0.0084 - val_acc: 0.9942 - val_mDice: 0.4978

Epoch 00018: val_mDice did not improve from 0.50194
Epoch 19/300
 - 42s - loss: 0.0470 - acc: 0.9948 - mDice: 0.9086 - val_loss: -2.7489e-03 - val_acc: 0.9922 - val_mDice: 0.4560

Epoch 00019: val_mDice did not improve from 0.50194
Epoch 20/300
 - 42s - loss: 0.0471 - acc: 0.9948 - mDice: 0.9084 - val_loss: 0.0084 - val_acc: 0.9936 - val_mDice: 0.4960

Epoch 00020: val_mDice did not improve from 0.50194
Epoch 21/300
 - 42s - loss: 0.0478 - acc: 0.9948 - mDice: 0.9071 - val_loss: 0.0319 - val_acc: 0.9920 - val_mDice: 0.4497

Epoch 00021: val_mDice did not improve from 0.50194
Epoch 22/300
 - 42s - loss: 0.0473 - acc: 0.9949 - mDice: 0.9080 - val_loss: 0.0074 - val_acc: 0.9942 - val_mDice: 0.4977

Epoch 00022: val_mDice did not improve from 0.50194
Epoch 23/300
 - 42s - loss: 0.0470 - acc: 0.9949 - mDice: 0.9087 - val_loss: 0.0124 - val_acc: 0.9933 - val_mDice: 0.4881

Epoch 00023: val_mDice did not improve from 0.50194
Epoch 24/300
 - 42s - loss: 0.0458 - acc: 0.9949 - mDice: 0.9110 - val_loss: 0.0789 - val_acc: 0.9879 - val_mDice: 0.3577

Epoch 00024: val_mDice did not improve from 0.50194

Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 25/300
 - 42s - loss: 0.0447 - acc: 0.9951 - mDice: 0.9131 - val_loss: 0.0056 - val_acc: 0.9942 - val_mDice: 0.5012

Epoch 00025: val_mDice did not improve from 0.50194
Epoch 26/300
 - 42s - loss: 0.0444 - acc: 0.9951 - mDice: 0.9137 - val_loss: 0.0093 - val_acc: 0.9937 - val_mDice: 0.4942

Epoch 00026: val_mDice did not improve from 0.50194
Epoch 27/300
 - 42s - loss: 0.0428 - acc: 0.9952 - mDice: 0.9167 - val_loss: 0.0084 - val_acc: 0.9940 - val_mDice: 0.4959

Epoch 00027: val_mDice did not improve from 0.50194
Epoch 28/300
 - 42s - loss: 0.0430 - acc: 0.9952 - mDice: 0.9164 - val_loss: 0.0030 - val_acc: 0.9941 - val_mDice: 0.5066

Epoch 00028: val_mDice improved from 0.50194 to 0.50664, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 29/300
 - 42s - loss: 0.0448 - acc: 0.9951 - mDice: 0.9129 - val_loss: 0.0023 - val_acc: 0.9936 - val_mDice: 0.5081

Epoch 00029: val_mDice improved from 0.50664 to 0.50813, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 30/300
 - 42s - loss: 0.0434 - acc: 0.9952 - mDice: 0.9155 - val_loss: 3.5496e-04 - val_acc: 0.9941 - val_mDice: 0.5119

Epoch 00030: val_mDice improved from 0.50813 to 0.51186, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 31/300
 - 42s - loss: 0.0419 - acc: 0.9953 - mDice: 0.9185 - val_loss: 0.0074 - val_acc: 0.9937 - val_mDice: 0.4979

Epoch 00031: val_mDice did not improve from 0.51186
Epoch 32/300
 - 42s - loss: 0.0425 - acc: 0.9953 - mDice: 0.9174 - val_loss: 0.0086 - val_acc: 0.9935 - val_mDice: 0.4957

Epoch 00032: val_mDice did not improve from 0.51186
Epoch 33/300
 - 42s - loss: 0.0413 - acc: 0.9953 - mDice: 0.9198 - val_loss: 0.0029 - val_acc: 0.9940 - val_mDice: 0.5068

Epoch 00033: val_mDice did not improve from 0.51186
Epoch 34/300
 - 42s - loss: 0.0413 - acc: 0.9953 - mDice: 0.9197 - val_loss: 0.0651 - val_acc: 0.9942 - val_mDice: 0.5046

Epoch 00034: val_mDice did not improve from 0.51186
Epoch 35/300
 - 42s - loss: 0.0427 - acc: 0.9953 - mDice: 0.9170 - val_loss: 0.0350 - val_acc: 0.9938 - val_mDice: 0.5056

Epoch 00035: val_mDice did not improve from 0.51186
Epoch 36/300
 - 42s - loss: 0.0414 - acc: 0.9954 - mDice: 0.9195 - val_loss: 0.0060 - val_acc: 0.9942 - val_mDice: 0.5005

Epoch 00036: val_mDice did not improve from 0.51186
Epoch 37/300
 - 42s - loss: 0.0409 - acc: 0.9954 - mDice: 0.9205 - val_loss: 0.0021 - val_acc: 0.9941 - val_mDice: 0.5085

Epoch 00037: val_mDice did not improve from 0.51186
Epoch 38/300
 - 42s - loss: 0.0409 - acc: 0.9954 - mDice: 0.9206 - val_loss: 0.0079 - val_acc: 0.9935 - val_mDice: 0.4970

Epoch 00038: val_mDice did not improve from 0.51186
Epoch 39/300
 - 42s - loss: 0.0411 - acc: 0.9954 - mDice: 0.9202 - val_loss: 0.0095 - val_acc: 0.9936 - val_mDice: 0.4938

Epoch 00039: val_mDice did not improve from 0.51186
Epoch 40/300
 - 42s - loss: 0.0404 - acc: 0.9954 - mDice: 0.9216 - val_loss: 0.0028 - val_acc: 0.9936 - val_mDice: 0.5073

Epoch 00040: val_mDice did not improve from 0.51186
Epoch 41/300
 - 42s - loss: 0.0401 - acc: 0.9955 - mDice: 0.9222 - val_loss: -4.0042e-05 - val_acc: 0.9942 - val_mDice: 0.5127

Epoch 00041: val_mDice improved from 0.51186 to 0.51266, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 42/300
 - 41s - loss: 0.0397 - acc: 0.9954 - mDice: 0.9229 - val_loss: -4.3249e-05 - val_acc: 0.9942 - val_mDice: 0.5126

Epoch 00042: val_mDice did not improve from 0.51266
Epoch 43/300
 - 42s - loss: 0.0414 - acc: 0.9954 - mDice: 0.9196 - val_loss: 0.0107 - val_acc: 0.9936 - val_mDice: 0.4913

Epoch 00043: val_mDice did not improve from 0.51266
Epoch 44/300
 - 42s - loss: 0.0412 - acc: 0.9955 - mDice: 0.9198 - val_loss: 0.0245 - val_acc: 0.9941 - val_mDice: 0.5090

Epoch 00044: val_mDice did not improve from 0.51266
Epoch 45/300
 - 42s - loss: 0.0399 - acc: 0.9955 - mDice: 0.9225 - val_loss: 0.0038 - val_acc: 0.9941 - val_mDice: 0.5049

Epoch 00045: val_mDice did not improve from 0.51266

Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 46/300
 - 42s - loss: 0.0390 - acc: 0.9956 - mDice: 0.9242 - val_loss: 0.0038 - val_acc: 0.9941 - val_mDice: 0.5050

Epoch 00046: val_mDice did not improve from 0.51266
Epoch 47/300
 - 42s - loss: 0.0394 - acc: 0.9956 - mDice: 0.9234 - val_loss: 0.0029 - val_acc: 0.9941 - val_mDice: 0.5067

Epoch 00047: val_mDice did not improve from 0.51266
Epoch 48/300
 - 42s - loss: 0.0387 - acc: 0.9956 - mDice: 0.9248 - val_loss: 0.0034 - val_acc: 0.9940 - val_mDice: 0.5058

Epoch 00048: val_mDice did not improve from 0.51266
Epoch 49/300
 - 42s - loss: 0.0385 - acc: 0.9956 - mDice: 0.9252 - val_loss: 0.0020 - val_acc: 0.9942 - val_mDice: 0.5086

Epoch 00049: val_mDice did not improve from 0.51266
Epoch 50/300
 - 42s - loss: 0.0374 - acc: 0.9956 - mDice: 0.9275 - val_loss: 0.0077 - val_acc: 0.9937 - val_mDice: 0.4974

Epoch 00050: val_mDice did not improve from 0.51266
Epoch 51/300
 - 42s - loss: 0.0381 - acc: 0.9956 - mDice: 0.9261 - val_loss: 0.0057 - val_acc: 0.9940 - val_mDice: 0.5012

Epoch 00051: val_mDice did not improve from 0.51266
Epoch 52/300
 - 43s - loss: 0.0379 - acc: 0.9956 - mDice: 0.9264 - val_loss: 0.0118 - val_acc: 0.9934 - val_mDice: 0.4892

Epoch 00052: val_mDice did not improve from 0.51266
Epoch 53/300
 - 43s - loss: 0.0377 - acc: 0.9956 - mDice: 0.9268 - val_loss: 0.0035 - val_acc: 0.9942 - val_mDice: 0.5054

Epoch 00053: val_mDice did not improve from 0.51266
Epoch 54/300
 - 43s - loss: 0.0386 - acc: 0.9956 - mDice: 0.9249 - val_loss: 0.0058 - val_acc: 0.9937 - val_mDice: 0.5011

Epoch 00054: val_mDice did not improve from 0.51266
Epoch 55/300
 - 43s - loss: 0.0376 - acc: 0.9956 - mDice: 0.9269 - val_loss: 0.0014 - val_acc: 0.9942 - val_mDice: 0.5097

Epoch 00055: val_mDice did not improve from 0.51266
Epoch 56/300
 - 43s - loss: 0.0380 - acc: 0.9957 - mDice: 0.9262 - val_loss: 0.0062 - val_acc: 0.9938 - val_mDice: 0.5002

Epoch 00056: val_mDice did not improve from 0.51266
Epoch 57/300
 - 43s - loss: 0.0382 - acc: 0.9956 - mDice: 0.9258 - val_loss: 0.0054 - val_acc: 0.9938 - val_mDice: 0.5019

Epoch 00057: val_mDice did not improve from 0.51266
Epoch 58/300
 - 43s - loss: 0.0381 - acc: 0.9957 - mDice: 0.9260 - val_loss: 0.0011 - val_acc: 0.9941 - val_mDice: 0.5103

Epoch 00058: val_mDice did not improve from 0.51266
Epoch 59/300
 - 43s - loss: 0.0368 - acc: 0.9957 - mDice: 0.9285 - val_loss: -5.0538e-04 - val_acc: 0.9942 - val_mDice: 0.5135

Epoch 00059: val_mDice improved from 0.51266 to 0.51355, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 60/300
 - 43s - loss: 0.0373 - acc: 0.9957 - mDice: 0.9276 - val_loss: 0.0075 - val_acc: 0.9934 - val_mDice: 0.4979

Epoch 00060: val_mDice did not improve from 0.51355
Epoch 61/300
 - 43s - loss: 0.0373 - acc: 0.9957 - mDice: 0.9276 - val_loss: 0.0018 - val_acc: 0.9942 - val_mDice: 0.5090

Epoch 00061: val_mDice did not improve from 0.51355
Epoch 62/300
 - 43s - loss: 0.0381 - acc: 0.9957 - mDice: 0.9259 - val_loss: 0.0070 - val_acc: 0.9939 - val_mDice: 0.4988

Epoch 00062: val_mDice did not improve from 0.51355
Epoch 63/300
 - 43s - loss: 0.0375 - acc: 0.9957 - mDice: 0.9272 - val_loss: 0.0071 - val_acc: 0.9938 - val_mDice: 0.4985

Epoch 00063: val_mDice did not improve from 0.51355
Epoch 64/300
 - 43s - loss: 0.0370 - acc: 0.9957 - mDice: 0.9281 - val_loss: 0.0084 - val_acc: 0.9933 - val_mDice: 0.4961

Epoch 00064: val_mDice did not improve from 0.51355
Epoch 65/300
 - 43s - loss: 0.0371 - acc: 0.9957 - mDice: 0.9278 - val_loss: -2.7723e-04 - val_acc: 0.9942 - val_mDice: 0.5131

Epoch 00065: val_mDice did not improve from 0.51355
Epoch 66/300
 - 42s - loss: 0.0366 - acc: 0.9957 - mDice: 0.9289 - val_loss: 0.0069 - val_acc: 0.9937 - val_mDice: 0.4989

Epoch 00066: val_mDice did not improve from 0.51355
Epoch 67/300
 - 42s - loss: 0.0369 - acc: 0.9958 - mDice: 0.9283 - val_loss: 0.0098 - val_acc: 0.9934 - val_mDice: 0.4932

Epoch 00067: val_mDice did not improve from 0.51355
Epoch 68/300
 - 42s - loss: 0.0369 - acc: 0.9957 - mDice: 0.9283 - val_loss: 0.0049 - val_acc: 0.9939 - val_mDice: 0.5029

Epoch 00068: val_mDice did not improve from 0.51355
Epoch 69/300
 - 42s - loss: 0.0375 - acc: 0.9957 - mDice: 0.9271 - val_loss: 0.0128 - val_acc: 0.9931 - val_mDice: 0.4874

Epoch 00069: val_mDice did not improve from 0.51355
Epoch 70/300
 - 42s - loss: 0.0369 - acc: 0.9958 - mDice: 0.9283 - val_loss: 4.7938e-05 - val_acc: 0.9942 - val_mDice: 0.5124

Epoch 00070: val_mDice did not improve from 0.51355
Epoch 71/300
 - 42s - loss: 0.0364 - acc: 0.9957 - mDice: 0.9294 - val_loss: 0.0061 - val_acc: 0.9937 - val_mDice: 0.5006

Epoch 00071: val_mDice did not improve from 0.51355
Epoch 72/300
 - 42s - loss: 0.0365 - acc: 0.9958 - mDice: 0.9291 - val_loss: 0.0070 - val_acc: 0.9936 - val_mDice: 0.4988

Epoch 00072: val_mDice did not improve from 0.51355
Epoch 73/300
 - 42s - loss: 0.0374 - acc: 0.9957 - mDice: 0.9274 - val_loss: 0.0059 - val_acc: 0.9939 - val_mDice: 0.5009

Epoch 00073: val_mDice did not improve from 0.51355
Epoch 74/300
 - 42s - loss: 0.0363 - acc: 0.9958 - mDice: 0.9295 - val_loss: 0.0060 - val_acc: 0.9939 - val_mDice: 0.5007

Epoch 00074: val_mDice did not improve from 0.51355

Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 75/300
 - 42s - loss: 0.0372 - acc: 0.9958 - mDice: 0.9276 - val_loss: 0.0075 - val_acc: 0.9937 - val_mDice: 0.4976

Epoch 00075: val_mDice did not improve from 0.51355
Epoch 76/300
 - 43s - loss: 0.0360 - acc: 0.9958 - mDice: 0.9300 - val_loss: 0.0022 - val_acc: 0.9940 - val_mDice: 0.5083

Epoch 00076: val_mDice did not improve from 0.51355
Epoch 77/300
 - 43s - loss: 0.0354 - acc: 0.9958 - mDice: 0.9314 - val_loss: 0.0043 - val_acc: 0.9939 - val_mDice: 0.5040

Epoch 00077: val_mDice did not improve from 0.51355
Epoch 78/300
 - 43s - loss: 0.0359 - acc: 0.9958 - mDice: 0.9302 - val_loss: 0.0034 - val_acc: 0.9939 - val_mDice: 0.5059

Epoch 00078: val_mDice did not improve from 0.51355
Epoch 79/300
 - 43s - loss: 0.0359 - acc: 0.9958 - mDice: 0.9303 - val_loss: 0.0096 - val_acc: 0.9936 - val_mDice: 0.4936

Epoch 00079: val_mDice did not improve from 0.51355
Epoch 80/300
 - 43s - loss: 0.0355 - acc: 0.9958 - mDice: 0.9312 - val_loss: 0.0046 - val_acc: 0.9939 - val_mDice: 0.5035

Epoch 00080: val_mDice did not improve from 0.51355
Epoch 81/300
 - 43s - loss: 0.0361 - acc: 0.9958 - mDice: 0.9298 - val_loss: 0.0077 - val_acc: 0.9935 - val_mDice: 0.4975

Epoch 00081: val_mDice did not improve from 0.51355
Epoch 82/300
 - 43s - loss: 0.0367 - acc: 0.9958 - mDice: 0.9287 - val_loss: 0.0058 - val_acc: 0.9936 - val_mDice: 0.5012

Epoch 00082: val_mDice did not improve from 0.51355
Epoch 83/300
 - 43s - loss: 0.0354 - acc: 0.9958 - mDice: 0.9312 - val_loss: 0.0015 - val_acc: 0.9940 - val_mDice: 0.5096

Epoch 00083: val_mDice did not improve from 0.51355
Epoch 84/300
 - 43s - loss: 0.0360 - acc: 0.9958 - mDice: 0.9300 - val_loss: 0.0059 - val_acc: 0.9938 - val_mDice: 0.5010

Epoch 00084: val_mDice did not improve from 0.51355
Epoch 85/300
 - 43s - loss: 0.0357 - acc: 0.9958 - mDice: 0.9307 - val_loss: 0.0042 - val_acc: 0.9938 - val_mDice: 0.5044

Epoch 00085: val_mDice did not improve from 0.51355
Epoch 86/300
 - 43s - loss: 0.0356 - acc: 0.9958 - mDice: 0.9309 - val_loss: 0.0033 - val_acc: 0.9940 - val_mDice: 0.5061

Epoch 00086: val_mDice did not improve from 0.51355
Epoch 87/300
 - 43s - loss: 0.0356 - acc: 0.9959 - mDice: 0.9309 - val_loss: 0.0100 - val_acc: 0.9934 - val_mDice: 0.4928

Epoch 00087: val_mDice did not improve from 0.51355
Epoch 88/300
 - 43s - loss: 0.0355 - acc: 0.9958 - mDice: 0.9312 - val_loss: 0.0035 - val_acc: 0.9939 - val_mDice: 0.5058

Epoch 00088: val_mDice did not improve from 0.51355
Epoch 89/300
 - 42s - loss: 0.0355 - acc: 0.9959 - mDice: 0.9310 - val_loss: 0.0041 - val_acc: 0.9939 - val_mDice: 0.5045

Epoch 00089: val_mDice did not improve from 0.51355

Epoch 00089: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 90/300
 - 42s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9321 - val_loss: 0.0073 - val_acc: 0.9935 - val_mDice: 0.4982

Epoch 00090: val_mDice did not improve from 0.51355
Epoch 91/300
 - 41s - loss: 0.0357 - acc: 0.9959 - mDice: 0.9306 - val_loss: 0.0051 - val_acc: 0.9939 - val_mDice: 0.5025

Epoch 00091: val_mDice did not improve from 0.51355
Epoch 92/300
 - 42s - loss: 0.0355 - acc: 0.9959 - mDice: 0.9310 - val_loss: 0.0037 - val_acc: 0.9940 - val_mDice: 0.5053

Epoch 00092: val_mDice did not improve from 0.51355
Epoch 93/300
 - 42s - loss: 0.0351 - acc: 0.9959 - mDice: 0.9318 - val_loss: 0.0041 - val_acc: 0.9939 - val_mDice: 0.5045

Epoch 00093: val_mDice did not improve from 0.51355
Epoch 94/300
 - 42s - loss: 0.0352 - acc: 0.9959 - mDice: 0.9317 - val_loss: 0.0024 - val_acc: 0.9940 - val_mDice: 0.5078

Epoch 00094: val_mDice did not improve from 0.51355
Epoch 95/300
 - 42s - loss: 0.0349 - acc: 0.9959 - mDice: 0.9322 - val_loss: 0.0046 - val_acc: 0.9940 - val_mDice: 0.5034

Epoch 00095: val_mDice did not improve from 0.51355
Epoch 96/300
 - 42s - loss: 0.0351 - acc: 0.9959 - mDice: 0.9319 - val_loss: 0.0045 - val_acc: 0.9941 - val_mDice: 0.5035

Epoch 00096: val_mDice did not improve from 0.51355
Epoch 97/300
 - 42s - loss: 0.0349 - acc: 0.9959 - mDice: 0.9321 - val_loss: 0.0074 - val_acc: 0.9937 - val_mDice: 0.4980

Epoch 00097: val_mDice did not improve from 0.51355
Epoch 98/300
 - 42s - loss: 0.0357 - acc: 0.9959 - mDice: 0.9307 - val_loss: 0.0047 - val_acc: 0.9940 - val_mDice: 0.5032

Epoch 00098: val_mDice did not improve from 0.51355
Epoch 99/300
 - 42s - loss: 0.0351 - acc: 0.9959 - mDice: 0.9318 - val_loss: 0.0045 - val_acc: 0.9940 - val_mDice: 0.5036

Epoch 00099: val_mDice did not improve from 0.51355
Restoring model weights from the end of the best epoch
Epoch 00099: early stopping
{'val_loss': [0.12627856939468743, 0.0925526109131627, 0.08986425849626649, 0.15313268162356983, 0.0586824764808019, 0.08004346096290732, 0.10942407111701725, 0.04750311557414397, 0.09130075990966281, 0.023195300696405973, 0.045151094970463206, 0.040133202975651004, 0.04682160510956866, 0.01346238374522647, 0.01829016831873348, 0.009967972647468999, 0.2709277135864744, 0.008393826162290273, -0.002748947520301027, 0.008407577403686332, 0.03189341470880328, 0.0074312223953271065, 0.012373921162677262, 0.07892075897950046, 0.005633782478248548, 0.009258068207674806, 0.008350038303519195, 0.002996686728870344, 0.0023111180408195878, 0.0003549589675927312, 0.007414824323459242, 0.00857197235590257, 0.0028872116931579397, 0.06512364918518367, 0.03497986247142156, 0.005985180911777905, 0.0020511511174387902, 0.007922439174082294, 0.00949422724591861, 0.0028291993171164075, -4.0041997372729224e-05, -4.3248558569254364e-05, 0.010711295284190268, 0.024457301593051768, 0.0038413316386300815, 0.003806724863232307, 0.0029340877941569444, 0.0033853254134550035, 0.0019746498210625077, 0.0076738437579112985, 0.005716509695323008, 0.011813629067169045, 0.003548820438624928, 0.005782177660075374, 0.0014257264212242462, 0.00623047300292261, 0.005393521637661652, 0.001138841581044707, -0.0005053799575979605, 0.007475360525104235, 0.001808660257162538, 0.006952366317218205, 0.0071010850604225255, 0.008421508817927642, -0.0002772291220209134, 0.0069263808944690156, 0.009823834136971887, 0.00486477127052703, 0.012776063673151363, 4.7938113317549606e-05, 0.006062650783631786, 0.006979938385621557, 0.005886966608605295, 0.005968077846293179, 0.007543198061439226, 0.0021813230694464917, 0.0043368243009039445, 0.003387399158387814, 0.009568548661732824, 0.004556206177990392, 0.007661577009554929, 0.0058000049313659185, 0.001513931689397344, 0.005858048702935752, 0.004172107895965096, 0.0032685359225333114, 0.010043242489391903, 0.003456071487762643, 0.004085215616900966, 0.0073139654859057015, 0.005051011887361419, 0.0036749367444020398, 0.004073711498728338, 0.002429556968452046, 0.004578627271097411, 0.004513528643164245, 0.007391902307669322, 0.004682786622137393, 0.004501755085756194], 'val_acc': [0.9921293318646509, 0.9928293944154896, 0.992719701251144, 0.9917681258429522, 0.9931642394395744, 0.993432066725485, 0.99285600282861, 0.9935299607942689, 0.9936702772506378, 0.9937523629680369, 0.9936981396105304, 0.9940299762869781, 0.9930681035203753, 0.9939215408181244, 0.9935189208144661, 0.9938419704917092, 0.9730841978540961, 0.9941579894449726, 0.9921732522406668, 0.9936271032447335, 0.9920311851321526, 0.994197148571974, 0.9933442154770378, 0.9878940342357324, 0.9942388155925199, 0.9936589842322487, 0.9940008637290331, 0.9940902200884789, 0.993613045545494, 0.994120847129222, 0.993719479197976, 0.9934988389225126, 0.9940369995135181, 0.9941851039352657, 0.9938324337485451, 0.9942245142264936, 0.9941396675769638, 0.9934687235820219, 0.993551049217488, 0.9935648520037813, 0.9942305365448478, 0.9942305327961279, 0.9936446753687829, 0.9940530702752887, 0.9940543242220609, 0.9941446889871322, 0.9941000061215095, 0.9939870515709404, 0.9942061867354051, 0.9936677712314533, 0.993975005059872, 0.9934067216309361, 0.9942039262573674, 0.9937495945384668, 0.9941815876360959, 0.9938394625981649, 0.9938176169335468, 0.9941030200922264, 0.9942252639704531, 0.9933685671608403, 0.994166021077138, 0.9938582830459067, 0.9938048169297992, 0.9933339233668346, 0.9942270239943978, 0.9937443257127918, 0.9933976834675051, 0.9938517602734596, 0.9930861779728776, 0.9942465979348188, 0.9936579833240629, 0.9936193227767944, 0.9938828858939357, 0.9939488989752043, 0.9937350363851344, 0.9940488004834397, 0.9939130049831463, 0.9938630551662085, 0.9936378995577494, 0.9939273119722523, 0.993529460340176, 0.9935897060160367, 0.9939918236912422, 0.993838703482406, 0.993765410387291, 0.9940053790620288, 0.9933919029415779, 0.9938884115069168, 0.9938886607967833, 0.9935224352392761, 0.9938808747057645, 0.9940106478877038, 0.9938826366040692, 0.993987557648113, 0.9939709920553291, 0.9940540711834746, 0.9936710344920369, 0.9939772636635499, 0.9939544170907458], 'val_mDice': [0.43729180949124596, 0.4539298139360247, 0.4597702967120135, 0.4535075976924009, 0.4612654626791207, 0.47863278163116685, 0.4831809810591194, 0.4898321272442176, 0.5019384655375151, 0.47102153640966743, 0.4853787549636649, 0.49525834948011915, 0.482323760365915, 0.485726332045951, 0.47668298132389597, 0.4927450507504385, 0.34743438036263036, 0.4977717883182022, 0.456049752966413, 0.4959507517343497, 0.44972287174665704, 0.4976714018193431, 0.48812676947446737, 0.3577125045542454, 0.5012481383182821, 0.4942093536538898, 0.495905063156062, 0.5066447550396028, 0.5081302592964306, 0.5118558673015504, 0.4978847320932719, 0.4956854954412367, 0.5068113096058369, 0.5046017390658271, 0.5056214709795496, 0.500534324785592, 0.5084905536177585, 0.49697835408385443, 0.4938130221719684, 0.5073232061973533, 0.5126565472228722, 0.5126010989711719, 0.4913372908420158, 0.5089873478472607, 0.50491919811323, 0.5049593759548364, 0.5066924343037905, 0.5058410866830334, 0.508597342988605, 0.4973910078874924, 0.5011732269476794, 0.4891919353449682, 0.5053968018846317, 0.5011008329595785, 0.5096885285474969, 0.5001890059537107, 0.5018673073383247, 0.5102937139055264, 0.5135462192947384, 0.4979495059862827, 0.5089667235624116, 0.4987600491434898, 0.49848928262696324, 0.49607443031649917, 0.5131264159795623, 0.4988511527578036, 0.49320129033342097, 0.5029367967128003, 0.4874464236902741, 0.5124387063039174, 0.5006211028440194, 0.49881639251918913, 0.5008731768378671, 0.5007290842491876, 0.4976304349893669, 0.5082506296347897, 0.5039627709478702, 0.5058914036402162, 0.4936037573644177, 0.503531675082895, 0.49750166746008695, 0.5012026781790286, 0.5096312286625119, 0.5009702156127999, 0.5043648780798012, 0.5060794620347098, 0.4927804091441556, 0.5057644677705735, 0.5044877701351103, 0.49820399134414, 0.5025324490179056, 0.5052641469914958, 0.5045114061648741, 0.5077720098431755, 0.5034466317427233, 0.5035470836098839, 0.49796914049195795, 0.5032386784236761, 0.5036309333342426], 'loss': [0.22689670710142607, 0.0875734989158484, 0.07749651886204972, 0.06987734482502604, 0.0672419149596797, 0.0628280126210697, 0.06117017289874975, 0.058498190768410605, 0.055398779205957475, 0.05528249500152565, 0.054050562504179965, 0.05273306731717282, 0.05104517619095113, 0.05026202769306539, 0.049607670413649385, 0.05026450294821927, 0.050556997049587805, 0.050571459509296646, 0.04704030781954594, 0.047102916916057815, 0.047783222620952276, 0.04733425457412449, 0.04695195566893486, 0.045791345378293394, 0.04470271901983696, 0.04436914893375962, 0.042845904962785765, 0.04301274436820799, 0.04480750254132588, 0.04344154146784974, 0.04194705229811045, 0.04249195605293418, 0.04128708283680132, 0.041309852040625775, 0.042692262825227846, 0.041414029633286706, 0.040925938804255484, 0.04085324278315513, 0.04107092865541797, 0.04035238574295456, 0.04005785894980452, 0.03970414826246413, 0.04136420489955823, 0.04123715151089271, 0.03986771069197591, 0.039012828481728136, 0.03942513915443694, 0.03868936243204293, 0.03851809628989875, 0.037351026525221494, 0.03805632843273808, 0.03791057425775294, 0.03768080636769734, 0.03862871737659617, 0.03761326797245208, 0.037980480723122045, 0.038169939903531715, 0.03807901472213798, 0.03682917724466883, 0.03727533541067814, 0.03729397637770045, 0.038131382478966504, 0.037453367651051554, 0.03700182545836295, 0.03714804077299345, 0.036599363098383304, 0.03691418688065038, 0.03692111747335186, 0.03750476342305099, 0.03690448707310182, 0.036383099825186276, 0.03651773934335029, 0.037380900883517025, 0.0363140480783804, 0.037220410856746565, 0.03601501676530189, 0.035352056197883425, 0.03591637029950236, 0.035890829036452285, 0.035452123418223624, 0.03613151163122963, 0.03669131253389504, 0.0354208640770949, 0.03602982676235123, 0.035702716228365156, 0.03560535674117901, 0.03559493271545241, 0.03545574642983598, 0.03554684388615985, 0.034957964537327475, 0.035733265267491314, 0.03549670496429104, 0.0351071116944506, 0.035180854291675334, 0.03494030356139547, 0.03508510126135955, 0.034949843697184846, 0.035664780715414936, 0.035117744706268175], 'acc': [0.9824938856475993, 0.9910074767105358, 0.9920787066630099, 0.992711571623899, 0.9929005422774144, 0.9933309635859708, 0.99361143678791, 0.9938008351705413, 0.9940187816579433, 0.9940749135999258, 0.9941804736785741, 0.9943132669543887, 0.9944765983703696, 0.9944886526924085, 0.9945910235434346, 0.9945665880699471, 0.9945335121010865, 0.994567230228594, 0.9948077997860394, 0.9948062265371259, 0.9948071627195829, 0.9948525879635244, 0.9948844795260949, 0.99488741705084, 0.9951173777918055, 0.9951364419189109, 0.9952243222028248, 0.9952241876054565, 0.9950617684943922, 0.9952417990012965, 0.9953323806289665, 0.9952946557505644, 0.9953425408048979, 0.9953345961852037, 0.9953203701592348, 0.9953784839816746, 0.9953518742395774, 0.9953892157838421, 0.9953847315044407, 0.9954361392170689, 0.9954513316812822, 0.9954461256043516, 0.9954417050628181, 0.9954608788913133, 0.9955173191524082, 0.9955600082398531, 0.9955743831807938, 0.9955764145186846, 0.9956126957797267, 0.9956169819692091, 0.995629968080297, 0.995618444639538, 0.9956249404456081, 0.9956447621122148, 0.9956485798796623, 0.9956511383893395, 0.9956428461997816, 0.995663626328107, 0.995705145304564, 0.9956748711331345, 0.9957079429985074, 0.9956929310431472, 0.9956979831054817, 0.9957213584518575, 0.9956917159647738, 0.9957130253835341, 0.9957527863797954, 0.9957126116003292, 0.9957431045500945, 0.9957503327692379, 0.9957310049707498, 0.9957597048153571, 0.9957497152761201, 0.995786031476278, 0.995787745016892, 0.9958280028250783, 0.9958150919445973, 0.9958130253776704, 0.995834284989606, 0.9958338122856709, 0.9958240663612772, 0.9958486200256162, 0.9958322393192439, 0.9958429607363168, 0.9958409206116101, 0.9958279831179302, 0.995863249471997, 0.995822538800833, 0.9958607067592604, 0.9958506067752482, 0.995880885221144, 0.9958877003261293, 0.9958735141307524, 0.995896745126543, 0.9958732447650374, 0.9958876155281519, 0.9958956787698612, 0.995872802049271, 0.9958880734981875], 'mDice': [0.5554878587455491, 0.8295203504275952, 0.8490991268678967, 0.8640061604323118, 0.8691765999078496, 0.8777761485740769, 0.8809448737232044, 0.8861902132509548, 0.8922718198155488, 0.8924736330621585, 0.8948825988672297, 0.8974426991273026, 0.90073738746897, 0.9022942699378611, 0.9035474882403286, 0.9022438330680362, 0.9016832088930572, 0.9016242384256942, 0.9085616633913023, 0.9084362972032461, 0.9070759532821241, 0.9079501357326323, 0.9086955949035955, 0.9110129402593117, 0.9130696450035443, 0.9137202436380863, 0.9167228977031677, 0.9163892430449162, 0.912884529749706, 0.9155221638513878, 0.9184620637464297, 0.9173877635934936, 0.919775398239497, 0.9197330660848553, 0.9169743426383865, 0.9194981589314943, 0.9204823776176368, 0.9206106476755207, 0.9201809326946423, 0.9215852459876369, 0.9221692223424298, 0.9228756675832614, 0.9195630112269024, 0.9198011818257583, 0.9225200805009288, 0.924197509435086, 0.9233635470427222, 0.9248370466074107, 0.925153841666671, 0.9274883678828311, 0.926072975569055, 0.9263662052930636, 0.9268254371809228, 0.9249187823274422, 0.9269455425101166, 0.9262094304028756, 0.9258365613943293, 0.926005854738059, 0.9284807537359678, 0.9276054867985362, 0.9275510981288685, 0.9258854544659925, 0.9272346777656068, 0.9281290184830038, 0.9278468067998689, 0.9289359994647092, 0.9282879869400875, 0.9282912508110418, 0.9271089477461304, 0.9283084161979178, 0.929362168400387, 0.9290699795951134, 0.9273542804621675, 0.9294716179385748, 0.9276442951872391, 0.9300421649201251, 0.931372938280422, 0.930245379388823, 0.9302836816728182, 0.9311649090695917, 0.9298124338926952, 0.9286864664815375, 0.9312234032507934, 0.9300011613030599, 0.9306621322476617, 0.9308552966135105, 0.9308726646658428, 0.9311588820702835, 0.9309651074370234, 0.9321395102567761, 0.9305746856919843, 0.9310475885532097, 0.9318337024492229, 0.9316739518056936, 0.9321613879463163, 0.9318723455944927, 0.9321344686464408, 0.9307165479096549, 0.9318038936296464], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.51it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.93it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.43it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.95it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.64it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.84it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:31,  7.90it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:30,  8.08it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:29,  8.24it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:29,  8.11it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:29,  8.12it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:29,  8.11it/s]predicting train subjects:   3%|▎         | 7/247 [00:00<00:29,  8.06it/s]predicting train subjects:   3%|▎         | 8/247 [00:00<00:29,  8.11it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:29,  8.07it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:29,  8.04it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:29,  8.09it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:29,  8.02it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:29,  8.03it/s]predicting train subjects:   6%|▌         | 14/247 [00:01<00:29,  7.82it/s]predicting train subjects:   6%|▌         | 15/247 [00:01<00:29,  7.82it/s]predicting train subjects:   6%|▋         | 16/247 [00:01<00:29,  7.87it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:28,  8.00it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:28,  7.93it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:29,  7.82it/s]predicting train subjects:   8%|▊         | 20/247 [00:02<00:28,  7.86it/s]predicting train subjects:   9%|▊         | 21/247 [00:02<00:28,  7.80it/s]predicting train subjects:   9%|▉         | 22/247 [00:02<00:28,  7.90it/s]predicting train subjects:   9%|▉         | 23/247 [00:02<00:27,  8.04it/s]predicting train subjects:  10%|▉         | 24/247 [00:02<00:27,  8.22it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:26,  8.24it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:26,  8.27it/s]predicting train subjects:  11%|█         | 27/247 [00:03<00:26,  8.31it/s]predicting train subjects:  11%|█▏        | 28/247 [00:03<00:26,  8.24it/s]predicting train subjects:  12%|█▏        | 29/247 [00:03<00:26,  8.21it/s]predicting train subjects:  12%|█▏        | 30/247 [00:03<00:26,  8.32it/s]predicting train subjects:  13%|█▎        | 31/247 [00:03<00:25,  8.37it/s]predicting train subjects:  13%|█▎        | 32/247 [00:03<00:25,  8.27it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:25,  8.29it/s]predicting train subjects:  14%|█▍        | 34/247 [00:04<00:25,  8.30it/s]predicting train subjects:  14%|█▍        | 35/247 [00:04<00:25,  8.38it/s]predicting train subjects:  15%|█▍        | 36/247 [00:04<00:25,  8.38it/s]predicting train subjects:  15%|█▍        | 37/247 [00:04<00:24,  8.43it/s]predicting train subjects:  15%|█▌        | 38/247 [00:04<00:24,  8.42it/s]predicting train subjects:  16%|█▌        | 39/247 [00:04<00:24,  8.44it/s]predicting train subjects:  16%|█▌        | 40/247 [00:04<00:24,  8.35it/s]predicting train subjects:  17%|█▋        | 41/247 [00:05<00:24,  8.41it/s]predicting train subjects:  17%|█▋        | 42/247 [00:05<00:24,  8.41it/s]predicting train subjects:  17%|█▋        | 43/247 [00:05<00:24,  8.38it/s]predicting train subjects:  18%|█▊        | 44/247 [00:05<00:24,  8.40it/s]predicting train subjects:  18%|█▊        | 45/247 [00:05<00:24,  8.39it/s]predicting train subjects:  19%|█▊        | 46/247 [00:05<00:23,  8.41it/s]predicting train subjects:  19%|█▉        | 47/247 [00:05<00:23,  8.39it/s]predicting train subjects:  19%|█▉        | 48/247 [00:05<00:23,  8.40it/s]predicting train subjects:  20%|█▉        | 49/247 [00:05<00:23,  8.42it/s]predicting train subjects:  20%|██        | 50/247 [00:06<00:23,  8.47it/s]predicting train subjects:  21%|██        | 51/247 [00:06<00:23,  8.47it/s]predicting train subjects:  21%|██        | 52/247 [00:06<00:22,  8.50it/s]predicting train subjects:  21%|██▏       | 53/247 [00:06<00:22,  8.46it/s]predicting train subjects:  22%|██▏       | 54/247 [00:06<00:22,  8.45it/s]predicting train subjects:  22%|██▏       | 55/247 [00:06<00:22,  8.38it/s]predicting train subjects:  23%|██▎       | 56/247 [00:06<00:22,  8.40it/s]predicting train subjects:  23%|██▎       | 57/247 [00:06<00:22,  8.38it/s]predicting train subjects:  23%|██▎       | 58/247 [00:07<00:22,  8.43it/s]predicting train subjects:  24%|██▍       | 59/247 [00:07<00:22,  8.18it/s]predicting train subjects:  24%|██▍       | 60/247 [00:07<00:23,  8.10it/s]predicting train subjects:  25%|██▍       | 61/247 [00:07<00:23,  7.85it/s]predicting train subjects:  25%|██▌       | 62/247 [00:07<00:23,  7.87it/s]predicting train subjects:  26%|██▌       | 63/247 [00:07<00:23,  7.87it/s]predicting train subjects:  26%|██▌       | 64/247 [00:07<00:23,  7.87it/s]predicting train subjects:  26%|██▋       | 65/247 [00:07<00:23,  7.89it/s]predicting train subjects:  27%|██▋       | 66/247 [00:08<00:23,  7.86it/s]predicting train subjects:  27%|██▋       | 67/247 [00:08<00:22,  7.84it/s]predicting train subjects:  28%|██▊       | 68/247 [00:08<00:22,  7.84it/s]predicting train subjects:  28%|██▊       | 69/247 [00:08<00:23,  7.63it/s]predicting train subjects:  28%|██▊       | 70/247 [00:08<00:23,  7.68it/s]predicting train subjects:  29%|██▊       | 71/247 [00:08<00:22,  7.72it/s]predicting train subjects:  29%|██▉       | 72/247 [00:08<00:22,  7.76it/s]predicting train subjects:  30%|██▉       | 73/247 [00:08<00:23,  7.56it/s]predicting train subjects:  30%|██▉       | 74/247 [00:09<00:22,  7.56it/s]predicting train subjects:  30%|███       | 75/247 [00:09<00:22,  7.52it/s]predicting train subjects:  31%|███       | 76/247 [00:09<00:22,  7.57it/s]predicting train subjects:  31%|███       | 77/247 [00:09<00:24,  7.08it/s]predicting train subjects:  32%|███▏      | 78/247 [00:09<00:24,  6.98it/s]predicting train subjects:  32%|███▏      | 79/247 [00:09<00:26,  6.34it/s]predicting train subjects:  32%|███▏      | 80/247 [00:10<00:28,  5.87it/s]predicting train subjects:  33%|███▎      | 81/247 [00:10<00:28,  5.84it/s]predicting train subjects:  33%|███▎      | 82/247 [00:10<00:27,  5.92it/s]predicting train subjects:  34%|███▎      | 83/247 [00:10<00:26,  6.15it/s]predicting train subjects:  34%|███▍      | 84/247 [00:10<00:25,  6.31it/s]predicting train subjects:  34%|███▍      | 85/247 [00:10<00:25,  6.44it/s]predicting train subjects:  35%|███▍      | 86/247 [00:11<00:24,  6.49it/s]predicting train subjects:  35%|███▌      | 87/247 [00:11<00:24,  6.61it/s]predicting train subjects:  36%|███▌      | 88/247 [00:11<00:23,  6.64it/s]predicting train subjects:  36%|███▌      | 89/247 [00:11<00:24,  6.53it/s]predicting train subjects:  36%|███▋      | 90/247 [00:11<00:23,  6.63it/s]predicting train subjects:  37%|███▋      | 91/247 [00:11<00:23,  6.69it/s]predicting train subjects:  37%|███▋      | 92/247 [00:11<00:23,  6.69it/s]predicting train subjects:  38%|███▊      | 93/247 [00:12<00:23,  6.50it/s]predicting train subjects:  38%|███▊      | 94/247 [00:12<00:23,  6.61it/s]predicting train subjects:  38%|███▊      | 95/247 [00:12<00:23,  6.53it/s]predicting train subjects:  39%|███▉      | 96/247 [00:12<00:22,  6.61it/s]predicting train subjects:  39%|███▉      | 97/247 [00:12<00:22,  6.65it/s]predicting train subjects:  40%|███▉      | 98/247 [00:12<00:22,  6.68it/s]predicting train subjects:  40%|████      | 99/247 [00:12<00:22,  6.70it/s]predicting train subjects:  40%|████      | 100/247 [00:13<00:21,  6.72it/s]predicting train subjects:  41%|████      | 101/247 [00:13<00:21,  6.83it/s]predicting train subjects:  41%|████▏     | 102/247 [00:13<00:20,  6.92it/s]predicting train subjects:  42%|████▏     | 103/247 [00:13<00:20,  6.86it/s]predicting train subjects:  42%|████▏     | 104/247 [00:13<00:20,  6.94it/s]predicting train subjects:  43%|████▎     | 105/247 [00:13<00:20,  6.95it/s]predicting train subjects:  43%|████▎     | 106/247 [00:13<00:20,  6.90it/s]predicting train subjects:  43%|████▎     | 107/247 [00:14<00:20,  6.83it/s]predicting train subjects:  44%|████▎     | 108/247 [00:14<00:20,  6.87it/s]predicting train subjects:  44%|████▍     | 109/247 [00:14<00:20,  6.86it/s]predicting train subjects:  45%|████▍     | 110/247 [00:14<00:19,  6.92it/s]predicting train subjects:  45%|████▍     | 111/247 [00:14<00:19,  6.98it/s]predicting train subjects:  45%|████▌     | 112/247 [00:14<00:19,  7.01it/s]predicting train subjects:  46%|████▌     | 113/247 [00:14<00:19,  7.03it/s]predicting train subjects:  46%|████▌     | 114/247 [00:15<00:18,  7.04it/s]predicting train subjects:  47%|████▋     | 115/247 [00:15<00:18,  7.07it/s]predicting train subjects:  47%|████▋     | 116/247 [00:15<00:19,  6.85it/s]predicting train subjects:  47%|████▋     | 117/247 [00:15<00:18,  6.87it/s]predicting train subjects:  48%|████▊     | 118/247 [00:15<00:17,  7.22it/s]predicting train subjects:  48%|████▊     | 119/247 [00:15<00:16,  7.55it/s]predicting train subjects:  49%|████▊     | 120/247 [00:15<00:16,  7.76it/s]predicting train subjects:  49%|████▉     | 121/247 [00:16<00:16,  7.83it/s]predicting train subjects:  49%|████▉     | 122/247 [00:16<00:15,  7.83it/s]predicting train subjects:  50%|████▉     | 123/247 [00:16<00:16,  7.57it/s]predicting train subjects:  50%|█████     | 124/247 [00:16<00:16,  7.55it/s]predicting train subjects:  51%|█████     | 125/247 [00:16<00:15,  7.68it/s]predicting train subjects:  51%|█████     | 126/247 [00:16<00:16,  7.55it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:16<00:15,  7.71it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:16<00:14,  7.94it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:17<00:14,  8.08it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:17<00:14,  8.16it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:17<00:14,  8.20it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:17<00:14,  8.04it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:17<00:14,  8.04it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:17<00:13,  8.17it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:17<00:13,  8.25it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:17<00:13,  8.16it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:18<00:13,  8.21it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:18<00:13,  8.24it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:18<00:13,  8.12it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:18<00:13,  8.15it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:18<00:13,  8.15it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:18<00:12,  8.10it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:18<00:12,  8.12it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:18<00:12,  8.21it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:19<00:12,  8.28it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:19<00:12,  8.26it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:19<00:12,  8.21it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:19<00:12,  8.18it/s]predicting train subjects:  60%|██████    | 149/247 [00:19<00:12,  8.16it/s]predicting train subjects:  61%|██████    | 150/247 [00:19<00:11,  8.22it/s]predicting train subjects:  61%|██████    | 151/247 [00:19<00:11,  8.16it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:19<00:11,  8.11it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:20<00:11,  8.12it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:20<00:12,  7.64it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:20<00:12,  7.47it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:20<00:12,  7.24it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:20<00:12,  7.13it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:20<00:12,  7.08it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:20<00:12,  7.03it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:21<00:12,  7.00it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:21<00:12,  6.95it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:21<00:12,  6.91it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:21<00:12,  6.89it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:21<00:11,  6.94it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:21<00:11,  6.89it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:21<00:11,  6.84it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:22<00:11,  6.80it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:22<00:12,  6.47it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:22<00:11,  6.53it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:22<00:11,  6.63it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:22<00:11,  6.69it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:22<00:10,  7.05it/s]predicting train subjects:  70%|███████   | 173/247 [00:23<00:11,  6.20it/s]predicting train subjects:  70%|███████   | 174/247 [00:23<00:11,  6.60it/s]predicting train subjects:  71%|███████   | 175/247 [00:23<00:12,  5.93it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:23<00:10,  6.46it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:23<00:10,  6.82it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:23<00:09,  7.13it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:23<00:09,  7.21it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:23<00:09,  7.37it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:24<00:08,  7.60it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:24<00:08,  7.67it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:24<00:08,  7.74it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:24<00:08,  7.63it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:24<00:08,  7.74it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:24<00:07,  7.85it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:24<00:07,  7.94it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:24<00:07,  7.95it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:25<00:07,  7.94it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:25<00:07,  8.01it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:25<00:06,  8.07it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:25<00:06,  7.94it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:25<00:06,  8.01it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:25<00:06,  8.07it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:25<00:06,  7.91it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:25<00:06,  8.10it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:26<00:06,  8.19it/s]predicting train subjects:  80%|████████  | 198/247 [00:26<00:05,  8.36it/s]predicting train subjects:  81%|████████  | 199/247 [00:26<00:06,  7.99it/s]predicting train subjects:  81%|████████  | 200/247 [00:26<00:05,  8.17it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:26<00:05,  8.28it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:26<00:05,  8.40it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:26<00:05,  8.47it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:26<00:05,  8.55it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:27<00:04,  8.60it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:27<00:04,  8.52it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:27<00:04,  8.41it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:27<00:04,  8.31it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:27<00:04,  8.44it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:27<00:04,  8.53it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:27<00:04,  8.45it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:27<00:04,  8.43it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:27<00:04,  8.45it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:28<00:03,  8.44it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:28<00:03,  8.47it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:28<00:03,  8.49it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:28<00:03,  8.48it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:28<00:03,  8.35it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:28<00:03,  8.27it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:28<00:03,  8.17it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:28<00:03,  8.22it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:29<00:03,  8.29it/s]predicting train subjects:  90%|█████████ | 223/247 [00:29<00:02,  8.32it/s]predicting train subjects:  91%|█████████ | 224/247 [00:29<00:02,  8.47it/s]predicting train subjects:  91%|█████████ | 225/247 [00:29<00:02,  8.52it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:29<00:02,  8.50it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:29<00:02,  8.51it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:29<00:02,  8.51it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:29<00:02,  8.50it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:30<00:02,  8.05it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:30<00:02,  7.83it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:30<00:01,  7.65it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:30<00:01,  7.54it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:30<00:01,  7.33it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:30<00:01,  7.30it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:30<00:01,  7.33it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:31<00:01,  7.34it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:31<00:01,  7.41it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:31<00:01,  7.44it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:31<00:00,  7.39it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:31<00:00,  7.29it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:31<00:00,  7.26it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:31<00:00,  7.23it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:31<00:00,  7.24it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:32<00:00,  7.27it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:32<00:00,  7.28it/s]predicting train subjects: 100%|██████████| 247/247 [00:32<00:00,  7.27it/s]predicting train subjects: 100%|██████████| 247/247 [00:32<00:00,  7.63it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  7.92it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  7.63it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  7.60it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  7.96it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  8.11it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.92it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:30,  8.08it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:30,  8.01it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:30,  8.11it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:30,  8.06it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:29,  8.09it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:29,  8.12it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:00<00:30,  7.98it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:00<00:29,  8.02it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:29,  8.03it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:29,  7.98it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:29,  7.97it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:30,  7.73it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:30,  7.70it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:01<00:30,  7.62it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:01<00:30,  7.60it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:02<00:29,  7.73it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:29,  7.84it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:29,  7.88it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:28,  7.89it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:02<00:28,  7.92it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:02<00:29,  7.69it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:02<00:28,  7.80it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:02<00:28,  7.93it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:03<00:27,  8.09it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:27,  8.18it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:26,  8.29it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:03<00:26,  8.38it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:03<00:26,  8.42it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:03<00:25,  8.47it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:03<00:25,  8.44it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:03<00:25,  8.44it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:03<00:25,  8.41it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:04<00:25,  8.39it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:04<00:25,  8.36it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:04<00:25,  8.32it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:04<00:25,  8.40it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:04<00:24,  8.41it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:04<00:24,  8.49it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:04<00:25,  8.22it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:04<00:25,  8.28it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:05<00:25,  8.24it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:05<00:24,  8.26it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:05<00:24,  8.30it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:05<00:24,  8.35it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:05<00:24,  8.35it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:05<00:24,  8.22it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:05<00:24,  8.33it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:05<00:24,  8.10it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:06<00:24,  8.07it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:06<00:24,  8.14it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:06<00:24,  7.96it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:06<00:23,  8.15it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:06<00:23,  8.24it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:06<00:23,  8.27it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:06<00:23,  8.29it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:06<00:23,  8.29it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:07<00:22,  8.30it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:07<00:22,  8.29it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:07<00:23,  8.14it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:07<00:23,  8.12it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:07<00:23,  8.01it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:07<00:23,  8.02it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:07<00:22,  8.02it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:07<00:22,  8.06it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:08<00:22,  8.14it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:08<00:22,  8.07it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:08<00:22,  8.11it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:08<00:21,  8.15it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:08<00:22,  7.97it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:08<00:22,  8.00it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:08<00:22,  7.99it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:08<00:21,  7.99it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:09<00:21,  8.00it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:09<00:21,  8.00it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:09<00:21,  8.07it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:09<00:21,  8.11it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:09<00:22,  7.67it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:09<00:22,  7.57it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:09<00:21,  7.90it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:09<00:20,  8.15it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:10<00:21,  7.83it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:10<00:22,  7.30it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:10<00:22,  7.18it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:10<00:22,  7.16it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:10<00:22,  7.18it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:10<00:22,  7.11it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:10<00:22,  7.07it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:11<00:22,  7.04it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:11<00:22,  7.06it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:11<00:22,  7.03it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:11<00:22,  7.02it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:11<00:22,  7.00it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:11<00:22,  6.99it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:11<00:21,  7.00it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:12<00:21,  6.93it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:12<00:21,  6.95it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:12<00:22,  6.65it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:12<00:23,  6.36it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:12<00:22,  6.52it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:12<00:21,  6.73it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:12<00:21,  6.87it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:13<00:20,  7.01it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:13<00:20,  7.09it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:13<00:19,  7.18it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:13<00:19,  7.17it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:13<00:19,  7.17it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:13<00:19,  7.18it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:13<00:19,  7.22it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:14<00:19,  7.23it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:14<00:19,  7.18it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:14<00:18,  7.22it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:14<00:18,  7.27it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:14<00:18,  7.30it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:14<00:18,  7.33it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:14<00:17,  7.34it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:14<00:17,  7.35it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:15<00:17,  7.24it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:15<00:16,  7.63it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:15<00:16,  7.94it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:15<00:15,  8.16it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:15<00:15,  8.32it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:15<00:14,  8.41it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:15<00:14,  8.51it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:15<00:14,  8.58it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:16<00:14,  8.62it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:16<00:14,  8.61it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:16<00:13,  8.72it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:16<00:13,  8.76it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:16<00:13,  8.76it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:16<00:13,  8.85it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:16<00:12,  8.93it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:16<00:12,  8.92it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:16<00:12,  8.92it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:17<00:12,  8.85it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:17<00:12,  8.77it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:17<00:12,  8.66it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:17<00:12,  8.68it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:17<00:12,  8.58it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:17<00:12,  8.49it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:17<00:12,  8.46it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:17<00:12,  8.56it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:18<00:12,  8.62it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:18<00:11,  8.68it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:18<00:11,  8.67it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:18<00:11,  8.74it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:18<00:11,  8.77it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:18<00:11,  8.78it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:18<00:11,  8.79it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:18<00:11,  8.76it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:18<00:11,  8.81it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:19<00:10,  8.85it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:19<00:10,  8.85it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:19<00:10,  8.76it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:19<00:11,  8.16it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:19<00:11,  7.92it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:19<00:11,  7.71it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:19<00:11,  7.60it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:19<00:11,  7.52it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:20<00:11,  7.42it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:20<00:11,  7.35it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:20<00:11,  7.29it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:20<00:11,  7.23it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:20<00:11,  7.19it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:20<00:11,  7.21it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:20<00:11,  7.19it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:21<00:11,  7.13it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:21<00:11,  7.16it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:21<00:11,  7.18it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:21<00:10,  7.15it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:21<00:10,  7.02it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:21<00:10,  7.07it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:21<00:10,  7.35it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:22<00:09,  7.73it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:22<00:09,  7.90it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:22<00:09,  7.70it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:22<00:08,  7.94it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:22<00:08,  8.13it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:22<00:08,  8.23it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:22<00:08,  8.24it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:22<00:08,  8.23it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:22<00:07,  8.26it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:23<00:07,  8.31it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:23<00:07,  8.40it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:23<00:07,  8.43it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:23<00:07,  8.48it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:23<00:07,  8.50it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:23<00:07,  8.50it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:23<00:07,  8.42it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:23<00:06,  8.40it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:24<00:06,  8.42it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:24<00:06,  8.47it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:24<00:06,  8.44it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:24<00:06,  8.34it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:24<00:06,  8.51it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:24<00:05,  8.69it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:24<00:05,  8.84it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:24<00:05,  8.95it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:24<00:05,  9.03it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:25<00:05,  9.08it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:25<00:05,  9.13it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:25<00:05,  9.17it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:25<00:04,  9.18it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:25<00:04,  9.14it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:25<00:04,  9.09it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:25<00:04,  8.76it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:25<00:04,  8.90it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:25<00:04,  8.98it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:26<00:04,  8.93it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:26<00:04,  8.91it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:26<00:04,  9.01it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:26<00:03,  9.08it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:26<00:03,  8.96it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:26<00:03,  8.86it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:26<00:03,  8.85it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:26<00:03,  8.77it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:26<00:03,  8.75it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:27<00:03,  8.71it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:27<00:03,  8.66it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:27<00:03,  8.69it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:27<00:03,  8.74it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:27<00:02,  8.78it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:27<00:02,  8.77it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:27<00:02,  8.72it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:27<00:02,  8.75it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:27<00:02,  8.78it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:28<00:02,  8.79it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:28<00:02,  8.79it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:28<00:02,  8.74it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:28<00:02,  8.68it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:28<00:02,  8.18it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:28<00:02,  7.92it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:28<00:01,  7.66it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:29<00:01,  7.51it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:29<00:01,  7.45it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:29<00:01,  7.41it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:29<00:01,  7.33it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:29<00:01,  7.29it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:29<00:01,  7.18it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:29<00:01,  7.27it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:29<00:01,  6.88it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:30<00:00,  7.05it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:30<00:00,  6.98it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:30<00:00,  7.12it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:30<00:00,  7.18it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:30<00:00,  7.23it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:30<00:00,  7.36it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  7.45it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  7.98it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 78.63it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 85.51it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 85.10it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 85.95it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:02, 86.59it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 87.50it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 88.66it/s]saving BB  train1-THALAMUS:  26%|██▌       | 63/247 [00:00<00:02, 83.92it/s]saving BB  train1-THALAMUS:  29%|██▊       | 71/247 [00:00<00:02, 81.63it/s]saving BB  train1-THALAMUS:  32%|███▏      | 79/247 [00:00<00:02, 80.46it/s]saving BB  train1-THALAMUS:  35%|███▌      | 87/247 [00:01<00:02, 76.57it/s]saving BB  train1-THALAMUS:  38%|███▊      | 95/247 [00:01<00:02, 73.54it/s]saving BB  train1-THALAMUS:  42%|████▏     | 103/247 [00:01<00:01, 72.76it/s]saving BB  train1-THALAMUS:  45%|████▍     | 111/247 [00:01<00:01, 73.38it/s]saving BB  train1-THALAMUS:  48%|████▊     | 119/247 [00:01<00:01, 74.12it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 128/247 [00:01<00:01, 76.07it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 136/247 [00:01<00:01, 76.13it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 144/247 [00:01<00:01, 76.53it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 153/247 [00:01<00:01, 79.36it/s]saving BB  train1-THALAMUS:  65%|██████▌   | 161/247 [00:02<00:01, 77.33it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 169/247 [00:02<00:01, 76.23it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 177/247 [00:02<00:00, 77.02it/s]saving BB  train1-THALAMUS:  75%|███████▍  | 185/247 [00:02<00:00, 77.38it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 193/247 [00:02<00:00, 77.52it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 202/247 [00:02<00:00, 79.35it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 211/247 [00:02<00:00, 81.37it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 220/247 [00:02<00:00, 82.66it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 229/247 [00:02<00:00, 84.16it/s]saving BB  train1-THALAMUS:  96%|█████████▋| 238/247 [00:02<00:00, 81.49it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 79.19it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 79.52it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 77.66it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/247 [00:00<00:03, 78.79it/s]saving BB  train1-THALAMUS Sagittal:   6%|▋         | 16/247 [00:00<00:02, 78.97it/s]saving BB  train1-THALAMUS Sagittal:  10%|█         | 25/247 [00:00<00:02, 79.85it/s]saving BB  train1-THALAMUS Sagittal:  13%|█▎        | 33/247 [00:00<00:02, 78.54it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 42/247 [00:00<00:02, 81.64it/s]saving BB  train1-THALAMUS Sagittal:  21%|██        | 52/247 [00:00<00:02, 84.82it/s]saving BB  train1-THALAMUS Sagittal:  25%|██▍       | 61/247 [00:00<00:02, 85.49it/s]saving BB  train1-THALAMUS Sagittal:  28%|██▊       | 70/247 [00:00<00:02, 83.79it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 78/247 [00:00<00:02, 80.93it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 86/247 [00:01<00:02, 78.05it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 94/247 [00:01<00:02, 74.64it/s]saving BB  train1-THALAMUS Sagittal:  41%|████▏     | 102/247 [00:01<00:01, 72.77it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 110/247 [00:01<00:01, 73.50it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 118/247 [00:01<00:01, 74.37it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████▏    | 127/247 [00:01<00:01, 76.09it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 135/247 [00:01<00:01, 76.77it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▊    | 145/247 [00:01<00:01, 80.46it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 155/247 [00:01<00:01, 82.81it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▋   | 164/247 [00:02<00:01, 81.18it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 173/247 [00:02<00:00, 80.54it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 182/247 [00:02<00:00, 80.82it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 191/247 [00:02<00:00, 80.61it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 200/247 [00:02<00:00, 80.29it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▍ | 209/247 [00:02<00:00, 81.94it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 218/247 [00:02<00:00, 83.45it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 227/247 [00:02<00:00, 81.77it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 236/247 [00:02<00:00, 80.36it/s]saving BB  train1-THALAMUS Sagittal:  99%|█████████▉| 245/247 [00:03<00:00, 78.24it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 79.83it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:39,  1.12it/s]Loading train:   1%|          | 2/247 [00:01<03:28,  1.17it/s]Loading train:   1%|          | 3/247 [00:02<03:18,  1.23it/s]Loading train:   2%|▏         | 4/247 [00:03<03:22,  1.20it/s]Loading train:   2%|▏         | 5/247 [00:03<03:02,  1.32it/s]Loading train:   2%|▏         | 6/247 [00:04<02:46,  1.44it/s]Loading train:   3%|▎         | 7/247 [00:04<02:33,  1.57it/s]Loading train:   3%|▎         | 8/247 [00:05<02:25,  1.65it/s]Loading train:   4%|▎         | 9/247 [00:05<02:18,  1.72it/s]Loading train:   4%|▍         | 10/247 [00:06<02:12,  1.79it/s]Loading train:   4%|▍         | 11/247 [00:06<02:09,  1.82it/s]Loading train:   5%|▍         | 12/247 [00:07<02:05,  1.88it/s]Loading train:   5%|▌         | 13/247 [00:07<02:02,  1.92it/s]Loading train:   6%|▌         | 14/247 [00:08<02:01,  1.92it/s]Loading train:   6%|▌         | 15/247 [00:08<01:58,  1.95it/s]Loading train:   6%|▋         | 16/247 [00:09<01:58,  1.95it/s]Loading train:   7%|▋         | 17/247 [00:10<01:58,  1.94it/s]Loading train:   7%|▋         | 18/247 [00:10<01:59,  1.92it/s]Loading train:   8%|▊         | 19/247 [00:11<01:58,  1.93it/s]Loading train:   8%|▊         | 20/247 [00:11<01:57,  1.93it/s]Loading train:   9%|▊         | 21/247 [00:12<01:56,  1.95it/s]Loading train:   9%|▉         | 22/247 [00:12<01:57,  1.92it/s]Loading train:   9%|▉         | 23/247 [00:13<01:58,  1.90it/s]Loading train:  10%|▉         | 24/247 [00:13<01:55,  1.93it/s]Loading train:  10%|█         | 25/247 [00:14<01:52,  1.98it/s]Loading train:  11%|█         | 26/247 [00:14<01:50,  2.01it/s]Loading train:  11%|█         | 27/247 [00:15<01:47,  2.04it/s]Loading train:  11%|█▏        | 28/247 [00:15<01:48,  2.02it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:47,  2.02it/s]Loading train:  12%|█▏        | 30/247 [00:16<01:46,  2.04it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:44,  2.07it/s]Loading train:  13%|█▎        | 32/247 [00:17<01:43,  2.07it/s]Loading train:  13%|█▎        | 33/247 [00:18<01:43,  2.06it/s]Loading train:  14%|█▍        | 34/247 [00:18<01:42,  2.07it/s]Loading train:  14%|█▍        | 35/247 [00:19<01:47,  1.97it/s]Loading train:  15%|█▍        | 36/247 [00:19<01:47,  1.96it/s]Loading train:  15%|█▍        | 37/247 [00:20<01:48,  1.94it/s]Loading train:  15%|█▌        | 38/247 [00:20<01:49,  1.92it/s]Loading train:  16%|█▌        | 39/247 [00:21<01:49,  1.90it/s]Loading train:  16%|█▌        | 40/247 [00:21<01:47,  1.92it/s]Loading train:  17%|█▋        | 41/247 [00:22<01:46,  1.94it/s]Loading train:  17%|█▋        | 42/247 [00:22<01:42,  2.00it/s]Loading train:  17%|█▋        | 43/247 [00:23<01:39,  2.05it/s]Loading train:  18%|█▊        | 44/247 [00:23<01:38,  2.07it/s]Loading train:  18%|█▊        | 45/247 [00:24<01:37,  2.07it/s]Loading train:  19%|█▊        | 46/247 [00:24<01:36,  2.09it/s]Loading train:  19%|█▉        | 47/247 [00:24<01:34,  2.12it/s]Loading train:  19%|█▉        | 48/247 [00:25<01:33,  2.13it/s]Loading train:  20%|█▉        | 49/247 [00:25<01:32,  2.13it/s]Loading train:  20%|██        | 50/247 [00:26<01:30,  2.17it/s]Loading train:  21%|██        | 51/247 [00:26<01:29,  2.19it/s]Loading train:  21%|██        | 52/247 [00:27<01:27,  2.23it/s]Loading train:  21%|██▏       | 53/247 [00:27<01:29,  2.16it/s]Loading train:  22%|██▏       | 54/247 [00:28<01:29,  2.15it/s]Loading train:  22%|██▏       | 55/247 [00:28<01:29,  2.13it/s]Loading train:  23%|██▎       | 56/247 [00:29<01:29,  2.12it/s]Loading train:  23%|██▎       | 57/247 [00:29<01:29,  2.13it/s]Loading train:  23%|██▎       | 58/247 [00:30<01:28,  2.12it/s]Loading train:  24%|██▍       | 59/247 [00:30<01:36,  1.96it/s]Loading train:  24%|██▍       | 60/247 [00:31<01:37,  1.93it/s]Loading train:  25%|██▍       | 61/247 [00:31<01:37,  1.92it/s]Loading train:  25%|██▌       | 62/247 [00:32<01:35,  1.93it/s]Loading train:  26%|██▌       | 63/247 [00:32<01:36,  1.91it/s]Loading train:  26%|██▌       | 64/247 [00:33<01:36,  1.89it/s]Loading train:  26%|██▋       | 65/247 [00:33<01:36,  1.89it/s]Loading train:  27%|██▋       | 66/247 [00:34<01:34,  1.91it/s]Loading train:  27%|██▋       | 67/247 [00:34<01:34,  1.90it/s]Loading train:  28%|██▊       | 68/247 [00:35<01:33,  1.92it/s]Loading train:  28%|██▊       | 69/247 [00:35<01:33,  1.90it/s]Loading train:  28%|██▊       | 70/247 [00:36<01:33,  1.88it/s]Loading train:  29%|██▊       | 71/247 [00:37<01:33,  1.89it/s]Loading train:  29%|██▉       | 72/247 [00:37<01:34,  1.85it/s]Loading train:  30%|██▉       | 73/247 [00:38<01:34,  1.85it/s]Loading train:  30%|██▉       | 74/247 [00:38<01:34,  1.83it/s]Loading train:  30%|███       | 75/247 [00:39<01:34,  1.83it/s]Loading train:  31%|███       | 76/247 [00:39<01:34,  1.82it/s]Loading train:  31%|███       | 77/247 [00:40<01:55,  1.48it/s]Loading train:  32%|███▏      | 78/247 [00:41<02:07,  1.33it/s]Loading train:  32%|███▏      | 79/247 [00:42<02:06,  1.33it/s]Loading train:  32%|███▏      | 80/247 [00:43<02:05,  1.33it/s]Loading train:  33%|███▎      | 81/247 [00:44<02:12,  1.25it/s]Loading train:  33%|███▎      | 82/247 [00:44<02:03,  1.34it/s]Loading train:  34%|███▎      | 83/247 [00:45<01:56,  1.41it/s]Loading train:  34%|███▍      | 84/247 [00:45<01:51,  1.46it/s]Loading train:  34%|███▍      | 85/247 [00:46<01:48,  1.50it/s]Loading train:  35%|███▍      | 86/247 [00:47<01:45,  1.53it/s]Loading train:  35%|███▌      | 87/247 [00:47<01:43,  1.55it/s]Loading train:  36%|███▌      | 88/247 [00:48<01:41,  1.57it/s]Loading train:  36%|███▌      | 89/247 [00:49<01:39,  1.59it/s]Loading train:  36%|███▋      | 90/247 [00:49<01:38,  1.60it/s]Loading train:  37%|███▋      | 91/247 [00:50<01:36,  1.62it/s]Loading train:  37%|███▋      | 92/247 [00:50<01:35,  1.63it/s]Loading train:  38%|███▊      | 93/247 [00:51<01:35,  1.61it/s]Loading train:  38%|███▊      | 94/247 [00:52<01:36,  1.58it/s]Loading train:  38%|███▊      | 95/247 [00:52<01:38,  1.54it/s]Loading train:  39%|███▉      | 96/247 [00:53<01:37,  1.54it/s]Loading train:  39%|███▉      | 97/247 [00:54<01:37,  1.55it/s]Loading train:  40%|███▉      | 98/247 [00:54<01:35,  1.56it/s]Loading train:  40%|████      | 99/247 [00:55<01:34,  1.57it/s]Loading train:  40%|████      | 100/247 [00:56<01:32,  1.59it/s]Loading train:  41%|████      | 101/247 [00:56<01:31,  1.60it/s]Loading train:  41%|████▏     | 102/247 [00:57<01:28,  1.64it/s]Loading train:  42%|████▏     | 103/247 [00:57<01:26,  1.67it/s]Loading train:  42%|████▏     | 104/247 [00:58<01:25,  1.67it/s]Loading train:  43%|████▎     | 105/247 [00:59<01:25,  1.67it/s]Loading train:  43%|████▎     | 106/247 [00:59<01:24,  1.68it/s]Loading train:  43%|████▎     | 107/247 [01:00<01:23,  1.68it/s]Loading train:  44%|████▎     | 108/247 [01:00<01:22,  1.69it/s]Loading train:  44%|████▍     | 109/247 [01:01<01:21,  1.69it/s]Loading train:  45%|████▍     | 110/247 [01:01<01:22,  1.67it/s]Loading train:  45%|████▍     | 111/247 [01:02<01:22,  1.64it/s]Loading train:  45%|████▌     | 112/247 [01:03<01:21,  1.66it/s]Loading train:  46%|████▌     | 113/247 [01:03<01:19,  1.68it/s]Loading train:  46%|████▌     | 114/247 [01:04<01:18,  1.70it/s]Loading train:  47%|████▋     | 115/247 [01:04<01:18,  1.69it/s]Loading train:  47%|████▋     | 116/247 [01:05<01:16,  1.72it/s]Loading train:  47%|████▋     | 117/247 [01:06<01:13,  1.77it/s]Loading train:  48%|████▊     | 118/247 [01:06<01:11,  1.81it/s]Loading train:  48%|████▊     | 119/247 [01:07<01:08,  1.87it/s]Loading train:  49%|████▊     | 120/247 [01:07<01:07,  1.89it/s]Loading train:  49%|████▉     | 121/247 [01:08<01:06,  1.91it/s]Loading train:  49%|████▉     | 122/247 [01:08<01:05,  1.91it/s]Loading train:  50%|████▉     | 123/247 [01:09<01:05,  1.91it/s]Loading train:  50%|█████     | 124/247 [01:09<01:04,  1.91it/s]Loading train:  51%|█████     | 125/247 [01:10<01:04,  1.91it/s]Loading train:  51%|█████     | 126/247 [01:10<01:03,  1.90it/s]Loading train:  51%|█████▏    | 127/247 [01:11<01:03,  1.88it/s]Loading train:  52%|█████▏    | 128/247 [01:11<01:03,  1.88it/s]Loading train:  52%|█████▏    | 129/247 [01:12<01:03,  1.86it/s]Loading train:  53%|█████▎    | 130/247 [01:12<01:01,  1.90it/s]Loading train:  53%|█████▎    | 131/247 [01:13<01:00,  1.90it/s]Loading train:  53%|█████▎    | 132/247 [01:13<01:00,  1.92it/s]Loading train:  54%|█████▍    | 133/247 [01:14<00:59,  1.90it/s]Loading train:  54%|█████▍    | 134/247 [01:14<01:00,  1.87it/s]Loading train:  55%|█████▍    | 135/247 [01:15<00:59,  1.89it/s]Loading train:  55%|█████▌    | 136/247 [01:16<00:59,  1.86it/s]Loading train:  55%|█████▌    | 137/247 [01:16<00:57,  1.90it/s]Loading train:  56%|█████▌    | 138/247 [01:17<00:57,  1.91it/s]Loading train:  56%|█████▋    | 139/247 [01:17<00:55,  1.93it/s]Loading train:  57%|█████▋    | 140/247 [01:18<00:54,  1.96it/s]Loading train:  57%|█████▋    | 141/247 [01:18<00:54,  1.96it/s]Loading train:  57%|█████▋    | 142/247 [01:19<00:52,  2.01it/s]Loading train:  58%|█████▊    | 143/247 [01:19<00:50,  2.06it/s]Loading train:  58%|█████▊    | 144/247 [01:19<00:49,  2.08it/s]Loading train:  59%|█████▊    | 145/247 [01:20<00:48,  2.10it/s]Loading train:  59%|█████▉    | 146/247 [01:20<00:48,  2.07it/s]Loading train:  60%|█████▉    | 147/247 [01:21<00:47,  2.10it/s]Loading train:  60%|█████▉    | 148/247 [01:21<00:47,  2.10it/s]Loading train:  60%|██████    | 149/247 [01:22<00:51,  1.92it/s]Loading train:  61%|██████    | 150/247 [01:23<00:59,  1.62it/s]Loading train:  61%|██████    | 151/247 [01:24<01:04,  1.48it/s]Loading train:  62%|██████▏   | 152/247 [01:25<01:11,  1.33it/s]Loading train:  62%|██████▏   | 153/247 [01:25<01:11,  1.32it/s]Loading train:  62%|██████▏   | 154/247 [01:28<02:05,  1.35s/it]Loading train:  63%|██████▎   | 155/247 [01:31<02:51,  1.87s/it]Loading train:  63%|██████▎   | 156/247 [01:34<03:20,  2.20s/it]Loading train:  64%|██████▎   | 157/247 [01:37<03:42,  2.47s/it]Loading train:  64%|██████▍   | 158/247 [01:40<03:57,  2.66s/it]Loading train:  64%|██████▍   | 159/247 [01:44<04:10,  2.85s/it]Loading train:  65%|██████▍   | 160/247 [01:47<04:15,  2.94s/it]Loading train:  65%|██████▌   | 161/247 [01:50<04:18,  3.01s/it]Loading train:  66%|██████▌   | 162/247 [01:53<04:18,  3.04s/it]Loading train:  66%|██████▌   | 163/247 [01:56<04:14,  3.03s/it]Loading train:  66%|██████▋   | 164/247 [01:59<04:16,  3.09s/it]Loading train:  67%|██████▋   | 165/247 [02:03<04:16,  3.13s/it]Loading train:  67%|██████▋   | 166/247 [02:06<04:20,  3.21s/it]Loading train:  68%|██████▊   | 167/247 [02:09<04:16,  3.20s/it]Loading train:  68%|██████▊   | 168/247 [02:12<04:08,  3.15s/it]Loading train:  68%|██████▊   | 169/247 [02:15<04:07,  3.17s/it]Loading train:  69%|██████▉   | 170/247 [02:18<04:01,  3.14s/it]Loading train:  69%|██████▉   | 171/247 [02:22<04:01,  3.18s/it]Loading train:  70%|██████▉   | 172/247 [02:27<04:51,  3.88s/it]Loading train:  70%|███████   | 173/247 [02:31<04:44,  3.85s/it]Loading train:  70%|███████   | 174/247 [02:35<04:34,  3.76s/it]Loading train:  71%|███████   | 175/247 [02:42<05:46,  4.81s/it]Loading train:  71%|███████▏  | 176/247 [02:45<05:07,  4.34s/it]Loading train:  72%|███████▏  | 177/247 [02:49<05:04,  4.35s/it]Loading train:  72%|███████▏  | 178/247 [02:54<04:58,  4.33s/it]Loading train:  72%|███████▏  | 179/247 [02:58<04:56,  4.36s/it]Loading train:  73%|███████▎  | 180/247 [03:02<04:47,  4.29s/it]Loading train:  73%|███████▎  | 181/247 [03:07<04:43,  4.30s/it]Loading train:  74%|███████▎  | 182/247 [03:11<04:41,  4.33s/it]Loading train:  74%|███████▍  | 183/247 [03:15<04:30,  4.23s/it]Loading train:  74%|███████▍  | 184/247 [03:19<04:31,  4.30s/it]Loading train:  75%|███████▍  | 185/247 [03:24<04:26,  4.29s/it]Loading train:  75%|███████▌  | 186/247 [03:28<04:19,  4.25s/it]Loading train:  76%|███████▌  | 187/247 [03:32<04:15,  4.27s/it]Loading train:  76%|███████▌  | 188/247 [03:36<04:10,  4.25s/it]Loading train:  77%|███████▋  | 189/247 [03:41<04:07,  4.26s/it]Loading train:  77%|███████▋  | 190/247 [03:44<03:47,  3.99s/it]Loading train:  77%|███████▋  | 191/247 [03:48<03:41,  3.95s/it]Loading train:  78%|███████▊  | 192/247 [03:52<03:42,  4.04s/it]Loading train:  78%|███████▊  | 193/247 [03:55<03:23,  3.77s/it]Loading train:  79%|███████▊  | 194/247 [03:57<02:49,  3.20s/it]Loading train:  79%|███████▉  | 195/247 [03:58<02:14,  2.59s/it]Loading train:  79%|███████▉  | 196/247 [03:59<01:49,  2.14s/it]Loading train:  80%|███████▉  | 197/247 [04:00<01:31,  1.83s/it]Loading train:  80%|████████  | 198/247 [04:02<01:20,  1.64s/it]Loading train:  81%|████████  | 199/247 [04:03<01:12,  1.51s/it]Loading train:  81%|████████  | 200/247 [04:04<01:04,  1.38s/it]Loading train:  81%|████████▏ | 201/247 [04:05<01:00,  1.31s/it]Loading train:  82%|████████▏ | 202/247 [04:06<00:55,  1.24s/it]Loading train:  82%|████████▏ | 203/247 [04:07<00:53,  1.22s/it]Loading train:  83%|████████▎ | 204/247 [04:09<00:52,  1.22s/it]Loading train:  83%|████████▎ | 205/247 [04:10<00:49,  1.19s/it]Loading train:  83%|████████▎ | 206/247 [04:11<00:48,  1.18s/it]Loading train:  84%|████████▍ | 207/247 [04:12<00:46,  1.16s/it]Loading train:  84%|████████▍ | 208/247 [04:13<00:45,  1.16s/it]Loading train:  85%|████████▍ | 209/247 [04:14<00:44,  1.18s/it]Loading train:  85%|████████▌ | 210/247 [04:15<00:42,  1.16s/it]Loading train:  85%|████████▌ | 211/247 [04:17<00:41,  1.16s/it]Loading train:  86%|████████▌ | 212/247 [04:18<00:40,  1.15s/it]Loading train:  86%|████████▌ | 213/247 [04:19<00:40,  1.19s/it]Loading train:  87%|████████▋ | 214/247 [04:20<00:38,  1.18s/it]Loading train:  87%|████████▋ | 215/247 [04:21<00:36,  1.15s/it]Loading train:  87%|████████▋ | 216/247 [04:22<00:35,  1.15s/it]Loading train:  88%|████████▊ | 217/247 [04:24<00:34,  1.16s/it]Loading train:  88%|████████▊ | 218/247 [04:25<00:34,  1.19s/it]Loading train:  89%|████████▊ | 219/247 [04:26<00:33,  1.18s/it]Loading train:  89%|████████▉ | 220/247 [04:27<00:32,  1.19s/it]Loading train:  89%|████████▉ | 221/247 [04:28<00:30,  1.16s/it]Loading train:  90%|████████▉ | 222/247 [04:29<00:28,  1.15s/it]Loading train:  90%|█████████ | 223/247 [04:31<00:28,  1.17s/it]Loading train:  91%|█████████ | 224/247 [04:32<00:26,  1.17s/it]Loading train:  91%|█████████ | 225/247 [04:33<00:25,  1.14s/it]Loading train:  91%|█████████▏| 226/247 [04:34<00:24,  1.16s/it]Loading train:  92%|█████████▏| 227/247 [04:35<00:22,  1.14s/it]Loading train:  92%|█████████▏| 228/247 [04:36<00:22,  1.17s/it]Loading train:  93%|█████████▎| 229/247 [04:38<00:20,  1.15s/it]Loading train:  93%|█████████▎| 230/247 [04:43<00:40,  2.36s/it]Loading train:  94%|█████████▎| 231/247 [04:48<00:53,  3.33s/it]Loading train:  94%|█████████▍| 232/247 [04:54<01:00,  4.05s/it]Loading train:  94%|█████████▍| 233/247 [04:57<00:51,  3.68s/it]Loading train:  95%|█████████▍| 234/247 [05:02<00:55,  4.25s/it]Loading train:  95%|█████████▌| 235/247 [05:08<00:53,  4.49s/it]Loading train:  96%|█████████▌| 236/247 [05:12<00:49,  4.47s/it]Loading train:  96%|█████████▌| 237/247 [05:17<00:46,  4.67s/it]Loading train:  96%|█████████▋| 238/247 [05:23<00:45,  5.00s/it]Loading train:  97%|█████████▋| 239/247 [05:29<00:41,  5.24s/it]Loading train:  97%|█████████▋| 240/247 [05:34<00:36,  5.28s/it]Loading train:  98%|█████████▊| 241/247 [05:39<00:31,  5.28s/it]Loading train:  98%|█████████▊| 242/247 [05:45<00:26,  5.29s/it]Loading train:  98%|█████████▊| 243/247 [05:50<00:21,  5.35s/it]Loading train:  99%|█████████▉| 244/247 [05:56<00:16,  5.45s/it]Loading train:  99%|█████████▉| 245/247 [06:01<00:10,  5.46s/it]Loading train: 100%|█████████▉| 246/247 [06:07<00:05,  5.60s/it]Loading train: 100%|██████████| 247/247 [06:12<00:00,  5.32s/it]Loading train: 100%|██████████| 247/247 [06:12<00:00,  1.51s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 53.48it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 53.50it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 53.29it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:04, 53.33it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 53.06it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:04, 52.28it/s]concatenating: train:  17%|█▋        | 42/247 [00:00<00:03, 52.41it/s]concatenating: train:  19%|█▉        | 47/247 [00:00<00:03, 51.47it/s]concatenating: train:  21%|██▏       | 53/247 [00:01<00:03, 51.10it/s]concatenating: train:  24%|██▍       | 59/247 [00:01<00:03, 50.88it/s]concatenating: train:  26%|██▌       | 64/247 [00:01<00:03, 48.66it/s]concatenating: train:  28%|██▊       | 69/247 [00:01<00:03, 48.54it/s]concatenating: train:  30%|██▉       | 74/247 [00:01<00:03, 48.01it/s]concatenating: train:  32%|███▏      | 79/247 [00:01<00:03, 46.70it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:03, 45.34it/s]concatenating: train:  36%|███▌      | 89/247 [00:01<00:03, 43.97it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:03, 43.35it/s]concatenating: train:  40%|████      | 99/247 [00:02<00:03, 42.74it/s]concatenating: train:  42%|████▏     | 104/247 [00:02<00:03, 42.88it/s]concatenating: train:  44%|████▍     | 109/247 [00:02<00:03, 42.24it/s]concatenating: train:  46%|████▌     | 114/247 [00:02<00:03, 41.93it/s]concatenating: train:  48%|████▊     | 119/247 [00:02<00:03, 42.49it/s]concatenating: train:  50%|█████     | 124/247 [00:02<00:02, 43.70it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 44.43it/s]concatenating: train:  54%|█████▍    | 134/247 [00:02<00:02, 45.17it/s]concatenating: train:  56%|█████▋    | 139/247 [00:02<00:02, 46.30it/s]concatenating: train:  58%|█████▊    | 144/247 [00:03<00:02, 47.04it/s]concatenating: train:  61%|██████    | 150/247 [00:03<00:02, 47.91it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 47.86it/s]concatenating: train:  65%|██████▍   | 160/247 [00:03<00:01, 47.34it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 47.01it/s]concatenating: train:  69%|██████▉   | 170/247 [00:03<00:01, 46.50it/s]concatenating: train:  71%|███████   | 175/247 [00:03<00:01, 46.49it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 45.29it/s]concatenating: train:  75%|███████▍  | 185/247 [00:03<00:01, 44.08it/s]concatenating: train:  77%|███████▋  | 190/247 [00:04<00:01, 43.42it/s]concatenating: train:  79%|███████▉  | 195/247 [00:04<00:01, 43.27it/s]concatenating: train:  81%|████████  | 200/247 [00:04<00:01, 44.86it/s]concatenating: train:  83%|████████▎ | 205/247 [00:04<00:00, 45.60it/s]concatenating: train:  85%|████████▌ | 210/247 [00:04<00:00, 46.35it/s]concatenating: train:  87%|████████▋ | 215/247 [00:04<00:00, 46.56it/s]concatenating: train:  89%|████████▉ | 220/247 [00:04<00:00, 47.42it/s]concatenating: train:  91%|█████████ | 225/247 [00:04<00:00, 47.83it/s]concatenating: train:  93%|█████████▎| 230/247 [00:04<00:00, 48.11it/s]concatenating: train:  95%|█████████▌| 235/247 [00:05<00:00, 47.19it/s]concatenating: train:  97%|█████████▋| 240/247 [00:05<00:00, 46.35it/s]concatenating: train:  99%|█████████▉| 245/247 [00:05<00:00, 45.68it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 46.69it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:11<00:46, 11.57s/it]Loading test:  40%|████      | 2/5 [00:24<00:35, 12.00s/it]Loading test:  60%|██████    | 3/5 [00:30<00:20, 10.22s/it]Loading test:  80%|████████  | 4/5 [00:34<00:08,  8.28s/it]Loading test: 100%|██████████| 5/5 [00:43<00:00,  8.59s/it]Loading test: 100%|██████████| 5/5 [00:43<00:00,  8.74s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 58.51it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      2020-01-22 04:27:17.939787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 04:27:17.939870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 04:27:17.939883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 04:27:17.939891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 04:27:17.940234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

loading the weights from thalamus:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights from thalamus:   2%|▏         | 1/44 [00:00<00:12,  3.57it/s]loading the weights from thalamus:   7%|▋         | 3/44 [00:00<00:09,  4.45it/s]loading the weights from thalamus:   9%|▉         | 4/44 [00:00<00:08,  4.59it/s]loading the weights from thalamus:  18%|█▊        | 8/44 [00:00<00:05,  6.02it/s]loading the weights from thalamus:  20%|██        | 9/44 [00:01<00:06,  5.76it/s]loading the weights from thalamus:  25%|██▌       | 11/44 [00:01<00:04,  6.73it/s]loading the weights from thalamus:  27%|██▋       | 12/44 [00:01<00:05,  6.20it/s]loading the weights from thalamus:  39%|███▊      | 17/44 [00:01<00:03,  8.08it/s]loading the weights from thalamus:  43%|████▎     | 19/44 [00:01<00:03,  8.17it/s]loading the weights from thalamus:  48%|████▊     | 21/44 [00:02<00:03,  6.51it/s]loading the weights from thalamus:  57%|█████▋    | 25/44 [00:02<00:02,  8.09it/s]loading the weights from thalamus:  61%|██████▏   | 27/44 [00:02<00:01,  8.54it/s]loading the weights from thalamus:  66%|██████▌   | 29/44 [00:02<00:01,  8.73it/s]loading the weights from thalamus:  70%|███████   | 31/44 [00:03<00:01,  6.85it/s]loading the weights from thalamus:  80%|███████▉  | 35/44 [00:03<00:01,  7.82it/s]loading the weights from thalamus:  84%|████████▍ | 37/44 [00:03<00:00,  8.00it/s]loading the weights from thalamus:  86%|████████▋ | 38/44 [00:04<00:00,  6.28it/s]loading the weights from thalamus:  91%|█████████ | 40/44 [00:04<00:00,  6.80it/s]loading the weights from thalamus:  93%|█████████▎| 41/44 [00:04<00:00,  5.84it/s]loading the weights from thalamus: 100%|██████████| 44/44 [00:04<00:00,  9.47it/s]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Thalamus /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [6.52385152e-02 3.19420474e-02 7.70779721e-02 9.60982534e-03
 2.75137344e-02 7.04670703e-03 8.85601333e-02 1.14423869e-01
 8.19908760e-02 1.27582517e-02 2.89595360e-01 1.93996847e-01
 2.45862188e-04]
Train on 9115 samples, validate on 182 samples
Epoch 1/300
 - 23s - loss: 0.7752 - acc: 0.7964 - mDice: 0.1669 - val_loss: 0.7202 - val_acc: 0.9258 - val_mDice: 0.2205

Epoch 00001: val_mDice improved from -inf to 0.22045, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 0.5899 - acc: 0.9120 - mDice: 0.3640 - val_loss: 0.6540 - val_acc: 0.9144 - val_mDice: 0.2783

Epoch 00002: val_mDice improved from 0.22045 to 0.27828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 19s - loss: 0.5138 - acc: 0.9190 - mDice: 0.4465 - val_loss: 0.6355 - val_acc: 0.9218 - val_mDice: 0.2835

Epoch 00003: val_mDice improved from 0.27828 to 0.28350, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 0.4682 - acc: 0.9236 - mDice: 0.4957 - val_loss: 0.5271 - val_acc: 0.9382 - val_mDice: 0.3109

Epoch 00004: val_mDice improved from 0.28350 to 0.31087, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 20s - loss: 0.4405 - acc: 0.9267 - mDice: 0.5257 - val_loss: 0.4646 - val_acc: 0.9287 - val_mDice: 0.2109

Epoch 00005: val_mDice did not improve from 0.31087
Epoch 6/300
 - 20s - loss: 0.4244 - acc: 0.9292 - mDice: 0.5431 - val_loss: 0.3555 - val_acc: 0.9301 - val_mDice: 0.2256

Epoch 00006: val_mDice did not improve from 0.31087
Epoch 7/300
 - 20s - loss: 0.4101 - acc: 0.9309 - mDice: 0.5585 - val_loss: 0.3943 - val_acc: 0.9411 - val_mDice: 0.3216

Epoch 00007: val_mDice improved from 0.31087 to 0.32157, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 20s - loss: 0.4002 - acc: 0.9324 - mDice: 0.5693 - val_loss: 0.2721 - val_acc: 0.9364 - val_mDice: 0.2518

Epoch 00008: val_mDice did not improve from 0.32157
Epoch 9/300
 - 20s - loss: 0.3925 - acc: 0.9339 - mDice: 0.5775 - val_loss: 0.2666 - val_acc: 0.9468 - val_mDice: 0.3252

Epoch 00009: val_mDice improved from 0.32157 to 0.32515, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 20s - loss: 0.3856 - acc: 0.9351 - mDice: 0.5850 - val_loss: 0.3597 - val_acc: 0.9430 - val_mDice: 0.3230

Epoch 00010: val_mDice did not improve from 0.32515
Epoch 11/300
 - 20s - loss: 0.3790 - acc: 0.9358 - mDice: 0.5921 - val_loss: 0.2187 - val_acc: 0.9480 - val_mDice: 0.3295

Epoch 00011: val_mDice improved from 0.32515 to 0.32947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 0.3750 - acc: 0.9370 - mDice: 0.5965 - val_loss: 0.2073 - val_acc: 0.9279 - val_mDice: 0.1949

Epoch 00012: val_mDice did not improve from 0.32947
Epoch 13/300
 - 20s - loss: 0.3645 - acc: 0.9378 - mDice: 0.6077 - val_loss: 0.2331 - val_acc: 0.9483 - val_mDice: 0.3340

Epoch 00013: val_mDice improved from 0.32947 to 0.33403, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 20s - loss: 0.3619 - acc: 0.9383 - mDice: 0.6106 - val_loss: 0.1760 - val_acc: 0.9438 - val_mDice: 0.2902

Epoch 00014: val_mDice did not improve from 0.33403
Epoch 15/300
 - 20s - loss: 0.3581 - acc: 0.9386 - mDice: 0.6147 - val_loss: 0.1883 - val_acc: 0.9399 - val_mDice: 0.2713

Epoch 00015: val_mDice did not improve from 0.33403
Epoch 16/300
 - 21s - loss: 0.3543 - acc: 0.9393 - mDice: 0.6187 - val_loss: 0.1541 - val_acc: 0.9480 - val_mDice: 0.3232

Epoch 00016: val_mDice did not improve from 0.33403
Epoch 17/300
 - 20s - loss: 0.3548 - acc: 0.9396 - mDice: 0.6183 - val_loss: 0.2355 - val_acc: 0.9442 - val_mDice: 0.3059

Epoch 00017: val_mDice did not improve from 0.33403
Epoch 18/300
 - 21s - loss: 0.3493 - acc: 0.9402 - mDice: 0.6242 - val_loss: 0.2262 - val_acc: 0.9483 - val_mDice: 0.3301

Epoch 00018: val_mDice did not improve from 0.33403
Epoch 19/300
 - 21s - loss: 0.3458 - acc: 0.9406 - mDice: 0.6279 - val_loss: 0.3376 - val_acc: 0.9438 - val_mDice: 0.3205

Epoch 00019: val_mDice did not improve from 0.33403
Epoch 20/300
 - 21s - loss: 0.3414 - acc: 0.9412 - mDice: 0.6327 - val_loss: 0.3624 - val_acc: 0.9423 - val_mDice: 0.3321

Epoch 00020: val_mDice did not improve from 0.33403
Epoch 21/300
 - 21s - loss: 0.3401 - acc: 0.9415 - mDice: 0.6341 - val_loss: 0.2100 - val_acc: 0.9490 - val_mDice: 0.3257

Epoch 00021: val_mDice did not improve from 0.33403
Epoch 22/300
 - 21s - loss: 0.3365 - acc: 0.9417 - mDice: 0.6380 - val_loss: 0.2494 - val_acc: 0.9474 - val_mDice: 0.3393

Epoch 00022: val_mDice improved from 0.33403 to 0.33932, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 20s - loss: 0.3355 - acc: 0.9423 - mDice: 0.6390 - val_loss: 0.1708 - val_acc: 0.9507 - val_mDice: 0.3380

Epoch 00023: val_mDice did not improve from 0.33932
Epoch 24/300
 - 20s - loss: 0.3344 - acc: 0.9424 - mDice: 0.6402 - val_loss: 0.2356 - val_acc: 0.9221 - val_mDice: 0.1652

Epoch 00024: val_mDice did not improve from 0.33932
Epoch 25/300
 - 21s - loss: 0.3323 - acc: 0.9426 - mDice: 0.6425 - val_loss: 0.3047 - val_acc: 0.9420 - val_mDice: 0.3035

Epoch 00025: val_mDice did not improve from 0.33932
Epoch 26/300
 - 22s - loss: 0.3343 - acc: 0.9432 - mDice: 0.6403 - val_loss: 0.3190 - val_acc: 0.9462 - val_mDice: 0.3343

Epoch 00026: val_mDice did not improve from 0.33932
Epoch 27/300
 - 21s - loss: 0.3285 - acc: 0.9433 - mDice: 0.6466 - val_loss: 0.1963 - val_acc: 0.9474 - val_mDice: 0.3199

Epoch 00027: val_mDice did not improve from 0.33932
Epoch 28/300
 - 22s - loss: 0.3249 - acc: 0.9435 - mDice: 0.6505 - val_loss: 0.1735 - val_acc: 0.9479 - val_mDice: 0.3398

Epoch 00028: val_mDice improved from 0.33932 to 0.33984, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 21s - loss: 0.3263 - acc: 0.9438 - mDice: 0.6489 - val_loss: 0.1583 - val_acc: 0.9507 - val_mDice: 0.3299

Epoch 00029: val_mDice did not improve from 0.33984
Epoch 30/300
 - 22s - loss: 0.3203 - acc: 0.9441 - mDice: 0.6555 - val_loss: 0.1171 - val_acc: 0.9472 - val_mDice: 0.3040

Epoch 00030: val_mDice did not improve from 0.33984
Epoch 31/300
 - 21s - loss: 0.3187 - acc: 0.9444 - mDice: 0.6572 - val_loss: 0.1786 - val_acc: 0.9511 - val_mDice: 0.3379

Epoch 00031: val_mDice did not improve from 0.33984
Epoch 32/300
 - 20s - loss: 0.3212 - acc: 0.9445 - mDice: 0.6545 - val_loss: 0.1971 - val_acc: 0.9418 - val_mDice: 0.2707

Epoch 00032: val_mDice did not improve from 0.33984
Epoch 33/300
 - 20s - loss: 0.3200 - acc: 0.9444 - mDice: 0.6557 - val_loss: 0.3033 - val_acc: 0.9421 - val_mDice: 0.3322

Epoch 00033: val_mDice did not improve from 0.33984
Epoch 34/300
 - 19s - loss: 0.3180 - acc: 0.9449 - mDice: 0.6579 - val_loss: 0.1416 - val_acc: 0.9497 - val_mDice: 0.3218

Epoch 00034: val_mDice did not improve from 0.33984
Epoch 35/300
 - 20s - loss: 0.3177 - acc: 0.9451 - mDice: 0.6582 - val_loss: 0.1768 - val_acc: 0.9509 - val_mDice: 0.3398

Epoch 00035: val_mDice did not improve from 0.33984
Epoch 36/300
 - 20s - loss: 0.3147 - acc: 0.9454 - mDice: 0.6614 - val_loss: 0.1346 - val_acc: 0.9459 - val_mDice: 0.2964

Epoch 00036: val_mDice did not improve from 0.33984
Epoch 37/300
 - 20s - loss: 0.3133 - acc: 0.9454 - mDice: 0.6629 - val_loss: 0.1160 - val_acc: 0.9501 - val_mDice: 0.3188

Epoch 00037: val_mDice did not improve from 0.33984

Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 38/300
 - 20s - loss: 0.3070 - acc: 0.9462 - mDice: 0.6697 - val_loss: 0.0981 - val_acc: 0.9515 - val_mDice: 0.3383

Epoch 00038: val_mDice did not improve from 0.33984
Epoch 39/300
 - 20s - loss: 0.3017 - acc: 0.9465 - mDice: 0.6755 - val_loss: 0.1068 - val_acc: 0.9500 - val_mDice: 0.3184

Epoch 00039: val_mDice did not improve from 0.33984
Epoch 40/300
 - 20s - loss: 0.3038 - acc: 0.9464 - mDice: 0.6732 - val_loss: 0.1570 - val_acc: 0.9504 - val_mDice: 0.3356

Epoch 00040: val_mDice did not improve from 0.33984
Epoch 41/300
 - 20s - loss: 0.3038 - acc: 0.9465 - mDice: 0.6732 - val_loss: 0.0767 - val_acc: 0.9518 - val_mDice: 0.3400

Epoch 00041: val_mDice improved from 0.33984 to 0.34000, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 42/300
 - 20s - loss: 0.3037 - acc: 0.9467 - mDice: 0.6733 - val_loss: 0.1536 - val_acc: 0.9519 - val_mDice: 0.3438

Epoch 00042: val_mDice improved from 0.34000 to 0.34383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 43/300
 - 20s - loss: 0.3009 - acc: 0.9468 - mDice: 0.6763 - val_loss: 0.3153 - val_acc: 0.9441 - val_mDice: 0.3309

Epoch 00043: val_mDice did not improve from 0.34383
Epoch 44/300
 - 20s - loss: 0.3023 - acc: 0.9468 - mDice: 0.6748 - val_loss: 0.2224 - val_acc: 0.9510 - val_mDice: 0.3504

Epoch 00044: val_mDice improved from 0.34383 to 0.35042, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 20s - loss: 0.3001 - acc: 0.9471 - mDice: 0.6772 - val_loss: 0.1672 - val_acc: 0.9516 - val_mDice: 0.3423

Epoch 00045: val_mDice did not improve from 0.35042
Epoch 46/300
 - 20s - loss: 0.3001 - acc: 0.9470 - mDice: 0.6772 - val_loss: 0.1896 - val_acc: 0.9503 - val_mDice: 0.3325

Epoch 00046: val_mDice did not improve from 0.35042
Epoch 47/300
 - 20s - loss: 0.2997 - acc: 0.9472 - mDice: 0.6776 - val_loss: 0.1422 - val_acc: 0.9511 - val_mDice: 0.3323

Epoch 00047: val_mDice did not improve from 0.35042
Epoch 48/300
 - 21s - loss: 0.2998 - acc: 0.9473 - mDice: 0.6775 - val_loss: 0.1973 - val_acc: 0.9509 - val_mDice: 0.3407

Epoch 00048: val_mDice did not improve from 0.35042
Epoch 49/300
 - 20s - loss: 0.2989 - acc: 0.9473 - mDice: 0.6784 - val_loss: 0.2324 - val_acc: 0.9497 - val_mDice: 0.3399

Epoch 00049: val_mDice did not improve from 0.35042
Epoch 50/300
 - 20s - loss: 0.2986 - acc: 0.9474 - mDice: 0.6788 - val_loss: 0.2056 - val_acc: 0.9499 - val_mDice: 0.3386

Epoch 00050: val_mDice did not improve from 0.35042
Epoch 51/300
 - 20s - loss: 0.2987 - acc: 0.9474 - mDice: 0.6787 - val_loss: 0.1261 - val_acc: 0.9524 - val_mDice: 0.3398

Epoch 00051: val_mDice did not improve from 0.35042
Epoch 52/300
 - 20s - loss: 0.2987 - acc: 0.9475 - mDice: 0.6786 - val_loss: 0.1733 - val_acc: 0.9517 - val_mDice: 0.3406

Epoch 00052: val_mDice did not improve from 0.35042
Epoch 53/300
 - 20s - loss: 0.2965 - acc: 0.9476 - mDice: 0.6811 - val_loss: 0.1503 - val_acc: 0.9499 - val_mDice: 0.3280

Epoch 00053: val_mDice did not improve from 0.35042
Epoch 54/300
 - 20s - loss: 0.2955 - acc: 0.9477 - mDice: 0.6822 - val_loss: 0.1707 - val_acc: 0.9509 - val_mDice: 0.3424

Epoch 00054: val_mDice did not improve from 0.35042
Epoch 55/300
 - 20s - loss: 0.2935 - acc: 0.9478 - mDice: 0.6843 - val_loss: 0.3037 - val_acc: 0.9482 - val_mDice: 0.3439

Epoch 00055: val_mDice did not improve from 0.35042
Epoch 56/300
 - 19s - loss: 0.2944 - acc: 0.9479 - mDice: 0.6833 - val_loss: 0.1400 - val_acc: 0.9499 - val_mDice: 0.3335

Epoch 00056: val_mDice did not improve from 0.35042
Epoch 57/300
 - 20s - loss: 0.2940 - acc: 0.9478 - mDice: 0.6837 - val_loss: 0.1658 - val_acc: 0.9508 - val_mDice: 0.3425

Epoch 00057: val_mDice did not improve from 0.35042
Epoch 58/300
 - 20s - loss: 0.2977 - acc: 0.9479 - mDice: 0.6798 - val_loss: 0.1637 - val_acc: 0.9495 - val_mDice: 0.3356

Epoch 00058: val_mDice did not improve from 0.35042
Epoch 59/300
 - 19s - loss: 0.2905 - acc: 0.9480 - mDice: 0.6875 - val_loss: 0.1954 - val_acc: 0.9477 - val_mDice: 0.3135

Epoch 00059: val_mDice did not improve from 0.35042

Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 60/300
 - 19s - loss: 0.2889 - acc: 0.9483 - mDice: 0.6893 - val_loss: 0.1818 - val_acc: 0.9518 - val_mDice: 0.3459

Epoch 00060: val_mDice did not improve from 0.35042
Epoch 61/300
 - 20s - loss: 0.2885 - acc: 0.9485 - mDice: 0.6897 - val_loss: 0.1850 - val_acc: 0.9509 - val_mDice: 0.3473

Epoch 00061: val_mDice did not improve from 0.35042
Epoch 62/300
 - 20s - loss: 0.2897 - acc: 0.9483 - mDice: 0.6884 - val_loss: 0.2315 - val_acc: 0.9499 - val_mDice: 0.3454

Epoch 00062: val_mDice did not improve from 0.35042
Epoch 63/300
 - 19s - loss: 0.2884 - acc: 0.9485 - mDice: 0.6898 - val_loss: 0.1503 - val_acc: 0.9509 - val_mDice: 0.3317

Epoch 00063: val_mDice did not improve from 0.35042
Epoch 64/300
 - 19s - loss: 0.2903 - acc: 0.9486 - mDice: 0.6878 - val_loss: 0.2073 - val_acc: 0.9512 - val_mDice: 0.3472

Epoch 00064: val_mDice did not improve from 0.35042
Epoch 65/300
 - 20s - loss: 0.2863 - acc: 0.9485 - mDice: 0.6921 - val_loss: 0.1266 - val_acc: 0.9519 - val_mDice: 0.3381

Epoch 00065: val_mDice did not improve from 0.35042
Epoch 66/300
 - 20s - loss: 0.2872 - acc: 0.9485 - mDice: 0.6911 - val_loss: 0.1194 - val_acc: 0.9515 - val_mDice: 0.3393

Epoch 00066: val_mDice did not improve from 0.35042
Epoch 67/300
 - 20s - loss: 0.2860 - acc: 0.9487 - mDice: 0.6924 - val_loss: 0.1125 - val_acc: 0.9513 - val_mDice: 0.3332

Epoch 00067: val_mDice did not improve from 0.35042
Epoch 68/300
 - 20s - loss: 0.2868 - acc: 0.9487 - mDice: 0.6916 - val_loss: 0.1356 - val_acc: 0.9510 - val_mDice: 0.3391

Epoch 00068: val_mDice did not improve from 0.35042
Epoch 69/300
 - 20s - loss: 0.2843 - acc: 0.9488 - mDice: 0.6943 - val_loss: 0.1009 - val_acc: 0.9512 - val_mDice: 0.3321

Epoch 00069: val_mDice did not improve from 0.35042
Epoch 70/300
 - 20s - loss: 0.2862 - acc: 0.9488 - mDice: 0.6922 - val_loss: 0.1228 - val_acc: 0.9497 - val_mDice: 0.3181

Epoch 00070: val_mDice did not improve from 0.35042
Epoch 71/300
 - 20s - loss: 0.2819 - acc: 0.9489 - mDice: 0.6969 - val_loss: 0.1087 - val_acc: 0.9519 - val_mDice: 0.3424

Epoch 00071: val_mDice did not improve from 0.35042
Epoch 72/300
 - 20s - loss: 0.2830 - acc: 0.9489 - mDice: 0.6956 - val_loss: 0.2726 - val_acc: 0.9490 - val_mDice: 0.3432

Epoch 00072: val_mDice did not improve from 0.35042
Epoch 73/300
 - 20s - loss: 0.2870 - acc: 0.9488 - mDice: 0.6913 - val_loss: 0.1242 - val_acc: 0.9509 - val_mDice: 0.3398

Epoch 00073: val_mDice did not improve from 0.35042
Epoch 74/300
 - 20s - loss: 0.2837 - acc: 0.9489 - mDice: 0.6949 - val_loss: 0.1425 - val_acc: 0.9512 - val_mDice: 0.3310

Epoch 00074: val_mDice did not improve from 0.35042

Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 75/300
 - 20s - loss: 0.2822 - acc: 0.9491 - mDice: 0.6965 - val_loss: 0.1448 - val_acc: 0.9513 - val_mDice: 0.3311

Epoch 00075: val_mDice did not improve from 0.35042
Epoch 76/300
 - 20s - loss: 0.2841 - acc: 0.9491 - mDice: 0.6944 - val_loss: 0.1441 - val_acc: 0.9516 - val_mDice: 0.3405

Epoch 00076: val_mDice did not improve from 0.35042
Epoch 77/300
 - 21s - loss: 0.2831 - acc: 0.9491 - mDice: 0.6955 - val_loss: 0.1844 - val_acc: 0.9515 - val_mDice: 0.3459

Epoch 00077: val_mDice did not improve from 0.35042
Epoch 78/300
 - 20s - loss: 0.2835 - acc: 0.9493 - mDice: 0.6951 - val_loss: 0.1573 - val_acc: 0.9511 - val_mDice: 0.3324

Epoch 00078: val_mDice did not improve from 0.35042
Epoch 79/300
 - 20s - loss: 0.2837 - acc: 0.9492 - mDice: 0.6949 - val_loss: 0.1598 - val_acc: 0.9513 - val_mDice: 0.3400

Epoch 00079: val_mDice did not improve from 0.35042
Epoch 80/300
 - 20s - loss: 0.2809 - acc: 0.9492 - mDice: 0.6979 - val_loss: 0.1830 - val_acc: 0.9512 - val_mDice: 0.3462

Epoch 00080: val_mDice did not improve from 0.35042
Epoch 81/300
 - 20s - loss: 0.2834 - acc: 0.9493 - mDice: 0.6952 - val_loss: 0.1594 - val_acc: 0.9521 - val_mDice: 0.3409

Epoch 00081: val_mDice did not improve from 0.35042
Epoch 82/300
 - 20s - loss: 0.2839 - acc: 0.9494 - mDice: 0.6946 - val_loss: 0.1912 - val_acc: 0.9516 - val_mDice: 0.3460

Epoch 00082: val_mDice did not improve from 0.35042
Epoch 83/300
 - 19s - loss: 0.2829 - acc: 0.9492 - mDice: 0.6957 - val_loss: 0.1552 - val_acc: 0.9516 - val_mDice: 0.3386

Epoch 00083: val_mDice did not improve from 0.35042
Epoch 84/300
 - 20s - loss: 0.2806 - acc: 0.9493 - mDice: 0.6982 - val_loss: 0.1118 - val_acc: 0.9516 - val_mDice: 0.3425

Epoch 00084: val_mDice did not improve from 0.35042
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
{'val_loss': [0.7202359110444456, 0.6539561709204873, 0.6354562551765651, 0.5271275076237354, 0.4646257572694794, 0.3555020041518159, 0.39428155271561593, 0.27209719495622664, 0.26664936591635696, 0.35969110414549543, 0.218657525317682, 0.20731267338147857, 0.23306177368203362, 0.1760290906570115, 0.18834238151436325, 0.15414905001583334, 0.2354912966653541, 0.2262473108814927, 0.33756285066624264, 0.3624008362191719, 0.20999800708595212, 0.24936686837943373, 0.17076864273666026, 0.23561207327868913, 0.30474850967280814, 0.3190406364808371, 0.19633621853459013, 0.17346858642585986, 0.1582837334864742, 0.11708332426272906, 0.17860585966935524, 0.19706837489054754, 0.3032644864294555, 0.14157014172319526, 0.17683395794541626, 0.13460918212984943, 0.11601882176166707, 0.09806180270491066, 0.10675678430841519, 0.15701693054902685, 0.0767216743021221, 0.1535872416877812, 0.31527832146365564, 0.22237016158280792, 0.16723182768775866, 0.18955916272742407, 0.14220961285652695, 0.19734932228431598, 0.23243969175350535, 0.20557609998754092, 0.12610460580377789, 0.17333115563615337, 0.15030275399868304, 0.1707215191243769, 0.3037323743849481, 0.14000282717029472, 0.16584033091235292, 0.1637399373473702, 0.19536171313170547, 0.1817643301827567, 0.18501790461468173, 0.23147610462383256, 0.1503210232726165, 0.2072709002173864, 0.12663835315750196, 0.11944925177146445, 0.11248586011620668, 0.13563256989141087, 0.10092872553146802, 0.12279814154237181, 0.10868194068853672, 0.2726216242894285, 0.1242406276760848, 0.14252234287150614, 0.1448135088597025, 0.14412788498205142, 0.18435307303545895, 0.15729176564203515, 0.15983863612943952, 0.18295900509334528, 0.15941283991048624, 0.19115674025046506, 0.15522938557378538, 0.11182717938017059], 'val_acc': [0.9258090801291413, 0.9144175491490207, 0.921849209528703, 0.9381968772018349, 0.9286984742342771, 0.9301022913429763, 0.9410749562494047, 0.9364056233521346, 0.9467895843170502, 0.9429668338744195, 0.9480361630628397, 0.9278971913096669, 0.9483405757736374, 0.9438322638417338, 0.9398572988562531, 0.947979564850147, 0.9441882542201451, 0.9483154271985148, 0.9437844622266162, 0.9422988839201875, 0.9489556924327389, 0.9473506146734887, 0.9507205204649286, 0.922076892721784, 0.9419743444893386, 0.946165667785393, 0.9473556352185679, 0.9478588097698086, 0.9506827894147936, 0.9472021761831346, 0.9510526133107615, 0.9417617622312608, 0.9420888194671044, 0.9496903098546542, 0.9509394005104735, 0.9458939721296121, 0.9501368534433973, 0.95146142912435, 0.9500475447256487, 0.9504312086891342, 0.9518274736928416, 0.9518677297529283, 0.9440863649923723, 0.9509934841931521, 0.9515607985821399, 0.9503280566288874, 0.951123045041011, 0.9508727251828372, 0.9497418809723068, 0.9498626393276256, 0.9523885040492802, 0.9517431953451135, 0.9498701848826565, 0.9508664372203114, 0.9482248523733118, 0.9498626458775866, 0.9508060695050837, 0.9495116891441765, 0.9477103680044741, 0.9517947762877077, 0.9508626611678155, 0.9498638936451503, 0.9509004053178725, 0.9512035538862039, 0.9518903696930016, 0.9515494802495935, 0.9512777780438517, 0.9509708435980828, 0.9511947572886289, 0.9496601145346086, 0.951931880070613, 0.9489846334352599, 0.9509217876654404, 0.9512350035237742, 0.9512777813188322, 0.9516148947097443, 0.9514626867168552, 0.9511331156059936, 0.9512865779164074, 0.9512287155612484, 0.9520828271960164, 0.9516274673598153, 0.9515670832696852, 0.9516337553223411], 'val_mDice': [0.22045386564287173, 0.2782823701157135, 0.28350333959541096, 0.31086578064571213, 0.2108776868208424, 0.22561184980057097, 0.32156597249783003, 0.25175823737959285, 0.32515261199448137, 0.3229899041272782, 0.3294668927952483, 0.1948690945589608, 0.3340316793093315, 0.2902426462170187, 0.2712918850746784, 0.32318513656219283, 0.305932974749869, 0.33010621401634843, 0.32050349944076695, 0.3320927119680821, 0.32565954335770764, 0.33932263379568584, 0.33797143006717767, 0.1651825281985841, 0.30347175159297146, 0.33430619881703305, 0.3199320135044528, 0.33984351593702056, 0.3299176602900683, 0.3039722848724533, 0.33792908047581766, 0.27070923165960625, 0.332191403224747, 0.3218168617932351, 0.3397626806418974, 0.29640781805737987, 0.31877898089178314, 0.33834815885011965, 0.318385905453137, 0.33561167194620595, 0.33999701409222005, 0.3438268389020647, 0.3309435651197538, 0.35041786378229056, 0.3422903650245824, 0.3325244669730847, 0.3323461287296735, 0.3407133554855546, 0.3398514182849245, 0.33862654815663346, 0.33981512576996625, 0.3405948056951984, 0.3279943326181108, 0.34242767144690506, 0.34392380901048814, 0.33352546107310516, 0.3424647041074522, 0.33560532053093334, 0.3134686684051713, 0.3459108358883596, 0.34732643719557876, 0.34538036109981957, 0.33174363466409534, 0.34720160230830477, 0.33807114012293765, 0.33927192645413534, 0.33317710344608015, 0.33905102492688777, 0.33213331476672664, 0.31806378328538204, 0.3423547650595288, 0.3432007739832113, 0.33975491566317423, 0.33101719609656177, 0.3310683271387121, 0.34053574879090864, 0.3459401547417536, 0.3324138364949069, 0.3400032680768233, 0.3462035687906401, 0.34092134908660426, 0.3459994429415399, 0.3386188286182645, 0.3425163521871462], 'loss': [0.7752086924970378, 0.58993345096879, 0.5137515127233797, 0.46818364774925786, 0.44052741233948095, 0.42442384815059125, 0.410138011240266, 0.4001522916264411, 0.392526168697036, 0.3856103765526383, 0.3790471078403952, 0.3749646423154654, 0.36454270605980793, 0.36189105833747265, 0.35806663266525646, 0.354345739934056, 0.35477302588412085, 0.34930386320287815, 0.34579835311436613, 0.3414316922017525, 0.34008500123834845, 0.3365190077043796, 0.3354950052692677, 0.33438406579780894, 0.3323094360264722, 0.33426133546931236, 0.32847501524712314, 0.3248858148588692, 0.3263301196591382, 0.3202884263607806, 0.3186613893155795, 0.32116742259646536, 0.32003972571888795, 0.3180013778637349, 0.31769608803914917, 0.31474145081300886, 0.31332632263348903, 0.3070364627318924, 0.3016931717041359, 0.30380888302052866, 0.30384750889018547, 0.3036777917265042, 0.30091659030741674, 0.30234991266579664, 0.30009077442784393, 0.30012689384535257, 0.29970591405362657, 0.2998341060541386, 0.2989402677060743, 0.29856256002001363, 0.29868556066194996, 0.2987357466938858, 0.29645098852902013, 0.29547656476661127, 0.29346393193442677, 0.294448348776822, 0.29404264021495247, 0.29765972519600975, 0.2905126014582351, 0.2888761410592875, 0.28851805103394074, 0.2897365413487644, 0.2884439746151896, 0.2902725660009693, 0.2862812711260048, 0.2872422172254216, 0.285989690173542, 0.2867618719922012, 0.28426740922185006, 0.28618286779733787, 0.2818694671986852, 0.2829991269098555, 0.28697619749436454, 0.2836937684314433, 0.282193603387457, 0.2841135218486116, 0.2831037325873456, 0.28345588660475585, 0.28368686990494657, 0.2809253896060908, 0.2834091394796387, 0.2839089687780829, 0.2829188838707374, 0.28057913345683755], 'acc': [0.7964468817029903, 0.9120248190596806, 0.918959259071392, 0.9235890997482797, 0.9267458549189292, 0.9291940192501426, 0.930902700043614, 0.9324398852610941, 0.9339141793389668, 0.9350539453724094, 0.9358147760373972, 0.9369748620887542, 0.9378386967403184, 0.9383195535664498, 0.9385795126037159, 0.9392675805144172, 0.9395901520567417, 0.9402350703243103, 0.9406095348212723, 0.9411872419366716, 0.9414772131059828, 0.9417344306892441, 0.9423101781752498, 0.9424249361781583, 0.942603289754065, 0.9432108334898621, 0.9432706129269749, 0.943544358554543, 0.9437612906564282, 0.9440993088258208, 0.9444414474973297, 0.9445117734908012, 0.9444452155048352, 0.9448999514373135, 0.9450549453872936, 0.9453781451161458, 0.9454024331424502, 0.9462141759501534, 0.9465250943757254, 0.9464476595066174, 0.9464930956401605, 0.9467227120224225, 0.9467725933938647, 0.9468062747917657, 0.9471007916408126, 0.9470139642502016, 0.947189302772725, 0.947262994712091, 0.9473125494513875, 0.9473914662626374, 0.9474205008196556, 0.9475083087606215, 0.9475552520121576, 0.9476663177312892, 0.9478196786840212, 0.9478630301263132, 0.9478400237143072, 0.9478864389922811, 0.9479801238923693, 0.9482888071928061, 0.9484636690743468, 0.9483120891005536, 0.9484721827951683, 0.9486059793651725, 0.9484983541713072, 0.948518070851586, 0.9487061440061882, 0.9486510877876052, 0.9487878231314336, 0.9488141205176115, 0.9488500865095602, 0.9488747769244347, 0.9487633081628147, 0.9489292044006594, 0.9490930394229167, 0.9491376728391622, 0.9491339803919057, 0.9492740043231046, 0.9492204307986692, 0.9491717305669926, 0.949256422718475, 0.9493996391764592, 0.9492493414381867, 0.9493046711580608], 'mDice': [0.16690136293215996, 0.3640366996374355, 0.44646361736694146, 0.4957448486535025, 0.5256560763943934, 0.5430509215910488, 0.5585123687671948, 0.5693099958943719, 0.5775348973745053, 0.5850132658170333, 0.5921001370896105, 0.5964728318036289, 0.6077193860097436, 0.6105900950243496, 0.6147308145586894, 0.6187315671508024, 0.6182553989427533, 0.6241573660960906, 0.6279336604781682, 0.6326522370550048, 0.6341063584917793, 0.637955274479898, 0.639034204540577, 0.6402346619164231, 0.6424743444201584, 0.6403338418220075, 0.6466246417964218, 0.6504938531824344, 0.6489191964898081, 0.6554552771138805, 0.6571941968836238, 0.65449429290738, 0.6557004675064777, 0.6578815403837328, 0.6582133403467857, 0.6613995533884062, 0.6629107860879981, 0.669696019497535, 0.6754705685216911, 0.6731914500907693, 0.6731690990028967, 0.6733322457108469, 0.6763208027534673, 0.6747721902825842, 0.6771996474436071, 0.6771510249628055, 0.6776073685695493, 0.6774585159905193, 0.6784330452135874, 0.6788481470980098, 0.6787214337046567, 0.6786479581468261, 0.6811332229526894, 0.6821718861359656, 0.6843408524695819, 0.6832756035875894, 0.6837202536163915, 0.6797946483567071, 0.6875398934247137, 0.6892995362875557, 0.6896775905993111, 0.68836893390576, 0.689758514416329, 0.6877709117585725, 0.692100085861658, 0.6910687145857254, 0.6924132999651914, 0.6915771733321662, 0.6942695985766342, 0.6921926152882704, 0.6968630956413323, 0.695646762978684, 0.6913478225551329, 0.6948784041457038, 0.6965060649798326, 0.6944268280441004, 0.6955256424169912, 0.6951412502972555, 0.6948947017819295, 0.6978834708902252, 0.6951836837037736, 0.6946361998706092, 0.6957220023174046, 0.6982454596086315], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.54s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.42s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.30s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.16s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_c/sd2/vimp*': No such file or directory

  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:00<00:01,  2.95it/s] 40%|████      | 2/5 [00:00<00:01,  2.88it/s] 60%|██████    | 3/5 [00:01<00:00,  2.83it/s] 80%|████████  | 4/5 [00:01<00:00,  3.04it/s]100%|██████████| 5/5 [00:01<00:00,  3.13it/s]100%|██████████| 5/5 [00:01<00:00,  3.04it/s]

CrossVal ['c']
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
2020-01-22 04:56:28.339946: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-22 04:56:32.033368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-22 04:56:32.033435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 04:56:32.473534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 04:56:32.473591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 04:56:32.473602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 04:56:32.475038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:07,  3.94it/s]Loading train:   1%|          | 2/266 [00:00<01:05,  4.00it/s]Loading train:   1%|          | 3/266 [00:00<01:04,  4.05it/s]Loading train:   2%|▏         | 4/266 [00:00<01:04,  4.08it/s]Loading train:   2%|▏         | 5/266 [00:01<01:02,  4.20it/s]Loading train:   2%|▏         | 6/266 [00:01<01:00,  4.26it/s]Loading train:   3%|▎         | 7/266 [00:01<01:00,  4.32it/s]Loading train:   3%|▎         | 8/266 [00:01<00:59,  4.36it/s]Loading train:   3%|▎         | 9/266 [00:02<00:58,  4.39it/s]Loading train:   4%|▍         | 10/266 [00:02<00:58,  4.41it/s]Loading train:   4%|▍         | 11/266 [00:02<00:58,  4.39it/s]Loading train:   5%|▍         | 12/266 [00:02<00:57,  4.42it/s]Loading train:   5%|▍         | 13/266 [00:03<00:57,  4.40it/s]Loading train:   5%|▌         | 14/266 [00:03<00:56,  4.44it/s]Loading train:   6%|▌         | 15/266 [00:03<00:56,  4.46it/s]Loading train:   6%|▌         | 16/266 [00:03<00:55,  4.49it/s]Loading train:   6%|▋         | 17/266 [00:03<00:55,  4.50it/s]Loading train:   7%|▋         | 18/266 [00:04<00:54,  4.52it/s]Loading train:   7%|▋         | 19/266 [00:04<00:54,  4.53it/s]Loading train:   8%|▊         | 20/266 [00:04<00:54,  4.52it/s]Loading train:   8%|▊         | 21/266 [00:04<00:54,  4.53it/s]Loading train:   8%|▊         | 22/266 [00:04<00:53,  4.54it/s]Loading train:   9%|▊         | 23/266 [00:05<00:53,  4.56it/s]Loading train:   9%|▉         | 24/266 [00:05<00:52,  4.58it/s]Loading train:   9%|▉         | 25/266 [00:05<01:01,  3.90it/s]Loading train:  10%|▉         | 26/266 [00:06<01:13,  3.26it/s]Loading train:  10%|█         | 27/266 [00:06<01:31,  2.62it/s]Loading train:  11%|█         | 28/266 [00:07<02:13,  1.78it/s]Loading train:  11%|█         | 29/266 [00:08<02:45,  1.43it/s]Loading train:  11%|█▏        | 30/266 [00:09<02:46,  1.42it/s]Loading train:  12%|█▏        | 31/266 [00:10<02:55,  1.34it/s]Loading train:  12%|█▏        | 32/266 [00:11<03:07,  1.25it/s]Loading train:  12%|█▏        | 33/266 [00:11<02:54,  1.34it/s]Loading train:  13%|█▎        | 34/266 [00:12<02:49,  1.37it/s]Loading train:  13%|█▎        | 35/266 [00:13<02:49,  1.36it/s]Loading train:  14%|█▎        | 36/266 [00:14<02:48,  1.37it/s]Loading train:  14%|█▍        | 37/266 [00:14<02:42,  1.41it/s]Loading train:  14%|█▍        | 38/266 [00:15<02:39,  1.43it/s]Loading train:  15%|█▍        | 39/266 [00:16<02:44,  1.38it/s]Loading train:  15%|█▌        | 40/266 [00:16<02:38,  1.42it/s]Loading train:  15%|█▌        | 41/266 [00:17<02:47,  1.34it/s]Loading train:  16%|█▌        | 42/266 [00:18<02:54,  1.28it/s]Loading train:  16%|█▌        | 43/266 [00:18<02:33,  1.45it/s]Loading train:  17%|█▋        | 44/266 [00:19<02:15,  1.64it/s]Loading train:  17%|█▋        | 45/266 [00:20<02:19,  1.58it/s]Loading train:  17%|█▋        | 46/266 [00:20<02:09,  1.70it/s]Loading train:  18%|█▊        | 47/266 [00:21<01:58,  1.84it/s]Loading train:  18%|█▊        | 48/266 [00:21<01:53,  1.93it/s]Loading train:  18%|█▊        | 49/266 [00:21<01:49,  1.99it/s]Loading train:  19%|█▉        | 50/266 [00:22<01:43,  2.08it/s]Loading train:  19%|█▉        | 51/266 [00:22<01:44,  2.05it/s]Loading train:  20%|█▉        | 52/266 [00:23<01:36,  2.21it/s]Loading train:  20%|█▉        | 53/266 [00:23<01:34,  2.25it/s]Loading train:  20%|██        | 54/266 [00:24<01:43,  2.05it/s]Loading train:  21%|██        | 55/266 [00:24<01:40,  2.10it/s]Loading train:  21%|██        | 56/266 [00:25<01:39,  2.12it/s]Loading train:  21%|██▏       | 57/266 [00:25<01:37,  2.14it/s]Loading train:  22%|██▏       | 58/266 [00:26<01:40,  2.07it/s]Loading train:  22%|██▏       | 59/266 [00:26<01:46,  1.94it/s]Loading train:  23%|██▎       | 60/266 [00:27<01:57,  1.75it/s]Loading train:  23%|██▎       | 61/266 [00:28<02:01,  1.69it/s]Loading train:  23%|██▎       | 62/266 [00:28<02:01,  1.67it/s]Loading train:  24%|██▎       | 63/266 [00:29<01:56,  1.74it/s]Loading train:  24%|██▍       | 64/266 [00:29<01:50,  1.82it/s]Loading train:  24%|██▍       | 65/266 [00:30<01:41,  1.98it/s]Loading train:  25%|██▍       | 66/266 [00:30<01:38,  2.02it/s]Loading train:  25%|██▌       | 67/266 [00:31<01:50,  1.80it/s]Loading train:  26%|██▌       | 68/266 [00:31<01:50,  1.80it/s]Loading train:  26%|██▌       | 69/266 [00:32<01:42,  1.92it/s]Loading train:  26%|██▋       | 70/266 [00:32<01:43,  1.90it/s]Loading train:  27%|██▋       | 71/266 [00:33<01:45,  1.85it/s]Loading train:  27%|██▋       | 72/266 [00:33<01:37,  2.00it/s]Loading train:  27%|██▋       | 73/266 [00:34<01:43,  1.87it/s]Loading train:  28%|██▊       | 74/266 [00:34<01:37,  1.97it/s]Loading train:  28%|██▊       | 75/266 [00:35<01:39,  1.93it/s]Loading train:  29%|██▊       | 76/266 [00:35<01:39,  1.91it/s]Loading train:  29%|██▉       | 77/266 [00:37<02:16,  1.39it/s]Loading train:  29%|██▉       | 78/266 [00:37<02:09,  1.45it/s]Loading train:  30%|██▉       | 79/266 [00:38<01:56,  1.60it/s]Loading train:  30%|███       | 80/266 [00:38<02:00,  1.55it/s]Loading train:  30%|███       | 81/266 [00:39<02:03,  1.50it/s]Loading train:  31%|███       | 82/266 [00:40<02:01,  1.51it/s]Loading train:  31%|███       | 83/266 [00:41<02:37,  1.16it/s]Loading train:  32%|███▏      | 84/266 [00:42<02:52,  1.05it/s]Loading train:  32%|███▏      | 85/266 [00:43<03:01,  1.01s/it]Loading train:  32%|███▏      | 86/266 [00:44<03:01,  1.01s/it]Loading train:  33%|███▎      | 87/266 [00:45<02:37,  1.14it/s]Loading train:  33%|███▎      | 88/266 [00:45<02:17,  1.30it/s]Loading train:  33%|███▎      | 89/266 [00:47<02:55,  1.01it/s]Loading train:  34%|███▍      | 90/266 [00:48<03:05,  1.05s/it]Loading train:  34%|███▍      | 91/266 [00:50<03:22,  1.16s/it]Loading train:  35%|███▍      | 92/266 [00:50<03:00,  1.04s/it]Loading train:  35%|███▍      | 93/266 [00:51<02:41,  1.07it/s]Loading train:  35%|███▌      | 94/266 [00:52<02:57,  1.03s/it]Loading train:  36%|███▌      | 95/266 [00:53<02:56,  1.03s/it]Loading train:  36%|███▌      | 96/266 [00:54<02:45,  1.03it/s]Loading train:  36%|███▋      | 97/266 [00:55<02:37,  1.07it/s]Loading train:  37%|███▋      | 98/266 [00:56<02:24,  1.16it/s]Loading train:  37%|███▋      | 99/266 [00:56<02:18,  1.21it/s]Loading train:  38%|███▊      | 100/266 [00:57<02:14,  1.24it/s]Loading train:  38%|███▊      | 101/266 [00:58<02:07,  1.29it/s]Loading train:  38%|███▊      | 102/266 [00:58<01:55,  1.42it/s]Loading train:  39%|███▊      | 103/266 [00:59<01:57,  1.39it/s]Loading train:  39%|███▉      | 104/266 [01:01<02:38,  1.03it/s]Loading train:  39%|███▉      | 105/266 [01:02<02:34,  1.04it/s]Loading train:  40%|███▉      | 106/266 [01:03<02:29,  1.07it/s]Loading train:  40%|████      | 107/266 [01:04<02:35,  1.02it/s]Loading train:  41%|████      | 108/266 [01:05<02:32,  1.04it/s]Loading train:  41%|████      | 109/266 [01:05<02:18,  1.13it/s]Loading train:  41%|████▏     | 110/266 [01:06<02:22,  1.09it/s]Loading train:  42%|████▏     | 111/266 [01:07<02:27,  1.05it/s]Loading train:  42%|████▏     | 112/266 [01:09<02:57,  1.15s/it]Loading train:  42%|████▏     | 113/266 [01:10<02:54,  1.14s/it]Loading train:  43%|████▎     | 114/266 [01:11<02:28,  1.02it/s]Loading train:  43%|████▎     | 115/266 [01:11<02:07,  1.19it/s]Loading train:  44%|████▎     | 116/266 [01:12<01:53,  1.32it/s]Loading train:  44%|████▍     | 117/266 [01:12<01:41,  1.46it/s]Loading train:  44%|████▍     | 118/266 [01:13<01:40,  1.47it/s]Loading train:  45%|████▍     | 119/266 [01:14<01:49,  1.34it/s]Loading train:  45%|████▌     | 120/266 [01:15<01:55,  1.26it/s]Loading train:  45%|████▌     | 121/266 [01:16<01:55,  1.26it/s]Loading train:  46%|████▌     | 122/266 [01:16<01:58,  1.22it/s]Loading train:  46%|████▌     | 123/266 [01:17<01:51,  1.28it/s]Loading train:  47%|████▋     | 124/266 [01:18<01:37,  1.46it/s]Loading train:  47%|████▋     | 125/266 [01:18<01:25,  1.65it/s]Loading train:  47%|████▋     | 126/266 [01:18<01:16,  1.82it/s]Loading train:  48%|████▊     | 127/266 [01:19<01:10,  1.96it/s]Loading train:  48%|████▊     | 128/266 [01:19<01:06,  2.07it/s]Loading train:  48%|████▊     | 129/266 [01:20<01:15,  1.81it/s]Loading train:  49%|████▉     | 130/266 [01:20<01:14,  1.83it/s]Loading train:  49%|████▉     | 131/266 [01:22<01:45,  1.28it/s]Loading train:  50%|████▉     | 132/266 [01:23<01:59,  1.12it/s]Loading train:  50%|█████     | 133/266 [01:24<02:09,  1.03it/s]Loading train:  50%|█████     | 134/266 [01:25<01:48,  1.22it/s]Loading train:  51%|█████     | 135/266 [01:25<01:36,  1.35it/s]Loading train:  51%|█████     | 136/266 [01:26<01:25,  1.52it/s]Loading train:  52%|█████▏    | 137/266 [01:26<01:15,  1.70it/s]Loading train:  52%|█████▏    | 138/266 [01:26<01:09,  1.84it/s]Loading train:  52%|█████▏    | 139/266 [01:27<01:04,  1.97it/s]Loading train:  53%|█████▎    | 140/266 [01:28<01:20,  1.56it/s]Loading train:  53%|█████▎    | 141/266 [01:29<01:27,  1.43it/s]Loading train:  53%|█████▎    | 142/266 [01:30<01:38,  1.26it/s]Loading train:  54%|█████▍    | 143/266 [01:31<01:49,  1.13it/s]Loading train:  54%|█████▍    | 144/266 [01:32<01:53,  1.08it/s]Loading train:  55%|█████▍    | 145/266 [01:32<01:40,  1.20it/s]Loading train:  55%|█████▍    | 146/266 [01:33<01:30,  1.33it/s]Loading train:  55%|█████▌    | 147/266 [01:33<01:19,  1.50it/s]Loading train:  56%|█████▌    | 148/266 [01:34<01:09,  1.71it/s]Loading train:  56%|█████▌    | 149/266 [01:34<01:03,  1.83it/s]Loading train:  56%|█████▋    | 150/266 [01:35<00:59,  1.96it/s]Loading train:  57%|█████▋    | 151/266 [01:35<00:54,  2.11it/s]Loading train:  57%|█████▋    | 152/266 [01:36<01:12,  1.58it/s]Loading train:  58%|█████▊    | 153/266 [01:37<01:13,  1.54it/s]Loading train:  58%|█████▊    | 154/266 [01:38<01:22,  1.36it/s]Loading train:  58%|█████▊    | 155/266 [01:39<01:35,  1.17it/s]Loading train:  59%|█████▊    | 156/266 [01:40<01:37,  1.12it/s]Loading train:  59%|█████▉    | 157/266 [01:41<01:31,  1.19it/s]Loading train:  59%|█████▉    | 158/266 [01:41<01:31,  1.19it/s]Loading train:  60%|█████▉    | 159/266 [01:42<01:19,  1.34it/s]Loading train:  60%|██████    | 160/266 [01:42<01:09,  1.52it/s]Loading train:  61%|██████    | 161/266 [01:43<01:03,  1.65it/s]Loading train:  61%|██████    | 162/266 [01:43<00:59,  1.74it/s]Loading train:  61%|██████▏   | 163/266 [01:44<01:09,  1.49it/s]Loading train:  62%|██████▏   | 164/266 [01:45<01:13,  1.39it/s]Loading train:  62%|██████▏   | 165/266 [01:46<01:16,  1.32it/s]Loading train:  62%|██████▏   | 166/266 [01:47<01:19,  1.26it/s]Loading train:  63%|██████▎   | 167/266 [01:48<01:26,  1.15it/s]Loading train:  63%|██████▎   | 168/266 [01:49<01:25,  1.15it/s]Loading train:  64%|██████▎   | 169/266 [01:49<01:19,  1.23it/s]Loading train:  64%|██████▍   | 170/266 [01:50<01:10,  1.37it/s]Loading train:  64%|██████▍   | 171/266 [01:50<01:02,  1.52it/s]Loading train:  65%|██████▍   | 172/266 [01:51<00:55,  1.68it/s]Loading train:  65%|██████▌   | 173/266 [01:52<00:59,  1.56it/s]Loading train:  65%|██████▌   | 174/266 [01:53<01:04,  1.43it/s]Loading train:  66%|██████▌   | 175/266 [01:53<00:53,  1.69it/s]Loading train:  66%|██████▌   | 176/266 [01:53<00:54,  1.65it/s]Loading train:  67%|██████▋   | 177/266 [01:54<01:01,  1.45it/s]Loading train:  67%|██████▋   | 178/266 [01:55<01:04,  1.37it/s]Loading train:  67%|██████▋   | 179/266 [01:56<01:12,  1.20it/s]Loading train:  68%|██████▊   | 180/266 [01:57<01:15,  1.15it/s]Loading train:  68%|██████▊   | 181/266 [01:58<01:19,  1.07it/s]Loading train:  68%|██████▊   | 182/266 [01:59<01:20,  1.05it/s]Loading train:  69%|██████▉   | 183/266 [02:00<01:20,  1.04it/s]Loading train:  69%|██████▉   | 184/266 [02:01<01:18,  1.04it/s]Loading train:  70%|██████▉   | 185/266 [02:02<01:21,  1.00s/it]Loading train:  70%|██████▉   | 186/266 [02:03<01:18,  1.02it/s]Loading train:  70%|███████   | 187/266 [02:04<01:21,  1.03s/it]Loading train:  71%|███████   | 188/266 [02:05<01:16,  1.03it/s]Loading train:  71%|███████   | 189/266 [02:06<01:11,  1.07it/s]Loading train:  71%|███████▏  | 190/266 [02:07<01:16,  1.00s/it]Loading train:  72%|███████▏  | 191/266 [02:08<01:14,  1.01it/s]Loading train:  72%|███████▏  | 192/266 [02:09<01:18,  1.06s/it]Loading train:  73%|███████▎  | 193/266 [02:10<01:14,  1.02s/it]Loading train:  73%|███████▎  | 194/266 [02:11<01:12,  1.01s/it]Loading train:  73%|███████▎  | 195/266 [02:13<01:17,  1.09s/it]Loading train:  74%|███████▎  | 196/266 [02:14<01:12,  1.03s/it]Loading train:  74%|███████▍  | 197/266 [02:15<01:15,  1.09s/it]Loading train:  74%|███████▍  | 198/266 [02:16<01:18,  1.16s/it]Loading train:  75%|███████▍  | 199/266 [02:17<01:17,  1.16s/it]Loading train:  75%|███████▌  | 200/266 [02:19<01:20,  1.21s/it]Loading train:  76%|███████▌  | 201/266 [02:20<01:17,  1.19s/it]Loading train:  76%|███████▌  | 202/266 [02:21<01:17,  1.21s/it]Loading train:  76%|███████▋  | 203/266 [02:22<01:14,  1.18s/it]Loading train:  77%|███████▋  | 204/266 [02:24<01:18,  1.27s/it]Loading train:  77%|███████▋  | 205/266 [02:25<01:18,  1.29s/it]Loading train:  77%|███████▋  | 206/266 [02:26<01:14,  1.25s/it]Loading train:  78%|███████▊  | 207/266 [02:27<01:15,  1.27s/it]Loading train:  78%|███████▊  | 208/266 [02:28<01:09,  1.20s/it]Loading train:  79%|███████▊  | 209/266 [02:30<01:15,  1.33s/it]Loading train:  79%|███████▉  | 210/266 [02:31<01:12,  1.30s/it]Loading train:  79%|███████▉  | 211/266 [02:32<01:07,  1.24s/it]Loading train:  80%|███████▉  | 212/266 [02:33<01:04,  1.20s/it]Loading train:  80%|████████  | 213/266 [02:34<01:00,  1.13s/it]Loading train:  80%|████████  | 214/266 [02:36<00:59,  1.14s/it]Loading train:  81%|████████  | 215/266 [02:37<00:56,  1.11s/it]Loading train:  81%|████████  | 216/266 [02:38<00:53,  1.07s/it]Loading train:  82%|████████▏ | 217/266 [02:39<00:52,  1.06s/it]Loading train:  82%|████████▏ | 218/266 [02:40<00:52,  1.10s/it]Loading train:  82%|████████▏ | 219/266 [02:41<00:47,  1.02s/it]Loading train:  83%|████████▎ | 220/266 [02:42<00:47,  1.03s/it]Loading train:  83%|████████▎ | 221/266 [02:43<00:45,  1.02s/it]Loading train:  83%|████████▎ | 222/266 [02:44<00:43,  1.01it/s]Loading train:  84%|████████▍ | 223/266 [02:45<00:44,  1.03s/it]Loading train:  84%|████████▍ | 224/266 [02:46<00:44,  1.05s/it]Loading train:  85%|████████▍ | 225/266 [02:47<00:41,  1.02s/it]Loading train:  85%|████████▍ | 226/266 [02:48<00:41,  1.04s/it]Loading train:  85%|████████▌ | 227/266 [02:49<00:41,  1.06s/it]Loading train:  86%|████████▌ | 228/266 [02:50<00:40,  1.07s/it]Loading train:  86%|████████▌ | 229/266 [02:51<00:39,  1.06s/it]Loading train:  86%|████████▋ | 230/266 [02:52<00:36,  1.02s/it]Loading train:  87%|████████▋ | 231/266 [02:53<00:34,  1.03it/s]Loading train:  87%|████████▋ | 232/266 [02:54<00:30,  1.12it/s]Loading train:  88%|████████▊ | 233/266 [02:54<00:26,  1.26it/s]Loading train:  88%|████████▊ | 234/266 [02:55<00:24,  1.28it/s]Loading train:  88%|████████▊ | 235/266 [02:56<00:22,  1.35it/s]Loading train:  89%|████████▊ | 236/266 [02:56<00:21,  1.38it/s]Loading train:  89%|████████▉ | 237/266 [02:57<00:19,  1.46it/s]Loading train:  89%|████████▉ | 238/266 [02:57<00:18,  1.53it/s]Loading train:  90%|████████▉ | 239/266 [02:58<00:18,  1.44it/s]Loading train:  90%|█████████ | 240/266 [02:59<00:17,  1.46it/s]Loading train:  91%|█████████ | 241/266 [03:00<00:18,  1.33it/s]Loading train:  91%|█████████ | 242/266 [03:01<00:18,  1.29it/s]Loading train:  91%|█████████▏| 243/266 [03:02<00:19,  1.16it/s]Loading train:  92%|█████████▏| 244/266 [03:02<00:17,  1.27it/s]Loading train:  92%|█████████▏| 245/266 [03:03<00:16,  1.31it/s]Loading train:  92%|█████████▏| 246/266 [03:04<00:14,  1.40it/s]Loading train:  93%|█████████▎| 247/266 [03:04<00:13,  1.39it/s]Loading train:  93%|█████████▎| 248/266 [03:05<00:12,  1.45it/s]Loading train:  94%|█████████▎| 249/266 [03:06<00:12,  1.41it/s]Loading train:  94%|█████████▍| 250/266 [03:06<00:11,  1.42it/s]Loading train:  94%|█████████▍| 251/266 [03:07<00:10,  1.39it/s]Loading train:  95%|█████████▍| 252/266 [03:08<00:11,  1.25it/s]Loading train:  95%|█████████▌| 253/266 [03:09<00:09,  1.32it/s]Loading train:  95%|█████████▌| 254/266 [03:09<00:08,  1.42it/s]Loading train:  96%|█████████▌| 255/266 [03:10<00:07,  1.43it/s]Loading train:  96%|█████████▌| 256/266 [03:11<00:06,  1.45it/s]Loading train:  97%|█████████▋| 257/266 [03:11<00:06,  1.48it/s]Loading train:  97%|█████████▋| 258/266 [03:12<00:05,  1.50it/s]Loading train:  97%|█████████▋| 259/266 [03:13<00:04,  1.54it/s]Loading train:  98%|█████████▊| 260/266 [03:13<00:03,  1.51it/s]Loading train:  98%|█████████▊| 261/266 [03:14<00:03,  1.54it/s]Loading train:  98%|█████████▊| 262/266 [03:15<00:02,  1.59it/s]Loading train:  99%|█████████▉| 263/266 [03:15<00:01,  1.58it/s]Loading train:  99%|█████████▉| 264/266 [03:16<00:01,  1.51it/s]Loading train: 100%|█████████▉| 265/266 [03:17<00:00,  1.60it/s]Loading train: 100%|██████████| 266/266 [03:17<00:00,  1.56it/s]Loading train: 100%|██████████| 266/266 [03:17<00:00,  1.35it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 55.30it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:04, 56.88it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:04, 58.26it/s]concatenating: train:  10%|▉         | 26/266 [00:00<00:04, 58.23it/s]concatenating: train:  12%|█▏        | 31/266 [00:00<00:04, 54.74it/s]concatenating: train:  14%|█▎        | 36/266 [00:00<00:04, 51.37it/s]concatenating: train:  15%|█▌        | 41/266 [00:00<00:04, 48.68it/s]concatenating: train:  17%|█▋        | 46/266 [00:00<00:04, 48.45it/s]concatenating: train:  19%|█▉        | 51/266 [00:00<00:04, 48.36it/s]concatenating: train:  21%|██        | 56/266 [00:01<00:04, 48.07it/s]concatenating: train:  23%|██▎       | 62/266 [00:01<00:04, 48.46it/s]concatenating: train:  25%|██▌       | 67/266 [00:01<00:04, 48.18it/s]concatenating: train:  27%|██▋       | 73/266 [00:01<00:03, 49.76it/s]concatenating: train:  29%|██▉       | 78/266 [00:01<00:03, 48.69it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:03, 46.64it/s]concatenating: train:  33%|███▎      | 88/266 [00:01<00:04, 43.51it/s]concatenating: train:  35%|███▍      | 93/266 [00:01<00:04, 42.68it/s]concatenating: train:  37%|███▋      | 98/266 [00:02<00:03, 42.59it/s]concatenating: train:  39%|███▊      | 103/266 [00:02<00:03, 42.66it/s]concatenating: train:  41%|████      | 108/266 [00:02<00:03, 41.47it/s]concatenating: train:  42%|████▏     | 113/266 [00:02<00:03, 41.74it/s]concatenating: train:  44%|████▍     | 118/266 [00:02<00:03, 42.68it/s]concatenating: train:  47%|████▋     | 124/266 [00:02<00:03, 45.04it/s]concatenating: train:  49%|████▉     | 130/266 [00:02<00:02, 46.86it/s]concatenating: train:  51%|█████     | 136/266 [00:02<00:02, 47.98it/s]concatenating: train:  53%|█████▎    | 141/266 [00:02<00:02, 48.05it/s]concatenating: train:  55%|█████▍    | 146/266 [00:03<00:02, 48.25it/s]concatenating: train:  57%|█████▋    | 151/266 [00:03<00:02, 48.25it/s]concatenating: train:  59%|█████▊    | 156/266 [00:03<00:02, 47.48it/s]concatenating: train:  61%|██████    | 161/266 [00:03<00:02, 46.57it/s]concatenating: train:  62%|██████▏   | 166/266 [00:03<00:02, 45.65it/s]concatenating: train:  64%|██████▍   | 171/266 [00:03<00:02, 41.94it/s]concatenating: train:  66%|██████▌   | 176/266 [00:03<00:02, 42.21it/s]concatenating: train:  68%|██████▊   | 181/266 [00:03<00:01, 44.06it/s]concatenating: train:  70%|██████▉   | 186/266 [00:03<00:01, 44.58it/s]concatenating: train:  72%|███████▏  | 191/266 [00:04<00:01, 45.01it/s]concatenating: train:  74%|███████▎  | 196/266 [00:04<00:01, 45.30it/s]concatenating: train:  76%|███████▌  | 201/266 [00:04<00:01, 44.24it/s]concatenating: train:  77%|███████▋  | 206/266 [00:04<00:01, 41.86it/s]concatenating: train:  79%|███████▉  | 211/266 [00:04<00:01, 41.68it/s]concatenating: train:  81%|████████  | 216/266 [00:04<00:01, 42.60it/s]concatenating: train:  83%|████████▎ | 221/266 [00:04<00:01, 43.62it/s]concatenating: train:  85%|████████▍ | 226/266 [00:04<00:00, 44.31it/s]concatenating: train:  87%|████████▋ | 231/266 [00:04<00:00, 45.37it/s]concatenating: train:  89%|████████▉ | 237/266 [00:05<00:00, 47.72it/s]concatenating: train:  91%|█████████▏| 243/266 [00:05<00:00, 48.54it/s]concatenating: train:  94%|█████████▎| 249/266 [00:05<00:00, 49.11it/s]concatenating: train:  95%|█████████▌| 254/266 [00:05<00:00, 49.21it/s]concatenating: train:  97%|█████████▋| 259/266 [00:05<00:00, 48.55it/s]concatenating: train:  99%|█████████▉| 264/266 [00:05<00:00, 48.71it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 46.81it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:02,  1.02it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.18it/s]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.28it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.29it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.37it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 64.92it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<02:42,  1.63it/s]Loading trainS:   1%|          | 2/266 [00:01<02:48,  1.56it/s]Loading trainS:   1%|          | 3/266 [00:02<02:53,  1.52it/s]Loading trainS:   2%|▏         | 4/266 [00:02<02:57,  1.48it/s]Loading trainS:   2%|▏         | 5/266 [00:03<02:54,  1.50it/s]Loading trainS:   2%|▏         | 6/266 [00:04<02:56,  1.47it/s]Loading trainS:   3%|▎         | 7/266 [00:04<03:04,  1.41it/s]Loading trainS:   3%|▎         | 8/266 [00:05<03:02,  1.41it/s]Loading trainS:   3%|▎         | 9/266 [00:06<02:58,  1.44it/s]Loading trainS:   4%|▍         | 10/266 [00:06<03:00,  1.42it/s]Loading trainS:   4%|▍         | 11/266 [00:07<03:02,  1.40it/s]Loading trainS:   5%|▍         | 12/266 [00:08<03:05,  1.37it/s]Loading trainS:   5%|▍         | 13/266 [00:09<03:01,  1.40it/s]Loading trainS:   5%|▌         | 14/266 [00:09<02:56,  1.43it/s]Loading trainS:   6%|▌         | 15/266 [00:10<02:48,  1.49it/s]Loading trainS:   6%|▌         | 16/266 [00:11<02:54,  1.43it/s]Loading trainS:   6%|▋         | 17/266 [00:11<02:55,  1.42it/s]Loading trainS:   7%|▋         | 18/266 [00:12<02:55,  1.41it/s]Loading trainS:   7%|▋         | 19/266 [00:13<02:52,  1.43it/s]Loading trainS:   8%|▊         | 20/266 [00:13<02:50,  1.44it/s]Loading trainS:   8%|▊         | 21/266 [00:14<02:51,  1.43it/s]Loading trainS:   8%|▊         | 22/266 [00:15<02:46,  1.46it/s]Loading trainS:   9%|▊         | 23/266 [00:15<02:39,  1.53it/s]Loading trainS:   9%|▉         | 24/266 [00:16<02:45,  1.46it/s]Loading trainS:   9%|▉         | 25/266 [00:17<02:44,  1.46it/s]Loading trainS:  10%|▉         | 26/266 [00:18<02:42,  1.47it/s]Loading trainS:  10%|█         | 27/266 [00:18<02:45,  1.45it/s]Loading trainS:  11%|█         | 28/266 [00:19<02:41,  1.47it/s]Loading trainS:  11%|█         | 29/266 [00:20<02:37,  1.51it/s]Loading trainS:  11%|█▏        | 30/266 [00:20<02:41,  1.46it/s]Loading trainS:  12%|█▏        | 31/266 [00:21<02:46,  1.41it/s]Loading trainS:  12%|█▏        | 32/266 [00:22<02:40,  1.46it/s]Loading trainS:  12%|█▏        | 33/266 [00:22<02:41,  1.44it/s]Loading trainS:  13%|█▎        | 34/266 [00:23<02:42,  1.43it/s]Loading trainS:  13%|█▎        | 35/266 [00:24<02:43,  1.41it/s]Loading trainS:  14%|█▎        | 36/266 [00:25<02:41,  1.42it/s]Loading trainS:  14%|█▍        | 37/266 [00:25<02:39,  1.44it/s]Loading trainS:  14%|█▍        | 38/266 [00:26<02:36,  1.45it/s]Loading trainS:  15%|█▍        | 39/266 [00:26<02:30,  1.51it/s]Loading trainS:  15%|█▌        | 40/266 [00:27<02:31,  1.49it/s]Loading trainS:  15%|█▌        | 41/266 [00:28<02:30,  1.50it/s]Loading trainS:  16%|█▌        | 42/266 [00:29<02:33,  1.46it/s]Loading trainS:  16%|█▌        | 43/266 [00:29<02:39,  1.39it/s]Loading trainS:  17%|█▋        | 44/266 [00:30<02:49,  1.31it/s]Loading trainS:  17%|█▋        | 45/266 [00:31<02:45,  1.33it/s]Loading trainS:  17%|█▋        | 46/266 [00:32<02:41,  1.36it/s]Loading trainS:  18%|█▊        | 47/266 [00:32<02:35,  1.41it/s]Loading trainS:  18%|█▊        | 48/266 [00:33<02:32,  1.43it/s]Loading trainS:  18%|█▊        | 49/266 [00:34<02:40,  1.35it/s]Loading trainS:  19%|█▉        | 50/266 [00:35<02:42,  1.33it/s]Loading trainS:  19%|█▉        | 51/266 [00:35<02:31,  1.42it/s]Loading trainS:  20%|█▉        | 52/266 [00:36<02:45,  1.29it/s]Loading trainS:  20%|█▉        | 53/266 [00:37<02:41,  1.32it/s]Loading trainS:  20%|██        | 54/266 [00:38<02:36,  1.35it/s]Loading trainS:  21%|██        | 55/266 [00:38<02:33,  1.37it/s]Loading trainS:  21%|██        | 56/266 [00:39<02:29,  1.40it/s]Loading trainS:  21%|██▏       | 57/266 [00:40<02:25,  1.43it/s]Loading trainS:  22%|██▏       | 58/266 [00:40<02:35,  1.34it/s]Loading trainS:  22%|██▏       | 59/266 [00:41<02:29,  1.38it/s]Loading trainS:  23%|██▎       | 60/266 [00:42<02:21,  1.46it/s]Loading trainS:  23%|██▎       | 61/266 [00:42<02:19,  1.47it/s]Loading trainS:  23%|██▎       | 62/266 [00:43<02:20,  1.45it/s]Loading trainS:  24%|██▎       | 63/266 [00:44<02:19,  1.46it/s]Loading trainS:  24%|██▍       | 64/266 [00:44<02:21,  1.43it/s]Loading trainS:  24%|██▍       | 65/266 [00:45<02:25,  1.38it/s]Loading trainS:  25%|██▍       | 66/266 [00:46<02:18,  1.44it/s]Loading trainS:  25%|██▌       | 67/266 [00:47<02:22,  1.39it/s]Loading trainS:  26%|██▌       | 68/266 [00:47<02:19,  1.42it/s]Loading trainS:  26%|██▌       | 69/266 [00:48<02:18,  1.43it/s]Loading trainS:  26%|██▋       | 70/266 [00:49<02:20,  1.40it/s]Loading trainS:  27%|██▋       | 71/266 [00:49<02:14,  1.45it/s]Loading trainS:  27%|██▋       | 72/266 [00:50<02:20,  1.38it/s]Loading trainS:  27%|██▋       | 73/266 [00:51<02:14,  1.43it/s]Loading trainS:  28%|██▊       | 74/266 [00:52<02:19,  1.38it/s]Loading trainS:  28%|██▊       | 75/266 [00:52<02:20,  1.36it/s]Loading trainS:  29%|██▊       | 76/266 [00:53<02:17,  1.38it/s]Loading trainS:  29%|██▉       | 77/266 [00:54<02:27,  1.28it/s]Loading trainS:  29%|██▉       | 78/266 [00:55<02:29,  1.26it/s]Loading trainS:  30%|██▉       | 79/266 [00:56<02:22,  1.31it/s]Loading trainS:  30%|███       | 80/266 [00:56<02:14,  1.39it/s]Loading trainS:  30%|███       | 81/266 [00:57<02:08,  1.44it/s]Loading trainS:  31%|███       | 82/266 [00:58<02:15,  1.36it/s]Loading trainS:  31%|███       | 83/266 [00:58<02:20,  1.30it/s]Loading trainS:  32%|███▏      | 84/266 [00:59<02:18,  1.32it/s]Loading trainS:  32%|███▏      | 85/266 [01:00<02:23,  1.26it/s]Loading trainS:  32%|███▏      | 86/266 [01:01<02:25,  1.24it/s]Loading trainS:  33%|███▎      | 87/266 [01:02<02:21,  1.27it/s]Loading trainS:  33%|███▎      | 88/266 [01:02<02:22,  1.25it/s]Loading trainS:  33%|███▎      | 89/266 [01:03<02:23,  1.23it/s]Loading trainS:  34%|███▍      | 90/266 [01:04<02:22,  1.24it/s]Loading trainS:  34%|███▍      | 91/266 [01:05<02:16,  1.28it/s]Loading trainS:  35%|███▍      | 92/266 [01:06<02:15,  1.28it/s]Loading trainS:  35%|███▍      | 93/266 [01:06<02:18,  1.25it/s]Loading trainS:  35%|███▌      | 94/266 [01:07<02:17,  1.25it/s]Loading trainS:  36%|███▌      | 95/266 [01:08<02:23,  1.19it/s]Loading trainS:  36%|███▌      | 96/266 [01:09<02:19,  1.22it/s]Loading trainS:  36%|███▋      | 97/266 [01:10<02:21,  1.19it/s]Loading trainS:  37%|███▋      | 98/266 [01:11<02:21,  1.18it/s]Loading trainS:  37%|███▋      | 99/266 [01:12<02:29,  1.12it/s]Loading trainS:  38%|███▊      | 100/266 [01:12<02:15,  1.23it/s]Loading trainS:  38%|███▊      | 101/266 [01:13<02:12,  1.24it/s]Loading trainS:  38%|███▊      | 102/266 [01:14<02:10,  1.26it/s]Loading trainS:  39%|███▊      | 103/266 [01:15<02:06,  1.29it/s]Loading trainS:  39%|███▉      | 104/266 [01:15<02:00,  1.35it/s]Loading trainS:  39%|███▉      | 105/266 [01:16<02:07,  1.26it/s]Loading trainS:  40%|███▉      | 106/266 [01:17<02:05,  1.27it/s]Loading trainS:  40%|████      | 107/266 [01:18<01:58,  1.34it/s]Loading trainS:  41%|████      | 108/266 [01:18<02:04,  1.27it/s]Loading trainS:  41%|████      | 109/266 [01:19<02:00,  1.30it/s]Loading trainS:  41%|████▏     | 110/266 [01:20<02:03,  1.26it/s]Loading trainS:  42%|████▏     | 111/266 [01:21<02:06,  1.23it/s]Loading trainS:  42%|████▏     | 112/266 [01:22<02:02,  1.25it/s]Loading trainS:  42%|████▏     | 113/266 [01:23<02:04,  1.23it/s]Loading trainS:  43%|████▎     | 114/266 [01:23<01:56,  1.30it/s]Loading trainS:  43%|████▎     | 115/266 [01:24<01:56,  1.29it/s]Loading trainS:  44%|████▎     | 116/266 [01:25<01:58,  1.26it/s]Loading trainS:  44%|████▍     | 117/266 [01:26<01:55,  1.29it/s]Loading trainS:  44%|████▍     | 118/266 [01:26<01:50,  1.34it/s]Loading trainS:  45%|████▍     | 119/266 [01:27<01:51,  1.32it/s]Loading trainS:  45%|████▌     | 120/266 [01:28<01:43,  1.40it/s]Loading trainS:  45%|████▌     | 121/266 [01:28<01:39,  1.46it/s]Loading trainS:  46%|████▌     | 122/266 [01:29<01:32,  1.55it/s]Loading trainS:  46%|████▌     | 123/266 [01:29<01:32,  1.55it/s]Loading trainS:  47%|████▋     | 124/266 [01:30<01:33,  1.52it/s]Loading trainS:  47%|████▋     | 125/266 [01:31<01:32,  1.52it/s]Loading trainS:  47%|████▋     | 126/266 [01:31<01:29,  1.56it/s]Loading trainS:  48%|████▊     | 127/266 [01:32<01:26,  1.61it/s]Loading trainS:  48%|████▊     | 128/266 [01:33<01:28,  1.56it/s]Loading trainS:  48%|████▊     | 129/266 [01:33<01:25,  1.61it/s]Loading trainS:  49%|████▉     | 130/266 [01:34<01:22,  1.65it/s]Loading trainS:  49%|████▉     | 131/266 [01:34<01:23,  1.62it/s]Loading trainS:  50%|████▉     | 132/266 [01:35<01:23,  1.61it/s]Loading trainS:  50%|█████     | 133/266 [01:36<01:20,  1.65it/s]Loading trainS:  50%|█████     | 134/266 [01:36<01:19,  1.66it/s]Loading trainS:  51%|█████     | 135/266 [01:37<01:19,  1.65it/s]Loading trainS:  51%|█████     | 136/266 [01:38<01:22,  1.57it/s]Loading trainS:  52%|█████▏    | 137/266 [01:38<01:24,  1.53it/s]Loading trainS:  52%|█████▏    | 138/266 [01:39<01:26,  1.48it/s]Loading trainS:  52%|█████▏    | 139/266 [01:40<01:26,  1.47it/s]Loading trainS:  53%|█████▎    | 140/266 [01:40<01:27,  1.43it/s]Loading trainS:  53%|█████▎    | 141/266 [01:41<01:27,  1.43it/s]Loading trainS:  53%|█████▎    | 142/266 [01:42<01:26,  1.43it/s]Loading trainS:  54%|█████▍    | 143/266 [01:43<01:28,  1.40it/s]Loading trainS:  54%|█████▍    | 144/266 [01:43<01:23,  1.47it/s]Loading trainS:  55%|█████▍    | 145/266 [01:44<01:23,  1.46it/s]Loading trainS:  55%|█████▍    | 146/266 [01:45<01:23,  1.43it/s]Loading trainS:  55%|█████▌    | 147/266 [01:45<01:22,  1.45it/s]Loading trainS:  56%|█████▌    | 148/266 [01:46<01:21,  1.45it/s]Loading trainS:  56%|█████▌    | 149/266 [01:47<01:20,  1.46it/s]Loading trainS:  56%|█████▋    | 150/266 [01:47<01:19,  1.47it/s]Loading trainS:  57%|█████▋    | 151/266 [01:48<01:20,  1.44it/s]Loading trainS:  57%|█████▋    | 152/266 [01:49<01:20,  1.41it/s]Loading trainS:  58%|█████▊    | 153/266 [01:49<01:16,  1.48it/s]Loading trainS:  58%|█████▊    | 154/266 [01:50<01:17,  1.45it/s]Loading trainS:  58%|█████▊    | 155/266 [01:51<01:20,  1.38it/s]Loading trainS:  59%|█████▊    | 156/266 [01:52<01:17,  1.42it/s]Loading trainS:  59%|█████▉    | 157/266 [01:52<01:12,  1.50it/s]Loading trainS:  59%|█████▉    | 158/266 [01:53<01:13,  1.47it/s]Loading trainS:  60%|█████▉    | 159/266 [01:54<01:15,  1.41it/s]Loading trainS:  60%|██████    | 160/266 [01:54<01:18,  1.35it/s]Loading trainS:  61%|██████    | 161/266 [01:55<01:15,  1.39it/s]Loading trainS:  61%|██████    | 162/266 [01:56<01:18,  1.33it/s]Loading trainS:  61%|██████▏   | 163/266 [01:57<01:18,  1.31it/s]Loading trainS:  62%|██████▏   | 164/266 [01:57<01:16,  1.33it/s]Loading trainS:  62%|██████▏   | 165/266 [01:58<01:13,  1.37it/s]Loading trainS:  62%|██████▏   | 166/266 [01:59<01:18,  1.28it/s]Loading trainS:  63%|██████▎   | 167/266 [02:00<01:19,  1.24it/s]Loading trainS:  63%|██████▎   | 168/266 [02:01<01:17,  1.27it/s]Loading trainS:  64%|██████▎   | 169/266 [02:01<01:15,  1.29it/s]Loading trainS:  64%|██████▍   | 170/266 [02:02<01:15,  1.27it/s]Loading trainS:  64%|██████▍   | 171/266 [02:03<01:13,  1.29it/s]Loading trainS:  65%|██████▍   | 172/266 [02:04<01:12,  1.30it/s]Loading trainS:  65%|██████▌   | 173/266 [02:04<01:10,  1.32it/s]Loading trainS:  65%|██████▌   | 174/266 [02:05<01:09,  1.33it/s]Loading trainS:  66%|██████▌   | 175/266 [02:06<01:00,  1.52it/s]Loading trainS:  66%|██████▌   | 176/266 [02:06<01:04,  1.39it/s]Loading trainS:  67%|██████▋   | 177/266 [02:07<00:58,  1.52it/s]Loading trainS:  67%|██████▋   | 178/266 [02:08<00:59,  1.48it/s]Loading trainS:  67%|██████▋   | 179/266 [02:08<00:58,  1.49it/s]Loading trainS:  68%|██████▊   | 180/266 [02:09<00:55,  1.54it/s]Loading trainS:  68%|██████▊   | 181/266 [02:10<00:55,  1.54it/s]Loading trainS:  68%|██████▊   | 182/266 [02:10<00:53,  1.58it/s]Loading trainS:  69%|██████▉   | 183/266 [02:11<00:52,  1.59it/s]Loading trainS:  69%|██████▉   | 184/266 [02:12<00:52,  1.56it/s]Loading trainS:  70%|██████▉   | 185/266 [02:12<00:50,  1.60it/s]Loading trainS:  70%|██████▉   | 186/266 [02:13<00:50,  1.60it/s]Loading trainS:  70%|███████   | 187/266 [02:13<00:48,  1.63it/s]Loading trainS:  71%|███████   | 188/266 [02:14<00:47,  1.65it/s]Loading trainS:  71%|███████   | 189/266 [02:14<00:43,  1.76it/s]Loading trainS:  71%|███████▏  | 190/266 [02:15<00:40,  1.89it/s]Loading trainS:  72%|███████▏  | 191/266 [02:15<00:36,  2.03it/s]Loading trainS:  72%|███████▏  | 192/266 [02:16<00:38,  1.92it/s]Loading trainS:  73%|███████▎  | 193/266 [02:16<00:41,  1.75it/s]Loading trainS:  73%|███████▎  | 194/266 [02:17<00:41,  1.73it/s]Loading trainS:  73%|███████▎  | 195/266 [02:18<00:44,  1.59it/s]Loading trainS:  74%|███████▎  | 196/266 [02:19<00:45,  1.53it/s]Loading trainS:  74%|███████▍  | 197/266 [02:19<00:45,  1.50it/s]Loading trainS:  74%|███████▍  | 198/266 [02:20<00:47,  1.44it/s]Loading trainS:  75%|███████▍  | 199/266 [02:21<00:49,  1.36it/s]Loading trainS:  75%|███████▌  | 200/266 [02:22<00:48,  1.35it/s]Loading trainS:  76%|███████▌  | 201/266 [02:22<00:48,  1.34it/s]Loading trainS:  76%|███████▌  | 202/266 [02:23<00:48,  1.32it/s]Loading trainS:  76%|███████▋  | 203/266 [02:24<00:50,  1.25it/s]Loading trainS:  77%|███████▋  | 204/266 [02:25<00:49,  1.26it/s]Loading trainS:  77%|███████▋  | 205/266 [02:26<00:46,  1.30it/s]Loading trainS:  77%|███████▋  | 206/266 [02:26<00:45,  1.32it/s]Loading trainS:  78%|███████▊  | 207/266 [02:27<00:44,  1.33it/s]Loading trainS:  78%|███████▊  | 208/266 [02:28<00:43,  1.34it/s]Loading trainS:  79%|███████▊  | 209/266 [02:28<00:42,  1.34it/s]Loading trainS:  79%|███████▉  | 210/266 [02:29<00:41,  1.35it/s]Loading trainS:  79%|███████▉  | 211/266 [02:30<00:41,  1.32it/s]Loading trainS:  80%|███████▉  | 212/266 [02:31<00:42,  1.28it/s]Loading trainS:  80%|████████  | 213/266 [02:32<00:40,  1.32it/s]Loading trainS:  80%|████████  | 214/266 [02:32<00:37,  1.37it/s]Loading trainS:  81%|████████  | 215/266 [02:33<00:35,  1.43it/s]Loading trainS:  81%|████████  | 216/266 [02:33<00:34,  1.45it/s]Loading trainS:  82%|████████▏ | 217/266 [02:34<00:34,  1.44it/s]Loading trainS:  82%|████████▏ | 218/266 [02:35<00:34,  1.41it/s]Loading trainS:  82%|████████▏ | 219/266 [02:36<00:33,  1.42it/s]Loading trainS:  83%|████████▎ | 220/266 [02:36<00:33,  1.37it/s]Loading trainS:  83%|████████▎ | 221/266 [02:37<00:31,  1.43it/s]Loading trainS:  83%|████████▎ | 222/266 [02:38<00:30,  1.43it/s]Loading trainS:  84%|████████▍ | 223/266 [02:38<00:30,  1.40it/s]Loading trainS:  84%|████████▍ | 224/266 [02:39<00:30,  1.40it/s]Loading trainS:  85%|████████▍ | 225/266 [02:40<00:28,  1.43it/s]Loading trainS:  85%|████████▍ | 226/266 [02:41<00:27,  1.45it/s]Loading trainS:  85%|████████▌ | 227/266 [02:41<00:27,  1.40it/s]Loading trainS:  86%|████████▌ | 228/266 [02:42<00:26,  1.45it/s]Loading trainS:  86%|████████▌ | 229/266 [02:43<00:25,  1.45it/s]Loading trainS:  86%|████████▋ | 230/266 [02:43<00:25,  1.40it/s]Loading trainS:  87%|████████▋ | 231/266 [02:44<00:22,  1.53it/s]Loading trainS:  87%|████████▋ | 232/266 [02:45<00:21,  1.57it/s]Loading trainS:  88%|████████▊ | 233/266 [02:45<00:19,  1.67it/s]Loading trainS:  88%|████████▊ | 234/266 [02:46<00:19,  1.65it/s]Loading trainS:  88%|████████▊ | 235/266 [02:46<00:18,  1.66it/s]Loading trainS:  89%|████████▊ | 236/266 [02:47<00:17,  1.70it/s]Loading trainS:  89%|████████▉ | 237/266 [02:47<00:17,  1.64it/s]Loading trainS:  89%|████████▉ | 238/266 [02:48<00:17,  1.61it/s]Loading trainS:  90%|████████▉ | 239/266 [02:49<00:15,  1.71it/s]Loading trainS:  90%|█████████ | 240/266 [02:49<00:14,  1.81it/s]Loading trainS:  91%|█████████ | 241/266 [02:50<00:14,  1.71it/s]Loading trainS:  91%|█████████ | 242/266 [02:50<00:14,  1.65it/s]Loading trainS:  91%|█████████▏| 243/266 [02:51<00:13,  1.67it/s]Loading trainS:  92%|█████████▏| 244/266 [02:51<00:12,  1.77it/s]Loading trainS:  92%|█████████▏| 245/266 [02:52<00:12,  1.62it/s]Loading trainS:  92%|█████████▏| 246/266 [02:53<00:12,  1.64it/s]Loading trainS:  93%|█████████▎| 247/266 [02:53<00:10,  1.73it/s]Loading trainS:  93%|█████████▎| 248/266 [02:54<00:10,  1.79it/s]Loading trainS:  94%|█████████▎| 249/266 [02:55<00:10,  1.64it/s]Loading trainS:  94%|█████████▍| 250/266 [02:55<00:09,  1.62it/s]Loading trainS:  94%|█████████▍| 251/266 [02:56<00:09,  1.64it/s]Loading trainS:  95%|█████████▍| 252/266 [02:57<00:09,  1.54it/s]Loading trainS:  95%|█████████▌| 253/266 [02:57<00:08,  1.60it/s]Loading trainS:  95%|█████████▌| 254/266 [02:58<00:07,  1.54it/s]Loading trainS:  96%|█████████▌| 255/266 [02:58<00:07,  1.54it/s]Loading trainS:  96%|█████████▌| 256/266 [02:59<00:06,  1.50it/s]Loading trainS:  97%|█████████▋| 257/266 [03:00<00:05,  1.51it/s]Loading trainS:  97%|█████████▋| 258/266 [03:00<00:05,  1.52it/s]Loading trainS:  97%|█████████▋| 259/266 [03:01<00:04,  1.56it/s]Loading trainS:  98%|█████████▊| 260/266 [03:02<00:03,  1.54it/s]Loading trainS:  98%|█████████▊| 261/266 [03:02<00:03,  1.57it/s]Loading trainS:  98%|█████████▊| 262/266 [03:03<00:02,  1.51it/s]Loading trainS:  99%|█████████▉| 263/266 [03:04<00:01,  1.52it/s]Loading trainS:  99%|█████████▉| 264/266 [03:04<00:01,  1.47it/s]Loading trainS: 100%|█████████▉| 265/266 [03:05<00:00,  1.47it/s]Loading trainS: 100%|██████████| 266/266 [03:06<00:00,  1.47it/s]Loading trainS: 100%|██████████| 266/266 [03:06<00:00,  1.43it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  1.55it/s]Loading testS:  50%|█████     | 2/4 [00:01<00:01,  1.61it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  1.53it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]----------+++ 
CrossVal ['d']
CrossVal ['d']
(0/4) test vimp2_ANON988_CSFn2
(1/4) test vimp2_M_CSFn2
(2/4) test vimp2_N_CSFn2
(3/4) test vimp2_L_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97410792 0.02589208]
Train on 17233 samples, validate on 255 samples
Epoch 1/300
 - 83s - loss: 0.1001 - acc: 0.9897 - mDice: 0.8051 - val_loss: 0.1962 - val_acc: 0.9922 - val_mDice: 0.4558

Epoch 00001: val_mDice improved from -inf to 0.45577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 78s - loss: 0.0651 - acc: 0.9934 - mDice: 0.8733 - val_loss: 0.1481 - val_acc: 0.9912 - val_mDice: 0.4734

Epoch 00002: val_mDice improved from 0.45577 to 0.47338, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 77s - loss: 0.0580 - acc: 0.9941 - mDice: 0.8870 - val_loss: 0.1258 - val_acc: 0.9766 - val_mDice: 0.1722

Epoch 00003: val_mDice did not improve from 0.47338
Epoch 4/300
 - 80s - loss: 0.0523 - acc: 0.9945 - mDice: 0.8981 - val_loss: 0.1005 - val_acc: 0.9933 - val_mDice: 0.4890

Epoch 00004: val_mDice improved from 0.47338 to 0.48900, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 80s - loss: 0.0514 - acc: 0.9946 - mDice: 0.8999 - val_loss: 0.1218 - val_acc: 0.9936 - val_mDice: 0.4962

Epoch 00005: val_mDice improved from 0.48900 to 0.49623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 81s - loss: 0.0476 - acc: 0.9949 - mDice: 0.9074 - val_loss: 0.0668 - val_acc: 0.9936 - val_mDice: 0.4775

Epoch 00006: val_mDice did not improve from 0.49623
Epoch 7/300
 - 80s - loss: 0.0468 - acc: 0.9950 - mDice: 0.9090 - val_loss: 0.1307 - val_acc: 0.9932 - val_mDice: 0.5066

Epoch 00007: val_mDice improved from 0.49623 to 0.50663, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 80s - loss: 0.0452 - acc: 0.9952 - mDice: 0.9121 - val_loss: 0.0913 - val_acc: 0.9935 - val_mDice: 0.5074

Epoch 00008: val_mDice improved from 0.50663 to 0.50736, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 9/300
 - 80s - loss: 0.0444 - acc: 0.9953 - mDice: 0.9136 - val_loss: 0.0083 - val_acc: 0.9934 - val_mDice: 0.4771

Epoch 00009: val_mDice did not improve from 0.50736
Epoch 10/300
 - 81s - loss: 0.0436 - acc: 0.9953 - mDice: 0.9152 - val_loss: 0.1708 - val_acc: 0.9935 - val_mDice: 0.5052

Epoch 00010: val_mDice did not improve from 0.50736
Epoch 11/300
 - 81s - loss: 0.0422 - acc: 0.9954 - mDice: 0.9179 - val_loss: 0.0891 - val_acc: 0.9933 - val_mDice: 0.5118

Epoch 00011: val_mDice improved from 0.50736 to 0.51185, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 12/300
 - 80s - loss: 0.0411 - acc: 0.9955 - mDice: 0.9201 - val_loss: 0.0265 - val_acc: 0.9936 - val_mDice: 0.4978

Epoch 00012: val_mDice did not improve from 0.51185
Epoch 13/300
 - 80s - loss: 0.0392 - acc: 0.9957 - mDice: 0.9238 - val_loss: 0.0565 - val_acc: 0.9931 - val_mDice: 0.4986

Epoch 00013: val_mDice did not improve from 0.51185
Epoch 14/300
 - 80s - loss: 0.0398 - acc: 0.9956 - mDice: 0.9226 - val_loss: 0.0996 - val_acc: 0.9934 - val_mDice: 0.4873

Epoch 00014: val_mDice did not improve from 0.51185
Epoch 15/300
 - 80s - loss: 0.0386 - acc: 0.9957 - mDice: 0.9250 - val_loss: 0.1212 - val_acc: 0.9933 - val_mDice: 0.4792

Epoch 00015: val_mDice did not improve from 0.51185
Epoch 16/300
 - 80s - loss: 0.0371 - acc: 0.9958 - mDice: 0.9278 - val_loss: 0.0193 - val_acc: 0.9936 - val_mDice: 0.4947

Epoch 00016: val_mDice did not improve from 0.51185
Epoch 17/300
 - 80s - loss: 0.0369 - acc: 0.9958 - mDice: 0.9282 - val_loss: 0.0420 - val_acc: 0.9910 - val_mDice: 0.4511

Epoch 00017: val_mDice did not improve from 0.51185
Epoch 18/300
 - 81s - loss: 0.0369 - acc: 0.9959 - mDice: 0.9282 - val_loss: 0.0624 - val_acc: 0.9934 - val_mDice: 0.4887

Epoch 00018: val_mDice did not improve from 0.51185
Epoch 19/300
 - 81s - loss: 0.0361 - acc: 0.9959 - mDice: 0.9298 - val_loss: 0.0524 - val_acc: 0.9933 - val_mDice: 0.4799

Epoch 00019: val_mDice did not improve from 0.51185
Epoch 20/300
 - 80s - loss: 0.0364 - acc: 0.9959 - mDice: 0.9293 - val_loss: 0.0742 - val_acc: 0.9934 - val_mDice: 0.5078

Epoch 00020: val_mDice did not improve from 0.51185
Epoch 21/300
 - 80s - loss: 0.0349 - acc: 0.9960 - mDice: 0.9321 - val_loss: 0.0196 - val_acc: 0.9934 - val_mDice: 0.4823

Epoch 00021: val_mDice did not improve from 0.51185
Epoch 22/300
 - 80s - loss: 0.0354 - acc: 0.9960 - mDice: 0.9313 - val_loss: 0.0444 - val_acc: 0.9932 - val_mDice: 0.4835

Epoch 00022: val_mDice did not improve from 0.51185
Epoch 23/300
 - 80s - loss: 0.0344 - acc: 0.9960 - mDice: 0.9331 - val_loss: 0.0373 - val_acc: 0.9936 - val_mDice: 0.4975

Epoch 00023: val_mDice did not improve from 0.51185
Epoch 24/300
 - 80s - loss: 0.0340 - acc: 0.9961 - mDice: 0.9340 - val_loss: 0.0812 - val_acc: 0.9934 - val_mDice: 0.4883

Epoch 00024: val_mDice did not improve from 0.51185
Epoch 25/300
 - 80s - loss: 0.0365 - acc: 0.9960 - mDice: 0.9290 - val_loss: 0.1341 - val_acc: 0.9931 - val_mDice: 0.5003

Epoch 00025: val_mDice did not improve from 0.51185
Epoch 26/300
 - 80s - loss: 0.0339 - acc: 0.9961 - mDice: 0.9341 - val_loss: 0.0248 - val_acc: 0.9935 - val_mDice: 0.4832

Epoch 00026: val_mDice did not improve from 0.51185

Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 27/300
 - 81s - loss: 0.0328 - acc: 0.9963 - mDice: 0.9362 - val_loss: 0.0571 - val_acc: 0.9935 - val_mDice: 0.4972

Epoch 00027: val_mDice did not improve from 0.51185
Epoch 28/300
 - 80s - loss: 0.0312 - acc: 0.9963 - mDice: 0.9395 - val_loss: 0.0045 - val_acc: 0.9937 - val_mDice: 0.4845

Epoch 00028: val_mDice did not improve from 0.51185
Epoch 29/300
 - 80s - loss: 0.0307 - acc: 0.9963 - mDice: 0.9404 - val_loss: 0.0779 - val_acc: 0.9937 - val_mDice: 0.4942

Epoch 00029: val_mDice did not improve from 0.51185
Epoch 30/300
 - 80s - loss: 0.0308 - acc: 0.9964 - mDice: 0.9401 - val_loss: 0.0245 - val_acc: 0.9937 - val_mDice: 0.4905

Epoch 00030: val_mDice did not improve from 0.51185
Epoch 31/300
 - 80s - loss: 0.0303 - acc: 0.9964 - mDice: 0.9412 - val_loss: 0.0360 - val_acc: 0.9935 - val_mDice: 0.5001

Epoch 00031: val_mDice did not improve from 0.51185
Epoch 32/300
 - 80s - loss: 0.0299 - acc: 0.9964 - mDice: 0.9420 - val_loss: 0.1335 - val_acc: 0.9936 - val_mDice: 0.5010

Epoch 00032: val_mDice did not improve from 0.51185
Epoch 33/300
 - 80s - loss: 0.0306 - acc: 0.9964 - mDice: 0.9406 - val_loss: 0.1019 - val_acc: 0.9937 - val_mDice: 0.4857

Epoch 00033: val_mDice did not improve from 0.51185
Epoch 34/300
 - 80s - loss: 0.0300 - acc: 0.9964 - mDice: 0.9417 - val_loss: 0.1323 - val_acc: 0.9935 - val_mDice: 0.5030

Epoch 00034: val_mDice did not improve from 0.51185
Epoch 35/300
 - 81s - loss: 0.0297 - acc: 0.9964 - mDice: 0.9424 - val_loss: 0.1787 - val_acc: 0.9884 - val_mDice: 0.4137

Epoch 00035: val_mDice did not improve from 0.51185
Epoch 36/300
 - 80s - loss: 0.0298 - acc: 0.9965 - mDice: 0.9420 - val_loss: 0.0947 - val_acc: 0.9934 - val_mDice: 0.5003

Epoch 00036: val_mDice did not improve from 0.51185
Epoch 37/300
 - 81s - loss: 0.0292 - acc: 0.9965 - mDice: 0.9433 - val_loss: 0.0956 - val_acc: 0.9935 - val_mDice: 0.4985

Epoch 00037: val_mDice did not improve from 0.51185
Epoch 38/300
 - 81s - loss: 0.0297 - acc: 0.9964 - mDice: 0.9423 - val_loss: 0.0033 - val_acc: 0.9938 - val_mDice: 0.4894

Epoch 00038: val_mDice did not improve from 0.51185
Epoch 39/300
 - 80s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9451 - val_loss: 0.0385 - val_acc: 0.9938 - val_mDice: 0.4933

Epoch 00039: val_mDice did not improve from 0.51185
Epoch 40/300
 - 80s - loss: 0.0297 - acc: 0.9965 - mDice: 0.9423 - val_loss: 0.0784 - val_acc: 0.9936 - val_mDice: 0.4937

Epoch 00040: val_mDice did not improve from 0.51185
Epoch 41/300
 - 80s - loss: 0.0287 - acc: 0.9965 - mDice: 0.9443 - val_loss: 7.8680e-04 - val_acc: 0.9934 - val_mDice: 0.4921

Epoch 00041: val_mDice did not improve from 0.51185

Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 42/300
 - 80s - loss: 0.0283 - acc: 0.9966 - mDice: 0.9451 - val_loss: 0.0459 - val_acc: 0.9937 - val_mDice: 0.4802

Epoch 00042: val_mDice did not improve from 0.51185
Epoch 43/300
 - 81s - loss: 0.0280 - acc: 0.9966 - mDice: 0.9457 - val_loss: -3.1367e-02 - val_acc: 0.9936 - val_mDice: 0.4779

Epoch 00043: val_mDice did not improve from 0.51185
Epoch 44/300
 - 80s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9466 - val_loss: 0.0356 - val_acc: 0.9936 - val_mDice: 0.5009

Epoch 00044: val_mDice did not improve from 0.51185
Epoch 45/300
 - 80s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9467 - val_loss: 0.0587 - val_acc: 0.9936 - val_mDice: 0.4937

Epoch 00045: val_mDice did not improve from 0.51185
Epoch 46/300
 - 80s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9478 - val_loss: 0.0570 - val_acc: 0.9934 - val_mDice: 0.4973

Epoch 00046: val_mDice did not improve from 0.51185
Epoch 47/300
 - 80s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9478 - val_loss: 0.0549 - val_acc: 0.9934 - val_mDice: 0.5016

Epoch 00047: val_mDice did not improve from 0.51185
Epoch 48/300
 - 80s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9469 - val_loss: 0.0567 - val_acc: 0.9934 - val_mDice: 0.4980

Epoch 00048: val_mDice did not improve from 0.51185
Epoch 49/300
 - 80s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9474 - val_loss: 0.0554 - val_acc: 0.9934 - val_mDice: 0.5005

Epoch 00049: val_mDice did not improve from 0.51185
Epoch 50/300
 - 80s - loss: 0.0273 - acc: 0.9966 - mDice: 0.9470 - val_loss: -2.5973e-02 - val_acc: 0.9935 - val_mDice: 0.4966

Epoch 00050: val_mDice did not improve from 0.51185
Epoch 51/300
 - 80s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9478 - val_loss: 0.0561 - val_acc: 0.9935 - val_mDice: 0.4992

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:02,  1.13it/s]predicting test subjects:  50%|█████     | 2/4 [00:01<00:01,  1.40it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:01<00:00,  1.83it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.21it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:41,  6.46it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:40,  6.59it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:39,  6.66it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:39,  6.60it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:39,  6.65it/s]predicting train subjects:   2%|▏         | 6/266 [00:00<00:38,  6.71it/s]predicting train subjects:   3%|▎         | 7/266 [00:01<00:38,  6.75it/s]predicting train subjects:   3%|▎         | 8/266 [00:01<00:38,  6.78it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:37,  6.80it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:37,  6.81it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:37,  6.80it/s]predicting train subjects:   5%|▍         | 12/266 [00:01<00:37,  6.81it/s]predicting train subjects:   5%|▍         | 13/266 [00:01<00:37,  6.82it/s]predicting train subjects:   5%|▌         | 14/266 [00:02<00:36,  6.83it/s]predicting train subjects:   6%|▌         | 15/266 [00:02<00:36,  6.83it/s]predicting train subjects:   6%|▌         | 16/266 [00:02<00:36,  6.84it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:36,  6.79it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:36,  6.81it/s]predicting train subjects:   7%|▋         | 19/266 [00:02<00:36,  6.83it/s]predicting train subjects:   8%|▊         | 20/266 [00:02<00:36,  6.83it/s]predicting train subjects:   8%|▊         | 21/266 [00:03<00:35,  6.83it/s]predicting train subjects:   8%|▊         | 22/266 [00:03<00:35,  6.82it/s]predicting train subjects:   9%|▊         | 23/266 [00:03<00:35,  6.90it/s]predicting train subjects:   9%|▉         | 24/266 [00:03<00:34,  6.96it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:34,  6.98it/s]predicting train subjects:  10%|▉         | 26/266 [00:03<00:34,  6.93it/s]predicting train subjects:  10%|█         | 27/266 [00:03<00:34,  6.94it/s]predicting train subjects:  11%|█         | 28/266 [00:04<00:34,  6.95it/s]predicting train subjects:  11%|█         | 29/266 [00:04<00:34,  6.93it/s]predicting train subjects:  11%|█▏        | 30/266 [00:04<00:34,  6.88it/s]predicting train subjects:  12%|█▏        | 31/266 [00:04<00:34,  6.87it/s]predicting train subjects:  12%|█▏        | 32/266 [00:04<00:34,  6.84it/s]predicting train subjects:  12%|█▏        | 33/266 [00:04<00:33,  6.87it/s]predicting train subjects:  13%|█▎        | 34/266 [00:04<00:33,  6.84it/s]predicting train subjects:  13%|█▎        | 35/266 [00:05<00:33,  6.83it/s]predicting train subjects:  14%|█▎        | 36/266 [00:05<00:33,  6.82it/s]predicting train subjects:  14%|█▍        | 37/266 [00:05<00:33,  6.85it/s]predicting train subjects:  14%|█▍        | 38/266 [00:05<00:33,  6.82it/s]predicting train subjects:  15%|█▍        | 39/266 [00:05<00:35,  6.42it/s]predicting train subjects:  15%|█▌        | 40/266 [00:05<00:34,  6.56it/s]predicting train subjects:  15%|█▌        | 41/266 [00:06<00:33,  6.67it/s]predicting train subjects:  16%|█▌        | 42/266 [00:06<00:33,  6.76it/s]predicting train subjects:  16%|█▌        | 43/266 [00:06<00:32,  6.79it/s]predicting train subjects:  17%|█▋        | 44/266 [00:06<00:32,  6.81it/s]predicting train subjects:  17%|█▋        | 45/266 [00:06<00:32,  6.79it/s]predicting train subjects:  17%|█▋        | 46/266 [00:06<00:32,  6.84it/s]predicting train subjects:  18%|█▊        | 47/266 [00:06<00:32,  6.81it/s]predicting train subjects:  18%|█▊        | 48/266 [00:07<00:32,  6.76it/s]predicting train subjects:  18%|█▊        | 49/266 [00:07<00:31,  6.84it/s]predicting train subjects:  19%|█▉        | 50/266 [00:07<00:31,  6.86it/s]predicting train subjects:  19%|█▉        | 51/266 [00:07<00:31,  6.88it/s]predicting train subjects:  20%|█▉        | 52/266 [00:07<00:30,  6.90it/s]predicting train subjects:  20%|█▉        | 53/266 [00:07<00:30,  6.92it/s]predicting train subjects:  20%|██        | 54/266 [00:07<00:30,  6.88it/s]predicting train subjects:  21%|██        | 55/266 [00:08<00:30,  6.82it/s]predicting train subjects:  21%|██        | 56/266 [00:08<00:31,  6.74it/s]predicting train subjects:  21%|██▏       | 57/266 [00:08<00:30,  6.76it/s]predicting train subjects:  22%|██▏       | 58/266 [00:08<00:30,  6.77it/s]predicting train subjects:  22%|██▏       | 59/266 [00:08<00:31,  6.65it/s]predicting train subjects:  23%|██▎       | 60/266 [00:08<00:30,  6.66it/s]predicting train subjects:  23%|██▎       | 61/266 [00:08<00:31,  6.54it/s]predicting train subjects:  23%|██▎       | 62/266 [00:09<00:31,  6.55it/s]predicting train subjects:  24%|██▎       | 63/266 [00:09<00:30,  6.55it/s]predicting train subjects:  24%|██▍       | 64/266 [00:09<00:31,  6.51it/s]predicting train subjects:  24%|██▍       | 65/266 [00:09<00:31,  6.46it/s]predicting train subjects:  25%|██▍       | 66/266 [00:09<00:30,  6.47it/s]predicting train subjects:  25%|██▌       | 67/266 [00:09<00:30,  6.49it/s]predicting train subjects:  26%|██▌       | 68/266 [00:10<00:30,  6.52it/s]predicting train subjects:  26%|██▌       | 69/266 [00:10<00:30,  6.53it/s]predicting train subjects:  26%|██▋       | 70/266 [00:10<00:29,  6.55it/s]predicting train subjects:  27%|██▋       | 71/266 [00:10<00:31,  6.15it/s]predicting train subjects:  27%|██▋       | 72/266 [00:10<00:30,  6.29it/s]predicting train subjects:  27%|██▋       | 73/266 [00:10<00:30,  6.40it/s]predicting train subjects:  28%|██▊       | 74/266 [00:10<00:29,  6.46it/s]predicting train subjects:  28%|██▊       | 75/266 [00:11<00:29,  6.45it/s]predicting train subjects:  29%|██▊       | 76/266 [00:11<00:29,  6.43it/s]predicting train subjects:  29%|██▉       | 77/266 [00:11<00:34,  5.55it/s]predicting train subjects:  29%|██▉       | 78/266 [00:11<00:37,  5.04it/s]predicting train subjects:  30%|██▉       | 79/266 [00:12<00:43,  4.33it/s]predicting train subjects:  30%|███       | 80/266 [00:12<00:47,  3.88it/s]predicting train subjects:  30%|███       | 81/266 [00:12<00:43,  4.29it/s]predicting train subjects:  31%|███       | 82/266 [00:12<00:39,  4.60it/s]predicting train subjects:  31%|███       | 83/266 [00:12<00:37,  4.88it/s]predicting train subjects:  32%|███▏      | 84/266 [00:13<00:35,  5.06it/s]predicting train subjects:  32%|███▏      | 85/266 [00:13<00:34,  5.21it/s]predicting train subjects:  32%|███▏      | 86/266 [00:13<00:33,  5.30it/s]predicting train subjects:  33%|███▎      | 87/266 [00:13<00:33,  5.41it/s]predicting train subjects:  33%|███▎      | 88/266 [00:13<00:32,  5.47it/s]predicting train subjects:  33%|███▎      | 89/266 [00:14<00:32,  5.48it/s]predicting train subjects:  34%|███▍      | 90/266 [00:14<00:32,  5.47it/s]predicting train subjects:  34%|███▍      | 91/266 [00:14<00:31,  5.48it/s]predicting train subjects:  35%|███▍      | 92/266 [00:14<00:31,  5.55it/s]predicting train subjects:  35%|███▍      | 93/266 [00:14<00:31,  5.53it/s]predicting train subjects:  35%|███▌      | 94/266 [00:14<00:31,  5.52it/s]predicting train subjects:  36%|███▌      | 95/266 [00:15<00:30,  5.55it/s]predicting train subjects:  36%|███▌      | 96/266 [00:15<00:30,  5.52it/s]predicting train subjects:  36%|███▋      | 97/266 [00:15<00:30,  5.52it/s]predicting train subjects:  37%|███▋      | 98/266 [00:15<00:30,  5.52it/s]predicting train subjects:  37%|███▋      | 99/266 [00:15<00:30,  5.51it/s]predicting train subjects:  38%|███▊      | 100/266 [00:16<00:29,  5.57it/s]predicting train subjects:  38%|███▊      | 101/266 [00:16<00:29,  5.64it/s]predicting train subjects:  38%|███▊      | 102/266 [00:16<00:28,  5.68it/s]predicting train subjects:  39%|███▊      | 103/266 [00:16<00:28,  5.71it/s]predicting train subjects:  39%|███▉      | 104/266 [00:16<00:28,  5.74it/s]predicting train subjects:  39%|███▉      | 105/266 [00:16<00:27,  5.78it/s]predicting train subjects:  40%|███▉      | 106/266 [00:17<00:27,  5.77it/s]predicting train subjects:  40%|████      | 107/266 [00:17<00:27,  5.79it/s]predicting train subjects:  41%|████      | 108/266 [00:17<00:27,  5.79it/s]predicting train subjects:  41%|████      | 109/266 [00:17<00:27,  5.80it/s]predicting train subjects:  41%|████▏     | 110/266 [00:17<00:26,  5.80it/s]predicting train subjects:  42%|████▏     | 111/266 [00:17<00:26,  5.75it/s]predicting train subjects:  42%|████▏     | 112/266 [00:18<00:26,  5.76it/s]predicting train subjects:  42%|████▏     | 113/266 [00:18<00:26,  5.77it/s]predicting train subjects:  43%|████▎     | 114/266 [00:18<00:26,  5.76it/s]predicting train subjects:  43%|████▎     | 115/266 [00:18<00:26,  5.77it/s]predicting train subjects:  44%|████▎     | 116/266 [00:18<00:25,  5.78it/s]predicting train subjects:  44%|████▍     | 117/266 [00:18<00:25,  5.78it/s]predicting train subjects:  44%|████▍     | 118/266 [00:19<00:24,  6.08it/s]predicting train subjects:  45%|████▍     | 119/266 [00:19<00:23,  6.36it/s]predicting train subjects:  45%|████▌     | 120/266 [00:19<00:22,  6.59it/s]predicting train subjects:  45%|████▌     | 121/266 [00:19<00:21,  6.71it/s]predicting train subjects:  46%|████▌     | 122/266 [00:19<00:21,  6.79it/s]predicting train subjects:  46%|████▌     | 123/266 [00:19<00:20,  6.84it/s]predicting train subjects:  47%|████▋     | 124/266 [00:19<00:20,  6.88it/s]predicting train subjects:  47%|████▋     | 125/266 [00:20<00:20,  6.90it/s]predicting train subjects:  47%|████▋     | 126/266 [00:20<00:20,  6.91it/s]predicting train subjects:  48%|████▊     | 127/266 [00:20<00:19,  6.98it/s]predicting train subjects:  48%|████▊     | 128/266 [00:20<00:19,  7.04it/s]predicting train subjects:  48%|████▊     | 129/266 [00:20<00:19,  7.04it/s]predicting train subjects:  49%|████▉     | 130/266 [00:20<00:19,  7.01it/s]predicting train subjects:  49%|████▉     | 131/266 [00:20<00:19,  7.02it/s]predicting train subjects:  50%|████▉     | 132/266 [00:21<00:19,  6.96it/s]predicting train subjects:  50%|█████     | 133/266 [00:21<00:19,  6.95it/s]predicting train subjects:  50%|█████     | 134/266 [00:21<00:18,  6.99it/s]predicting train subjects:  51%|█████     | 135/266 [00:21<00:18,  7.02it/s]predicting train subjects:  51%|█████     | 136/266 [00:21<00:18,  6.98it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:21<00:18,  6.92it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:21<00:18,  6.89it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:22<00:18,  6.85it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:22<00:18,  6.85it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:22<00:18,  6.83it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:22<00:18,  6.89it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:22<00:17,  6.85it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:22<00:17,  6.84it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:22<00:17,  6.82it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:23<00:17,  6.80it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:23<00:17,  6.80it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:23<00:17,  6.82it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:23<00:17,  6.82it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:23<00:16,  6.83it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:23<00:16,  6.80it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:24<00:16,  6.80it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:24<00:16,  6.80it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:24<00:17,  6.51it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:24<00:17,  6.22it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:24<00:18,  6.09it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:24<00:18,  5.77it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:25<00:18,  5.75it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:25<00:18,  5.75it/s]predicting train subjects:  60%|██████    | 160/266 [00:25<00:18,  5.78it/s]predicting train subjects:  61%|██████    | 161/266 [00:25<00:18,  5.77it/s]predicting train subjects:  61%|██████    | 162/266 [00:25<00:18,  5.75it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:25<00:17,  5.79it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:26<00:17,  5.79it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:26<00:17,  5.71it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:26<00:17,  5.66it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:26<00:17,  5.69it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:26<00:17,  5.65it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:26<00:16,  5.73it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:27<00:16,  5.71it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:27<00:16,  5.75it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:27<00:15,  5.95it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:27<00:18,  5.13it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:27<00:18,  5.02it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:28<00:19,  4.56it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:28<00:17,  5.06it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:28<00:16,  5.39it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:28<00:15,  5.70it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:28<00:14,  5.98it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:28<00:13,  6.18it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:29<00:13,  6.30it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:29<00:13,  6.36it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:29<00:12,  6.40it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:29<00:12,  6.45it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:29<00:12,  6.53it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:29<00:12,  6.55it/s]predicting train subjects:  70%|███████   | 187/266 [00:30<00:12,  6.49it/s]predicting train subjects:  71%|███████   | 188/266 [00:30<00:12,  6.49it/s]predicting train subjects:  71%|███████   | 189/266 [00:30<00:11,  6.51it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:30<00:11,  6.52it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:30<00:11,  6.56it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:30<00:11,  6.62it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:30<00:10,  6.65it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:31<00:10,  6.64it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:31<00:11,  6.21it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:31<00:11,  6.04it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:31<00:11,  5.91it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:31<00:11,  5.84it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:31<00:11,  5.78it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:32<00:11,  5.72it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:32<00:11,  5.62it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:32<00:11,  5.57it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:32<00:11,  5.50it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:32<00:11,  5.49it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:33<00:11,  5.50it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:33<00:10,  5.54it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:33<00:10,  5.56it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:33<00:10,  5.55it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:33<00:10,  5.60it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:33<00:09,  5.64it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:34<00:09,  5.62it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:34<00:09,  5.51it/s]predicting train subjects:  80%|████████  | 213/266 [00:34<00:09,  5.37it/s]predicting train subjects:  80%|████████  | 214/266 [00:34<00:09,  5.60it/s]predicting train subjects:  81%|████████  | 215/266 [00:34<00:08,  5.75it/s]predicting train subjects:  81%|████████  | 216/266 [00:35<00:08,  5.82it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:35<00:08,  5.86it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:35<00:08,  5.90it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:35<00:07,  5.94it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:35<00:07,  5.95it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:35<00:07,  5.97it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:36<00:07,  6.01it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:36<00:07,  6.00it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:36<00:07,  5.95it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:36<00:06,  5.96it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:36<00:06,  5.92it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:36<00:06,  5.85it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:37<00:06,  5.88it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:37<00:06,  5.95it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:37<00:06,  5.97it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:37<00:05,  6.38it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:37<00:05,  6.74it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:37<00:04,  6.95it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:37<00:04,  7.11it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:38<00:04,  7.23it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:38<00:04,  7.31it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:38<00:03,  7.37it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:38<00:03,  7.46it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:38<00:03,  7.50it/s]predicting train subjects:  90%|█████████ | 240/266 [00:38<00:03,  7.53it/s]predicting train subjects:  91%|█████████ | 241/266 [00:38<00:03,  7.50it/s]predicting train subjects:  91%|█████████ | 242/266 [00:38<00:03,  7.52it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:39<00:03,  7.51it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:39<00:02,  7.53it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:39<00:02,  7.50it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:39<00:02,  7.50it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:39<00:02,  7.46it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:39<00:02,  7.35it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:39<00:02,  7.08it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:40<00:02,  6.98it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:40<00:02,  6.91it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:40<00:02,  6.83it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:40<00:01,  6.81it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:40<00:01,  6.77it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:40<00:01,  6.72it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:40<00:01,  6.67it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:41<00:01,  6.57it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:41<00:01,  6.60it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:41<00:01,  6.54it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:41<00:00,  6.49it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:41<00:00,  6.56it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:41<00:00,  6.60it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:42<00:00,  6.64it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:42<00:00,  6.68it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:42<00:00,  6.71it/s]predicting train subjects: 100%|██████████| 266/266 [00:42<00:00,  6.64it/s]predicting train subjects: 100%|██████████| 266/266 [00:42<00:00,  6.26it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  6.43it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  6.60it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  6.61it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  6.34it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  6.44it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<00:46,  5.76it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<00:44,  5.92it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<00:43,  6.09it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:00<00:43,  6.07it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:00<00:42,  6.10it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:00<00:41,  6.24it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:01<00:41,  6.26it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:01<00:40,  6.38it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:01<00:40,  6.32it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:01<00:40,  6.39it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:01<00:40,  6.33it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:01<00:40,  6.25it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:02<00:39,  6.34it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:02<00:39,  6.39it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:02<00:39,  6.33it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:02<00:39,  6.27it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:02<00:39,  6.37it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:02<00:38,  6.41it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:02<00:38,  6.48it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:03<00:38,  6.41it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:03<00:38,  6.35it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:03<00:38,  6.26it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:03<00:37,  6.42it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:03<00:37,  6.44it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:03<00:37,  6.39it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:04<00:36,  6.56it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:04<00:36,  6.54it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:04<00:36,  6.45it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:04<00:36,  6.44it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:04<00:36,  6.46it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:04<00:35,  6.55it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:05<00:35,  6.52it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:05<00:35,  6.48it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:05<00:35,  6.49it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:05<00:35,  6.50it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:05<00:35,  6.49it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:05<00:34,  6.58it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:05<00:34,  6.54it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:06<00:34,  6.51it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:06<00:34,  6.59it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:06<00:34,  6.52it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:06<00:33,  6.64it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:06<00:33,  6.58it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:06<00:33,  6.60it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:06<00:32,  6.71it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:07<00:32,  6.81it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:07<00:32,  6.72it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:07<00:32,  6.74it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:07<00:32,  6.76it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:07<00:31,  6.82it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:07<00:31,  6.73it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:08<00:32,  6.59it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:08<00:32,  6.65it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:08<00:32,  6.56it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:08<00:32,  6.44it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:08<00:32,  6.45it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:08<00:31,  6.59it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:08<00:31,  6.53it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:09<00:31,  6.51it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:09<00:32,  6.38it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:09<00:33,  6.21it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:09<00:33,  6.11it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:09<00:33,  6.04it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:09<00:33,  6.09it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:10<00:33,  6.04it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:10<00:32,  6.11it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:10<00:32,  6.07it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:10<00:32,  6.18it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:10<00:32,  6.15it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:10<00:32,  6.02it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:11<00:32,  5.95it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:11<00:33,  5.79it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:11<00:32,  5.99it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:11<00:32,  5.99it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:11<00:31,  5.97it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:11<00:31,  6.03it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:12<00:32,  5.85it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:12<00:32,  5.77it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:12<00:30,  6.03it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:12<00:30,  6.17it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:12<00:31,  5.92it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:12<00:31,  5.81it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:13<00:32,  5.63it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:13<00:32,  5.56it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:13<00:33,  5.46it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:13<00:33,  5.34it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:13<00:33,  5.29it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:14<00:34,  5.22it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:14<00:33,  5.28it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:14<00:33,  5.26it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:14<00:33,  5.28it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:14<00:33,  5.25it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:15<00:33,  5.24it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:15<00:32,  5.25it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:15<00:32,  5.30it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:15<00:31,  5.34it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:15<00:31,  5.39it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:15<00:30,  5.43it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:16<00:30,  5.46it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:16<00:30,  5.41it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:16<00:29,  5.51it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:16<00:29,  5.60it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:16<00:29,  5.56it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:17<00:29,  5.52it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:17<00:28,  5.60it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:17<00:28,  5.53it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:17<00:29,  5.45it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:17<00:28,  5.50it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:17<00:28,  5.57it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:18<00:28,  5.52it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:18<00:28,  5.52it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:18<00:27,  5.60it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:18<00:27,  5.58it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:18<00:26,  5.63it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:19<00:26,  5.63it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:19<00:26,  5.67it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:19<00:26,  5.68it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:19<00:24,  5.93it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:19<00:24,  6.08it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:19<00:23,  6.30it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:19<00:22,  6.52it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:20<00:21,  6.60it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:20<00:21,  6.66it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:20<00:21,  6.66it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:20<00:21,  6.68it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:20<00:21,  6.62it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:20<00:20,  6.64it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:21<00:20,  6.71it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:21<00:20,  6.61it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:21<00:20,  6.56it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:21<00:20,  6.52it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:21<00:20,  6.48it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:21<00:20,  6.61it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:21<00:20,  6.55it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:22<00:19,  6.66it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:22<00:19,  6.61it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:22<00:19,  6.56it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:22<00:19,  6.59it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:22<00:19,  6.59it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:22<00:19,  6.55it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:23<00:19,  6.50it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:23<00:19,  6.47it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:23<00:18,  6.48it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:23<00:18,  6.50it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:23<00:18,  6.51it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:23<00:18,  6.59it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:23<00:18,  6.56it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:24<00:18,  6.40it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:24<00:18,  6.22it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:24<00:18,  6.36it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:24<00:17,  6.46it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:24<00:17,  6.43it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:24<00:17,  6.44it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:25<00:18,  6.08it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:25<00:18,  6.02it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:25<00:18,  5.86it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:25<00:19,  5.69it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:25<00:19,  5.66it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:25<00:19,  5.54it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:26<00:19,  5.48it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:26<00:19,  5.44it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:26<00:19,  5.44it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:26<00:18,  5.53it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:26<00:18,  5.58it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:27<00:18,  5.51it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:27<00:17,  5.57it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:27<00:17,  5.63it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:27<00:17,  5.64it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:27<00:17,  5.69it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:27<00:16,  5.70it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:28<00:16,  5.72it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:28<00:15,  5.93it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:28<00:15,  5.83it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:28<00:15,  5.94it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:28<00:14,  6.34it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:28<00:13,  6.47it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:29<00:13,  6.50it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:29<00:13,  6.48it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:29<00:13,  6.46it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:29<00:13,  6.53it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:29<00:13,  6.49it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:29<00:12,  6.48it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:29<00:12,  6.40it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:30<00:12,  6.45it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:30<00:12,  6.42it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:30<00:12,  6.42it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:30<00:12,  6.43it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:30<00:12,  6.49it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:30<00:12,  6.41it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:31<00:11,  6.40it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:31<00:11,  6.45it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:31<00:11,  6.45it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:31<00:11,  6.47it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:31<00:11,  6.47it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:31<00:11,  6.09it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:32<00:11,  5.86it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:32<00:11,  5.78it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:32<00:11,  5.76it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:32<00:11,  5.74it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:32<00:11,  5.70it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:32<00:11,  5.56it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:33<00:11,  5.52it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:33<00:11,  5.56it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:33<00:11,  5.56it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:33<00:10,  5.60it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:33<00:10,  5.60it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:34<00:10,  5.60it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:34<00:10,  5.57it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:34<00:10,  5.52it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:34<00:10,  5.50it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:34<00:10,  5.43it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:34<00:10,  5.38it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:35<00:09,  5.54it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:35<00:09,  5.65it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:35<00:08,  5.76it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:35<00:08,  5.84it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:35<00:08,  5.96it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:35<00:07,  6.01it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:36<00:07,  6.04it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:36<00:07,  6.10it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:36<00:07,  6.06it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [00:36<00:07,  6.06it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [00:36<00:07,  6.10it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [00:36<00:06,  6.02it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [00:37<00:06,  5.99it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [00:37<00:06,  5.99it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [00:37<00:06,  5.96it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [00:37<00:06,  5.97it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [00:37<00:06,  5.98it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [00:37<00:05,  6.05it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [00:38<00:05,  6.43it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [00:38<00:05,  6.67it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [00:38<00:04,  6.92it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [00:38<00:04,  7.11it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [00:38<00:04,  7.03it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [00:38<00:04,  6.91it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [00:38<00:04,  7.10it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [00:39<00:03,  7.27it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [00:39<00:03,  7.16it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [00:39<00:03,  7.30it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [00:39<00:03,  7.30it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [00:39<00:03,  7.31it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [00:39<00:03,  7.37it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [00:39<00:02,  7.38it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [00:39<00:02,  7.29it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [00:40<00:02,  7.39it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [00:40<00:02,  7.44it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [00:40<00:02,  7.40it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [00:40<00:02,  7.21it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [00:40<00:02,  7.09it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [00:40<00:02,  6.94it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [00:40<00:02,  6.91it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [00:41<00:01,  6.82it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [00:41<00:01,  6.76it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [00:41<00:01,  6.72it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [00:41<00:01,  6.73it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [00:41<00:01,  6.73it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [00:41<00:01,  6.72it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [00:42<00:01,  6.77it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [00:42<00:00,  6.74it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [00:42<00:00,  6.77it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [00:42<00:00,  6.74it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [00:42<00:00,  6.78it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [00:42<00:00,  6.74it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [00:42<00:00,  6.74it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:43<00:00,  6.66it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:43<00:00,  6.18it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 68.40it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 9/266 [00:00<00:03, 74.11it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/266 [00:00<00:03, 74.53it/s]saving BB  train1-THALAMUS:  10%|█         | 27/266 [00:00<00:03, 76.45it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:02, 78.78it/s]saving BB  train1-THALAMUS:  17%|█▋        | 44/266 [00:00<00:02, 78.36it/s]saving BB  train1-THALAMUS:  20%|█▉        | 52/266 [00:00<00:02, 78.04it/s]saving BB  train1-THALAMUS:  23%|██▎       | 61/266 [00:00<00:02, 78.32it/s]saving BB  train1-THALAMUS:  26%|██▌       | 69/266 [00:00<00:02, 76.82it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:00<00:02, 76.05it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 72.59it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 68.55it/s]saving BB  train1-THALAMUS:  38%|███▊      | 100/266 [00:01<00:02, 66.87it/s]saving BB  train1-THALAMUS:  41%|████      | 108/266 [00:01<00:02, 68.36it/s]saving BB  train1-THALAMUS:  44%|████▎     | 116/266 [00:01<00:02, 69.41it/s]saving BB  train1-THALAMUS:  47%|████▋     | 124/266 [00:01<00:01, 71.48it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 74.20it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 142/266 [00:01<00:01, 77.02it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 151/266 [00:02<00:01, 79.07it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 159/266 [00:02<00:01, 77.78it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 167/266 [00:02<00:01, 76.22it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 75.44it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 183/266 [00:02<00:01, 76.51it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 191/266 [00:02<00:01, 73.42it/s]saving BB  train1-THALAMUS:  75%|███████▍  | 199/266 [00:02<00:00, 73.39it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 207/266 [00:02<00:00, 72.92it/s]saving BB  train1-THALAMUS:  81%|████████  | 215/266 [00:02<00:00, 70.46it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 223/266 [00:03<00:00, 70.56it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 231/266 [00:03<00:00, 71.86it/s]saving BB  train1-THALAMUS:  91%|█████████ | 241/266 [00:03<00:00, 76.49it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 251/266 [00:03<00:00, 80.39it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:03<00:00, 82.43it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 75.81it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 76.50it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/266 [00:00<00:03, 79.13it/s]saving BB  train1-THALAMUS Sagittal:   6%|▋         | 17/266 [00:00<00:03, 79.57it/s]saving BB  train1-THALAMUS Sagittal:  10%|▉         | 26/266 [00:00<00:02, 80.82it/s]saving BB  train1-THALAMUS Sagittal:  13%|█▎        | 35/266 [00:00<00:02, 82.85it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 44/266 [00:00<00:02, 84.62it/s]saving BB  train1-THALAMUS Sagittal:  20%|██        | 54/266 [00:00<00:02, 86.29it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▎       | 63/266 [00:00<00:02, 85.78it/s]saving BB  train1-THALAMUS Sagittal:  27%|██▋       | 72/266 [00:00<00:02, 84.16it/s]saving BB  train1-THALAMUS Sagittal:  30%|███       | 80/266 [00:00<00:02, 81.10it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 88/266 [00:01<00:02, 77.38it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 96/266 [00:01<00:02, 74.01it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▉      | 104/266 [00:01<00:02, 73.27it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 112/266 [00:01<00:02, 73.63it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▌     | 120/266 [00:01<00:01, 73.30it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 128/266 [00:01<00:01, 73.95it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 136/266 [00:01<00:01, 75.19it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 145/266 [00:01<00:01, 78.06it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 154/266 [00:01<00:01, 79.74it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████    | 162/266 [00:02<00:01, 78.16it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 170/266 [00:02<00:01, 75.48it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 178/266 [00:02<00:01, 74.48it/s]saving BB  train1-THALAMUS Sagittal:  70%|██████▉   | 186/266 [00:02<00:01, 75.90it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 194/266 [00:02<00:00, 76.23it/s]saving BB  train1-THALAMUS Sagittal:  76%|███████▌  | 202/266 [00:02<00:00, 74.62it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▉  | 210/266 [00:02<00:00, 72.72it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 218/266 [00:02<00:00, 72.59it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▍ | 226/266 [00:02<00:00, 72.99it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 235/266 [00:03<00:00, 75.39it/s]saving BB  train1-THALAMUS Sagittal:  91%|█████████▏| 243/266 [00:03<00:00, 74.69it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▍| 252/266 [00:03<00:00, 77.96it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 261/266 [00:03<00:00, 80.17it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 77.96it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<04:30,  1.02s/it]Loading train:   1%|          | 2/266 [00:01<04:09,  1.06it/s]Loading train:   1%|          | 3/266 [00:02<03:49,  1.15it/s]Loading train:   2%|▏         | 4/266 [00:03<03:58,  1.10it/s]Loading train:   2%|▏         | 5/266 [00:04<03:30,  1.24it/s]Loading train:   2%|▏         | 6/266 [00:04<03:06,  1.40it/s]Loading train:   3%|▎         | 7/266 [00:05<02:49,  1.53it/s]Loading train:   3%|▎         | 8/266 [00:05<02:39,  1.62it/s]Loading train:   3%|▎         | 9/266 [00:06<02:32,  1.68it/s]Loading train:   4%|▍         | 10/266 [00:06<02:28,  1.72it/s]Loading train:   4%|▍         | 11/266 [00:07<02:23,  1.78it/s]Loading train:   5%|▍         | 12/266 [00:07<02:20,  1.81it/s]Loading train:   5%|▍         | 13/266 [00:08<02:18,  1.82it/s]Loading train:   5%|▌         | 14/266 [00:08<02:15,  1.86it/s]Loading train:   6%|▌         | 15/266 [00:09<02:15,  1.85it/s]Loading train:   6%|▌         | 16/266 [00:09<02:14,  1.86it/s]Loading train:   6%|▋         | 17/266 [00:10<02:12,  1.88it/s]Loading train:   7%|▋         | 18/266 [00:10<02:11,  1.88it/s]Loading train:   7%|▋         | 19/266 [00:11<02:11,  1.88it/s]Loading train:   8%|▊         | 20/266 [00:12<02:12,  1.85it/s]Loading train:   8%|▊         | 21/266 [00:12<02:13,  1.83it/s]Loading train:   8%|▊         | 22/266 [00:13<02:12,  1.84it/s]Loading train:   9%|▊         | 23/266 [00:13<02:08,  1.89it/s]Loading train:   9%|▉         | 24/266 [00:14<02:03,  1.96it/s]Loading train:   9%|▉         | 25/266 [00:14<02:00,  2.00it/s]Loading train:  10%|▉         | 26/266 [00:15<01:57,  2.04it/s]Loading train:  10%|█         | 27/266 [00:15<01:55,  2.07it/s]Loading train:  11%|█         | 28/266 [00:15<01:57,  2.03it/s]Loading train:  11%|█         | 29/266 [00:16<01:56,  2.04it/s]Loading train:  11%|█▏        | 30/266 [00:16<01:55,  2.04it/s]Loading train:  12%|█▏        | 31/266 [00:17<01:54,  2.04it/s]Loading train:  12%|█▏        | 32/266 [00:17<01:53,  2.06it/s]Loading train:  12%|█▏        | 33/266 [00:18<01:55,  2.02it/s]Loading train:  13%|█▎        | 34/266 [00:19<01:59,  1.95it/s]Loading train:  13%|█▎        | 35/266 [00:19<01:59,  1.94it/s]Loading train:  14%|█▎        | 36/266 [00:20<01:58,  1.94it/s]Loading train:  14%|█▍        | 37/266 [00:20<01:56,  1.97it/s]Loading train:  14%|█▍        | 38/266 [00:21<01:55,  1.98it/s]Loading train:  15%|█▍        | 39/266 [00:21<01:56,  1.96it/s]Loading train:  15%|█▌        | 40/266 [00:22<01:57,  1.93it/s]Loading train:  15%|█▌        | 41/266 [00:22<01:55,  1.95it/s]Loading train:  16%|█▌        | 42/266 [00:23<01:55,  1.94it/s]Loading train:  16%|█▌        | 43/266 [00:23<01:55,  1.93it/s]Loading train:  17%|█▋        | 44/266 [00:24<01:55,  1.92it/s]Loading train:  17%|█▋        | 45/266 [00:24<01:53,  1.96it/s]Loading train:  17%|█▋        | 46/266 [00:25<01:50,  1.99it/s]Loading train:  18%|█▊        | 47/266 [00:25<01:48,  2.01it/s]Loading train:  18%|█▊        | 48/266 [00:26<01:48,  2.02it/s]Loading train:  18%|█▊        | 49/266 [00:26<01:45,  2.05it/s]Loading train:  19%|█▉        | 50/266 [00:27<01:44,  2.06it/s]Loading train:  19%|█▉        | 51/266 [00:27<01:44,  2.05it/s]Loading train:  20%|█▉        | 52/266 [00:28<01:45,  2.04it/s]Loading train:  20%|█▉        | 53/266 [00:28<01:45,  2.02it/s]Loading train:  20%|██        | 54/266 [00:29<01:44,  2.03it/s]Loading train:  21%|██        | 55/266 [00:29<01:43,  2.04it/s]Loading train:  21%|██        | 56/266 [00:30<01:42,  2.04it/s]Loading train:  21%|██▏       | 57/266 [00:30<01:43,  2.03it/s]Loading train:  22%|██▏       | 58/266 [00:31<01:46,  1.96it/s]Loading train:  22%|██▏       | 59/266 [00:31<01:53,  1.82it/s]Loading train:  23%|██▎       | 60/266 [00:32<01:57,  1.76it/s]Loading train:  23%|██▎       | 61/266 [00:32<01:57,  1.75it/s]Loading train:  23%|██▎       | 62/266 [00:33<01:55,  1.76it/s]Loading train:  24%|██▎       | 63/266 [00:34<01:57,  1.73it/s]Loading train:  24%|██▍       | 64/266 [00:34<01:57,  1.71it/s]Loading train:  24%|██▍       | 65/266 [00:35<01:59,  1.69it/s]Loading train:  25%|██▍       | 66/266 [00:35<01:57,  1.71it/s]Loading train:  25%|██▌       | 67/266 [00:36<01:58,  1.69it/s]Loading train:  26%|██▌       | 68/266 [00:37<01:55,  1.72it/s]Loading train:  26%|██▌       | 69/266 [00:37<01:53,  1.73it/s]Loading train:  26%|██▋       | 70/266 [00:38<01:53,  1.73it/s]Loading train:  27%|██▋       | 71/266 [00:38<01:53,  1.72it/s]Loading train:  27%|██▋       | 72/266 [00:39<01:54,  1.69it/s]Loading train:  27%|██▋       | 73/266 [00:39<01:54,  1.69it/s]Loading train:  28%|██▊       | 74/266 [00:40<01:52,  1.71it/s]Loading train:  28%|██▊       | 75/266 [00:41<01:50,  1.73it/s]Loading train:  29%|██▊       | 76/266 [00:41<01:51,  1.70it/s]Loading train:  29%|██▉       | 77/266 [00:42<02:16,  1.39it/s]Loading train:  29%|██▉       | 78/266 [00:43<02:26,  1.29it/s]Loading train:  30%|██▉       | 79/266 [00:44<02:29,  1.25it/s]Loading train:  30%|███       | 80/266 [00:45<02:27,  1.26it/s]Loading train:  30%|███       | 81/266 [00:46<02:39,  1.16it/s]Loading train:  31%|███       | 82/266 [00:46<02:27,  1.25it/s]Loading train:  31%|███       | 83/266 [00:47<02:16,  1.34it/s]Loading train:  32%|███▏      | 84/266 [00:48<02:09,  1.40it/s]Loading train:  32%|███▏      | 85/266 [00:48<02:05,  1.44it/s]Loading train:  32%|███▏      | 86/266 [00:49<02:01,  1.48it/s]Loading train:  33%|███▎      | 87/266 [00:50<01:59,  1.50it/s]Loading train:  33%|███▎      | 88/266 [00:50<01:57,  1.51it/s]Loading train:  33%|███▎      | 89/266 [00:51<01:55,  1.53it/s]Loading train:  34%|███▍      | 90/266 [00:52<01:54,  1.54it/s]Loading train:  34%|███▍      | 91/266 [00:52<01:54,  1.53it/s]Loading train:  35%|███▍      | 92/266 [00:53<01:55,  1.51it/s]Loading train:  35%|███▍      | 93/266 [00:54<01:52,  1.54it/s]Loading train:  35%|███▌      | 94/266 [00:54<01:52,  1.53it/s]Loading train:  36%|███▌      | 95/266 [00:55<01:55,  1.48it/s]Loading train:  36%|███▌      | 96/266 [00:56<01:53,  1.49it/s]Loading train:  36%|███▋      | 97/266 [00:56<01:52,  1.50it/s]Loading train:  37%|███▋      | 98/266 [00:57<01:51,  1.51it/s]Loading train:  37%|███▋      | 99/266 [00:57<01:47,  1.55it/s]Loading train:  38%|███▊      | 100/266 [00:58<01:48,  1.53it/s]Loading train:  38%|███▊      | 101/266 [00:59<01:46,  1.56it/s]Loading train:  38%|███▊      | 102/266 [00:59<01:42,  1.60it/s]Loading train:  39%|███▊      | 103/266 [01:00<01:39,  1.63it/s]Loading train:  39%|███▉      | 104/266 [01:01<01:38,  1.65it/s]Loading train:  39%|███▉      | 105/266 [01:01<01:35,  1.68it/s]Loading train:  40%|███▉      | 106/266 [01:02<01:35,  1.67it/s]Loading train:  40%|████      | 107/266 [01:02<01:35,  1.66it/s]Loading train:  41%|████      | 108/266 [01:03<01:33,  1.69it/s]Loading train:  41%|████      | 109/266 [01:03<01:32,  1.70it/s]Loading train:  41%|████▏     | 110/266 [01:04<01:30,  1.73it/s]Loading train:  42%|████▏     | 111/266 [01:05<01:28,  1.75it/s]Loading train:  42%|████▏     | 112/266 [01:05<01:28,  1.73it/s]Loading train:  42%|████▏     | 113/266 [01:06<01:29,  1.71it/s]Loading train:  43%|████▎     | 114/266 [01:06<01:28,  1.71it/s]Loading train:  43%|████▎     | 115/266 [01:07<01:28,  1.71it/s]Loading train:  44%|████▎     | 116/266 [01:08<01:28,  1.69it/s]Loading train:  44%|████▍     | 117/266 [01:08<01:28,  1.69it/s]Loading train:  44%|████▍     | 118/266 [01:09<01:25,  1.72it/s]Loading train:  45%|████▍     | 119/266 [01:09<01:23,  1.75it/s]Loading train:  45%|████▌     | 120/266 [01:10<01:24,  1.73it/s]Loading train:  45%|████▌     | 121/266 [01:10<01:22,  1.77it/s]Loading train:  46%|████▌     | 122/266 [01:11<01:21,  1.76it/s]Loading train:  46%|████▌     | 123/266 [01:11<01:20,  1.77it/s]Loading train:  47%|████▋     | 124/266 [01:12<01:19,  1.79it/s]Loading train:  47%|████▋     | 125/266 [01:13<01:20,  1.75it/s]Loading train:  47%|████▋     | 126/266 [01:13<01:21,  1.73it/s]Loading train:  48%|████▊     | 127/266 [01:14<01:21,  1.71it/s]Loading train:  48%|████▊     | 128/266 [01:14<01:19,  1.73it/s]Loading train:  48%|████▊     | 129/266 [01:15<01:17,  1.76it/s]Loading train:  49%|████▉     | 130/266 [01:16<01:17,  1.74it/s]Loading train:  49%|████▉     | 131/266 [01:16<01:17,  1.75it/s]Loading train:  50%|████▉     | 132/266 [01:17<01:17,  1.72it/s]Loading train:  50%|█████     | 133/266 [01:17<01:16,  1.74it/s]Loading train:  50%|█████     | 134/266 [01:18<01:16,  1.73it/s]Loading train:  51%|█████     | 135/266 [01:18<01:15,  1.74it/s]Loading train:  51%|█████     | 136/266 [01:19<01:14,  1.74it/s]Loading train:  52%|█████▏    | 137/266 [01:20<01:13,  1.76it/s]Loading train:  52%|█████▏    | 138/266 [01:20<01:11,  1.80it/s]Loading train:  52%|█████▏    | 139/266 [01:21<01:10,  1.81it/s]Loading train:  53%|█████▎    | 140/266 [01:21<01:08,  1.85it/s]Loading train:  53%|█████▎    | 141/266 [01:22<01:05,  1.91it/s]Loading train:  53%|█████▎    | 142/266 [01:22<01:05,  1.90it/s]Loading train:  54%|█████▍    | 143/266 [01:23<01:04,  1.90it/s]Loading train:  54%|█████▍    | 144/266 [01:23<01:05,  1.86it/s]Loading train:  55%|█████▍    | 145/266 [01:24<01:06,  1.82it/s]Loading train:  55%|█████▍    | 146/266 [01:24<01:04,  1.85it/s]Loading train:  55%|█████▌    | 147/266 [01:25<01:04,  1.84it/s]Loading train:  56%|█████▌    | 148/266 [01:25<01:03,  1.86it/s]Loading train:  56%|█████▌    | 149/266 [01:26<01:02,  1.87it/s]Loading train:  56%|█████▋    | 150/266 [01:26<01:01,  1.88it/s]Loading train:  57%|█████▋    | 151/266 [01:27<01:01,  1.88it/s]Loading train:  57%|█████▋    | 152/266 [01:28<01:00,  1.89it/s]Loading train:  58%|█████▊    | 153/266 [01:28<01:00,  1.86it/s]Loading train:  58%|█████▊    | 154/266 [01:29<01:03,  1.76it/s]Loading train:  58%|█████▊    | 155/266 [01:29<01:04,  1.73it/s]Loading train:  59%|█████▊    | 156/266 [01:30<01:03,  1.72it/s]Loading train:  59%|█████▉    | 157/266 [01:31<01:04,  1.70it/s]Loading train:  59%|█████▉    | 158/266 [01:31<01:03,  1.69it/s]Loading train:  60%|█████▉    | 159/266 [01:32<01:03,  1.68it/s]Loading train:  60%|██████    | 160/266 [01:32<01:02,  1.71it/s]Loading train:  61%|██████    | 161/266 [01:33<01:02,  1.67it/s]Loading train:  61%|██████    | 162/266 [01:33<01:02,  1.67it/s]Loading train:  61%|██████▏   | 163/266 [01:34<01:01,  1.69it/s]Loading train:  62%|██████▏   | 164/266 [01:35<01:00,  1.68it/s]Loading train:  62%|██████▏   | 165/266 [01:35<01:02,  1.61it/s]Loading train:  62%|██████▏   | 166/266 [01:36<01:01,  1.63it/s]Loading train:  63%|██████▎   | 167/266 [01:37<00:59,  1.67it/s]Loading train:  63%|██████▎   | 168/266 [01:37<00:59,  1.65it/s]Loading train:  64%|██████▎   | 169/266 [01:38<00:59,  1.64it/s]Loading train:  64%|██████▍   | 170/266 [01:38<00:57,  1.66it/s]Loading train:  64%|██████▍   | 171/266 [01:39<00:57,  1.65it/s]Loading train:  65%|██████▍   | 172/266 [01:40<01:03,  1.48it/s]Loading train:  65%|██████▌   | 173/266 [01:41<01:10,  1.32it/s]
Epoch 00051: val_mDice did not improve from 0.51185
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [0.1961820826810949, 0.14807902510259666, 0.12576166788736978, 0.10047558622032988, 0.12176806523519404, 0.06684342552633847, 0.1306597692709343, 0.0912556662863376, 0.008332804721944472, 0.1708397143611721, 0.08908761628702574, 0.02648749801458097, 0.05646293420417636, 0.0996418887493657, 0.1212460798960106, 0.019276017067479154, 0.04204736503900266, 0.06236205995082855, 0.05235858378457088, 0.0742213051108753, 0.019645919110260757, 0.0443610291855008, 0.03727033296052147, 0.08116879474882986, 0.13407675279121772, 0.02482011738945456, 0.05706263406603944, 0.004476575290455538, 0.0779055064799739, 0.02450183209250955, 0.03599232084610883, 0.13346251757705913, 0.1018955205001083, 0.13226665001289517, 0.17868235590411166, 0.09473164671776342, 0.09563221183477663, 0.0032504650891995897, 0.0384583853039087, 0.07839440364463657, 0.0007868043932260252, 0.04585671278775907, -0.031366647458543964, 0.035563549574683696, 0.05868220855208004, 0.05704551643016292, 0.05489106856140436, 0.0566803748701133, 0.05544732598697438, -0.025972845799782696, 0.0560576693684447], 'val_acc': [0.9921887855903775, 0.991215915072198, 0.9766289790471395, 0.9932959582291397, 0.9936290137908038, 0.9936321459564508, 0.9931676177417531, 0.993527283855513, 0.9933983134288414, 0.9934737530409121, 0.9933344628296646, 0.9935961494258806, 0.9930514856880787, 0.9933557440252865, 0.9933466747695324, 0.9936208795098698, 0.9910227784923479, 0.9933770298957825, 0.9933150562585569, 0.9933989398619708, 0.9933807896632775, 0.9931622977350273, 0.9935845604129866, 0.9933767248602474, 0.993095313801485, 0.9935432438756905, 0.9935207098138099, 0.9936659499710682, 0.9936781560673433, 0.9937420171849868, 0.9935006744721356, 0.9935610902075674, 0.9936913088256237, 0.993529783744438, 0.9884440805397782, 0.993438696160036, 0.9935009865199819, 0.9938265318964042, 0.9937667449315389, 0.9935895718780219, 0.9934321244557699, 0.9936863020354626, 0.993564530914905, 0.9935986551583982, 0.9935861288332472, 0.9934427644692215, 0.9933598170093462, 0.993393624530119, 0.9933954956484776, 0.9935138213868234, 0.9935009876887003], 'val_mDice': [0.45577083212632646, 0.47337711880020067, 0.1722273610386194, 0.48899796899960296, 0.4962273684202456, 0.47754378529223596, 0.5066253426028233, 0.507361033967897, 0.4770698208434909, 0.5051792960314468, 0.5118458621642169, 0.497803531171253, 0.49861450580989614, 0.48729949254615634, 0.4791802360731013, 0.4946917102617376, 0.4510780073994515, 0.48865185546524387, 0.4798689407716487, 0.507759024699529, 0.4822639125103718, 0.4834724036700164, 0.49752684401384756, 0.4883067167418845, 0.5002913486723807, 0.4831804095530967, 0.4971805775866789, 0.4845459656972511, 0.49415669924301076, 0.4905004650445692, 0.5000826716423035, 0.5010005948590297, 0.4856739511676863, 0.5029638453113376, 0.41368362891907784, 0.5003311512809173, 0.4984592736936083, 0.48936325019481136, 0.4933352821013507, 0.4936978042710061, 0.4920899595950883, 0.4801954755596147, 0.47786465184945687, 0.5009103291759304, 0.4937116522707191, 0.49725273886903665, 0.5016350795734016, 0.49795620347939284, 0.5005333861180606, 0.49658748449063767, 0.4991886019706726], 'loss': [0.10012633103360871, 0.06505547175434111, 0.05802151691005337, 0.05233575150336875, 0.05142495287662802, 0.047605567038844374, 0.04676396078894075, 0.04518185221127872, 0.04437240069920247, 0.04356159494887902, 0.04216489494486762, 0.041080551724242145, 0.0391560604464314, 0.039808991386589776, 0.03856517148053854, 0.037135135254656275, 0.03693701966024141, 0.036924629146262926, 0.036124753740523784, 0.036388092668640466, 0.03492068994057709, 0.035359468606146034, 0.03443270797797422, 0.0339603235959481, 0.03645997622562618, 0.03388227891854206, 0.03280343263018382, 0.031168036855900343, 0.03070316551085558, 0.030808774568605278, 0.030263006189968945, 0.02987644571986276, 0.030553221495050662, 0.03003191062237516, 0.029669091572392416, 0.02983430912104789, 0.029207151776810568, 0.02968601324474833, 0.02826965228566192, 0.02968681685253394, 0.02869439585680113, 0.028269728005489263, 0.027982152084040295, 0.02753173493712264, 0.027465739683841223, 0.026897368591300624, 0.026909105212096447, 0.027363806961237545, 0.027097239463471676, 0.027300355930125825, 0.026902613815605235], 'acc': [0.9896981642588386, 0.9933634644866799, 0.994077658252736, 0.9945334678690134, 0.9946042756967064, 0.9949213137914693, 0.9950384913764772, 0.9951570128796859, 0.9952617388631313, 0.9953433893647341, 0.9954465416202292, 0.9955284059175673, 0.9956614838448637, 0.9956289220034734, 0.9957207073872318, 0.9957753069815976, 0.9958088243961584, 0.9959034161511517, 0.9958977843648025, 0.9958687329647857, 0.9959766558262155, 0.9959755805214844, 0.9960453556285803, 0.9960906188624835, 0.9960117511987783, 0.9961157457464522, 0.9962812950653588, 0.9962920914957765, 0.996333893693096, 0.9963829932172431, 0.9963682721843088, 0.9964008336729067, 0.9964014557084045, 0.9964251378273885, 0.9964455500230395, 0.9964585750093174, 0.9964674125349695, 0.9964309143520637, 0.9965094744429353, 0.9964835546300725, 0.9964966306882582, 0.9965734363003449, 0.9965861699699159, 0.9965989394825168, 0.9965946970208429, 0.9966180970130196, 0.996617435433629, 0.9966101449447508, 0.9966265872317142, 0.9966293758215136, 0.9966441375812333], 'mDice': [0.805136747728212, 0.8732959903542747, 0.8869807177454515, 0.898103357275364, 0.8998847377941515, 0.9073514837013107, 0.9089705544125977, 0.9120622388532149, 0.9136284942179529, 0.9152071581733958, 0.9179399856589685, 0.9200650962142156, 0.9238436554358562, 0.922555581688957, 0.9249915291212539, 0.9278211697701728, 0.9281925152121906, 0.9281723376547045, 0.9297715326536485, 0.929263817487864, 0.932133988229935, 0.9312677271151816, 0.9330732188014224, 0.9339942365654774, 0.9290371385680705, 0.9341356126608965, 0.9361968644813757, 0.93945902290606, 0.9403626402608822, 0.9401311577698044, 0.9412227789690081, 0.9419885144620807, 0.9406270351828168, 0.941656204808549, 0.9423756718441869, 0.9420414060321375, 0.9432778800245655, 0.9423449727862957, 0.9451333449464205, 0.9423134116106687, 0.9442898724205445, 0.9450990460825583, 0.9456601458148395, 0.9465590205968987, 0.9466939135553224, 0.9478120935127171, 0.9477798472788374, 0.9468776615146198, 0.9474002715881775, 0.9470017753156251, 0.9477878766570941], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label valuesLoading train:  65%|██████▌   | 174/266 [01:42<01:11,  1.29it/s]Loading train:  66%|██████▌   | 175/266 [01:42<01:08,  1.33it/s]Loading train:  66%|██████▌   | 176/266 [01:43<01:08,  1.32it/s]Loading train:  67%|██████▋   | 177/266 [01:44<01:01,  1.44it/s]Loading train:  67%|██████▋   | 178/266 [01:44<00:57,  1.54it/s]Loading train:  67%|██████▋   | 179/266 [01:45<00:54,  1.60it/s]Loading train:  68%|██████▊   | 180/266 [01:45<00:52,  1.63it/s]Loading train:  68%|██████▊   | 181/266 [01:46<00:51,  1.66it/s]Loading train:  68%|██████▊   | 182/266 [01:46<00:50,  1.67it/s]Loading train:  69%|██████▉   | 183/266 [01:47<00:49,  1.69it/s]Loading train:  69%|██████▉   | 184/266 [01:48<00:48,  1.69it/s]Loading train:  70%|██████▉   | 185/266 [01:48<00:46,  1.73it/s]Loading train:  70%|██████▉   | 186/266 [01:49<00:45,  1.74it/s]Loading train:  70%|███████   | 187/266 [01:49<00:44,  1.78it/s]Loading train:  71%|███████   | 188/266 [01:50<00:44,  1.75it/s]Loading train:  71%|███████   | 189/266 [01:50<00:43,  1.78it/s]Loading train:  71%|███████▏  | 190/266 [01:51<00:43,  1.73it/s]Loading train:  72%|███████▏  | 191/266 [01:52<00:43,  1.71it/s]Loading train:  72%|███████▏  | 192/266 [01:52<00:42,  1.75it/s]Loading train:  73%|███████▎  | 193/266 [01:53<00:41,  1.76it/s]Loading train:  73%|███████▎  | 194/266 [01:53<00:39,  1.81it/s]Loading train:  73%|███████▎  | 195/266 [01:54<00:39,  1.81it/s]Loading train:  74%|███████▎  | 196/266 [01:54<00:38,  1.81it/s]Loading train:  74%|███████▍  | 197/266 [01:55<00:37,  1.82it/s]Loading train:  74%|███████▍  | 198/266 [01:55<00:38,  1.79it/s]Loading train:  75%|███████▍  | 199/266 [01:56<00:37,  1.80it/s]Loading train:  75%|███████▌  | 200/266 [01:57<00:37,  1.78it/s]Loading train:  76%|███████▌  | 201/266 [01:57<00:36,  1.76it/s]Loading train:  76%|███████▌  | 202/266 [01:58<00:36,  1.75it/s]Loading train:  76%|███████▋  | 203/266 [01:58<00:35,  1.77it/s]Loading train:  77%|███████▋  | 204/266 [01:59<00:35,  1.76it/s]Loading train:  77%|███████▋  | 205/266 [01:59<00:34,  1.74it/s]Loading train:  77%|███████▋  | 206/266 [02:00<00:34,  1.73it/s]Loading train:  78%|███████▊  | 207/266 [02:01<00:34,  1.71it/s]Loading train:  78%|███████▊  | 208/266 [02:01<00:33,  1.76it/s]Loading train:  79%|███████▊  | 209/266 [02:02<00:32,  1.78it/s]Loading train:  79%|███████▉  | 210/266 [02:02<00:31,  1.79it/s]Loading train:  79%|███████▉  | 211/266 [02:03<00:30,  1.81it/s]Loading train:  80%|███████▉  | 212/266 [02:03<00:29,  1.81it/s]Loading train:  80%|████████  | 213/266 [02:04<00:30,  1.72it/s]Loading train:  80%|████████  | 214/266 [02:05<00:30,  1.70it/s]Loading train:  81%|████████  | 215/266 [02:05<00:30,  1.68it/s]Loading train:  81%|████████  | 216/266 [02:06<00:29,  1.67it/s]Loading train:  82%|████████▏ | 217/266 [02:06<00:29,  1.64it/s]Loading train:  82%|████████▏ | 218/266 [02:07<00:29,  1.63it/s]Loading train:  82%|████████▏ | 219/266 [02:08<00:39,  1.19it/s]Loading train:  83%|████████▎ | 220/266 [02:13<01:32,  2.01s/it]Loading train:  83%|████████▎ | 221/266 [02:17<01:58,  2.63s/it]Loading train:  83%|████████▎ | 222/266 [02:22<02:20,  3.19s/it]Loading train:  84%|████████▍ | 223/266 [02:26<02:32,  3.55s/it]Loading train:  84%|████████▍ | 224/266 [02:31<02:40,  3.81s/it]Loading train:  85%|████████▍ | 225/266 [02:35<02:44,  4.02s/it]Loading train:  85%|████████▍ | 226/266 [02:40<02:52,  4.31s/it]Loading train:  85%|████████▌ | 227/266 [02:45<02:54,  4.47s/it]Loading train:  86%|████████▌ | 228/266 [02:50<02:52,  4.53s/it]Loading train:  86%|████████▌ | 229/266 [02:54<02:48,  4.54s/it]Loading train:  86%|████████▋ | 230/266 [02:59<02:47,  4.66s/it]Loading train:  87%|████████▋ | 231/266 [03:03<02:31,  4.33s/it]Loading train:  87%|████████▋ | 232/266 [03:06<02:17,  4.06s/it]Loading train:  88%|████████▊ | 233/266 [03:09<02:05,  3.80s/it]Loading train:  88%|████████▊ | 234/266 [03:13<01:59,  3.72s/it]Loading train:  88%|████████▊ | 235/266 [03:16<01:53,  3.65s/it]Loading train:  89%|████████▊ | 236/266 [03:20<01:47,  3.58s/it]Loading train:  89%|████████▉ | 237/266 [03:23<01:44,  3.59s/it]Loading train:  89%|████████▉ | 238/266 [03:27<01:38,  3.52s/it]Loading train:  90%|████████▉ | 239/266 [03:30<01:35,  3.53s/it]Loading train:  90%|█████████ | 240/266 [03:34<01:30,  3.50s/it]Loading train:  91%|█████████ | 241/266 [03:37<01:26,  3.48s/it]Loading train:  91%|█████████ | 242/266 [03:40<01:22,  3.45s/it]Loading train:  91%|█████████▏| 243/266 [03:44<01:18,  3.43s/it]Loading train:  92%|█████████▏| 244/266 [03:47<01:14,  3.39s/it]Loading train:  92%|█████████▏| 245/266 [03:50<01:10,  3.36s/it]Loading train:  92%|█████████▏| 246/266 [03:54<01:07,  3.40s/it]Loading train:  93%|█████████▎| 247/266 [03:57<01:04,  3.37s/it]Loading train:  93%|█████████▎| 248/266 [04:01<01:00,  3.36s/it]Loading train:  94%|█████████▎| 249/266 [04:05<01:01,  3.61s/it]Loading train:  94%|█████████▍| 250/266 [04:09<00:59,  3.73s/it]Loading train:  94%|█████████▍| 251/266 [04:13<00:57,  3.81s/it]Loading train:  95%|█████████▍| 252/266 [04:17<00:54,  3.86s/it]Loading train:  95%|█████████▌| 253/266 [04:21<00:51,  3.95s/it]Loading train:  95%|█████████▌| 254/266 [04:25<00:47,  3.96s/it]Loading train:  96%|█████████▌| 255/266 [04:29<00:43,  3.99s/it]Loading train:  96%|█████████▌| 256/266 [04:33<00:40,  4.03s/it]Loading train:  97%|█████████▋| 257/266 [04:37<00:36,  4.09s/it]Loading train:  97%|█████████▋| 258/266 [04:41<00:32,  4.08s/it]Loading train:  97%|█████████▋| 259/266 [04:45<00:28,  4.06s/it]Loading train:  98%|█████████▊| 260/266 [04:49<00:24,  4.06s/it]Loading train:  98%|█████████▊| 261/266 [04:54<00:20,  4.09s/it]Loading train:  98%|█████████▊| 262/266 [04:58<00:16,  4.07s/it]Loading train:  99%|█████████▉| 263/266 [05:02<00:12,  4.08s/it]Loading train:  99%|█████████▉| 264/266 [05:06<00:08,  4.08s/it]Loading train: 100%|█████████▉| 265/266 [05:10<00:04,  4.05s/it]Loading train: 100%|██████████| 266/266 [05:14<00:00,  4.10s/it]Loading train: 100%|██████████| 266/266 [05:14<00:00,  1.18s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 45.90it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:05, 45.08it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:05, 45.78it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:05, 44.14it/s]concatenating: train:  10%|▉         | 26/266 [00:00<00:05, 46.14it/s]concatenating: train:  12%|█▏        | 31/266 [00:00<00:05, 46.80it/s]concatenating: train:  14%|█▎        | 36/266 [00:00<00:04, 47.07it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:04, 47.06it/s]concatenating: train:  18%|█▊        | 47/266 [00:01<00:04, 47.58it/s]concatenating: train:  20%|█▉        | 52/266 [00:01<00:04, 47.49it/s]concatenating: train:  21%|██▏       | 57/266 [00:01<00:04, 44.56it/s]concatenating: train:  23%|██▎       | 62/266 [00:01<00:04, 43.44it/s]concatenating: train:  25%|██▌       | 67/266 [00:01<00:04, 42.35it/s]concatenating: train:  27%|██▋       | 72/266 [00:01<00:04, 42.01it/s]concatenating: train:  29%|██▉       | 77/266 [00:01<00:04, 43.33it/s]concatenating: train:  31%|███       | 82/266 [00:01<00:04, 42.05it/s]concatenating: train:  33%|███▎      | 87/266 [00:01<00:04, 42.51it/s]concatenating: train:  35%|███▍      | 92/266 [00:02<00:04, 41.93it/s]concatenating: train:  36%|███▋      | 97/266 [00:02<00:04, 41.01it/s]concatenating: train:  38%|███▊      | 102/266 [00:02<00:03, 41.37it/s]concatenating: train:  40%|████      | 107/266 [00:02<00:03, 41.04it/s]concatenating: train:  42%|████▏     | 112/266 [00:02<00:03, 42.42it/s]concatenating: train:  44%|████▍     | 117/266 [00:02<00:03, 43.76it/s]concatenating: train:  46%|████▌     | 122/266 [00:02<00:03, 41.76it/s]concatenating: train:  48%|████▊     | 127/266 [00:02<00:03, 40.96it/s]concatenating: train:  50%|████▉     | 132/266 [00:03<00:03, 40.41it/s]concatenating: train:  52%|█████▏    | 137/266 [00:03<00:03, 40.41it/s]concatenating: train:  53%|█████▎    | 142/266 [00:03<00:02, 41.70it/s]concatenating: train:  55%|█████▌    | 147/266 [00:03<00:02, 42.27it/s]concatenating: train:  57%|█████▋    | 152/266 [00:03<00:02, 43.76it/s]concatenating: train:  59%|█████▉    | 157/266 [00:03<00:02, 43.31it/s]concatenating: train:  61%|██████    | 162/266 [00:03<00:02, 41.05it/s]concatenating: train:  63%|██████▎   | 167/266 [00:03<00:02, 41.23it/s]concatenating: train:  65%|██████▍   | 172/266 [00:03<00:02, 41.94it/s]concatenating: train:  67%|██████▋   | 177/266 [00:04<00:02, 42.58it/s]concatenating: train:  68%|██████▊   | 182/266 [00:04<00:02, 41.47it/s]concatenating: train:  70%|███████   | 187/266 [00:04<00:01, 41.84it/s]concatenating: train:  72%|███████▏  | 192/266 [00:04<00:01, 41.62it/s]concatenating: train:  74%|███████▍  | 197/266 [00:04<00:01, 43.51it/s]concatenating: train:  76%|███████▋  | 203/266 [00:04<00:01, 44.93it/s]concatenating: train:  78%|███████▊  | 208/266 [00:04<00:01, 45.67it/s]concatenating: train:  80%|████████  | 213/266 [00:04<00:01, 46.78it/s]concatenating: train:  82%|████████▏ | 218/266 [00:05<00:01, 45.60it/s]concatenating: train:  84%|████████▍ | 223/266 [00:05<00:00, 43.49it/s]concatenating: train:  86%|████████▌ | 228/266 [00:05<00:00, 42.86it/s]concatenating: train:  88%|████████▊ | 233/266 [00:05<00:00, 43.01it/s]concatenating: train:  89%|████████▉ | 238/266 [00:05<00:00, 43.54it/s]concatenating: train:  91%|█████████▏| 243/266 [00:05<00:00, 43.89it/s]concatenating: train:  93%|█████████▎| 248/266 [00:05<00:00, 44.01it/s]concatenating: train:  95%|█████████▌| 253/266 [00:05<00:00, 45.04it/s]concatenating: train:  97%|█████████▋| 258/266 [00:05<00:00, 45.71it/s]concatenating: train:  99%|█████████▉| 263/266 [00:06<00:00, 46.20it/s]concatenating: train: 100%|██████████| 266/266 [00:06<00:00, 43.58it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:13<00:39, 13.26s/it]Loading test:  50%|█████     | 2/4 [00:21<00:23, 11.83s/it]Loading test:  75%|███████▌  | 3/4 [00:32<00:11, 11.45s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 12.22s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.59s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 67.89it/s] min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 52, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 26, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 26, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 26, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 26, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 26, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 26, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 26, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 26, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 13, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 13, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 13, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 13, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 13, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 13, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 13, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 13, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 13, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 13, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 26, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 26, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 26, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 26, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 26, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 26, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 26, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 26, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 26, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 26, 280)  0           concatenate_4[0][0]              2020-01-22 06:24:47.928558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 06:24:47.928657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 06:24:47.928673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 06:24:47.928681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 06:24:47.928998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 52, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 52, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 52, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 52, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 52, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 52, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 52, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 52, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 52, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 52, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.84031975e-02 3.28090299e-02 8.45619916e-02 1.02698597e-02
 2.88072412e-02 7.67109261e-03 8.68491215e-02 1.12977982e-01
 9.17343691e-02 1.37658634e-02 2.77081005e-01 1.84830650e-01
 2.38596878e-04]
Train on 10390 samples, validate on 158 samples
Epoch 1/300
 - 31s - loss: 0.5645 - acc: 0.9184 - mDice: 0.3917 - val_loss: 0.6837 - val_acc: 0.9500 - val_mDice: 0.2611

Epoch 00001: val_mDice improved from -inf to 0.26109, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 26s - loss: 0.4072 - acc: 0.9413 - mDice: 0.5609 - val_loss: 0.6535 - val_acc: 0.9535 - val_mDice: 0.2936

Epoch 00002: val_mDice improved from 0.26109 to 0.29364, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 26s - loss: 0.3685 - acc: 0.9458 - mDice: 0.6027 - val_loss: 0.6520 - val_acc: 0.9512 - val_mDice: 0.2951

Epoch 00003: val_mDice improved from 0.29364 to 0.29514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 26s - loss: 0.3428 - acc: 0.9486 - mDice: 0.6305 - val_loss: 0.6585 - val_acc: 0.9541 - val_mDice: 0.2873

Epoch 00004: val_mDice did not improve from 0.29514
Epoch 5/300
 - 26s - loss: 0.3363 - acc: 0.9496 - mDice: 0.6374 - val_loss: 0.6621 - val_acc: 0.9526 - val_mDice: 0.2824

Epoch 00005: val_mDice did not improve from 0.29514
Epoch 6/300
 - 26s - loss: 0.3234 - acc: 0.9515 - mDice: 0.6513 - val_loss: 0.6489 - val_acc: 0.9554 - val_mDice: 0.2901

Epoch 00006: val_mDice did not improve from 0.29514
Epoch 7/300
 - 26s - loss: 0.3121 - acc: 0.9523 - mDice: 0.6636 - val_loss: 0.6384 - val_acc: 0.9516 - val_mDice: 0.2842

Epoch 00007: val_mDice did not improve from 0.29514
Epoch 8/300
 - 26s - loss: 0.3060 - acc: 0.9529 - mDice: 0.6701 - val_loss: 0.6216 - val_acc: 0.9520 - val_mDice: 0.2892

Epoch 00008: val_mDice did not improve from 0.29514
Epoch 9/300
 - 26s - loss: 0.3009 - acc: 0.9538 - mDice: 0.6757 - val_loss: 0.5467 - val_acc: 0.9518 - val_mDice: 0.2868

Epoch 00009: val_mDice did not improve from 0.29514
Epoch 10/300
 - 26s - loss: 0.2917 - acc: 0.9546 - mDice: 0.6856 - val_loss: 0.6282 - val_acc: 0.9528 - val_mDice: 0.2873

Epoch 00010: val_mDice did not improve from 0.29514
Epoch 11/300
 - 26s - loss: 0.2894 - acc: 0.9553 - mDice: 0.6880 - val_loss: 0.4569 - val_acc: 0.9508 - val_mDice: 0.2655

Epoch 00011: val_mDice did not improve from 0.29514
Epoch 12/300
 - 26s - loss: 0.2838 - acc: 0.9556 - mDice: 0.6941 - val_loss: 0.4246 - val_acc: 0.9532 - val_mDice: 0.2945

Epoch 00012: val_mDice did not improve from 0.29514
Epoch 13/300
 - 25s - loss: 0.2771 - acc: 0.9563 - mDice: 0.7013 - val_loss: 0.4960 - val_acc: 0.9530 - val_mDice: 0.2893

Epoch 00013: val_mDice did not improve from 0.29514
Epoch 14/300
 - 26s - loss: 0.2776 - acc: 0.9563 - mDice: 0.7008 - val_loss: 0.5740 - val_acc: 0.9528 - val_mDice: 0.2839

Epoch 00014: val_mDice did not improve from 0.29514
Epoch 15/300
 - 25s - loss: 0.2758 - acc: 0.9568 - mDice: 0.7028 - val_loss: 0.3780 - val_acc: 0.9463 - val_mDice: 0.2707

Epoch 00015: val_mDice did not improve from 0.29514
Epoch 16/300
 - 26s - loss: 0.2711 - acc: 0.9571 - mDice: 0.7078 - val_loss: 0.4360 - val_acc: 0.9541 - val_mDice: 0.2876

Epoch 00016: val_mDice did not improve from 0.29514
Epoch 17/300
 - 26s - loss: 0.2703 - acc: 0.9571 - mDice: 0.7087 - val_loss: 0.3342 - val_acc: 0.9527 - val_mDice: 0.2881

Epoch 00017: val_mDice did not improve from 0.29514
Epoch 18/300
 - 25s - loss: 0.2651 - acc: 0.9578 - mDice: 0.7142 - val_loss: 0.3142 - val_acc: 0.9519 - val_mDice: 0.2842

Epoch 00018: val_mDice did not improve from 0.29514

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 19/300
 - 26s - loss: 0.2532 - acc: 0.9590 - mDice: 0.7272 - val_loss: 0.3370 - val_acc: 0.9539 - val_mDice: 0.2954

Epoch 00019: val_mDice improved from 0.29514 to 0.29539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 26s - loss: 0.2484 - acc: 0.9595 - mDice: 0.7324 - val_loss: 0.3966 - val_acc: 0.9542 - val_mDice: 0.2835

Epoch 00020: val_mDice did not improve from 0.29539
Epoch 21/300
 - 26s - loss: 0.2491 - acc: 0.9596 - mDice: 0.7315 - val_loss: 0.2451 - val_acc: 0.9549 - val_mDice: 0.2875

Epoch 00021: val_mDice did not improve from 0.29539
Epoch 22/300
 - 26s - loss: 0.2439 - acc: 0.9600 - mDice: 0.7372 - val_loss: 0.1903 - val_acc: 0.9525 - val_mDice: 0.2767

Epoch 00022: val_mDice did not improve from 0.29539
Epoch 23/300
 - 26s - loss: 0.2461 - acc: 0.9598 - mDice: 0.7348 - val_loss: 0.2621 - val_acc: 0.9547 - val_mDice: 0.2880

Epoch 00023: val_mDice did not improve from 0.29539
Epoch 24/300
 - 25s - loss: 0.2417 - acc: 0.9602 - mDice: 0.7395 - val_loss: 0.2768 - val_acc: 0.9538 - val_mDice: 0.2805

Epoch 00024: val_mDice did not improve from 0.29539
Epoch 25/300
 - 26s - loss: 0.2443 - acc: 0.9604 - mDice: 0.7368 - val_loss: 0.3788 - val_acc: 0.9555 - val_mDice: 0.2948

Epoch 00025: val_mDice did not improve from 0.29539
Epoch 26/300
 - 25s - loss: 0.2399 - acc: 0.9605 - mDice: 0.7415 - val_loss: 0.2508 - val_acc: 0.9549 - val_mDice: 0.2891

Epoch 00026: val_mDice did not improve from 0.29539
Epoch 27/300
 - 25s - loss: 0.2386 - acc: 0.9606 - mDice: 0.7429 - val_loss: 0.2130 - val_acc: 0.9531 - val_mDice: 0.2852

Epoch 00027: val_mDice did not improve from 0.29539
Epoch 28/300
 - 26s - loss: 0.2388 - acc: 0.9606 - mDice: 0.7427 - val_loss: 0.1617 - val_acc: 0.9541 - val_mDice: 0.2834

Epoch 00028: val_mDice did not improve from 0.29539
Epoch 29/300
 - 25s - loss: 0.2386 - acc: 0.9607 - mDice: 0.7429 - val_loss: 0.2007 - val_acc: 0.9550 - val_mDice: 0.2890

Epoch 00029: val_mDice did not improve from 0.29539
Epoch 30/300
 - 25s - loss: 0.2359 - acc: 0.9608 - mDice: 0.7458 - val_loss: 0.1408 - val_acc: 0.9525 - val_mDice: 0.2844

Epoch 00030: val_mDice did not improve from 0.29539
Epoch 31/300
 - 25s - loss: 0.2356 - acc: 0.9609 - mDice: 0.7461 - val_loss: 0.0900 - val_acc: 0.9519 - val_mDice: 0.2850

Epoch 00031: val_mDice did not improve from 0.29539
Epoch 32/300
 - 25s - loss: 0.2364 - acc: 0.9608 - mDice: 0.7453 - val_loss: 0.0695 - val_acc: 0.9541 - val_mDice: 0.2849

Epoch 00032: val_mDice did not improve from 0.29539
Epoch 33/300
 - 25s - loss: 0.2351 - acc: 0.9611 - mDice: 0.7466 - val_loss: 0.1071 - val_acc: 0.9547 - val_mDice: 0.2885

Epoch 00033: val_mDice did not improve from 0.29539

Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 34/300
 - 26s - loss: 0.2251 - acc: 0.9617 - mDice: 0.7574 - val_loss: 0.0353 - val_acc: 0.9544 - val_mDice: 0.2898

Epoch 00034: val_mDice did not improve from 0.29539
Epoch 35/300
 - 25s - loss: 0.2244 - acc: 0.9619 - mDice: 0.7582 - val_loss: 0.1873 - val_acc: 0.9548 - val_mDice: 0.2879

Epoch 00035: val_mDice did not improve from 0.29539
Epoch 36/300
 - 25s - loss: 0.2257 - acc: 0.9621 - mDice: 0.7569 - val_loss: 0.0581 - val_acc: 0.9547 - val_mDice: 0.2870

Epoch 00036: val_mDice did not improve from 0.29539
Epoch 37/300
 - 25s - loss: 0.2256 - acc: 0.9621 - mDice: 0.7569 - val_loss: 0.0431 - val_acc: 0.9546 - val_mDice: 0.2917

Epoch 00037: val_mDice did not improve from 0.29539
Epoch 38/300
 - 26s - loss: 0.2216 - acc: 0.9622 - mDice: 0.7613 - val_loss: 0.0607 - val_acc: 0.9547 - val_mDice: 0.2892

Epoch 00038: val_mDice did not improve from 0.29539
Epoch 39/300
 - 25s - loss: 0.2206 - acc: 0.9622 - mDice: 0.7623 - val_loss: 0.1218 - val_acc: 0.9549 - val_mDice: 0.2889

Epoch 00039: val_mDice did not improve from 0.29539
Epoch 40/300
 - 25s - loss: 0.2250 - acc: 0.9622 - mDice: 0.7576 - val_loss: 0.0526 - val_acc: 0.9543 - val_mDice: 0.2852

Epoch 00040: val_mDice did not improve from 0.29539
Epoch 41/300
 - 26s - loss: 0.2211 - acc: 0.9624 - mDice: 0.7618 - val_loss: 0.0493 - val_acc: 0.9537 - val_mDice: 0.2858

Epoch 00041: val_mDice did not improve from 0.29539
Epoch 42/300
 - 25s - loss: 0.2214 - acc: 0.9624 - mDice: 0.7615 - val_loss: 0.1777 - val_acc: 0.9547 - val_mDice: 0.2853

Epoch 00042: val_mDice did not improve from 0.29539
Epoch 43/300
 - 25s - loss: 0.2184 - acc: 0.9626 - mDice: 0.7647 - val_loss: 0.0499 - val_acc: 0.9552 - val_mDice: 0.2853

Epoch 00043: val_mDice did not improve from 0.29539
Epoch 44/300
 - 26s - loss: 0.2210 - acc: 0.9625 - mDice: 0.7619 - val_loss: 0.1019 - val_acc: 0.9547 - val_mDice: 0.2903

Epoch 00044: val_mDice did not improve from 0.29539
Epoch 45/300
 - 25s - loss: 0.2207 - acc: 0.9625 - mDice: 0.7623 - val_loss: 0.1216 - val_acc: 0.9549 - val_mDice: 0.2905

Epoch 00045: val_mDice did not improve from 0.29539
Epoch 46/300
 - 25s - loss: 0.2172 - acc: 0.9627 - mDice: 0.7660 - val_loss: 0.1223 - val_acc: 0.9541 - val_mDice: 0.2857

Epoch 00046: val_mDice did not improve from 0.29539
Epoch 47/300
 - 26s - loss: 0.2188 - acc: 0.9628 - mDice: 0.7642 - val_loss: 0.1426 - val_acc: 0.9541 - val_mDice: 0.2876

Epoch 00047: val_mDice did not improve from 0.29539
Epoch 48/300
 - 25s - loss: 0.2160 - acc: 0.9627 - mDice: 0.7673 - val_loss: 0.0070 - val_acc: 0.9554 - val_mDice: 0.2927

Epoch 00048: val_mDice did not improve from 0.29539

Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 49/300
 - 25s - loss: 0.2128 - acc: 0.9630 - mDice: 0.7707 - val_loss: 0.0433 - val_acc: 0.9548 - val_mDice: 0.2891

Epoch 00049: val_mDice did not improve from 0.29539
Epoch 50/300
 - 26s - loss: 0.2102 - acc: 0.9631 - mDice: 0.7736 - val_loss: 0.0558 - val_acc: 0.9552 - val_mDice: 0.2897

Epoch 00050: val_mDice did not improve from 0.29539
Epoch 51/300
 - 26s - loss: 0.2129 - acc: 0.9632 - mDice: 0.7706 - val_loss: 0.0113 - val_acc: 0.9553 - val_mDice: 0.2922

Epoch 00051: val_mDice did not improve from 0.29539
Epoch 52/300
 - 25s - loss: 0.2117 - acc: 0.9632 - mDice: 0.7720 - val_loss: 0.0822 - val_acc: 0.9552 - val_mDice: 0.2928

Epoch 00052: val_mDice did not improve from 0.29539
Epoch 53/300
 - 26s - loss: 0.2124 - acc: 0.9633 - mDice: 0.7712 - val_loss: 0.1525 - val_acc: 0.9550 - val_mDice: 0.2877

Epoch 00053: val_mDice did not improve from 0.29539
Epoch 54/300
 - 25s - loss: 0.2143 - acc: 0.9633 - mDice: 0.7692 - val_loss: 0.0545 - val_acc: 0.9554 - val_mDice: 0.2912

Epoch 00054: val_mDice did not improve from 0.29539
Epoch 55/300
 - 25s - loss: 0.2114 - acc: 0.9634 - mDice: 0.7722 - val_loss: 0.0616 - val_acc: 0.9554 - val_mDice: 0.2902

Epoch 00055: val_mDice did not improve from 0.29539
Epoch 56/300
 - 26s - loss: 0.2124 - acc: 0.9634 - mDice: 0.7711 - val_loss: 0.0031 - val_acc: 0.9552 - val_mDice: 0.2922

Epoch 00056: val_mDice did not improve from 0.29539
Epoch 57/300
 - 25s - loss: 0.2115 - acc: 0.9634 - mDice: 0.7722 - val_loss: 0.0625 - val_acc: 0.9553 - val_mDice: 0.2925

Epoch 00057: val_mDice did not improve from 0.29539
Epoch 58/300
 - 25s - loss: 0.2122 - acc: 0.9634 - mDice: 0.7714 - val_loss: 0.0371 - val_acc: 0.9547 - val_mDice: 0.2927

Epoch 00058: val_mDice did not improve from 0.29539
Epoch 59/300
 - 26s - loss: 0.2078 - acc: 0.9635 - mDice: 0.7761 - val_loss: 0.0278 - val_acc: 0.9553 - val_mDice: 0.2902

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.25s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.12s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]
Epoch 00059: val_mDice did not improve from 0.29539
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
{'val_loss': [0.683742227433603, 0.653547846818272, 0.6519595079029663, 0.6584680514245094, 0.6621095692809624, 0.6489335724824592, 0.6383680603172206, 0.6215731403495692, 0.5466877029666418, 0.6282183867466601, 0.4569009476447407, 0.42455723900583725, 0.49604296533367304, 0.5740228917779802, 0.37801205149934264, 0.43602387022368516, 0.3341946786245968, 0.31415522532372536, 0.33698592261894594, 0.39664782800629167, 0.2451430314892455, 0.19034417515879945, 0.2620910884270185, 0.27680105715990067, 0.3787571842534633, 0.250806775604245, 0.21302094020515303, 0.16169029917520814, 0.20066797874773604, 0.14078837802893, 0.08999627972422522, 0.06949326096550573, 0.10708752614033373, 0.03532146512754733, 0.18727175768794893, 0.05812604942276508, 0.04309272294557547, 0.06070836507302674, 0.12183062906695317, 0.05255802779140163, 0.04925927875822858, 0.17771823543913756, 0.04993920721396615, 0.10191365029615691, 0.1216174122771319, 0.12234117717871183, 0.14263005201009255, 0.007007388958023696, 0.04333659470128485, 0.05577239934119243, 0.011258679194540917, 0.08224263226118268, 0.15247775187503687, 0.05452934343697904, 0.06162876355214209, 0.003078632316068758, 0.06245856359601021, 0.03706236050428846, 0.02784711466748503], 'val_acc': [0.9499553675892987, 0.9535241836233984, 0.9511507674108578, 0.9541211701646636, 0.9526084487951254, 0.9553890220726593, 0.9515999638581578, 0.952030295812631, 0.9517564501943467, 0.9527823170529136, 0.9508262103116965, 0.9531648423098311, 0.9530257507215573, 0.9527634804761862, 0.9462894721876217, 0.9541385520862627, 0.9527272544329679, 0.9519201788721205, 0.9539472905895378, 0.9541994212548944, 0.9549166597897494, 0.9524722348285627, 0.9546949576727951, 0.953785011285468, 0.9555469645729547, 0.954864489126809, 0.9530953010426292, 0.9541197222999379, 0.9549746143667004, 0.9525113596191889, 0.9519216297548029, 0.954141447815714, 0.9546529416796528, 0.9543674972992909, 0.9548210260234301, 0.9547123471392861, 0.9546181665191168, 0.9547485792184178, 0.9549485392208341, 0.9543109853056413, 0.9536777953558331, 0.9546993178657338, 0.955200654041918, 0.9547413323498979, 0.954938401149798, 0.9540849433669562, 0.9541371027125588, 0.9553890228271484, 0.9548239225073706, 0.9551977583124668, 0.955291942705082, 0.9551557453372811, 0.9550499621825882, 0.9554339375676988, 0.9553701870049103, 0.9551861640773242, 0.9553368544276757, 0.9547369849832752, 0.9553296052956883], 'val_mDice': [0.2610908490193041, 0.2936433360357828, 0.2951408787807332, 0.2872932981935483, 0.28238312885919703, 0.2901252143179314, 0.2842108113101766, 0.28923600402813926, 0.28675766581598716, 0.2872555230425883, 0.2654596282334267, 0.29452253548027596, 0.2893184745990777, 0.28387727286619474, 0.2707016702882851, 0.28756539749948284, 0.2880691927445086, 0.284173093924794, 0.29539180018856553, 0.28349452880741677, 0.2875348721878438, 0.2766561053598983, 0.2880298558481132, 0.28050190125462376, 0.29479777388557604, 0.2891037593348117, 0.28523724139491213, 0.28338128432065623, 0.28903640561465976, 0.28437091485608984, 0.28495706702712215, 0.28494718505800526, 0.2884968628611746, 0.28976792012211644, 0.2878793032863472, 0.28701242182073716, 0.2916536992297897, 0.28923206568896015, 0.28885176843857463, 0.28518383553888227, 0.28583290390198746, 0.2852712043478519, 0.285330569159381, 0.29033335571802116, 0.29046171120827713, 0.2856841225035583, 0.28757033431077306, 0.2927448926847192, 0.2891161146609089, 0.2896504169212112, 0.2922350771819489, 0.2927877425770216, 0.2876505427345445, 0.2911648726727389, 0.29021602359753623, 0.2922107312309591, 0.2925165188086184, 0.29265393571385856, 0.2902164556368997], 'loss': [0.5644598620171956, 0.4072137550164921, 0.3685054964349176, 0.342796364851131, 0.3363218938248793, 0.32344068644193646, 0.31209888061843777, 0.30603383574724424, 0.30091458785637165, 0.29174040701093296, 0.2894464214050047, 0.2838187621434912, 0.27712530135764196, 0.27757778715008835, 0.2757612158175956, 0.2711390049212018, 0.2702923542295544, 0.26514238438948173, 0.25317220985028926, 0.24836258286174612, 0.24914643727780766, 0.24391697405965657, 0.24609770101635817, 0.24173149330267205, 0.24425420869245795, 0.23989838684431283, 0.23863226069178686, 0.23878241577781772, 0.23864460671257812, 0.23593761874461427, 0.2356276963626799, 0.23637955921905562, 0.2351406341682155, 0.22513494397494746, 0.22440923241265584, 0.22566160029006532, 0.22562472100608963, 0.22155287232217707, 0.2206229972254209, 0.2250135010601352, 0.22109001803214556, 0.22138921316996346, 0.2183916551689326, 0.2210276311871177, 0.220671174414922, 0.21724238937238413, 0.21884656419997267, 0.21597973706919604, 0.21280902051174147, 0.2101596907656048, 0.21292629164640897, 0.211652647915428, 0.2123923030779612, 0.2142692807348332, 0.21141145480895296, 0.21242874812001328, 0.21147611859156834, 0.21218293129365184, 0.20780976587069275], 'acc': [0.9183790730572412, 0.941307152889461, 0.9458373437372966, 0.9485801671191519, 0.9496169314003542, 0.9514742799397268, 0.9523040522624944, 0.9529157046863274, 0.9538269848979587, 0.9545670988699699, 0.9552537142025724, 0.9556380598102199, 0.9563309761397074, 0.9562738631297122, 0.956766266680544, 0.957095968769191, 0.9570665087575977, 0.9578385277363517, 0.9589906637202787, 0.9594930277292951, 0.9596002027320678, 0.9600455189003637, 0.959805123041867, 0.960188235596353, 0.9603731042496624, 0.9605176719595768, 0.9606421674181339, 0.9605637244356723, 0.9606574361317426, 0.9607980387272803, 0.9609349166348763, 0.9608475941092608, 0.9610739971033304, 0.9616721213380228, 0.9618788050618506, 0.9620805086713209, 0.9621205000032933, 0.9622476390626593, 0.9622279635063149, 0.962242615349139, 0.9624101658413569, 0.962399038130326, 0.9625557256043245, 0.9625232684371331, 0.9625102675110245, 0.9627056026022749, 0.9627642137024469, 0.9626775970816956, 0.9630204970958258, 0.9631161698937072, 0.9632056308435177, 0.9632479586316716, 0.9632620602071686, 0.9632593511502483, 0.9633557510215348, 0.9633739509756917, 0.963377080420328, 0.9633881192120138, 0.9634735466656028], 'mDice': [0.39167626266286165, 0.5609322422478954, 0.6027027836089185, 0.6304615362259605, 0.6374445721951669, 0.65132868332973, 0.66358403025394, 0.6701364806056367, 0.6756508136965886, 0.685563233090319, 0.6880182109852039, 0.6940986117396478, 0.7013299276727799, 0.7008476943437358, 0.7027889703533992, 0.7077923934257754, 0.708696359734448, 0.7142430738087912, 0.7271758278077101, 0.7323621662909073, 0.7315121535444856, 0.7371567413712833, 0.7348128958202762, 0.7395193431099754, 0.7367824395478517, 0.7414969661066002, 0.7428687610112209, 0.742711806004729, 0.7428514057908412, 0.7457863498583106, 0.7461102314587392, 0.7452886927804773, 0.7466218778155421, 0.7574338061919685, 0.7582297398851283, 0.7568575421758749, 0.7569003677689421, 0.761303912486103, 0.762313942936777, 0.7575648846364686, 0.7618032052783121, 0.7614777297842835, 0.7647230033695526, 0.7618645675143333, 0.7622555973612425, 0.7659655202743064, 0.7642162703802312, 0.7673272316678427, 0.7707465023404709, 0.773614299911163, 0.7706160813254502, 0.7719906082912864, 0.7711903091745955, 0.7691616839061458, 0.7722482569981814, 0.7711365345123299, 0.772171603675297, 0.7713984130550968, 0.7761475639749422], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3 
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:24,  3.15it/s]Loading train:   1%|          | 2/266 [00:00<01:21,  3.24it/s]Loading train:   1%|          | 3/266 [00:00<01:18,  3.36it/s]Loading train:   2%|▏         | 4/266 [00:01<01:18,  3.32it/s]Loading train:   2%|▏         | 5/266 [00:01<01:18,  3.31it/s]Loading train:   2%|▏         | 6/266 [00:01<01:17,  3.34it/s]Loading train:   3%|▎         | 7/266 [00:02<01:16,  3.36it/s]Loading train:   3%|▎         | 8/266 [00:02<01:16,  3.38it/s]Loading train:   3%|▎         | 9/266 [00:02<01:15,  3.41it/s]Loading train:   4%|▍         | 10/266 [00:02<01:15,  3.39it/s]Loading train:   4%|▍         | 11/266 [00:03<01:14,  3.40it/s]Loading train:   5%|▍         | 12/266 [00:03<01:14,  3.42it/s]Loading train:   5%|▍         | 13/266 [00:03<01:14,  3.42it/s]Loading train:   5%|▌         | 14/266 [00:04<01:13,  3.42it/s]Loading train:   6%|▌         | 15/266 [00:04<01:13,  3.40it/s]Loading train:   6%|▌         | 16/266 [00:04<01:13,  3.41it/s]Loading train:   6%|▋         | 17/266 [00:05<01:12,  3.42it/s]Loading train:   7%|▋         | 18/266 [00:05<01:15,  3.28it/s]Loading train:   7%|▋         | 19/266 [00:05<01:14,  3.33it/s]Loading train:   8%|▊         | 20/266 [00:05<01:13,  3.36it/s]Loading train:   8%|▊         | 21/266 [00:06<01:12,  3.39it/s]Loading train:   8%|▊         | 22/266 [00:06<01:11,  3.41it/s]Loading train:   9%|▊         | 23/266 [00:06<01:08,  3.53it/s]Loading train:   9%|▉         | 24/266 [00:07<01:06,  3.62it/s]Loading train:   9%|▉         | 25/266 [00:07<01:05,  3.69it/s]Loading train:  10%|▉         | 26/266 [00:07<01:04,  3.71it/s]Loading train:  10%|█         | 27/266 [00:07<01:03,  3.75it/s]Loading train:  11%|█         | 28/266 [00:08<01:02,  3.79it/s]Loading train:  11%|█         | 29/266 [00:08<01:02,  3.82it/s]Loading train:  11%|█▏        | 30/266 [00:08<01:01,  3.85it/s]Loading train:  12%|█▏        | 31/266 [00:08<01:00,  3.85it/s]Loading train:  12%|█▏        | 32/266 [00:09<01:00,  3.86it/s]Loading train:  12%|█▏        | 33/266 [00:09<01:00,  3.87it/s]Loading train:  13%|█▎        | 34/266 [00:09<00:59,  3.88it/s]Loading train:  13%|█▎        | 35/266 [00:09<00:59,  3.86it/s]Loading train:  14%|█▎        | 36/266 [00:10<00:59,  3.87it/s]Loading train:  14%|█▍        | 37/266 [00:10<00:59,  3.88it/s]Loading train:  14%|█▍        | 38/266 [00:10<00:58,  3.89it/s]Loading train:  15%|█▍        | 39/266 [00:10<00:58,  3.88it/s]Loading train:  15%|█▌        | 40/266 [00:11<01:01,  3.67it/s]Loading train:  15%|█▌        | 41/266 [00:11<01:01,  3.67it/s]Loading train:  16%|█▌        | 42/266 [00:11<01:00,  3.70it/s]Loading train:  16%|█▌        | 43/266 [00:11<01:00,  3.72it/s]Loading train:  17%|█▋        | 44/266 [00:12<00:59,  3.73it/s]Loading train:  17%|█▋        | 45/266 [00:12<00:59,  3.74it/s]Loading train:  17%|█▋        | 46/266 [00:12<00:58,  3.75it/s]Loading train:  18%|█▊        | 47/266 [00:13<00:58,  3.76it/s]Loading train:  18%|█▊        | 48/266 [00:13<00:58,  3.75it/s]Loading train:  18%|█▊        | 49/266 [00:13<00:58,  3.71it/s]Loading train:  19%|█▉        | 50/266 [00:13<00:58,  3.68it/s]Loading train:  19%|█▉        | 51/266 [00:14<00:58,  3.67it/s]Loading train:  20%|█▉        | 52/266 [00:14<01:01,  3.48it/s]Loading train:  20%|█▉        | 53/266 [00:14<01:00,  3.54it/s]Loading train:  20%|██        | 54/266 [00:15<00:59,  3.57it/s]Loading train:  21%|██        | 55/266 [00:15<00:58,  3.61it/s]Loading train:  21%|██        | 56/266 [00:15<00:57,  3.64it/s]Loading train:  21%|██▏       | 57/266 [00:15<00:57,  3.66it/s]Loading train:  22%|██▏       | 58/266 [00:16<00:56,  3.67it/s]Loading train:  22%|██▏       | 59/266 [00:16<00:57,  3.60it/s]Loading train:  23%|██▎       | 60/266 [00:16<00:57,  3.56it/s]Loading train:  23%|██▎       | 61/266 [00:16<00:57,  3.54it/s]Loading train:  23%|██▎       | 62/266 [00:17<00:57,  3.52it/s]Loading train:  24%|██▎       | 63/266 [00:17<00:57,  3.51it/s]Loading train:  24%|██▍       | 64/266 [00:17<00:57,  3.49it/s]Loading train:  24%|██▍       | 65/266 [00:18<00:57,  3.47it/s]Loading train:  25%|██▍       | 66/266 [00:18<00:57,  3.46it/s]Loading train:  25%|██▌       | 67/266 [00:18<00:57,  3.47it/s]Loading train:  26%|██▌       | 68/266 [00:18<00:57,  3.46it/s]Loading train:  26%|██▌       | 69/266 [00:19<00:56,  3.46it/s]Loading train:  26%|██▋       | 70/266 [00:19<00:59,  3.27it/s]Loading train:  27%|██▋       | 71/266 [00:19<00:58,  3.33it/s]Loading train:  27%|██▋       | 72/266 [00:20<00:57,  3.36it/s]Loading train:  27%|██▋       | 73/266 [00:20<00:56,  3.40it/s]Loading train:  28%|██▊       | 74/266 [00:20<00:56,  3.40it/s]Loading train:  28%|██▊       | 75/266 [00:21<00:55,  3.42it/s]Loading train:  29%|██▊       | 76/266 [00:21<00:55,  3.43it/s]Loading train:  29%|██▉       | 77/266 [00:21<00:58,  3.23it/s]Loading train:  29%|██▉       | 78/266 [00:22<00:59,  3.18it/s]Loading train:  30%|██▉       | 79/266 [00:22<00:58,  3.22it/s]Loading train:  30%|███       | 80/266 [00:22<00:56,  3.30it/s]Loading train:  30%|███       | 81/266 [00:22<00:58,  3.17it/s]Loading train:  31%|███       | 82/266 [00:23<00:58,  3.13it/s]Loading train:  31%|███       | 83/266 [00:23<00:58,  3.10it/s]Loading train:  32%|███▏      | 84/266 [00:23<00:58,  3.09it/s]Loading train:  32%|███▏      | 85/266 [00:24<00:59,  3.05it/s]Loading train:  32%|███▏      | 86/266 [00:24<00:59,  3.05it/s]Loading train:  33%|███▎      | 87/266 [00:24<00:58,  3.04it/s]Loading train:  33%|███▎      | 88/266 [00:25<00:58,  3.03it/s]Loading train:  33%|███▎      | 89/266 [00:25<00:58,  3.02it/s]Loading train:  34%|███▍      | 90/266 [00:25<00:57,  3.04it/s]Loading train:  34%|███▍      | 91/266 [00:26<00:58,  3.01it/s]Loading train:  35%|███▍      | 92/266 [00:26<00:58,  3.00it/s]Loading train:  35%|███▍      | 93/266 [00:26<00:57,  3.00it/s]Loading train:  35%|███▌      | 94/266 [00:27<00:57,  3.01it/s]Loading train:  36%|███▌      | 95/266 [00:27<00:56,  3.03it/s]Loading train:  36%|███▌      | 96/266 [00:27<00:55,  3.05it/s]Loading train:  36%|███▋      | 97/266 [00:28<00:55,  3.02it/s]Loading train:  37%|███▋      | 98/266 [00:28<00:55,  3.02it/s]Loading train:  37%|███▋      | 99/266 [00:28<00:55,  3.01it/s]Loading train:  38%|███▊      | 100/266 [00:29<00:54,  3.05it/s]Loading train:  38%|███▊      | 101/266 [00:29<00:53,  3.09it/s]Loading train:  38%|███▊      | 102/266 [00:29<00:52,  3.12it/s]Loading train:  39%|███▊      | 103/266 [00:30<00:51,  3.14it/s]Loading train:  39%|███▉      | 104/266 [00:30<00:51,  3.16it/s]Loading train:  39%|███▉      | 105/266 [00:30<00:50,  3.16it/s]Loading train:  40%|███▉      | 106/266 [00:31<00:50,  3.17it/s]Loading train:  40%|████      | 107/266 [00:31<00:50,  3.18it/s]Loading train:  41%|████      | 108/266 [00:31<00:49,  3.16it/s]Loading train:  41%|████      | 109/266 [00:32<00:49,  3.18it/s]Loading train:  41%|████▏     | 110/266 [00:32<00:49,  3.18it/s]Loading train:  42%|████▏     | 111/266 [00:32<00:48,  3.18it/s]Loading train:  42%|████▏     | 112/266 [00:33<00:48,  3.17it/s]Loading train:  42%|████▏     | 113/266 [00:33<00:48,  3.18it/s]Loading train:  43%|████▎     | 114/266 [00:33<00:47,  3.18it/s]Loading train:  43%|████▎     | 115/266 [00:33<00:47,  3.21it/s]Loading train:  44%|████▎     | 116/266 [00:34<00:46,  3.20it/s]Loading train:  44%|████▍     | 117/266 [00:34<00:46,  3.22it/s]Loading train:  44%|████▍     | 118/266 [00:34<00:45,  3.28it/s]Loading train:  45%|████▍     | 119/266 [00:35<00:44,  3.33it/s]Loading train:  45%|████▌     | 120/266 [00:35<00:43,  3.38it/s]Loading train:  45%|████▌     | 121/266 [00:35<00:42,  3.39it/s]Loading train:  46%|████▌     | 122/266 [00:36<00:42,  3.42it/s]Loading train:  46%|████▌     | 123/266 [00:36<00:41,  3.42it/s]Loading train:  47%|████▋     | 124/266 [00:36<00:41,  3.43it/s]Loading train:  47%|████▋     | 125/266 [00:36<00:40,  3.45it/s]Loading train:  47%|████▋     | 126/266 [00:37<00:40,  3.46it/s]Loading train:  48%|████▊     | 127/266 [00:37<00:40,  3.47it/s]Loading train:  48%|████▊     | 128/266 [00:37<00:40,  3.45it/s]Loading train:  48%|████▊     | 129/266 [00:38<00:39,  3.47it/s]Loading train:  49%|████▉     | 130/266 [00:38<00:39,  3.47it/s]Loading train:  49%|████▉     | 131/266 [00:38<00:39,  3.45it/s]Loading train:  50%|████▉     | 132/266 [00:38<00:38,  3.46it/s]Loading train:  50%|█████     | 133/266 [00:39<00:38,  3.47it/s]Loading train:  50%|█████     | 134/266 [00:39<00:38,  3.46it/s]Loading train:  51%|█████     | 135/266 [00:39<00:38,  3.44it/s]Loading train:  51%|█████     | 136/266 [00:40<00:37,  3.46it/s]Loading train:  52%|█████▏    | 137/266 [00:40<00:36,  3.52it/s]Loading train:  52%|█████▏    | 138/266 [00:40<00:35,  3.58it/s]Loading train:  52%|█████▏    | 139/266 [00:40<00:35,  3.59it/s]Loading train:  53%|█████▎    | 140/266 [00:41<00:34,  3.62it/s]Loading train:  53%|█████▎    | 141/266 [00:41<00:34,  3.65it/s]Loading train:  53%|█████▎    | 142/266 [00:41<00:33,  3.65it/s]Loading train:  54%|█████▍    | 143/266 [00:42<00:37,  3.25it/s]Loading train:  54%|█████▍    | 144/266 [00:42<00:41,  2.97it/s]Loading train:  55%|█████▍    | 145/266 [00:42<00:38,  3.15it/s]Loading train:  55%|█████▍    | 146/266 [00:43<00:36,  3.29it/s]Loading train:  55%|█████▌    | 147/266 [00:43<00:35,  3.34it/s]Loading train:  56%|█████▌    | 148/266 [00:43<00:34,  3.44it/s]Loading train:  56%|█████▌    | 149/266 [00:43<00:34,  3.42it/s]Loading train:  56%|█████▋    | 150/266 [00:44<00:33,  3.50it/s]Loading train:  57%|█████▋    | 151/266 [00:44<00:32,  3.55it/s]Loading train:  57%|█████▋    | 152/266 [00:44<00:31,  3.59it/s]Loading train:  58%|█████▊    | 153/266 [00:44<00:31,  3.60it/s]Loading train:  58%|█████▊    | 154/266 [00:45<00:32,  3.43it/s]Loading train:  58%|█████▊    | 155/266 [00:45<00:33,  3.32it/s]Loading train:  59%|█████▊    | 156/266 [00:45<00:33,  3.24it/s]Loading train:  59%|█████▉    | 157/266 [00:46<00:34,  3.19it/s]Loading train:  59%|█████▉    | 158/266 [00:46<00:35,  3.08it/s]Loading train:  60%|█████▉    | 159/266 [00:46<00:34,  3.07it/s]Loading train:  60%|██████    | 160/266 [00:47<00:34,  3.07it/s]Loading train:  61%|██████    | 161/266 [00:47<00:34,  3.08it/s]Loading train:  61%|██████    | 162/266 [00:47<00:33,  3.06it/s]Loading train:  61%|██████▏   | 163/266 [00:48<00:35,  2.93it/s]Loading train:  62%|██████▏   | 164/266 [00:48<00:34,  2.94it/s]Loading train:  62%|██████▏   | 165/266 [00:48<00:33,  2.99it/s]Loading train:  62%|██████▏   | 166/266 [00:49<00:33,  3.02it/s]Loading train:  63%|██████▎   | 167/266 [00:49<00:32,  3.05it/s]Loading train:  63%|██████▎   | 168/266 [00:49<00:32,  3.04it/s]Loading train:  64%|██████▎   | 169/266 [00:50<00:31,  3.06it/s]Loading train:  64%|██████▍   | 170/266 [00:50<00:31,  3.07it/s]Loading train:  64%|██████▍   | 171/266 [00:50<00:31,  3.00it/s]Loading train:  65%|██████▍   | 172/266 [00:51<00:31,  3.02it/s]Loading train:  65%|██████▌   | 173/266 [00:51<00:31,  2.97it/s]Loading train:  65%|██████▌   | 174/266 [00:51<00:30,  3.03it/s]Loading train:  66%|██████▌   | 175/266 [00:52<00:28,  3.18it/s]Loading train:  66%|██████▌   | 176/266 [00:52<00:27,  3.24it/s]Loading train:  67%|██████▋   | 177/266 [00:52<00:27,  3.24it/s]Loading train:  67%|██████▋   | 178/266 [00:53<00:27,  3.25it/s]Loading train:  67%|██████▋   | 179/266 [00:53<00:27,  3.20it/s]Loading train:  68%|██████▊   | 180/266 [00:53<00:26,  3.20it/s]Loading train:  68%|██████▊   | 181/266 [00:54<00:26,  3.19it/s]Loading train:  68%|██████▊   | 182/266 [00:54<00:26,  3.14it/s]Loading train:  69%|██████▉   | 183/266 [00:54<00:26,  3.13it/s]Loading train:  69%|██████▉   | 184/266 [00:55<00:25,  3.16it/s]Loading train:  70%|██████▉   | 185/266 [00:55<00:25,  3.17it/s]Loading train:  70%|██████▉   | 186/266 [00:55<00:25,  3.17it/s]Loading train:  70%|███████   | 187/266 [00:55<00:24,  3.18it/s]Loading train:  71%|███████   | 188/266 [00:56<00:24,  3.16it/s]Loading train:  71%|███████   | 189/266 [00:56<00:24,  3.15it/s]Loading train:  71%|███████▏  | 190/266 [00:56<00:23,  3.17it/s]Loading train:  72%|███████▏  | 191/266 [00:57<00:23,  3.15it/s]Loading train:  72%|███████▏  | 192/266 [00:57<00:23,  3.14it/s]Loading train:  73%|███████▎  | 193/266 [00:57<00:22,  3.18it/s]Loading train:  73%|███████▎  | 194/266 [00:58<00:22,  3.21it/s]Loading train:  73%|███████▎  | 195/266 [00:58<00:22,  3.16it/s]Loading train:  74%|███████▎  | 196/266 [00:58<00:22,  3.12it/s]Loading train:  74%|███████▍  | 197/266 [00:59<00:22,  3.13it/s]Loading train:  74%|███████▍  | 198/266 [00:59<00:21,  3.11it/s]Loading train:  75%|███████▍  | 199/266 [00:59<00:21,  3.10it/s]Loading train:  75%|███████▌  | 200/266 [01:00<00:21,  3.11it/s]Loading train:  76%|███████▌  | 201/266 [01:00<00:20,  3.11it/s]Loading train:  76%|███████▌  | 202/266 [01:00<00:20,  3.10it/s]Loading train:  76%|███████▋  | 203/266 [01:01<00:20,  3.11it/s]Loading train:  77%|███████▋  | 204/266 [01:01<00:19,  3.11it/s]Loading train:  77%|███████▋  | 205/266 [01:01<00:19,  3.11it/s]Loading train:  77%|███████▋  | 206/266 [01:02<00:19,  3.09it/s]Loading train:  78%|███████▊  | 207/266 [01:02<00:18,  3.11it/s]Loading train:  78%|███████▊  | 208/266 [01:02<00:18,  3.11it/s]Loading train:  79%|███████▊  | 209/266 [01:03<00:18,  3.08it/s]Loading train:  79%|███████▉  | 210/266 [01:03<00:18,  3.08it/s]Loading train:  79%|███████▉  | 211/266 [01:03<00:17,  3.10it/s]Loading train:  80%|███████▉  | 212/266 [01:03<00:17,  3.11it/s]Loading train:  80%|████████  | 213/266 [01:04<00:16,  3.16it/s]Loading train:  80%|████████  | 214/266 [01:04<00:16,  3.21it/s]Loading train:  81%|████████  | 215/266 [01:04<00:15,  3.24it/s]Loading train:  81%|████████  | 216/266 [01:05<00:15,  3.27it/s]Loading train:  82%|████████▏ | 217/266 [01:05<00:14,  3.29it/s]Loading train:  82%|████████▏ | 218/266 [01:05<00:14,  3.30it/s]Loading train:  82%|████████▏ | 219/266 [01:06<00:14,  3.30it/s]Loading train:  83%|████████▎ | 220/266 [01:06<00:13,  3.30it/s]Loading train:  83%|████████▎ | 221/266 [01:06<00:13,  3.31it/s]Loading train:  83%|████████▎ | 222/266 [01:07<00:13,  3.26it/s]Loading train:  84%|████████▍ | 223/266 [01:07<00:13,  3.22it/s]Loading train:  84%|████████▍ | 224/266 [01:07<00:13,  3.19it/s]Loading train:  85%|████████▍ | 225/266 [01:07<00:12,  3.18it/s]Loading train:  85%|████████▍ | 226/266 [01:08<00:12,  3.17it/s]Loading train:  85%|████████▌ | 227/266 [01:08<00:12,  3.21it/s]Loading train:  86%|████████▌ | 228/266 [01:08<00:11,  3.24it/s]Loading train:  86%|████████▌ | 229/266 [01:09<00:11,  3.26it/s]Loading train:  86%|████████▋ | 230/266 [01:09<00:10,  3.28it/s]Loading train:  87%|████████▋ | 231/266 [01:09<00:10,  3.45it/s]Loading train:  87%|████████▋ | 232/266 [01:10<00:09,  3.57it/s]Loading train:  88%|████████▊ | 233/266 [01:10<00:09,  3.65it/s]Loading train:  88%|████████▊ | 234/266 [01:10<00:08,  3.71it/s]Loading train:  88%|████████▊ | 235/266 [01:10<00:08,  3.75it/s]Loading train:  89%|████████▊ | 236/266 [01:11<00:07,  3.78it/s]Loading train:  89%|████████▉ | 237/266 [01:11<00:07,  3.84it/s]Loading train:  89%|████████▉ | 238/266 [01:11<00:07,  3.85it/s]Loading train:  90%|████████▉ | 239/266 [01:11<00:07,  3.85it/s]Loading train:  90%|█████████ | 240/266 [01:12<00:06,  3.88it/s]Loading train:  91%|█████████ | 241/266 [01:12<00:06,  3.91it/s]Loading train:  91%|█████████ | 242/266 [01:12<00:06,  3.91it/s]Loading train:  91%|█████████▏| 243/266 [01:12<00:05,  3.92it/s]Loading train:  92%|█████████▏| 244/266 [01:13<00:05,  3.91it/s]Loading train:  92%|█████████▏| 245/266 [01:13<00:05,  3.93it/s]Loading train:  92%|█████████▏| 246/266 [01:13<00:05,  3.92it/s]Loading train:  93%|█████████▎| 247/266 [01:13<00:04,  3.92it/s]Loading train:  93%|█████████▎| 248/266 [01:14<00:04,  3.93it/s]Loading train:  94%|█████████▎| 249/266 [01:14<00:04,  3.87it/s]Loading train:  94%|█████████▍| 250/266 [01:14<00:04,  3.84it/s]Loading train:  94%|█████████▍| 251/266 [01:14<00:03,  3.76it/s]Loading train:  95%|█████████▍| 252/266 [01:15<00:03,  3.74it/s]Loading train:  95%|█████████▌| 253/266 [01:15<00:03,  3.70it/s]Loading train:  95%|█████████▌| 254/266 [01:15<00:03,  3.70it/s]Loading train:  96%|█████████▌| 255/266 [01:16<00:03,  3.66it/s]Loading train:  96%|█████████▌| 256/266 [01:16<00:02,  3.63it/s]Loading train:  97%|█████████▋| 257/266 [01:16<00:02,  3.59it/s]Loading train:  97%|█████████▋| 258/266 [01:16<00:02,  3.54it/s]Loading train:  97%|█████████▋| 259/266 [01:17<00:01,  3.54it/s]Loading train:  98%|█████████▊| 260/266 [01:17<00:01,  3.55it/s]Loading train:  98%|█████████▊| 261/266 [01:17<00:01,  3.53it/s]Loading train:  98%|█████████▊| 262/266 [01:18<00:01,  3.54it/s]Loading train:  99%|█████████▉| 263/266 [01:18<00:00,  3.53it/s]Loading train:  99%|█████████▉| 264/266 [01:18<00:00,  3.54it/s]Loading train: 100%|█████████▉| 265/266 [01:18<00:00,  3.54it/s]Loading train: 100%|██████████| 266/266 [01:19<00:00,  3.55it/s]Loading train: 100%|██████████| 266/266 [01:19<00:00,  3.36it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 45.83it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:05, 45.72it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:05, 45.24it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:05, 45.25it/s]concatenating: train:   9%|▉         | 25/266 [00:00<00:05, 46.23it/s]concatenating: train:  12%|█▏        | 31/266 [00:00<00:04, 47.46it/s]concatenating: train:  14%|█▎        | 36/266 [00:00<00:04, 48.15it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:04, 48.79it/s]concatenating: train:  18%|█▊        | 48/266 [00:00<00:04, 49.57it/s]concatenating: train:  20%|█▉        | 53/266 [00:01<00:04, 48.63it/s]concatenating: train:  22%|██▏       | 58/266 [00:01<00:04, 48.38it/s]concatenating: train:  24%|██▎       | 63/266 [00:01<00:04, 47.11it/s]concatenating: train:  26%|██▌       | 68/266 [00:01<00:04, 45.79it/s]concatenating: train:  27%|██▋       | 73/266 [00:01<00:04, 45.07it/s]concatenating: train:  29%|██▉       | 78/266 [00:01<00:04, 44.01it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:04, 43.25it/s]concatenating: train:  33%|███▎      | 88/266 [00:01<00:04, 41.92it/s]concatenating: train:  35%|███▍      | 93/266 [00:02<00:04, 41.17it/s]concatenating: train:  37%|███▋      | 98/266 [00:02<00:04, 40.26it/s]concatenating: train:  39%|███▊      | 103/266 [00:02<00:04, 40.41it/s]concatenating: train:  41%|████      | 108/266 [00:02<00:03, 40.48it/s]concatenating: train:  42%|████▏     | 113/266 [00:02<00:03, 40.96it/s]concatenating: train:  44%|████▍     | 118/266 [00:02<00:03, 41.29it/s]concatenating: train:  46%|████▌     | 123/266 [00:02<00:03, 42.24it/s]concatenating: train:  48%|████▊     | 128/266 [00:02<00:03, 42.94it/s]concatenating: train:  50%|█████     | 133/266 [00:03<00:03, 43.40it/s]concatenating: train:  52%|█████▏    | 138/266 [00:03<00:02, 44.15it/s]concatenating: train:  54%|█████▍    | 143/266 [00:03<00:02, 44.71it/s]concatenating: train:  56%|█████▌    | 148/266 [00:03<00:02, 45.21it/s]concatenating: train:  58%|█████▊    | 153/266 [00:03<00:02, 45.70it/s]concatenating: train:  59%|█████▉    | 158/266 [00:03<00:02, 43.85it/s]concatenating: train:  61%|██████▏   | 163/266 [00:03<00:02, 42.17it/s]concatenating: train:  63%|██████▎   | 168/266 [00:03<00:02, 42.12it/s]concatenating: train:  65%|██████▌   | 173/266 [00:03<00:02, 41.94it/s]concatenating: train:  67%|██████▋   | 178/266 [00:04<00:02, 42.83it/s]concatenating: train:  69%|██████▉   | 183/266 [00:04<00:01, 42.98it/s]concatenating: train:  71%|███████   | 188/266 [00:04<00:01, 43.66it/s]concatenating: train:  73%|███████▎  | 193/266 [00:04<00:01, 43.27it/s]concatenating: train:  74%|███████▍  | 198/266 [00:04<00:01, 42.62it/s]concatenating: train:  76%|███████▋  | 203/266 [00:04<00:01, 42.13it/s]concatenating: train:  78%|███████▊  | 208/266 [00:04<00:01, 41.84it/s]concatenating: train:  80%|████████  | 213/266 [00:04<00:01, 41.90it/s]concatenating: train:  82%|████████▏ | 218/266 [00:04<00:01, 42.74it/s]concatenating: train:  84%|████████▍ | 223/266 [00:05<00:01, 42.70it/s]concatenating: train:  86%|████████▌ | 228/266 [00:05<00:00, 43.98it/s]concatenating: train:  89%|████████▊ | 236/266 [00:05<00:00, 49.44it/s]concatenating: train:  91%|█████████ | 242/266 [00:05<00:00, 51.87it/s]concatenating: train:  93%|█████████▎| 248/266 [00:05<00:00, 51.15it/s]concatenating: train:  95%|█████████▌| 254/266 [00:05<00:00, 49.75it/s]concatenating: train:  98%|█████████▊| 260/266 [00:05<00:00, 48.97it/s]concatenating: train: 100%|█████████▉| 265/266 [00:05<00:00, 48.45it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 44.94it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:00,  3.29it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  3.42it/s]Loading test:  75%|███████▌  | 3/4 [00:00<00:00,  3.45it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  3.30it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  3.37it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 368.18it/s] |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  2020-01-22 06:52:16.513476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 06:52:16.513568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 06:52:16.513583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 06:52:16.513592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 06:52:16.513879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [0.97555386 0.02444614]
Train on 27854 samples, validate on 403 samples
Epoch 1/300
 - 74s - loss: 0.0772 - acc: 0.9922 - mDice: 0.8497 - val_loss: 6.9616e-04 - val_acc: 0.9937 - val_mDice: 0.5411

Epoch 00001: val_mDice improved from -inf to 0.54105, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 70s - loss: 0.0513 - acc: 0.9945 - mDice: 0.9002 - val_loss: -2.6435e-03 - val_acc: 0.9939 - val_mDice: 0.5470

Epoch 00002: val_mDice improved from 0.54105 to 0.54697, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 3/300
 - 70s - loss: 0.0468 - acc: 0.9950 - mDice: 0.9089 - val_loss: 0.1059 - val_acc: 0.9940 - val_mDice: 0.5424

Epoch 00003: val_mDice did not improve from 0.54697
Epoch 4/300
 - 69s - loss: 0.0430 - acc: 0.9953 - mDice: 0.9163 - val_loss: 0.0502 - val_acc: 0.9939 - val_mDice: 0.5407

Epoch 00004: val_mDice did not improve from 0.54697
Epoch 5/300
 - 69s - loss: 0.0408 - acc: 0.9955 - mDice: 0.9207 - val_loss: 0.0300 - val_acc: 0.9938 - val_mDice: 0.5314

Epoch 00005: val_mDice did not improve from 0.54697
Epoch 6/300
 - 69s - loss: 0.0397 - acc: 0.9956 - mDice: 0.9229 - val_loss: -4.6932e-02 - val_acc: 0.9942 - val_mDice: 0.5361

Epoch 00006: val_mDice did not improve from 0.54697
Epoch 7/300
 - 69s - loss: 0.0384 - acc: 0.9957 - mDice: 0.9253 - val_loss: -7.5332e-03 - val_acc: 0.9942 - val_mDice: 0.5417

Epoch 00007: val_mDice did not improve from 0.54697
Epoch 8/300
 - 69s - loss: 0.0371 - acc: 0.9958 - mDice: 0.9279 - val_loss: 0.0250 - val_acc: 0.9941 - val_mDice: 0.5416

Epoch 00008: val_mDice did not improve from 0.54697
Epoch 9/300
 - 70s - loss: 0.0364 - acc: 0.9959 - mDice: 0.9292 - val_loss: 1.9271e-04 - val_acc: 0.9942 - val_mDice: 0.5402

Epoch 00009: val_mDice did not improve from 0.54697
Epoch 10/300
 - 69s - loss: 0.0357 - acc: 0.9960 - mDice: 0.9307 - val_loss: -2.3952e-02 - val_acc: 0.9942 - val_mDice: 0.5410

Epoch 00010: val_mDice did not improve from 0.54697
Epoch 11/300
 - 69s - loss: 0.0350 - acc: 0.9960 - mDice: 0.9321 - val_loss: -2.7126e-04 - val_acc: 0.9942 - val_mDice: 0.5422

Epoch 00011: val_mDice did not improve from 0.54697
Epoch 12/300
 - 69s - loss: 0.0343 - acc: 0.9961 - mDice: 0.9334 - val_loss: 0.0052 - val_acc: 0.9938 - val_mDice: 0.5314

Epoch 00012: val_mDice did not improve from 0.54697
Epoch 13/300
 - 69s - loss: 0.0336 - acc: 0.9961 - mDice: 0.9347 - val_loss: 0.0060 - val_acc: 0.9938 - val_mDice: 0.5298

Epoch 00013: val_mDice did not improve from 0.54697
Epoch 14/300
 - 69s - loss: 0.0332 - acc: 0.9962 - mDice: 0.9356 - val_loss: 0.0103 - val_acc: 0.9939 - val_mDice: 0.5365

Epoch 00014: val_mDice did not improve from 0.54697
Epoch 15/300
 - 69s - loss: 0.0335 - acc: 0.9962 - mDice: 0.9349 - val_loss: -2.1042e-02 - val_acc: 0.9940 - val_mDice: 0.5341

Epoch 00015: val_mDice did not improve from 0.54697
Epoch 16/300
 - 69s - loss: 0.0325 - acc: 0.9962 - mDice: 0.9369 - val_loss: -4.5348e-02 - val_acc: 0.9939 - val_mDice: 0.5279

Epoch 00016: val_mDice did not improve from 0.54697
Epoch 17/300
 - 69s - loss: 0.0324 - acc: 0.9962 - mDice: 0.9370 - val_loss: -1.9340e-02 - val_acc: 0.9939 - val_mDice: 0.5318

Epoch 00017: val_mDice did not improve from 0.54697

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 18/300
 - 69s - loss: 0.0306 - acc: 0.9964 - mDice: 0.9406 - val_loss: -4.6760e-02 - val_acc: 0.9942 - val_mDice: 0.5364

Epoch 00018: val_mDice did not improve from 0.54697
Epoch 19/300
 - 69s - loss: 0.0303 - acc: 0.9964 - mDice: 0.9411 - val_loss: 0.0265 - val_acc: 0.9941 - val_mDice: 0.5381

Epoch 00019: val_mDice did not improve from 0.54697
Epoch 20/300
 - 69s - loss: 0.0302 - acc: 0.9964 - mDice: 0.9414 - val_loss: -1.7400e-02 - val_acc: 0.9943 - val_mDice: 0.5419

Epoch 00020: val_mDice did not improve from 0.54697
Epoch 21/300
 - 70s - loss: 0.0301 - acc: 0.9965 - mDice: 0.9416 - val_loss: 0.0020 - val_acc: 0.9942 - val_mDice: 0.5348

Epoch 00021: val_mDice did not improve from 0.54697
Epoch 22/300
 - 70s - loss: 0.0294 - acc: 0.9965 - mDice: 0.9430 - val_loss: -4.4348e-02 - val_acc: 0.9941 - val_mDice: 0.5323

Epoch 00022: val_mDice did not improve from 0.54697
Epoch 23/300
 - 69s - loss: 0.0295 - acc: 0.9965 - mDice: 0.9428 - val_loss: 0.0282 - val_acc: 0.9939 - val_mDice: 0.5350

Epoch 00023: val_mDice did not improve from 0.54697
Epoch 24/300
 - 69s - loss: 0.0291 - acc: 0.9965 - mDice: 0.9435 - val_loss: 0.0258 - val_acc: 0.9942 - val_mDice: 0.5400

Epoch 00024: val_mDice did not improve from 0.54697
Epoch 25/300
 - 69s - loss: 0.0288 - acc: 0.9965 - mDice: 0.9440 - val_loss: -6.8301e-02 - val_acc: 0.9941 - val_mDice: 0.5298

Epoch 00025: val_mDice did not improve from 0.54697
Epoch 26/300
 - 69s - loss: 0.0287 - acc: 0.9965 - mDice: 0.9443 - val_loss: -4.4723e-02 - val_acc: 0.9941 - val_mDice: 0.5327

Epoch 00026: val_mDice did not improve from 0.54697
Epoch 27/300
 - 69s - loss: 0.0286 - acc: 0.9966 - mDice: 0.9445 - val_loss: 0.0272 - val_acc: 0.9941 - val_mDice: 0.5369

Epoch 00027: val_mDice did not improve from 0.54697
Epoch 28/300
 - 69s - loss: 0.0285 - acc: 0.9966 - mDice: 0.9447 - val_loss: 0.0244 - val_acc: 0.9943 - val_mDice: 0.5380

Epoch 00028: val_mDice did not improve from 0.54697
Epoch 29/300
 - 69s - loss: 0.0288 - acc: 0.9966 - mDice: 0.9442 - val_loss: -1.7608e-02 - val_acc: 0.9940 - val_mDice: 0.5272

Epoch 00029: val_mDice did not improve from 0.54697
Epoch 30/300
 - 69s - loss: 0.0287 - acc: 0.9966 - mDice: 0.9443 - val_loss: -2.0805e-02 - val_acc: 0.9942 - val_mDice: 0.5335

Epoch 00030: val_mDice did not improve from 0.54697
Epoch 31/300
 - 70s - loss: 0.0287 - acc: 0.9966 - mDice: 0.9443 - val_loss: -1.3140e-02 - val_acc: 0.9942 - val_mDice: 0.5356

Epoch 00031: val_mDice did not improve from 0.54697
Epoch 32/300
 - 69s - loss: 0.0284 - acc: 0.9966 - mDice: 0.9448 - val_loss: 0.0277 - val_acc: 0.9940 - val_mDice: 0.5339

Epoch 00032: val_mDice did not improve from 0.54697

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 33/300
 - 69s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9467 - val_loss: -2.2417e-02 - val_acc: 0.9942 - val_mDice: 0.5371

Epoch 00033: val_mDice did not improve from 0.54697
Epoch 34/300
 - 69s - loss: 0.0272 - acc: 0.9967 - mDice: 0.9472 - val_loss: -7.9996e-03 - val_acc: 0.9941 - val_mDice: 0.5336

Epoch 00034: val_mDice did not improve from 0.54697
Epoch 35/300
 - 69s - loss: 0.0270 - acc: 0.9967 - mDice: 0.9477 - val_loss: 0.0247 - val_acc: 0.9940 - val_mDice: 0.5369

Epoch 00035: val_mDice did not improve from 0.54697
Epoch 36/300
 - 69s - loss: 0.0269 - acc: 0.9967 - mDice: 0.9477 - val_loss: 0.0484 - val_acc: 0.9942 - val_mDice: 0.5382

Epoch 00036: val_mDice did not improve from 0.54697
Epoch 37/300
 - 69s - loss: 0.0268 - acc: 0.9967 - mDice: 0.9479 - val_loss: -7.8231e-03 - val_acc: 0.9941 - val_mDice: 0.5362

Epoch 00037: val_mDice did not improve from 0.54697
Epoch 38/300
 - 69s - loss: 0.0269 - acc: 0.9967 - mDice: 0.9479 - val_loss: 0.0255 - val_acc: 0.9941 - val_mDice: 0.5390

Epoch 00038: val_mDice did not improve from 0.54697
Epoch 39/300
 - 69s - loss: 0.0270 - acc: 0.9967 - mDice: 0.9476 - val_loss: 0.0266 - val_acc: 0.9942 - val_mDice: 0.5372

Epoch 00039: val_mDice did not improve from 0.54697
Epoch 40/300
 - 69s - loss: 0.0268 - acc: 0.9967 - mDice: 0.9480 - val_loss: 0.0012 - val_acc: 0.9942 - val_mDice: 0.5391

Epoch 00040: val_mDice did not improve from 0.54697
Epoch 41/300
 - 69s - loss: 0.0267 - acc: 0.9967 - mDice: 0.9483 - val_loss: -2.1226e-02 - val_acc: 0.9939 - val_mDice: 0.5343

Epoch 00041: val_mDice did not improve from 0.54697
Epoch 42/300
 - 70s - loss: 0.0264 - acc: 0.9967 - mDice: 0.9487 - val_loss: 0.0150 - val_acc: 0.9940 - val_mDice: 0.5347

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:01,  1.58it/s]predicting test subjects:  50%|█████     | 2/4 [00:00<00:01,  1.97it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:00<00:00,  2.52it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.92it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  3.33it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:49,  5.39it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:47,  5.51it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:49,  5.27it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:49,  5.24it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:46,  5.57it/s]predicting train subjects:   2%|▏         | 6/266 [00:01<00:44,  5.86it/s]predicting train subjects:   3%|▎         | 7/266 [00:01<00:42,  6.06it/s]predicting train subjects:   3%|▎         | 8/266 [00:01<00:41,  6.18it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:40,  6.33it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:40,  6.40it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:39,  6.52it/s]predicting train subjects:   5%|▍         | 12/266 [00:01<00:38,  6.58it/s]predicting train subjects:   5%|▍         | 13/266 [00:02<00:38,  6.64it/s]predicting train subjects:   5%|▌         | 14/266 [00:02<00:37,  6.71it/s]predicting train subjects:   6%|▌         | 15/266 [00:02<00:37,  6.70it/s]predicting train subjects:   6%|▌         | 16/266 [00:02<00:37,  6.63it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:37,  6.69it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:36,  6.79it/s]predicting train subjects:   7%|▋         | 19/266 [00:02<00:36,  6.81it/s]predicting train subjects:   8%|▊         | 20/266 [00:03<00:36,  6.76it/s]predicting train subjects:   8%|▊         | 21/266 [00:03<00:36,  6.79it/s]predicting train subjects:   8%|▊         | 22/266 [00:03<00:35,  6.79it/s]predicting train subjects:   9%|▊         | 23/266 [00:03<00:34,  7.01it/s]predicting train subjects:   9%|▉         | 24/266 [00:03<00:33,  7.24it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:32,  7.40it/s]predicting train subjects:  10%|▉         | 26/266 [00:03<00:32,  7.32it/s]predicting train subjects:  10%|█         | 27/266 [00:04<00:32,  7.42it/s]predicting train subjects:  11%|█         | 28/266 [00:04<00:31,  7.53it/s]predicting train subjects:  11%|█         | 29/266 [00:04<00:31,  7.59it/s]predicting train subjects:  11%|█▏        | 30/266 [00:04<00:31,  7.52it/s]predicting train subjects:  12%|█▏        | 31/266 [00:04<00:31,  7.49it/s]predicting train subjects:  12%|█▏        | 32/266 [00:04<00:31,  7.54it/s]predicting train subjects:  12%|█▏        | 33/266 [00:04<00:30,  7.59it/s]predicting train subjects:  13%|█▎        | 34/266 [00:05<00:30,  7.62it/s]predicting train subjects:  13%|█▎        | 35/266 [00:05<00:30,  7.68it/s]predicting train subjects:  14%|█▎        | 36/266 [00:05<00:29,  7.75it/s]predicting train subjects:  14%|█▍        | 37/266 [00:05<00:29,  7.77it/s]predicting train subjects:  14%|█▍        | 38/266 [00:05<00:29,  7.77it/s]predicting train subjects:  15%|█▍        | 39/266 [00:05<00:29,  7.79it/s]predicting train subjects:  15%|█▌        | 40/266 [00:05<00:28,  7.83it/s]predicting train subjects:  15%|█▌        | 41/266 [00:05<00:29,  7.70it/s]predicting train subjects:  16%|█▌        | 42/266 [00:06<00:29,  7.63it/s]predicting train subjects:  16%|█▌        | 43/266 [00:06<00:29,  7.65it/s]predicting train subjects:  17%|█▋        | 44/266 [00:06<00:29,  7.62it/s]predicting train subjects:  17%|█▋        | 45/266 [00:06<00:28,  7.63it/s]predicting train subjects:  17%|█▋        | 46/266 [00:06<00:29,  7.57it/s]predicting train subjects:  18%|█▊        | 47/266 [00:06<00:28,  7.57it/s]predicting train subjects:  18%|█▊        | 48/266 [00:06<00:29,  7.51it/s]predicting train subjects:  18%|█▊        | 49/266 [00:06<00:29,  7.40it/s]predicting train subjects:  19%|█▉        | 50/266 [00:07<00:29,  7.39it/s]predicting train subjects:  19%|█▉        | 51/266 [00:07<00:28,  7.44it/s]predicting train subjects:  20%|█▉        | 52/266 [00:07<00:28,  7.48it/s]predicting train subjects:  20%|█▉        | 53/266 [00:07<00:28,  7.50it/s]predicting train subjects:  20%|██        | 54/266 [00:07<00:28,  7.49it/s]predicting train subjects:  21%|██        | 55/266 [00:07<00:28,  7.51it/s]predicting train subjects:  21%|██        | 56/266 [00:07<00:27,  7.52it/s]predicting train subjects:  21%|██▏       | 57/266 [00:08<00:27,  7.49it/s]predicting train subjects:  22%|██▏       | 58/266 [00:08<00:27,  7.50it/s]predicting train subjects:  22%|██▏       | 59/266 [00:08<00:28,  7.28it/s]predicting train subjects:  23%|██▎       | 60/266 [00:08<00:28,  7.12it/s]predicting train subjects:  23%|██▎       | 61/266 [00:08<00:29,  6.92it/s]predicting train subjects:  23%|██▎       | 62/266 [00:08<00:29,  6.84it/s]predicting train subjects:  24%|██▎       | 63/266 [00:08<00:29,  6.81it/s]predicting train subjects:  24%|██▍       | 64/266 [00:09<00:29,  6.75it/s]predicting train subjects:  24%|██▍       | 65/266 [00:09<00:29,  6.76it/s]predicting train subjects:  25%|██▍       | 66/266 [00:09<00:29,  6.75it/s]predicting train subjects:  25%|██▌       | 67/266 [00:09<00:29,  6.76it/s]predicting train subjects:  26%|██▌       | 68/266 [00:09<00:29,  6.63it/s]predicting train subjects:  26%|██▌       | 69/266 [00:09<00:29,  6.66it/s]predicting train subjects:  26%|██▋       | 70/266 [00:09<00:29,  6.69it/s]predicting train subjects:  27%|██▋       | 71/266 [00:10<00:29,  6.68it/s]predicting train subjects:  27%|██▋       | 72/266 [00:10<00:29,  6.67it/s]predicting train subjects:  27%|██▋       | 73/266 [00:10<00:28,  6.69it/s]predicting train subjects:  28%|██▊       | 74/266 [00:10<00:28,  6.71it/s]predicting train subjects:  28%|██▊       | 75/266 [00:10<00:28,  6.73it/s]predicting train subjects:  29%|██▊       | 76/266 [00:10<00:28,  6.73it/s]predicting train subjects:  29%|██▉       | 77/266 [00:11<00:33,  5.71it/s]predicting train subjects:  29%|██▉       | 78/266 [00:11<00:35,  5.30it/s]predicting train subjects:  30%|██▉       | 79/266 [00:11<00:32,  5.68it/s]predicting train subjects:  30%|███       | 80/266 [00:11<00:32,  5.74it/s]predicting train subjects:  30%|███       | 81/266 [00:11<00:35,  5.18it/s]predicting train subjects:  31%|███       | 82/266 [00:12<00:34,  5.36it/s]predicting train subjects:  31%|███       | 83/266 [00:12<00:33,  5.48it/s]predicting train subjects:  32%|███▏      | 84/266 [00:12<00:32,  5.58it/s]predicting train subjects:  32%|███▏      | 85/266 [00:12<00:32,  5.61it/s]predicting train subjects:  32%|███▏      | 86/266 [00:12<00:31,  5.69it/s]predicting train subjects:  33%|███▎      | 87/266 [00:12<00:31,  5.74it/s]predicting train subjects:  33%|███▎      | 88/266 [00:13<00:31,  5.71it/s]predicting train subjects:  33%|███▎      | 89/266 [00:13<00:31,  5.70it/s]predicting train subjects:  34%|███▍      | 90/266 [00:13<00:32,  5.46it/s]predicting train subjects:  34%|███▍      | 91/266 [00:13<00:31,  5.50it/s]predicting train subjects:  35%|███▍      | 92/266 [00:13<00:31,  5.60it/s]predicting train subjects:  35%|███▍      | 93/266 [00:13<00:30,  5.70it/s]predicting train subjects:  35%|███▌      | 94/266 [00:14<00:29,  5.76it/s]predicting train subjects:  36%|███▌      | 95/266 [00:14<00:29,  5.77it/s]predicting train subjects:  36%|███▌      | 96/266 [00:14<00:29,  5.82it/s]predicting train subjects:  36%|███▋      | 97/266 [00:14<00:29,  5.81it/s]predicting train subjects:  37%|███▋      | 98/266 [00:14<00:28,  5.80it/s]predicting train subjects:  37%|███▋      | 99/266 [00:15<00:28,  5.79it/s]predicting train subjects:  38%|███▊      | 100/266 [00:15<00:28,  5.90it/s]predicting train subjects:  38%|███▊      | 101/266 [00:15<00:27,  5.93it/s]predicting train subjects:  38%|███▊      | 102/266 [00:15<00:27,  6.00it/s]predicting train subjects:  39%|███▊      | 103/266 [00:15<00:28,  5.66it/s]predicting train subjects:  39%|███▉      | 104/266 [00:15<00:28,  5.76it/s]predicting train subjects:  39%|███▉      | 105/266 [00:16<00:27,  5.86it/s]predicting train subjects:  40%|███▉      | 106/266 [00:16<00:26,  5.94it/s]predicting train subjects:  40%|████      | 107/266 [00:16<00:26,  5.99it/s]predicting train subjects:  41%|████      | 108/266 [00:16<00:26,  6.02it/s]predicting train subjects:  41%|████      | 109/266 [00:16<00:25,  6.08it/s]predicting train subjects:  41%|████▏     | 110/266 [00:16<00:25,  6.12it/s]predicting train subjects:  42%|████▏     | 111/266 [00:17<00:25,  6.12it/s]predicting train subjects:  42%|████▏     | 112/266 [00:17<00:25,  6.12it/s]predicting train subjects:  42%|████▏     | 113/266 [00:17<00:25,  6.11it/s]predicting train subjects:  43%|████▎     | 114/266 [00:17<00:25,  6.06it/s]predicting train subjects:  43%|████▎     | 115/266 [00:17<00:24,  6.08it/s]predicting train subjects:  44%|████▎     | 116/266 [00:17<00:24,  6.08it/s]predicting train subjects:  44%|████▍     | 117/266 [00:18<00:24,  6.03it/s]predicting train subjects:  44%|████▍     | 118/266 [00:18<00:23,  6.23it/s]predicting train subjects:  45%|████▍     | 119/266 [00:18<00:23,  6.37it/s]predicting train subjects:  45%|████▌     | 120/266 [00:18<00:22,  6.50it/s]predicting train subjects:  45%|████▌     | 121/266 [00:18<00:22,  6.56it/s]predicting train subjects:  46%|████▌     | 122/266 [00:18<00:21,  6.63it/s]predicting train subjects:  46%|████▌     | 123/266 [00:18<00:21,  6.66it/s]predicting train subjects:  47%|████▋     | 124/266 [00:19<00:21,  6.71it/s]predicting train subjects:  47%|████▋     | 125/266 [00:19<00:20,  6.76it/s]predicting train subjects:  47%|████▋     | 126/266 [00:19<00:20,  6.74it/s]predicting train subjects:  48%|████▊     | 127/266 [00:19<00:20,  6.75it/s]predicting train subjects:  48%|████▊     | 128/266 [00:19<00:20,  6.76it/s]predicting train subjects:  48%|████▊     | 129/266 [00:19<00:20,  6.77it/s]predicting train subjects:  49%|████▉     | 130/266 [00:19<00:20,  6.78it/s]predicting train subjects:  49%|████▉     | 131/266 [00:20<00:19,  6.76it/s]predicting train subjects:  50%|████▉     | 132/266 [00:20<00:19,  6.78it/s]predicting train subjects:  50%|█████     | 133/266 [00:20<00:19,  6.81it/s]predicting train subjects:  50%|█████     | 134/266 [00:20<00:19,  6.81it/s]predicting train subjects:  51%|█████     | 135/266 [00:20<00:19,  6.77it/s]predicting train subjects:  51%|█████     | 136/266 [00:20<00:18,  6.88it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:20<00:18,  6.95it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:21<00:18,  7.04it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:21<00:17,  7.08it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:21<00:17,  7.15it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:21<00:17,  7.20it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:21<00:17,  7.20it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:21<00:17,  7.22it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:21<00:16,  7.18it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:22<00:16,  7.19it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:22<00:16,  7.18it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:22<00:16,  7.12it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:22<00:16,  7.08it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:22<00:16,  7.10it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:22<00:16,  7.07it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:22<00:16,  7.06it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:23<00:16,  7.07it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:23<00:15,  7.10it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:23<00:16,  6.66it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:23<00:17,  6.37it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:23<00:17,  6.20it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:23<00:17,  6.07it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:24<00:18,  5.96it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:24<00:18,  5.92it/s]predicting train subjects:  60%|██████    | 160/266 [00:24<00:18,  5.89it/s]predicting train subjects:  61%|██████    | 161/266 [00:24<00:17,  5.88it/s]predicting train subjects:  61%|██████    | 162/266 [00:24<00:17,  5.89it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:24<00:17,  5.86it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:25<00:17,  5.82it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:25<00:17,  5.80it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:25<00:17,  5.86it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:25<00:16,  5.91it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:25<00:16,  5.90it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:25<00:16,  5.89it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:26<00:16,  5.91it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:26<00:16,  5.90it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:26<00:17,  5.52it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:26<00:18,  5.13it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:26<00:18,  5.04it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:27<00:16,  5.57it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:27<00:16,  5.57it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:27<00:15,  5.81it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:27<00:14,  5.97it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:27<00:14,  6.12it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:27<00:13,  6.26it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:27<00:13,  6.35it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:28<00:13,  6.42it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:28<00:12,  6.46it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:28<00:12,  6.50it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:28<00:12,  6.52it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:28<00:12,  6.52it/s]predicting train subjects:  70%|███████   | 187/266 [00:28<00:12,  6.54it/s]predicting train subjects:  71%|███████   | 188/266 [00:29<00:11,  6.55it/s]predicting train subjects:  71%|███████   | 189/266 [00:29<00:11,  6.52it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:29<00:11,  6.54it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:29<00:11,  6.56it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:29<00:11,  6.56it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:29<00:11,  6.56it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:29<00:10,  6.57it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:30<00:11,  6.42it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:30<00:11,  6.22it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:30<00:11,  6.18it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:30<00:11,  5.98it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:30<00:11,  5.99it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:30<00:11,  5.97it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:31<00:10,  5.95it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:31<00:10,  5.95it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:31<00:10,  5.87it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:31<00:10,  5.87it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:31<00:10,  5.89it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:32<00:10,  5.87it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:32<00:09,  5.90it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:32<00:09,  5.89it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:32<00:09,  5.88it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:32<00:09,  5.88it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:32<00:09,  5.91it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:33<00:09,  5.90it/s]predicting train subjects:  80%|████████  | 213/266 [00:33<00:08,  5.99it/s]predicting train subjects:  80%|████████  | 214/266 [00:33<00:08,  6.12it/s]predicting train subjects:  81%|████████  | 215/266 [00:33<00:08,  6.13it/s]predicting train subjects:  81%|████████  | 216/266 [00:33<00:08,  6.18it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:33<00:07,  6.21it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:33<00:07,  6.17it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:34<00:07,  6.16it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:34<00:07,  6.15it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:34<00:07,  6.16it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:34<00:07,  6.11it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:34<00:07,  6.12it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:34<00:06,  6.16it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:35<00:06,  6.15it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:35<00:06,  6.19it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:35<00:06,  6.20it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:35<00:06,  6.15it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:35<00:05,  6.21it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:35<00:05,  6.26it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:36<00:05,  6.56it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:36<00:04,  6.84it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:36<00:04,  6.99it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:36<00:04,  7.18it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:36<00:04,  7.27it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:36<00:04,  7.34it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:36<00:03,  7.47it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:36<00:03,  7.56it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:37<00:03,  7.51it/s]predicting train subjects:  90%|█████████ | 240/266 [00:37<00:03,  7.53it/s]predicting train subjects:  91%|█████████ | 241/266 [00:37<00:03,  7.56it/s]predicting train subjects:  91%|█████████ | 242/266 [00:37<00:03,  6.80it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:37<00:03,  7.01it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:37<00:03,  7.20it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:37<00:02,  7.32it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:38<00:02,  7.39it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:38<00:02,  7.35it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:38<00:02,  7.43it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:38<00:02,  7.31it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:38<00:02,  7.17it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:38<00:02,  6.51it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:38<00:02,  6.37it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:39<00:01,  6.56it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:39<00:01,  6.67it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:39<00:01,  6.71it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:39<00:01,  6.78it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:39<00:01,  6.77it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:39<00:01,  6.82it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:40<00:01,  6.83it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:40<00:00,  6.81it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:40<00:00,  6.75it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:40<00:00,  6.78it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:40<00:00,  6.83it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:40<00:00,  6.87it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:40<00:00,  6.83it/s]predicting train subjects: 100%|██████████| 266/266 [00:41<00:00,  6.82it/s]predicting train subjects: 100%|██████████| 266/266 [00:41<00:00,  6.48it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 70.89it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/266 [00:00<00:03, 77.84it/s]saving BB  train1-THALAMUS:   6%|▋         | 17/266 [00:00<00:03, 79.10it/s]saving BB  train1-THALAMUS:  10%|▉         | 26/266 [00:00<00:02, 81.25it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:02, 83.41it/s]saving BB  train1-THALAMUS:  17%|█▋        | 45/266 [00:00<00:02, 85.58it/s]saving BB  train1-THALAMUS:  21%|██        | 55/266 [00:00<00:02, 86.26it/s]saving BB  train1-THALAMUS:  24%|██▍       | 64/266 [00:00<00:02, 85.93it/s]saving BB  train1-THALAMUS:  27%|██▋       | 73/266 [00:00<00:02, 84.37it/s]saving BB  train1-THALAMUS:  31%|███       | 82/266 [00:00<00:02, 82.34it/s]saving BB  train1-THALAMUS:  34%|███▍      | 90/266 [00:01<00:02, 77.74it/s]saving BB  train1-THALAMUS:  37%|███▋      | 98/266 [00:01<00:02, 73.92it/s]saving BB  train1-THALAMUS:  40%|███▉      | 106/266 [00:01<00:02, 73.05it/s]saving BB  train1-THALAMUS:  43%|████▎     | 114/266 [00:01<00:02, 73.62it/s]saving BB  train1-THALAMUS:  46%|████▌     | 122/266 [00:01<00:01, 73.96it/s]saving BB  train1-THALAMUS:  49%|████▉     | 131/266 [00:01<00:01, 76.64it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 140/266 [00:01<00:01, 79.92it/s]saving BB  train1-THALAMUS:  56%|█████▋    | 150/266 [00:01<00:01, 83.19it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 159/266 [00:01<00:01, 83.51it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 168/266 [00:02<00:01, 81.65it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 177/266 [00:02<00:01, 80.62it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 186/266 [00:02<00:00, 80.06it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 195/266 [00:02<00:00, 80.87it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 204/266 [00:02<00:00, 80.29it/s]saving BB  train1-THALAMUS:  80%|████████  | 213/266 [00:02<00:00, 79.90it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 221/266 [00:02<00:00, 79.82it/s]saving BB  train1-THALAMUS:  86%|████████▋ | 230/266 [00:02<00:00, 79.95it/s]saving BB  train1-THALAMUS:  90%|█████████ | 240/266 [00:02<00:00, 83.88it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 250/266 [00:03<00:00, 86.65it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:03<00:00, 89.67it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 82.31it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<04:41,  1.06s/it]Loading train:   1%|          | 2/266 [00:01<04:23,  1.00it/s]Loading train:   1%|          | 3/266 [00:02<04:06,  1.07it/s]Loading train:   2%|▏         | 4/266 [00:03<04:12,  1.04it/s]Loading train:   2%|▏         | 5/266 [00:04<03:53,  1.12it/s]Loading train:   2%|▏         | 6/266 [00:05<03:36,  1.20it/s]Loading train:   3%|▎         | 7/266 [00:05<03:23,  1.27it/s]Loading train:   3%|▎         | 8/266 [00:06<03:14,  1.33it/s]Loading train:   3%|▎         | 9/266 [00:07<03:12,  1.33it/s]Loading train:   4%|▍         | 10/266 [00:08<03:15,  1.31it/s]Loading train:   4%|▍         | 11/266 [00:08<03:13,  1.32it/s]Loading train:   5%|▍         | 12/266 [00:09<03:08,  1.35it/s]Loading train:   5%|▍         | 13/266 [00:10<02:59,  1.41it/s]Loading train:   5%|▌         | 14/266 [00:10<02:54,  1.44it/s]Loading train:   6%|▌         | 15/266 [00:11<02:50,  1.48it/s]Loading train:   6%|▌         | 16/266 [00:12<02:47,  1.49it/s]Loading train:   6%|▋         | 17/266 [00:12<02:46,  1.50it/s]Loading train:   7%|▋         | 18/266 [00:13<02:44,  1.51it/s]Loading train:   7%|▋         | 19/266 [00:14<02:42,  1.52it/s]Loading train:   8%|▊         | 20/266 [00:14<02:41,  1.52it/s]Loading train:   8%|▊         | 21/266 [00:15<02:41,  1.52it/s]Loading train:   8%|▊         | 22/266 [00:16<02:41,  1.51it/s]Loading train:   9%|▊         | 23/266 [00:16<02:36,  1.56it/s]Loading train:   9%|▉         | 24/266 [00:17<02:29,  1.62it/s]Loading train:   9%|▉         | 25/266 [00:17<02:25,  1.66it/s]Loading train:  10%|▉         | 26/266 [00:18<02:23,  1.68it/s]Loading train:  10%|█         | 27/266 [00:18<02:19,  1.71it/s]Loading train:  11%|█         | 28/266 [00:19<02:16,  1.74it/s]Loading train:  11%|█         | 29/266 [00:19<02:14,  1.76it/s]Loading train:  11%|█▏        | 30/266 [00:20<02:13,  1.76it/s]Loading train:  12%|█▏        | 31/266 [00:21<02:12,  1.77it/s]Loading train:  12%|█▏        | 32/266 [00:21<02:11,  1.78it/s]Loading train:  12%|█▏        | 33/266 [00:22<02:10,  1.79it/s]Loading train:  13%|█▎        | 34/266 [00:22<02:09,  1.79it/s]Loading train:  13%|█▎        | 35/266 [00:23<02:09,  1.78it/s]Loading train:  14%|█▎        | 36/266 [00:23<02:08,  1.79it/s]Loading train:  14%|█▍        | 37/266 [00:24<02:07,  1.79it/s]Loading train:  14%|█▍        | 38/266 [00:25<02:07,  1.79it/s]Loading train:  15%|█▍        | 39/266 [00:25<02:06,  1.79it/s]Loading train:  15%|█▌        | 40/266 [00:26<02:05,  1.80it/s]Loading train:  15%|█▌        | 41/266 [00:26<02:07,  1.76it/s]Loading train:  16%|█▌        | 42/266 [00:27<02:08,  1.75it/s]Loading train:  16%|█▌        | 43/266 [00:27<02:08,  1.73it/s]Loading train:  17%|█▋        | 44/266 [00:28<02:08,  1.73it/s]Loading train:  17%|█▋        | 45/266 [00:29<02:08,  1.72it/s]Loading train:  17%|█▋        | 46/266 [00:29<02:08,  1.71it/s]Loading train:  18%|█▊        | 47/266 [00:30<02:08,  1.70it/s]Loading train:  18%|█▊        | 48/266 [00:30<02:08,  1.70it/s]Loading train:  18%|█▊        | 49/266 [00:31<02:07,  1.70it/s]Loading train:  19%|█▉        | 50/266 [00:32<02:07,  1.69it/s]Loading train:  19%|█▉        | 51/266 [00:32<02:06,  1.70it/s]Loading train:  20%|█▉        | 52/266 [00:33<02:05,  1.70it/s]Loading train:  20%|█▉        | 53/266 [00:33<02:05,  1.69it/s]Loading train:  20%|██        | 54/266 [00:34<02:05,  1.69it/s]Loading train:  21%|██        | 55/266 [00:34<02:03,  1.71it/s]Loading train:  21%|██        | 56/266 [00:35<02:01,  1.73it/s]Loading train:  21%|██▏       | 57/266 [00:36<01:59,  1.75it/s]Loading train:  22%|██▏       | 58/266 [00:36<01:56,  1.79it/s]Loading train:  22%|██▏       | 59/266 [00:37<02:00,  1.71it/s]Loading train:  23%|██▎       | 60/266 [00:37<02:00,  1.71it/s]Loading train:  23%|██▎       | 61/266 [00:38<02:00,  1.70it/s]Loading train:  23%|██▎       | 62/266 [00:39<02:00,  1.69it/s]Loading train:  24%|██▎       | 63/266 [00:39<02:04,  1.63it/s]Loading train:  24%|██▍       | 64/266 [00:40<02:07,  1.58it/s]Loading train:  24%|██▍       | 65/266 [00:41<02:08,  1.57it/s]Loading train:  25%|██▍       | 66/266 [00:41<02:11,  1.53it/s]Loading train:  25%|██▌       | 67/266 [00:42<02:10,  1.53it/s]Loading train:  26%|██▌       | 68/266 [00:43<02:10,  1.51it/s]Loading train:  26%|██▌       | 69/266 [00:43<02:11,  1.50it/s]Loading train:  26%|██▋       | 70/266 [00:44<02:12,  1.48it/s]Loading train:  27%|██▋       | 71/266 [00:45<02:10,  1.49it/s]Loading train:  27%|██▋       | 72/266 [00:45<02:07,  1.52it/s]Loading train:  27%|██▋       | 73/266 [00:46<02:05,  1.54it/s]Loading train:  28%|██▊       | 74/266 [00:46<02:05,  1.53it/s]Loading train:  28%|██▊       | 75/266 [00:47<02:03,  1.55it/s]Loading train:  29%|██▊       | 76/266 [00:48<02:03,  1.54it/s]Loading train:  29%|██▉       | 77/266 [00:49<02:30,  1.25it/s]Loading train:  29%|██▉       | 78/266 [00:50<02:41,  1.17it/s]Loading train:  30%|██▉       | 79/266 [00:51<02:42,  1.15it/s]Loading train:  30%|███       | 80/266 [00:52<02:40,  1.16it/s]Loading train:  30%|███       | 81/266 [00:53<02:47,  1.11it/s]Loading train:  31%|███       | 82/266 [00:53<02:40,  1.14it/s]Loading train:  31%|███       | 83/266 [00:54<02:35,  1.18it/s]Loading train:  32%|███▏      | 84/266 [00:55<02:29,  1.22it/s]Loading train:  32%|███▏      | 85/266 [00:56<02:24,  1.25it/s]Loading train:  32%|███▏      | 86/266 [00:57<02:21,  1.27it/s]Loading train:  33%|███▎      | 87/266 [00:57<02:20,  1.28it/s]Loading train:  33%|███▎      | 88/266 [00:58<02:18,  1.29it/s]Loading train:  33%|███▎      | 89/266 [00:59<02:16,  1.30it/s]Loading train:  34%|███▍      | 90/266 [01:00<02:15,  1.30it/s]Loading train:  34%|███▍      | 91/266 [01:00<02:15,  1.30it/s]Loading train:  35%|███▍      | 92/266 [01:01<02:14,  1.29it/s]Loading train:  35%|███▍      | 93/266 [01:02<02:13,  1.30it/s]Loading train:  35%|███▌      | 94/266 [01:03<02:12,  1.30it/s]Loading train:  36%|███▌      | 95/266 [01:03<02:11,  1.30it/s]Loading train:  36%|███▌      | 96/266 [01:04<02:11,  1.29it/s]Loading train:  36%|███▋      | 97/266 [01:05<02:10,  1.29it/s]Loading train:  37%|███▋      | 98/266 [01:06<02:10,  1.28it/s]Loading train:  37%|███▋      | 99/266 [01:07<02:10,  1.28it/s]Loading train:  38%|███▊      | 100/266 [01:07<02:05,  1.33it/s]Loading train:  38%|███▊      | 101/266 [01:08<02:01,  1.36it/s]Loading train:  38%|███▊      | 102/266 [01:09<01:57,  1.39it/s]Loading train:  39%|███▊      | 103/266 [01:09<01:54,  1.42it/s]Loading train:  39%|███▉      | 104/266 [01:10<01:54,  1.41it/s]Loading train:  39%|███▉      | 105/266 [01:11<01:54,  1.41it/s]Loading train:  40%|███▉      | 106/266 [01:11<01:54,  1.40it/s]Loading train:  40%|████      | 107/266 [01:12<01:51,  1.43it/s]Loading train:  41%|████      | 108/266 [01:13<01:49,  1.45it/s]Loading train:  41%|████      | 109/266 [01:13<01:48,  1.45it/s]Loading train:  41%|████▏     | 110/266 [01:14<01:47,  1.45it/s]Loading train:  42%|████▏     | 111/266 [01:15<01:46,  1.46it/s]Loading train:  42%|████▏     | 112/266 [01:16<01:44,  1.48it/s]Loading train:  42%|████▏     | 113/266 [01:16<01:42,  1.49it/s]Loading train:  43%|████▎     | 114/266 [01:17<01:42,  1.49it/s]Loading train:  43%|████▎     | 115/266 [01:18<01:42,  1.47it/s]Loading train:  44%|████▎     | 116/266 [01:18<01:41,  1.47it/s]Loading train:  44%|████▍     | 117/266 [01:19<01:39,  1.49it/s]Loading train:  44%|████▍     | 118/266 [01:20<01:38,  1.50it/s]Loading train:  45%|████▍     | 119/266 [01:20<01:37,  1.51it/s]Loading train:  45%|████▌     | 120/266 [01:21<01:35,  1.52it/s]Loading train:  45%|████▌     | 121/266 [01:21<01:34,  1.53it/s]Loading train:  46%|████▌     | 122/266 [01:22<01:34,  1.53it/s]Loading train:  46%|████▌     | 123/266 [01:23<01:34,  1.52it/s]Loading train:  47%|████▋     | 124/266 [01:23<01:33,  1.52it/s]Loading train:  47%|████▋     | 125/266 [01:24<01:33,  1.51it/s]Loading train:  47%|████▋     | 126/266 [01:25<01:31,  1.53it/s]Loading train:  48%|████▊     | 127/266 [01:25<01:33,  1.49it/s]Loading train:  48%|████▊     | 128/266 [01:26<01:32,  1.49it/s]Loading train:  48%|████▊     | 129/266 [01:27<01:32,  1.47it/s]Loading train:  49%|████▉     | 130/266 [01:27<01:31,  1.49it/s]Loading train:  49%|████▉     | 131/266 [01:28<01:29,  1.50it/s]Loading train:  50%|████▉     | 132/266 [01:29<01:28,  1.52it/s]Loading train:  50%|█████     | 133/266 [01:29<01:27,  1.52it/s]Loading train:  50%|█████     | 134/266 [01:30<01:27,  1.51it/s]Loading train:  51%|█████     | 135/266 [01:31<01:26,  1.51it/s]Loading train:  51%|█████     | 136/266 [01:31<01:23,  1.55it/s]Loading train:  52%|█████▏    | 137/266 [01:32<01:21,  1.59it/s]Loading train:  52%|█████▏    | 138/266 [01:33<01:19,  1.61it/s]Loading train:  52%|█████▏    | 139/266 [01:33<01:18,  1.62it/s]Loading train:  53%|█████▎    | 140/266 [01:34<01:17,  1.63it/s]Loading train:  53%|█████▎    | 141/266 [01:34<01:16,  1.63it/s]Loading train:  53%|█████▎    | 142/266 [01:35<01:15,  1.64it/s]Loading train:  54%|█████▍    | 143/266 [01:36<01:15,  1.64it/s]Loading train:  54%|█████▍    | 144/266 [01:36<01:14,  1.64it/s]Loading train:  55%|█████▍    | 145/266 [01:37<01:13,  1.65it/s]Loading train:  55%|█████▍    | 146/266 [01:37<01:13,  1.64it/s]Loading train:  55%|█████▌    | 147/266 [01:38<01:11,  1.65it/s]Loading train:  56%|█████▌    | 148/266 [01:39<01:11,  1.66it/s]Loading train:  56%|█████▌    | 149/266 [01:39<01:10,  1.66it/s]Loading train:  56%|█████▋    | 150/266 [01:40<01:10,  1.64it/s]Loading train:  57%|█████▋    | 151/266 [01:40<01:10,  1.63it/s]Loading train:  57%|█████▋    | 152/266 [01:41<01:09,  1.63it/s]Loading train:  58%|█████▊    | 153/266 [01:42<01:08,  1.64it/s]Loading train:  58%|█████▊    | 154/266 [01:42<01:14,  1.50it/s]Loading train:  58%|█████▊    | 155/266 [01:43<01:14,  1.49it/s]Loading train:  59%|█████▊    | 156/266 [01:44<01:13,  1.49it/s]Loading train:  59%|█████▉    | 157/266 [01:45<01:13,  1.49it/s]Loading train:  59%|█████▉    | 158/266 [01:45<01:12,  1.50it/s]Loading train:  60%|█████▉    | 159/266 [01:46<01:11,  1.50it/s]Loading train:  60%|██████    | 160/266 [01:46<01:10,  1.51it/s]Loading train:  61%|██████    | 161/266 [01:47<01:09,  1.51it/s]Loading train:  61%|██████    | 162/266 [01:48<01:07,  1.54it/s]Loading train:  61%|██████▏   | 163/266 [01:48<01:07,  1.53it/s]Loading train:  62%|██████▏   | 164/266 [01:49<01:06,  1.53it/s]Loading train:  62%|██████▏   | 165/266 [01:50<01:05,  1.54it/s]Loading train:  62%|██████▏   | 166/266 [01:50<01:06,  1.51it/s]Loading train:  63%|██████▎   | 167/266 [01:51<01:05,  1.52it/s]Loading train:  63%|██████▎   | 168/266 [01:52<01:04,  1.53it/s]Loading train:  64%|██████▎   | 169/266 [01:52<01:03,  1.52it/s]Loading train:  64%|██████▍   | 170/266 [01:53<01:03,  1.51it/s]Loading train:  64%|██████▍   | 171/266 [01:54<01:02,  1.52it/s]Loading train:  65%|██████▍   | 172/266 [01:55<01:11,  1.32it/s]Loading train:  65%|██████▌   | 173/266 [01:56<01:17,  1.21it/s]Loading train:  65%|██████▌   | 174/266 [01:57<01:18,  1.17it/s]Loading train:  66%|██████▌   | 175/266 [01:57<01:16,  1.19it/s]Loading train:  66%|██████▌   | 176/266 [01:58<01:15,  1.19it/s]Loading train:  67%|██████▋   | 177/266 [01:59<01:10,  1.26it/s]Loading train:  67%|██████▋   | 178/266 [02:00<01:06,  1.33it/s]Loading train:  67%|██████▋   | 179/266 [02:00<01:03,  1.37it/s]Loading train:  68%|██████▊   | 180/266 [02:01<01:01,  1.41it/s]Loading train:  68%|██████▊   | 181/266 [02:02<00:59,  1.43it/s]Loading train:  68%|██████▊   | 182/266 [02:02<00:58,  1.44it/s]Loading train:  69%|██████▉   | 183/266 [02:03<00:57,  1.44it/s]Loading train:  69%|██████▉   | 184/266 [02:04<00:56,  1.46it/s]Loading train:  70%|██████▉   | 185/266 [02:04<00:54,  1.48it/s]Loading train:  70%|██████▉   | 186/266 [02:05<00:54,  1.48it/s]Loading train:  70%|███████   | 187/266 [02:06<00:53,  1.48it/s]Loading train:  71%|███████   | 188/266 [02:06<00:52,  1.48it/s]Loading train:  71%|███████   | 189/266 [02:07<00:52,  1.46it/s]Loading train:  71%|███████▏  | 190/266 [02:08<00:51,  1.47it/s]Loading train:  72%|███████▏  | 191/266 [02:08<00:50,  1.48it/s]Loading train:  72%|███████▏  | 192/266 [02:09<00:52,  1.42it/s]Loading train:  73%|███████▎  | 193/266 [02:10<00:51,  1.41it/s]Loading train:  73%|███████▎  | 194/266 [02:11<00:51,  1.39it/s]Loading train:  73%|███████▎  | 195/266 [02:11<00:52,  1.36it/s]Loading train:  74%|███████▎  | 196/266 [02:12<00:52,  1.33it/s]Loading train:  74%|███████▍  | 197/266 [02:13<00:54,  1.28it/s]Loading train:  74%|███████▍  | 198/266 [02:14<00:54,  1.24it/s]Loading train:  75%|███████▍  | 199/266 [02:15<00:53,  1.26it/s]Loading train:  75%|███████▌  | 200/266 [02:15<00:52,  1.26it/s]Loading train:  76%|███████▌  | 201/266 [02:16<00:50,  1.30it/s]Loading train:  76%|███████▌  | 202/266 [02:17<00:49,  1.29it/s]Loading train:  76%|███████▋  | 203/266 [02:18<00:47,  1.33it/s]Loading train:  77%|███████▋  | 204/266 [02:18<00:46,  1.34it/s]Loading train:  77%|███████▋  | 205/266 [02:19<00:44,  1.36it/s]Loading train:  77%|███████▋  | 206/266 [02:20<00:43,  1.37it/s]Loading train:  78%|███████▊  | 207/266 [02:21<00:43,  1.35it/s]Loading train:  78%|███████▊  | 208/266 [02:21<00:42,  1.36it/s]Loading train:  79%|███████▊  | 209/266 [02:22<00:42,  1.34it/s]Loading train:  79%|███████▉  | 210/266 [02:23<00:41,  1.34it/s]Loading train:  79%|███████▉  | 211/266 [02:24<00:40,  1.36it/s]Loading train:  80%|███████▉  | 212/266 [02:25<00:59,  1.11s/it]Loading train:  80%|████████  | 213/266 [02:29<01:37,  1.85s/it]Loading train:  80%|████████  | 214/266 [02:35<02:36,  3.01s/it]Loading train:  81%|████████  | 215/266 [02:40<03:02,  3.59s/it]Loading train:  81%|████████  | 216/266 [02:43<02:54,  3.49s/it]Loading train:  82%|████████▏ | 217/266 [02:46<02:48,  3.44s/it]Loading train:  82%|████████▏ | 218/266 [02:50<02:41,  3.36s/it]Loading train:  82%|████████▏ | 219/266 [02:53<02:38,  3.37s/it]Loading train:  83%|████████▎ | 220/266 [02:57<02:40,  3.48s/it]Loading train:  83%|████████▎ | 221/266 [03:00<02:35,  3.46s/it]Loading train:  83%|████████▎ | 222/266 [03:03<02:31,  3.44s/it]Loading train:  84%|████████▍ | 223/266 [03:07<02:25,  3.38s/it]Loading train:  84%|████████▍ | 224/266 [03:10<02:18,  3.29s/it]Loading train:  85%|████████▍ | 225/266 [03:13<02:14,  3.28s/it]Loading train:  85%|████████▍ | 226/266 [03:16<02:11,  3.30s/it]Loading train:  85%|████████▌ | 227/266 [03:20<02:08,  3.30s/it]Loading train:  86%|████████▌ | 228/266 [03:23<02:04,  3.27s/it]Loading train:  86%|████████▌ | 229/266 [03:26<02:01,  3.29s/it]Loading train:  86%|████████▋ | 230/266 [03:30<02:00,  3.34s/it]Loading train:  87%|████████▋ | 231/266 [03:32<01:48,  3.10s/it]Loading train:  87%|████████▋ | 232/266 [03:34<01:35,  2.80s/it]Loading train:  88%|████████▊ | 233/266 [03:37<01:26,  2.62s/it]Loading train:  88%|████████▊ | 234/266 [03:39<01:18,  2.45s/it]Loading train:  88%|████████▊ | 235/266 [03:41<01:12,  2.33s/it]Loading train:  89%|████████▊ | 236/266 [03:43<01:08,  2.27s/it]Loading train:  89%|████████▉ | 237/266 [03:45<01:05,  2.24s/it]Loading train:  89%|████████▉ | 238/266 [03:47<01:02,  2.24s/it]Loading train:  90%|████████▉ | 239/266 [03:49<00:59,  2.21s/it]Loading train:  90%|█████████ | 240/266 [03:51<00:56,  2.19s/it]Loading train:  91%|█████████ | 241/266 [03:54<00:53,  2.16s/it]Loading train:  91%|█████████ | 242/266 [03:56<00:51,  2.15s/it]Loading train:  91%|█████████▏| 243/266 [03:58<00:49,  2.16s/it]Loading train:  92%|█████████▏| 244/266 [04:00<00:47,  2.16s/it]Loading train:  92%|█████████▏| 245/266 [04:02<00:45,  2.15s/it]Loading train:  92%|█████████▏| 246/266 [04:04<00:42,  2.14s/it]Loading train:  93%|█████████▎| 247/266 [04:06<00:40,  2.12s/it]Loading train:  93%|█████████▎| 248/266 [04:08<00:37,  2.10s/it]Loading train:  94%|█████████▎| 249/266 [04:11<00:36,  2.14s/it]Loading train:  94%|█████████▍| 250/266 [04:13<00:34,  2.16s/it]Loading train:  94%|█████████▍| 251/266 [04:15<00:32,  2.20s/it]Loading train:  95%|█████████▍| 252/266 [04:17<00:31,  2.23s/it]Loading train:  95%|█████████▌| 253/266 [04:20<00:28,  2.22s/it]Loading train:  95%|█████████▌| 254/266 [04:22<00:26,  2.22s/it]Loading train:  96%|█████████▌| 255/266 [04:24<00:24,  2.21s/it]Loading train:  96%|█████████▌| 256/266 [04:26<00:21,  2.19s/it]Loading train:  97%|█████████▋| 257/266 [04:28<00:19,  2.20s/it]Loading train:  97%|█████████▋| 258/266 [04:30<00:17,  2.18s/it]Loading train:  97%|█████████▋| 259/266 [04:33<00:15,  2.17s/it]Loading train:  98%|█████████▊| 260/266 [04:35<00:12,  2.14s/it]Loading train:  98%|█████████▊| 261/266 [04:37<00:10,  2.18s/it]Loading train:  98%|█████████▊| 262/266 [04:39<00:08,  2.21s/it]Loading train:  99%|█████████▉| 263/266 [04:41<00:06,  2.19s/it]Loading train:  99%|█████████▉| 264/266 [04:44<00:04,  2.20s/it]Loading train: 100%|█████████▉| 265/266 [04:46<00:02,  2.17s/it]Loading train: 100%|██████████| 266/266 [04:48<00:00,  2.16s/it]Loading train: 100%|██████████| 266/266 [04:48<00:00,  1.08s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 53.57it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:04, 52.92it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:04, 52.81it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:04, 53.60it/s]concatenating: train:  11%|█▏        | 30/266 [00:00<00:04, 55.29it/s]concatenating: train:  14%|█▍        | 37/266 [00:00<00:04, 56.62it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:03, 57.29it/s]concatenating: train:  18%|█▊        | 49/266 [00:00<00:03, 56.61it/s]concatenating: train:  21%|██        | 55/266 [00:00<00:03, 55.79it/s]concatenating: train:  23%|██▎       | 61/266 [00:01<00:03, 55.09it/s]concatenating: train:  25%|██▌       | 67/266 [00:01<00:03, 54.26it/s]concatenating: train:  27%|██▋       | 73/266 [00:01<00:03, 54.72it/s]concatenating: train:  30%|██▉       | 79/266 [00:01<00:03, 53.87it/s]concatenating: train:  32%|███▏      | 85/266 [00:01<00:03, 51.56it/s]concatenating: train:  34%|███▍      | 91/266 [00:01<00:03, 49.55it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:03, 47.91it/s]concatenating: train:  38%|███▊      | 101/266 [00:01<00:03, 47.80it/s]concatenating: train:  40%|████      | 107/266 [00:02<00:03, 48.93it/s]concatenating: train:  42%|████▏     | 113/266 [00:02<00:03, 50.34it/s]concatenating: train:  45%|████▍     | 119/266 [00:02<00:02, 51.03it/s]concatenating: train:  47%|████▋     | 125/266 [00:02<00:02, 50.54it/s]concatenating: train:  49%|████▉     | 131/266 [00:02<00:02, 49.99it/s]concatenating: train:  52%|█████▏    | 137/266 [00:02<00:02, 50.58it/s]concatenating: train:  54%|█████▍    | 143/266 [00:02<00:02, 51.74it/s]concatenating: train:  56%|█████▌    | 149/266 [00:02<00:02, 53.20it/s]concatenating: train:  58%|█████▊    | 155/266 [00:02<00:02, 53.92it/s]concatenating: train:  61%|██████    | 161/266 [00:03<00:01, 54.57it/s]concatenating: train:  63%|██████▎   | 167/266 [00:03<00:01, 55.00it/s]concatenating: train:  65%|██████▌   | 173/266 [00:03<00:01, 52.79it/s]concatenating: train:  67%|██████▋   | 179/266 [00:03<00:01, 50.35it/s]concatenating: train:  70%|██████▉   | 185/266 [00:03<00:01, 47.69it/s]concatenating: train:  71%|███████▏  | 190/266 [00:03<00:01, 45.97it/s]concatenating: train:  73%|███████▎  | 195/266 [00:03<00:01, 45.35it/s]concatenating: train:  75%|███████▌  | 200/266 [00:03<00:01, 45.64it/s]concatenating: train:  77%|███████▋  | 205/266 [00:03<00:01, 46.64it/s]concatenating: train:  79%|███████▉  | 211/266 [00:04<00:01, 47.91it/s]concatenating: train:  81%|████████  | 216/266 [00:04<00:01, 46.57it/s]concatenating: train:  83%|████████▎ | 221/266 [00:04<00:00, 45.91it/s]concatenating: train:  85%|████████▍ | 226/266 [00:04<00:00, 45.25it/s]concatenating: train:  87%|████████▋ | 231/266 [00:04<00:00, 44.64it/s]concatenating: train:  89%|████████▊ | 236/266 [00:04<00:00, 44.76it/s]concatenating: train:  91%|█████████ | 241/266 [00:04<00:00, 44.69it/s]concatenating: train:  92%|█████████▏| 246/266 [00:04<00:00, 44.71it/s]concatenating: train:  94%|█████████▍| 251/266 [00:05<00:00, 45.95it/s]concatenating: train:  97%|█████████▋| 257/266 [00:05<00:00, 48.04it/s]concatenating: train:  99%|█████████▉| 263/266 [00:05<00:00, 49.54it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 50.34it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:10<00:32, 10.79s/it]Loading test:  50%|█████     | 2/4 [00:18<00:19, 10.00s/it]Loading test:  75%|███████▌  | 3/4 [00:25<00:08,  8.89s/it]Loading test: 100%|██████████| 4/4 [00:39<00:00, 10.47s/it]Loading test: 100%|██████████| 4/4 [00:39<00:00,  9.85s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 50.14it/s]
Epoch 00042: val_mDice did not improve from 0.54697
Restoring model weights from the end of the best epoch
Epoch 00042: early stopping
{'val_loss': [0.0006961574403582968, -0.002643525748335694, 0.1059343890649805, 0.05015517930239069, 0.029971624130646586, -0.04693206338669467, -0.0075332314219723265, 0.024964385270776584, 0.00019271357479521418, -0.02395196144397442, -0.0002712588526179122, 0.005161363049121412, 0.0060029311969913264, 0.010344992093649455, -0.021042244421045478, -0.04534823338387917, -0.019340040776924815, -0.046759808736462745, 0.026459205239345654, -0.01739990903485206, 0.002032077231123193, -0.044347964652418796, 0.02815268098124795, 0.02582295911927377, -0.0683011780527626, -0.044723079015244326, 0.02717337463393105, 0.024378903302602083, -0.017608327287302418, -0.020804552042454703, -0.013140038469293278, 0.02771900986175679, -0.022416629914018712, -0.007999635363926663, 0.024722831716608468, 0.04841947023093553, -0.007823127781782789, 0.025505975184606264, 0.026590094931664005, 0.001207609663234455, -0.021226481194827455, 0.015017071669509925], 'val_acc': [0.9936668349258952, 0.9939374059956364, 0.9939510056161999, 0.9938630406968942, 0.9937913849691008, 0.9941883282389298, 0.9941856083148171, 0.9941393503775964, 0.994165955051299, 0.9941535563977717, 0.9942336691816155, 0.9937529939575763, 0.9937998523783151, 0.9939238004589791, 0.9939600764669793, 0.9939074720401622, 0.9938823804074423, 0.9941955813698969, 0.9941130474246761, 0.9942762975953057, 0.9941698848165886, 0.9941496266324822, 0.9938990090680182, 0.9942433479110301, 0.994063470558848, 0.994089165633133, 0.9940737453347105, 0.9942926230560757, 0.9939806363718682, 0.9942088822277249, 0.9942052571412647, 0.994039886051017, 0.9941623284858154, 0.9940943052395993, 0.9940296127541781, 0.9941544674762129, 0.9941060989725383, 0.9941057942937089, 0.9941529529562068, 0.9942397213455465, 0.9938736186725626, 0.9940105629322251], 'val_mDice': [0.5410538632284028, 0.5469744628475558, 0.542353518843355, 0.5406547335921683, 0.5313826021426369, 0.5361088836755113, 0.5417122176060309, 0.5415547711233939, 0.5402098814251997, 0.5410094965924105, 0.5421991524270391, 0.5313649329890684, 0.5298228462044122, 0.5365125823849188, 0.5340504568652539, 0.527857312974208, 0.531759118249931, 0.5363540244161639, 0.538146466238623, 0.5418790673499664, 0.5348139376409592, 0.532288810159669, 0.535038683018081, 0.5399880415896328, 0.5298488855214036, 0.532696773633176, 0.5368615250581548, 0.538003832545529, 0.5271577328517478, 0.533549083077878, 0.5356328178280341, 0.5338648475577162, 0.5370919609779755, 0.5336232298509063, 0.5369192232417114, 0.5381603705380158, 0.5361518396928944, 0.5389552025434101, 0.5372239471812994, 0.5390909262389758, 0.5343082894758314, 0.534735059471935], 'loss': [0.07719807754023775, 0.05128539459373412, 0.046840619691983616, 0.04302439944465667, 0.040784167040359046, 0.039667217305272874, 0.03841766619449919, 0.03709825676772055, 0.036414891099963195, 0.03565591455004516, 0.03495701554090848, 0.03427633760791076, 0.03362462986154995, 0.033162887201944664, 0.03349252136849087, 0.03246636129929088, 0.032436993820220285, 0.0305726059108016, 0.030309234219185625, 0.030165048955013603, 0.030069076880965648, 0.029371508865330936, 0.02945144231735252, 0.029093054578284948, 0.02882693746354084, 0.02868839454486535, 0.028595722619549253, 0.02846514319298452, 0.028750578037430963, 0.028693756401440413, 0.028664923569335577, 0.028408389783277064, 0.027446339997829586, 0.027183476529751727, 0.026963178024264088, 0.026941216277863896, 0.026845703793952683, 0.02685408840623172, 0.026983375359015512, 0.0267798954807797, 0.026651292904508492, 0.026426515041168348], 'acc': [0.9921780862965381, 0.9944893406710622, 0.9949588114920681, 0.9952800438282023, 0.9954562749259734, 0.9956095387239402, 0.9957198417262917, 0.9958065460441596, 0.9958853131135933, 0.9959617084385873, 0.9960284948032294, 0.9960702175923548, 0.9961049997336628, 0.9961523382586862, 0.996161191395165, 0.9962228165975963, 0.9962276150946249, 0.9963655519050647, 0.9964267700309257, 0.9964258421594674, 0.9964522569804556, 0.9964689221772116, 0.9964738426568341, 0.9964950386925097, 0.9965215492224568, 0.9965334029800972, 0.9965500543531294, 0.9965523550402042, 0.9965554735653191, 0.9966049913811549, 0.9965862182676557, 0.9965739620556191, 0.9966396901735394, 0.9966639264269999, 0.9966735090965977, 0.9966972113306167, 0.9966938616411679, 0.9966865798555153, 0.9967110689247708, 0.9967227688667343, 0.9967317876653506, 0.9967188669772931], 'mDice': [0.8497498239600829, 0.9002495477198185, 0.908882032796059, 0.9163388607831869, 0.9207207992755306, 0.9228727428160044, 0.9253085093504393, 0.9279030245983773, 0.9292212959913664, 0.9306988994825457, 0.9320606022609568, 0.9333953804694853, 0.9346812857004526, 0.9355790223224153, 0.934910607169328, 0.9369316079632467, 0.9369821126281963, 0.9406329756955059, 0.9411295198346533, 0.9414202034282968, 0.941592405029318, 0.9429814146803946, 0.94282025868735, 0.9435220787023072, 0.9440405294593361, 0.9443117923162053, 0.9444867531977819, 0.9447462595252952, 0.9441720028089897, 0.9442670620860719, 0.9443271049471744, 0.9448461130378045, 0.9467331546672995, 0.9472440475707781, 0.9476795411335898, 0.9477163377167327, 0.9479080037212324, 0.9478905721680384, 0.9476180707204879, 0.948024723079924, 0.9482811679661706, 0.9487266527944759], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________2020-01-22 07:50:30.296109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 07:50:30.296210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 07:50:30.296225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 07:50:30.296233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 07:50:30.296535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights from thalamus:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights from thalamus:   2%|▏         | 1/44 [00:00<00:07,  5.72it/s]loading the weights from thalamus:   7%|▋         | 3/44 [00:00<00:06,  6.81it/s]loading the weights from thalamus:   9%|▉         | 4/44 [00:00<00:06,  6.48it/s]loading the weights from thalamus:  18%|█▊        | 8/44 [00:00<00:04,  8.28it/s]loading the weights from thalamus:  23%|██▎       | 10/44 [00:00<00:03,  8.83it/s]loading the weights from thalamus:  27%|██▋       | 12/44 [00:01<00:04,  6.90it/s]loading the weights from thalamus:  39%|███▊      | 17/44 [00:01<00:03,  8.93it/s]loading the weights from thalamus:  43%|████▎     | 19/44 [00:01<00:02,  9.44it/s]loading the weights from thalamus:  48%|████▊     | 21/44 [00:02<00:03,  7.48it/s]loading the weights from thalamus:  57%|█████▋    | 25/44 [00:02<00:02,  9.33it/s]loading the weights from thalamus:  61%|██████▏   | 27/44 [00:02<00:01,  9.41it/s]loading the weights from thalamus:  66%|██████▌   | 29/44 [00:02<00:01,  9.09it/s]loading the weights from thalamus:  70%|███████   | 31/44 [00:03<00:01,  6.89it/s]loading the weights from thalamus:  80%|███████▉  | 35/44 [00:03<00:01,  8.30it/s]loading the weights from thalamus:  84%|████████▍ | 37/44 [00:03<00:00,  8.85it/s]loading the weights from thalamus:  89%|████████▊ | 39/44 [00:03<00:00,  8.70it/s]loading the weights from thalamus:  93%|█████████▎| 41/44 [00:04<00:00,  6.69it/s]loading the weights from thalamus: 100%|██████████| 44/44 [00:04<00:00, 10.25it/s]
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Thalamus /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [6.84354053e-02 3.28244781e-02 8.46018078e-02 1.02746953e-02
 2.88208052e-02 7.67474126e-03 8.69041316e-02 1.13031178e-01
 9.17775624e-02 1.37723451e-02 2.77211469e-01 1.84411200e-01
 2.60181914e-04]
Train on 16849 samples, validate on 249 samples
Epoch 1/300
 - 39s - loss: 0.5957 - acc: 0.8968 - mDice: 0.3579 - val_loss: 0.7261 - val_acc: 0.9438 - val_mDice: 0.2089

Epoch 00001: val_mDice improved from -inf to 0.20895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 34s - loss: 0.4426 - acc: 0.9363 - mDice: 0.5226 - val_loss: 0.5083 - val_acc: 0.9440 - val_mDice: 0.2162

Epoch 00002: val_mDice improved from 0.20895 to 0.21624, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 34s - loss: 0.4058 - acc: 0.9408 - mDice: 0.5624 - val_loss: 0.1158 - val_acc: 0.9472 - val_mDice: 0.2246

Epoch 00003: val_mDice improved from 0.21624 to 0.22465, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 34s - loss: 0.3892 - acc: 0.9433 - mDice: 0.5803 - val_loss: 0.2351 - val_acc: 0.9474 - val_mDice: 0.2169

Epoch 00004: val_mDice did not improve from 0.22465
Epoch 5/300
 - 34s - loss: 0.3743 - acc: 0.9447 - mDice: 0.5964 - val_loss: 0.0278 - val_acc: 0.9477 - val_mDice: 0.2211

Epoch 00005: val_mDice did not improve from 0.22465
Epoch 6/300
 - 34s - loss: 0.3694 - acc: 0.9460 - mDice: 0.6016 - val_loss: 0.2164 - val_acc: 0.9442 - val_mDice: 0.1980

Epoch 00006: val_mDice did not improve from 0.22465
Epoch 7/300
 - 34s - loss: 0.3574 - acc: 0.9469 - mDice: 0.6146 - val_loss: -8.8656e-02 - val_acc: 0.9484 - val_mDice: 0.2248

Epoch 00007: val_mDice improved from 0.22465 to 0.22485, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 33s - loss: 0.3537 - acc: 0.9477 - mDice: 0.6187 - val_loss: -8.3980e-03 - val_acc: 0.9430 - val_mDice: 0.2062

Epoch 00008: val_mDice did not improve from 0.22485
Epoch 9/300
 - 34s - loss: 0.3466 - acc: 0.9484 - mDice: 0.6263 - val_loss: -1.0012e-01 - val_acc: 0.9467 - val_mDice: 0.2170

Epoch 00009: val_mDice did not improve from 0.22485
Epoch 10/300
 - 33s - loss: 0.3422 - acc: 0.9488 - mDice: 0.6311 - val_loss: -1.4152e-01 - val_acc: 0.9484 - val_mDice: 0.2312

Epoch 00010: val_mDice improved from 0.22485 to 0.23120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 34s - loss: 0.3349 - acc: 0.9495 - mDice: 0.6390 - val_loss: -6.0904e-02 - val_acc: 0.9452 - val_mDice: 0.2173

Epoch 00011: val_mDice did not improve from 0.23120
Epoch 12/300
 - 34s - loss: 0.3369 - acc: 0.9496 - mDice: 0.6368 - val_loss: -1.1794e-01 - val_acc: 0.9431 - val_mDice: 0.2036

Epoch 00012: val_mDice did not improve from 0.23120
Epoch 13/300
 - 34s - loss: 0.3323 - acc: 0.9501 - mDice: 0.6418 - val_loss: -1.1079e-01 - val_acc: 0.9480 - val_mDice: 0.2161

Epoch 00013: val_mDice did not improve from 0.23120
Epoch 14/300
 - 33s - loss: 0.3307 - acc: 0.9503 - mDice: 0.6435 - val_loss: -9.6969e-02 - val_acc: 0.9460 - val_mDice: 0.2179

Epoch 00014: val_mDice did not improve from 0.23120
Epoch 15/300
 - 34s - loss: 0.3262 - acc: 0.9506 - mDice: 0.6484 - val_loss: -1.3582e-01 - val_acc: 0.9455 - val_mDice: 0.2163

Epoch 00015: val_mDice did not improve from 0.23120
Epoch 16/300
 - 34s - loss: 0.3262 - acc: 0.9508 - mDice: 0.6484 - val_loss: -1.5878e-01 - val_acc: 0.9486 - val_mDice: 0.2173

Epoch 00016: val_mDice did not improve from 0.23120
Epoch 17/300
 - 34s - loss: 0.3222 - acc: 0.9512 - mDice: 0.6527 - val_loss: -1.3700e-01 - val_acc: 0.9490 - val_mDice: 0.2234

Epoch 00017: val_mDice did not improve from 0.23120
Epoch 18/300
 - 33s - loss: 0.3220 - acc: 0.9515 - mDice: 0.6530 - val_loss: -1.5319e-01 - val_acc: 0.9492 - val_mDice: 0.2269

Epoch 00018: val_mDice did not improve from 0.23120
Epoch 19/300
 - 34s - loss: 0.3184 - acc: 0.9516 - mDice: 0.6568 - val_loss: -1.2474e-01 - val_acc: 0.9477 - val_mDice: 0.2193

Epoch 00019: val_mDice did not improve from 0.23120
Epoch 20/300
 - 34s - loss: 0.3162 - acc: 0.9520 - mDice: 0.6592 - val_loss: -1.3539e-01 - val_acc: 0.9490 - val_mDice: 0.2256

Epoch 00020: val_mDice did not improve from 0.23120
Epoch 21/300
 - 34s - loss: 0.3156 - acc: 0.9520 - mDice: 0.6599 - val_loss: -1.7718e-01 - val_acc: 0.9477 - val_mDice: 0.2192

Epoch 00021: val_mDice did not improve from 0.23120
Epoch 22/300
 - 33s - loss: 0.3156 - acc: 0.9523 - mDice: 0.6599 - val_loss: -1.8494e-01 - val_acc: 0.9498 - val_mDice: 0.2280

Epoch 00022: val_mDice did not improve from 0.23120
Epoch 23/300
 - 33s - loss: 0.3089 - acc: 0.9524 - mDice: 0.6671 - val_loss: -1.7918e-01 - val_acc: 0.9480 - val_mDice: 0.2222

Epoch 00023: val_mDice did not improve from 0.23120
Epoch 24/300
 - 33s - loss: 0.3084 - acc: 0.9525 - mDice: 0.6676 - val_loss: -1.2625e-01 - val_acc: 0.9480 - val_mDice: 0.2310

Epoch 00024: val_mDice did not improve from 0.23120
Epoch 25/300
 - 33s - loss: 0.3082 - acc: 0.9527 - mDice: 0.6679 - val_loss: -9.6667e-02 - val_acc: 0.9481 - val_mDice: 0.2179

Epoch 00025: val_mDice did not improve from 0.23120

Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 26/300
 - 34s - loss: 0.3009 - acc: 0.9536 - mDice: 0.6757 - val_loss: -2.0921e-01 - val_acc: 0.9492 - val_mDice: 0.2255

Epoch 00026: val_mDice did not improve from 0.23120
Epoch 27/300
 - 33s - loss: 0.2986 - acc: 0.9538 - mDice: 0.6781 - val_loss: -1.6751e-01 - val_acc: 0.9480 - val_mDice: 0.2242

Epoch 00027: val_mDice did not improve from 0.23120
Epoch 28/300
 - 33s - loss: 0.2961 - acc: 0.9541 - mDice: 0.6808 - val_loss: -1.7356e-01 - val_acc: 0.9474 - val_mDice: 0.2191

Epoch 00028: val_mDice did not improve from 0.23120
Epoch 29/300
 - 33s - loss: 0.2982 - acc: 0.9539 - mDice: 0.6785 - val_loss: -1.7642e-01 - val_acc: 0.9480 - val_mDice: 0.2248

Epoch 00029: val_mDice did not improve from 0.23120
Epoch 30/300
 - 33s - loss: 0.2960 - acc: 0.9541 - mDice: 0.6796 - val_loss: -1.7472e-01 - val_acc: 0.9481 - val_mDice: 0.2284

Epoch 00030: val_mDice did not improve from 0.23120
Epoch 31/300
 - 34s - loss: 0.2907 - acc: 0.9531 - mDice: 0.6737 - val_loss: -1.5619e-01 - val_acc: 0.9485 - val_mDice: 0.2263

Epoch 00031: val_mDice did not improve from 0.23120
Epoch 32/300
 - 33s - loss: 0.2764 - acc: 0.9529 - mDice: 0.6688 - val_loss: -2.1169e-01 - val_acc: 0.9492 - val_mDice: 0.2248

Epoch 00032: val_mDice did not improve from 0.23120
Epoch 33/300
 - 33s - loss: 0.2672 - acc: 0.9520 - mDice: 0.6610 - val_loss: -1.6449e-01 - val_acc: 0.9419 - val_mDice: 0.1954

Epoch 00033: val_mDice did not improve from 0.23120
Epoch 34/300
 - 33s - loss: 0.2595 - acc: 0.9518 - mDice: 0.6559 - val_loss: -2.2701e-01 - val_acc: 0.9489 - val_mDice: 0.2215

Epoch 00034: val_mDice did not improve from 0.23120
Epoch 35/300
 - 33s - loss: 0.2595 - acc: 0.9515 - mDice: 0.6512 - val_loss: -2.3415e-01 - val_acc: 0.9465 - val_mDice: 0.2139

Epoch 00035: val_mDice did not improve from 0.23120
Epoch 36/300
 - 34s - loss: 0.2532 - acc: 0.9517 - mDice: 0.6507 - val_loss: -1.8798e-01 - val_acc: 0.9416 - val_mDice: 0.2002

Epoch 00036: val_mDice did not improve from 0.23120
Epoch 37/300
 - 33s - loss: 0.2496 - acc: 0.9515 - mDice: 0.6520 - val_loss: -2.2053e-01 - val_acc: 0.9485 - val_mDice: 0.2191

Epoch 00037: val_mDice did not improve from 0.23120
Epoch 38/300
 - 34s - loss: 0.2470 - acc: 0.9520 - mDice: 0.6505 - val_loss: -1.3294e-01 - val_acc: 0.9296 - val_mDice: 0.1487

Epoch 00038: val_mDice did not improve from 0.23120
Epoch 39/300
 - 33s - loss: 0.2447 - acc: 0.9520 - mDice: 0.6482 - val_loss: -1.0629e-01 - val_acc: 0.9325 - val_mDice: 0.1609

Epoch 00039: val_mDice did not improve from 0.23120
Epoch 40/300
 - 34s - loss: 0.2369 - acc: 0.9524 - mDice: 0.6564 - val_loss: -2.3009e-01 - val_acc: 0.9491 - val_mDice: 0.2223

Epoch 00040: val_mDice did not improve from 0.23120

Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 41/300
 - 33s - loss: 0.2329 - acc: 0.9528 - mDice: 0.6617 - val_loss: -2.3707e-01 - val_acc: 0.9497 - val_mDice: 0.2279

Epoch 00041: val_mDice did not improve from 0.23120
Epoch 42/300
 - 33s - loss: 0.2286 - acc: 0.9531 - mDice: 0.6649 - val_loss: -2.3784e-01 - val_acc: 0.9492 - val_mDice: 0.2251

Epoch 00042: val_mDice did not improve from 0.23120
Epoch 43/300
 - 34s - loss: 0.2304 - acc: 0.9530 - mDice: 0.6603 - val_loss: -2.3225e-01 - val_acc: 0.9484 - val_mDice: 0.2163

Epoch 00043: val_mDice did not improve from 0.23120
Epoch 44/300
 - 33s - loss: 0.2219 - acc: 0.9532 - mDice: 0.6642 - val_loss: -2.4233e-01 - val_acc: 0.9477 - val_mDice: 0.2191

Epoch 00044: val_mDice did not improve from 0.23120
Epoch 45/300
 - 34s - loss: 0.2269 - acc: 0.9530 - mDice: 0.6628 - val_loss: -2.3721e-01 - val_acc: 0.9481 - val_mDice: 0.2202

Epoch 00045: val_mDice did not improve from 0.23120
Epoch 46/300
 - 33s - loss: 0.2213 - acc: 0.9532 - mDice: 0.6659 - val_loss: -2.1302e-01 - val_acc: 0.9486 - val_mDice: 0.2170

Epoch 00046: val_mDice did not improve from 0.23120
Epoch 47/300
 - 34s - loss: 0.2230 - acc: 0.9534 - mDice: 0.6697 - val_loss: -2.4017e-01 - val_acc: 0.9492 - val_mDice: 0.2227

Epoch 00047: val_mDice did not improve from 0.23120
Epoch 48/300
 - 33s - loss: 0.2210 - acc: 0.9533 - mDice: 0.6704 - val_loss: -2.3925e-01 - val_acc: 0.9484 - val_mDice: 0.2224

Epoch 00048: val_mDice did not improve from 0.23120
Epoch 49/300
 - 33s - loss: 0.2176 - acc: 0.9535 - mDice: 0.6700 - val_loss: -2.2817e-01 - val_acc: 0.9491 - val_mDice: 0.2236

Epoch 00049: val_mDice did not improve from 0.23120
Epoch 50/300
 - 34s - loss: 0.2217 - acc: 0.9534 - mDice: 0.6710 - val_loss: -2.2381e-01 - val_acc: 0.9481 - val_mDice: 0.2191

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.50s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.31s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.17s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.10s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:08,  3.88it/s]Loading train:   1%|          | 2/266 [00:00<01:06,  3.98it/s]Loading train:   1%|          | 3/266 [00:00<01:05,  4.04it/s]Loading train:   2%|▏         | 4/266 [00:00<01:05,  4.01it/s]Loading train:   2%|▏         | 5/266 [00:01<01:03,  4.10it/s]Loading train:   2%|▏         | 6/266 [00:01<01:02,  4.16it/s]Loading train:   3%|▎         | 7/266 [00:01<01:01,  4.21it/s]Loading train:   3%|▎         | 8/266 [00:01<01:00,  4.24it/s]Loading train:   3%|▎         | 9/266 [00:02<01:01,  4.20it/s]Loading train:   4%|▍         | 10/266 [00:02<01:00,  4.20it/s]Loading train:   4%|▍         | 11/266 [00:02<01:00,  4.21it/s]Loading train:   5%|▍         | 12/266 [00:02<01:00,  4.20it/s]Loading train:   5%|▍         | 13/266 [00:03<00:59,  4.22it/s]Loading train:   5%|▌         | 14/266 [00:03<00:59,  4.24it/s]Loading train:   6%|▌         | 15/266 [00:03<00:59,  4.24it/s]Loading train:   6%|▌         | 16/266 [00:03<00:58,  4.24it/s]Loading train:   6%|▋         | 17/266 [00:04<00:58,  4.24it/s]Loading train:   7%|▋         | 18/266 [00:04<00:58,  4.23it/s]Loading train:   7%|▋         | 19/266 [00:04<00:58,  4.22it/s]Loading train:   8%|▊         | 20/266 [00:04<00:58,  4.22it/s]Loading train:   8%|▊         | 21/266 [00:04<00:58,  4.22it/s]Loading train:   8%|▊         | 22/266 [00:05<00:57,  4.23it/s]Loading train:   9%|▊         | 23/266 [00:05<00:57,  4.22it/s]Loading train:   9%|▉         | 24/266 [00:05<00:56,  4.26it/s]Loading train:   9%|▉         | 25/266 [00:05<00:56,  4.27it/s]Loading train:  10%|▉         | 26/266 [00:06<00:55,  4.30it/s]Loading train:  10%|█         | 27/266 [00:06<00:55,  4.33it/s]Loading train:  11%|█         | 28/266 [00:06<00:54,  4.35it/s]Loading train:  11%|█         | 29/266 [00:06<00:58,  4.08it/s]Loading train:  11%|█▏        | 30/266 [00:07<00:56,  4.18it/s]Loading train:  12%|█▏        | 31/266 [00:07<00:55,  4.24it/s]Loading train:  12%|█▏        | 32/266 [00:07<00:54,  4.30it/s]Loading train:  12%|█▏        | 33/266 [00:07<00:54,  4.31it/s]Loading train:  13%|█▎        | 34/266 [00:08<00:53,  4.36it/s]Loading train:  13%|█▎        | 35/266 [00:08<00:53,  4.32it/s]Loading train:  14%|█▎        | 36/266 [00:08<00:52,  4.34it/s]Loading train:  14%|█▍        | 37/266 [00:08<00:52,  4.34it/s]Loading train:  14%|█▍        | 38/266 [00:08<00:52,  4.37it/s]Loading train:  15%|█▍        | 39/266 [00:09<00:51,  4.37it/s]Loading train:  15%|█▌        | 40/266 [00:09<00:51,  4.38it/s]Loading train:  15%|█▌        | 41/266 [00:09<00:51,  4.41it/s]Loading train:  16%|█▌        | 42/266 [00:09<00:50,  4.41it/s]Loading train:  16%|█▌        | 43/266 [00:10<00:50,  4.41it/s]Loading train:  17%|█▋        | 44/266 [00:10<00:50,  4.43it/s]Loading train:  17%|█▋        | 45/266 [00:10<00:49,  4.43it/s]Loading train:  17%|█▋        | 46/266 [00:10<00:49,  4.43it/s]Loading train:  18%|█▊        | 47/266 [00:10<00:49,  4.43it/s]Loading train:  18%|█▊        | 48/266 [00:11<00:49,  4.44it/s]Loading train:  18%|█▊        | 49/266 [00:11<00:49,  4.43it/s]Loading train:  19%|█▉        | 50/266 [00:11<00:48,  4.43it/s]Loading train:  19%|█▉        | 51/266 [00:11<00:48,  4.46it/s]Loading train:  20%|█▉        | 52/266 [00:12<00:47,  4.48it/s]Loading train:  20%|█▉        | 53/266 [00:12<00:47,  4.47it/s]Loading train:  20%|██        | 54/266 [00:12<00:47,  4.49it/s]Loading train:  21%|██        | 55/266 [00:12<00:47,  4.48it/s]Loading train:  21%|██        | 56/266 [00:12<00:46,  4.49it/s]Loading train:  21%|██▏       | 57/266 [00:13<00:46,  4.47it/s]Loading train:  22%|██▏       | 58/266 [00:13<00:46,  4.49it/s]Loading train:  22%|██▏       | 59/266 [00:13<00:46,  4.47it/s]Loading train:  23%|██▎       | 60/266 [00:13<00:46,  4.42it/s]Loading train:  23%|██▎       | 61/266 [00:14<00:46,  4.37it/s]Loading train:  23%|██▎       | 62/266 [00:14<00:47,  4.32it/s]Loading train:  24%|██▎       | 63/266 [00:14<00:47,  4.28it/s]Loading train:  24%|██▍       | 64/266 [00:14<00:46,  4.30it/s]Loading train:  24%|██▍       | 65/266 [00:15<00:46,  4.33it/s]Loading train:  25%|██▍       | 66/266 [00:15<00:46,  4.35it/s]Loading train:  25%|██▌       | 67/266 [00:15<00:45,  4.34it/s]Loading train:  26%|██▌       | 68/266 [00:15<00:45,  4.35it/s]Loading train:  26%|██▌       | 69/266 [00:15<00:45,  4.37it/s]Loading train:  26%|██▋       | 70/266 [00:16<00:44,  4.38it/s]Loading train:  27%|██▋       | 71/266 [00:16<00:44,  4.36it/s]Loading train:  27%|██▋       | 72/266 [00:16<00:44,  4.34it/s]Loading train:  27%|██▋       | 73/266 [00:16<00:44,  4.37it/s]Loading train:  28%|██▊       | 74/266 [00:17<00:43,  4.37it/s]Loading train:  28%|██▊       | 75/266 [00:17<00:43,  4.37it/s]Loading train:  29%|██▊       | 76/266 [00:17<00:43,  4.35it/s]Loading train:  29%|██▉       | 77/266 [00:17<00:46,  4.06it/s]Loading train:  29%|██▉       | 78/266 [00:18<00:47,  3.94it/s]Loading train:  30%|██▉       | 79/266 [00:18<00:45,  4.12it/s]Loading train:  30%|███       | 80/266 [00:18<00:44,  4.17it/s]Loading train:  30%|███       | 81/266 [00:18<00:45,  4.06it/s]Loading train:  31%|███       | 82/266 [00:19<00:46,  4.00it/s]Loading train:  31%|███       | 83/266 [00:19<00:45,  3.98it/s]Loading train:  32%|███▏      | 84/266 [00:19<00:46,  3.88it/s]Loading train:  32%|███▏      | 85/266 [00:19<00:47,  3.81it/s]Loading train:  32%|███▏      | 86/266 [00:20<00:47,  3.75it/s]Loading train:  33%|███▎      | 87/266 [00:20<00:47,  3.75it/s]Loading train:  33%|███▎      | 88/266 [00:20<00:47,  3.73it/s]Loading train:  33%|███▎      | 89/266 [00:20<00:47,  3.73it/s]Loading train:  34%|███▍      | 90/266 [00:21<00:47,  3.71it/s]Loading train:  34%|███▍      | 91/266 [00:21<00:47,  3.71it/s]Loading train:  35%|███▍      | 92/266 [00:21<00:46,  3.71it/s]Loading train:  35%|███▍      | 93/266 [00:22<00:46,  3.72it/s]Loading train:  35%|███▌      | 94/266 [00:22<00:46,  3.72it/s]Loading train:  36%|███▌      | 95/266 [00:22<00:45,  3.74it/s]Loading train:  36%|███▌      | 96/266 [00:22<00:49,  3.41it/s]Loading train:  36%|███▋      | 97/266 [00:23<00:50,  3.33it/s]Loading train:  37%|███▋      | 98/266 [00:23<00:48,  3.44it/s]Loading train:  37%|███▋      | 99/266 [00:23<00:47,  3.52it/s]Loading train:  38%|███▊      | 100/266 [00:24<00:45,  3.61it/s]Loading train:  38%|███▊      | 101/266 [00:24<00:45,  3.66it/s]Loading train:  38%|███▊      | 102/266 [00:24<00:43,  3.73it/s]Loading train:  39%|███▊      | 103/266 [00:24<00:43,  3.77it/s]Loading train:  39%|███▉      | 104/266 [00:25<00:42,  3.80it/s]Loading train:  39%|███▉      | 105/266 [00:25<00:42,  3.81it/s]Loading train:  40%|███▉      | 106/266 [00:25<00:41,  3.82it/s]Loading train:  40%|████      | 107/266 [00:25<00:41,  3.84it/s]Loading train:  41%|████      | 108/266 [00:26<00:41,  3.84it/s]Loading train:  41%|████      | 109/266 [00:26<00:41,  3.81it/s]Loading train:  41%|████▏     | 110/266 [00:26<00:40,  3.86it/s]Loading train:  42%|████▏     | 111/266 [00:26<00:40,  3.85it/s]Loading train:  42%|████▏     | 112/266 [00:27<00:40,  3.81it/s]Loading train:  42%|████▏     | 113/266 [00:27<00:39,  3.83it/s]Loading train:  43%|████▎     | 114/266 [00:27<00:39,  3.83it/s]Loading train:  43%|████▎     | 115/266 [00:27<00:39,  3.82it/s]Loading train:  44%|████▎     | 116/266 [00:28<00:39,  3.80it/s]Loading train:  44%|████▍     | 117/266 [00:28<00:38,  3.85it/s]Loading train:  44%|████▍     | 118/266 [00:28<00:36,  4.01it/s]Loading train:  45%|████▍     | 119/266 [00:28<00:35,  4.16it/s]Loading train:  45%|████▌     | 120/266 [00:29<00:33,  4.30it/s]Loading train:  45%|████▌     | 121/266 [00:29<00:33,  4.38it/s]Loading train:  46%|████▌     | 122/266 [00:29<00:32,  4.48it/s]Loading train:  46%|████▌     | 123/266 [00:29<00:31,  4.54it/s]Loading train:  47%|████▋     | 124/266 [00:30<00:30,  4.60it/s]Loading train:  47%|████▋     | 125/266 [00:30<00:30,  4.60it/s]Loading train:  47%|████▋     | 126/266 [00:30<00:30,  4.60it/s]Loading train:  48%|████▊     | 127/266 [00:30<00:30,  4.60it/s]Loading train:  48%|████▊     | 128/266 [00:30<00:30,  4.54it/s]Loading train:  48%|████▊     | 129/266 [00:31<00:30,  4.55it/s]Loading train:  49%|████▉     | 130/266 [00:31<00:29,  4.55it/s]Loading train:  49%|████▉     | 131/266 [00:31<00:29,  4.58it/s]Loading train:  50%|████▉     | 132/266 [00:31<00:29,  4.62it/s]Loading train:  50%|█████     | 133/266 [00:31<00:28,  4.61it/s]Loading train:  50%|█████     | 134/266 [00:32<00:28,  4.64it/s]Loading train:  51%|█████     | 135/266 [00:32<00:28,  4.60it/s]Loading train:  51%|█████     | 136/266 [00:32<00:28,  4.56it/s]Loading train:  52%|█████▏    | 137/266 [00:32<00:28,  4.52it/s]Loading train:  52%|█████▏    | 138/266 [00:33<00:28,  4.49it/s]Loading train:  52%|█████▏    | 139/266 [00:33<00:28,  4.43it/s]Loading train:  53%|█████▎    | 140/266 [00:33<00:28,  4.42it/s]Loading train:  53%|█████▎    | 141/266 [00:33<00:28,  4.42it/s]Loading train:  53%|█████▎    | 142/266 [00:34<00:28,  4.37it/s]Loading train:  54%|█████▍    | 143/266 [00:34<00:28,  4.35it/s]Loading train:  54%|█████▍    | 144/266 [00:34<00:28,  4.34it/s]Loading train:  55%|█████▍    | 145/266 [00:34<00:27,  4.38it/s]Loading train:  55%|█████▍    | 146/266 [00:34<00:27,  4.40it/s]Loading train:  55%|█████▌    | 147/266 [00:35<00:26,  4.41it/s]Loading train:  56%|█████▌    | 148/266 [00:35<00:26,  4.40it/s]Loading train:  56%|█████▌    | 149/266 [00:35<00:26,  4.40it/s]Loading train:  56%|█████▋    | 150/266 [00:35<00:26,  4.39it/s]Loading train:  57%|█████▋    | 151/266 [00:36<00:26,  4.38it/s]Loading train:  57%|█████▋    | 152/266 [00:36<00:25,  4.39it/s]Loading train:  58%|█████▊    | 153/266 [00:36<00:25,  4.39it/s]Loading train:  58%|█████▊    | 154/266 [00:36<00:26,  4.19it/s]Loading train:  58%|█████▊    | 155/266 [00:37<00:27,  4.08it/s]Loading train:  59%|█████▊    | 156/266 [00:37<00:27,  4.04it/s]Loading train:  59%|█████▉    | 157/266 [00:37<00:27,  3.96it/s]Loading train:  59%|█████▉    | 158/266 [00:37<00:27,  3.94it/s]Loading train:  60%|█████▉    | 159/266 [00:38<00:27,  3.90it/s]Loading train:  60%|██████    | 160/266 [00:38<00:27,  3.91it/s]Loading train:  61%|██████    | 161/266 [00:38<00:26,  3.94it/s]Loading train:  61%|██████    | 162/266 [00:38<00:26,  3.99it/s]Loading train:  61%|██████▏   | 163/266 [00:39<00:25,  4.01it/s]Loading train:  62%|██████▏   | 164/266 [00:39<00:25,  4.02it/s]Loading train:  62%|██████▏   | 165/266 [00:39<00:25,  4.02it/s]Loading train:  62%|██████▏   | 166/266 [00:39<00:24,  4.03it/s]Loading train:  63%|██████▎   | 167/266 [00:40<00:24,  4.03it/s]Loading train:  63%|██████▎   | 168/266 [00:40<00:24,  4.04it/s]Loading train:  64%|██████▎   | 169/266 [00:40<00:24,  4.02it/s]Loading train:  64%|██████▍   | 170/266 [00:40<00:23,  4.03it/s]Loading train:  64%|██████▍   | 171/266 [00:41<00:23,  4.03it/s]Loading train:  65%|██████▍   | 172/266 [00:41<00:22,  4.11it/s]Loading train:  65%|██████▌   | 173/266 [00:41<00:23,  3.95it/s]Loading train:  65%|██████▌   | 174/266 [00:41<00:23,  3.97it/s]Loading train:  66%|██████▌   | 175/266 [00:42<00:21,  4.19it/s]Loading train:  66%|██████▌   | 176/266 [00:42<00:21,  4.18it/s]Loading train:  67%|██████▋   | 177/266 [00:42<00:20,  4.29it/s]Loading train:  67%|██████▋   | 178/266 [00:42<00:20,  4.35it/s]Loading train:  67%|██████▋   | 179/266 [00:42<00:19,  4.38it/s]Loading train:  68%|██████▊   | 180/266 [00:43<00:19,  4.43it/s]Loading train:  68%|██████▊   | 181/266 [00:43<00:19,  4.40it/s]Loading train:  68%|██████▊   | 182/266 [00:43<00:18,  4.47it/s]Loading train:  69%|██████▉   | 183/266 [00:43<00:18,  4.46it/s]Loading train:  69%|██████▉   | 184/266 [00:44<00:18,  4.45it/s]Loading train:  70%|██████▉   | 185/266 [00:44<00:18,  4.49it/s]Loading train:  70%|██████▉   | 186/266 [00:44<00:17,  4.49it/s]Loading train:  70%|███████   | 187/266 [00:44<00:17,  4.45it/s]Loading train:  71%|███████   | 188/266 [00:44<00:17,  4.47it/s]Loading train:  71%|███████   | 189/266 [00:45<00:17,  4.48it/s]Loading train:  71%|███████▏  | 190/266 [00:45<00:17,  4.46it/s]Loading train:  72%|███████▏  | 191/266 [00:45<00:16,  4.48it/s]Loading train:  72%|███████▏  | 192/266 [00:45<00:16,  4.47it/s]Loading train:  73%|███████▎  | 193/266 [00:46<00:16,  4.50it/s]Loading train:  73%|███████▎  | 194/266 [00:46<00:16,  4.47it/s]Loading train:  73%|███████▎  | 195/266 [00:46<00:16,  4.32it/s]Loading train:  74%|███████▎  | 196/266 [00:46<00:16,  4.18it/s]Loading train:  74%|███████▍  | 197/266 [00:47<00:18,  3.82it/s]Loading train:  74%|███████▍  | 198/266 [00:47<00:17,  3.80it/s]Loading train:  75%|███████▍  | 199/266 [00:47<00:17,  3.78it/s]Loading train:  75%|███████▌  | 200/266 [00:47<00:17,  3.78it/s]Loading train:  76%|███████▌  | 201/266 [00:48<00:17,  3.76it/s]Loading train:  76%|███████▌  | 202/266 [00:48<00:17,  3.76it/s]Loading train:  76%|███████▋  | 203/266 [00:48<00:16,  3.77it/s]Loading train:  77%|███████▋  | 204/266 [00:48<00:16,  3.80it/s]Loading train:  77%|███████▋  | 205/266 [00:49<00:16,  3.79it/s]Loading train:  77%|███████▋  | 206/266 [00:49<00:15,  3.80it/s]Loading train:  78%|███████▊  | 207/266 [00:49<00:15,  3.80it/s]Loading train:  78%|███████▊  | 208/266 [00:49<00:15,  3.81it/s]Loading train:  79%|███████▊  | 209/266 [00:50<00:14,  3.80it/s]Loading train:  79%|███████▉  | 210/266 [00:50<00:14,  3.82it/s]Loading train:  79%|███████▉  | 211/266 [00:50<00:14,  3.83it/s]Loading train:  80%|███████▉  | 212/266 [00:51<00:14,  3.85it/s]Loading train:  80%|████████  | 213/266 [00:51<00:13,  3.96it/s]Loading train:  80%|████████  | 214/266 [00:51<00:12,  4.05it/s]Loading train:  81%|████████  | 215/266 [00:51<00:12,  4.12it/s]Loading train:  81%|████████  | 216/266 [00:51<00:12,  4.15it/s]Loading train:  82%|████████▏ | 217/266 [00:52<00:11,  4.17it/s]Loading train:  82%|████████▏ | 218/266 [00:52<00:11,  4.20it/s]Loading train:  82%|████████▏ | 219/266 [00:52<00:11,  4.23it/s]Loading train:  83%|████████▎ | 220/266 [00:52<00:10,  4.23it/s]Loading train:  83%|████████▎ | 221/266 [00:53<00:10,  4.25it/s]Loading train:  83%|████████▎ | 222/266 [00:53<00:10,  4.25it/s]Loading train:  84%|████████▍ | 223/266 [00:53<00:10,  4.24it/s]Loading train:  84%|████████▍ | 224/266 [00:53<00:09,  4.25it/s]Loading train:  85%|████████▍ | 225/266 [00:54<00:09,  4.26it/s]Loading train:  85%|████████▍ | 226/266 [00:54<00:09,  4.29it/s]Loading train:  85%|████████▌ | 227/266 [00:54<00:09,  4.30it/s]Loading train:  86%|████████▌ | 228/266 [00:54<00:08,  4.31it/s]Loading train:  86%|████████▌ | 229/266 [00:55<00:08,  4.32it/s]Loading train:  86%|████████▋ | 230/266 [00:55<00:08,  4.32it/s]Loading train:  87%|████████▋ | 231/266 [00:55<00:07,  4.48it/s]Loading train:  87%|████████▋ | 232/266 [00:55<00:07,  4.64it/s]Loading train:  88%|████████▊ | 233/266 [00:55<00:06,  4.74it/s]Loading train:  88%|████████▊ | 234/266 [00:56<00:06,  4.84it/s]Loading train:  88%|████████▊ | 235/266 [00:56<00:06,  4.89it/s]Loading train:  89%|████████▊ | 236/266 [00:56<00:06,  4.94it/s]Loading train:  89%|████████▉ | 237/266 [00:56<00:05,  4.93it/s]Loading train:  89%|████████▉ | 238/266 [00:56<00:05,  4.89it/s]Loading train:  90%|████████▉ | 239/266 [00:57<00:05,  4.90it/s]Loading train:  90%|█████████ | 240/266 [00:57<00:05,  4.97it/s]Loading train:  91%|█████████ | 241/266 [00:57<00:04,  5.00it/s]Loading train:  91%|█████████ | 242/266 [00:57<00:04,  5.02it/s]Loading train:  91%|█████████▏| 243/266 [00:57<00:04,  5.04it/s]Loading train:  92%|█████████▏| 244/266 [00:58<00:04,  5.07it/s]Loading train:  92%|█████████▏| 245/266 [00:58<00:04,  5.02it/s]Loading train:  92%|█████████▏| 246/266 [00:58<00:03,  5.02it/s]Loading train:  93%|█████████▎| 247/266 [00:58<00:03,  5.06it/s]Loading train:  93%|█████████▎| 248/266 [00:58<00:03,  5.04it/s]Loading train:  94%|█████████▎| 249/266 [00:59<00:03,  4.93it/s]Loading train:  94%|█████████▍| 250/266 [00:59<00:03,  4.83it/s]Loading train:  94%|█████████▍| 251/266 [00:59<00:03,  4.78it/s]Loading train:  95%|█████████▍| 252/266 [00:59<00:02,  4.75it/s]Loading train:  95%|█████████▌| 253/266 [00:59<00:02,  4.73it/s]Loading train:  95%|█████████▌| 254/266 [01:00<00:02,  4.68it/s]Loading train:  96%|█████████▌| 255/266 [01:00<00:02,  4.66it/s]Loading train:  96%|█████████▌| 256/266 [01:00<00:02,  4.66it/s]Loading train:  97%|█████████▋| 257/266 [01:00<00:01,  4.64it/s]Loading train:  97%|█████████▋| 258/266 [01:00<00:01,  4.59it/s]Loading train:  97%|█████████▋| 259/266 [01:01<00:01,  4.63it/s]Loading train:  98%|█████████▊| 260/266 [01:01<00:01,  4.57it/s]Loading train:  98%|█████████▊| 261/266 [01:01<00:01,  4.53it/s]Loading train:  98%|█████████▊| 262/266 [01:01<00:00,  4.53it/s]Loading train:  99%|█████████▉| 263/266 [01:02<00:00,  4.53it/s]Loading train:  99%|█████████▉| 264/266 [01:02<00:00,  4.54it/s]Loading train: 100%|█████████▉| 265/266 [01:02<00:00,  4.53it/s]Loading train: 100%|██████████| 266/266 [01:02<00:00,  4.54it/s]Loading train: 100%|██████████| 266/266 [01:02<00:00,  4.24it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 46.73it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:05, 47.36it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:05, 47.67it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:05, 47.56it/s]concatenating: train:   9%|▉         | 25/266 [00:00<00:05, 47.20it/s]concatenating: train:  11%|█▏        | 30/266 [00:00<00:04, 47.82it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:04, 47.47it/s]concatenating: train:  15%|█▌        | 40/266 [00:00<00:04, 47.35it/s]concatenating: train:  17%|█▋        | 46/266 [00:00<00:04, 48.35it/s]concatenating: train:  19%|█▉        | 51/266 [00:01<00:04, 48.41it/s]concatenating: train:  21%|██        | 56/266 [00:01<00:04, 47.83it/s]concatenating: train:  23%|██▎       | 61/266 [00:01<00:04, 47.64it/s]concatenating: train:  25%|██▍       | 66/266 [00:01<00:04, 46.97it/s]concatenating: train:  27%|██▋       | 71/266 [00:01<00:04, 46.78it/s]concatenating: train:  29%|██▊       | 76/266 [00:01<00:04, 46.89it/s]concatenating: train:  30%|███       | 81/266 [00:01<00:03, 46.55it/s]concatenating: train:  32%|███▏      | 86/266 [00:01<00:04, 44.87it/s]concatenating: train:  34%|███▍      | 91/266 [00:01<00:04, 43.70it/s]concatenating: train:  36%|███▌      | 96/266 [00:02<00:03, 43.20it/s]concatenating: train:  38%|███▊      | 101/266 [00:02<00:03, 42.87it/s]concatenating: train:  40%|███▉      | 106/266 [00:02<00:03, 43.07it/s]concatenating: train:  42%|████▏     | 111/266 [00:02<00:03, 42.99it/s]concatenating: train:  44%|████▎     | 116/266 [00:02<00:03, 43.01it/s]concatenating: train:  46%|████▌     | 122/266 [00:02<00:03, 44.97it/s]concatenating: train:  48%|████▊     | 128/266 [00:02<00:02, 46.55it/s]concatenating: train:  50%|█████     | 134/266 [00:02<00:02, 48.12it/s]concatenating: train:  52%|█████▏    | 139/266 [00:02<00:02, 48.27it/s]concatenating: train:  54%|█████▍    | 144/266 [00:03<00:02, 48.44it/s]concatenating: train:  56%|█████▌    | 149/266 [00:03<00:02, 48.04it/s]concatenating: train:  58%|█████▊    | 154/266 [00:03<00:02, 48.01it/s]concatenating: train:  60%|█████▉    | 159/266 [00:03<00:02, 46.42it/s]concatenating: train:  62%|██████▏   | 164/266 [00:03<00:02, 45.96it/s]concatenating: train:  64%|██████▎   | 169/266 [00:03<00:02, 45.26it/s]concatenating: train:  65%|██████▌   | 174/266 [00:03<00:02, 45.75it/s]concatenating: train:  68%|██████▊   | 180/266 [00:03<00:01, 47.29it/s]concatenating: train:  70%|██████▉   | 186/266 [00:03<00:01, 48.05it/s]concatenating: train:  72%|███████▏  | 192/266 [00:04<00:01, 48.67it/s]concatenating: train:  74%|███████▍  | 197/266 [00:04<00:01, 47.71it/s]concatenating: train:  76%|███████▌  | 202/266 [00:04<00:01, 46.10it/s]concatenating: train:  78%|███████▊  | 207/266 [00:04<00:01, 44.73it/s]concatenating: train:  80%|███████▉  | 212/266 [00:04<00:01, 44.28it/s]concatenating: train:  82%|████████▏ | 217/266 [00:04<00:01, 45.03it/s]concatenating: train:  83%|████████▎ | 222/266 [00:04<00:00, 46.13it/s]concatenating: train:  85%|████████▌ | 227/266 [00:04<00:00, 46.43it/s]concatenating: train:  88%|████████▊ | 233/266 [00:04<00:00, 48.07it/s]concatenating: train:  90%|████████▉ | 239/266 [00:05<00:00, 49.91it/s]concatenating: train:  92%|█████████▏| 245/266 [00:05<00:00, 51.70it/s]concatenating: train:  95%|█████████▍| 252/266 [00:05<00:00, 54.81it/s]concatenating: train:  98%|█████████▊| 260/266 [00:05<00:00, 58.37it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 48.15it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:00,  4.02it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  4.16it/s]Loading test:  75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  4.08it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  4.14it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 380.38it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<01:03,  4.17it/s]Loading trainS:   1%|          | 2/266 [00:00<01:02,  4.24it/s]Loading trainS:   1%|          | 3/266 [00:00<01:01,  4.25it/s]Loading trainS:   2%|▏         | 4/266 [00:00<01:01,  4.24it/s]Loading trainS:   2%|▏         | 5/266 [00:01<01:00,  4.30it/s]Loading trainS:   2%|▏         | 6/266 [00:01<01:00,  4.32it/s]Loading trainS:   3%|▎         | 7/266 [00:01<00:59,  4.37it/s]Loading trainS:   3%|▎         | 8/266 [00:01<00:58,  4.39it/s]Loading trainS:   3%|▎         | 9/266 [00:02<00:58,  4.42it/s]Loading trainS:   4%|▍         | 10/266 [00:02<00:58,  4.35it/s]Loading trainS:   4%|▍         | 11/266 [00:02<00:58,  4.34it/s]Loading trainS:   5%|▍         | 12/266 [00:02<00:58,  4.36it/s]Loading trainS:   5%|▍         | 13/266 [00:02<00:57,  4.38it/s]Loading trainS:   5%|▌         | 14/266 [00:03<00:57,  4.39it/s]Loading trainS:   6%|▌         | 15/266 [00:03<00:57,  4.35it/s]Loading trainS:   6%|▌         | 16/266 [00:03<00:57,  4.33it/s]Loading trainS:   6%|▋         | 17/266 [00:03<00:58,  4.28it/s]Loading trainS:   7%|▋         | 18/266 [00:04<01:00,  4.11it/s]Loading trainS:   7%|▋         | 19/266 [00:04<00:58,  4.19it/s]Loading trainS:   8%|▊         | 20/266 [00:04<00:57,  4.26it/s]Loading trainS:   8%|▊         | 21/266 [00:04<00:56,  4.31it/s]Loading trainS:   8%|▊         | 22/266 [00:05<00:56,  4.34it/s]Loading trainS:   9%|▊         | 23/266 [00:05<00:55,  4.38it/s]Loading trainS:   9%|▉         | 24/266 [00:05<00:54,  4.41it/s]Loading trainS:   9%|▉         | 25/266 [00:05<00:54,  4.44it/s]Loading trainS:  10%|▉         | 26/266 [00:05<00:54,  4.44it/s]Loading trainS:  10%|█         | 27/266 [00:06<00:53,  4.44it/s]Loading trainS:  11%|█         | 28/266 [00:06<00:53,  4.46it/s]Loading trainS:  11%|█         | 29/266 [00:06<00:52,  4.50it/s]Loading trainS:  11%|█▏        | 30/266 [00:06<00:52,  4.52it/s]Loading trainS:  12%|█▏        | 31/266 [00:07<00:52,  4.50it/s]Loading trainS:  12%|█▏        | 32/266 [00:07<00:51,  4.54it/s]Loading trainS:  12%|█▏        | 33/266 [00:07<00:51,  4.53it/s]Loading trainS:  13%|█▎        | 34/266 [00:07<00:51,  4.53it/s]Loading trainS:  13%|█▎        | 35/266 [00:07<00:50,  4.54it/s]Loading trainS:  14%|█▎        | 36/266 [00:08<00:50,  4.56it/s]Loading trainS:  14%|█▍        | 37/266 [00:08<00:50,  4.56it/s]Loading trainS:  14%|█▍        | 38/266 [00:08<00:50,  4.56it/s]Loading trainS:  15%|█▍        | 39/266 [00:08<00:49,  4.57it/s]Loading trainS:  15%|█▌        | 40/266 [00:09<00:49,  4.53it/s]Loading trainS:  15%|█▌        | 41/266 [00:09<00:49,  4.51it/s]Loading trainS:  16%|█▌        | 42/266 [00:09<00:49,  4.50it/s]Loading trainS:  16%|█▌        | 43/266 [00:09<00:49,  4.51it/s]Loading trainS:  17%|█▋        | 44/266 [00:09<00:49,  4.49it/s]Loading trainS:  17%|█▋        | 45/266 [00:10<00:48,  4.52it/s]Loading trainS:  17%|█▋        | 46/266 [00:10<00:48,  4.54it/s]Loading trainS:  18%|█▊        | 47/266 [00:10<00:48,  4.53it/s]Loading trainS:  18%|█▊        | 48/266 [00:10<00:47,  4.57it/s]Loading trainS:  18%|█▊        | 49/266 [00:11<00:47,  4.58it/s]Loading trainS:  19%|█▉        | 50/266 [00:11<00:47,  4.56it/s]Loading trainS:  19%|█▉        | 51/266 [00:11<00:47,  4.55it/s]Loading trainS:  20%|█▉        | 52/266 [00:11<00:47,  4.52it/s]Loading trainS:  20%|█▉        | 53/266 [00:11<00:47,  4.49it/s]Loading trainS:  20%|██        | 54/266 [00:12<00:47,  4.49it/s]Loading trainS:  21%|██        | 55/266 [00:12<00:46,  4.49it/s]Loading trainS:  21%|██        | 56/266 [00:12<00:46,  4.51it/s]Loading trainS:  21%|██▏       | 57/266 [00:12<00:46,  4.48it/s]Loading trainS:  22%|██▏       | 58/266 [00:13<00:47,  4.42it/s]Loading trainS:  22%|██▏       | 59/266 [00:13<00:47,  4.40it/s]Loading trainS:  23%|██▎       | 60/266 [00:13<00:46,  4.41it/s]Loading trainS:  23%|██▎       | 61/266 [00:13<00:46,  4.42it/s]Loading trainS:  23%|██▎       | 62/266 [00:13<00:45,  4.44it/s]Loading trainS:  24%|██▎       | 63/266 [00:14<00:45,  4.44it/s]Loading trainS:  24%|██▍       | 64/266 [00:14<00:45,  4.43it/s]Loading trainS:  24%|██▍       | 65/266 [00:14<00:45,  4.45it/s]Loading trainS:  25%|██▍       | 66/266 [00:14<00:45,  4.43it/s]Loading trainS:  25%|██▌       | 67/266 [00:15<00:45,  4.41it/s]Loading trainS:  26%|██▌       | 68/266 [00:15<00:44,  4.42it/s]Loading trainS:  26%|██▌       | 69/266 [00:15<00:44,  4.45it/s]Loading trainS:  26%|██▋       | 70/266 [00:15<00:43,  4.46it/s]Loading trainS:  27%|██▋       | 71/266 [00:15<00:43,  4.47it/s]Loading trainS:  27%|██▋       | 72/266 [00:16<00:43,  4.46it/s]Loading trainS:  27%|██▋       | 73/266 [00:16<00:43,  4.41it/s]Loading trainS:  28%|██▊       | 74/266 [00:16<00:43,  4.40it/s]Loading trainS:  28%|██▊       | 75/266 [00:16<00:43,  4.43it/s]Loading trainS:  29%|██▊       | 76/266 [00:17<00:42,  4.44it/s]Loading trainS:  29%|██▉       | 77/266 [00:17<00:45,  4.13it/s]Loading trainS:  29%|██▉       | 78/266 [00:17<00:46,  4.04it/s]Loading trainS:  30%|██▉       | 79/266 [00:17<00:44,  4.20it/s]Loading trainS:  30%|███       | 80/266 [00:18<00:43,  4.24it/s]Loading trainS:  30%|███       | 81/266 [00:18<00:45,  4.09it/s]Loading trainS:  31%|███       | 82/266 [00:18<00:45,  4.01it/s]Loading trainS:  31%|███       | 83/266 [00:18<00:46,  3.97it/s]Loading trainS:  32%|███▏      | 84/266 [00:19<00:46,  3.94it/s]Loading trainS:  32%|███▏      | 85/266 [00:19<00:46,  3.93it/s]Loading trainS:  32%|███▏      | 86/266 [00:19<00:46,  3.91it/s]Loading trainS:  33%|███▎      | 87/266 [00:19<00:45,  3.90it/s]Loading trainS:  33%|███▎      | 88/266 [00:20<00:46,  3.87it/s]Loading trainS:  33%|███▎      | 89/266 [00:20<00:45,  3.87it/s]Loading trainS:  34%|███▍      | 90/266 [00:20<00:45,  3.88it/s]Loading trainS:  34%|███▍      | 91/266 [00:20<00:45,  3.88it/s]Loading trainS:  35%|███▍      | 92/266 [00:21<00:44,  3.87it/s]Loading trainS:  35%|███▍      | 93/266 [00:21<00:44,  3.88it/s]Loading trainS:  35%|███▌      | 94/266 [00:21<00:44,  3.85it/s]Loading trainS:  36%|███▌      | 95/266 [00:22<00:44,  3.85it/s]Loading trainS:  36%|███▌      | 96/266 [00:22<00:44,  3.82it/s]Loading trainS:  36%|███▋      | 97/266 [00:22<00:44,  3.82it/s]Loading trainS:  37%|███▋      | 98/266 [00:22<00:44,  3.81it/s]Loading trainS:  37%|███▋      | 99/266 [00:23<00:43,  3.84it/s]Loading trainS:  38%|███▊      | 100/266 [00:23<00:42,  3.90it/s]Loading trainS:  38%|███▊      | 101/266 [00:23<00:41,  3.96it/s]Loading trainS:  38%|███▊      | 102/266 [00:23<00:40,  4.00it/s]Loading trainS:  39%|███▊      | 103/266 [00:24<00:40,  4.03it/s]Loading trainS:  39%|███▉      | 104/266 [00:24<00:40,  4.03it/s]Loading trainS:  39%|███▉      | 105/266 [00:24<00:39,  4.05it/s]Loading trainS:  40%|███▉      | 106/266 [00:24<00:39,  4.05it/s]Loading trainS:  40%|████      | 107/266 [00:25<00:39,  4.03it/s]Loading trainS:  41%|████      | 108/266 [00:25<00:39,  4.02it/s]Loading trainS:  41%|████      | 109/266 [00:25<00:38,  4.04it/s]Loading trainS:  41%|████▏     | 110/266 [00:25<00:38,  4.05it/s]Loading trainS:  42%|████▏     | 111/266 [00:26<00:38,  4.03it/s]Loading trainS:  42%|████▏     | 112/266 [00:26<00:38,  4.01it/s]Loading trainS:  42%|████▏     | 113/266 [00:26<00:38,  4.02it/s]Loading trainS:  43%|████▎     | 114/266 [00:26<00:37,  4.03it/s]Loading trainS:  43%|████▎     | 115/266 [00:27<00:37,  4.03it/s]Loading trainS:  44%|████▎     | 116/266 [00:27<00:37,  4.01it/s]Loading trainS:  44%|████▍     | 117/266 [00:27<00:37,  4.02it/s]Loading trainS:  44%|████▍     | 118/266 [00:27<00:35,  4.22it/s]Loading trainS:  45%|████▍     | 119/266 [00:27<00:33,  4.40it/s]Loading trainS:  45%|████▌     | 120/266 [00:28<00:32,  4.51it/s]Loading trainS:  45%|████▌     | 121/266 [00:28<00:31,  4.62it/s]Loading trainS:  46%|████▌     | 122/266 [00:28<00:30,  4.70it/s]Loading trainS:  46%|████▌     | 123/266 [00:28<00:30,  4.73it/s]Loading trainS:  47%|████▋     | 124/266 [00:28<00:30,  4.72it/s]Loading trainS:  47%|████▋     | 125/266 [00:29<00:30,  4.70it/s]Loading trainS:  47%|████▋     | 126/266 [00:29<00:29,  4.69it/s]Loading trainS:  48%|████▊     | 127/266 [00:29<00:29,  4.67it/s]Loading trainS:  48%|████▊     | 128/266 [00:29<00:29,  4.61it/s]Loading trainS:  48%|████▊     | 129/266 [00:30<00:29,  4.64it/s]Loading trainS:  49%|████▉     | 130/266 [00:30<00:29,  4.69it/s]Loading trainS:  49%|████▉     | 131/266 [00:30<00:28,  4.72it/s]Loading trainS:  50%|████▉     | 132/266 [00:30<00:28,  4.74it/s]Loading trainS:  50%|█████     | 133/266 [00:30<00:28,  4.75it/s]Loading trainS:  50%|█████     | 134/266 [00:31<00:27,  4.75it/s]Loading trainS:  51%|█████     | 135/266 [00:31<00:27,  4.76it/s]Loading trainS:  51%|█████     | 136/266 [00:31<00:27,  4.67it/s]Loading trainS:  52%|█████▏    | 137/266 [00:31<00:27,  4.66it/s]Loading trainS:  52%|█████▏    | 138/266 [00:31<00:27,  4.63it/s]Loading trainS:  52%|█████▏    | 139/266 [00:32<00:27,  4.60it/s]Loading trainS:  53%|█████▎    | 140/266 [00:32<00:27,  4.60it/s]Loading trainS:  53%|█████▎    | 141/266 [00:32<00:27,  4.59it/s]Loading trainS:  53%|█████▎    | 142/266 [00:32<00:27,  4.59it/s]Loading trainS:  54%|█████▍    | 143/266 [00:33<00:27,  4.51it/s]Loading trainS:  54%|█████▍    | 144/266 [00:33<00:27,  4.44it/s]Loading trainS:  55%|█████▍    | 145/266 [00:33<00:27,  4.45it/s]Loading trainS:  55%|█████▍    | 146/266 [00:33<00:26,  4.49it/s]Loading trainS:  55%|█████▌    | 147/266 [00:33<00:26,  4.53it/s]Loading trainS:  56%|█████▌    | 148/266 [00:34<00:25,  4.55it/s]Loading trainS:  56%|█████▌    | 149/266 [00:34<00:25,  4.54it/s]Loading trainS:  56%|█████▋    | 150/266 [00:34<00:25,  4.57it/s]Loading trainS:  57%|█████▋    | 151/266 [00:34<00:25,  4.57it/s]Loading trainS:  57%|█████▋    | 152/266 [00:35<00:25,  4.54it/s]Loading trainS:  58%|█████▊    | 153/266 [00:35<00:24,  4.52it/s]Loading trainS:  58%|█████▊    | 154/266 [00:35<00:25,  4.33it/s]Loading trainS:  58%|█████▊    | 155/266 [00:35<00:26,  4.22it/s]Loading trainS:  59%|█████▊    | 156/266 [00:36<00:26,  4.12it/s]Loading trainS:  59%|█████▉    | 157/266 [00:36<00:26,  4.10it/s]Loading trainS:  59%|█████▉    | 158/266 [00:36<00:26,  4.09it/s]Loading trainS:  60%|█████▉    | 159/266 [00:36<00:26,  4.07it/s]Loading trainS:  60%|██████    | 160/266 [00:37<00:26,  4.07it/s]Loading trainS:  61%|██████    | 161/266 [00:37<00:25,  4.07it/s]Loading trainS:  61%|██████    | 162/266 [00:37<00:26,  3.98it/s]Loading trainS:  61%|██████▏   | 163/266 [00:37<00:25,  4.02it/s]Loading trainS:  62%|██████▏   | 164/266 [00:38<00:25,  4.06it/s]Loading trainS:  62%|██████▏   | 165/266 [00:38<00:24,  4.08it/s]Loading trainS:  62%|██████▏   | 166/266 [00:38<00:24,  4.09it/s]Loading trainS:  63%|██████▎   | 167/266 [00:38<00:24,  4.09it/s]Loading trainS:  63%|██████▎   | 168/266 [00:38<00:23,  4.11it/s]Loading trainS:  64%|██████▎   | 169/266 [00:39<00:23,  4.09it/s]Loading trainS:  64%|██████▍   | 170/266 [00:39<00:23,  4.10it/s]Loading trainS:  64%|██████▍   | 171/266 [00:39<00:23,  4.11it/s]Loading trainS:  65%|██████▍   | 172/266 [00:39<00:22,  4.15it/s]Loading trainS:  65%|██████▌   | 173/266 [00:40<00:23,  3.99it/s]Loading trainS:  65%|██████▌   | 174/266 [00:40<00:22,  4.04it/s]Loading trainS:  66%|██████▌   | 175/266 [00:40<00:21,  4.26it/s]Loading trainS:  66%|██████▌   | 176/266 [00:40<00:21,  4.27it/s]Loading trainS:  67%|██████▋   | 177/266 [00:41<00:20,  4.36it/s]Loading trainS:  67%|██████▋   | 178/266 [00:41<00:19,  4.43it/s]Loading trainS:  67%|██████▋   | 179/266 [00:41<00:19,  4.45it/s]Loading trainS:  68%|██████▊   | 180/266 [00:41<00:19,  4.48it/s]Loading trainS:  68%|██████▊   | 181/266 [00:41<00:18,  4.50it/s]Loading trainS:  68%|██████▊   | 182/266 [00:42<00:18,  4.48it/s]Loading trainS:  69%|██████▉   | 183/266 [00:42<00:18,  4.50it/s]Loading trainS:  69%|██████▉   | 184/266 [00:42<00:18,  4.53it/s]Loading trainS:  70%|██████▉   | 185/266 [00:42<00:17,  4.55it/s]Loading trainS:  70%|██████▉   | 186/266 [00:43<00:17,  4.56it/s]Loading trainS:  70%|███████   | 187/266 [00:43<00:17,  4.56it/s]Loading trainS:  71%|███████   | 188/266 [00:43<00:17,  4.57it/s]Loading trainS:  71%|███████   | 189/266 [00:43<00:16,  4.56it/s]Loading trainS:  71%|███████▏  | 190/266 [00:43<00:16,  4.58it/s]Loading trainS:  72%|███████▏  | 191/266 [00:44<00:16,  4.57it/s]Loading trainS:  72%|███████▏  | 192/266 [00:44<00:16,  4.58it/s]Loading trainS:  73%|███████▎  | 193/266 [00:44<00:15,  4.58it/s]Loading trainS:  73%|███████▎  | 194/266 [00:44<00:15,  4.55it/s]Loading trainS:  73%|███████▎  | 195/266 [00:45<00:16,  4.33it/s]Loading trainS:  74%|███████▎  | 196/266 [00:45<00:16,  4.18it/s]Loading trainS:  74%|███████▍  | 197/266 [00:45<00:16,  4.09it/s]Loading trainS:  74%|███████▍  | 198/266 [00:45<00:16,  4.03it/s]Loading trainS:  75%|███████▍  | 199/266 [00:46<00:16,  4.00it/s]Loading trainS:  75%|███████▌  | 200/266 [00:46<00:16,  4.01it/s]Loading trainS:  76%|███████▌  | 201/266 [00:46<00:16,  4.00it/s]Loading trainS:  76%|███████▌  | 202/266 [00:46<00:15,  4.00it/s]Loading trainS:  76%|███████▋  | 203/266 [00:47<00:15,  4.00it/s]Loading trainS:  77%|███████▋  | 204/266 [00:47<00:15,  4.00it/s]Loading trainS:  77%|███████▋  | 205/266 [00:47<00:15,  3.99it/s]Loading trainS:  77%|███████▋  | 206/266 [00:47<00:15,  3.99it/s]Loading trainS:  78%|███████▊  | 207/266 [00:48<00:14,  4.00it/s]Loading trainS:  78%|███████▊  | 208/266 [00:48<00:14,  3.97it/s]Loading trainS:  79%|███████▊  | 209/266 [00:48<00:14,  3.95it/s]Loading trainS:  79%|███████▉  | 210/266 [00:48<00:14,  3.93it/s]Loading trainS:  79%|███████▉  | 211/266 [00:49<00:13,  3.93it/s]Loading trainS:  80%|███████▉  | 212/266 [00:49<00:14,  3.85it/s]Loading trainS:  80%|████████  | 213/266 [00:49<00:13,  3.97it/s]Loading trainS:  80%|████████  | 214/266 [00:49<00:12,  4.08it/s]Loading trainS:  81%|████████  | 215/266 [00:50<00:12,  4.16it/s]Loading trainS:  81%|████████  | 216/266 [00:50<00:11,  4.22it/s]Loading trainS:  82%|████████▏ | 217/266 [00:50<00:11,  4.26it/s]Loading trainS:  82%|████████▏ | 218/266 [00:50<00:11,  4.31it/s]Loading trainS:  82%|████████▏ | 219/266 [00:51<00:10,  4.33it/s]Loading trainS:  83%|████████▎ | 220/266 [00:51<00:10,  4.34it/s]Loading trainS:  83%|████████▎ | 221/266 [00:51<00:10,  4.35it/s]Loading trainS:  83%|████████▎ | 222/266 [00:51<00:10,  4.34it/s]Loading trainS:  84%|████████▍ | 223/266 [00:51<00:09,  4.35it/s]Loading trainS:  84%|████████▍ | 224/266 [00:52<00:09,  4.37it/s]Loading trainS:  85%|████████▍ | 225/266 [00:52<00:09,  4.36it/s]Loading trainS:  85%|████████▍ | 226/266 [00:52<00:09,  4.34it/s]Loading trainS:  85%|████████▌ | 227/266 [00:52<00:08,  4.34it/s]Loading trainS:  86%|████████▌ | 228/266 [00:53<00:08,  4.34it/s]Loading trainS:  86%|████████▌ | 229/266 [00:53<00:08,  4.34it/s]Loading trainS:  86%|████████▋ | 230/266 [00:53<00:08,  4.36it/s]Loading trainS:  87%|████████▋ | 231/266 [00:53<00:07,  4.58it/s]Loading trainS:  87%|████████▋ | 232/266 [00:53<00:07,  4.76it/s]Loading trainS:  88%|████████▊ | 233/266 [00:54<00:06,  4.89it/s]Loading trainS:  88%|████████▊ | 234/266 [00:54<00:06,  4.97it/s]Loading trainS:  88%|████████▊ | 235/266 [00:54<00:06,  5.02it/s]Loading trainS:  89%|████████▊ | 236/266 [00:54<00:05,  5.08it/s]Loading trainS:  89%|████████▉ | 237/266 [00:54<00:05,  5.09it/s]Loading trainS:  89%|████████▉ | 238/266 [00:55<00:05,  5.13it/s]Loading trainS:  90%|████████▉ | 239/266 [00:55<00:05,  5.14it/s]Loading trainS:  90%|█████████ | 240/266 [00:55<00:05,  5.16it/s]Loading trainS:  91%|█████████ | 241/266 [00:55<00:04,  5.19it/s]Loading trainS:  91%|█████████ | 242/266 [00:55<00:04,  5.19it/s]Loading trainS:  91%|█████████▏| 243/266 [00:56<00:04,  5.18it/s]Loading trainS:  92%|█████████▏| 244/266 [00:56<00:04,  5.17it/s]Loading trainS:  92%|█████████▏| 245/266 [00:56<00:04,  5.17it/s]Loading trainS:  92%|█████████▏| 246/266 [00:56<00:03,  5.18it/s]Loading trainS:  93%|█████████▎| 247/266 [00:56<00:03,  5.20it/s]Loading trainS:  93%|█████████▎| 248/266 [00:57<00:03,  5.19it/s]Loading trainS:  94%|█████████▎| 249/266 [00:57<00:03,  4.99it/s]Loading trainS:  94%|█████████▍| 250/266 [00:57<00:03,  4.81it/s]Loading trainS:  94%|█████████▍| 251/266 [00:57<00:03,  4.76it/s]Loading trainS:  95%|█████████▍| 252/266 [00:57<00:02,  4.75it/s]Loading trainS:  95%|█████████▌| 253/266 [00:58<00:02,  4.71it/s]Loading trainS:  95%|█████████▌| 254/266 [00:58<00:02,  4.70it/s]Loading trainS:  96%|█████████▌| 255/266 [00:58<00:02,  4.69it/s]Loading trainS:  96%|█████████▌| 256/266 [00:58<00:02,  4.69it/s]Loading trainS:  97%|█████████▋| 257/266 [00:58<00:01,  4.68it/s]Loading trainS:  97%|█████████▋| 258/266 [00:59<00:01,  4.67it/s]Loading trainS:  97%|█████████▋| 259/266 [00:59<00:01,  4.65it/s]Loading trainS:  98%|█████████▊| 260/266 [00:59<00:01,  4.64it/s]Loading trainS:  98%|█████████▊| 261/266 [00:59<00:01,  3.97it/s]Loading trainS:  98%|█████████▊| 262/266 [01:00<00:01,  3.77it/s]Loading trainS:  99%|█████████▉| 263/266 [01:00<00:00,  3.53it/s]Loading trainS:  99%|█████████▉| 264/266 [01:01<00:00,  2.62it/s]Loading trainS: 100%|█████████▉| 265/266 [01:01<00:00,  2.22it/s]Loading trainS: 100%|██████████| 266/266 [01:02<00:00,  2.04it/s]Loading trainS: 100%|██████████| 266/266 [01:02<00:00,  4.26it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:02,  1.48it/s]Loading testS:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  1.53it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]
Epoch 00050: val_mDice did not improve from 0.23120
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
{'val_loss': [0.7261139451260548, 0.5083484891428047, 0.1157560648927727, 0.23505322856596675, 0.027818623761904526, 0.21644763974659892, -0.08865599142739093, -0.008397960644514566, -0.10011534726464126, -0.14151553315555596, -0.06090362112684901, -0.1179448223923404, -0.1107887439654175, -0.09696915075482135, -0.1358155340973632, -0.15877981373224873, -0.13699532309210444, -0.15319451779486185, -0.12473618052151787, -0.13538754596767655, -0.17718087997003254, -0.18493856429814334, -0.1791777674811911, -0.12625041061705614, -0.09666733540983564, -0.2092108330932487, -0.16751461262145195, -0.17356393852057944, -0.1764170271774612, -0.17472224045885226, -0.15618632400191454, -0.21169307429986786, -0.1644882117229772, -0.2270090986177864, -0.23415451176674013, -0.18798436568189697, -0.2205282705106649, -0.1329418960285474, -0.10629058959912584, -0.23008739835317116, -0.23706548829304885, -0.23783939545338292, -0.232247115468165, -0.2423257290957922, -0.2372135619920899, -0.2130248260246702, -0.24017250720396577, -0.23925193834556155, -0.22816569042433218, -0.22381267555985584], 'val_acc': [0.9437783173767917, 0.944016448225841, 0.9472022736407667, 0.9473824781107615, 0.9477364586060306, 0.9441870056002973, 0.9484331502493126, 0.9430397906935358, 0.9466584245842623, 0.9483864970475315, 0.9451700994767338, 0.9431459772060196, 0.9479584962009905, 0.9460228698320657, 0.9454999441602623, 0.9486439354927185, 0.9489979179029963, 0.9492119155734419, 0.9477026711506058, 0.9489802110147285, 0.9477219806617523, 0.9498345962011192, 0.9480486066944628, 0.9480067695001043, 0.9480502076417088, 0.9491523762783373, 0.9480196357252129, 0.9473567315373554, 0.9480148151696447, 0.9480920438785629, 0.9485023471725035, 0.9492086923744784, 0.9418861298675997, 0.9488901079419148, 0.9464910956750433, 0.9415949077970053, 0.9484798185317871, 0.9295885433633644, 0.9325265829342915, 0.949089627668082, 0.9497396627583178, 0.9491829450829441, 0.9483559229766508, 0.9476560148369356, 0.9481290504635578, 0.948647155819169, 0.9491716838744749, 0.9483736236411405, 0.949094456123061, 0.9480775676099172], 'val_mDice': [0.20894896723778852, 0.21624343773447366, 0.22464943021894937, 0.2169244330690568, 0.22107979068794403, 0.1979595216282879, 0.2248451720519238, 0.20617606618018994, 0.21704350232359876, 0.23119700852646885, 0.21728739615185672, 0.2035501961218545, 0.21606723192226457, 0.21790235690084328, 0.21628928331127129, 0.21727964012737733, 0.22340388027539693, 0.22688755016010928, 0.2192661117418224, 0.2256284722063436, 0.21919616021545058, 0.22798232375139213, 0.2221975232283753, 0.2310463627837748, 0.21787912027543807, 0.225462240387637, 0.22424999552677913, 0.21908659042124767, 0.2247593543495998, 0.22842942905354213, 0.22634845460394779, 0.22484583925291238, 0.1953776223083816, 0.22148944401597404, 0.21393523027140451, 0.20024510844045854, 0.21910337170204483, 0.14866231899543939, 0.1609224871279724, 0.22234241828980694, 0.2279426731677898, 0.2251445566375093, 0.2163213200897098, 0.21906218196014804, 0.2201682519781063, 0.2169544974184898, 0.22270579028680143, 0.22239269322180844, 0.22359507895976186, 0.21908865870541358], 'loss': [0.5957142402173589, 0.44262130828319485, 0.40576295306211524, 0.3891554220142729, 0.3743192999644112, 0.3694249235937748, 0.35741430528263385, 0.3536858027275256, 0.3465932162464305, 0.34219097308967084, 0.3348921798189512, 0.3368929557785718, 0.33225141643338746, 0.33068134487329714, 0.32617607883610666, 0.3261964166986531, 0.3221604851022503, 0.3219548796212201, 0.31843219888239305, 0.31622441626562975, 0.31556597096261035, 0.31555406624814214, 0.30888391793732883, 0.3084079393951948, 0.30816286080626043, 0.300871187865582, 0.29860961007586545, 0.2961238294201326, 0.29816911234559346, 0.2959970027779647, 0.29067516653776465, 0.27639387407970184, 0.26717137586935863, 0.25947537964090633, 0.25947069095933967, 0.2531529598756015, 0.24961853687762503, 0.2470381985065238, 0.244740070174606, 0.2368735075505475, 0.23286376635459596, 0.22863575432846894, 0.23036859530607157, 0.221923191399685, 0.22689547745750385, 0.22128565843454812, 0.22302076651124023, 0.2209866689634171, 0.2175740432699228, 0.22173525454867737], 'acc': [0.896777617653843, 0.9363030461721926, 0.940820024935978, 0.9433113516165924, 0.9447354836607978, 0.9460417930892656, 0.9468856866235612, 0.9477498622115793, 0.9483690733152282, 0.94882970724313, 0.9494522710081109, 0.9496123935923151, 0.950055741469254, 0.9503065073721501, 0.9506243529981432, 0.9507820503005175, 0.9512469404153678, 0.9514832972341125, 0.9515808832610748, 0.9520137437027112, 0.9520007129118516, 0.9522951837993672, 0.9524291270571198, 0.9525260234687072, 0.9526984645277606, 0.9536150479551606, 0.9538417737259979, 0.9541151295097952, 0.9539448067557388, 0.9540577762466106, 0.9530691927042098, 0.9529026490169376, 0.9520461541643143, 0.9518265607371317, 0.9515456194955169, 0.9516523131256436, 0.9515407455201687, 0.9519729876533815, 0.9520070378140346, 0.9523551773441971, 0.9528437974410663, 0.9530521431190833, 0.9529675403697758, 0.9532365449720536, 0.9530403018280748, 0.9531914607142332, 0.9534153094156693, 0.9533491106908947, 0.9535004598987273, 0.9533514883321671], 'mDice': [0.3579418464859009, 0.5225856394907566, 0.5623947085170506, 0.5803209800905301, 0.5963617721766532, 0.6016400329889378, 0.6146257072112292, 0.6186523070157943, 0.6263168162886088, 0.6310744100355934, 0.6389741150481997, 0.636799239784725, 0.6418238710392066, 0.6435323902050659, 0.6484103237328893, 0.6483798019945731, 0.6527435855346445, 0.6529604147287694, 0.6567712912142641, 0.6591518428199857, 0.6598686625840183, 0.6598591828418419, 0.667056658026146, 0.6676106543079372, 0.667853946568768, 0.6757396592733889, 0.6781368725529353, 0.6807940842539445, 0.6784639831388504, 0.6796148290859995, 0.6736714349379419, 0.6688125669457409, 0.6609625937436495, 0.655871641714429, 0.6512223148503016, 0.6507120754034047, 0.6520486028939159, 0.6505213830264303, 0.6481718139957198, 0.656372164100757, 0.6616585278406335, 0.6649411274591704, 0.6602785562724627, 0.664181498991176, 0.662845450573572, 0.6658801915058503, 0.6697190061076274, 0.6703511354912494, 0.6699609399970345, 0.6709592782097603], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________2020-01-22 08:22:35.397534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 08:22:35.397608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 08:22:35.397620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 08:22:35.397627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 08:22:35.397926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from WMn   /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97410792 0.02589208]
Train on 17233 samples, validate on 255 samples
Epoch 1/300
 - 48s - loss: 0.1441 - acc: 0.9867 - mDice: 0.7188 - val_loss: 0.2986 - val_acc: 0.9828 - val_mDice: 0.4105

Epoch 00001: val_mDice improved from -inf to 0.41045, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 44s - loss: 0.0879 - acc: 0.9913 - mDice: 0.8287 - val_loss: 0.1808 - val_acc: 0.9926 - val_mDice: 0.4574

Epoch 00002: val_mDice improved from 0.41045 to 0.45743, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 44s - loss: 0.0794 - acc: 0.9922 - mDice: 0.8452 - val_loss: 0.1816 - val_acc: 0.9936 - val_mDice: 0.4726

Epoch 00003: val_mDice improved from 0.45743 to 0.47262, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 44s - loss: 0.0714 - acc: 0.9928 - mDice: 0.8609 - val_loss: 0.1145 - val_acc: 0.9931 - val_mDice: 0.4623

Epoch 00004: val_mDice did not improve from 0.47262
Epoch 5/300
 - 44s - loss: 0.0683 - acc: 0.9931 - mDice: 0.8669 - val_loss: 0.1457 - val_acc: 0.9932 - val_mDice: 0.4762

Epoch 00005: val_mDice improved from 0.47262 to 0.47623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 43s - loss: 0.0642 - acc: 0.9935 - mDice: 0.8750 - val_loss: 0.1202 - val_acc: 0.9932 - val_mDice: 0.4681

Epoch 00006: val_mDice did not improve from 0.47623
Epoch 7/300
 - 44s - loss: 0.0649 - acc: 0.9935 - mDice: 0.8736 - val_loss: 0.1468 - val_acc: 0.9934 - val_mDice: 0.4873

Epoch 00007: val_mDice improved from 0.47623 to 0.48731, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 43s - loss: 0.0618 - acc: 0.9937 - mDice: 0.8796 - val_loss: 0.1476 - val_acc: 0.9930 - val_mDice: 0.4767

Epoch 00008: val_mDice did not improve from 0.48731
Epoch 9/300
 - 44s - loss: 0.0594 - acc: 0.9939 - mDice: 0.8843 - val_loss: 0.1247 - val_acc: 0.9929 - val_mDice: 0.4699

Epoch 00009: val_mDice did not improve from 0.48731
Epoch 10/300
 - 43s - loss: 0.0587 - acc: 0.9940 - mDice: 0.8856 - val_loss: 0.1606 - val_acc: 0.9927 - val_mDice: 0.4711

Epoch 00010: val_mDice did not improve from 0.48731
Epoch 11/300
 - 44s - loss: 0.0571 - acc: 0.9941 - mDice: 0.8887 - val_loss: 0.0887 - val_acc: 0.9931 - val_mDice: 0.4787

Epoch 00011: val_mDice did not improve from 0.48731
Epoch 12/300
 - 44s - loss: 0.0548 - acc: 0.9943 - mDice: 0.8932 - val_loss: 0.0502 - val_acc: 0.9932 - val_mDice: 0.4779

Epoch 00012: val_mDice did not improve from 0.48731
Epoch 13/300
 - 44s - loss: 0.0552 - acc: 0.9943 - mDice: 0.8924 - val_loss: 0.0664 - val_acc: 0.9933 - val_mDice: 0.4807

Epoch 00013: val_mDice did not improve from 0.48731
Epoch 14/300
 - 44s - loss: 0.0527 - acc: 0.9945 - mDice: 0.8973 - val_loss: 0.0845 - val_acc: 0.9930 - val_mDice: 0.4818

Epoch 00014: val_mDice did not improve from 0.48731
Epoch 15/300
 - 44s - loss: 0.0522 - acc: 0.9945 - mDice: 0.8984 - val_loss: 0.1964 - val_acc: 0.9919 - val_mDice: 0.4557

Epoch 00015: val_mDice did not improve from 0.48731
Epoch 16/300
 - 43s - loss: 0.0516 - acc: 0.9946 - mDice: 0.8996 - val_loss: 0.0118 - val_acc: 0.9932 - val_mDice: 0.4761

Epoch 00016: val_mDice did not improve from 0.48731
Epoch 17/300
 - 44s - loss: 0.0513 - acc: 0.9946 - mDice: 0.9002 - val_loss: 0.0411 - val_acc: 0.9936 - val_mDice: 0.4904

Epoch 00017: val_mDice improved from 0.48731 to 0.49042, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 18/300
 - 44s - loss: 0.0506 - acc: 0.9947 - mDice: 0.9014 - val_loss: 0.0082 - val_acc: 0.9933 - val_mDice: 0.4774

Epoch 00018: val_mDice did not improve from 0.49042
Epoch 19/300
 - 44s - loss: 0.0503 - acc: 0.9947 - mDice: 0.9020 - val_loss: 0.0087 - val_acc: 0.9932 - val_mDice: 0.4790

Epoch 00019: val_mDice did not improve from 0.49042
Epoch 20/300
 - 44s - loss: 0.0505 - acc: 0.9947 - mDice: 0.9018 - val_loss: 0.0247 - val_acc: 0.9934 - val_mDice: 0.4816

Epoch 00020: val_mDice did not improve from 0.49042
Epoch 21/300
 - 44s - loss: 0.0498 - acc: 0.9948 - mDice: 0.9030 - val_loss: -2.5555e-02 - val_acc: 0.9929 - val_mDice: 0.4667

Epoch 00021: val_mDice did not improve from 0.49042
Epoch 22/300
 - 43s - loss: 0.0499 - acc: 0.9947 - mDice: 0.9029 - val_loss: 0.1284 - val_acc: 0.9926 - val_mDice: 0.4728

Epoch 00022: val_mDice did not improve from 0.49042
Epoch 23/300
 - 44s - loss: 0.0480 - acc: 0.9949 - mDice: 0.9066 - val_loss: -2.3548e-02 - val_acc: 0.9936 - val_mDice: 0.4841

Epoch 00023: val_mDice did not improve from 0.49042
Epoch 24/300
 - 43s - loss: 0.0482 - acc: 0.9949 - mDice: 0.9061 - val_loss: 0.1422 - val_acc: 0.9930 - val_mDice: 0.4849

Epoch 00024: val_mDice did not improve from 0.49042
Epoch 25/300
 - 44s - loss: 0.0469 - acc: 0.9949 - mDice: 0.9088 - val_loss: 0.0452 - val_acc: 0.9930 - val_mDice: 0.4823

Epoch 00025: val_mDice did not improve from 0.49042
Epoch 26/300
 - 43s - loss: 0.0463 - acc: 0.9950 - mDice: 0.9099 - val_loss: 0.0523 - val_acc: 0.9930 - val_mDice: 0.4678

Epoch 00026: val_mDice did not improve from 0.49042
Epoch 27/300
 - 44s - loss: 0.0465 - acc: 0.9950 - mDice: 0.9096 - val_loss: -1.0589e-02 - val_acc: 0.9936 - val_mDice: 0.4828

Epoch 00027: val_mDice did not improve from 0.49042
Epoch 28/300
 - 43s - loss: 0.0475 - acc: 0.9950 - mDice: 0.9076 - val_loss: 0.1062 - val_acc: 0.9930 - val_mDice: 0.4755

Epoch 00028: val_mDice did not improve from 0.49042
Epoch 29/300
 - 44s - loss: 0.0459 - acc: 0.9951 - mDice: 0.9107 - val_loss: 0.0104 - val_acc: 0.9933 - val_mDice: 0.4851

Epoch 00029: val_mDice did not improve from 0.49042
Epoch 30/300
 - 44s - loss: 0.0461 - acc: 0.9951 - mDice: 0.9103 - val_loss: 0.0857 - val_acc: 0.9933 - val_mDice: 0.4869

Epoch 00030: val_mDice did not improve from 0.49042
Epoch 31/300
 - 43s - loss: 0.0469 - acc: 0.9951 - mDice: 0.9087 - val_loss: 0.1012 - val_acc: 0.9930 - val_mDice: 0.4887

Epoch 00031: val_mDice did not improve from 0.49042
Epoch 32/300
 - 44s - loss: 0.0485 - acc: 0.9949 - mDice: 0.9056 - val_loss: 0.0938 - val_acc: 0.9931 - val_mDice: 0.4846

Epoch 00032: val_mDice did not improve from 0.49042

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 33/300
 - 43s - loss: 0.0447 - acc: 0.9952 - mDice: 0.9130 - val_loss: 0.0617 - val_acc: 0.9934 - val_mDice: 0.4891

Epoch 00033: val_mDice did not improve from 0.49042
Epoch 34/300
 - 44s - loss: 0.0434 - acc: 0.9953 - mDice: 0.9156 - val_loss: 0.0310 - val_acc: 0.9931 - val_mDice: 0.4644

Epoch 00034: val_mDice did not improve from 0.49042
Epoch 35/300
 - 43s - loss: 0.0426 - acc: 0.9953 - mDice: 0.9171 - val_loss: 0.0093 - val_acc: 0.9938 - val_mDice: 0.4860

Epoch 00035: val_mDice did not improve from 0.49042
Epoch 36/300
 - 44s - loss: 0.0421 - acc: 0.9954 - mDice: 0.9181 - val_loss: 0.0220 - val_acc: 0.9937 - val_mDice: 0.4832

Epoch 00036: val_mDice did not improve from 0.49042
Epoch 37/300
 - 43s - loss: 0.0420 - acc: 0.9954 - mDice: 0.9184 - val_loss: 0.0509 - val_acc: 0.9934 - val_mDice: 0.4750

Epoch 00037: val_mDice did not improve from 0.49042
Epoch 38/300
 - 43s - loss: 0.0433 - acc: 0.9954 - mDice: 0.9158 - val_loss: 0.0527 - val_acc: 0.9934 - val_mDice: 0.4737

Epoch 00038: val_mDice did not improve from 0.49042
Epoch 39/300
 - 44s - loss: 0.0428 - acc: 0.9954 - mDice: 0.9166 - val_loss: 0.0377 - val_acc: 0.9934 - val_mDice: 0.4899

Epoch 00039: val_mDice did not improve from 0.49042
Epoch 40/300
 - 43s - loss: 0.0429 - acc: 0.9954 - mDice: 0.9165 - val_loss: 0.0400 - val_acc: 0.9934 - val_mDice: 0.4781

Epoch 00040: val_mDice did not improve from 0.49042
Epoch 41/300
 - 44s - loss: 0.0415 - acc: 0.9955 - mDice: 0.9193 - val_loss: 0.1461 - val_acc: 0.9930 - val_mDice: 0.4827

Epoch 00041: val_mDice did not improve from 0.49042
Epoch 42/300
 - 43s - loss: 0.0414 - acc: 0.9955 - mDice: 0.9194 - val_loss: 0.0260 - val_acc: 0.9935 - val_mDice: 0.4796

Epoch 00042: val_mDice did not improve from 0.49042
Epoch 43/300
 - 44s - loss: 0.0417 - acc: 0.9955 - mDice: 0.9189 - val_loss: 0.0655 - val_acc: 0.9932 - val_mDice: 0.4809

Epoch 00043: val_mDice did not improve from 0.49042
Epoch 44/300
 - 44s - loss: 0.0416 - acc: 0.9955 - mDice: 0.9190 - val_loss: -1.1522e-02 - val_acc: 0.9936 - val_mDice: 0.4754

Epoch 00044: val_mDice did not improve from 0.49042
Epoch 45/300
 - 44s - loss: 0.0410 - acc: 0.9955 - mDice: 0.9203 - val_loss: 0.0699 - val_acc: 0.9930 - val_mDice: 0.4832

Epoch 00045: val_mDice did not improve from 0.49042
Epoch 46/300
 - 44s - loss: 0.0409 - acc: 0.9955 - mDice: 0.9205 - val_loss: 0.1422 - val_acc: 0.9870 - val_mDice: 0.3622

Epoch 00046: val_mDice did not improve from 0.49042
Epoch 47/300
 - 44s - loss: 0.0410 - acc: 0.9955 - mDice: 0.9203 - val_loss: 0.1483 - val_acc: 0.9935 - val_mDice: 0.4853

Epoch 00047: val_mDice did not improve from 0.49042

Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 48/300
 - 44s - loss: 0.0407 - acc: 0.9956 - mDice: 0.9208 - val_loss: 0.1693 - val_acc: 0.9929 - val_mDice: 0.4735

Epoch 00048: val_mDice did not improve from 0.49042
Epoch 49/300
 - 43s - loss: 0.0401 - acc: 0.9956 - mDice: 0.9219 - val_loss: 0.1136 - val_acc: 0.9934 - val_mDice: 0.4792

Epoch 00049: val_mDice did not improve from 0.49042
Epoch 50/300
 - 44s - loss: 0.0392 - acc: 0.9956 - mDice: 0.9238 - val_loss: 0.0926 - val_acc: 0.9935 - val_mDice: 0.4802

Epoch 00050: val_mDice did not improve from 0.49042
Epoch 51/300
 - 43s - loss: 0.0395 - acc: 0.9956 - mDice: 0.9233 - val_loss: 0.1305 - val_acc: 0.9934 - val_mDice: 0.4789

Epoch 00051: val_mDice did not improve from 0.49042
Epoch 52/300
 - 44s - loss: 0.0393 - acc: 0.9957 - mDice: 0.9236 - val_loss: 0.1377 - val_acc: 0.9933 - val_mDice: 0.4810

Epoch 00052: val_mDice did not improve from 0.49042
Epoch 53/300
 - 43s - loss: 0.0390 - acc: 0.9957 - mDice: 0.9241 - val_loss: 0.0747 - val_acc: 0.9934 - val_mDice: 0.4791

Epoch 00053: val_mDice did not improve from 0.49042
Epoch 54/300
 - 44s - loss: 0.0395 - acc: 0.9957 - mDice: 0.9232 - val_loss: 0.0658 - val_acc: 0.9936 - val_mDice: 0.4806

Epoch 00054: val_mDice did not improve from 0.49042
Epoch 55/300
 - 44s - loss: 0.0394 - acc: 0.9957 - mDice: 0.9234 - val_loss: 0.1001 - val_acc: 0.9937 - val_mDice: 0.4844

Epoch 00055: val_mDice did not improve from 0.49042
Epoch 56/300
 - 44s - loss: 0.0385 - acc: 0.9957 - mDice: 0.9252 - val_loss: 0.1113 - val_acc: 0.9934 - val_mDice: 0.4815

Epoch 00056: val_mDice did not improve from 0.49042
Epoch 57/300
 - 44s - loss: 0.0385 - acc: 0.9957 - mDice: 0.9252 - val_loss: 0.0726 - val_acc: 0.9933 - val_mDice: 0.4802

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:02,  1.44it/s]predicting test subjects:  50%|█████     | 2/4 [00:00<00:01,  1.84it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:01<00:00,  2.41it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.94it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  3.43it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:32,  8.11it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:31,  8.34it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:34,  7.61it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:33,  7.79it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:32,  7.95it/s]predicting train subjects:   2%|▏         | 6/266 [00:00<00:32,  8.01it/s]predicting train subjects:   3%|▎         | 7/266 [00:00<00:31,  8.12it/s]predicting train subjects:   3%|▎         | 8/266 [00:00<00:31,  8.17it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:31,  8.21it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:31,  8.24it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:30,  8.27it/s]predicting train subjects:   5%|▍         | 12/266 [00:01<00:30,  8.25it/s]predicting train subjects:   5%|▍         | 13/266 [00:01<00:30,  8.32it/s]predicting train subjects:   5%|▌         | 14/266 [00:01<00:29,  8.41it/s]predicting train subjects:   6%|▌         | 15/266 [00:01<00:29,  8.42it/s]predicting train subjects:   6%|▌         | 16/266 [00:01<00:29,  8.35it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:29,  8.31it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:29,  8.30it/s]predicting train subjects:   7%|▋         | 19/266 [00:02<00:29,  8.25it/s]predicting train subjects:   8%|▊         | 20/266 [00:02<00:29,  8.26it/s]predicting train subjects:   8%|▊         | 21/266 [00:02<00:29,  8.27it/s]predicting train subjects:   8%|▊         | 22/266 [00:02<00:29,  8.32it/s]predicting train subjects:   9%|▊         | 23/266 [00:02<00:28,  8.50it/s]predicting train subjects:   9%|▉         | 24/266 [00:02<00:28,  8.58it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:27,  8.65it/s]predicting train subjects:  10%|▉         | 26/266 [00:03<00:27,  8.73it/s]predicting train subjects:  10%|█         | 27/266 [00:03<00:27,  8.70it/s]predicting train subjects:  11%|█         | 28/266 [00:03<00:27,  8.78it/s]predicting train subjects:  11%|█         | 29/266 [00:03<00:26,  8.89it/s]predicting train subjects:  11%|█▏        | 30/266 [00:03<00:26,  8.93it/s]predicting train subjects:  12%|█▏        | 31/266 [00:03<00:26,  8.97it/s]predicting train subjects:  12%|█▏        | 32/266 [00:03<00:26,  8.97it/s]predicting train subjects:  12%|█▏        | 33/266 [00:03<00:25,  8.96it/s]predicting train subjects:  13%|█▎        | 34/266 [00:04<00:25,  8.95it/s]predicting train subjects:  13%|█▎        | 35/266 [00:04<00:25,  8.99it/s]predicting train subjects:  14%|█▎        | 36/266 [00:04<00:25,  8.95it/s]predicting train subjects:  14%|█▍        | 37/266 [00:04<00:25,  8.94it/s]predicting train subjects:  14%|█▍        | 38/266 [00:04<00:25,  8.99it/s]predicting train subjects:  15%|█▍        | 39/266 [00:04<00:25,  8.98it/s]predicting train subjects:  15%|█▌        | 40/266 [00:04<00:25,  8.93it/s]predicting train subjects:  15%|█▌        | 41/266 [00:04<00:34,  6.58it/s]predicting train subjects:  16%|█▌        | 42/266 [00:05<00:32,  6.95it/s]predicting train subjects:  16%|█▌        | 43/266 [00:05<00:30,  7.37it/s]predicting train subjects:  17%|█▋        | 44/266 [00:05<00:29,  7.63it/s]predicting train subjects:  17%|█▋        | 45/266 [00:05<00:27,  7.93it/s]predicting train subjects:  17%|█▋        | 46/266 [00:05<00:26,  8.23it/s]predicting train subjects:  18%|█▊        | 47/266 [00:05<00:26,  8.42it/s]predicting train subjects:  18%|█▊        | 48/266 [00:05<00:25,  8.42it/s]predicting train subjects:  18%|█▊        | 49/266 [00:05<00:25,  8.54it/s]predicting train subjects:  19%|█▉        | 50/266 [00:05<00:25,  8.59it/s]predicting train subjects:  19%|█▉        | 51/266 [00:06<00:24,  8.70it/s]predicting train subjects:  20%|█▉        | 52/266 [00:06<00:24,  8.72it/s]predicting train subjects:  20%|█▉        | 53/266 [00:06<00:24,  8.69it/s]predicting train subjects:  20%|██        | 54/266 [00:06<00:24,  8.67it/s]predicting train subjects:  21%|██        | 55/266 [00:06<00:24,  8.64it/s]predicting train subjects:  21%|██        | 56/266 [00:06<00:24,  8.59it/s]predicting train subjects:  21%|██▏       | 57/266 [00:06<00:24,  8.56it/s]predicting train subjects:  22%|██▏       | 58/266 [00:06<00:24,  8.54it/s]predicting train subjects:  22%|██▏       | 59/266 [00:07<00:24,  8.36it/s]predicting train subjects:  23%|██▎       | 60/266 [00:07<00:25,  8.10it/s]predicting train subjects:  23%|██▎       | 61/266 [00:07<00:25,  8.03it/s]predicting train subjects:  23%|██▎       | 62/266 [00:07<00:25,  8.06it/s]predicting train subjects:  24%|██▎       | 63/266 [00:07<00:24,  8.13it/s]predicting train subjects:  24%|██▍       | 64/266 [00:07<00:25,  8.03it/s]predicting train subjects:  24%|██▍       | 65/266 [00:07<00:24,  8.10it/s]predicting train subjects:  25%|██▍       | 66/266 [00:07<00:24,  8.18it/s]predicting train subjects:  25%|██▌       | 67/266 [00:08<00:24,  8.23it/s]predicting train subjects:  26%|██▌       | 68/266 [00:08<00:24,  8.23it/s]predicting train subjects:  26%|██▌       | 69/266 [00:08<00:24,  8.17it/s]predicting train subjects:  26%|██▋       | 70/266 [00:08<00:23,  8.21it/s]predicting train subjects:  27%|██▋       | 71/266 [00:08<00:23,  8.20it/s]predicting train subjects:  27%|██▋       | 72/266 [00:08<00:23,  8.18it/s]predicting train subjects:  27%|██▋       | 73/266 [00:08<00:23,  8.17it/s]predicting train subjects:  28%|██▊       | 74/266 [00:08<00:23,  8.19it/s]predicting train subjects:  28%|██▊       | 75/266 [00:09<00:23,  8.09it/s]predicting train subjects:  29%|██▊       | 76/266 [00:09<00:23,  8.11it/s]predicting train subjects:  29%|██▉       | 77/266 [00:09<00:26,  7.22it/s]predicting train subjects:  29%|██▉       | 78/266 [00:09<00:28,  6.56it/s]predicting train subjects:  30%|██▉       | 79/266 [00:09<00:30,  6.08it/s]predicting train subjects:  30%|███       | 80/266 [00:09<00:32,  5.65it/s]predicting train subjects:  30%|███       | 81/266 [00:10<00:31,  5.97it/s]predicting train subjects:  31%|███       | 82/266 [00:10<00:29,  6.18it/s]predicting train subjects:  31%|███       | 83/266 [00:10<00:29,  6.30it/s]predicting train subjects:  32%|███▏      | 84/266 [00:10<00:28,  6.38it/s]predicting train subjects:  32%|███▏      | 85/266 [00:10<00:27,  6.53it/s]predicting train subjects:  32%|███▏      | 86/266 [00:10<00:27,  6.63it/s]predicting train subjects:  33%|███▎      | 87/266 [00:10<00:26,  6.69it/s]predicting train subjects:  33%|███▎      | 88/266 [00:11<00:26,  6.69it/s]predicting train subjects:  33%|███▎      | 89/266 [00:11<00:26,  6.65it/s]predicting train subjects:  34%|███▍      | 90/266 [00:11<00:26,  6.66it/s]predicting train subjects:  34%|███▍      | 91/266 [00:11<00:26,  6.63it/s]predicting train subjects:  35%|███▍      | 92/266 [00:11<00:26,  6.66it/s]predicting train subjects:  35%|███▍      | 93/266 [00:11<00:25,  6.68it/s]predicting train subjects:  35%|███▌      | 94/266 [00:11<00:25,  6.76it/s]predicting train subjects:  36%|███▌      | 95/266 [00:12<00:25,  6.74it/s]predicting train subjects:  36%|███▌      | 96/266 [00:12<00:25,  6.80it/s]predicting train subjects:  36%|███▋      | 97/266 [00:12<00:24,  6.80it/s]predicting train subjects:  37%|███▋      | 98/266 [00:12<00:24,  6.79it/s]predicting train subjects:  37%|███▋      | 99/266 [00:12<00:24,  6.79it/s]predicting train subjects:  38%|███▊      | 100/266 [00:12<00:24,  6.85it/s]predicting train subjects:  38%|███▊      | 101/266 [00:12<00:23,  6.92it/s]predicting train subjects:  38%|███▊      | 102/266 [00:13<00:23,  6.95it/s]predicting train subjects:  39%|███▊      | 103/266 [00:13<00:23,  6.94it/s]predicting train subjects:  39%|███▉      | 104/266 [00:13<00:23,  6.92it/s]predicting train subjects:  39%|███▉      | 105/266 [00:13<00:23,  6.92it/s]predicting train subjects:  40%|███▉      | 106/266 [00:13<00:23,  6.95it/s]predicting train subjects:  40%|████      | 107/266 [00:13<00:23,  6.90it/s]predicting train subjects:  41%|████      | 108/266 [00:14<00:22,  6.90it/s]predicting train subjects:  41%|████      | 109/266 [00:14<00:22,  6.99it/s]predicting train subjects:  41%|████▏     | 110/266 [00:14<00:22,  7.06it/s]predicting train subjects:  42%|████▏     | 111/266 [00:14<00:21,  7.09it/s]predicting train subjects:  42%|████▏     | 112/266 [00:14<00:21,  7.07it/s]predicting train subjects:  42%|████▏     | 113/266 [00:14<00:21,  7.11it/s]predicting train subjects:  43%|████▎     | 114/266 [00:14<00:21,  7.13it/s]predicting train subjects:  43%|████▎     | 115/266 [00:14<00:21,  7.07it/s]predicting train subjects:  44%|████▎     | 116/266 [00:15<00:21,  7.11it/s]predicting train subjects:  44%|████▍     | 117/266 [00:15<00:21,  7.09it/s]predicting train subjects:  44%|████▍     | 118/266 [00:15<00:19,  7.50it/s]predicting train subjects:  45%|████▍     | 119/266 [00:15<00:18,  7.75it/s]predicting train subjects:  45%|████▌     | 120/266 [00:15<00:18,  7.98it/s]predicting train subjects:  45%|████▌     | 121/266 [00:15<00:17,  8.16it/s]predicting train subjects:  46%|████▌     | 122/266 [00:15<00:17,  8.19it/s]predicting train subjects:  46%|████▌     | 123/266 [00:15<00:17,  8.17it/s]predicting train subjects:  47%|████▋     | 124/266 [00:16<00:17,  8.26it/s]predicting train subjects:  47%|████▋     | 125/266 [00:16<00:16,  8.32it/s]predicting train subjects:  47%|████▋     | 126/266 [00:16<00:16,  8.40it/s]predicting train subjects:  48%|████▊     | 127/266 [00:16<00:16,  8.46it/s]predicting train subjects:  48%|████▊     | 128/266 [00:16<00:16,  8.46it/s]predicting train subjects:  48%|████▊     | 129/266 [00:16<00:16,  8.40it/s]predicting train subjects:  49%|████▉     | 130/266 [00:16<00:16,  8.37it/s]predicting train subjects:  49%|████▉     | 131/266 [00:16<00:16,  8.44it/s]predicting train subjects:  50%|████▉     | 132/266 [00:17<00:15,  8.47it/s]predicting train subjects:  50%|█████     | 133/266 [00:17<00:15,  8.41it/s]predicting train subjects:  50%|█████     | 134/266 [00:17<00:15,  8.48it/s]predicting train subjects:  51%|█████     | 135/266 [00:17<00:15,  8.46it/s]predicting train subjects:  51%|█████     | 136/266 [00:17<00:15,  8.45it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:17<00:15,  8.45it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:17<00:15,  8.47it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:17<00:15,  8.41it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:17<00:14,  8.43it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:18<00:14,  8.45it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:18<00:14,  8.50it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:18<00:14,  8.52it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:18<00:14,  8.43it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:18<00:14,  8.40it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:18<00:14,  8.41it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:18<00:14,  8.38it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:18<00:13,  8.45it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:19<00:13,  8.48it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:19<00:13,  8.46it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:19<00:13,  8.51it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:19<00:13,  8.58it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:19<00:13,  8.61it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:19<00:13,  8.14it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:19<00:14,  7.72it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:19<00:14,  7.48it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:20<00:14,  7.38it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:20<00:14,  7.35it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:20<00:14,  7.29it/s]predicting train subjects:  60%|██████    | 160/266 [00:20<00:14,  7.23it/s]predicting train subjects:  61%|██████    | 161/266 [00:20<00:14,  7.07it/s]predicting train subjects:  61%|██████    | 162/266 [00:20<00:15,  6.65it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:20<00:15,  6.83it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:21<00:14,  6.91it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:21<00:14,  6.86it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:21<00:14,  6.86it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:21<00:14,  6.92it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:21<00:14,  6.94it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:21<00:13,  6.97it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:21<00:13,  6.90it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:22<00:13,  6.92it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:22<00:13,  7.23it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:22<00:14,  6.53it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:22<00:14,  6.41it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:22<00:14,  6.20it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:22<00:13,  6.70it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:23<00:12,  7.04it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:23<00:12,  7.32it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:23<00:11,  7.54it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:23<00:11,  7.70it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:23<00:10,  7.83it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:23<00:10,  7.93it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:23<00:10,  8.01it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:23<00:10,  8.13it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:23<00:09,  8.14it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:24<00:09,  8.15it/s]predicting train subjects:  70%|███████   | 187/266 [00:24<00:09,  8.20it/s]predicting train subjects:  71%|███████   | 188/266 [00:24<00:09,  8.26it/s]predicting train subjects:  71%|███████   | 189/266 [00:24<00:09,  8.22it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:24<00:09,  8.21it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:24<00:09,  8.23it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:24<00:08,  8.25it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:24<00:08,  8.21it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:25<00:08,  8.21it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:25<00:09,  7.81it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:25<00:09,  7.57it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:25<00:09,  7.28it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:25<00:09,  7.20it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:25<00:09,  7.14it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:25<00:09,  6.99it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:26<00:09,  6.97it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:26<00:09,  7.00it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:26<00:09,  6.99it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:26<00:08,  6.96it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:26<00:08,  6.91it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:26<00:08,  6.88it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:26<00:08,  6.85it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:27<00:08,  6.81it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:27<00:08,  6.80it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:27<00:08,  6.81it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:27<00:08,  6.86it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:27<00:07,  6.92it/s]predicting train subjects:  80%|████████  | 213/266 [00:27<00:07,  7.05it/s]predicting train subjects:  80%|████████  | 214/266 [00:27<00:07,  7.19it/s]predicting train subjects:  81%|████████  | 215/266 [00:28<00:06,  7.34it/s]predicting train subjects:  81%|████████  | 216/266 [00:28<00:06,  7.42it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:28<00:06,  7.47it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:28<00:06,  7.53it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:28<00:06,  7.55it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:28<00:06,  7.55it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:28<00:05,  7.56it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:29<00:05,  7.57it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:29<00:05,  7.55it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:29<00:05,  7.53it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:29<00:05,  7.52it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:29<00:05,  7.53it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:29<00:05,  7.51it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:29<00:05,  7.49it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:29<00:04,  7.56it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:30<00:04,  7.53it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:30<00:04,  8.02it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:30<00:04,  8.40it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:30<00:03,  8.78it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:30<00:03,  9.07it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:30<00:03,  9.30it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:30<00:03,  9.36it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:30<00:03,  9.39it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:30<00:02,  9.50it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:31<00:02,  9.49it/s]predicting train subjects:  90%|█████████ | 240/266 [00:31<00:02,  9.60it/s]predicting train subjects:  91%|█████████ | 241/266 [00:31<00:02,  9.61it/s]predicting train subjects:  91%|█████████ | 242/266 [00:31<00:02,  9.47it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:31<00:02,  9.45it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:31<00:02,  9.41it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:31<00:02,  9.45it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:31<00:02,  9.48it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:31<00:02,  9.44it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:31<00:01,  9.45it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:32<00:01,  9.12it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:32<00:01,  8.96it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:32<00:01,  8.95it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:32<00:01,  8.98it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:32<00:01,  9.00it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:32<00:01,  8.96it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:32<00:01,  8.89it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:32<00:01,  8.90it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:32<00:01,  8.89it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:33<00:00,  8.84it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:33<00:00,  8.81it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:33<00:00,  8.83it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:33<00:00,  8.80it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:33<00:00,  8.64it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:33<00:00,  8.55it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:33<00:00,  8.57it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:33<00:00,  8.57it/s]predicting train subjects: 100%|██████████| 266/266 [00:34<00:00,  8.42it/s]predicting train subjects: 100%|██████████| 266/266 [00:34<00:00,  7.82it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  8.27it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  8.45it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  8.55it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  8.14it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  8.27it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<00:32,  8.09it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<00:31,  8.27it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<00:31,  8.40it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:00<00:31,  8.26it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:00<00:31,  8.19it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:00<00:31,  8.20it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:00<00:31,  8.24it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:00<00:31,  8.21it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:01<00:31,  8.11it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:01<00:31,  8.13it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:01<00:31,  8.15it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:01<00:31,  8.11it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:01<00:31,  8.06it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:01<00:31,  8.06it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:01<00:31,  8.06it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:01<00:31,  8.06it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:02<00:31,  8.00it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:02<00:31,  7.97it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:02<00:31,  7.95it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:02<00:30,  8.00it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:02<00:30,  8.03it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:02<00:30,  8.09it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:02<00:29,  8.27it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:02<00:28,  8.38it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:03<00:28,  8.39it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:03<00:28,  8.43it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:03<00:28,  8.50it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:03<00:27,  8.57it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:03<00:27,  8.62it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:03<00:27,  8.66it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:03<00:27,  8.68it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:03<00:26,  8.67it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:03<00:27,  8.62it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:04<00:26,  8.63it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:04<00:26,  8.57it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:04<00:26,  8.61it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:04<00:26,  8.61it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:04<00:26,  8.67it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:04<00:26,  8.69it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:04<00:26,  8.67it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:04<00:26,  8.60it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:05<00:26,  8.55it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:05<00:25,  8.59it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:05<00:25,  8.62it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:05<00:25,  8.60it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:05<00:25,  8.59it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:05<00:25,  8.64it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:05<00:25,  8.68it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:05<00:25,  8.56it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:05<00:25,  8.58it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:06<00:24,  8.65it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:06<00:24,  8.69it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:06<00:24,  8.61it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:06<00:24,  8.55it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:06<00:24,  8.53it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:06<00:24,  8.48it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:06<00:24,  8.49it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:06<00:24,  8.42it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:07<00:25,  8.12it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:07<00:25,  8.03it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:07<00:25,  7.98it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:07<00:25,  8.01it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:07<00:25,  7.97it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:07<00:25,  8.05it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:07<00:25,  8.02it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:07<00:24,  8.07it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:08<00:24,  8.14it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:08<00:24,  8.10it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:08<00:24,  8.12it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:08<00:24,  8.14it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:08<00:23,  8.20it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:08<00:23,  8.21it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:08<00:23,  8.17it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:08<00:23,  8.15it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:09<00:23,  8.14it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:09<00:23,  8.21it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:09<00:24,  7.86it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:09<00:24,  7.76it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:09<00:23,  8.07it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:09<00:22,  8.31it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:09<00:23,  7.98it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:09<00:23,  7.72it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:10<00:24,  7.56it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:10<00:24,  7.43it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:10<00:24,  7.31it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:10<00:24,  7.24it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:10<00:24,  7.21it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:10<00:24,  7.18it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:10<00:25,  7.06it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:11<00:24,  7.09it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:11<00:24,  7.04it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:11<00:24,  7.02it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:11<00:24,  7.02it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:11<00:24,  7.07it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:11<00:24,  7.11it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:11<00:24,  7.05it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:12<00:24,  6.99it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:12<00:23,  7.00it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:12<00:23,  7.05it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:12<00:23,  7.13it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:12<00:23,  7.11it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:12<00:23,  7.12it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:12<00:22,  7.13it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:13<00:22,  7.18it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:13<00:22,  7.18it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:13<00:22,  7.16it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:13<00:22,  7.18it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:13<00:21,  7.21it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:13<00:21,  7.23it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:13<00:21,  7.25it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:13<00:21,  7.26it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:14<00:21,  7.30it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:14<00:20,  7.32it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:14<00:21,  7.22it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:14<00:20,  7.26it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:14<00:20,  7.24it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:14<00:20,  7.25it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:14<00:19,  7.68it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:15<00:18,  8.05it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:15<00:17,  8.32it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:15<00:17,  8.51it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:15<00:16,  8.63it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:15<00:16,  8.75it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:15<00:16,  8.82it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:15<00:15,  8.86it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:15<00:15,  8.91it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:15<00:15,  8.96it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:16<00:15,  8.97it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:16<00:15,  8.91it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:16<00:15,  8.95it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:16<00:15,  8.95it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:16<00:14,  8.96it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:16<00:14,  8.92it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:16<00:14,  8.88it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:16<00:14,  8.87it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:16<00:14,  8.90it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:17<00:14,  8.91it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:17<00:14,  8.86it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:17<00:14,  8.82it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:17<00:14,  8.81it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:17<00:14,  8.86it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:17<00:14,  8.75it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:17<00:14,  8.70it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:17<00:14,  8.68it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:17<00:13,  8.76it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:18<00:13,  8.83it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:18<00:13,  8.84it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:18<00:13,  8.78it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:18<00:13,  8.74it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:18<00:13,  8.71it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:18<00:13,  8.58it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:18<00:13,  8.59it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:18<00:13,  8.59it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:19<00:14,  7.97it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:19<00:14,  7.73it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:19<00:14,  7.60it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:19<00:14,  7.52it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:19<00:14,  7.45it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:19<00:14,  7.38it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:19<00:14,  7.36it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:19<00:14,  7.37it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:20<00:14,  7.41it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:20<00:13,  7.41it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:20<00:13,  7.42it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:20<00:13,  7.38it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:20<00:13,  7.37it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:20<00:13,  7.36it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:20<00:13,  7.26it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:21<00:13,  7.25it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:21<00:13,  7.20it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:21<00:13,  7.17it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:21<00:12,  7.44it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:21<00:12,  7.27it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:21<00:12,  7.28it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:21<00:11,  7.80it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:21<00:11,  8.00it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:22<00:10,  8.10it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:22<00:10,  8.12it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:22<00:10,  8.18it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:22<00:10,  8.15it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:22<00:10,  8.13it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:22<00:10,  8.20it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:22<00:10,  8.24it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:22<00:10,  8.12it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:23<00:09,  8.13it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:23<00:09,  8.12it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:23<00:09,  8.09it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:23<00:09,  8.04it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:23<00:09,  7.98it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:23<00:09,  7.98it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:23<00:09,  7.98it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:23<00:09,  8.00it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:24<00:09,  8.05it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:24<00:08,  8.05it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:24<00:09,  7.59it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:24<00:09,  7.34it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:24<00:09,  7.25it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:24<00:09,  7.18it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:24<00:09,  7.04it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:25<00:09,  7.01it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:25<00:09,  6.97it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:25<00:09,  6.97it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:25<00:08,  7.00it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:25<00:08,  7.04it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:25<00:08,  6.98it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:25<00:08,  7.00it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:26<00:08,  6.97it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:26<00:08,  6.99it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:26<00:08,  6.94it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:26<00:08,  6.93it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:26<00:07,  6.92it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:26<00:07,  6.91it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:26<00:07,  7.03it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:27<00:07,  7.19it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:27<00:07,  7.22it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:27<00:06,  7.29it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:27<00:06,  7.34it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:27<00:06,  7.38it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:27<00:06,  7.44it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:27<00:06,  7.36it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:28<00:06,  7.37it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [00:28<00:05,  7.47it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [00:28<00:05,  7.54it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [00:28<00:05,  7.58it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [00:28<00:05,  7.52it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [00:28<00:05,  7.51it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [00:28<00:05,  7.47it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [00:28<00:05,  7.52it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [00:29<00:04,  7.48it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [00:29<00:04,  7.47it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [00:29<00:04,  7.97it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [00:29<00:04,  8.38it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [00:29<00:03,  8.66it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [00:29<00:03,  8.81it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [00:29<00:03,  8.98it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [00:29<00:03,  8.94it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [00:29<00:03,  9.03it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [00:30<00:03,  9.13it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [00:30<00:02,  9.22it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [00:30<00:02,  9.26it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [00:30<00:02,  9.35it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [00:30<00:02,  9.48it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [00:30<00:02,  9.58it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [00:30<00:02,  9.61it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [00:30<00:02,  9.63it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [00:30<00:02,  9.63it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [00:31<00:01,  9.61it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [00:31<00:01,  9.56it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [00:31<00:01,  9.16it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [00:31<00:01,  8.95it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [00:31<00:01,  8.80it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [00:31<00:01,  8.78it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [00:31<00:01,  8.76it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [00:31<00:01,  8.70it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [00:31<00:01,  8.66it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [00:32<00:01,  8.65it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [00:32<00:01,  8.62it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [00:32<00:00,  8.59it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [00:32<00:00,  8.64it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [00:32<00:00,  8.61it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [00:32<00:00,  8.59it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [00:32<00:00,  8.60it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [00:32<00:00,  8.60it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [00:32<00:00,  8.58it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [00:33<00:00,  8.61it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:33<00:00,  8.64it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:33<00:00,  8.01it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 74.50it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 9/266 [00:00<00:03, 83.80it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/266 [00:00<00:02, 83.54it/s]saving BB  train1-THALAMUS:  10%|█         | 27/266 [00:00<00:02, 84.76it/s]saving BB  train1-THALAMUS:  14%|█▍        | 37/266 [00:00<00:02, 86.26it/s]saving BB  train1-THALAMUS:  18%|█▊        | 47/266 [00:00<00:02, 87.92it/s]saving BB  train1-THALAMUS:  21%|██▏       | 57/266 [00:00<00:02, 89.33it/s]saving BB  train1-THALAMUS:  25%|██▍       | 66/266 [00:00<00:02, 86.76it/s]saving BB  train1-THALAMUS:  28%|██▊       | 75/266 [00:00<00:02, 84.16it/s]saving BB  train1-THALAMUS:  31%|███       | 83/266 [00:00<00:02, 79.83it/s]saving BB  train1-THALAMUS:  34%|███▍      | 91/266 [00:01<00:02, 75.21it/s]saving BB  train1-THALAMUS:  37%|███▋      | 99/266 [00:01<00:02, 72.41it/s]saving BB  train1-THALAMUS:  40%|████      | 107/266 [00:01<00:02, 72.44it/s]saving BB  train1-THALAMUS:  43%|████▎     | 115/266 [00:01<00:02, 69.79it/s]saving BB  train1-THALAMUS:  46%|████▌     | 123/266 [00:01<00:01, 71.68it/s]saving BB  train1-THALAMUS:  50%|████▉     | 132/266 [00:01<00:01, 71.85it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:01<00:01, 75.93it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 151/266 [00:01<00:01, 80.01it/s]saving BB  train1-THALAMUS:  60%|██████    | 160/266 [00:02<00:01, 79.46it/s]saving BB  train1-THALAMUS:  64%|██████▎   | 169/266 [00:02<00:01, 78.97it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 178/266 [00:02<00:01, 79.19it/s]saving BB  train1-THALAMUS:  70%|███████   | 187/266 [00:02<00:00, 79.86it/s]saving BB  train1-THALAMUS:  74%|███████▎  | 196/266 [00:02<00:00, 80.01it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 205/266 [00:02<00:00, 79.14it/s]saving BB  train1-THALAMUS:  80%|████████  | 213/266 [00:02<00:00, 78.65it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 221/266 [00:02<00:00, 77.89it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 229/266 [00:02<00:00, 77.06it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 238/266 [00:03<00:00, 79.47it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 247/266 [00:03<00:00, 81.97it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 257/266 [00:03<00:00, 84.68it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 80.37it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 82.82it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 9/266 [00:00<00:03, 84.48it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/266 [00:00<00:02, 83.86it/s]saving BB  train1-THALAMUS Sagittal:  10%|█         | 27/266 [00:00<00:02, 84.08it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 37/266 [00:00<00:02, 86.26it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 47/266 [00:00<00:02, 88.32it/s]saving BB  train1-THALAMUS Sagittal:  21%|██▏       | 57/266 [00:00<00:02, 89.87it/s]saving BB  train1-THALAMUS Sagittal:  25%|██▍       | 66/266 [00:00<00:02, 87.15it/s]saving BB  train1-THALAMUS Sagittal:  28%|██▊       | 75/266 [00:00<00:02, 85.54it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 84/266 [00:00<00:02, 82.27it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 92/266 [00:01<00:02, 78.01it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 100/266 [00:01<00:02, 75.10it/s]saving BB  train1-THALAMUS Sagittal:  41%|████      | 108/266 [00:01<00:02, 74.85it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▎     | 116/266 [00:01<00:01, 75.06it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 125/266 [00:01<00:01, 77.13it/s]saving BB  train1-THALAMUS Sagittal:  50%|█████     | 133/266 [00:01<00:01, 77.92it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 142/266 [00:01<00:01, 80.02it/s]saving BB  train1-THALAMUS Sagittal:  57%|█████▋    | 152/266 [00:01<00:01, 82.98it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████    | 161/266 [00:01<00:01, 80.88it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 170/266 [00:02<00:01, 79.04it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 179/266 [00:02<00:01, 79.03it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████   | 188/266 [00:02<00:00, 79.67it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 196/266 [00:02<00:00, 78.46it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 204/266 [00:02<00:00, 77.59it/s]saving BB  train1-THALAMUS Sagittal:  80%|███████▉  | 212/266 [00:02<00:00, 77.02it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 220/266 [00:02<00:00, 76.08it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 228/266 [00:02<00:00, 74.71it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 237/266 [00:02<00:00, 77.89it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 247/266 [00:03<00:00, 81.35it/s]saving BB  train1-THALAMUS Sagittal:  97%|█████████▋| 257/266 [00:03<00:00, 84.18it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 85.46it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 81.15it/s]
Epoch 00057: val_mDice did not improve from 0.49042
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [0.29856416261663626, 0.18080721649469114, 0.18164159971124985, 0.11446124578223509, 0.1457135671494054, 0.12019159834758908, 0.14680634526645436, 0.14763760829673095, 0.12470971135532155, 0.16064931890543768, 0.08874188684949688, 0.05018367457623575, 0.0663517696015975, 0.0845101913985084, 0.19636966930884941, 0.011762178703850391, 0.04108684115550097, 0.00817730380039589, 0.008677675443537095, 0.02470815006424399, -0.025554947993334604, 0.1283738919917275, -0.023547731778200937, 0.14222641113926382, 0.045228225635547264, 0.0522989212882285, -0.010589173611472635, 0.1061531077412998, 0.010426475429067425, 0.0856852508058735, 0.10121924707702562, 0.0938446594803941, 0.0617412395921408, 0.03104813484584584, 0.009335246156243718, 0.022014435307652343, 0.0509150647649578, 0.05274840458935382, 0.037722113085728065, 0.04002480325745601, 0.1460550573526644, 0.026034749021717145, 0.06554938005466088, -0.011522081844946918, 0.06992919859932918, 0.14218641876005658, 0.14827011116579467, 0.16929319091871672, 0.11359391405301936, 0.0925522621940164, 0.13050344498718486, 0.1376890513826819, 0.07470035114709069, 0.0657891932071424, 0.10006318665018268, 0.11131798256846036, 0.07258275618740156], 'val_acc': [0.9828459562039843, 0.9926420520333683, 0.9935629683382371, 0.993121911497677, 0.9932089307728935, 0.9931591702442543, 0.9933551187608757, 0.9930311406359953, 0.9929018558240404, 0.9926880656504163, 0.9930680779849782, 0.9932321006176519, 0.9932793671009588, 0.992983245382122, 0.9918648074654972, 0.9932183261011162, 0.9935570160547892, 0.9933081678315705, 0.993233042604783, 0.99336263478971, 0.9928812022302665, 0.9925988491843728, 0.9936390390583113, 0.9929557010239246, 0.9930427214678597, 0.9929657122668099, 0.9936355913386625, 0.9929851200066361, 0.9933006553088918, 0.9933091028063905, 0.9930320802856895, 0.9930971919321546, 0.9934155333275888, 0.9931059491400626, 0.9937761367536059, 0.9936672028373269, 0.9934136540282006, 0.9934152247858983, 0.9934368227042404, 0.9934224217545753, 0.9930079742973926, 0.9935319797665465, 0.993228973126879, 0.9936277679368561, 0.993036148594875, 0.9869509514640359, 0.9935432438756905, 0.9928868319474015, 0.9934396323035745, 0.9934653043746948, 0.9934227326337028, 0.9933235072622112, 0.9934327462140251, 0.9935945856804941, 0.9937172941133088, 0.9933785971473245, 0.9933319535909915], 'val_mDice': [0.41045352918844596, 0.45743122521568746, 0.47262176812863815, 0.4623096417270455, 0.476234143855525, 0.4681424545306786, 0.4873112043611857, 0.4766833034272677, 0.46986711492725447, 0.4710546476189382, 0.47871509019071834, 0.47789504123376864, 0.4807255630764891, 0.48184037325429024, 0.4556757401339692, 0.47610779486450494, 0.49042218047029834, 0.47735149720135855, 0.4790106814188561, 0.4816490972743315, 0.466665644271701, 0.47275834311457243, 0.48412180596999094, 0.48491594195365906, 0.48228104909261066, 0.46778842274957866, 0.4828411250137815, 0.4754742150213204, 0.48511114599657995, 0.4868638538846783, 0.4886650758631089, 0.48461976822684794, 0.48911283238261355, 0.46440017143008755, 0.4860125961256962, 0.4832323398806301, 0.4749593470325778, 0.47369192395697113, 0.489912432198431, 0.47814529969850006, 0.48269276467024114, 0.4795698904085393, 0.4809393464204143, 0.4753526634007108, 0.4831526215169944, 0.3621872891398037, 0.4852642663845829, 0.47353080703931694, 0.4791872685446459, 0.48017578031502517, 0.47885551398583487, 0.4809706298743977, 0.4791248203529155, 0.4805850014820987, 0.48435397986687867, 0.4815230171616171, 0.4802381747639647], 'loss': [0.14406720879740884, 0.08789281992556594, 0.07941641760275035, 0.07140100403244452, 0.06833357789754688, 0.06418686434700077, 0.06487404090096571, 0.061816416606882044, 0.05941150676977238, 0.058737532751846455, 0.057147414909425716, 0.054848416577031316, 0.05524199623423238, 0.0527476537608439, 0.05219440237236737, 0.051553680944593554, 0.051288671623371765, 0.05063034794493573, 0.050329098986720194, 0.05045906942657037, 0.049804399163006476, 0.049882022608719004, 0.04799096074880729, 0.04823403150969039, 0.04688412442121145, 0.04631450348069731, 0.04646338109805318, 0.04745200659431418, 0.045905295964154255, 0.04610679860556526, 0.04692118930825643, 0.04848992886725481, 0.044715315026573686, 0.043395644785882925, 0.04264839376865354, 0.042109189337255756, 0.04198756453168861, 0.04327702273593682, 0.04283417839580063, 0.042892834820708915, 0.04148461073351662, 0.04144174876990186, 0.04166258106912095, 0.041619234333109996, 0.0409622811084075, 0.040883076107592606, 0.040971322173735523, 0.04069820337651645, 0.04012347838318729, 0.0391872466831443, 0.03946912634886682, 0.039274912746252964, 0.03903197638116752, 0.039466261563661904, 0.03937956481274467, 0.03847582289708136, 0.03848884652666447], 'acc': [0.9867167298760451, 0.991275138948505, 0.9922253693941057, 0.9927777718184739, 0.9931344177824895, 0.9934638878331129, 0.9935101701843477, 0.9937310590903398, 0.9939146993026463, 0.9940455646223804, 0.994144886176972, 0.9943372805590472, 0.9942859456929716, 0.9944830178619573, 0.9945132000727308, 0.9946051979206059, 0.9946170314919034, 0.9946785437135891, 0.9947232546957414, 0.9947326431000204, 0.9947730895675067, 0.9947463207282781, 0.9948750605317835, 0.9948986415065311, 0.9949294285766483, 0.9950118396021129, 0.9950219421968343, 0.9950191396475184, 0.9950919154626553, 0.995090063135823, 0.9950631372312824, 0.9949034717171106, 0.9952003108862278, 0.9953209392630009, 0.995347159890299, 0.9953692865712045, 0.9953785269997674, 0.9953783414308937, 0.9954339061999207, 0.9954469171505896, 0.99546382329748, 0.9954533276019464, 0.995490664614822, 0.9954859817470074, 0.9955246865918838, 0.995519883041352, 0.9955195220723304, 0.9955742563919397, 0.9956090553772675, 0.9956322891246088, 0.9956262304938788, 0.9956772548990643, 0.9956500668627521, 0.9956723416335126, 0.9956918877200298, 0.9956808546384545, 0.9957069694452856], 'mDice': [0.7187783955947535, 0.8287216502834439, 0.8451699052207945, 0.8609128046611007, 0.866860349990913, 0.8749782121140675, 0.8735775429233829, 0.8795799164241781, 0.8842875867647974, 0.8855686064088337, 0.8886957958382491, 0.8931948472901985, 0.892433860850061, 0.897318486485068, 0.8984068180309377, 0.8996350712240216, 0.9001609857876635, 0.9014441953901834, 0.9020224889370801, 0.9017590778706721, 0.9030460309305768, 0.9029077957004096, 0.9066141767443863, 0.9061179735777736, 0.9088036069734136, 0.9098955451048293, 0.9095926103032708, 0.9076240324492504, 0.9106716083970466, 0.9102718058703552, 0.9086571826796741, 0.9056085414986916, 0.9129934588858264, 0.9155659097986836, 0.9170538434673503, 0.9181160523995489, 0.9183524721685526, 0.9157715206884199, 0.9166305376468501, 0.9165084957073439, 0.9193131671428875, 0.9194026342992241, 0.9189429293846922, 0.9190323925937056, 0.9203268793471379, 0.9204905129887407, 0.9203078117060978, 0.9208251059017282, 0.9219491524341996, 0.9238128126210596, 0.9232520134161375, 0.9236184899199481, 0.9241150643643877, 0.9232316605553489, 0.9233998427165265, 0.9252120891208402, 0.9251678647606508], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<04:05,  1.08it/s]Loading train:   1%|          | 2/266 [00:01<03:49,  1.15it/s]Loading train:   1%|          | 3/266 [00:02<03:38,  1.20it/s]Loading train:   2%|▏         | 4/266 [00:03<03:40,  1.19it/s]Loading train:   2%|▏         | 5/266 [00:03<03:17,  1.32it/s]Loading train:   2%|▏         | 6/266 [00:04<02:56,  1.47it/s]Loading train:   3%|▎         | 7/266 [00:04<02:42,  1.59it/s]Loading train:   3%|▎         | 8/266 [00:05<02:36,  1.65it/s]Loading train:   3%|▎         | 9/266 [00:05<02:30,  1.70it/s]Loading train:   4%|▍         | 10/266 [00:06<02:24,  1.78it/s]Loading train:   4%|▍         | 11/266 [00:06<02:21,  1.81it/s]Loading train:   5%|▍         | 12/266 [00:07<02:20,  1.81it/s]Loading train:   5%|▍         | 13/266 [00:08<02:16,  1.85it/s]Loading train:   5%|▌         | 14/266 [00:08<02:16,  1.84it/s]Loading train:   6%|▌         | 15/266 [00:09<02:14,  1.87it/s]Loading train:   6%|▌         | 16/266 [00:09<02:13,  1.87it/s]Loading train:   6%|▋         | 17/266 [00:10<02:12,  1.88it/s]Loading train:   7%|▋         | 18/266 [00:10<02:12,  1.87it/s]Loading train:   7%|▋         | 19/266 [00:11<02:10,  1.90it/s]Loading train:   8%|▊         | 20/266 [00:11<02:07,  1.92it/s]Loading train:   8%|▊         | 21/266 [00:12<02:05,  1.95it/s]Loading train:   8%|▊         | 22/266 [00:12<02:07,  1.92it/s]Loading train:   9%|▊         | 23/266 [00:13<02:08,  1.89it/s]Loading train:   9%|▉         | 24/266 [00:13<02:07,  1.90it/s]Loading train:   9%|▉         | 25/266 [00:14<02:05,  1.93it/s]Loading train:  10%|▉         | 26/266 [00:14<02:02,  1.96it/s]Loading train:  10%|█         | 27/266 [00:15<02:03,  1.94it/s]Loading train:  11%|█         | 28/266 [00:15<02:03,  1.93it/s]Loading train:  11%|█         | 29/266 [00:16<02:01,  1.95it/s]Loading train:  11%|█▏        | 30/266 [00:16<02:01,  1.95it/s]Loading train:  12%|█▏        | 31/266 [00:17<01:59,  1.97it/s]Loading train:  12%|█▏        | 32/266 [00:17<01:56,  2.00it/s]Loading train:  12%|█▏        | 33/266 [00:18<01:54,  2.03it/s]Loading train:  13%|█▎        | 34/266 [00:18<01:54,  2.02it/s]Loading train:  13%|█▎        | 35/266 [00:19<01:53,  2.03it/s]Loading train:  14%|█▎        | 36/266 [00:19<01:54,  2.01it/s]Loading train:  14%|█▍        | 37/266 [00:20<01:54,  2.01it/s]Loading train:  14%|█▍        | 38/266 [00:20<01:54,  1.99it/s]Loading train:  15%|█▍        | 39/266 [00:21<01:54,  1.98it/s]Loading train:  15%|█▌        | 40/266 [00:21<01:56,  1.94it/s]Loading train:  15%|█▌        | 41/266 [00:22<01:52,  2.01it/s]Loading train:  16%|█▌        | 42/266 [00:22<01:48,  2.06it/s]Loading train:  16%|█▌        | 43/266 [00:23<01:46,  2.10it/s]Loading train:  17%|█▋        | 44/266 [00:23<01:45,  2.11it/s]Loading train:  17%|█▋        | 45/266 [00:24<01:43,  2.13it/s]Loading train:  17%|█▋        | 46/266 [00:24<01:44,  2.11it/s]Loading train:  18%|█▊        | 47/266 [00:25<01:43,  2.11it/s]Loading train:  18%|█▊        | 48/266 [00:25<01:40,  2.17it/s]Loading train:  18%|█▊        | 49/266 [00:26<01:39,  2.17it/s]Loading train:  19%|█▉        | 50/266 [00:26<01:39,  2.17it/s]Loading train:  19%|█▉        | 51/266 [00:26<01:37,  2.21it/s]Loading train:  20%|█▉        | 52/266 [00:27<01:36,  2.21it/s]Loading train:  20%|█▉        | 53/266 [00:27<01:35,  2.22it/s]Loading train:  20%|██        | 54/266 [00:28<01:34,  2.23it/s]Loading train:  21%|██        | 55/266 [00:28<01:35,  2.21it/s]Loading train:  21%|██        | 56/266 [00:29<01:36,  2.17it/s]Loading train:  21%|██▏       | 57/266 [00:29<01:36,  2.16it/s]Loading train:  22%|██▏       | 58/266 [00:30<01:37,  2.14it/s]Loading train:  22%|██▏       | 59/266 [00:30<01:44,  1.98it/s]Loading train:  23%|██▎       | 60/266 [00:31<01:46,  1.94it/s]Loading train:  23%|██▎       | 61/266 [00:31<01:45,  1.95it/s]Loading train:  23%|██▎       | 62/266 [00:32<01:44,  1.95it/s]Loading train:  24%|██▎       | 63/266 [00:32<01:45,  1.93it/s]Loading train:  24%|██▍       | 64/266 [00:33<01:45,  1.91it/s]Loading train:  24%|██▍       | 65/266 [00:33<01:45,  1.91it/s]Loading train:  25%|██▍       | 66/266 [00:34<01:44,  1.91it/s]Loading train:  25%|██▌       | 67/266 [00:34<01:46,  1.87it/s]Loading train:  26%|██▌       | 68/266 [00:35<01:46,  1.86it/s]Loading train:  26%|██▌       | 69/266 [00:36<01:45,  1.87it/s]Loading train:  26%|██▋       | 70/266 [00:36<01:43,  1.90it/s]Loading train:  27%|██▋       | 71/266 [00:37<01:41,  1.91it/s]Loading train:  27%|██▋       | 72/266 [00:37<01:40,  1.93it/s]Loading train:  27%|██▋       | 73/266 [00:38<01:39,  1.95it/s]Loading train:  28%|██▊       | 74/266 [00:38<01:39,  1.92it/s]Loading train:  28%|██▊       | 75/266 [00:39<01:40,  1.90it/s]Loading train:  29%|██▊       | 76/266 [00:39<01:41,  1.87it/s]Loading train:  29%|██▉       | 77/266 [00:40<02:07,  1.48it/s]Loading train:  29%|██▉       | 78/266 [00:41<02:21,  1.33it/s]Loading train:  30%|██▉       | 79/266 [00:42<02:24,  1.30it/s]Loading train:  30%|███       | 80/266 [00:43<02:21,  1.32it/s]Loading train:  30%|███       | 81/266 [00:44<02:32,  1.21it/s]Loading train:  31%|███       | 82/266 [00:44<02:22,  1.29it/s]Loading train:  31%|███       | 83/266 [00:45<02:10,  1.40it/s]Loading train:  32%|███▏      | 84/266 [00:46<02:05,  1.45it/s]Loading train:  32%|███▏      | 85/266 [00:46<02:00,  1.50it/s]Loading train:  32%|███▏      | 86/266 [00:47<01:57,  1.53it/s]Loading train:  33%|███▎      | 87/266 [00:47<01:54,  1.57it/s]Loading train:  33%|███▎      | 88/266 [00:48<01:52,  1.58it/s]Loading train:  33%|███▎      | 89/266 [00:49<01:50,  1.60it/s]Loading train:  34%|███▍      | 90/266 [00:49<01:48,  1.62it/s]Loading train:  34%|███▍      | 91/266 [00:50<01:47,  1.63it/s]Loading train:  35%|███▍      | 92/266 [00:50<01:45,  1.65it/s]Loading train:  35%|███▍      | 93/266 [00:51<01:42,  1.69it/s]Loading train:  35%|███▌      | 94/266 [00:52<01:40,  1.71it/s]Loading train:  36%|███▌      | 95/266 [00:52<01:41,  1.68it/s]Loading train:  36%|███▌      | 96/266 [00:53<01:42,  1.66it/s]Loading train:  36%|███▋      | 97/266 [00:53<01:44,  1.62it/s]Loading train:  37%|███▋      | 98/266 [00:54<01:44,  1.61it/s]Loading train:  37%|███▋      | 99/266 [00:55<01:42,  1.63it/s]Loading train:  38%|███▊      | 100/266 [00:55<01:40,  1.65it/s]Loading train:  38%|███▊      | 101/266 [00:56<01:38,  1.67it/s]Loading train:  38%|███▊      | 102/266 [00:56<01:36,  1.69it/s]Loading train:  39%|███▊      | 103/266 [00:57<01:34,  1.72it/s]Loading train:  39%|███▉      | 104/266 [00:58<01:33,  1.74it/s]Loading train:  39%|███▉      | 105/266 [00:58<01:32,  1.73it/s]Loading train:  40%|███▉      | 106/266 [00:59<01:32,  1.72it/s]Loading train:  40%|████      | 107/266 [00:59<01:31,  1.75it/s]Loading train:  41%|████      | 108/266 [01:00<01:29,  1.76it/s]Loading train:  41%|████      | 109/266 [01:00<01:28,  1.78it/s]Loading train:  41%|████▏     | 110/266 [01:01<01:27,  1.78it/s]Loading train:  42%|████▏     | 111/266 [01:01<01:28,  1.74it/s]Loading train:  42%|████▏     | 112/266 [01:02<01:28,  1.73it/s]Loading train:  42%|████▏     | 113/266 [01:03<01:27,  1.75it/s]Loading train:  43%|████▎     | 114/266 [01:03<01:27,  1.74it/s]Loading train:  43%|████▎     | 115/266 [01:04<01:27,  1.72it/s]Loading train:  44%|████▎     | 116/266 [01:04<01:26,  1.72it/s]Loading train:  44%|████▍     | 117/266 [01:05<01:27,  1.71it/s]Loading train:  44%|████▍     | 118/266 [01:06<01:24,  1.75it/s]Loading train:  45%|████▍     | 119/266 [01:06<01:22,  1.78it/s]Loading train:  45%|████▌     | 120/266 [01:07<01:18,  1.86it/s]Loading train:  45%|████▌     | 121/266 [01:07<01:17,  1.88it/s]Loading train:  46%|████▌     | 122/266 [01:08<01:13,  1.96it/s]Loading train:  46%|████▌     | 123/266 [01:08<01:12,  1.99it/s]Loading train:  47%|████▋     | 124/266 [01:09<01:10,  2.00it/s]Loading train:  47%|████▋     | 125/266 [01:09<01:09,  2.02it/s]Loading train:  47%|████▋     | 126/266 [01:09<01:08,  2.05it/s]Loading train:  48%|████▊     | 127/266 [01:10<01:08,  2.03it/s]Loading train:  48%|████▊     | 128/266 [01:10<01:08,  2.02it/s]Loading train:  48%|████▊     | 129/266 [01:11<01:08,  2.00it/s]Loading train:  49%|████▉     | 130/266 [01:12<01:09,  1.95it/s]Loading train:  49%|████▉     | 131/266 [01:12<01:10,  1.92it/s]Loading train:  50%|████▉     | 132/266 [01:13<01:09,  1.94it/s]Loading train:  50%|█████     | 133/266 [01:13<01:08,  1.94it/s]Loading train:  50%|█████     | 134/266 [01:14<01:07,  1.96it/s]Loading train:  51%|█████     | 135/266 [01:14<01:06,  1.98it/s]Loading train:  51%|█████     | 136/266 [01:15<01:07,  1.94it/s]Loading train:  52%|█████▏    | 137/266 [01:15<01:04,  2.00it/s]Loading train:  52%|█████▏    | 138/266 [01:16<01:03,  2.03it/s]Loading train:  52%|█████▏    | 139/266 [01:16<01:02,  2.03it/s]Loading train:  53%|█████▎    | 140/266 [01:17<01:01,  2.06it/s]Loading train:  53%|█████▎    | 141/266 [01:17<01:00,  2.06it/s]Loading train:  53%|█████▎    | 142/266 [01:17<00:59,  2.07it/s]Loading train:  54%|█████▍    | 143/266 [01:18<00:59,  2.07it/s]Loading train:  54%|█████▍    | 144/266 [01:18<00:58,  2.10it/s]Loading train:  55%|█████▍    | 145/266 [01:19<00:58,  2.09it/s]Loading train:  55%|█████▍    | 146/266 [01:19<00:58,  2.06it/s]Loading train:  55%|█████▌    | 147/266 [01:20<00:58,  2.02it/s]Loading train:  56%|█████▌    | 148/266 [01:20<00:58,  2.00it/s]Loading train:  56%|█████▌    | 149/266 [01:21<00:58,  2.02it/s]Loading train:  56%|█████▋    | 150/266 [01:21<00:56,  2.04it/s]Loading train:  57%|█████▋    | 151/266 [01:22<00:56,  2.04it/s]Loading train:  57%|█████▋    | 152/266 [01:22<00:56,  2.03it/s]Loading train:  58%|█████▊    | 153/266 [01:23<00:56,  2.01it/s]Loading train:  58%|█████▊    | 154/266 [01:24<01:00,  1.85it/s]Loading train:  58%|█████▊    | 155/266 [01:24<01:01,  1.81it/s]Loading train:  59%|█████▊    | 156/266 [01:25<01:01,  1.79it/s]Loading train:  59%|█████▉    | 157/266 [01:25<01:01,  1.77it/s]Loading train:  59%|█████▉    | 158/266 [01:26<01:01,  1.76it/s]Loading train:  60%|█████▉    | 159/266 [01:26<01:01,  1.75it/s]Loading train:  60%|██████    | 160/266 [01:27<01:00,  1.75it/s]Loading train:  61%|██████    | 161/266 [01:28<01:00,  1.74it/s]Loading train:  61%|██████    | 162/266 [01:28<01:00,  1.71it/s]Loading train:  61%|██████▏   | 163/266 [01:29<01:01,  1.69it/s]Loading train:  62%|██████▏   | 164/266 [01:29<01:01,  1.67it/s]Loading train:  62%|██████▏   | 165/266 [01:30<01:00,  1.68it/s]Loading train:  62%|██████▏   | 166/266 [01:31<00:59,  1.69it/s]Loading train:  63%|██████▎   | 167/266 [01:31<00:59,  1.67it/s]Loading train:  63%|██████▎   | 168/266 [01:32<00:57,  1.71it/s]Loading train:  64%|██████▎   | 169/266 [01:32<00:56,  1.71it/s]Loading train:  64%|██████▍   | 170/266 [01:33<00:56,  1.70it/s]Loading train:  64%|██████▍   | 171/266 [01:34<00:55,  1.70it/s]Loading train:  65%|██████▍   | 172/266 [01:34<01:03,  1.49it/s]Loading train:  65%|██████▌   | 173/266 [01:35<01:10,  1.31it/s]Loading train:  65%|██████▌   | 174/266 [01:36<01:12,  1.28it/s]Loading train:  66%|██████▌   | 175/266 [01:37<01:08,  1.32it/s]Loading train:  66%|██████▌   | 176/266 [01:38<01:10,  1.28it/s]Loading train:  67%|██████▋   | 177/266 [01:38<01:04,  1.37it/s]Loading train:  67%|██████▋   | 178/266 [01:39<01:00,  1.45it/s]Loading train:  67%|██████▋   | 179/266 [01:39<00:56,  1.54it/s]Loading train:  68%|██████▊   | 180/266 [01:40<00:53,  1.60it/s]Loading train:  68%|██████▊   | 181/266 [01:41<00:51,  1.66it/s]Loading train:  68%|██████▊   | 182/266 [01:41<00:49,  1.70it/s]Loading train:  69%|██████▉   | 183/266 [01:42<01:03,  1.31it/s]Loading train:  69%|██████▉   | 184/266 [01:45<01:38,  1.20s/it]Loading train:  70%|██████▉   | 185/266 [01:48<02:39,  1.96s/it]Loading train:  70%|██████▉   | 186/266 [01:52<03:27,  2.59s/it]Loading train:  70%|███████   | 187/266 [01:55<03:36,  2.74s/it]Loading train:  71%|███████   | 188/266 [02:00<04:07,  3.17s/it]Loading train:  71%|███████   | 189/266 [02:04<04:22,  3.41s/it]Loading train:  71%|███████▏  | 190/266 [02:08<04:31,  3.57s/it]Loading train:  72%|███████▏  | 191/266 [02:12<04:37,  3.70s/it]Loading train:  72%|███████▏  | 192/266 [02:15<04:36,  3.73s/it]Loading train:  73%|███████▎  | 193/266 [02:19<04:37,  3.81s/it]Loading train:  73%|███████▎  | 194/266 [02:23<04:40,  3.89s/it]Loading train:  73%|███████▎  | 195/266 [02:29<05:07,  4.33s/it]Loading train:  74%|███████▎  | 196/266 [02:34<05:25,  4.66s/it]Loading train:  74%|███████▍  | 197/266 [02:40<05:39,  4.92s/it]Loading train:  74%|███████▍  | 198/266 [02:45<05:44,  5.07s/it]Loading train:  75%|███████▍  | 199/266 [02:51<05:45,  5.16s/it]Loading train:  75%|███████▌  | 200/266 [02:55<05:21,  4.88s/it]Loading train:  76%|███████▌  | 201/266 [03:00<05:32,  5.12s/it]Loading train:  76%|███████▌  | 202/266 [03:05<05:17,  4.96s/it]Loading train:  76%|███████▋  | 203/266 [03:10<05:17,  5.04s/it]Loading train:  77%|███████▋  | 204/266 [03:16<05:20,  5.17s/it]Loading train:  77%|███████▋  | 205/266 [03:21<05:23,  5.30s/it]Loading train:  77%|███████▋  | 206/266 [03:27<05:23,  5.39s/it]Loading train:  78%|███████▊  | 207/266 [03:33<05:22,  5.46s/it]Loading train:  78%|███████▊  | 208/266 [03:38<05:23,  5.58s/it]Loading train:  79%|███████▊  | 209/266 [03:44<05:21,  5.64s/it]Loading train:  79%|███████▉  | 210/266 [03:50<05:15,  5.64s/it]Loading train:  79%|███████▉  | 211/266 [03:56<05:17,  5.77s/it]Loading train:  80%|███████▉  | 212/266 [04:02<05:09,  5.73s/it]Loading train:  80%|████████  | 213/266 [04:06<04:48,  5.44s/it]Loading train:  80%|████████  | 214/266 [04:11<04:38,  5.35s/it]Loading train:  81%|████████  | 215/266 [04:16<04:26,  5.22s/it]Loading train:  81%|████████  | 216/266 [04:21<04:15,  5.11s/it]Loading train:  82%|████████▏ | 217/266 [04:26<04:12,  5.15s/it]Loading train:  82%|████████▏ | 218/266 [04:32<04:13,  5.27s/it]Loading train:  82%|████████▏ | 219/266 [04:37<04:07,  5.26s/it]Loading train:  83%|████████▎ | 220/266 [04:42<04:01,  5.25s/it]Loading train:  83%|████████▎ | 221/266 [04:47<03:53,  5.18s/it]Loading train:  83%|████████▎ | 222/266 [04:53<03:47,  5.16s/it]Loading train:  84%|████████▍ | 223/266 [04:58<03:43,  5.20s/it]Loading train:  84%|████████▍ | 224/266 [05:03<03:41,  5.28s/it]Loading train:  85%|████████▍ | 225/266 [05:09<03:38,  5.32s/it]Loading train:  85%|████████▍ | 226/266 [05:14<03:31,  5.29s/it]Loading train:  85%|████████▌ | 227/266 [05:18<03:15,  5.02s/it]Loading train:  86%|████████▌ | 228/266 [05:24<03:13,  5.10s/it]Loading train:  86%|████████▌ | 229/266 [05:28<02:58,  4.82s/it]Loading train:  86%|████████▋ | 230/266 [05:33<02:56,  4.90s/it]Loading train:  87%|████████▋ | 231/266 [05:33<02:05,  3.58s/it]Loading train:  87%|████████▋ | 232/266 [05:34<01:35,  2.82s/it]Loading train:  88%|████████▊ | 233/266 [05:36<01:17,  2.34s/it]Loading train:  88%|████████▊ | 234/266 [05:37<01:02,  1.95s/it]Loading train:  88%|████████▊ | 235/266 [05:38<00:52,  1.69s/it]Loading train:  89%|████████▊ | 236/266 [05:39<00:45,  1.51s/it]Loading train:  89%|████████▉ | 237/266 [05:40<00:39,  1.38s/it]Loading train:  89%|████████▉ | 238/266 [05:41<00:36,  1.29s/it]Loading train:  90%|████████▉ | 239/266 [05:42<00:32,  1.22s/it]Loading train:  90%|█████████ | 240/266 [05:43<00:31,  1.22s/it]Loading train:  91%|█████████ | 241/266 [05:44<00:29,  1.20s/it]Loading train:  91%|█████████ | 242/266 [05:46<00:28,  1.17s/it]Loading train:  91%|█████████▏| 243/266 [05:47<00:27,  1.21s/it]Loading train:  92%|█████████▏| 244/266 [05:48<00:26,  1.19s/it]Loading train:  92%|█████████▏| 245/266 [05:49<00:24,  1.18s/it]Loading train:  92%|█████████▏| 246/266 [05:50<00:23,  1.15s/it]Loading train:  93%|█████████▎| 247/266 [05:51<00:21,  1.14s/it]Loading train:  93%|█████████▎| 248/266 [05:52<00:19,  1.10s/it]Loading train:  94%|█████████▎| 249/266 [05:56<00:30,  1.79s/it]Loading train:  94%|█████████▍| 250/266 [06:00<00:40,  2.55s/it]Loading train:  94%|█████████▍| 251/266 [06:04<00:45,  3.06s/it]Loading train:  95%|█████████▍| 252/266 [06:09<00:48,  3.47s/it]Loading train:  95%|█████████▌| 253/266 [06:13<00:48,  3.72s/it]Loading train:  95%|█████████▌| 254/266 [06:17<00:46,  3.88s/it]Loading train:  96%|█████████▌| 255/266 [06:22<00:44,  4.04s/it]Loading train:  96%|█████████▌| 256/266 [06:26<00:41,  4.14s/it]Loading train:  97%|█████████▋| 257/266 [06:29<00:35,  3.90s/it]Loading train:  97%|█████████▋| 258/266 [06:34<00:32,  4.05s/it]Loading train:  97%|█████████▋| 259/266 [06:38<00:29,  4.15s/it]Loading train:  98%|█████████▊| 260/266 [06:42<00:23,  3.92s/it]Loading train:  98%|█████████▊| 261/266 [06:46<00:20,  4.07s/it]Loading train:  98%|█████████▊| 262/266 [06:50<00:16,  4.05s/it]Loading train:  99%|█████████▉| 263/266 [06:54<00:12,  4.16s/it]Loading train:  99%|█████████▉| 264/266 [06:59<00:08,  4.18s/it]Loading train: 100%|█████████▉| 265/266 [07:03<00:04,  4.20s/it]Loading train: 100%|██████████| 266/266 [07:07<00:00,  4.16s/it]Loading train: 100%|██████████| 266/266 [07:07<00:00,  1.61s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 54.79it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:04, 53.56it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:04, 52.55it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:04, 51.68it/s]concatenating: train:  11%|█▏        | 30/266 [00:00<00:04, 52.07it/s]concatenating: train:  14%|█▎        | 36/266 [00:00<00:04, 51.93it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:04, 52.12it/s]concatenating: train:  18%|█▊        | 48/266 [00:00<00:04, 53.11it/s]concatenating: train:  20%|██        | 54/266 [00:01<00:03, 54.21it/s]concatenating: train:  23%|██▎       | 60/266 [00:01<00:03, 55.01it/s]concatenating: train:  25%|██▍       | 66/266 [00:01<00:03, 55.24it/s]concatenating: train:  27%|██▋       | 72/266 [00:01<00:03, 55.42it/s]concatenating: train:  29%|██▉       | 78/266 [00:01<00:03, 54.15it/s]concatenating: train:  32%|███▏      | 84/266 [00:01<00:03, 53.12it/s]concatenating: train:  34%|███▍      | 90/266 [00:01<00:03, 51.90it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:03, 53.84it/s]concatenating: train:  38%|███▊      | 102/266 [00:01<00:03, 54.60it/s]concatenating: train:  41%|████      | 108/266 [00:02<00:02, 54.36it/s]concatenating: train:  43%|████▎     | 114/266 [00:02<00:02, 53.74it/s]concatenating: train:  45%|████▌     | 120/266 [00:02<00:02, 53.15it/s]concatenating: train:  47%|████▋     | 126/266 [00:02<00:02, 53.30it/s]concatenating: train:  50%|████▉     | 132/266 [00:02<00:02, 53.32it/s]concatenating: train:  52%|█████▏    | 138/266 [00:02<00:02, 54.50it/s]concatenating: train:  54%|█████▍    | 144/266 [00:02<00:02, 54.61it/s]concatenating: train:  56%|█████▋    | 150/266 [00:02<00:02, 55.65it/s]concatenating: train:  59%|█████▊    | 156/266 [00:02<00:02, 54.98it/s]concatenating: train:  61%|██████    | 162/266 [00:03<00:01, 53.35it/s]concatenating: train:  63%|██████▎   | 168/266 [00:03<00:01, 52.72it/s]concatenating: train:  65%|██████▌   | 174/266 [00:03<00:01, 52.44it/s]concatenating: train:  68%|██████▊   | 180/266 [00:03<00:01, 52.70it/s]concatenating: train:  70%|██████▉   | 186/266 [00:03<00:01, 50.39it/s]concatenating: train:  72%|███████▏  | 192/266 [00:03<00:01, 50.48it/s]concatenating: train:  74%|███████▍  | 198/266 [00:03<00:01, 50.09it/s]concatenating: train:  77%|███████▋  | 204/266 [00:03<00:01, 49.58it/s]concatenating: train:  79%|███████▊  | 209/266 [00:03<00:01, 49.26it/s]concatenating: train:  80%|████████  | 214/266 [00:04<00:01, 49.46it/s]concatenating: train:  83%|████████▎ | 220/266 [00:04<00:00, 51.02it/s]concatenating: train:  85%|████████▍ | 226/266 [00:04<00:00, 50.48it/s]concatenating: train:  87%|████████▋ | 232/266 [00:04<00:00, 51.46it/s]concatenating: train:  89%|████████▉ | 238/266 [00:04<00:00, 52.39it/s]concatenating: train:  92%|█████████▏| 244/266 [00:04<00:00, 53.54it/s]concatenating: train:  94%|█████████▍| 250/266 [00:04<00:00, 53.87it/s]concatenating: train:  96%|█████████▌| 256/266 [00:04<00:00, 53.93it/s]concatenating: train:  98%|█████████▊| 262/266 [00:04<00:00, 54.43it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 52.92it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 11.67s/it]Loading test:  50%|█████     | 2/4 [00:18<00:20, 10.32s/it]Loading test:  75%|███████▌  | 3/4 [00:26<00:09,  9.54s/it]Loading test: 100%|██████████| 4/4 [00:39<00:00, 10.49s/it]Loading test: 100%|██████████| 4/4 [00:39<00:00,  9.82s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 65.03it/s]
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      2020-01-22 09:17:07.746528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 09:17:07.746638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 09:17:07.746654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 09:17:07.746663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 09:17:07.748728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

loading the weights from thalamus:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights from thalamus:   2%|▏         | 1/44 [00:00<00:07,  5.68it/s]loading the weights from thalamus:   7%|▋         | 3/44 [00:00<00:06,  6.68it/s]loading the weights from thalamus:   9%|▉         | 4/44 [00:00<00:06,  6.24it/s]loading the weights from thalamus:  18%|█▊        | 8/44 [00:00<00:04,  8.01it/s]loading the weights from thalamus:  23%|██▎       | 10/44 [00:00<00:04,  8.50it/s]loading the weights from thalamus:  27%|██▋       | 12/44 [00:01<00:04,  6.92it/s]loading the weights from thalamus:  39%|███▊      | 17/44 [00:01<00:03,  8.84it/s]loading the weights from thalamus:  43%|████▎     | 19/44 [00:01<00:02,  9.17it/s]loading the weights from thalamus:  48%|████▊     | 21/44 [00:02<00:03,  7.01it/s]loading the weights from thalamus:  57%|█████▋    | 25/44 [00:02<00:02,  8.64it/s]loading the weights from thalamus:  61%|██████▏   | 27/44 [00:02<00:01,  8.84it/s]loading the weights from thalamus:  66%|██████▌   | 29/44 [00:02<00:01,  9.13it/s]loading the weights from thalamus:  70%|███████   | 31/44 [00:03<00:01,  6.99it/s]loading the weights from thalamus:  80%|███████▉  | 35/44 [00:03<00:01,  8.52it/s]loading the weights from thalamus:  84%|████████▍ | 37/44 [00:03<00:00,  8.36it/s]loading the weights from thalamus:  89%|████████▊ | 39/44 [00:03<00:00,  8.40it/s]loading the weights from thalamus:  91%|█████████ | 40/44 [00:04<00:00,  6.61it/s]loading the weights from thalamus:  93%|█████████▎| 41/44 [00:04<00:00,  5.41it/s]loading the weights from thalamus: 100%|██████████| 44/44 [00:04<00:00,  9.92it/s]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Thalamus /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [6.83254415e-02 3.27717349e-02 8.44658674e-02 1.02581857e-02
 2.87744951e-02 7.66237264e-03 8.69898377e-02 1.12849556e-01
 9.16300918e-02 1.37502153e-02 2.76766038e-01 1.85496961e-01
 2.59202208e-04]
Train on 9646 samples, validate on 140 samples
Epoch 1/300
 - 25s - loss: 0.7090 - acc: 0.8428 - mDice: 0.2372 - val_loss: 0.6984 - val_acc: 0.9251 - val_mDice: 0.2436

Epoch 00001: val_mDice improved from -inf to 0.24364, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 0.5297 - acc: 0.9159 - mDice: 0.4294 - val_loss: 0.6125 - val_acc: 0.9312 - val_mDice: 0.3134

Epoch 00002: val_mDice improved from 0.24364 to 0.31340, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 0.4765 - acc: 0.9223 - mDice: 0.4867 - val_loss: 0.5846 - val_acc: 0.9262 - val_mDice: 0.3087

Epoch 00003: val_mDice did not improve from 0.31340
Epoch 4/300
 - 19s - loss: 0.4505 - acc: 0.9259 - mDice: 0.5148 - val_loss: 0.5175 - val_acc: 0.9350 - val_mDice: 0.3319

Epoch 00004: val_mDice improved from 0.31340 to 0.33189, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 20s - loss: 0.4284 - acc: 0.9284 - mDice: 0.5387 - val_loss: 0.4787 - val_acc: 0.9422 - val_mDice: 0.3444

Epoch 00005: val_mDice improved from 0.33189 to 0.34442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 20s - loss: 0.4125 - acc: 0.9306 - mDice: 0.5558 - val_loss: 0.5092 - val_acc: 0.9403 - val_mDice: 0.3450

Epoch 00006: val_mDice improved from 0.34442 to 0.34499, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 0.4014 - acc: 0.9322 - mDice: 0.5678 - val_loss: 0.4048 - val_acc: 0.9378 - val_mDice: 0.3111

Epoch 00007: val_mDice did not improve from 0.34499
Epoch 8/300
 - 20s - loss: 0.3897 - acc: 0.9340 - mDice: 0.5804 - val_loss: 0.4732 - val_acc: 0.9383 - val_mDice: 0.3361

Epoch 00008: val_mDice did not improve from 0.34499
Epoch 9/300
 - 20s - loss: 0.3811 - acc: 0.9355 - mDice: 0.5896 - val_loss: 0.4046 - val_acc: 0.9444 - val_mDice: 0.3533

Epoch 00009: val_mDice improved from 0.34499 to 0.35329, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 19s - loss: 0.3735 - acc: 0.9365 - mDice: 0.5979 - val_loss: 0.3947 - val_acc: 0.9422 - val_mDice: 0.3244

Epoch 00010: val_mDice did not improve from 0.35329
Epoch 11/300
 - 20s - loss: 0.3704 - acc: 0.9372 - mDice: 0.6012 - val_loss: 0.4389 - val_acc: 0.9385 - val_mDice: 0.3522

Epoch 00011: val_mDice did not improve from 0.35329
Epoch 12/300
 - 20s - loss: 0.3644 - acc: 0.9379 - mDice: 0.6076 - val_loss: 0.3316 - val_acc: 0.9434 - val_mDice: 0.3274

Epoch 00012: val_mDice did not improve from 0.35329
Epoch 13/300
 - 19s - loss: 0.3619 - acc: 0.9387 - mDice: 0.6103 - val_loss: 0.3820 - val_acc: 0.9427 - val_mDice: 0.3245

Epoch 00013: val_mDice did not improve from 0.35329
Epoch 14/300
 - 19s - loss: 0.3583 - acc: 0.9389 - mDice: 0.6142 - val_loss: 0.3858 - val_acc: 0.9453 - val_mDice: 0.3566

Epoch 00014: val_mDice improved from 0.35329 to 0.35664, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 20s - loss: 0.3522 - acc: 0.9397 - mDice: 0.6208 - val_loss: 0.3256 - val_acc: 0.9413 - val_mDice: 0.3001

Epoch 00015: val_mDice did not improve from 0.35664
Epoch 16/300
 - 20s - loss: 0.3512 - acc: 0.9402 - mDice: 0.6219 - val_loss: 0.3769 - val_acc: 0.9448 - val_mDice: 0.3709

Epoch 00016: val_mDice improved from 0.35664 to 0.37092, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 19s - loss: 0.3455 - acc: 0.9407 - mDice: 0.6280 - val_loss: 0.4306 - val_acc: 0.9456 - val_mDice: 0.3569

Epoch 00017: val_mDice did not improve from 0.37092
Epoch 18/300
 - 19s - loss: 0.3444 - acc: 0.9411 - mDice: 0.6292 - val_loss: 0.3116 - val_acc: 0.9475 - val_mDice: 0.3504

Epoch 00018: val_mDice did not improve from 0.37092
Epoch 19/300
 - 20s - loss: 0.3420 - acc: 0.9415 - mDice: 0.6318 - val_loss: 0.3859 - val_acc: 0.9441 - val_mDice: 0.3583

Epoch 00019: val_mDice did not improve from 0.37092
Epoch 20/300
 - 20s - loss: 0.3410 - acc: 0.9419 - mDice: 0.6329 - val_loss: 0.3458 - val_acc: 0.9459 - val_mDice: 0.3580

Epoch 00020: val_mDice did not improve from 0.37092
Epoch 21/300
 - 20s - loss: 0.3346 - acc: 0.9423 - mDice: 0.6397 - val_loss: 0.2067 - val_acc: 0.9464 - val_mDice: 0.3506

Epoch 00021: val_mDice did not improve from 0.37092
Epoch 22/300
 - 20s - loss: 0.3360 - acc: 0.9426 - mDice: 0.6382 - val_loss: 0.3018 - val_acc: 0.9469 - val_mDice: 0.3475

Epoch 00022: val_mDice did not improve from 0.37092
Epoch 23/300
 - 20s - loss: 0.3333 - acc: 0.9426 - mDice: 0.6412 - val_loss: 0.3451 - val_acc: 0.9452 - val_mDice: 0.3679

Epoch 00023: val_mDice did not improve from 0.37092
Epoch 24/300
 - 20s - loss: 0.3332 - acc: 0.9427 - mDice: 0.6413 - val_loss: 0.3397 - val_acc: 0.9456 - val_mDice: 0.3573

Epoch 00024: val_mDice did not improve from 0.37092
Epoch 25/300
 - 19s - loss: 0.3272 - acc: 0.9435 - mDice: 0.6478 - val_loss: 0.3248 - val_acc: 0.9464 - val_mDice: 0.3469

Epoch 00025: val_mDice did not improve from 0.37092
Epoch 26/300
 - 19s - loss: 0.3257 - acc: 0.9436 - mDice: 0.6495 - val_loss: 0.3021 - val_acc: 0.9468 - val_mDice: 0.3601

Epoch 00026: val_mDice did not improve from 0.37092
Epoch 27/300
 - 20s - loss: 0.3233 - acc: 0.9436 - mDice: 0.6520 - val_loss: 0.2309 - val_acc: 0.9478 - val_mDice: 0.3514

Epoch 00027: val_mDice did not improve from 0.37092
Epoch 28/300
 - 20s - loss: 0.3222 - acc: 0.9442 - mDice: 0.6532 - val_loss: 0.3501 - val_acc: 0.9463 - val_mDice: 0.3585

Epoch 00028: val_mDice did not improve from 0.37092
Epoch 29/300
 - 19s - loss: 0.3226 - acc: 0.9440 - mDice: 0.6528 - val_loss: 0.3352 - val_acc: 0.9468 - val_mDice: 0.3592

Epoch 00029: val_mDice did not improve from 0.37092
Epoch 30/300
 - 19s - loss: 0.3196 - acc: 0.9445 - mDice: 0.6560 - val_loss: 0.2296 - val_acc: 0.9468 - val_mDice: 0.3594

Epoch 00030: val_mDice did not improve from 0.37092
Epoch 31/300
 - 20s - loss: 0.3189 - acc: 0.9446 - mDice: 0.6567 - val_loss: 0.2471 - val_acc: 0.9469 - val_mDice: 0.3581

Epoch 00031: val_mDice did not improve from 0.37092

Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 32/300
 - 20s - loss: 0.3148 - acc: 0.9454 - mDice: 0.6612 - val_loss: 0.1716 - val_acc: 0.9482 - val_mDice: 0.3527

Epoch 00032: val_mDice did not improve from 0.37092
Epoch 33/300
 - 20s - loss: 0.3112 - acc: 0.9455 - mDice: 0.6651 - val_loss: 0.2086 - val_acc: 0.9474 - val_mDice: 0.3624

Epoch 00033: val_mDice did not improve from 0.37092
Epoch 34/300
 - 19s - loss: 0.3090 - acc: 0.9460 - mDice: 0.6674 - val_loss: 0.2060 - val_acc: 0.9479 - val_mDice: 0.3605

Epoch 00034: val_mDice did not improve from 0.37092
Epoch 35/300
 - 20s - loss: 0.3091 - acc: 0.9458 - mDice: 0.6674 - val_loss: 0.2350 - val_acc: 0.9482 - val_mDice: 0.3540

Epoch 00035: val_mDice did not improve from 0.37092
Epoch 36/300
 - 20s - loss: 0.3076 - acc: 0.9461 - mDice: 0.6690 - val_loss: 0.3165 - val_acc: 0.9452 - val_mDice: 0.3622

Epoch 00036: val_mDice did not improve from 0.37092
Epoch 37/300
 - 19s - loss: 0.3089 - acc: 0.9461 - mDice: 0.6676 - val_loss: 0.2494 - val_acc: 0.9469 - val_mDice: 0.3594

Epoch 00037: val_mDice did not improve from 0.37092
Epoch 38/300
 - 20s - loss: 0.3051 - acc: 0.9463 - mDice: 0.6717 - val_loss: 0.2312 - val_acc: 0.9484 - val_mDice: 0.3599

Epoch 00038: val_mDice did not improve from 0.37092
Epoch 39/300
 - 20s - loss: 0.3061 - acc: 0.9463 - mDice: 0.6707 - val_loss: 0.1769 - val_acc: 0.9476 - val_mDice: 0.3635

Epoch 00039: val_mDice did not improve from 0.37092
Epoch 40/300
 - 19s - loss: 0.3052 - acc: 0.9464 - mDice: 0.6716 - val_loss: 0.2505 - val_acc: 0.9467 - val_mDice: 0.3598

Epoch 00040: val_mDice did not improve from 0.37092
Epoch 41/300
 - 19s - loss: 0.3015 - acc: 0.9466 - mDice: 0.6756 - val_loss: 0.2095 - val_acc: 0.9481 - val_mDice: 0.3588

Epoch 00041: val_mDice did not improve from 0.37092
Epoch 42/300
 - 20s - loss: 0.3020 - acc: 0.9465 - mDice: 0.6751 - val_loss: 0.2653 - val_acc: 0.9468 - val_mDice: 0.3642

Epoch 00042: val_mDice did not improve from 0.37092
Epoch 43/300
 - 20s - loss: 0.3041 - acc: 0.9464 - mDice: 0.6728 - val_loss: 0.2997 - val_acc: 0.9411 - val_mDice: 0.3113

Epoch 00043: val_mDice did not improve from 0.37092
Epoch 44/300
 - 19s - loss: 0.3016 - acc: 0.9466 - mDice: 0.6755 - val_loss: 0.2063 - val_acc: 0.9472 - val_mDice: 0.3573

Epoch 00044: val_mDice did not improve from 0.37092
Epoch 45/300
 - 19s - loss: 0.3020 - acc: 0.9466 - mDice: 0.6750 - val_loss: 0.1831 - val_acc: 0.9483 - val_mDice: 0.3558

Epoch 00045: val_mDice did not improve from 0.37092
Epoch 46/300
 - 20s - loss: 0.3017 - acc: 0.9468 - mDice: 0.6754 - val_loss: 0.1860 - val_acc: 0.9472 - val_mDice: 0.3536

Epoch 00046: val_mDice did not improve from 0.37092

Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 47/300
 - 20s - loss: 0.2984 - acc: 0.9471 - mDice: 0.6789 - val_loss: 0.1810 - val_acc: 0.9480 - val_mDice: 0.3546

Epoch 00047: val_mDice did not improve from 0.37092
Epoch 48/300
 - 19s - loss: 0.2926 - acc: 0.9473 - mDice: 0.6853 - val_loss: 0.2373 - val_acc: 0.9467 - val_mDice: 0.3547

Epoch 00048: val_mDice did not improve from 0.37092
Epoch 49/300
 - 20s - loss: 0.2963 - acc: 0.9474 - mDice: 0.6813 - val_loss: 0.1711 - val_acc: 0.9476 - val_mDice: 0.3620

Epoch 00049: val_mDice did not improve from 0.37092
Epoch 50/300
 - 20s - loss: 0.2966 - acc: 0.9474 - mDice: 0.6809 - val_loss: 0.1754 - val_acc: 0.9477 - val_mDice: 0.3622

Epoch 00050: val_mDice did not improve from 0.37092
Epoch 51/300
 - 20s - loss: 0.2961 - acc: 0.9474 - mDice: 0.6815 - val_loss: 0.1695 - val_acc: 0.9478 - val_mDice: 0.3617

Epoch 00051: val_mDice did not improve from 0.37092
Epoch 52/300
 - 19s - loss: 0.2928 - acc: 0.9476 - mDice: 0.6850 - val_loss: 0.1690 - val_acc: 0.9487 - val_mDice: 0.3561

Epoch 00052: val_mDice did not improve from 0.37092
Epoch 53/300
 - 20s - loss: 0.2955 - acc: 0.9474 - mDice: 0.6821 - val_loss: 0.1669 - val_acc: 0.9480 - val_mDice: 0.3599

Epoch 00053: val_mDice did not improve from 0.37092
Epoch 54/300
 - 20s - loss: 0.2929 - acc: 0.9477 - mDice: 0.6849 - val_loss: 0.1408 - val_acc: 0.9484 - val_mDice: 0.3596

Epoch 00054: val_mDice did not improve from 0.37092
Epoch 55/300
 - 20s - loss: 0.2936 - acc: 0.9477 - mDice: 0.6842 - val_loss: 0.1877 - val_acc: 0.9483 - val_mDice: 0.3619

Epoch 00055: val_mDice did not improve from 0.37092
Epoch 56/300
 - 19s - loss: 0.2912 - acc: 0.9477 - mDice: 0.6868 - val_loss: 0.1694 - val_acc: 0.9486 - val_mDice: 0.3605

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.08s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Thalamus_wBiasCorrection_CV_d/sd2/vimp*': No such file or directory

  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.29it/s] 50%|█████     | 2/4 [00:00<00:00,  3.47it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.60it/s]100%|██████████| 4/4 [00:01<00:00,  3.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.51it/s]

Epoch 00056: val_mDice did not improve from 0.37092
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [0.6984321475028992, 0.6125206479004451, 0.584642116512571, 0.5175422195877347, 0.4787060809986932, 0.509243871484484, 0.40483741488839897, 0.47317992789404734, 0.40461208179060904, 0.3946877217718533, 0.4389191908495767, 0.3315700281943594, 0.38195752246039255, 0.3857894406786987, 0.3255651233983891, 0.3768860523455909, 0.4306038128478186, 0.3115804653082575, 0.3858887798019818, 0.34580188031707493, 0.206713415948408, 0.3017986688230719, 0.3450616787054709, 0.3396517232592617, 0.32476952033383505, 0.3020688859479768, 0.2308576078420239, 0.3501360522849219, 0.3352477231195995, 0.2296190114159669, 0.24705303320661187, 0.17156797807131494, 0.2085760354197451, 0.20604206222508634, 0.23496617749333382, 0.31653022054316743, 0.24936016276478767, 0.23124062281567603, 0.17690090875008277, 0.2505329293864114, 0.20954216245029653, 0.26529176413480726, 0.29971431302172796, 0.20631682420415537, 0.18312310261119688, 0.1859592360228167, 0.18104580603539944, 0.2372708184910672, 0.17113553333495343, 0.17541261882122075, 0.1695229070527213, 0.16900606426809514, 0.1668620217325432, 0.1407739988395146, 0.18771667911538056, 0.16937006823718548], 'val_acc': [0.9250719547271729, 0.9312221961362022, 0.9261822998523712, 0.9349800476006099, 0.9421539860112327, 0.9403437376022339, 0.9377796266760144, 0.938280028956277, 0.944431905235563, 0.9421556123665401, 0.9384648033550808, 0.9433542617729732, 0.9427410449300494, 0.9453100476946149, 0.9412791005202702, 0.944825998374394, 0.9456387332507542, 0.9474555211407798, 0.9440656091485705, 0.9458644092082977, 0.9463827865464347, 0.9468815411840167, 0.945200481585094, 0.9455553293228149, 0.9463566201073783, 0.9467866931642804, 0.9478234563555036, 0.9463059220995221, 0.9467605394976479, 0.9468390260423932, 0.9468684622219631, 0.9481586813926697, 0.9474015533924103, 0.9478659757546016, 0.9482077402727944, 0.9451530703476497, 0.9469240520681653, 0.9484268639768872, 0.9476386734417507, 0.9466640523501805, 0.9480605678898948, 0.9468014069965908, 0.9410648899418967, 0.9472053221293858, 0.948260064635958, 0.9472249490874154, 0.9479706329958779, 0.9466853099209922, 0.9475847099508558, 0.9477057244096484, 0.9477972856589726, 0.9487228563853672, 0.9480393103190831, 0.9483908925737653, 0.9483238543782916, 0.9485675011362348], 'val_mDice': [0.24364321412784712, 0.31339994605098453, 0.308677685047899, 0.33189249677317484, 0.34441691849912914, 0.3449875978486879, 0.31113765814474653, 0.3360843615872519, 0.35328966485602514, 0.32443940958806444, 0.352172315120697, 0.32744174557072775, 0.3244950462664877, 0.35663597711494993, 0.30005221122077536, 0.37091593870094847, 0.35688849432127817, 0.3503769582935742, 0.3582517398255212, 0.3580458749617849, 0.35059657213943346, 0.3475205690733024, 0.3678738261972155, 0.35728598279612406, 0.346870950290135, 0.3600895644298622, 0.3514123058744839, 0.358487249485084, 0.3592055120638439, 0.35940967925957273, 0.35811526009014677, 0.35274313603128704, 0.3624412513204983, 0.36052709605012623, 0.3539982704179628, 0.3622315930468695, 0.35935179782765253, 0.35993061321122305, 0.36351506624902996, 0.35975332664591925, 0.35877547200237003, 0.3641646312815802, 0.3113291391304561, 0.35732064289706095, 0.35583534304584774, 0.35357547072427614, 0.35464477964809965, 0.3547350498182433, 0.36196472495794296, 0.36223712669951574, 0.36169181604470524, 0.35607209695237024, 0.35990933594959124, 0.359620784010206, 0.3618879733341081, 0.36047406920364927], 'loss': [0.7090053364322464, 0.5297460316029817, 0.4765396262201412, 0.4505444703422442, 0.428395991512732, 0.41248945864977593, 0.40137140358010936, 0.3897378508502854, 0.38108800086222716, 0.37345792818756585, 0.37038887673558324, 0.36438073122400033, 0.36193129796594253, 0.35827542646480454, 0.35221206968549423, 0.3511903590151761, 0.34549127724280426, 0.34442261909699506, 0.34200781189861473, 0.3409626563937986, 0.3346367729153842, 0.3360224114910537, 0.3332504441344884, 0.3331912764493494, 0.3272162898803385, 0.3256503304931204, 0.32330129892035636, 0.32218132273255606, 0.3226299338968073, 0.3196165695919329, 0.3189434511778193, 0.3147750449562478, 0.3112157903906717, 0.3090396799346409, 0.30908071968519857, 0.307563922991897, 0.30888524030516956, 0.30507311353773936, 0.30608332107392383, 0.3052222389923248, 0.3014607711739741, 0.3019602927007592, 0.30409731695371717, 0.3016268905146399, 0.30204999161080504, 0.30165941151573084, 0.2983986947908704, 0.2925634441436536, 0.2962555351678499, 0.29657629303434885, 0.2960933474536113, 0.2927704656578905, 0.295526511109817, 0.29289860926721445, 0.2935646255493856, 0.29118402914624725], 'acc': [0.8428351507301453, 0.915926404397764, 0.9222578406210339, 0.925930242122715, 0.9283870403731534, 0.9305969783559321, 0.9322448989278717, 0.9339768609119702, 0.9355086036028023, 0.9365442806498381, 0.9371990784925468, 0.9379155819109063, 0.9386602579966488, 0.9389139748746717, 0.9397127651065903, 0.9402244913733749, 0.9406773839875818, 0.9411166512988401, 0.9415243760866667, 0.941888740862056, 0.9422866159421687, 0.9425519137938142, 0.9426444545218293, 0.9427348795259441, 0.9434590022790835, 0.9436125851211374, 0.9436190651087452, 0.9441658701363772, 0.9439981197040407, 0.9444660816774956, 0.9446076785853215, 0.9454181458899126, 0.9455316652778073, 0.9459676339422152, 0.9458238776852772, 0.9460838600211486, 0.9461215250896957, 0.9463401382552274, 0.9463131763419496, 0.9463661518824588, 0.9466141706775536, 0.9464714342248209, 0.9464155890351876, 0.9466421767411182, 0.9465698351658357, 0.9468302690164692, 0.9470926943765545, 0.9472893069276369, 0.9473966779166081, 0.9473972248630654, 0.9473520358049249, 0.9475548430742774, 0.9474419881119511, 0.9476591302180424, 0.9476526742057634, 0.9476769536875749], 'mDice': [0.23715792442226857, 0.42941419406103293, 0.48673009975629306, 0.5147759590947527, 0.5386810351426538, 0.5558322847890528, 0.567800505401533, 0.5803578977525025, 0.5896400385208949, 0.5978593257992143, 0.6011596743605232, 0.607642194226449, 0.6102698049232868, 0.6142321507292567, 0.6207701899427955, 0.6218727272241016, 0.6280197053807864, 0.6291739411270522, 0.631789823488504, 0.6329099977693691, 0.6397464733548415, 0.6382404149456091, 0.6412455951267818, 0.6413206227051131, 0.6477730197701839, 0.6494743429895211, 0.6520348120323979, 0.6532276010589928, 0.6527535972841394, 0.6560086305522582, 0.6567487838590588, 0.6612409940713574, 0.6651015586374015, 0.6674437343691139, 0.6674180519536351, 0.6690463533348101, 0.6676123874231465, 0.6717482816436442, 0.6706617493711515, 0.671579732381776, 0.6756495871213667, 0.6751017669919069, 0.6728028204989537, 0.6754757945663129, 0.6750238544461936, 0.6754352182193142, 0.6789441672741762, 0.6852672916525953, 0.6812702821864642, 0.6809215732328184, 0.6814554682194186, 0.6850407573906386, 0.6820699622058631, 0.684892275102055, 0.6841676405065416, 0.6867548248010529], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
CrossVal ['d']
