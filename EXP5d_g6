*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/456) train vimp2_845_05312013_VZ
(1/456) train vimp2_823_05202013_AJ
(2/456) train vimp2_915_07112013_LC
(3/456) train vimp2_901_07052013_AS
(4/456) train vimp2_ctrl_911_07082013_TTO
(5/456) train vimp2_ctrl_925_07152013_LS
(6/456) train vimp2_869_06142013_BL
(7/456) train vimp2_ANON724_03272013
(8/456) train vimp2_819_05172013_DS
(9/456) train vimp2_ctrl_918_07112013_TQ
(10/456) train vimp2_ctrl_902_07052013_SI
(11/456) train vimp2_ANON606_20130110
(12/456) train vimp2_943_07242013_PA
(13/456) train vimp2_824_05212013_JS
(14/456) train vimp2_ANON624_20130117
(15/456) train vimp2_ctrl_920_07122013_SW
(16/456) train vimp2_884_06272013_TS
(17/456) train vimp2_668_02282013_CD
(18/456) train vimp2_964_08092013_TG
(19/456) train vimp2_ctrl_921_07122013_MP
(20/456) train vimp2_972_08152013_DC
(21/456) train vimp2_988_08302013_CB
(22/456) train vimp2_ANON702_03152013
(23/456) train vimp2_ANON714_03222013
(24/456) train vimp2_972_08152013_DC_Aug0_Rot_-1_sd0
(25/456) train vimp2_972_08152013_DC_Aug0_Rot_1_sd2
(26/456) train vimp2_972_08152013_DC_Aug0_Rot_-7_sd1
(27/456) train vimp2_972_08152013_DC_Aug1_Rot_2_sd0
(28/456) train vimp2_972_08152013_DC_Aug1_Rot_5_sd1
(29/456) train vimp2_972_08152013_DC_Aug1_Rot_6_sd2
(30/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd1
(31/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd2
(32/456) train vimp2_972_08152013_DC_Aug2_Rot_-5_sd0
(33/456) train vimp2_972_08152013_DC_Aug3_Rot_2_sd1
(34/456) train vimp2_972_08152013_DC_Aug3_Rot_-3_sd0
(35/456) train vimp2_972_08152013_DC_Aug3_Rot_-6_sd2
(36/456) train vimp2_972_08152013_DC_Aug4_Rot_-2_sd2
(37/456) train vimp2_972_08152013_DC_Aug4_Rot_3_sd0
(38/456) train vimp2_972_08152013_DC_Aug4_Rot_6_sd1
(39/456) train vimp2_972_08152013_DC_Aug5_Rot_-1_sd2
(40/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd0
(41/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd1
(42/456) train vimp2_988_08302013_CB_Aug0_Rot_-3_sd2
(43/456) train vimp2_988_08302013_CB_Aug0_Rot_4_sd0
(44/456) train vimp2_988_08302013_CB_Aug0_Rot_-5_sd1
(45/456) train vimp2_988_08302013_CB_Aug1_Rot_-2_sd2
(46/456) train vimp2_988_08302013_CB_Aug1_Rot_-3_sd0
(47/456) train vimp2_988_08302013_CB_Aug1_Rot_-6_sd1
(48/456) train vimp2_988_08302013_CB_Aug2_Rot_-2_sd0
(49/456) train vimp2_988_08302013_CB_Aug2_Rot_4_sd1
(50/456) train vimp2_988_08302013_CB_Aug2_Rot_-5_sd2
(51/456) train vimp2_988_08302013_CB_Aug3_Rot_2_sd2
(52/456) train vimp2_988_08302013_CB_Aug3_Rot_-3_sd0
(53/456) train vimp2_988_08302013_CB_Aug3_Rot_3_sd1
(54/456) train vimp2_988_08302013_CB_Aug4_Rot_-2_sd0
(55/456) train vimp2_988_08302013_CB_Aug4_Rot_-6_sd1
(56/456) train vimp2_988_08302013_CB_Aug4_Rot_7_sd2
(57/456) train vimp2_988_08302013_CB_Aug5_Rot_-1_sd0
(58/456) train vimp2_988_08302013_CB_Aug5_Rot_-6_sd1
(59/456) train vimp2_988_08302013_CB_Aug5_Rot_7_sd2
(60/456) train vimp2_ANON702_03152013_Aug0_Rot_-2_sd1
(61/456) train vimp2_ANON702_03152013_Aug0_Rot_-3_sd2
(62/456) train vimp2_ANON702_03152013_Aug0_Rot_-4_sd0
(63/456) train vimp2_ANON702_03152013_Aug1_Rot_-4_sd1
(64/456) train vimp2_ANON702_03152013_Aug1_Rot_-5_sd2
(65/456) train vimp2_ANON702_03152013_Aug1_Rot_-7_sd0
(66/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd0
(67/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd2
(68/456) train vimp2_ANON702_03152013_Aug2_Rot_-7_sd1
(69/456) train vimp2_ANON702_03152013_Aug3_Rot_-1_sd2
(70/456) train vimp2_ANON702_03152013_Aug3_Rot_-3_sd0
(71/456) train vimp2_ANON702_03152013_Aug3_Rot_-6_sd1
(72/456) train vimp2_ANON702_03152013_Aug4_Rot_-2_sd0
(73/456) train vimp2_ANON702_03152013_Aug4_Rot_-3_sd2
(74/456) train vimp2_ANON702_03152013_Aug4_Rot_-7_sd1
(75/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd0
(76/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd2
(77/456) train vimp2_ANON702_03152013_Aug5_Rot_4_sd1
(78/456) train vimp2_ANON714_03222013_Aug0_Rot_-1_sd2
(79/456) train vimp2_ANON714_03222013_Aug0_Rot_-2_sd1
(80/456) train vimp2_ANON714_03222013_Aug0_Rot_4_sd0
(81/456) train vimp2_ANON714_03222013_Aug1_Rot_0_sd0
(82/456) train vimp2_ANON714_03222013_Aug1_Rot_1_sd1
(83/456) train vimp2_ANON714_03222013_Aug1_Rot_-6_sd2
(84/456) train vimp2_ANON714_03222013_Aug2_Rot_-2_sd0
(85/456) train vimp2_ANON714_03222013_Aug2_Rot_4_sd1
(86/456) train vimp2_ANON714_03222013_Aug2_Rot_6_sd2
(87/456) train vimp2_ANON714_03222013_Aug3_Rot_2_sd0
(88/456) train vimp2_ANON714_03222013_Aug3_Rot_-3_sd2
(89/456) train vimp2_ANON714_03222013_Aug3_Rot_-7_sd1
(90/456) train vimp2_ANON714_03222013_Aug4_Rot_1_sd0
(91/456) train vimp2_ANON714_03222013_Aug4_Rot_-2_sd1
(92/456) train vimp2_ANON714_03222013_Aug4_Rot_4_sd2
(93/456) train vimp2_ANON714_03222013_Aug5_Rot_1_sd0
(94/456) train vimp2_ANON714_03222013_Aug5_Rot_6_sd1
(95/456) train vimp2_ANON714_03222013_Aug5_Rot_-7_sd2
(96/456) train vimp2_668_02282013_CD_Aug0_Rot_7_sd0
(97/456) train vimp2_668_02282013_CD_Aug1_Rot_-1_sd0
(98/456) train vimp2_668_02282013_CD_Aug2_Rot_-4_sd0
(99/456) train vimp2_668_02282013_CD_Aug3_Rot_3_sd0
(100/456) train vimp2_668_02282013_CD_Aug4_Rot_-5_sd0
(101/456) train vimp2_668_02282013_CD_Aug5_Rot_-6_sd0
(102/456) train vimp2_819_05172013_DS_Aug0_Rot_1_sd0
(103/456) train vimp2_819_05172013_DS_Aug1_Rot_5_sd0
(104/456) train vimp2_819_05172013_DS_Aug2_Rot_-4_sd0
(105/456) train vimp2_819_05172013_DS_Aug3_Rot_2_sd0
(106/456) train vimp2_819_05172013_DS_Aug4_Rot_5_sd0
(107/456) train vimp2_819_05172013_DS_Aug5_Rot_4_sd0
(108/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd0
(109/456) train vimp2_823_05202013_AJ_Aug1_Rot_7_sd0
(110/456) train vimp2_823_05202013_AJ_Aug2_Rot_3_sd0
(111/456) train vimp2_823_05202013_AJ_Aug3_Rot_-5_sd0
(112/456) train vimp2_823_05202013_AJ_Aug4_Rot_-3_sd0
(113/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd0
(114/456) train vimp2_824_05212013_JS_Aug0_Rot_-2_sd0
(115/456) train vimp2_824_05212013_JS_Aug1_Rot_6_sd0
(116/456) train vimp2_824_05212013_JS_Aug2_Rot_1_sd0
(117/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd0
(118/456) train vimp2_824_05212013_JS_Aug4_Rot_7_sd0
(119/456) train vimp2_824_05212013_JS_Aug5_Rot_2_sd0
(120/456) train vimp2_845_05312013_VZ_Aug0_Rot_1_sd0
(121/456) train vimp2_845_05312013_VZ_Aug1_Rot_5_sd0
(122/456) train vimp2_845_05312013_VZ_Aug2_Rot_-6_sd0
(123/456) train vimp2_845_05312013_VZ_Aug3_Rot_3_sd0
(124/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd0
(125/456) train vimp2_845_05312013_VZ_Aug5_Rot_5_sd0
(126/456) train vimp2_869_06142013_BL_Aug0_Rot_-2_sd0
(127/456) train vimp2_869_06142013_BL_Aug1_Rot_-4_sd0
(128/456) train vimp2_869_06142013_BL_Aug2_Rot_-1_sd0
(129/456) train vimp2_869_06142013_BL_Aug3_Rot_3_sd0
(130/456) train vimp2_869_06142013_BL_Aug4_Rot_3_sd0
(131/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd0
(132/456) train vimp2_884_06272013_TS_Aug0_Rot_-7_sd0
(133/456) train vimp2_884_06272013_TS_Aug1_Rot_7_sd0
(134/456) train vimp2_884_06272013_TS_Aug2_Rot_-5_sd0
(135/456) train vimp2_884_06272013_TS_Aug3_Rot_-2_sd0
(136/456) train vimp2_884_06272013_TS_Aug4_Rot_6_sd0
(137/456) train vimp2_884_06272013_TS_Aug5_Rot_-1_sd0
(138/456) train vimp2_901_07052013_AS_Aug0_Rot_-4_sd0
(139/456) train vimp2_901_07052013_AS_Aug1_Rot_-2_sd0
(140/456) train vimp2_901_07052013_AS_Aug2_Rot_1_sd0
(141/456) train vimp2_901_07052013_AS_Aug3_Rot_2_sd0
(142/456) train vimp2_901_07052013_AS_Aug4_Rot_-7_sd0
(143/456) train vimp2_901_07052013_AS_Aug5_Rot_-5_sd0
(144/456) train vimp2_915_07112013_LC_Aug0_Rot_-2_sd0
(145/456) train vimp2_915_07112013_LC_Aug1_Rot_4_sd0
(146/456) train vimp2_915_07112013_LC_Aug2_Rot_-2_sd0
(147/456) train vimp2_915_07112013_LC_Aug3_Rot_-1_sd0
(148/456) train vimp2_915_07112013_LC_Aug4_Rot_1_sd0
(149/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd0
(150/456) train vimp2_943_07242013_PA_Aug0_Rot_-5_sd0
(151/456) train vimp2_943_07242013_PA_Aug1_Rot_-7_sd0
(152/456) train vimp2_943_07242013_PA_Aug2_Rot_-4_sd0
(153/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd0
(154/456) train vimp2_943_07242013_PA_Aug4_Rot_6_sd0
(155/456) train vimp2_943_07242013_PA_Aug5_Rot_5_sd0
(156/456) train vimp2_964_08092013_TG_Aug0_Rot_5_sd0
(157/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd0
(158/456) train vimp2_964_08092013_TG_Aug2_Rot_7_sd0
(159/456) train vimp2_964_08092013_TG_Aug3_Rot_-1_sd0
(160/456) train vimp2_964_08092013_TG_Aug4_Rot_-1_sd0
(161/456) train vimp2_964_08092013_TG_Aug5_Rot_2_sd0
(162/456) train vimp2_ANON606_20130110_Aug0_Rot_1_sd0
(163/456) train vimp2_ANON606_20130110_Aug1_Rot_2_sd0
(164/456) train vimp2_ANON606_20130110_Aug2_Rot_-5_sd0
(165/456) train vimp2_ANON606_20130110_Aug3_Rot_-5_sd0
(166/456) train vimp2_ANON606_20130110_Aug4_Rot_3_sd0
(167/456) train vimp2_ANON606_20130110_Aug5_Rot_-1_sd0
(168/456) train vimp2_ANON624_20130117_Aug0_Rot_1_sd0
(169/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd0
(170/456) train vimp2_ANON624_20130117_Aug2_Rot_5_sd0
(171/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd0
(172/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd0
(173/456) train vimp2_ANON624_20130117_Aug5_Rot_3_sd0
(174/456) train vimp2_ANON724_03272013_Aug0_Rot_-4_sd0
(175/456) train vimp2_ANON724_03272013_Aug1_Rot_-3_sd0
(176/456) train vimp2_ANON724_03272013_Aug2_Rot_-4_sd0
(177/456) train vimp2_ANON724_03272013_Aug3_Rot_5_sd0
(178/456) train vimp2_ANON724_03272013_Aug4_Rot_5_sd0
(179/456) train vimp2_ANON724_03272013_Aug5_Rot_-6_sd0
(180/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_5_sd0
(181/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd0
(182/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_4_sd0
(183/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd0
(184/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_3_sd0
(185/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-7_sd0
(186/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_6_sd0
(187/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_1_sd0
(188/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_4_sd0
(189/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-2_sd0
(190/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd0
(191/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_-2_sd0
(192/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_5_sd0
(193/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-3_sd0
(194/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-4_sd0
(195/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_1_sd0
(196/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_3_sd0
(197/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_7_sd0
(198/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd0
(199/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-6_sd0
(200/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd0
(201/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_1_sd0
(202/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-2_sd0
(203/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_4_sd0
(204/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_-1_sd0
(205/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-3_sd0
(206/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd0
(207/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_3_sd0
(208/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_1_sd0
(209/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_-5_sd0
(210/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-5_sd0
(211/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_-2_sd0
(212/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_5_sd0
(213/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_3_sd0
(214/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_4_sd0
(215/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-7_sd0
(216/456) train vimp2_668_02282013_CD_Aug0_Rot_-5_sd1
(217/456) train vimp2_668_02282013_CD_Aug1_Rot_-6_sd1
(218/456) train vimp2_668_02282013_CD_Aug2_Rot_3_sd1
(219/456) train vimp2_668_02282013_CD_Aug3_Rot_4_sd1
(220/456) train vimp2_668_02282013_CD_Aug4_Rot_-6_sd1
(221/456) train vimp2_668_02282013_CD_Aug5_Rot_-2_sd1
(222/456) train vimp2_819_05172013_DS_Aug0_Rot_-1_sd1
(223/456) train vimp2_819_05172013_DS_Aug1_Rot_3_sd1
(224/456) train vimp2_819_05172013_DS_Aug2_Rot_6_sd1
(225/456) train vimp2_819_05172013_DS_Aug3_Rot_3_sd1
(226/456) train vimp2_819_05172013_DS_Aug4_Rot_-7_sd1
(227/456) train vimp2_819_05172013_DS_Aug5_Rot_-5_sd1
(228/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd1
(229/456) train vimp2_823_05202013_AJ_Aug1_Rot_3_sd1
(230/456) train vimp2_823_05202013_AJ_Aug2_Rot_6_sd1
(231/456) train vimp2_823_05202013_AJ_Aug3_Rot_-7_sd1
(232/456) train vimp2_823_05202013_AJ_Aug4_Rot_-4_sd1
(233/456) train vimp2_823_05202013_AJ_Aug5_Rot_-4_sd1
(234/456) train vimp2_824_05212013_JS_Aug0_Rot_7_sd1
(235/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd1
(236/456) train vimp2_824_05212013_JS_Aug2_Rot_3_sd1
(237/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd1
(238/456) train vimp2_824_05212013_JS_Aug4_Rot_4_sd1
(239/456) train vimp2_824_05212013_JS_Aug5_Rot_6_sd1
(240/456) train vimp2_845_05312013_VZ_Aug0_Rot_5_sd1
(241/456) train vimp2_845_05312013_VZ_Aug1_Rot_6_sd1
(242/456) train vimp2_845_05312013_VZ_Aug2_Rot_1_sd1
(243/456) train vimp2_845_05312013_VZ_Aug3_Rot_-6_sd1
(244/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd1
(245/456) train vimp2_845_05312013_VZ_Aug5_Rot_-6_sd1
(246/456) train vimp2_869_06142013_BL_Aug0_Rot_-4_sd1
(247/456) train vimp2_869_06142013_BL_Aug1_Rot_-3_sd1
(248/456) train vimp2_869_06142013_BL_Aug2_Rot_-4_sd1
(249/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd1
(250/456) train vimp2_869_06142013_BL_Aug4_Rot_7_sd1
(251/456) train vimp2_869_06142013_BL_Aug5_Rot_5_sd1
(252/456) train vimp2_884_06272013_TS_Aug0_Rot_5_sd1
(253/456) train vimp2_884_06272013_TS_Aug1_Rot_-1_sd1
(254/456) train vimp2_884_06272013_TS_Aug2_Rot_-1_sd1
(255/456) train vimp2_884_06272013_TS_Aug3_Rot_3_sd1
(256/456) train vimp2_884_06272013_TS_Aug4_Rot_4_sd1
(257/456) train vimp2_884_06272013_TS_Aug5_Rot_3_sd1
(258/456) train vimp2_901_07052013_AS_Aug0_Rot_3_sd1
(259/456) train vimp2_901_07052013_AS_Aug1_Rot_5_sd1
(260/456) train vimp2_901_07052013_AS_Aug2_Rot_-5_sd1
(261/456) train vimp2_901_07052013_AS_Aug3_Rot_7_sd1
(262/456) train vimp2_901_07052013_AS_Aug4_Rot_7_sd1
(263/456) train vimp2_901_07052013_AS_Aug5_Rot_6_sd1
(264/456) train vimp2_915_07112013_LC_Aug0_Rot_-6_sd1
(265/456) train vimp2_915_07112013_LC_Aug1_Rot_-5_sd1
(266/456) train vimp2_915_07112013_LC_Aug2_Rot_7_sd1
(267/456) train vimp2_915_07112013_LC_Aug3_Rot_1_sd1
(268/456) train vimp2_915_07112013_LC_Aug4_Rot_6_sd1
(269/456) train vimp2_915_07112013_LC_Aug5_Rot_-7_sd1
(270/456) train vimp2_943_07242013_PA_Aug0_Rot_1_sd1
(271/456) train vimp2_943_07242013_PA_Aug1_Rot_6_sd1
(272/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd1
(273/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd1
(274/456) train vimp2_943_07242013_PA_Aug4_Rot_3_sd1
(275/456) train vimp2_943_07242013_PA_Aug5_Rot_3_sd1
(276/456) train vimp2_964_08092013_TG_Aug0_Rot_6_sd1
(277/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd1
(278/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd1
(279/456) train vimp2_964_08092013_TG_Aug3_Rot_0_sd1
(280/456) train vimp2_964_08092013_TG_Aug4_Rot_3_sd1
(281/456) train vimp2_964_08092013_TG_Aug5_Rot_-1_sd1
(282/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd1
(283/456) train vimp2_ANON606_20130110_Aug1_Rot_7_sd1
(284/456) train vimp2_ANON606_20130110_Aug2_Rot_1_sd1
(285/456) train vimp2_ANON606_20130110_Aug3_Rot_1_sd1
(286/456) train vimp2_ANON606_20130110_Aug4_Rot_4_sd1
(287/456) train vimp2_ANON606_20130110_Aug5_Rot_4_sd1
(288/456) train vimp2_ANON624_20130117_Aug0_Rot_7_sd1
(289/456) train vimp2_ANON624_20130117_Aug1_Rot_6_sd1
(290/456) train vimp2_ANON624_20130117_Aug2_Rot_-1_sd1
(291/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd1
(292/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd1
(293/456) train vimp2_ANON624_20130117_Aug5_Rot_4_sd1
(294/456) train vimp2_ANON724_03272013_Aug0_Rot_-2_sd1
(295/456) train vimp2_ANON724_03272013_Aug1_Rot_4_sd1
(296/456) train vimp2_ANON724_03272013_Aug2_Rot_-1_sd1
(297/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd1
(298/456) train vimp2_ANON724_03272013_Aug4_Rot_-5_sd1
(299/456) train vimp2_ANON724_03272013_Aug5_Rot_-4_sd1
(300/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2_sd1
(301/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd1
(302/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_2_sd1
(303/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd1
(304/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1_sd1
(305/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-4_sd1
(306/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_7_sd1
(307/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_-1_sd1
(308/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_-5_sd1
(309/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-3_sd1
(310/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd1
(311/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_6_sd1
(312/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_1_sd1
(313/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-2_sd1
(314/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_3_sd1
(315/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_-1_sd1
(316/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_7_sd1
(317/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_6_sd1
(318/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-3_sd1
(319/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_7_sd1
(320/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd1
(321/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-1_sd1
(322/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5_sd1
(323/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_-5_sd1
(324/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_4_sd1
(325/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_3_sd1
(326/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-1_sd1
(327/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd1
(328/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_2_sd1
(329/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_4_sd1
(330/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-2_sd1
(331/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_4_sd1
(332/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_-2_sd1
(333/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_2_sd1
(334/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_3_sd1
(335/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-4_sd1
(336/456) train vimp2_668_02282013_CD_Aug0_Rot_-3_sd2
(337/456) train vimp2_668_02282013_CD_Aug1_Rot_6_sd2
(338/456) train vimp2_668_02282013_CD_Aug2_Rot_-6_sd2
(339/456) train vimp2_668_02282013_CD_Aug3_Rot_7_sd2
(340/456) train vimp2_668_02282013_CD_Aug4_Rot_1_sd2
(341/456) train vimp2_668_02282013_CD_Aug5_Rot_7_sd2
(342/456) train vimp2_819_05172013_DS_Aug0_Rot_3_sd2
(343/456) train vimp2_819_05172013_DS_Aug1_Rot_-1_sd2
(344/456) train vimp2_819_05172013_DS_Aug2_Rot_-2_sd2
(345/456) train vimp2_819_05172013_DS_Aug3_Rot_-1_sd2
(346/456) train vimp2_819_05172013_DS_Aug4_Rot_7_sd2
(347/456) train vimp2_819_05172013_DS_Aug5_Rot_3_sd2
(348/456) train vimp2_823_05202013_AJ_Aug0_Rot_-6_sd2
(349/456) train vimp2_823_05202013_AJ_Aug1_Rot_-7_sd2
(350/456) train vimp2_823_05202013_AJ_Aug2_Rot_7_sd2
(351/456) train vimp2_823_05202013_AJ_Aug3_Rot_-2_sd2
(352/456) train vimp2_823_05202013_AJ_Aug4_Rot_1_sd2
(353/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd2
(354/456) train vimp2_824_05212013_JS_Aug0_Rot_-5_sd2
(355/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd2
(356/456) train vimp2_824_05212013_JS_Aug2_Rot_5_sd2
(357/456) train vimp2_824_05212013_JS_Aug3_Rot_2_sd2
(358/456) train vimp2_824_05212013_JS_Aug4_Rot_5_sd2
(359/456) train vimp2_824_05212013_JS_Aug5_Rot_-7_sd2
(360/456) train vimp2_845_05312013_VZ_Aug0_Rot_-5_sd2
(361/456) train vimp2_845_05312013_VZ_Aug1_Rot_3_sd2
(362/456) train vimp2_845_05312013_VZ_Aug2_Rot_-3_sd2
(363/456) train vimp2_845_05312013_VZ_Aug3_Rot_-1_sd2
(364/456) train vimp2_845_05312013_VZ_Aug4_Rot_4_sd2
(365/456) train vimp2_845_05312013_VZ_Aug5_Rot_-2_sd2
(366/456) train vimp2_869_06142013_BL_Aug0_Rot_3_sd2
(367/456) train vimp2_869_06142013_BL_Aug1_Rot_7_sd2
(368/456) train vimp2_869_06142013_BL_Aug2_Rot_4_sd2
(369/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd2
(370/456) train vimp2_869_06142013_BL_Aug4_Rot_1_sd2
(371/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd2
(372/456) train vimp2_884_06272013_TS_Aug0_Rot_3_sd2
(373/456) train vimp2_884_06272013_TS_Aug1_Rot_-5_sd2
(374/456) train vimp2_884_06272013_TS_Aug2_Rot_-7_sd2
(375/456) train vimp2_884_06272013_TS_Aug3_Rot_-6_sd2
(376/456) train vimp2_884_06272013_TS_Aug4_Rot_-2_sd2
(377/456) train vimp2_884_06272013_TS_Aug5_Rot_-6_sd2
(378/456) train vimp2_901_07052013_AS_Aug0_Rot_2_sd2
(379/456) train vimp2_901_07052013_AS_Aug1_Rot_-3_sd2
(380/456) train vimp2_901_07052013_AS_Aug2_Rot_-6_sd2
(381/456) train vimp2_901_07052013_AS_Aug3_Rot_6_sd2
(382/456) train vimp2_901_07052013_AS_Aug4_Rot_-5_sd2
(383/456) train vimp2_901_07052013_AS_Aug5_Rot_1_sd2
(384/456) train vimp2_915_07112013_LC_Aug0_Rot_1_sd2
(385/456) train vimp2_915_07112013_LC_Aug1_Rot_7_sd2
(386/456) train vimp2_915_07112013_LC_Aug2_Rot_3_sd2
(387/456) train vimp2_915_07112013_LC_Aug3_Rot_6_sd2
(388/456) train vimp2_915_07112013_LC_Aug4_Rot_4_sd2
(389/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd2
(390/456) train vimp2_943_07242013_PA_Aug0_Rot_3_sd2
(391/456) train vimp2_943_07242013_PA_Aug1_Rot_-4_sd2
(392/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd2
(393/456) train vimp2_943_07242013_PA_Aug3_Rot_2_sd2
(394/456) train vimp2_943_07242013_PA_Aug4_Rot_-1_sd2
(395/456) train vimp2_943_07242013_PA_Aug5_Rot_-3_sd2
(396/456) train vimp2_964_08092013_TG_Aug0_Rot_2_sd2
(397/456) train vimp2_964_08092013_TG_Aug1_Rot_-6_sd2
(398/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd2
(399/456) train vimp2_964_08092013_TG_Aug3_Rot_-7_sd2
(400/456) train vimp2_964_08092013_TG_Aug4_Rot_-6_sd2
(401/456) train vimp2_964_08092013_TG_Aug5_Rot_5_sd2
(402/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd2
(403/456) train vimp2_ANON606_20130110_Aug1_Rot_-5_sd2
(404/456) train vimp2_ANON606_20130110_Aug2_Rot_-3_sd2
(405/456) train vimp2_ANON606_20130110_Aug3_Rot_3_sd2
(406/456) train vimp2_ANON606_20130110_Aug4_Rot_-2_sd2
(407/456) train vimp2_ANON606_20130110_Aug5_Rot_-3_sd2
(408/456) train vimp2_ANON624_20130117_Aug0_Rot_2_sd2
(409/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd2
(410/456) train vimp2_ANON624_20130117_Aug2_Rot_-6_sd2
(411/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd2
(412/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd2
(413/456) train vimp2_ANON624_20130117_Aug5_Rot_-7_sd2
(414/456) train vimp2_ANON724_03272013_Aug0_Rot_-5_sd2
(415/456) train vimp2_ANON724_03272013_Aug1_Rot_6_sd2
(416/456) train vimp2_ANON724_03272013_Aug2_Rot_-3_sd2
(417/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd2
(418/456) train vimp2_ANON724_03272013_Aug4_Rot_-1_sd2
(419/456) train vimp2_ANON724_03272013_Aug5_Rot_-7_sd2
(420/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-4_sd2
(421/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_-3_sd2
(422/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-5_sd2
(423/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5_sd2
(424/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-2_sd2
(425/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_5_sd2
(426/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_-3_sd2
(427/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_7_sd2
(428/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_3_sd2
(429/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_5_sd2
(430/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_7_sd2
(431/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_2_sd2
(432/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7_sd2
(433/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_5_sd2
(434/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_5_sd2
(435/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_4_sd2
(436/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_5_sd2
(437/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_-4_sd2
(438/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd2
(439/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-2_sd2
(440/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_1_sd2
(441/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-7_sd2
(442/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-3_sd2
(443/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_7_sd2
(444/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_1_sd2
(445/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-7_sd2
(446/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd2
(447/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd2
(448/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_-5_sd2
(449/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_6_sd2
(450/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_2_sd2
(451/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_5_sd2
(452/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_2_sd2
(453/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_5_sd2
(454/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_-4_sd2
(455/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-3_sd22019-07-06 18:04:21.597413: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-06 18:04:22.928741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:88:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-06 18:04:22.928808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 18:04:23.311836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 18:04:23.311903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 18:04:23.311915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 18:04:23.312409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:26,  1.41s/it]Loading train:   0%|          | 2/532 [00:02<11:05,  1.26s/it]Loading train:   1%|          | 3/532 [00:03<10:17,  1.17s/it]Loading train:   1%|          | 4/532 [00:04<09:51,  1.12s/it]Loading train:   1%|          | 5/532 [00:05<09:22,  1.07s/it]Loading train:   1%|          | 6/532 [00:06<08:49,  1.01s/it]Loading train:   1%|▏         | 7/532 [00:07<08:34,  1.02it/s]Loading train:   2%|▏         | 8/532 [00:07<08:13,  1.06it/s]Loading train:   2%|▏         | 9/532 [00:08<08:35,  1.01it/s]Loading train:   2%|▏         | 10/532 [00:09<08:14,  1.06it/s]Loading train:   2%|▏         | 11/532 [00:10<07:43,  1.12it/s]Loading train:   2%|▏         | 12/532 [00:11<08:25,  1.03it/s]Loading train:   2%|▏         | 13/532 [00:12<07:57,  1.09it/s]Loading train:   3%|▎         | 14/532 [00:13<07:29,  1.15it/s]Loading train:   3%|▎         | 15/532 [00:14<07:15,  1.19it/s]Loading train:   3%|▎         | 16/532 [00:14<07:24,  1.16it/s]Loading train:   3%|▎         | 17/532 [00:15<07:06,  1.21it/s]Loading train:   3%|▎         | 18/532 [00:16<07:30,  1.14it/s]Loading train:   4%|▎         | 19/532 [00:17<06:58,  1.23it/s]Loading train:   4%|▍         | 20/532 [00:18<06:53,  1.24it/s]Loading train:   4%|▍         | 21/532 [00:19<07:12,  1.18it/s]Loading train:   4%|▍         | 22/532 [00:19<06:52,  1.24it/s]Loading train:   4%|▍         | 23/532 [00:20<07:04,  1.20it/s]Loading train:   5%|▍         | 24/532 [00:21<06:44,  1.26it/s]Loading train:   5%|▍         | 25/532 [00:22<07:28,  1.13it/s]Loading train:   5%|▍         | 26/532 [00:23<07:13,  1.17it/s]Loading train:   5%|▌         | 27/532 [00:24<08:07,  1.04it/s]Loading train:   5%|▌         | 28/532 [00:25<07:46,  1.08it/s]Loading train:   5%|▌         | 29/532 [00:26<07:52,  1.07it/s]Loading train:   6%|▌         | 30/532 [00:27<07:27,  1.12it/s]Loading train:   6%|▌         | 31/532 [00:27<07:19,  1.14it/s]Loading train:   6%|▌         | 32/532 [00:28<07:06,  1.17it/s]Loading train:   6%|▌         | 33/532 [00:29<06:51,  1.21it/s]Loading train:   6%|▋         | 34/532 [00:30<07:47,  1.07it/s]Loading train:   7%|▋         | 35/532 [00:31<07:45,  1.07it/s]Loading train:   7%|▋         | 36/532 [00:32<07:45,  1.07it/s]Loading train:   7%|▋         | 37/532 [00:33<07:37,  1.08it/s]Loading train:   7%|▋         | 38/532 [00:34<07:37,  1.08it/s]Loading train:   7%|▋         | 39/532 [00:35<07:19,  1.12it/s]Loading train:   8%|▊         | 40/532 [00:35<06:58,  1.18it/s]Loading train:   8%|▊         | 41/532 [00:36<07:00,  1.17it/s]Loading train:   8%|▊         | 42/532 [00:37<07:15,  1.13it/s]Loading train:   8%|▊         | 43/532 [00:38<06:52,  1.19it/s]Loading train:   8%|▊         | 44/532 [00:39<07:13,  1.13it/s]Loading train:   8%|▊         | 45/532 [00:40<06:58,  1.16it/s]Loading train:   9%|▊         | 46/532 [00:41<07:01,  1.15it/s]Loading train:   9%|▉         | 47/532 [00:42<07:37,  1.06it/s]Loading train:   9%|▉         | 48/532 [00:43<07:35,  1.06it/s]Loading train:   9%|▉         | 49/532 [00:44<07:07,  1.13it/s]Loading train:   9%|▉         | 50/532 [00:45<07:28,  1.08it/s]Loading train:  10%|▉         | 51/532 [00:45<07:22,  1.09it/s]Loading train:  10%|▉         | 52/532 [00:46<07:36,  1.05it/s]Loading train:  10%|▉         | 53/532 [00:47<07:13,  1.11it/s]Loading train:  10%|█         | 54/532 [00:48<07:37,  1.05it/s]Loading train:  10%|█         | 55/532 [00:49<07:28,  1.06it/s]Loading train:  11%|█         | 56/532 [00:50<07:18,  1.09it/s]Loading train:  11%|█         | 57/532 [00:51<06:55,  1.14it/s]Loading train:  11%|█         | 58/532 [00:52<07:24,  1.07it/s]Loading train:  11%|█         | 59/532 [00:53<07:51,  1.00it/s]Loading train:  11%|█▏        | 60/532 [00:54<07:13,  1.09it/s]Loading train:  11%|█▏        | 61/532 [00:55<07:00,  1.12it/s]Loading train:  12%|█▏        | 62/532 [00:56<07:29,  1.04it/s]Loading train:  12%|█▏        | 63/532 [00:57<07:40,  1.02it/s]Loading train:  12%|█▏        | 64/532 [00:58<07:06,  1.10it/s]Loading train:  12%|█▏        | 65/532 [00:59<07:15,  1.07it/s]Loading train:  12%|█▏        | 66/532 [01:00<07:40,  1.01it/s]Loading train:  13%|█▎        | 67/532 [01:01<08:02,  1.04s/it]Loading train:  13%|█▎        | 68/532 [01:02<07:47,  1.01s/it]Loading train:  13%|█▎        | 69/532 [01:03<07:26,  1.04it/s]Loading train:  13%|█▎        | 70/532 [01:03<07:09,  1.07it/s]Loading train:  13%|█▎        | 71/532 [01:04<06:49,  1.13it/s]Loading train:  14%|█▎        | 72/532 [01:05<06:28,  1.18it/s]Loading train:  14%|█▎        | 73/532 [01:06<06:29,  1.18it/s]Loading train:  14%|█▍        | 74/532 [01:07<07:11,  1.06it/s]Loading train:  14%|█▍        | 75/532 [01:09<08:28,  1.11s/it]Loading train:  14%|█▍        | 76/532 [01:09<07:52,  1.04s/it]Loading train:  14%|█▍        | 77/532 [01:10<07:44,  1.02s/it]Loading train:  15%|█▍        | 78/532 [01:11<07:24,  1.02it/s]Loading train:  15%|█▍        | 79/532 [01:12<07:13,  1.04it/s]Loading train:  15%|█▌        | 80/532 [01:13<07:07,  1.06it/s]Loading train:  15%|█▌        | 81/532 [01:14<07:01,  1.07it/s]Loading train:  15%|█▌        | 82/532 [01:15<07:08,  1.05it/s]Loading train:  16%|█▌        | 83/532 [01:16<06:45,  1.11it/s]Loading train:  16%|█▌        | 84/532 [01:17<06:51,  1.09it/s]Loading train:  16%|█▌        | 85/532 [01:17<06:28,  1.15it/s]Loading train:  16%|█▌        | 86/532 [01:18<06:13,  1.19it/s]Loading train:  16%|█▋        | 87/532 [01:19<05:58,  1.24it/s]Loading train:  17%|█▋        | 88/532 [01:20<05:53,  1.26it/s]Loading train:  17%|█▋        | 89/532 [01:21<05:57,  1.24it/s]Loading train:  17%|█▋        | 90/532 [01:21<06:02,  1.22it/s]Loading train:  17%|█▋        | 91/532 [01:22<06:03,  1.21it/s]Loading train:  17%|█▋        | 92/532 [01:23<06:11,  1.18it/s]Loading train:  17%|█▋        | 93/532 [01:24<06:12,  1.18it/s]Loading train:  18%|█▊        | 94/532 [01:25<06:12,  1.18it/s]Loading train:  18%|█▊        | 95/532 [01:26<06:38,  1.10it/s]Loading train:  18%|█▊        | 96/532 [01:27<06:46,  1.07it/s]Loading train:  18%|█▊        | 97/532 [01:28<06:57,  1.04it/s]Loading train:  18%|█▊        | 98/532 [01:29<07:04,  1.02it/s]Loading train:  19%|█▊        | 99/532 [01:30<07:09,  1.01it/s]Loading train:  19%|█▉        | 100/532 [01:31<07:21,  1.02s/it]Loading train:  19%|█▉        | 101/532 [01:32<06:52,  1.05it/s]Loading train:  19%|█▉        | 102/532 [01:33<06:34,  1.09it/s]Loading train:  19%|█▉        | 103/532 [01:33<06:07,  1.17it/s]Loading train:  20%|█▉        | 104/532 [01:34<05:55,  1.20it/s]Loading train:  20%|█▉        | 105/532 [01:35<05:45,  1.24it/s]Loading train:  20%|█▉        | 106/532 [01:36<05:44,  1.23it/s]Loading train:  20%|██        | 107/532 [01:37<05:47,  1.22it/s]Loading train:  20%|██        | 108/532 [01:37<05:40,  1.25it/s]Loading train:  20%|██        | 109/532 [01:38<05:29,  1.28it/s]Loading train:  21%|██        | 110/532 [01:39<05:17,  1.33it/s]Loading train:  21%|██        | 111/532 [01:39<05:10,  1.36it/s]Loading train:  21%|██        | 112/532 [01:40<05:04,  1.38it/s]Loading train:  21%|██        | 113/532 [01:41<05:29,  1.27it/s]Loading train:  21%|██▏       | 114/532 [01:42<05:49,  1.19it/s]Loading train:  22%|██▏       | 115/532 [01:43<05:53,  1.18it/s]Loading train:  22%|██▏       | 116/532 [01:44<05:50,  1.19it/s]Loading train:  22%|██▏       | 117/532 [01:45<05:56,  1.16it/s]Loading train:  22%|██▏       | 118/532 [01:46<06:12,  1.11it/s]Loading train:  22%|██▏       | 119/532 [01:47<06:22,  1.08it/s]Loading train:  23%|██▎       | 120/532 [01:48<06:25,  1.07it/s]Loading train:  23%|██▎       | 121/532 [01:49<06:28,  1.06it/s]Loading train:  23%|██▎       | 122/532 [01:50<06:33,  1.04it/s]Loading train:  23%|██▎       | 123/532 [01:51<06:33,  1.04it/s]Loading train:  23%|██▎       | 124/532 [01:51<06:27,  1.05it/s]Loading train:  23%|██▎       | 125/532 [01:52<06:29,  1.04it/s]Loading train:  24%|██▎       | 126/532 [01:53<06:17,  1.07it/s]Loading train:  24%|██▍       | 127/532 [01:54<06:07,  1.10it/s]Loading train:  24%|██▍       | 128/532 [01:55<06:01,  1.12it/s]Loading train:  24%|██▍       | 129/532 [01:56<05:55,  1.13it/s]Loading train:  24%|██▍       | 130/532 [01:57<05:53,  1.14it/s]Loading train:  25%|██▍       | 131/532 [01:58<06:19,  1.06it/s]Loading train:  25%|██▍       | 132/532 [01:59<06:34,  1.01it/s]Loading train:  25%|██▌       | 133/532 [02:00<06:51,  1.03s/it]Loading train:  25%|██▌       | 134/532 [02:01<06:58,  1.05s/it]Loading train:  25%|██▌       | 135/532 [02:02<07:10,  1.09s/it]Loading train:  26%|██▌       | 136/532 [02:03<07:15,  1.10s/it]Loading train:  26%|██▌       | 137/532 [02:05<07:18,  1.11s/it]Loading train:  26%|██▌       | 138/532 [02:06<07:25,  1.13s/it]Loading train:  26%|██▌       | 139/532 [02:07<07:36,  1.16s/it]Loading train:  26%|██▋       | 140/532 [02:08<07:59,  1.22s/it]Loading train:  27%|██▋       | 141/532 [02:10<07:52,  1.21s/it]Loading train:  27%|██▋       | 142/532 [02:11<07:50,  1.21s/it]Loading train:  27%|██▋       | 143/532 [02:12<07:13,  1.11s/it]Loading train:  27%|██▋       | 144/532 [02:13<06:42,  1.04s/it]Loading train:  27%|██▋       | 145/532 [02:13<06:28,  1.00s/it]Loading train:  27%|██▋       | 146/532 [02:15<06:51,  1.07s/it]Loading train:  28%|██▊       | 147/532 [02:15<06:18,  1.02it/s]Loading train:  28%|██▊       | 148/532 [02:16<05:51,  1.09it/s]Loading train:  28%|██▊       | 149/532 [02:17<05:34,  1.15it/s]Loading train:  28%|██▊       | 150/532 [02:18<05:19,  1.20it/s]Loading train:  28%|██▊       | 151/532 [02:19<05:13,  1.21it/s]Loading train:  29%|██▊       | 152/532 [02:19<05:12,  1.22it/s]Loading train:  29%|██▉       | 153/532 [02:20<05:14,  1.20it/s]Loading train:  29%|██▉       | 154/532 [02:21<05:45,  1.09it/s]Loading train:  29%|██▉       | 155/532 [02:22<06:13,  1.01it/s]Loading train:  29%|██▉       | 156/532 [02:24<06:45,  1.08s/it]Loading train:  30%|██▉       | 157/532 [02:25<07:17,  1.17s/it]Loading train:  30%|██▉       | 158/532 [02:26<07:22,  1.18s/it]Loading train:  30%|██▉       | 159/532 [02:28<07:22,  1.19s/it]Loading train:  30%|███       | 160/532 [02:29<07:33,  1.22s/it]Loading train:  30%|███       | 161/532 [02:30<06:57,  1.12s/it]Loading train:  30%|███       | 162/532 [02:31<06:30,  1.05s/it]Loading train:  31%|███       | 163/532 [02:32<06:11,  1.01s/it]Loading train:  31%|███       | 164/532 [02:32<05:56,  1.03it/s]Loading train:  31%|███       | 165/532 [02:33<05:55,  1.03it/s]Loading train:  31%|███       | 166/532 [02:34<05:42,  1.07it/s]Loading train:  31%|███▏      | 167/532 [02:35<05:43,  1.06it/s]Loading train:  32%|███▏      | 168/532 [02:36<05:45,  1.05it/s]Loading train:  32%|███▏      | 169/532 [02:37<05:44,  1.05it/s]Loading train:  32%|███▏      | 170/532 [02:38<05:42,  1.06it/s]Loading train:  32%|███▏      | 171/532 [02:39<05:46,  1.04it/s]Loading train:  32%|███▏      | 172/532 [02:40<05:47,  1.04it/s]Loading train:  33%|███▎      | 173/532 [02:41<05:42,  1.05it/s]Loading train:  33%|███▎      | 174/532 [02:42<05:34,  1.07it/s]Loading train:  33%|███▎      | 175/532 [02:43<05:35,  1.06it/s]Loading train:  33%|███▎      | 176/532 [02:44<05:28,  1.08it/s]Loading train:  33%|███▎      | 177/532 [02:45<05:25,  1.09it/s]Loading train:  33%|███▎      | 178/532 [02:45<05:15,  1.12it/s]Loading train:  34%|███▎      | 179/532 [02:46<05:11,  1.13it/s]Loading train:  34%|███▍      | 180/532 [02:47<05:05,  1.15it/s]Loading train:  34%|███▍      | 181/532 [02:48<05:18,  1.10it/s]Loading train:  34%|███▍      | 182/532 [02:49<05:21,  1.09it/s]Loading train:  34%|███▍      | 183/532 [02:50<05:18,  1.10it/s]Loading train:  35%|███▍      | 184/532 [02:51<05:14,  1.11it/s]Loading train:  35%|███▍      | 185/532 [02:52<05:07,  1.13it/s]Loading train:  35%|███▍      | 186/532 [02:53<05:07,  1.12it/s]Loading train:  35%|███▌      | 187/532 [02:53<05:02,  1.14it/s]Loading train:  35%|███▌      | 188/532 [02:54<04:55,  1.16it/s]Loading train:  36%|███▌      | 189/532 [02:55<04:50,  1.18it/s]Loading train:  36%|███▌      | 190/532 [02:56<04:55,  1.16it/s]Loading train:  36%|███▌      | 191/532 [02:57<05:30,  1.03it/s]Loading train:  36%|███▌      | 192/532 [02:58<05:52,  1.04s/it]Loading train:  36%|███▋      | 193/532 [03:00<06:15,  1.11s/it]Loading train:  36%|███▋      | 194/532 [03:01<06:30,  1.16s/it]Loading train:  37%|███▋      | 195/532 [03:02<06:44,  1.20s/it]Loading train:  37%|███▋      | 196/532 [03:03<06:44,  1.20s/it]Loading train:  37%|███▋      | 197/532 [03:05<06:37,  1.19s/it]Loading train:  37%|███▋      | 198/532 [03:06<06:27,  1.16s/it]Loading train:  37%|███▋      | 199/532 [03:07<06:12,  1.12s/it]Loading train:  38%|███▊      | 200/532 [03:08<05:57,  1.08s/it]Loading train:  38%|███▊      | 201/532 [03:09<05:52,  1.07s/it]Loading train:  38%|███▊      | 202/532 [03:10<05:51,  1.07s/it]Loading train:  38%|███▊      | 203/532 [03:11<05:35,  1.02s/it]Loading train:  38%|███▊      | 204/532 [03:12<05:23,  1.01it/s]Loading train:  39%|███▊      | 205/532 [03:12<05:07,  1.06it/s]Loading train:  39%|███▊      | 206/532 [03:13<04:53,  1.11it/s]Loading train:  39%|███▉      | 207/532 [03:14<04:49,  1.12it/s]Loading train:  39%|███▉      | 208/532 [03:15<04:41,  1.15it/s]Loading train:  39%|███▉      | 209/532 [03:16<04:32,  1.19it/s]Loading train:  39%|███▉      | 210/532 [03:17<04:30,  1.19it/s]Loading train:  40%|███▉      | 211/532 [03:17<04:23,  1.22it/s]Loading train:  40%|███▉      | 212/532 [03:18<04:24,  1.21it/s]Loading train:  40%|████      | 213/532 [03:19<04:17,  1.24it/s]Loading train:  40%|████      | 214/532 [03:20<04:18,  1.23it/s]Loading train:  40%|████      | 215/532 [03:21<04:55,  1.07it/s]Loading train:  41%|████      | 216/532 [03:22<05:16,  1.00s/it]Loading train:  41%|████      | 217/532 [03:23<05:32,  1.06s/it]Loading train:  41%|████      | 218/532 [03:24<05:41,  1.09s/it]Loading train:  41%|████      | 219/532 [03:26<05:53,  1.13s/it]Loading train:  41%|████▏     | 220/532 [03:27<05:52,  1.13s/it]Loading train:  42%|████▏     | 221/532 [03:28<05:22,  1.04s/it]Loading train:  42%|████▏     | 222/532 [03:28<04:55,  1.05it/s]Loading train:  42%|████▏     | 223/532 [03:29<04:36,  1.12it/s]Loading train:  42%|████▏     | 224/532 [03:30<04:32,  1.13it/s]Loading train:  42%|████▏     | 225/532 [03:31<04:26,  1.15it/s]Loading train:  42%|████▏     | 226/532 [03:32<04:19,  1.18it/s]Loading train:  43%|████▎     | 227/532 [03:32<04:13,  1.20it/s]Loading train:  43%|████▎     | 228/532 [03:33<04:18,  1.18it/s]Loading train:  43%|████▎     | 229/532 [03:34<04:08,  1.22it/s]Loading train:  43%|████▎     | 230/532 [03:35<03:57,  1.27it/s]Loading train:  43%|████▎     | 231/532 [03:36<03:52,  1.29it/s]Loading train:  44%|████▎     | 232/532 [03:36<03:49,  1.31it/s]Loading train:  44%|████▍     | 233/532 [03:37<03:57,  1.26it/s]Loading train:  44%|████▍     | 234/532 [03:38<04:04,  1.22it/s]Loading train:  44%|████▍     | 235/532 [03:39<04:10,  1.18it/s]Loading train:  44%|████▍     | 236/532 [03:40<04:04,  1.21it/s]Loading train:  45%|████▍     | 237/532 [03:40<03:59,  1.23it/s]Loading train:  45%|████▍     | 238/532 [03:41<04:00,  1.22it/s]Loading train:  45%|████▍     | 239/532 [03:42<04:17,  1.14it/s]Loading train:  45%|████▌     | 240/532 [03:43<04:16,  1.14it/s]Loading train:  45%|████▌     | 241/532 [03:44<04:16,  1.14it/s]Loading train:  45%|████▌     | 242/532 [03:45<04:08,  1.17it/s]Loading train:  46%|████▌     | 243/532 [03:46<04:08,  1.16it/s]Loading train:  46%|████▌     | 244/532 [03:47<04:04,  1.18it/s]Loading train:  46%|████▌     | 245/532 [03:47<03:54,  1.22it/s]Loading train:  46%|████▌     | 246/532 [03:48<03:50,  1.24it/s]Loading train:  46%|████▋     | 247/532 [03:49<03:55,  1.21it/s]Loading train:  47%|████▋     | 248/532 [03:50<03:47,  1.25it/s]Loading train:  47%|████▋     | 249/532 [03:51<03:45,  1.26it/s]Loading train:  47%|████▋     | 250/532 [03:51<03:35,  1.31it/s]Loading train:  47%|████▋     | 251/532 [03:52<03:37,  1.29it/s]Loading train:  47%|████▋     | 252/532 [03:53<03:44,  1.25it/s]Loading train:  48%|████▊     | 253/532 [03:54<03:51,  1.21it/s]Loading train:  48%|████▊     | 254/532 [03:55<03:49,  1.21it/s]Loading train:  48%|████▊     | 255/532 [03:55<03:51,  1.20it/s]Loading train:  48%|████▊     | 256/532 [03:56<03:53,  1.18it/s]Loading train:  48%|████▊     | 257/532 [03:57<04:10,  1.10it/s]Loading train:  48%|████▊     | 258/532 [03:58<04:19,  1.05it/s]Loading train:  49%|████▊     | 259/532 [03:59<04:23,  1.03it/s]Loading train:  49%|████▉     | 260/532 [04:00<04:23,  1.03it/s]Loading train:  49%|████▉     | 261/532 [04:01<04:23,  1.03it/s]Loading train:  49%|████▉     | 262/532 [04:02<04:24,  1.02it/s]Loading train:  49%|████▉     | 263/532 [04:03<04:11,  1.07it/s]Loading train:  50%|████▉     | 264/532 [04:04<03:55,  1.14it/s]Loading train:  50%|████▉     | 265/532 [04:05<03:41,  1.20it/s]Loading train:  50%|█████     | 266/532 [04:05<03:35,  1.24it/s]Loading train:  50%|█████     | 267/532 [04:06<03:23,  1.30it/s]Loading train:  50%|█████     | 268/532 [04:07<03:21,  1.31it/s]Loading train:  51%|█████     | 269/532 [04:08<03:32,  1.24it/s]Loading train:  51%|█████     | 270/532 [04:09<03:41,  1.18it/s]Loading train:  51%|█████     | 271/532 [04:10<03:51,  1.13it/s]Loading train:  51%|█████     | 272/532 [04:11<03:48,  1.14it/s]Loading train:  51%|█████▏    | 273/532 [04:11<03:42,  1.16it/s]Loading train:  52%|█████▏    | 274/532 [04:12<03:55,  1.10it/s]Loading train:  52%|█████▏    | 275/532 [04:13<04:05,  1.05it/s]Loading train:  52%|█████▏    | 276/532 [04:14<04:10,  1.02it/s]Loading train:  52%|█████▏    | 277/532 [04:16<04:18,  1.02s/it]Loading train:  52%|█████▏    | 278/532 [04:17<04:25,  1.04s/it]Loading train:  52%|█████▏    | 279/532 [04:18<04:24,  1.04s/it]Loading train:  53%|█████▎    | 280/532 [04:19<04:25,  1.05s/it]Loading train:  53%|█████▎    | 281/532 [04:20<04:27,  1.06s/it]Loading train:  53%|█████▎    | 282/532 [04:21<04:19,  1.04s/it]Loading train:  53%|█████▎    | 283/532 [04:22<04:17,  1.03s/it]Loading train:  53%|█████▎    | 284/532 [04:23<04:13,  1.02s/it]Loading train:  54%|█████▎    | 285/532 [04:24<04:11,  1.02s/it]Loading train:  54%|█████▍    | 286/532 [04:25<04:16,  1.04s/it]Loading train:  54%|█████▍    | 287/532 [04:26<04:07,  1.01s/it]Loading train:  54%|█████▍    | 288/532 [04:27<03:57,  1.03it/s]Loading train:  54%|█████▍    | 289/532 [04:28<03:41,  1.09it/s]Loading train:  55%|█████▍    | 290/532 [04:28<03:33,  1.13it/s]Loading train:  55%|█████▍    | 291/532 [04:29<03:28,  1.16it/s]Loading train:  55%|█████▍    | 292/532 [04:30<03:33,  1.12it/s]Loading train:  55%|█████▌    | 293/532 [04:31<03:32,  1.13it/s]Loading train:  55%|█████▌    | 294/532 [04:32<03:37,  1.09it/s]Loading train:  55%|█████▌    | 295/532 [04:33<03:41,  1.07it/s]Loading train:  56%|█████▌    | 296/532 [04:34<03:37,  1.08it/s]Loading train:  56%|█████▌    | 297/532 [04:35<03:39,  1.07it/s]Loading train:  56%|█████▌    | 298/532 [04:36<03:37,  1.08it/s]Loading train:  56%|█████▌    | 299/532 [04:37<03:24,  1.14it/s]Loading train:  56%|█████▋    | 300/532 [04:37<03:14,  1.19it/s]Loading train:  57%|█████▋    | 301/532 [04:38<03:06,  1.24it/s]Loading train:  57%|█████▋    | 302/532 [04:39<02:59,  1.28it/s]Loading train:  57%|█████▋    | 303/532 [04:39<02:52,  1.33it/s]Loading train:  57%|█████▋    | 304/532 [04:40<02:54,  1.31it/s]Loading train:  57%|█████▋    | 305/532 [04:41<03:18,  1.14it/s]Loading train:  58%|█████▊    | 306/532 [04:42<03:30,  1.07it/s]Loading train:  58%|█████▊    | 307/532 [04:43<03:38,  1.03it/s]Loading train:  58%|█████▊    | 308/532 [04:45<03:45,  1.01s/it]Loading train:  58%|█████▊    | 309/532 [04:46<03:51,  1.04s/it]Loading train:  58%|█████▊    | 310/532 [04:47<04:00,  1.09s/it]Loading train:  58%|█████▊    | 311/532 [04:48<04:32,  1.23s/it]Loading train:  59%|█████▊    | 312/532 [04:50<04:47,  1.31s/it]Loading train:  59%|█████▉    | 313/532 [04:51<04:52,  1.34s/it]Loading train:  59%|█████▉    | 314/532 [04:53<04:58,  1.37s/it]Loading train:  59%|█████▉    | 315/532 [04:54<05:00,  1.38s/it]Loading train:  59%|█████▉    | 316/532 [04:56<04:59,  1.39s/it]Loading train:  60%|█████▉    | 317/532 [04:56<04:22,  1.22s/it]Loading train:  60%|█████▉    | 318/532 [04:57<03:55,  1.10s/it]Loading train:  60%|█████▉    | 319/532 [04:58<03:39,  1.03s/it]Loading train:  60%|██████    | 320/532 [04:59<03:27,  1.02it/s]Loading train:  60%|██████    | 321/532 [05:00<03:16,  1.07it/s]Loading train:  61%|██████    | 322/532 [05:01<03:05,  1.13it/s]Loading train:  61%|██████    | 323/532 [05:02<03:28,  1.00it/s]Loading train:  61%|██████    | 324/532 [05:03<03:33,  1.03s/it]Loading train:  61%|██████    | 325/532 [05:04<03:52,  1.12s/it]Loading train:  61%|██████▏   | 326/532 [05:05<03:50,  1.12s/it]Loading train:  61%|██████▏   | 327/532 [05:07<03:51,  1.13s/it]Loading train:  62%|██████▏   | 328/532 [05:08<03:49,  1.12s/it]Loading train:  62%|██████▏   | 329/532 [05:08<03:30,  1.04s/it]Loading train:  62%|██████▏   | 330/532 [05:09<03:15,  1.04it/s]Loading train:  62%|██████▏   | 331/532 [05:10<03:05,  1.08it/s]Loading train:  62%|██████▏   | 332/532 [05:11<03:08,  1.06it/s]Loading train:  63%|██████▎   | 333/532 [05:12<02:58,  1.11it/s]Loading train:  63%|██████▎   | 334/532 [05:13<02:57,  1.11it/s]Loading train:  63%|██████▎   | 335/532 [05:14<03:04,  1.07it/s]Loading train:  63%|██████▎   | 336/532 [05:15<03:12,  1.02it/s]Loading train:  63%|██████▎   | 337/532 [05:16<03:14,  1.00it/s]Loading train:  64%|██████▎   | 338/532 [05:17<03:13,  1.00it/s]Loading train:  64%|██████▎   | 339/532 [05:18<03:10,  1.01it/s]Loading train:  64%|██████▍   | 340/532 [05:19<03:10,  1.01it/s]Loading train:  64%|██████▍   | 341/532 [05:20<02:56,  1.08it/s]Loading train:  64%|██████▍   | 342/532 [05:20<02:47,  1.13it/s]Loading train:  64%|██████▍   | 343/532 [05:21<02:40,  1.18it/s]Loading train:  65%|██████▍   | 344/532 [05:22<02:32,  1.23it/s]Loading train:  65%|██████▍   | 345/532 [05:23<02:27,  1.27it/s]Loading train:  65%|██████▌   | 346/532 [05:23<02:24,  1.29it/s]Loading train:  65%|██████▌   | 347/532 [05:24<02:29,  1.24it/s]Loading train:  65%|██████▌   | 348/532 [05:25<02:31,  1.21it/s]Loading train:  66%|██████▌   | 349/532 [05:26<02:33,  1.19it/s]Loading train:  66%|██████▌   | 350/532 [05:27<02:30,  1.21it/s]Loading train:  66%|██████▌   | 351/532 [05:28<02:33,  1.18it/s]Loading train:  66%|██████▌   | 352/532 [05:29<02:30,  1.20it/s]Loading train:  66%|██████▋   | 353/532 [05:29<02:34,  1.16it/s]Loading train:  67%|██████▋   | 354/532 [05:30<02:31,  1.18it/s]Loading train:  67%|██████▋   | 355/532 [05:31<02:27,  1.20it/s]Loading train:  67%|██████▋   | 356/532 [05:32<02:23,  1.22it/s]Loading train:  67%|██████▋   | 357/532 [05:33<02:21,  1.23it/s]Loading train:  67%|██████▋   | 358/532 [05:34<02:23,  1.21it/s]Loading train:  67%|██████▋   | 359/532 [05:34<02:22,  1.21it/s]Loading train:  68%|██████▊   | 360/532 [05:35<02:19,  1.23it/s]Loading train:  68%|██████▊   | 361/532 [05:36<02:16,  1.25it/s]Loading train:  68%|██████▊   | 362/532 [05:37<02:15,  1.26it/s]Loading train:  68%|██████▊   | 363/532 [05:37<02:13,  1.27it/s]Loading train:  68%|██████▊   | 364/532 [05:38<02:15,  1.24it/s]Loading train:  69%|██████▊   | 365/532 [05:39<02:10,  1.28it/s]Loading train:  69%|██████▉   | 366/532 [05:40<02:11,  1.26it/s]Loading train:  69%|██████▉   | 367/532 [05:41<02:11,  1.26it/s]Loading train:  69%|██████▉   | 368/532 [05:41<02:09,  1.27it/s]Loading train:  69%|██████▉   | 369/532 [05:42<02:05,  1.30it/s]Loading train:  70%|██████▉   | 370/532 [05:43<02:04,  1.30it/s]Loading train:  70%|██████▉   | 371/532 [05:44<02:19,  1.16it/s]Loading train:  70%|██████▉   | 372/532 [05:45<02:27,  1.09it/s]Loading train:  70%|███████   | 373/532 [05:46<02:31,  1.05it/s]Loading train:  70%|███████   | 374/532 [05:47<02:42,  1.03s/it]Loading train:  70%|███████   | 375/532 [05:48<02:42,  1.04s/it]Loading train:  71%|███████   | 376/532 [05:49<02:43,  1.04s/it]Loading train:  71%|███████   | 377/532 [05:50<02:36,  1.01s/it]Loading train:  71%|███████   | 378/532 [05:51<02:33,  1.00it/s]Loading train:  71%|███████   | 379/532 [05:52<02:27,  1.04it/s]Loading train:  71%|███████▏  | 380/532 [05:53<02:19,  1.09it/s]Loading train:  72%|███████▏  | 381/532 [05:54<02:16,  1.10it/s]Loading train:  72%|███████▏  | 382/532 [05:55<02:13,  1.13it/s]Loading train:  72%|███████▏  | 383/532 [05:56<02:12,  1.12it/s]Loading train:  72%|███████▏  | 384/532 [05:56<02:08,  1.15it/s]Loading train:  72%|███████▏  | 385/532 [05:57<02:05,  1.18it/s]Loading train:  73%|███████▎  | 386/532 [05:58<02:04,  1.17it/s]Loading train:  73%|███████▎  | 387/532 [05:59<02:01,  1.19it/s]Loading train:  73%|███████▎  | 388/532 [06:00<02:00,  1.19it/s]Loading train:  73%|███████▎  | 389/532 [06:01<02:03,  1.15it/s]Loading train:  73%|███████▎  | 390/532 [06:02<02:08,  1.11it/s]Loading train:  73%|███████▎  | 391/532 [06:03<02:08,  1.10it/s]Loading train:  74%|███████▎  | 392/532 [06:04<02:08,  1.09it/s]Loading train:  74%|███████▍  | 393/532 [06:05<02:11,  1.06it/s]Loading train:  74%|███████▍  | 394/532 [06:06<02:12,  1.04it/s]Loading train:  74%|███████▍  | 395/532 [06:06<02:09,  1.06it/s]Loading train:  74%|███████▍  | 396/532 [06:07<02:06,  1.08it/s]Loading train:  75%|███████▍  | 397/532 [06:08<02:04,  1.09it/s]Loading train:  75%|███████▍  | 398/532 [06:09<02:01,  1.11it/s]Loading train:  75%|███████▌  | 399/532 [06:10<01:59,  1.11it/s]Loading train:  75%|███████▌  | 400/532 [06:11<01:59,  1.10it/s]Loading train:  75%|███████▌  | 401/532 [06:12<02:05,  1.05it/s]Loading train:  76%|███████▌  | 402/532 [06:13<02:03,  1.05it/s]Loading train:  76%|███████▌  | 403/532 [06:14<02:05,  1.03it/s]Loading train:  76%|███████▌  | 404/532 [06:15<02:04,  1.03it/s]Loading train:  76%|███████▌  | 405/532 [06:16<02:04,  1.02it/s]Loading train:  76%|███████▋  | 406/532 [06:17<02:01,  1.04it/s]Loading train:  77%|███████▋  | 407/532 [06:18<01:54,  1.09it/s]Loading train:  77%|███████▋  | 408/532 [06:18<01:48,  1.14it/s]Loading train:  77%|███████▋  | 409/532 [06:19<01:45,  1.17it/s]Loading train:  77%|███████▋  | 410/532 [06:20<01:42,  1.19it/s]Loading train:  77%|███████▋  | 411/532 [06:21<01:41,  1.19it/s]Loading train:  77%|███████▋  | 412/532 [06:22<01:39,  1.21it/s]Loading train:  78%|███████▊  | 413/532 [06:23<01:40,  1.18it/s]Loading train:  78%|███████▊  | 414/532 [06:24<01:42,  1.15it/s]Loading train:  78%|███████▊  | 415/532 [06:24<01:41,  1.15it/s]Loading train:  78%|███████▊  | 416/532 [06:25<01:39,  1.17it/s]Loading train:  78%|███████▊  | 417/532 [06:26<01:37,  1.18it/s]Loading train:  79%|███████▊  | 418/532 [06:27<01:36,  1.19it/s]Loading train:  79%|███████▉  | 419/532 [06:28<01:36,  1.17it/s]Loading train:  79%|███████▉  | 420/532 [06:29<01:40,  1.12it/s]Loading train:  79%|███████▉  | 421/532 [06:30<01:40,  1.10it/s]Loading train:  79%|███████▉  | 422/532 [06:31<01:40,  1.10it/s]Loading train:  80%|███████▉  | 423/532 [06:32<01:39,  1.09it/s]Loading train:  80%|███████▉  | 424/532 [06:32<01:38,  1.10it/s]Loading train:  80%|███████▉  | 425/532 [06:33<01:36,  1.11it/s]Loading train:  80%|████████  | 426/532 [06:34<01:36,  1.10it/s]Loading train:  80%|████████  | 427/532 [06:35<01:35,  1.10it/s]Loading train:  80%|████████  | 428/532 [06:36<01:33,  1.11it/s]Loading train:  81%|████████  | 429/532 [06:37<01:36,  1.07it/s]Loading train:  81%|████████  | 430/532 [06:38<01:35,  1.06it/s]Loading train:  81%|████████  | 431/532 [06:39<01:37,  1.04it/s]Loading train:  81%|████████  | 432/532 [06:40<01:36,  1.04it/s]Loading train:  81%|████████▏ | 433/532 [06:41<01:35,  1.03it/s]Loading train:  82%|████████▏ | 434/532 [06:42<01:36,  1.01it/s]Loading train:  82%|████████▏ | 435/532 [06:43<01:36,  1.01it/s]Loading train:  82%|████████▏ | 436/532 [06:44<01:35,  1.01it/s]Loading train:  82%|████████▏ | 437/532 [06:45<01:27,  1.09it/s]Loading train:  82%|████████▏ | 438/532 [06:45<01:22,  1.14it/s]Loading train:  83%|████████▎ | 439/532 [06:46<01:18,  1.18it/s]Loading train:  83%|████████▎ | 440/532 [06:47<01:15,  1.22it/s]Loading train:  83%|████████▎ | 441/532 [06:48<01:12,  1.26it/s]Loading train:  83%|████████▎ | 442/532 [06:49<01:10,  1.28it/s]Loading train:  83%|████████▎ | 443/532 [06:49<01:07,  1.32it/s]Loading train:  83%|████████▎ | 444/532 [06:50<01:07,  1.30it/s]Loading train:  84%|████████▎ | 445/532 [06:51<01:05,  1.32it/s]Loading train:  84%|████████▍ | 446/532 [06:52<01:05,  1.32it/s]Loading train:  84%|████████▍ | 447/532 [06:52<01:02,  1.35it/s]Loading train:  84%|████████▍ | 448/532 [06:53<00:59,  1.40it/s]Loading train:  84%|████████▍ | 449/532 [06:54<01:00,  1.38it/s]Loading train:  85%|████████▍ | 450/532 [06:54<01:00,  1.35it/s]Loading train:  85%|████████▍ | 451/532 [06:55<01:01,  1.32it/s]Loading train:  85%|████████▍ | 452/532 [06:56<01:03,  1.26it/s]Loading train:  85%|████████▌ | 453/532 [06:57<01:02,  1.25it/s]Loading train:  85%|████████▌ | 454/532 [06:58<01:01,  1.27it/s]Loading train:  86%|████████▌ | 455/532 [06:58<01:02,  1.23it/s]Loading train:  86%|████████▌ | 456/532 [06:59<01:04,  1.18it/s]Loading train:  86%|████████▌ | 457/532 [07:00<01:04,  1.16it/s]Loading train:  86%|████████▌ | 458/532 [07:01<01:04,  1.14it/s]Loading train:  86%|████████▋ | 459/532 [07:02<01:05,  1.12it/s]Loading train:  86%|████████▋ | 460/532 [07:03<01:04,  1.12it/s]Loading train:  87%|████████▋ | 461/532 [07:04<01:08,  1.04it/s]Loading train:  87%|████████▋ | 462/532 [07:05<01:09,  1.01it/s]Loading train:  87%|████████▋ | 463/532 [07:06<01:10,  1.02s/it]Loading train:  87%|████████▋ | 464/532 [07:07<01:10,  1.04s/it]Loading train:  87%|████████▋ | 465/532 [07:09<01:11,  1.07s/it]Loading train:  88%|████████▊ | 466/532 [07:10<01:12,  1.10s/it]Loading train:  88%|████████▊ | 467/532 [07:11<01:09,  1.06s/it]Loading train:  88%|████████▊ | 468/532 [07:12<01:04,  1.01s/it]Loading train:  88%|████████▊ | 469/532 [07:13<01:02,  1.01it/s]Loading train:  88%|████████▊ | 470/532 [07:13<01:00,  1.03it/s]Loading train:  89%|████████▊ | 471/532 [07:14<00:57,  1.06it/s]Loading train:  89%|████████▊ | 472/532 [07:15<00:56,  1.06it/s]Loading train:  89%|████████▉ | 473/532 [07:16<00:59,  1.00s/it]Loading train:  89%|████████▉ | 474/532 [07:17<00:58,  1.00s/it]Loading train:  89%|████████▉ | 475/532 [07:18<00:54,  1.04it/s]Loading train:  89%|████████▉ | 476/532 [07:19<00:53,  1.05it/s]Loading train:  90%|████████▉ | 477/532 [07:20<00:52,  1.04it/s]Loading train:  90%|████████▉ | 478/532 [07:21<00:52,  1.03it/s]Loading train:  90%|█████████ | 479/532 [07:22<00:49,  1.07it/s]Loading train:  90%|█████████ | 480/532 [07:23<00:47,  1.10it/s]Loading train:  90%|█████████ | 481/532 [07:24<00:44,  1.13it/s]Loading train:  91%|█████████ | 482/532 [07:24<00:42,  1.19it/s]Loading train:  91%|█████████ | 483/532 [07:25<00:39,  1.23it/s]Loading train:  91%|█████████ | 484/532 [07:26<00:39,  1.22it/s]Loading train:  91%|█████████ | 485/532 [07:27<00:42,  1.12it/s]Loading train:  91%|█████████▏| 486/532 [07:28<00:43,  1.06it/s]Loading train:  92%|█████████▏| 487/532 [07:29<00:44,  1.02it/s]Loading train:  92%|█████████▏| 488/532 [07:30<00:44,  1.01s/it]Loading train:  92%|█████████▏| 489/532 [07:31<00:44,  1.04s/it]Loading train:  92%|█████████▏| 490/532 [07:33<00:45,  1.09s/it]Loading train:  92%|█████████▏| 491/532 [07:34<00:43,  1.06s/it]Loading train:  92%|█████████▏| 492/532 [07:34<00:39,  1.00it/s]Loading train:  93%|█████████▎| 493/532 [07:35<00:36,  1.05it/s]Loading train:  93%|█████████▎| 494/532 [07:36<00:34,  1.09it/s]Loading train:  93%|█████████▎| 495/532 [07:37<00:32,  1.14it/s]Loading train:  93%|█████████▎| 496/532 [07:38<00:31,  1.14it/s]Loading train:  93%|█████████▎| 497/532 [07:39<00:30,  1.14it/s]Loading train:  94%|█████████▎| 498/532 [07:40<00:30,  1.13it/s]Loading train:  94%|█████████▍| 499/532 [07:40<00:29,  1.13it/s]Loading train:  94%|█████████▍| 500/532 [07:41<00:27,  1.15it/s]Loading train:  94%|█████████▍| 501/532 [07:42<00:27,  1.13it/s]Loading train:  94%|█████████▍| 502/532 [07:43<00:26,  1.13it/s]Loading train:  95%|█████████▍| 503/532 [07:44<00:25,  1.13it/s]Loading train:  95%|█████████▍| 504/532 [07:45<00:23,  1.17it/s]Loading train:  95%|█████████▍| 505/532 [07:46<00:22,  1.20it/s]Loading train:  95%|█████████▌| 506/532 [07:46<00:21,  1.22it/s]Loading train:  95%|█████████▌| 507/532 [07:47<00:20,  1.22it/s]Loading train:  95%|█████████▌| 508/532 [07:48<00:19,  1.24it/s]Loading train:  96%|█████████▌| 509/532 [07:49<00:20,  1.15it/s]Loading train:  96%|█████████▌| 510/532 [07:50<00:20,  1.08it/s]Loading train:  96%|█████████▌| 511/532 [07:51<00:20,  1.03it/s]Loading train:  96%|█████████▌| 512/532 [07:52<00:19,  1.02it/s]Loading train:  96%|█████████▋| 513/532 [07:53<00:19,  1.02s/it]Loading train:  97%|█████████▋| 514/532 [07:54<00:18,  1.02s/it]Loading train:  97%|█████████▋| 515/532 [07:55<00:16,  1.02it/s]Loading train:  97%|█████████▋| 516/532 [07:56<00:14,  1.07it/s]Loading train:  97%|█████████▋| 517/532 [07:57<00:13,  1.08it/s]Loading train:  97%|█████████▋| 518/532 [07:58<00:12,  1.09it/s]Loading train:  98%|█████████▊| 519/532 [07:59<00:11,  1.14it/s]Loading train:  98%|█████████▊| 520/532 [07:59<00:10,  1.18it/s]Loading train:  98%|█████████▊| 521/532 [08:00<00:09,  1.16it/s]Loading train:  98%|█████████▊| 522/532 [08:01<00:08,  1.14it/s]Loading train:  98%|█████████▊| 523/532 [08:02<00:07,  1.15it/s]Loading train:  98%|█████████▊| 524/532 [08:03<00:07,  1.13it/s]Loading train:  99%|█████████▊| 525/532 [08:04<00:06,  1.14it/s]Loading train:  99%|█████████▉| 526/532 [08:05<00:05,  1.14it/s]Loading train:  99%|█████████▉| 527/532 [08:05<00:04,  1.18it/s]Loading train:  99%|█████████▉| 528/532 [08:06<00:03,  1.20it/s]Loading train:  99%|█████████▉| 529/532 [08:07<00:02,  1.19it/s]Loading train: 100%|█████████▉| 530/532 [08:08<00:01,  1.20it/s]Loading train: 100%|█████████▉| 531/532 [08:09<00:00,  1.18it/s]Loading train: 100%|██████████| 532/532 [08:10<00:00,  1.21it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 7/532 [00:00<00:07, 69.61it/s]concatenating: train:   6%|▌         | 31/532 [00:00<00:05, 87.62it/s]concatenating: train:  10%|█         | 54/532 [00:00<00:04, 107.25it/s]concatenating: train:  15%|█▌        | 81/532 [00:00<00:03, 130.64it/s]concatenating: train:  20%|██        | 108/532 [00:00<00:02, 154.53it/s]concatenating: train:  25%|██▌       | 135/532 [00:00<00:02, 176.70it/s]concatenating: train:  30%|███       | 161/532 [00:00<00:01, 194.44it/s]concatenating: train:  35%|███▌      | 187/532 [00:00<00:01, 209.86it/s]concatenating: train:  40%|███▉      | 212/532 [00:00<00:01, 219.94it/s]concatenating: train:  45%|████▍     | 238/532 [00:01<00:01, 228.92it/s]concatenating: train:  49%|████▉     | 263/532 [00:01<00:01, 227.82it/s]concatenating: train:  54%|█████▍    | 288/532 [00:01<00:01, 232.94it/s]concatenating: train:  59%|█████▉    | 314/532 [00:01<00:00, 237.48it/s]concatenating: train:  64%|██████▎   | 339/532 [00:01<00:00, 230.87it/s]concatenating: train:  68%|██████▊   | 363/532 [00:01<00:00, 231.59it/s]concatenating: train:  73%|███████▎  | 387/532 [00:01<00:00, 230.08it/s]concatenating: train:  77%|███████▋  | 411/532 [00:01<00:00, 223.52it/s]concatenating: train:  82%|████████▏ | 435/532 [00:01<00:00, 227.73it/s]concatenating: train:  87%|████████▋ | 461/532 [00:01<00:00, 235.83it/s]concatenating: train:  91%|█████████ | 485/532 [00:02<00:00, 229.11it/s]concatenating: train:  96%|█████████▌| 509/532 [00:02<00:00, 221.93it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 218.17it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:11,  1.17it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.19it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.13it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:10,  1.08it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.00it/s]Loading test:  40%|████      | 6/15 [00:06<00:09,  1.06s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:07,  1.02it/s]Loading test:  53%|█████▎    | 8/15 [00:07<00:07,  1.03s/it]Loading test:  60%|██████    | 9/15 [00:08<00:05,  1.01it/s]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.06it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.12it/s]Loading test:  80%|████████  | 12/15 [00:11<00:02,  1.08it/s]Loading test:  87%|████████▋ | 13/15 [00:12<00:01,  1.05it/s]Loading test:  93%|█████████▎| 14/15 [00:13<00:00,  1.09it/s]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 194.86it/s]
(0/4) test vimp2_ctrl_991_08302013_JF
(1/4) test vimp2_967_08132013_KW
(2/4) test vimp2_765_04162013_AW
(3/4) test vimp2_ANON695_03132013
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 42, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 28s - loss: 11.3619 - acc: 0.7927 - mDice: 0.0317 - val_loss: 3.3395 - val_acc: 0.9136 - val_mDice: 0.0736

Epoch 00001: val_mDice improved from -inf to 0.07357, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 17s - loss: 3.1214 - acc: 0.9000 - mDice: 0.1311 - val_loss: 2.2889 - val_acc: 0.9101 - val_mDice: 0.2159

Epoch 00002: val_mDice improved from 0.07357 to 0.21592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 19s - loss: 2.1776 - acc: 0.9124 - mDice: 0.2581 - val_loss: 1.6313 - val_acc: 0.9273 - val_mDice: 0.3652

Epoch 00003: val_mDice improved from 0.21592 to 0.36525, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 17s - loss: 1.7134 - acc: 0.9228 - mDice: 0.3581 - val_loss: 1.1074 - val_acc: 0.9473 - val_mDice: 0.5041

Epoch 00004: val_mDice improved from 0.36525 to 0.50411, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 1.4538 - acc: 0.9297 - mDice: 0.4271 - val_loss: 0.8709 - val_acc: 0.9559 - val_mDice: 0.5904

Epoch 00005: val_mDice improved from 0.50411 to 0.59036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 1.2841 - acc: 0.9346 - mDice: 0.4777 - val_loss: 0.7968 - val_acc: 0.9631 - val_mDice: 0.6327

Epoch 00006: val_mDice improved from 0.59036 to 0.63272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 18s - loss: 1.1720 - acc: 0.9388 - mDice: 0.5140 - val_loss: 0.7454 - val_acc: 0.9658 - val_mDice: 0.6607

Epoch 00007: val_mDice improved from 0.63272 to 0.66071, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 17s - loss: 1.0972 - acc: 0.9415 - mDice: 0.5389 - val_loss: 0.6676 - val_acc: 0.9661 - val_mDice: 0.6896

Epoch 00008: val_mDice improved from 0.66071 to 0.68964, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 1.0430 - acc: 0.9433 - mDice: 0.5576 - val_loss: 0.6546 - val_acc: 0.9677 - val_mDice: 0.6964

Epoch 00009: val_mDice improved from 0.68964 to 0.69638, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 17s - loss: 0.9984 - acc: 0.9448 - mDice: 0.5732 - val_loss: 0.6076 - val_acc: 0.9681 - val_mDice: 0.7167

Epoch 00010: val_mDice improved from 0.69638 to 0.71671, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 18s - loss: 0.9627 - acc: 0.9459 - mDice: 0.5864 - val_loss: 0.6068 - val_acc: 0.9685 - val_mDice: 0.7183

Epoch 00011: val_mDice improved from 0.71671 to 0.71826, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 0.9319 - acc: 0.9469 - mDice: 0.5974 - val_loss: 0.5917 - val_acc: 0.9714 - val_mDice: 0.7246

Epoch 00012: val_mDice improved from 0.71826 to 0.72458, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 17s - loss: 0.9085 - acc: 0.9478 - mDice: 0.6067 - val_loss: 0.5744 - val_acc: 0.9698 - val_mDice: 0.7325

Epoch 00013: val_mDice improved from 0.72458 to 0.73250, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 18s - loss: 0.8858 - acc: 0.9486 - mDice: 0.6151 - val_loss: 0.5805 - val_acc: 0.9709 - val_mDice: 0.7332

Epoch 00014: val_mDice improved from 0.73250 to 0.73323, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 17s - loss: 0.8619 - acc: 0.9494 - mDice: 0.6246 - val_loss: 0.5688 - val_acc: 0.9707 - val_mDice: 0.7395

Epoch 00015: val_mDice improved from 0.73323 to 0.73951, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 18s - loss: 0.8463 - acc: 0.9498 - mDice: 0.6305 - val_loss: 0.5597 - val_acc: 0.9704 - val_mDice: 0.7434

Epoch 00016: val_mDice improved from 0.73951 to 0.74344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 17s - loss: 0.8275 - acc: 0.9505 - mDice: 0.6386 - val_loss: 0.5516 - val_acc: 0.9713 - val_mDice: 0.7441

Epoch 00017: val_mDice improved from 0.74344 to 0.74408, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 19s - loss: 0.8142 - acc: 0.9509 - mDice: 0.6439 - val_loss: 0.5434 - val_acc: 0.9723 - val_mDice: 0.7492

Epoch 00018: val_mDice improved from 0.74408 to 0.74917, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 17s - loss: 0.7987 - acc: 0.9513 - mDice: 0.6496 - val_loss: 0.5560 - val_acc: 0.9697 - val_mDice: 0.7483

Epoch 00019: val_mDice did not improve from 0.74917
Epoch 20/300
 - 18s - loss: 0.7871 - acc: 0.9517 - mDice: 0.6545 - val_loss: 0.5563 - val_acc: 0.9712 - val_mDice: 0.7480

Epoch 00020: val_mDice did not improve from 0.74917
Epoch 21/300
 - 17s - loss: 0.7772 - acc: 0.9520 - mDice: 0.6587 - val_loss: 0.5411 - val_acc: 0.9725 - val_mDice: 0.7555

Epoch 00021: val_mDice improved from 0.74917 to 0.75554, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 18s - loss: 0.7659 - acc: 0.9523 - mDice: 0.6633 - val_loss: 0.5313 - val_acc: 0.9713 - val_mDice: 0.7581

Epoch 00022: val_mDice improved from 0.75554 to 0.75812, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 18s - loss: 0.7554 - acc: 0.9525 - mDice: 0.6671 - val_loss: 0.5426 - val_acc: 0.9720 - val_mDice: 0.7565

Epoch 00023: val_mDice did not improve from 0.75812
Epoch 24/300
 - 17s - loss: 0.7463 - acc: 0.9528 - mDice: 0.6710 - val_loss: 0.5296 - val_acc: 0.9722 - val_mDice: 0.7595

Epoch 00024: val_mDice improved from 0.75812 to 0.75954, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 19s - loss: 0.7355 - acc: 0.9531 - mDice: 0.6750 - val_loss: 0.5260 - val_acc: 0.9722 - val_mDice: 0.7630

Epoch 00025: val_mDice improved from 0.75954 to 0.76300, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 17s - loss: 0.7276 - acc: 0.9534 - mDice: 0.6782 - val_loss: 0.5130 - val_acc: 0.9721 - val_mDice: 0.7689

Epoch 00026: val_mDice improved from 0.76300 to 0.76885, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 27/300
 - 18s - loss: 0.7189 - acc: 0.9536 - mDice: 0.6820 - val_loss: 0.5054 - val_acc: 0.9718 - val_mDice: 0.7679

Epoch 00027: val_mDice did not improve from 0.76885
Epoch 28/300
 - 17s - loss: 0.7137 - acc: 0.9539 - mDice: 0.6839 - val_loss: 0.5146 - val_acc: 0.9729 - val_mDice: 0.7648

Epoch 00028: val_mDice did not improve from 0.76885
Epoch 29/300
 - 18s - loss: 0.7055 - acc: 0.9541 - mDice: 0.6873 - val_loss: 0.5149 - val_acc: 0.9714 - val_mDice: 0.7660

Epoch 00029: val_mDice did not improve from 0.76885
Epoch 30/300
 - 18s - loss: 0.7016 - acc: 0.9543 - mDice: 0.6890 - val_loss: 0.5110 - val_acc: 0.9719 - val_mDice: 0.7659

Epoch 00030: val_mDice did not improve from 0.76885
Epoch 31/300
 - 17s - loss: 0.6964 - acc: 0.9546 - mDice: 0.6913 - val_loss: 0.5019 - val_acc: 0.9736 - val_mDice: 0.7726

Epoch 00031: val_mDice improved from 0.76885 to 0.77262, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 19s - loss: 0.6902 - acc: 0.9549 - mDice: 0.6941 - val_loss: 0.5093 - val_acc: 0.9727 - val_mDice: 0.7691

Epoch 00032: val_mDice did not improve from 0.77262
Epoch 33/300
 - 17s - loss: 0.6866 - acc: 0.9551 - mDice: 0.6958 - val_loss: 0.5005 - val_acc: 0.9728 - val_mDice: 0.7728

Epoch 00033: val_mDice improved from 0.77262 to 0.77281, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 34/300
 - 20s - loss: 0.6799 - acc: 0.9553 - mDice: 0.6982 - val_loss: 0.4972 - val_acc: 0.9721 - val_mDice: 0.7727

Epoch 00034: val_mDice did not improve from 0.77281
Epoch 35/300
 - 18s - loss: 0.6770 - acc: 0.9554 - mDice: 0.6992 - val_loss: 0.5056 - val_acc: 0.9734 - val_mDice: 0.7710

Epoch 00035: val_mDice did not improve from 0.77281
Epoch 36/300
 - 17s - loss: 0.6679 - acc: 0.9557 - mDice: 0.7030 - val_loss: 0.5088 - val_acc: 0.9736 - val_mDice: 0.7704

Epoch 00036: val_mDice did not improve from 0.77281
Epoch 37/300
 - 18s - loss: 0.6643 - acc: 0.9558 - mDice: 0.7046 - val_loss: 0.4903 - val_acc: 0.9732 - val_mDice: 0.7757

Epoch 00037: val_mDice improved from 0.77281 to 0.77573, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 17s - loss: 0.6605 - acc: 0.9560 - mDice: 0.7060 - val_loss: 0.4987 - val_acc: 0.9728 - val_mDice: 0.7743

Epoch 00038: val_mDice did not improve from 0.77573
Epoch 39/300
 - 17s - loss: 0.6564 - acc: 0.9560 - mDice: 0.7076 - val_loss: 0.4946 - val_acc: 0.9739 - val_mDice: 0.7754

Epoch 00039: val_mDice did not improve from 0.77573
Epoch 40/300
 - 17s - loss: 0.6542 - acc: 0.9562 - mDice: 0.7088 - val_loss: 0.4895 - val_acc: 0.9742 - val_mDice: 0.7792

Epoch 00040: val_mDice improved from 0.77573 to 0.77918, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 41/300
 - 17s - loss: 0.6499 - acc: 0.9563 - mDice: 0.7103 - val_loss: 0.4953 - val_acc: 0.9737 - val_mDice: 0.7760

Epoch 00041: val_mDice did not improve from 0.77918
Epoch 42/300
 - 17s - loss: 0.6496 - acc: 0.9563 - mDice: 0.7105 - val_loss: 0.4856 - val_acc: 0.9732 - val_mDice: 0.7780

Epoch 00042: val_mDice did not improve from 0.77918
Epoch 43/300
 - 16s - loss: 0.6439 - acc: 0.9565 - mDice: 0.7126 - val_loss: 0.4878 - val_acc: 0.9739 - val_mDice: 0.7782

Epoch 00043: val_mDice did not improve from 0.77918
Epoch 44/300
 - 16s - loss: 0.6427 - acc: 0.9565 - mDice: 0.7129 - val_loss: 0.4829 - val_acc: 0.9738 - val_mDice: 0.7799

Epoch 00044: val_mDice improved from 0.77918 to 0.77993, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 17s - loss: 0.6388 - acc: 0.9567 - mDice: 0.7147 - val_loss: 0.4899 - val_acc: 0.9737 - val_mDice: 0.7783

Epoch 00045: val_mDice did not improve from 0.77993
Epoch 46/300
 - 16s - loss: 0.6343 - acc: 0.9568 - mDice: 0.7167 - val_loss: 0.4889 - val_acc: 0.9734 - val_mDice: 0.7797

Epoch 00046: val_mDice did not improve from 0.77993
Epoch 47/300
 - 17s - loss: 0.6319 - acc: 0.9569 - mDice: 0.7173 - val_loss: 0.4720 - val_acc: 0.9736 - val_mDice: 0.7825

Epoch 00047: val_mDice improved from 0.77993 to 0.78246, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 17s - loss: 0.6299 - acc: 0.9569 - mDice: 0.7177 - val_loss: 0.4808 - val_acc: 0.9742 - val_mDice: 0.7806

Epoch 00048: val_mDice did not improve from 0.78246
Epoch 49/300
 - 16s - loss: 0.6260 - acc: 0.9571 - mDice: 0.7196 - val_loss: 0.4799 - val_acc: 0.9744 - val_mDice: 0.7801

Epoch 00049: val_mDice did not improve from 0.78246
Epoch 50/300
 - 17s - loss: 0.6230 - acc: 0.9571 - mDice: 0.7204 - val_loss: 0.4835 - val_acc: 0.9743 - val_mDice: 0.7819

Epoch 00050: val_mDice did not improve from 0.78246
Epoch 51/300
 - 16s - loss: 0.6231 - acc: 0.9571 - mDice: 0.7204 - val_loss: 0.4790 - val_acc: 0.9738 - val_mDice: 0.7819

Epoch 00051: val_mDice did not improve from 0.78246
Epoch 52/300
 - 16s - loss: 0.6202 - acc: 0.9573 - mDice: 0.7219 - val_loss: 0.4797 - val_acc: 0.9747 - val_mDice: 0.7817

Epoch 00052: val_mDice did not improve from 0.78246
Epoch 53/300
 - 17s - loss: 0.6189 - acc: 0.9572 - mDice: 0.7222 - val_loss: 0.4738 - val_acc: 0.9740 - val_mDice: 0.7831

Epoch 00053: val_mDice improved from 0.78246 to 0.78307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 54/300
 - 16s - loss: 0.6169 - acc: 0.9574 - mDice: 0.7232 - val_loss: 0.4847 - val_acc: 0.9743 - val_mDice: 0.7795

Epoch 00054: val_mDice did not improve from 0.78307
Epoch 55/300
 - 16s - loss: 0.6156 - acc: 0.9574 - mDice: 0.7237 - val_loss: 0.4842 - val_acc: 0.9728 - val_mDice: 0.7780

Epoch 00055: val_mDice did not improve from 0.78307
Epoch 56/300
 - 16s - loss: 0.6127 - acc: 0.9574 - mDice: 0.7244 - val_loss: 0.4704 - val_acc: 0.9745 - val_mDice: 0.7823

Epoch 00056: val_mDice did not improve from 0.78307
Epoch 57/300
 - 17s - loss: 0.6106 - acc: 0.9573 - mDice: 0.7256 - val_loss: 0.4835 - val_acc: 0.9739 - val_mDice: 0.7803

Epoch 00057: val_mDice did not improve from 0.78307
Epoch 58/300
 - 16s - loss: 0.6052 - acc: 0.9572 - mDice: 0.7276 - val_loss: 0.4782 - val_acc: 0.9743 - val_mDice: 0.7810

Epoch 00058: val_mDice did not improve from 0.78307
Epoch 59/300
 - 16s - loss: 0.6061 - acc: 0.9571 - mDice: 0.7273 - val_loss: 0.4747 - val_acc: 0.9739 - val_mDice: 0.7837

Epoch 00059: val_mDice improved from 0.78307 to 0.78369, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 60/300
 - 16s - loss: 0.6040 - acc: 0.9571 - mDice: 0.7286 - val_loss: 0.4664 - val_acc: 0.9746 - val_mDice: 0.7853

Epoch 00060: val_mDice improved from 0.78369 to 0.78531, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 61/300
 - 17s - loss: 0.6037 - acc: 0.9572 - mDice: 0.7286 - val_loss: 0.4786 - val_acc: 0.9748 - val_mDice: 0.7827

Epoch 00061: val_mDice did not improve from 0.78531
Epoch 62/300
 - 17s - loss: 0.6025 - acc: 0.9571 - mDice: 0.7290 - val_loss: 0.4738 - val_acc: 0.9738 - val_mDice: 0.7822

Epoch 00062: val_mDice did not improve from 0.78531
Epoch 63/300
 - 16s - loss: 0.5983 - acc: 0.9572 - mDice: 0.7305 - val_loss: 0.4813 - val_acc: 0.9744 - val_mDice: 0.7816

Epoch 00063: val_mDice did not improve from 0.78531
Epoch 64/300
 - 16s - loss: 0.5982 - acc: 0.9572 - mDice: 0.7309 - val_loss: 0.4662 - val_acc: 0.9746 - val_mDice: 0.7846

Epoch 00064: val_mDice did not improve from 0.78531
Epoch 65/300
 - 16s - loss: 0.5967 - acc: 0.9572 - mDice: 0.7315 - val_loss: 0.4699 - val_acc: 0.9743 - val_mDice: 0.7833

Epoch 00065: val_mDice did not improve from 0.78531
Epoch 66/300
 - 17s - loss: 0.5954 - acc: 0.9572 - mDice: 0.7319 - val_loss: 0.4678 - val_acc: 0.9743 - val_mDice: 0.7842

Epoch 00066: val_mDice did not improve from 0.78531
Epoch 67/300
 - 17s - loss: 0.5942 - acc: 0.9573 - mDice: 0.7323 - val_loss: 0.4718 - val_acc: 0.9741 - val_mDice: 0.7846

Epoch 00067: val_mDice did not improve from 0.78531
Epoch 68/300
 - 16s - loss: 0.5929 - acc: 0.9574 - mDice: 0.7330 - val_loss: 0.4711 - val_acc: 0.9748 - val_mDice: 0.7841

Epoch 00068: val_mDice did not improve from 0.78531
Epoch 69/300
 - 16s - loss: 0.5916 - acc: 0.9574 - mDice: 0.7334 - val_loss: 0.4751 - val_acc: 0.9749 - val_mDice: 0.7841

Epoch 00069: val_mDice did not improve from 0.78531
Epoch 70/300
 - 16s - loss: 0.5909 - acc: 0.9574 - mDice: 0.7337 - val_loss: 0.4694 - val_acc: 0.9743 - val_mDice: 0.7847

Epoch 00070: val_mDice did not improve from 0.78531
Epoch 71/300
 - 16s - loss: 0.5891 - acc: 0.9575 - mDice: 0.7346 - val_loss: 0.4667 - val_acc: 0.9744 - val_mDice: 0.7848

Epoch 00071: val_mDice did not improve from 0.78531
Epoch 72/300
 - 16s - loss: 0.5880 - acc: 0.9573 - mDice: 0.7349 - val_loss: 0.4746 - val_acc: 0.9747 - val_mDice: 0.7830

Epoch 00072: val_mDice did not improve from 0.78531
Epoch 73/300
 - 17s - loss: 0.5888 - acc: 0.9573 - mDice: 0.7347 - val_loss: 0.4733 - val_acc: 0.9748 - val_mDice: 0.7833

Epoch 00073: val_mDice did not improve from 0.78531
Epoch 74/300
 - 17s - loss: 0.5861 - acc: 0.9575 - mDice: 0.7357 - val_loss: 0.4756 - val_acc: 0.9748 - val_mDice: 0.7830

Epoch 00074: val_mDice did not improve from 0.78531
Epoch 75/300
 - 16s - loss: 0.5864 - acc: 0.9574 - mDice: 0.7358 - val_loss: 0.4757 - val_acc: 0.9737 - val_mDice: 0.7808

Epoch 00075: val_mDice did not improve from 0.78531
Epoch 76/300
 - 16s - loss: 0.5831 - acc: 0.9574 - mDice: 0.7368 - val_loss: 0.4667 - val_acc: 0.9751 - val_mDice: 0.7864

Epoch 00076: val_mDice improved from 0.78531 to 0.78644, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 77/300
 - 16s - loss: 0.5838 - acc: 0.9574 - mDice: 0.7367 - val_loss: 0.4778 - val_acc: 0.9741 - val_mDice: 0.7820

Epoch 00077: val_mDice did not improve from 0.78644
Epoch 78/300
 - 16s - loss: 0.5824 - acc: 0.9574 - mDice: 0.7374 - val_loss: 0.4719 - val_acc: 0.9752 - val_mDice: 0.7857

Epoch 00078: val_mDice did not improve from 0.78644
Epoch 79/300
 - 16s - loss: 0.5822 - acc: 0.9574 - mDice: 0.7371 - val_loss: 0.4656 - val_acc: 0.9747 - val_mDice: 0.7848

Epoch 00079: val_mDice did not improve from 0.78644
Epoch 80/300
 - 16s - loss: 0.5803 - acc: 0.9574 - mDice: 0.7385 - val_loss: 0.4665 - val_acc: 0.9746 - val_mDice: 0.7857

Epoch 00080: val_mDice did not improve from 0.78644
Epoch 81/300
 - 17s - loss: 0.5802 - acc: 0.9574 - mDice: 0.7383 - val_loss: 0.4723 - val_acc: 0.9742 - val_mDice: 0.7845

Epoch 00081: val_mDice did not improve from 0.78644
Epoch 82/300
 - 16s - loss: 0.5788 - acc: 0.9574 - mDice: 0.7389 - val_loss: 0.4701 - val_acc: 0.9745 - val_mDice: 0.7847

Epoch 00082: val_mDice did not improve from 0.78644
Epoch 83/300
 - 16s - loss: 0.5771 - acc: 0.9574 - mDice: 0.7394 - val_loss: 0.4745 - val_acc: 0.9746 - val_mDice: 0.7821

Epoch 00083: val_mDice did not improve from 0.78644
Epoch 84/300
 - 16s - loss: 0.5756 - acc: 0.9575 - mDice: 0.7399 - val_loss: 0.4667 - val_acc: 0.9748 - val_mDice: 0.7861

Epoch 00084: val_mDice did not improve from 0.78644
Epoch 85/300
 - 16s - loss: 0.5745 - acc: 0.9575 - mDice: 0.7404 - val_loss: 0.4699 - val_acc: 0.9749 - val_mDice: 0.7877

Epoch 00085: val_mDice improved from 0.78644 to 0.78766, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 86/300
 - 16s - loss: 0.5753 - acc: 0.9575 - mDice: 0.7402 - val_loss: 0.4862 - val_acc: 0.9749 - val_mDice: 0.7809

Epoch 00086: val_mDice did not improve from 0.78766
Epoch 87/300
 - 17s - loss: 0.5772 - acc: 0.9574 - mDice: 0.7394 - val_loss: 0.4690 - val_acc: 0.9743 - val_mDice: 0.7842

Epoch 00087: val_mDice did not improve from 0.78766
Epoch 88/300
 - 17s - loss: 0.5737 - acc: 0.9574 - mDice: 0.7408 - val_loss: 0.4657 - val_acc: 0.9746 - val_mDice: 0.7873

Epoch 00088: val_mDice did not improve from 0.78766
Epoch 89/300
 - 16s - loss: 0.5742 - acc: 0.9575 - mDice: 0.7409 - val_loss: 0.4586 - val_acc: 0.9746 - val_mDice: 0.7897

Epoch 00089: val_mDice improved from 0.78766 to 0.78971, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 90/300
 - 16s - loss: 0.5715 - acc: 0.9576 - mDice: 0.7417 - val_loss: 0.4715 - val_acc: 0.9744 - val_mDice: 0.7838

Epoch 00090: val_mDice did not improve from 0.78971
Epoch 91/300
 - 16s - loss: 0.5718 - acc: 0.9575 - mDice: 0.7417 - val_loss: 0.4635 - val_acc: 0.9751 - val_mDice: 0.7880

Epoch 00091: val_mDice did not improve from 0.78971
Epoch 92/300
 - 16s - loss: 0.5708 - acc: 0.9575 - mDice: 0.7422 - val_loss: 0.4676 - val_acc: 0.9740 - val_mDice: 0.7847

Epoch 00092: val_mDice did not improve from 0.78971
Epoch 93/300
 - 16s - loss: 0.5717 - acc: 0.9574 - mDice: 0.7418 - val_loss: 0.4570 - val_acc: 0.9742 - val_mDice: 0.7893

Epoch 00093: val_mDice did not improve from 0.78971
Epoch 94/300
 - 16s - loss: 0.5705 - acc: 0.9575 - mDice: 0.7422 - val_loss: 0.4610 - val_acc: 0.9747 - val_mDice: 0.7872

Epoch 00094: val_mDice did not improve from 0.78971
Epoch 95/300
 - 17s - loss: 0.5683 - acc: 0.9576 - mDice: 0.7431 - val_loss: 0.4643 - val_acc: 0.9748 - val_mDice: 0.7879

Epoch 00095: val_mDice did not improve from 0.78971
Epoch 96/300
 - 16s - loss: 0.5686 - acc: 0.9576 - mDice: 0.7428 - val_loss: 0.4738 - val_acc: 0.9743 - val_mDice: 0.7826

Epoch 00096: val_mDice did not improve from 0.78971
Epoch 97/300
 - 16s - loss: 0.5682 - acc: 0.9575 - mDice: 0.7433 - val_loss: 0.4737 - val_acc: 0.9749 - val_mDice: 0.7859

Epoch 00097: val_mDice did not improve from 0.78971
Epoch 98/300
 - 16s - loss: 0.5679 - acc: 0.9575 - mDice: 0.7430 - val_loss: 0.4652 - val_acc: 0.9749 - val_mDice: 0.7905

Epoch 00098: val_mDice improved from 0.78971 to 0.79052, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 99/300
 - 16s - loss: 0.5672 - acc: 0.9576 - mDice: 0.7436 - val_loss: 0.4607 - val_acc: 0.9745 - val_mDice: 0.7904

Epoch 00099: val_mDice did not improve from 0.79052
Epoch 100/300
 - 16s - loss: 0.5662 - acc: 0.9576 - mDice: 0.7441 - val_loss: 0.4591 - val_acc: 0.9741 - val_mDice: 0.7891

Epoch 00100: val_mDice did not improve from 0.79052
Epoch 101/300
 - 16s - loss: 0.5658 - acc: 0.9576 - mDice: 0.7442 - val_loss: 0.4619 - val_acc: 0.9739 - val_mDice: 0.7896

Epoch 00101: val_mDice did not improve from 0.79052
Epoch 102/300
 - 17s - loss: 0.5646 - acc: 0.9576 - mDice: 0.7446 - val_loss: 0.4619 - val_acc: 0.9746 - val_mDice: 0.7907

Epoch 00102: val_mDice improved from 0.79052 to 0.79069, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 103/300
 - 16s - loss: 0.5631 - acc: 0.9577 - mDice: 0.7449 - val_loss: 0.4634 - val_acc: 0.9749 - val_mDice: 0.7902

Epoch 00103: val_mDice did not improve from 0.79069
Epoch 104/300
 - 16s - loss: 0.5620 - acc: 0.9577 - mDice: 0.7454 - val_loss: 0.4621 - val_acc: 0.9746 - val_mDice: 0.7883

Epoch 00104: val_mDice did not improve from 0.79069
Epoch 105/300
 - 16s - loss: 0.5630 - acc: 0.9576 - mDice: 0.7452 - val_loss: 0.4651 - val_acc: 0.9743 - val_mDice: 0.7886

Epoch 00105: val_mDice did not improve from 0.79069
Epoch 106/300
 - 16s - loss: 0.5627 - acc: 0.9576 - mDice: 0.7454 - val_loss: 0.4658 - val_acc: 0.9745 - val_mDice: 0.7885

Epoch 00106: val_mDice did not improve from 0.79069
Epoch 107/300
 - 16s - loss: 0.5638 - acc: 0.9576 - mDice: 0.7449 - val_loss: 0.4735 - val_acc: 0.9740 - val_mDice: 0.7844

Epoch 00107: val_mDice did not improve from 0.79069
Epoch 108/300
 - 17s - loss: 0.5623 - acc: 0.9577 - mDice: 0.7456 - val_loss: 0.4602 - val_acc: 0.9746 - val_mDice: 0.7907

Epoch 00108: val_mDice improved from 0.79069 to 0.79070, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 109/300
 - 17s - loss: 0.5622 - acc: 0.9577 - mDice: 0.7457 - val_loss: 0.4634 - val_acc: 0.9748 - val_mDice: 0.7906

Epoch 00109: val_mDice did not improve from 0.79070
Epoch 110/300
 - 16s - loss: 0.5620 - acc: 0.9577 - mDice: 0.7459 - val_loss: 0.4648 - val_acc: 0.9750 - val_mDice: 0.7897

Epoch 00110: val_mDice did not improve from 0.79070
Epoch 111/300
 - 16s - loss: 0.5621 - acc: 0.9577 - mDice: 0.7456 - val_loss: 0.4632 - val_acc: 0.9746 - val_mDice: 0.7874

Epoch 00111: val_mDice did not improve from 0.79070
Epoch 112/300
 - 16s - loss: 0.5598 - acc: 0.9577 - mDice: 0.7466 - val_loss: 0.4638 - val_acc: 0.9751 - val_mDice: 0.7882

Epoch 00112: val_mDice did not improve from 0.79070
Epoch 113/300
 - 16s - loss: 0.5595 - acc: 0.9577 - mDice: 0.7469 - val_loss: 0.4589 - val_acc: 0.9745 - val_mDice: 0.7901

Epoch 00113: val_mDice did not improve from 0.79070
Epoch 114/300
 - 17s - loss: 0.5599 - acc: 0.9577 - mDice: 0.7464 - val_loss: 0.4613 - val_acc: 0.9747 - val_mDice: 0.7885

Epoch 00114: val_mDice did not improve from 0.79070
Epoch 115/300
 - 16s - loss: 0.5589 - acc: 0.9577 - mDice: 0.7469 - val_loss: 0.4652 - val_acc: 0.9748 - val_mDice: 0.7906

Epoch 00115: val_mDice did not improve from 0.79070
Epoch 116/300
 - 16s - loss: 0.5580 - acc: 0.9578 - mDice: 0.7475 - val_loss: 0.4606 - val_acc: 0.9742 - val_mDice: 0.7895

Epoch 00116: val_mDice did not improve from 0.79070
Epoch 117/300
 - 16s - loss: 0.5586 - acc: 0.9577 - mDice: 0.7472 - val_loss: 0.4628 - val_acc: 0.9744 - val_mDice: 0.7887

Epoch 00117: val_mDice did not improve from 0.79070
Epoch 118/300
 - 16s - loss: 0.5580 - acc: 0.9577 - mDice: 0.7475 - val_loss: 0.4610 - val_acc: 0.9739 - val_mDice: 0.7885

Epoch 00118: val_mDice did not improve from 0.79070
Epoch 119/300
 - 16s - loss: 0.5577 - acc: 0.9577 - mDice: 0.7475 - val_loss: 0.4663 - val_acc: 0.9745 - val_mDice: 0.7873

Epoch 00119: val_mDice did not improve from 0.79070
Epoch 120/300
 - 16s - loss: 0.5567 - acc: 0.9577 - mDice: 0.7477 - val_loss: 0.4665 - val_acc: 0.9743 - val_mDice: 0.7881

Epoch 00120: val_mDice did not improve from 0.79070
Epoch 121/300
 - 18s - loss: 0.5558 - acc: 0.9578 - mDice: 0.7481 - val_loss: 0.4621 - val_acc: 0.9739 - val_mDice: 0.7878

Epoch 00121: val_mDice did not improve from 0.79070
Epoch 122/300
 - 16s - loss: 0.5574 - acc: 0.9578 - mDice: 0.7480 - val_loss: 0.4726 - val_acc: 0.9739 - val_mDice: 0.7863

Epoch 00122: val_mDice did not improve from 0.79070
Epoch 123/300
 - 16s - loss: 0.5567 - acc: 0.9577 - mDice: 0.7477 - val_loss: 0.4639 - val_acc: 0.9744 - val_mDice: 0.7883

Epoch 00123: val_mDice did not improve from 0.79070
Epoch 124/300
 - 17s - loss: 0.5561 - acc: 0.9578 - mDice: 0.7481 - val_loss: 0.4700 - val_acc: 0.9741 - val_mDice: 0.7881

Epoch 00124: val_mDice did not improve from 0.79070
Epoch 125/300
 - 16s - loss: 0.5559 - acc: 0.9577 - mDice: 0.7480 - val_loss: 0.4662 - val_acc: 0.9744 - val_mDice: 0.7874

Epoch 00125: val_mDice did not improve from 0.79070
Epoch 126/300
 - 17s - loss: 0.5533 - acc: 0.9578 - mDice: 0.7491 - val_loss: 0.4650 - val_acc: 0.9744 - val_mDice: 0.7899

Epoch 00126: val_mDice did not improve from 0.79070
Epoch 127/300
 - 16s - loss: 0.5539 - acc: 0.9578 - mDice: 0.7490 - val_loss: 0.4604 - val_acc: 0.9744 - val_mDice: 0.7901

Epoch 00127: val_mDice did not improve from 0.79070
Epoch 128/300
 - 18s - loss: 0.5526 - acc: 0.9578 - mDice: 0.7495 - val_loss: 0.4671 - val_acc: 0.9745 - val_mDice: 0.7885

Epoch 00128: val_mDice did not improve from 0.79070
Epoch 129/300
 - 17s - loss: 0.5538 - acc: 0.9579 - mDice: 0.7491 - val_loss: 0.4618 - val_acc: 0.9747 - val_mDice: 0.7886

Epoch 00129: val_mDice did not improve from 0.79070
Epoch 130/300
 - 16s - loss: 0.5530 - acc: 0.9578 - mDice: 0.7492 - val_loss: 0.4633 - val_acc: 0.9745 - val_mDice: 0.7889

Epoch 00130: val_mDice did not improve from 0.79070
Epoch 131/300
 - 16s - loss: 0.5525 - acc: 0.9579 - mDice: 0.7494 - val_loss: 0.4624 - val_acc: 0.9743 - val_mDice: 0.7886

Epoch 00131: val_mDice did not improve from 0.79070
Epoch 132/300
 - 16s - loss: 0.5530 - acc: 0.9578 - mDice: 0.7493 - val_loss: 0.4552 - val_acc: 0.9748 - val_mDice: 0.7927

Epoch 00132: val_mDice improved from 0.79070 to 0.79270, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 133/300
 - 17s - loss: 0.5526 - acc: 0.9579 - mDice: 0.7494 - val_loss: 0.4593 - val_acc: 0.9743 - val_mDice: 0.7898

Epoch 00133: val_mDice did not improve from 0.79270
Epoch 134/300
 - 17s - loss: 0.5514 - acc: 0.9579 - mDice: 0.7497 - val_loss: 0.4699 - val_acc: 0.9741 - val_mDice: 0.7868

Epoch 00134: val_mDice did not improve from 0.79270
Epoch 135/300
 - 18s - loss: 0.5532 - acc: 0.9578 - mDice: 0.7494 - val_loss: 0.4567 - val_acc: 0.9740 - val_mDice: 0.7891

Epoch 00135: val_mDice did not improve from 0.79270
Epoch 136/300
 - 17s - loss: 0.5507 - acc: 0.9579 - mDice: 0.7500 - val_loss: 0.4644 - val_acc: 0.9746 - val_mDice: 0.7907

Epoch 00136: val_mDice did not improve from 0.79270
Epoch 137/300
 - 16s - loss: 0.5514 - acc: 0.9579 - mDice: 0.7498 - val_loss: 0.4632 - val_acc: 0.9745 - val_mDice: 0.7889

Epoch 00137: val_mDice did not improve from 0.79270
Epoch 138/300
 - 16s - loss: 0.5492 - acc: 0.9579 - mDice: 0.7505 - val_loss: 0.4672 - val_acc: 0.9746 - val_mDice: 0.7900

Epoch 00138: val_mDice did not improve from 0.79270
Epoch 139/300
 - 16s - loss: 0.5504 - acc: 0.9579 - mDice: 0.7502 - val_loss: 0.4625 - val_acc: 0.9746 - val_mDice: 0.7882

Epoch 00139: val_mDice did not improve from 0.79270
Epoch 140/300
 - 17s - loss: 0.5516 - acc: 0.9578 - mDice: 0.7500 - val_loss: 0.4608 - val_acc: 0.9747 - val_mDice: 0.7904

Epoch 00140: val_mDice did not improve from 0.79270
Epoch 141/300
 - 17s - loss: 0.5491 - acc: 0.9578 - mDice: 0.7508 - val_loss: 0.4629 - val_acc: 0.9747 - val_mDice: 0.7899

Epoch 00141: val_mDice did not improve from 0.79270
Epoch 142/300
 - 16s - loss: 0.5495 - acc: 0.9578 - mDice: 0.7509 - val_loss: 0.4618 - val_acc: 0.9739 - val_mDice: 0.7904

Epoch 00142: val_mDice did not improve from 0.79270
Epoch 143/300
 - 16s - loss: 0.5484 - acc: 0.9579 - mDice: 0.7509 - val_loss: 0.4615 - val_acc: 0.9744 - val_mDice: 0.7899

Epoch 00143: val_mDice did not improve from 0.79270
Epoch 144/300
 - 16s - loss: 0.5492 - acc: 0.9578 - mDice: 0.7509 - val_loss: 0.4618 - val_acc: 0.9743 - val_mDice: 0.7903

Epoch 00144: val_mDice did not improve from 0.79270
Epoch 145/300
 - 16s - loss: 0.5500 - acc: 0.9578 - mDice: 0.7505 - val_loss: 0.4612 - val_acc: 0.9735 - val_mDice: 0.7881

Epoch 00145: val_mDice did not improve from 0.79270
Epoch 146/300
 - 17s - loss: 0.5479 - acc: 0.9579 - mDice: 0.7516 - val_loss: 0.4582 - val_acc: 0.9745 - val_mDice: 0.7923

Epoch 00146: val_mDice did not improve from 0.79270
Epoch 147/300
 - 17s - loss: 0.5484 - acc: 0.9579 - mDice: 0.7512 - val_loss: 0.4573 - val_acc: 0.9739 - val_mDice: 0.7919

Epoch 00147: val_mDice did not improve from 0.79270
Epoch 148/300
 - 16s - loss: 0.5488 - acc: 0.9579 - mDice: 0.7510 - val_loss: 0.4564 - val_acc: 0.9739 - val_mDice: 0.7908

Epoch 00148: val_mDice did not improve from 0.79270
Epoch 149/300
 - 16s - loss: 0.5482 - acc: 0.9579 - mDice: 0.7515 - val_loss: 0.4584 - val_acc: 0.9737 - val_mDice: 0.7899

Epoch 00149: val_mDice did not improve from 0.79270
Epoch 150/300
 - 16s - loss: 0.5488 - acc: 0.9579 - mDice: 0.7513 - val_loss: 0.4611 - val_acc: 0.9746 - val_mDice: 0.7899

Epoch 00150: val_mDice did not improve from 0.79270
Epoch 151/300
 - 16s - loss: 0.5475 - acc: 0.9579 - mDice: 0.7514 - val_loss: 0.4650 - val_acc: 0.9740 - val_mDice: 0.7881

Epoch 00151: val_mDice did not improve from 0.79270
Epoch 152/300
 - 16s - loss: 0.5476 - acc: 0.9580 - mDice: 0.7516 - val_loss: 0.4545 - val_acc: 0.9742 - val_mDice: 0.7920

Epoch 00152: val_mDice did not improve from 0.79270
Epoch 153/300
 - 17s - loss: 0.5461 - acc: 0.9580 - mDice: 0.7522 - val_loss: 0.4682 - val_acc: 0.9742 - val_mDice: 0.7890

Epoch 00153: val_mDice did not improve from 0.79270
Epoch 154/300
 - 16s - loss: 0.5459 - acc: 0.9579 - mDice: 0.7523 - val_loss: 0.4604 - val_acc: 0.9749 - val_mDice: 0.7930

Epoch 00154: val_mDice improved from 0.79270 to 0.79304, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 155/300
 - 16s - loss: 0.5457 - acc: 0.9579 - mDice: 0.7523 - val_loss: 0.4626 - val_acc: 0.9744 - val_mDice: 0.7898

Epoch 00155: val_mDice did not improve from 0.79304
Epoch 156/300
 - 16s - loss: 0.5443 - acc: 0.9580 - mDice: 0.7529 - val_loss: 0.4670 - val_acc: 0.9734 - val_mDice: 0.7896

Epoch 00156: val_mDice did not improve from 0.79304
Epoch 157/300
 - 16s - loss: 0.5452 - acc: 0.9579 - mDice: 0.7526 - val_loss: 0.4583 - val_acc: 0.9740 - val_mDice: 0.7904

Epoch 00157: val_mDice did not improve from 0.79304
Epoch 158/300
 - 16s - loss: 0.5454 - acc: 0.9580 - mDice: 0.7523 - val_loss: 0.4554 - val_acc: 0.9747 - val_mDice: 0.7917

Epoch 00158: val_mDice did not improve from 0.79304
Epoch 159/300
 - 16s - loss: 0.5450 - acc: 0.9580 - mDice: 0.7526 - val_loss: 0.4588 - val_acc: 0.9741 - val_mDice: 0.7924

Epoch 00159: val_mDice did not improve from 0.79304
Epoch 160/300
 - 17s - loss: 0.5459 - acc: 0.9579 - mDice: 0.7522 - val_loss: 0.4562 - val_acc: 0.9745 - val_mDice: 0.7924

Epoch 00160: val_mDice did not improve from 0.79304
Epoch 161/300
 - 16s - loss: 0.5456 - acc: 0.9579 - mDice: 0.7525 - val_loss: 0.4621 - val_acc: 0.9744 - val_mDice: 0.7910

Epoch 00161: val_mDice did not improve from 0.79304
Epoch 162/300
 - 16s - loss: 0.5460 - acc: 0.9580 - mDice: 0.7522 - val_loss: 0.4691 - val_acc: 0.9746 - val_mDice: 0.7891

Epoch 00162: val_mDice did not improve from 0.79304
Epoch 163/300
 - 16s - loss: 0.5461 - acc: 0.9580 - mDice: 0.7523 - val_loss: 0.4578 - val_acc: 0.9744 - val_mDice: 0.7920

Epoch 00163: val_mDice did not improve from 0.79304
Epoch 164/300
 - 16s - loss: 0.5433 - acc: 0.9580 - mDice: 0.7533 - val_loss: 0.4622 - val_acc: 0.9749 - val_mDice: 0.7912

Epoch 00164: val_mDice did not improve from 0.79304
Epoch 165/300
 - 16s - loss: 0.5446 - acc: 0.9580 - mDice: 0.7528 - val_loss: 0.4525 - val_acc: 0.9747 - val_mDice: 0.7948

Epoch 00165: val_mDice improved from 0.79304 to 0.79484, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 166/300
 - 17s - loss: 0.5433 - acc: 0.9580 - mDice: 0.7534 - val_loss: 0.4643 - val_acc: 0.9742 - val_mDice: 0.7894

Epoch 00166: val_mDice did not improve from 0.79484
Epoch 167/300
 - 16s - loss: 0.5424 - acc: 0.9580 - mDice: 0.7533 - val_loss: 0.4672 - val_acc: 0.9741 - val_mDice: 0.7912

Epoch 00167: val_mDice did not improve from 0.79484
Epoch 168/300
 - 16s - loss: 0.5422 - acc: 0.9579 - mDice: 0.7536 - val_loss: 0.4674 - val_acc: 0.9741 - val_mDice: 0.7914

Epoch 00168: val_mDice did not improve from 0.79484
Epoch 169/300
 - 16s - loss: 0.5422 - acc: 0.9580 - mDice: 0.7537 - val_loss: 0.4551 - val_acc: 0.9740 - val_mDice: 0.7928

Epoch 00169: val_mDice did not improve from 0.79484
Epoch 170/300
 - 16s - loss: 0.5424 - acc: 0.9581 - mDice: 0.7539 - val_loss: 0.4580 - val_acc: 0.9743 - val_mDice: 0.7901

Epoch 00170: val_mDice did not improve from 0.79484
Epoch 171/300
 - 16s - loss: 0.5439 - acc: 0.9579 - mDice: 0.7529 - val_loss: 0.4584 - val_acc: 0.9742 - val_mDice: 0.7927

Epoch 00171: val_mDice did not improve from 0.79484
Epoch 172/300
 - 16s - loss: 0.5424 - acc: 0.9580 - mDice: 0.7536 - val_loss: 0.4652 - val_acc: 0.9740 - val_mDice: 0.7895

Epoch 00172: val_mDice did not improve from 0.79484
Epoch 173/300
 - 16s - loss: 0.5416 - acc: 0.9581 - mDice: 0.7538 - val_loss: 0.4684 - val_acc: 0.9745 - val_mDice: 0.7904

Epoch 00173: val_mDice did not improve from 0.79484
Epoch 174/300
 - 17s - loss: 0.5405 - acc: 0.9581 - mDice: 0.7545 - val_loss: 0.4588 - val_acc: 0.9741 - val_mDice: 0.7923

Epoch 00174: val_mDice did not improve from 0.79484
Epoch 175/300
 - 16s - loss: 0.5414 - acc: 0.9581 - mDice: 0.7540 - val_loss: 0.4645 - val_acc: 0.9744 - val_mDice: 0.7907

Epoch 00175: val_mDice did not improve from 0.79484
Epoch 176/300
 - 16s - loss: 0.5420 - acc: 0.9580 - mDice: 0.7538 - val_loss: 0.4643 - val_acc: 0.9747 - val_mDice: 0.7919

Epoch 00176: val_mDice did not improve from 0.79484
Epoch 177/300
 - 16s - loss: 0.5393 - acc: 0.9581 - mDice: 0.7550 - val_loss: 0.4565 - val_acc: 0.9742 - val_mDice: 0.7927

Epoch 00177: val_mDice did not improve from 0.79484
Epoch 178/300
 - 16s - loss: 0.5401 - acc: 0.9581 - mDice: 0.7545 - val_loss: 0.4546 - val_acc: 0.9748 - val_mDice: 0.7931

Epoch 00178: val_mDice did not improve from 0.79484
Epoch 179/300
 - 16s - loss: 0.5412 - acc: 0.9582 - mDice: 0.7542 - val_loss: 0.4655 - val_acc: 0.9739 - val_mDice: 0.7916

Epoch 00179: val_mDice did not improve from 0.79484
Epoch 180/300
 - 17s - loss: 0.5425 - acc: 0.9580 - mDice: 0.7537 - val_loss: 0.4611 - val_acc: 0.9745 - val_mDice: 0.7924

Epoch 00180: val_mDice did not improve from 0.79484
Epoch 181/300
 - 16s - loss: 0.5404 - acc: 0.9582 - mDice: 0.7544 - val_loss: 0.4618 - val_acc: 0.9742 - val_mDice: 0.7918

Epoch 00181: val_mDice did not improve from 0.79484
Epoch 182/300
 - 15s - loss: 0.5401 - acc: 0.9581 - mDice: 0.7545 - val_loss: 0.4540 - val_acc: 0.9746 - val_mDice: 0.7933

Epoch 00182: val_mDice did not improve from 0.79484
Epoch 183/300
 - 16s - loss: 0.5402 - acc: 0.9581 - mDice: 0.7546 - val_loss: 0.4610 - val_acc: 0.9742 - val_mDice: 0.7917

Epoch 00183: val_mDice did not improve from 0.79484
Epoch 184/300
 - 16s - loss: 0.5409 - acc: 0.9581 - mDice: 0.7541 - val_loss: 0.4535 - val_acc: 0.9742 - val_mDice: 0.7940

Epoch 00184: val_mDice did not improve from 0.79484
Epoch 185/300
 - 17s - loss: 0.5385 - acc: 0.9582 - mDice: 0.7551 - val_loss: 0.4639 - val_acc: 0.9742 - val_mDice: 0.7913

Epoch 00185: val_mDice did not improve from 0.79484
Epoch 186/300
 - 16s - loss: 0.5401 - acc: 0.9581 - mDice: 0.7544 - val_loss: 0.4578 - val_acc: 0.9734 - val_mDice: 0.7908

Epoch 00186: val_mDice did not improve from 0.79484
Epoch 187/300
 - 15s - loss: 0.5405 - acc: 0.9581 - mDice: 0.7545 - val_loss: 0.4569 - val_acc: 0.9740 - val_mDice: 0.7926

Epoch 00187: val_mDice did not improve from 0.79484
Epoch 188/300
 - 15s - loss: 0.5391 - acc: 0.9581 - mDice: 0.7549 - val_loss: 0.4589 - val_acc: 0.9737 - val_mDice: 0.7908

Epoch 00188: val_mDice did not improve from 0.79484
Epoch 189/300
 - 15s - loss: 0.5385 - acc: 0.9581 - mDice: 0.7552 - val_loss: 0.4545 - val_acc: 0.9746 - val_mDice: 0.7940

Epoch 00189: val_mDice did not improve from 0.79484
Epoch 190/300
 - 15s - loss: 0.5372 - acc: 0.9582 - mDice: 0.7557 - val_loss: 0.4654 - val_acc: 0.9741 - val_mDice: 0.7898

Epoch 00190: val_mDice did not improve from 0.79484
Epoch 191/300
 - 16s - loss: 0.5376 - acc: 0.9583 - mDice: 0.7553 - val_loss: 0.4535 - val_acc: 0.9741 - val_mDice: 0.7940

Epoch 00191: val_mDice did not improve from 0.79484
Epoch 192/300
 - 17s - loss: 0.5392 - acc: 0.9582 - mDice: 0.7550 - val_loss: 0.4630 - val_acc: 0.9739 - val_mDice: 0.7899

Epoch 00192: val_mDice did not improve from 0.79484
Epoch 193/300
 - 16s - loss: 0.5391 - acc: 0.9583 - mDice: 0.7549 - val_loss: 0.4589 - val_acc: 0.9738 - val_mDice: 0.7913

Epoch 00193: val_mDice did not improve from 0.79484
Epoch 194/300
 - 15s - loss: 0.5391 - acc: 0.9582 - mDice: 0.7548 - val_loss: 0.4568 - val_acc: 0.9740 - val_mDice: 0.7915

Epoch 00194: val_mDice did not improve from 0.79484
Epoch 195/300
 - 15s - loss: 0.5364 - acc: 0.9583 - mDice: 0.7562 - val_loss: 0.4575 - val_acc: 0.9740 - val_mDice: 0.7924

Epoch 00195: val_mDice did not improve from 0.79484
Restoring model weights from the end of the best epoch
Epoch 00195: early stopping
{'val_loss': [3.3395494565571826, 2.288926408715444, 1.6312861981457227, 1.107358560986715, 0.8708624451944272, 0.796787003131762, 0.7453721439185208, 0.667561750705928, 0.6546495356788374, 0.6075742334535678, 0.6067878167106681, 0.5916878493273094, 0.5743944399977383, 0.5805101982534748, 0.5688025808497651, 0.5596974375721526, 0.5516356535970348, 0.5433865687618517, 0.5560169650675499, 0.556269712439955, 0.5411026779919454, 0.5313303021535482, 0.5426398113574067, 0.5296413408566828, 0.5260468617285767, 0.5130353329116351, 0.5054077859202476, 0.5145778688665938, 0.5149346198121162, 0.5110038641380937, 0.5018763605454196, 0.5092979206206047, 0.5005145542425652, 0.4972269512610893, 0.5055654947071859, 0.5087951864689997, 0.49031433197733476, 0.4986547507243614, 0.49464128523656764, 0.4894579332577039, 0.4953024858889514, 0.48564737198287494, 0.4877792882592711, 0.4828661518962416, 0.4899253683955702, 0.48894041837894753, 0.4719844148175357, 0.4807888787903198, 0.4799497472505047, 0.4835369413437909, 0.4790349535337866, 0.4796953613627447, 0.4738015295708016, 0.48472181391226105, 0.48424717885990665, 0.47043779186189993, 0.4834594334641548, 0.4782097278392478, 0.47472958858699016, 0.46639769575367235, 0.47857248987237067, 0.47376598642296985, 0.4813437380202829, 0.466217744636209, 0.4698589631955918, 0.4678415876545318, 0.4717818912986207, 0.4711194332331827, 0.4751428284057199, 0.46944389441241957, 0.4667137126400046, 0.47460652091731764, 0.47325858922853864, 0.47562288666424685, 0.47572817908574455, 0.46672778382693253, 0.4777568066365098, 0.4719070179821694, 0.4656126188905272, 0.4665251021107582, 0.4722973585945286, 0.4700949051200527, 0.4745294010802491, 0.4667057835892455, 0.4699135812586301, 0.48622589527744137, 0.46898241381939143, 0.4657391023962465, 0.4586456732390678, 0.47153672984201617, 0.4635337225786627, 0.4676263642637697, 0.45697595056605667, 0.4609555902138148, 0.4643423910418602, 0.47375007973958366, 0.47372094245806134, 0.46522523871023364, 0.4606947662079171, 0.4591481828526275, 0.46192737740196593, 0.461896247651479, 0.4634048606026663, 0.4620979158845666, 0.4651032292271314, 0.4658157551941806, 0.4734949324637243, 0.46021955225565664, 0.4634340660621042, 0.46484990070943966, 0.46321253253989025, 0.46381910206520394, 0.4588787369940379, 0.4612940698862076, 0.4652354649893225, 0.4605529334855406, 0.4627847932789424, 0.46097376350670644, 0.4662661550387944, 0.46653422060078137, 0.4621281529942604, 0.4726345726888474, 0.4638704994361695, 0.46996485492954515, 0.46624182511682377, 0.46500466253659495, 0.46040040295417994, 0.4670700592129198, 0.4618137048123634, 0.4633044916881274, 0.46239146773945794, 0.4551843951826226, 0.4592502362107577, 0.469907891872811, 0.4567223797514014, 0.46444831543589293, 0.46319337413735584, 0.46717399746587834, 0.4625458190702412, 0.4607906941681692, 0.46287855220167606, 0.4617985007289338, 0.461513562357589, 0.4618484328870904, 0.461196899209937, 0.4582308714520441, 0.45726517659344085, 0.4563746754437277, 0.45840333545044676, 0.4610702364820324, 0.4650196282014455, 0.4545343079387325, 0.4682161561022066, 0.46044379370669797, 0.46262432594005376, 0.4669680274920921, 0.4582739833691349, 0.45543324130855195, 0.4588303882373522, 0.4561544317905217, 0.4621051553994009, 0.46905469629046037, 0.45778721387255683, 0.4622327695562415, 0.45252974902930326, 0.4643310312538931, 0.46715306562103637, 0.46741133744586005, 0.4551299173537999, 0.4580421374268728, 0.4583548403357806, 0.46520834671307915, 0.4684241661061979, 0.45881037434486494, 0.4645231774408523, 0.464262090521316, 0.45649341871477156, 0.4545950460923861, 0.4655437163294178, 0.46111333227320894, 0.46176772105367214, 0.4540307623882816, 0.4610118178063876, 0.4535098555561614, 0.46388139116437466, 0.45777389570458293, 0.45688940217233687, 0.4589413488156175, 0.45452150865776897, 0.4654471661946545, 0.4534820430491069, 0.462981153024386, 0.4589130025203914, 0.4567797022731337, 0.45746099050730876], 'val_acc': [0.9136435177228223, 0.9100856180876902, 0.9272850041520105, 0.9472799929853988, 0.9559417513951863, 0.9630950158589506, 0.9658058498003711, 0.9661087005922239, 0.9677241958983956, 0.9681450083647689, 0.9685133911975442, 0.9714491742931001, 0.9697827202816532, 0.9708765769658023, 0.9706512330329582, 0.970378967588895, 0.9712558886776231, 0.972260934032806, 0.9696687684483725, 0.9712125577338754, 0.972468035678341, 0.9713330619955716, 0.971994841751987, 0.9722106934410252, 0.9722234296472105, 0.9720829247611843, 0.9718099187498224, 0.9728619203175584, 0.9714047700574954, 0.9719369440046075, 0.9736369101152028, 0.9727370575682758, 0.972783289951821, 0.9720676418853132, 0.9733686263430609, 0.9736471033259614, 0.9731698697560454, 0.972812777512694, 0.9739437707482952, 0.974232801019329, 0.9736642131250198, 0.9732444984455632, 0.9738811638257275, 0.9737635834576333, 0.9736835021678716, 0.9734134045365739, 0.9736154438698128, 0.9741509046456586, 0.9744497476375267, 0.9743005090380368, 0.9737937944392635, 0.9747438708396807, 0.9740001975673519, 0.9742895911817682, 0.972761092120654, 0.9744592068130022, 0.9738698797683193, 0.9743416403254418, 0.9738939073804307, 0.974596085613721, 0.9748294275917418, 0.9738138207834061, 0.9744377368933534, 0.9745957259445974, 0.9743296336637784, 0.9742644804797761, 0.9741155737883425, 0.9747733779966015, 0.9749014965475422, 0.9742680922762988, 0.9743565778209738, 0.9746972820530199, 0.9748403495305205, 0.9748046700268576, 0.9737260839710496, 0.9750671280573492, 0.9740631666085492, 0.9752211031848437, 0.9747220375766493, 0.9745822565196312, 0.9741770951715234, 0.9745192793134141, 0.9746182895686528, 0.9747966625919081, 0.9749462661677843, 0.9748756428287454, 0.9742663020957006, 0.9745913527599753, 0.9746208370548405, 0.9744238992259927, 0.975081692411475, 0.9740038330424322, 0.9742022234283082, 0.9747045648424593, 0.97481048841999, 0.9742884929866007, 0.9748887623826118, 0.9748803903795269, 0.9744759614336981, 0.9740824748391974, 0.9738946197784111, 0.9746328526980257, 0.9749360749982807, 0.9746084637837867, 0.9743427434196211, 0.9744533953601366, 0.9739707071487218, 0.9745724201202393, 0.9747897402880943, 0.9749637356359665, 0.9746328575970375, 0.9751177193367317, 0.9745309312049657, 0.9746554216293439, 0.9748199512697246, 0.9742429999456014, 0.9744104436815602, 0.9738764362792446, 0.9745494951940563, 0.9743198115531713, 0.973897541222507, 0.9739048260532014, 0.9744195378806493, 0.9741367085339272, 0.9744381067687518, 0.9743631016718198, 0.974387139081955, 0.9745152813114532, 0.9747449629110833, 0.9745159933011825, 0.9743136134866166, 0.9747820945635234, 0.9743092341782296, 0.9740540809827308, 0.9739794543344681, 0.9745917201858677, 0.9745294696664157, 0.9745636896727836, 0.9745953601517089, 0.9747413384587797, 0.9747256787672435, 0.973887709722127, 0.9744249994624151, 0.9742568290396912, 0.9735368081968124, 0.9744803362513241, 0.9739139239265494, 0.9738793487418188, 0.9736725839033519, 0.9746095583046952, 0.9740275120081967, 0.9741872965473019, 0.9741851164870066, 0.9749400783075045, 0.9743798754803122, 0.973444352819495, 0.9740347837748593, 0.9746736373803387, 0.9741439839748487, 0.9745487627917773, 0.9744155259981547, 0.9745855417153607, 0.9744482995712593, 0.9749036847728573, 0.9747129401115522, 0.9742087921867632, 0.974133796887855, 0.9741483563429689, 0.973999464348571, 0.9743460155513188, 0.974199308924479, 0.973953957018787, 0.9745494809052716, 0.9741356127882657, 0.9743569342240895, 0.9746605292575, 0.9742302457763724, 0.9747620808751616, 0.9738687840226579, 0.9745287482869135, 0.9741541763691053, 0.974566982625282, 0.9742044173691371, 0.9741745591163635, 0.9741731016603234, 0.9734159446742436, 0.974011482849513, 0.9736980693797542, 0.9745844382129304, 0.9740923006240636, 0.9740653380955735, 0.9739175687914026, 0.9738149083640477, 0.9739903766814977, 0.9740467949272835], 'val_mDice': [0.07356661420366535, 0.21591820567846298, 0.36524807855690994, 0.5041121181151639, 0.5903606933273681, 0.6327227174419247, 0.6607088401709518, 0.6896359018267018, 0.6963821874089438, 0.7167074712988448, 0.718259428053686, 0.7245790305202955, 0.7325028128003421, 0.7332286871459386, 0.7395101932630147, 0.7434355906427723, 0.7440834576136446, 0.7491736305903082, 0.7483395313563412, 0.747991586384708, 0.755543004568309, 0.7581192916386748, 0.7565088161866959, 0.7595392412518802, 0.7629984021186829, 0.7688533133023405, 0.7678889521997269, 0.7647971992623316, 0.7659916383762883, 0.7658915042060696, 0.7726168485536967, 0.7691372971828669, 0.7728126747150944, 0.7727161037595305, 0.7709581153850033, 0.770438599668137, 0.7757250266532375, 0.7742726982456364, 0.7754074282025638, 0.7791835445247285, 0.7760127823646754, 0.7780497274170183, 0.7781984626430355, 0.7799316505863242, 0.7783021285925826, 0.7796954177830318, 0.7824600624711546, 0.7806106491448128, 0.7801153467942591, 0.7818737891438889, 0.7819437449925566, 0.7817185843644077, 0.7830699114766839, 0.7795313131319334, 0.7780023151881075, 0.7822736999759935, 0.7802943954729054, 0.7810458598071581, 0.7836899291979124, 0.7853101246977505, 0.782674495487997, 0.7821881199536258, 0.7815875353878492, 0.7845944035543154, 0.783311418066286, 0.7841954239427227, 0.7846213930273709, 0.7841058079510519, 0.7841261266029045, 0.7846840342430219, 0.7848402633242411, 0.7829661206023334, 0.7833277579039744, 0.7830300710789145, 0.7808177846751801, 0.7864389223595188, 0.7820158298701456, 0.7856752398895891, 0.7848028165020354, 0.785735791268414, 0.7844737911061065, 0.7847164346747202, 0.7820503536152513, 0.7861429150790384, 0.7876614589397222, 0.7808781739783613, 0.7841941587728997, 0.7873237961775637, 0.7897140391885418, 0.7838077059347336, 0.7879681717859556, 0.7847127057101628, 0.7893005825885354, 0.7872167866523951, 0.7878968691172665, 0.78262027118304, 0.7859287821266749, 0.7905175142908749, 0.7904483537151389, 0.7890564872793955, 0.7895704618055527, 0.7906894830808248, 0.7902050104043256, 0.7882821429265688, 0.7886269586543514, 0.7884898549073363, 0.784365371890264, 0.7906950785689157, 0.7906485783727202, 0.789669542279962, 0.7874267456466204, 0.7881767337452875, 0.7900841489230117, 0.7884873380399731, 0.790619969776232, 0.7894667395173687, 0.7886838814983629, 0.7885315099807635, 0.787329717041695, 0.7880726415817052, 0.7877792895656742, 0.7862652111543368, 0.7883084387811896, 0.7880789196654542, 0.7874061746956551, 0.78988486691697, 0.7900851177026148, 0.7885076779208772, 0.7885638463170561, 0.7888542993427956, 0.7885647048688915, 0.7927036179255132, 0.7898053098214816, 0.7867732897196731, 0.7890779049429175, 0.790665965374202, 0.7889206858530436, 0.7899675242704888, 0.7882003384093715, 0.7903877202778646, 0.7899115338717422, 0.7904371023178101, 0.7899253907268995, 0.7903095908360939, 0.7881082039173335, 0.7923231239188208, 0.7919139404819436, 0.7908063775872531, 0.7899438665337759, 0.789927312772568, 0.7880842975557667, 0.7920467053374199, 0.7890429627405454, 0.7930365572236988, 0.789839066462974, 0.7895999624304575, 0.7904078392949823, 0.7917006779206942, 0.7923754490401647, 0.7924304404487349, 0.7910252931999834, 0.789123094245179, 0.7919739725655073, 0.7911695674674152, 0.7948355527773295, 0.7893774162416589, 0.791205789536646, 0.7913763416956549, 0.7928362403013934, 0.7900931079910226, 0.7927088929365759, 0.7894547267319405, 0.7903716335557911, 0.7923167968449527, 0.7907352814935658, 0.7919210963053246, 0.7926545996372014, 0.7930907994916995, 0.7915782887641698, 0.7923813372442167, 0.791791560306941, 0.7932963065088612, 0.7917360545021214, 0.7939864968600339, 0.7913372598282279, 0.7907804826351061, 0.7925721766197518, 0.7908016512655232, 0.7940496075643252, 0.789836877829408, 0.7940285516111818, 0.7898623494252767, 0.7913402131159012, 0.7915399262349899, 0.7924239762025337], 'loss': [11.36188257903994, 3.1213846664795493, 2.1775931090215606, 1.7134391632624273, 1.4538171302669565, 1.284105497194466, 1.1719798975590885, 1.0972288596158406, 1.0429660043513507, 0.9983687860557008, 0.9626555452806885, 0.93191007626672, 0.9085112533900725, 0.8857629349147953, 0.8619016910025605, 0.8462927333676297, 0.827506543248583, 0.8142357992088314, 0.7986936857254627, 0.7871013367208805, 0.7771975069461061, 0.7659246420864887, 0.7554205082670408, 0.7462588312758142, 0.7355278298431859, 0.7276325559258731, 0.718916311174239, 0.7137314719121722, 0.705470299736851, 0.7016078909883569, 0.6964265602333838, 0.6901966311700763, 0.6865573761991618, 0.6799288643452683, 0.6769841467767137, 0.6679437079885344, 0.6642686239012328, 0.6605140065663097, 0.6563723666997489, 0.6542277340357766, 0.6498908970541446, 0.6496492196185956, 0.6439126181920768, 0.6427224741248523, 0.638750820231671, 0.6342746427121913, 0.6319154246185847, 0.6299135896624, 0.6260097325121077, 0.6229883756179213, 0.6230725841833268, 0.6202474055511301, 0.6189250821845836, 0.616895989334045, 0.6156219679985605, 0.6126898597941881, 0.6105655419294492, 0.6051749543983612, 0.6061488850138906, 0.6039950333923838, 0.6036777985507341, 0.6025328636787054, 0.5983163586274257, 0.5982430172780088, 0.5966544680319279, 0.5954049003587308, 0.5941981332659106, 0.5929136756380079, 0.5915799371115736, 0.5908567579825348, 0.5890656945328981, 0.5880304881665062, 0.5887540188032298, 0.5860757173684782, 0.5864244759416022, 0.5831483673133576, 0.5837588323628254, 0.5823741113084144, 0.5822071636939394, 0.5803331239903494, 0.5801986702520121, 0.5788030691063888, 0.5771324854956184, 0.5756183306038124, 0.5744658112798842, 0.575285612091891, 0.577200380885358, 0.5737189927329913, 0.5741728732307719, 0.5715424055863337, 0.5718389543227514, 0.5707565785241452, 0.5716909621458661, 0.5705165779888214, 0.5683271840981009, 0.5686431280779168, 0.5682178345210432, 0.5679486902244201, 0.5671806969630114, 0.5661628797095197, 0.5658138590141333, 0.5646160813970872, 0.5630856095678783, 0.5620059064425206, 0.5630031084289286, 0.5627167967564973, 0.5638429653607792, 0.5623064890523274, 0.5621907562398067, 0.5619562067358262, 0.5621238620164934, 0.5598270790514541, 0.5595323262076658, 0.5599453961629742, 0.5588512703380651, 0.5579862783466961, 0.5585520434373258, 0.5579500054659869, 0.5576840742860186, 0.5566692377358806, 0.555804976607364, 0.5574136131889557, 0.5566533649333719, 0.5561135427177001, 0.5559067384964805, 0.5533266064646595, 0.5539062786455057, 0.5525768874116597, 0.5537913254605321, 0.5530227628482256, 0.5525028737425902, 0.552981715566239, 0.5526281294564039, 0.5514398680330098, 0.5532344242260654, 0.5507402939419326, 0.5514019344883014, 0.5491544202747871, 0.5503778112679253, 0.551631849750541, 0.5491312558225588, 0.5495169514908584, 0.5483565517486253, 0.5492079790913746, 0.5500419429913677, 0.547852416743232, 0.5483822865215311, 0.5487880229754611, 0.5482473526266869, 0.5488473369596183, 0.5475104926043151, 0.5475717644325722, 0.5460764150072783, 0.5459028596395217, 0.5456804899478442, 0.5443276074818688, 0.5452219533359547, 0.5453875749646867, 0.544996598091888, 0.5458509195232409, 0.5455680718188791, 0.5460090379171115, 0.5461189420150041, 0.5432728583556817, 0.5445596609821008, 0.5433108006332505, 0.5424233851628025, 0.5421943366857912, 0.542155404587333, 0.5424204029211441, 0.5438920638636972, 0.5424110136455419, 0.5416492745542395, 0.5405137012927433, 0.5414408762125551, 0.5420338834037011, 0.5392590220580418, 0.5400867909530576, 0.5412062395192944, 0.5424857188752832, 0.5404165968937359, 0.5401116790076418, 0.5401800905755011, 0.5408919401985001, 0.5384553839967443, 0.540097955919368, 0.5404698730083861, 0.5390822629427828, 0.53850065797023, 0.5372192787172663, 0.5375561397534359, 0.5391598139273309, 0.5390558891370731, 0.5390882469026765, 0.5363591384761873], 'acc': [0.7927306892369258, 0.9000007042144142, 0.9124389920695913, 0.9228114001957433, 0.9297411442291329, 0.934601398529883, 0.9387672737860566, 0.9414897125177173, 0.943346462960335, 0.944770656046715, 0.9459011505193506, 0.946884858848974, 0.9477521427637514, 0.9485578869467982, 0.949388400756501, 0.9498119621375904, 0.9505462703133062, 0.9508643224300365, 0.9513273313824679, 0.9517274787439899, 0.95195660262092, 0.9523289039816487, 0.9525194712831714, 0.9527857859362533, 0.9530580202765255, 0.9533843618570176, 0.9536233378252964, 0.9538686585584901, 0.9540917149962755, 0.9543477403576951, 0.9546138682855607, 0.9549196683485495, 0.9550861586168063, 0.9552524418530737, 0.9553917027409148, 0.9557135232305336, 0.955821449480618, 0.9560346592333847, 0.9560315162855503, 0.9561875043785643, 0.9563456542337134, 0.9562905117904568, 0.9564534400082696, 0.9565351980641076, 0.9566840856435748, 0.9568488454898011, 0.9569142526262059, 0.9569247924820177, 0.9571021258288093, 0.9571485073832214, 0.9571127487617008, 0.9572584832040388, 0.9572408181672223, 0.957437114127487, 0.9574264983044077, 0.9573850446111858, 0.9573095564934379, 0.9572445891025159, 0.9570847668356595, 0.9571124613385608, 0.9571819888165993, 0.9571096245378085, 0.9572172443075831, 0.9572052066628, 0.9572387176126714, 0.957238566804216, 0.9572657984511537, 0.9573596549658059, 0.9573508750054284, 0.9573607410032827, 0.9574635564847144, 0.9573361941019112, 0.9573336916864048, 0.9574538348806847, 0.9574345129243701, 0.9574388460605321, 0.9573914915965295, 0.957389001651203, 0.9574170523571378, 0.9574496746896302, 0.957375609005461, 0.9574198701064658, 0.9574037027580777, 0.9574616834211765, 0.9575033068249005, 0.9574965059576256, 0.9574115807518648, 0.9574245530310307, 0.9575056053080083, 0.9575703147032317, 0.9574780457708898, 0.9575287077712912, 0.9574410770909115, 0.9575359940678247, 0.9575651094186013, 0.9575686655657465, 0.9575067949706407, 0.9575064351739203, 0.9575787910415877, 0.9575749361070933, 0.957617906344828, 0.9575837370234631, 0.9576826995525298, 0.9577079331870826, 0.9576387570170795, 0.957601493522629, 0.9575777846454994, 0.9577111897281729, 0.9576784788663085, 0.9576728037451714, 0.9577182715694854, 0.9577360405560671, 0.9576531728524301, 0.957674084821318, 0.9576914264148181, 0.9577714975750402, 0.9577445912759869, 0.9577107318591322, 0.9577476773051057, 0.9577383328773377, 0.9577919075595792, 0.9577830033311729, 0.9577494813704285, 0.9577851457287647, 0.9577250227054186, 0.9577961798932008, 0.9578492408362037, 0.9578454303703536, 0.9578621307478347, 0.9578413314443364, 0.9578833468414581, 0.9578362203654373, 0.9578571202117361, 0.9578903148453393, 0.957823215823523, 0.9578675282760449, 0.9578608699640979, 0.9579128062094807, 0.9579121896120846, 0.9578397948544619, 0.9578087936970657, 0.9578148364199174, 0.957876629108716, 0.957808515724949, 0.9578022449135729, 0.9578673642792468, 0.9578614211971831, 0.9578866065826822, 0.9578978353089278, 0.9578577161921128, 0.9579024559544095, 0.9579582620806921, 0.9579956606529587, 0.9579334188796875, 0.9579314100201707, 0.957975231504962, 0.9579089192248142, 0.9579537036166237, 0.9579519818068022, 0.9579136126460475, 0.9579281720478993, 0.9579672501215769, 0.9579738278125612, 0.9580269735447441, 0.9579900970452779, 0.9580217550688982, 0.9579565322389373, 0.9579281315234054, 0.9579956495760148, 0.9580543791020001, 0.9579304157437988, 0.957978386224922, 0.958058148006329, 0.9580982718285471, 0.958125043604206, 0.9580153412626786, 0.9581413012859913, 0.958058556646742, 0.9581712808050106, 0.958044797261081, 0.958163686422355, 0.9581050708601978, 0.95812287774567, 0.9581002672756543, 0.9581703580203151, 0.9581128989129395, 0.9580618265657702, 0.9581234036362242, 0.9581268345242759, 0.9582409485833456, 0.9582778549612594, 0.95816437332215, 0.9582537575838761, 0.9581840829887392, 0.9582553549303285], 'mDice': [0.03172073581117861, 0.13114526849050648, 0.2581427397886077, 0.3580620404875269, 0.42710443517203345, 0.4776558923421983, 0.5140345795791496, 0.5389495912796216, 0.5576227635462615, 0.5731525012364278, 0.5864010383849649, 0.5973859139078008, 0.6066989698802553, 0.6150600575925046, 0.6246312671560535, 0.6304616706159536, 0.638587821626716, 0.6438781880425789, 0.6495617454819199, 0.6544962355680216, 0.6587340078317572, 0.6632827206274775, 0.6671394668485384, 0.6710307588921529, 0.6749995402373075, 0.6781620832688953, 0.6819975701974004, 0.6839022625497498, 0.6873439325126455, 0.6890166038702503, 0.6912817471090228, 0.6941385351150511, 0.6958156523690051, 0.6981598273278018, 0.6992185093292622, 0.7029583683800563, 0.7046430068732147, 0.7060436712465457, 0.7076200122166567, 0.7088194344036722, 0.7102566445940712, 0.7105402089158072, 0.712569213326026, 0.7129284544240205, 0.7147053613898967, 0.7166698085491304, 0.7173299923294268, 0.7176964222663822, 0.7195622021850089, 0.7203678234817723, 0.7204108288491615, 0.7218962350381852, 0.7222048215184925, 0.7231601728112492, 0.7237033060105015, 0.7244270843243598, 0.7255635399135648, 0.7276227712125639, 0.7273413411071085, 0.7286207852544448, 0.7285919376864906, 0.7290216360105263, 0.7304884941470244, 0.7309409975057579, 0.7314820667652746, 0.7318634731039104, 0.732263034973106, 0.7330432106910932, 0.733446241091565, 0.7337166728890196, 0.734589917931857, 0.7348897688859595, 0.7347074661940183, 0.7356991556398702, 0.7357572499421874, 0.7368130495108273, 0.7366913519708144, 0.7374464404215852, 0.7371092090905905, 0.7384770213796396, 0.7383456470748132, 0.7389379460941804, 0.7394193769753757, 0.7398528095509461, 0.7403663109139286, 0.7402309545856355, 0.7394391986150455, 0.7408487215531154, 0.7408914821332573, 0.7416880165785443, 0.7417151792301397, 0.7421548014531923, 0.7418346958617956, 0.7421672910464816, 0.7431391626273277, 0.7427815566856238, 0.7432961903501346, 0.7429818170858559, 0.7435715787927468, 0.7440541858351128, 0.7441967880704603, 0.7446245222133271, 0.7449429903388213, 0.7454098718035014, 0.7452399816689558, 0.7454359123227544, 0.7449190618848334, 0.7455967751357795, 0.7456713531803146, 0.7458768377614783, 0.7456052646280065, 0.7465590317683988, 0.7468681949708277, 0.746424881907749, 0.74693335703272, 0.7474895755758262, 0.7472345923922413, 0.747488885389718, 0.747471443603881, 0.747716346949438, 0.7481481929395083, 0.7479961139850487, 0.7477242787192601, 0.7481157863316487, 0.7480482166057851, 0.7491346838572058, 0.7489845722007421, 0.7494543070011561, 0.7490825968320941, 0.7491575909744452, 0.7493693159714602, 0.7492654049067309, 0.7494380167923386, 0.7497376934052249, 0.7494252878727123, 0.7499960769319587, 0.7497998373560966, 0.7504516725793184, 0.7501988211788783, 0.7499771894239576, 0.7507562790556329, 0.7509074577900742, 0.7509226680600538, 0.7509305051300484, 0.750467977507602, 0.7516119644994523, 0.7511963575390415, 0.7510229090511543, 0.7514735649416743, 0.7512975679580789, 0.7514224136827699, 0.751631963522476, 0.7521773590410271, 0.752282604142105, 0.7522683347114351, 0.7528770358839738, 0.7525920212467042, 0.7523098944859296, 0.7526156044855503, 0.7522323317910178, 0.7525186613471406, 0.7521638266264292, 0.7522685100293526, 0.7533206114614318, 0.7527779713901441, 0.7533641132430988, 0.7533104814956364, 0.7536265554500032, 0.7536839763884591, 0.7538500226453457, 0.7529099192859018, 0.7536069594944487, 0.7538461820884719, 0.7545296588778938, 0.7539843259142005, 0.7538343600677786, 0.7550106477298486, 0.7544874207526151, 0.7542465940987532, 0.7537387225465767, 0.7544372784751853, 0.7545237036588778, 0.7546293709391749, 0.7541462304339455, 0.7551397320689784, 0.75435752768167, 0.7545026612572512, 0.7549405860908922, 0.7552329564796619, 0.7557011375519631, 0.7552789505708476, 0.7550118040582336, 0.7548633874988054, 0.7547772891079411, 0.7561606722852685]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:28,  2.02s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:24,  1.91s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:22,  1.91s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:21,  1.92s/it]predicting test subjects:  33%|███▎      | 5/15 [00:09<00:19,  1.99s/it]predicting test subjects:  40%|████      | 6/15 [00:11<00:18,  2.05s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:14,  1.86s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:15<00:14,  2.05s/it]predicting test subjects:  60%|██████    | 9/15 [00:17<00:11,  1.98s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.82s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:20<00:07,  1.78s/it]predicting test subjects:  80%|████████  | 12/15 [00:22<00:05,  1.85s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:24<00:03,  1.92s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:26<00:01,  1.88s/it]predicting test subjects: 100%|██████████| 15/15 [00:28<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<21:13,  2.40s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:08,  2.17s/it]predicting train subjects:   1%|          | 3/532 [00:05<17:57,  2.04s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:09,  1.95s/it]predicting train subjects:   1%|          | 5/532 [00:09<16:44,  1.91s/it]predicting train subjects:   1%|          | 6/532 [00:10<15:51,  1.81s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<15:45,  1.80s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:25,  1.77s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<15:56,  1.83s/it]predicting train subjects:   2%|▏         | 10/532 [00:17<15:26,  1.77s/it]predicting train subjects:   2%|▏         | 11/532 [00:19<14:46,  1.70s/it]predicting train subjects:   2%|▏         | 12/532 [00:21<16:02,  1.85s/it]predicting train subjects:   2%|▏         | 13/532 [00:23<15:02,  1.74s/it]predicting train subjects:   3%|▎         | 14/532 [00:24<14:31,  1.68s/it]predicting train subjects:   3%|▎         | 15/532 [00:26<14:36,  1.70s/it]predicting train subjects:   3%|▎         | 16/532 [00:28<15:08,  1.76s/it]predicting train subjects:   3%|▎         | 17/532 [00:29<14:24,  1.68s/it]predicting train subjects:   3%|▎         | 18/532 [00:31<15:08,  1.77s/it]predicting train subjects:   4%|▎         | 19/532 [00:33<14:10,  1.66s/it]predicting train subjects:   4%|▍         | 20/532 [00:35<14:26,  1.69s/it]predicting train subjects:   4%|▍         | 21/532 [00:36<15:04,  1.77s/it]predicting train subjects:   4%|▍         | 22/532 [00:38<14:19,  1.69s/it]predicting train subjects:   4%|▍         | 23/532 [00:40<14:35,  1.72s/it]predicting train subjects:   5%|▍         | 24/532 [00:41<13:54,  1.64s/it]predicting train subjects:   5%|▍         | 25/532 [00:43<15:21,  1.82s/it]predicting train subjects:   5%|▍         | 26/532 [00:45<14:49,  1.76s/it]predicting train subjects:   5%|▌         | 27/532 [00:47<15:57,  1.90s/it]predicting train subjects:   5%|▌         | 28/532 [00:49<15:29,  1.85s/it]predicting train subjects:   5%|▌         | 29/532 [00:51<16:03,  1.92s/it]predicting train subjects:   6%|▌         | 30/532 [00:53<15:02,  1.80s/it]predicting train subjects:   6%|▌         | 31/532 [00:54<15:03,  1.80s/it]predicting train subjects:   6%|▌         | 32/532 [00:56<14:44,  1.77s/it]predicting train subjects:   6%|▌         | 33/532 [00:58<14:07,  1.70s/it]predicting train subjects:   6%|▋         | 34/532 [01:00<15:12,  1.83s/it]predicting train subjects:   7%|▋         | 35/532 [01:02<15:02,  1.82s/it]predicting train subjects:   7%|▋         | 36/532 [01:04<15:32,  1.88s/it]predicting train subjects:   7%|▋         | 37/532 [01:05<15:24,  1.87s/it]predicting train subjects:   7%|▋         | 38/532 [01:07<15:37,  1.90s/it]predicting train subjects:   7%|▋         | 39/532 [01:09<15:03,  1.83s/it]predicting train subjects:   8%|▊         | 40/532 [01:11<14:26,  1.76s/it]predicting train subjects:   8%|▊         | 41/532 [01:13<14:33,  1.78s/it]predicting train subjects:   8%|▊         | 42/532 [01:14<14:42,  1.80s/it]predicting train subjects:   8%|▊         | 43/532 [01:16<13:48,  1.69s/it]predicting train subjects:   8%|▊         | 44/532 [01:17<13:09,  1.62s/it]predicting train subjects:   8%|▊         | 45/532 [01:19<13:10,  1.62s/it]predicting train subjects:   9%|▊         | 46/532 [01:21<13:49,  1.71s/it]predicting train subjects:   9%|▉         | 47/532 [01:23<15:15,  1.89s/it]predicting train subjects:   9%|▉         | 48/532 [01:25<15:18,  1.90s/it]predicting train subjects:   9%|▉         | 49/532 [01:27<14:29,  1.80s/it]predicting train subjects:   9%|▉         | 50/532 [01:29<15:03,  1.87s/it]predicting train subjects:  10%|▉         | 51/532 [01:30<14:48,  1.85s/it]predicting train subjects:  10%|▉         | 52/532 [01:32<14:42,  1.84s/it]predicting train subjects:  10%|▉         | 53/532 [01:34<14:15,  1.79s/it]predicting train subjects:  10%|█         | 54/532 [01:36<14:39,  1.84s/it]predicting train subjects:  10%|█         | 55/532 [01:38<14:35,  1.84s/it]predicting train subjects:  11%|█         | 56/532 [01:40<14:30,  1.83s/it]predicting train subjects:  11%|█         | 57/532 [01:41<14:29,  1.83s/it]predicting train subjects:  11%|█         | 58/532 [01:43<14:35,  1.85s/it]predicting train subjects:  11%|█         | 59/532 [01:45<15:24,  1.95s/it]predicting train subjects:  11%|█▏        | 60/532 [01:47<14:00,  1.78s/it]predicting train subjects:  11%|█▏        | 61/532 [01:48<13:33,  1.73s/it]predicting train subjects:  12%|█▏        | 62/532 [01:50<14:16,  1.82s/it]predicting train subjects:  12%|█▏        | 63/532 [01:53<14:55,  1.91s/it]predicting train subjects:  12%|█▏        | 64/532 [01:54<14:00,  1.80s/it]predicting train subjects:  12%|█▏        | 65/532 [01:56<13:59,  1.80s/it]predicting train subjects:  12%|█▏        | 66/532 [01:58<15:08,  1.95s/it]predicting train subjects:  13%|█▎        | 67/532 [02:00<15:36,  2.01s/it]predicting train subjects:  13%|█▎        | 68/532 [02:02<15:09,  1.96s/it]predicting train subjects:  13%|█▎        | 69/532 [02:04<14:24,  1.87s/it]predicting train subjects:  13%|█▎        | 70/532 [02:05<13:50,  1.80s/it]predicting train subjects:  13%|█▎        | 71/532 [02:07<13:20,  1.74s/it]predicting train subjects:  14%|█▎        | 72/532 [02:09<12:45,  1.66s/it]predicting train subjects:  14%|█▎        | 73/532 [02:10<13:12,  1.73s/it]predicting train subjects:  14%|█▍        | 74/532 [02:13<14:30,  1.90s/it]predicting train subjects:  14%|█▍        | 75/532 [02:16<16:39,  2.19s/it]predicting train subjects:  14%|█▍        | 76/532 [02:17<15:41,  2.07s/it]predicting train subjects:  14%|█▍        | 77/532 [02:19<15:03,  1.99s/it]predicting train subjects:  15%|█▍        | 78/532 [02:21<14:48,  1.96s/it]predicting train subjects:  15%|█▍        | 79/532 [02:23<14:31,  1.92s/it]predicting train subjects:  15%|█▌        | 80/532 [02:25<14:32,  1.93s/it]predicting train subjects:  15%|█▌        | 81/532 [02:27<14:09,  1.88s/it]predicting train subjects:  15%|█▌        | 82/532 [02:29<14:05,  1.88s/it]predicting train subjects:  16%|█▌        | 83/532 [02:30<13:13,  1.77s/it]predicting train subjects:  16%|█▌        | 84/532 [02:32<12:42,  1.70s/it]predicting train subjects:  16%|█▌        | 85/532 [02:33<12:25,  1.67s/it]predicting train subjects:  16%|█▌        | 86/532 [02:35<12:09,  1.64s/it]predicting train subjects:  16%|█▋        | 87/532 [02:36<12:06,  1.63s/it]predicting train subjects:  17%|█▋        | 88/532 [02:38<11:59,  1.62s/it]predicting train subjects:  17%|█▋        | 89/532 [02:40<12:23,  1.68s/it]predicting train subjects:  17%|█▋        | 90/532 [02:41<12:25,  1.69s/it]predicting train subjects:  17%|█▋        | 91/532 [02:43<12:30,  1.70s/it]predicting train subjects:  17%|█▋        | 92/532 [02:45<12:30,  1.71s/it]predicting train subjects:  17%|█▋        | 93/532 [02:47<12:28,  1.71s/it]predicting train subjects:  18%|█▊        | 94/532 [02:48<12:26,  1.70s/it]predicting train subjects:  18%|█▊        | 95/532 [02:50<13:10,  1.81s/it]predicting train subjects:  18%|█▊        | 96/532 [02:52<13:30,  1.86s/it]predicting train subjects:  18%|█▊        | 97/532 [02:54<14:03,  1.94s/it]predicting train subjects:  18%|█▊        | 98/532 [02:57<14:17,  1.97s/it]predicting train subjects:  19%|█▊        | 99/532 [02:59<14:20,  1.99s/it]predicting train subjects:  19%|█▉        | 100/532 [03:01<14:29,  2.01s/it]predicting train subjects:  19%|█▉        | 101/532 [03:02<13:28,  1.88s/it]predicting train subjects:  19%|█▉        | 102/532 [03:04<12:44,  1.78s/it]predicting train subjects:  19%|█▉        | 103/532 [03:05<12:06,  1.69s/it]predicting train subjects:  20%|█▉        | 104/532 [03:07<11:41,  1.64s/it]predicting train subjects:  20%|█▉        | 105/532 [03:08<11:26,  1.61s/it]predicting train subjects:  20%|█▉        | 106/532 [03:10<11:14,  1.58s/it]predicting train subjects:  20%|██        | 107/532 [03:11<11:07,  1.57s/it]predicting train subjects:  20%|██        | 108/532 [03:13<11:07,  1.57s/it]predicting train subjects:  20%|██        | 109/532 [03:14<10:55,  1.55s/it]predicting train subjects:  21%|██        | 110/532 [03:16<10:48,  1.54s/it]predicting train subjects:  21%|██        | 111/532 [03:17<10:38,  1.52s/it]predicting train subjects:  21%|██        | 112/532 [03:19<10:32,  1.51s/it]predicting train subjects:  21%|██        | 113/532 [03:21<11:08,  1.59s/it]predicting train subjects:  21%|██▏       | 114/532 [03:22<11:31,  1.65s/it]predicting train subjects:  22%|██▏       | 115/532 [03:24<11:54,  1.71s/it]predicting train subjects:  22%|██▏       | 116/532 [03:26<12:01,  1.74s/it]predicting train subjects:  22%|██▏       | 117/532 [03:28<12:12,  1.76s/it]predicting train subjects:  22%|██▏       | 118/532 [03:30<12:21,  1.79s/it]predicting train subjects:  22%|██▏       | 119/532 [03:32<12:18,  1.79s/it]predicting train subjects:  23%|██▎       | 120/532 [03:33<12:14,  1.78s/it]predicting train subjects:  23%|██▎       | 121/532 [03:35<12:12,  1.78s/it]predicting train subjects:  23%|██▎       | 122/532 [03:37<12:11,  1.79s/it]predicting train subjects:  23%|██▎       | 123/532 [03:39<12:09,  1.78s/it]predicting train subjects:  23%|██▎       | 124/532 [03:40<12:03,  1.77s/it]predicting train subjects:  23%|██▎       | 125/532 [03:42<12:16,  1.81s/it]predicting train subjects:  24%|██▎       | 126/532 [03:44<12:43,  1.88s/it]predicting train subjects:  24%|██▍       | 127/532 [03:46<12:51,  1.90s/it]predicting train subjects:  24%|██▍       | 128/532 [03:48<12:38,  1.88s/it]predicting train subjects:  24%|██▍       | 129/532 [03:50<12:32,  1.87s/it]predicting train subjects:  24%|██▍       | 130/532 [03:52<12:24,  1.85s/it]predicting train subjects:  25%|██▍       | 131/532 [03:54<13:04,  1.96s/it]predicting train subjects:  25%|██▍       | 132/532 [03:56<13:31,  2.03s/it]predicting train subjects:  25%|██▌       | 133/532 [03:58<13:50,  2.08s/it]predicting train subjects:  25%|██▌       | 134/532 [04:01<14:10,  2.14s/it]predicting train subjects:  25%|██▌       | 135/532 [04:03<14:15,  2.15s/it]predicting train subjects:  26%|██▌       | 136/532 [04:05<14:15,  2.16s/it]predicting train subjects:  26%|██▌       | 137/532 [04:07<14:28,  2.20s/it]predicting train subjects:  26%|██▌       | 138/532 [04:10<14:35,  2.22s/it]predicting train subjects:  26%|██▌       | 139/532 [04:12<14:37,  2.23s/it]predicting train subjects:  26%|██▋       | 140/532 [04:14<14:40,  2.25s/it]predicting train subjects:  27%|██▋       | 141/532 [04:16<14:43,  2.26s/it]predicting train subjects:  27%|██▋       | 142/532 [04:19<14:44,  2.27s/it]predicting train subjects:  27%|██▋       | 143/532 [04:20<13:35,  2.10s/it]predicting train subjects:  27%|██▋       | 144/532 [04:22<12:39,  1.96s/it]predicting train subjects:  27%|██▋       | 145/532 [04:24<11:54,  1.85s/it]predicting train subjects:  27%|██▋       | 146/532 [04:25<11:31,  1.79s/it]predicting train subjects:  28%|██▊       | 147/532 [04:27<11:11,  1.74s/it]predicting train subjects:  28%|██▊       | 148/532 [04:29<10:51,  1.70s/it]predicting train subjects:  28%|██▊       | 149/532 [04:30<10:46,  1.69s/it]predicting train subjects:  28%|██▊       | 150/532 [04:32<10:49,  1.70s/it]predicting train subjects:  28%|██▊       | 151/532 [04:34<10:50,  1.71s/it]predicting train subjects:  29%|██▊       | 152/532 [04:35<10:51,  1.71s/it]predicting train subjects:  29%|██▉       | 153/532 [04:37<10:46,  1.71s/it]predicting train subjects:  29%|██▉       | 154/532 [04:39<10:43,  1.70s/it]predicting train subjects:  29%|██▉       | 155/532 [04:41<11:52,  1.89s/it]predicting train subjects:  29%|██▉       | 156/532 [04:43<12:35,  2.01s/it]predicting train subjects:  30%|██▉       | 157/532 [04:46<13:07,  2.10s/it]predicting train subjects:  30%|██▉       | 158/532 [04:48<13:32,  2.17s/it]predicting train subjects:  30%|██▉       | 159/532 [04:50<13:35,  2.19s/it]predicting train subjects:  30%|███       | 160/532 [04:52<13:39,  2.20s/it]predicting train subjects:  30%|███       | 161/532 [04:54<12:38,  2.04s/it]predicting train subjects:  30%|███       | 162/532 [04:56<11:58,  1.94s/it]predicting train subjects:  31%|███       | 163/532 [04:58<11:27,  1.86s/it]predicting train subjects:  31%|███       | 164/532 [04:59<11:16,  1.84s/it]predicting train subjects:  31%|███       | 165/532 [05:01<11:06,  1.81s/it]predicting train subjects:  31%|███       | 166/532 [05:03<10:54,  1.79s/it]predicting train subjects:  31%|███▏      | 167/532 [05:05<10:53,  1.79s/it]predicting train subjects:  32%|███▏      | 168/532 [05:06<10:48,  1.78s/it]predicting train subjects:  32%|███▏      | 169/532 [05:08<10:43,  1.77s/it]predicting train subjects:  32%|███▏      | 170/532 [05:10<10:38,  1.76s/it]predicting train subjects:  32%|███▏      | 171/532 [05:12<10:46,  1.79s/it]predicting train subjects:  32%|███▏      | 172/532 [05:14<10:49,  1.80s/it]predicting train subjects:  33%|███▎      | 173/532 [05:15<10:26,  1.75s/it]predicting train subjects:  33%|███▎      | 174/532 [05:17<10:05,  1.69s/it]predicting train subjects:  33%|███▎      | 175/532 [05:18<09:52,  1.66s/it]predicting train subjects:  33%|███▎      | 176/532 [05:20<09:40,  1.63s/it]predicting train subjects:  33%|███▎      | 177/532 [05:22<09:40,  1.63s/it]predicting train subjects:  33%|███▎      | 178/532 [05:23<09:31,  1.61s/it]predicting train subjects:  34%|███▎      | 179/532 [05:25<09:36,  1.63s/it]predicting train subjects:  34%|███▍      | 180/532 [05:26<09:43,  1.66s/it]predicting train subjects:  34%|███▍      | 181/532 [05:28<09:45,  1.67s/it]predicting train subjects:  34%|███▍      | 182/532 [05:30<09:34,  1.64s/it]predicting train subjects:  34%|███▍      | 183/532 [05:31<09:31,  1.64s/it]predicting train subjects:  35%|███▍      | 184/532 [05:33<09:33,  1.65s/it]predicting train subjects:  35%|███▍      | 185/532 [05:35<09:26,  1.63s/it]predicting train subjects:  35%|███▍      | 186/532 [05:36<09:16,  1.61s/it]predicting train subjects:  35%|███▌      | 187/532 [05:38<09:12,  1.60s/it]predicting train subjects:  35%|███▌      | 188/532 [05:39<09:21,  1.63s/it]predicting train subjects:  36%|███▌      | 189/532 [05:41<09:20,  1.63s/it]predicting train subjects:  36%|███▌      | 190/532 [05:43<09:11,  1.61s/it]predicting train subjects:  36%|███▌      | 191/532 [05:45<10:21,  1.82s/it]predicting train subjects:  36%|███▌      | 192/532 [05:47<11:08,  1.97s/it]predicting train subjects:  36%|███▋      | 193/532 [05:50<11:49,  2.09s/it]predicting train subjects:  36%|███▋      | 194/532 [05:52<12:17,  2.18s/it]predicting train subjects:  37%|███▋      | 195/532 [05:54<12:29,  2.22s/it]predicting train subjects:  37%|███▋      | 196/532 [05:57<12:37,  2.26s/it]predicting train subjects:  37%|███▋      | 197/532 [05:59<12:10,  2.18s/it]predicting train subjects:  37%|███▋      | 198/532 [06:01<11:54,  2.14s/it]predicting train subjects:  37%|███▋      | 199/532 [06:03<11:50,  2.13s/it]predicting train subjects:  38%|███▊      | 200/532 [06:05<11:28,  2.07s/it]predicting train subjects:  38%|███▊      | 201/532 [06:07<11:14,  2.04s/it]predicting train subjects:  38%|███▊      | 202/532 [06:09<11:05,  2.02s/it]predicting train subjects:  38%|███▊      | 203/532 [06:10<10:29,  1.91s/it]predicting train subjects:  38%|███▊      | 204/532 [06:12<10:08,  1.86s/it]predicting train subjects:  39%|███▊      | 205/532 [06:14<09:47,  1.80s/it]predicting train subjects:  39%|███▊      | 206/532 [06:16<09:41,  1.78s/it]predicting train subjects:  39%|███▉      | 207/532 [06:17<09:37,  1.78s/it]predicting train subjects:  39%|███▉      | 208/532 [06:19<09:32,  1.77s/it]predicting train subjects:  39%|███▉      | 209/532 [06:21<09:06,  1.69s/it]predicting train subjects:  39%|███▉      | 210/532 [06:22<08:44,  1.63s/it]predicting train subjects:  40%|███▉      | 211/532 [06:24<08:29,  1.59s/it]predicting train subjects:  40%|███▉      | 212/532 [06:25<08:21,  1.57s/it]predicting train subjects:  40%|████      | 213/532 [06:27<08:14,  1.55s/it]predicting train subjects:  40%|████      | 214/532 [06:28<08:07,  1.53s/it]predicting train subjects:  40%|████      | 215/532 [06:30<09:20,  1.77s/it]predicting train subjects:  41%|████      | 216/532 [06:33<10:02,  1.91s/it]predicting train subjects:  41%|████      | 217/532 [06:35<10:43,  2.04s/it]predicting train subjects:  41%|████      | 218/532 [06:37<10:49,  2.07s/it]predicting train subjects:  41%|████      | 219/532 [06:39<11:04,  2.12s/it]predicting train subjects:  41%|████▏     | 220/532 [06:42<11:09,  2.15s/it]predicting train subjects:  42%|████▏     | 221/532 [06:43<10:00,  1.93s/it]predicting train subjects:  42%|████▏     | 222/532 [06:44<09:11,  1.78s/it]predicting train subjects:  42%|████▏     | 223/532 [06:46<08:42,  1.69s/it]predicting train subjects:  42%|████▏     | 224/532 [06:47<08:18,  1.62s/it]predicting train subjects:  42%|████▏     | 225/532 [06:49<08:01,  1.57s/it]predicting train subjects:  42%|████▏     | 226/532 [06:50<07:53,  1.55s/it]predicting train subjects:  43%|████▎     | 227/532 [06:52<07:37,  1.50s/it]predicting train subjects:  43%|████▎     | 228/532 [06:53<07:27,  1.47s/it]predicting train subjects:  43%|████▎     | 229/532 [06:55<07:21,  1.46s/it]predicting train subjects:  43%|████▎     | 230/532 [06:56<07:18,  1.45s/it]predicting train subjects:  43%|████▎     | 231/532 [06:57<07:16,  1.45s/it]predicting train subjects:  44%|████▎     | 232/532 [06:59<07:11,  1.44s/it]predicting train subjects:  44%|████▍     | 233/532 [07:00<07:26,  1.49s/it]predicting train subjects:  44%|████▍     | 234/532 [07:02<07:39,  1.54s/it]predicting train subjects:  44%|████▍     | 235/532 [07:04<07:50,  1.58s/it]predicting train subjects:  44%|████▍     | 236/532 [07:05<08:00,  1.62s/it]predicting train subjects:  45%|████▍     | 237/532 [07:07<08:04,  1.64s/it]predicting train subjects:  45%|████▍     | 238/532 [07:09<08:17,  1.69s/it]predicting train subjects:  45%|████▍     | 239/532 [07:11<08:32,  1.75s/it]predicting train subjects:  45%|████▌     | 240/532 [07:13<08:42,  1.79s/it]predicting train subjects:  45%|████▌     | 241/532 [07:15<08:53,  1.83s/it]predicting train subjects:  45%|████▌     | 242/532 [07:17<08:54,  1.84s/it]predicting train subjects:  46%|████▌     | 243/532 [07:18<09:00,  1.87s/it]predicting train subjects:  46%|████▌     | 244/532 [07:20<08:59,  1.87s/it]predicting train subjects:  46%|████▌     | 245/532 [07:22<08:25,  1.76s/it]predicting train subjects:  46%|████▌     | 246/532 [07:23<07:57,  1.67s/it]predicting train subjects:  46%|████▋     | 247/532 [07:25<07:35,  1.60s/it]predicting train subjects:  47%|████▋     | 248/532 [07:26<07:20,  1.55s/it]predicting train subjects:  47%|████▋     | 249/532 [07:28<07:12,  1.53s/it]predicting train subjects:  47%|████▋     | 250/532 [07:29<06:59,  1.49s/it]predicting train subjects:  47%|████▋     | 251/532 [07:31<07:04,  1.51s/it]predicting train subjects:  47%|████▋     | 252/532 [07:32<07:15,  1.56s/it]predicting train subjects:  48%|████▊     | 253/532 [07:34<07:23,  1.59s/it]predicting train subjects:  48%|████▊     | 254/532 [07:36<07:18,  1.58s/it]predicting train subjects:  48%|████▊     | 255/532 [07:37<07:15,  1.57s/it]predicting train subjects:  48%|████▊     | 256/532 [07:39<07:19,  1.59s/it]predicting train subjects:  48%|████▊     | 257/532 [07:41<07:52,  1.72s/it]predicting train subjects:  48%|████▊     | 258/532 [07:43<08:17,  1.82s/it]predicting train subjects:  49%|████▊     | 259/532 [07:45<08:29,  1.87s/it]predicting train subjects:  49%|████▉     | 260/532 [07:47<08:46,  1.93s/it]predicting train subjects:  49%|████▉     | 261/532 [07:49<08:44,  1.94s/it]predicting train subjects:  49%|████▉     | 262/532 [07:51<08:52,  1.97s/it]predicting train subjects:  49%|████▉     | 263/532 [07:52<08:07,  1.81s/it]predicting train subjects:  50%|████▉     | 264/532 [07:54<07:34,  1.70s/it]predicting train subjects:  50%|████▉     | 265/532 [07:55<07:09,  1.61s/it]predicting train subjects:  50%|█████     | 266/532 [07:57<06:54,  1.56s/it]predicting train subjects:  50%|█████     | 267/532 [07:58<06:42,  1.52s/it]predicting train subjects:  50%|█████     | 268/532 [07:59<06:30,  1.48s/it]predicting train subjects:  51%|█████     | 269/532 [08:01<06:50,  1.56s/it]predicting train subjects:  51%|█████     | 270/532 [08:03<07:03,  1.62s/it]predicting train subjects:  51%|█████     | 271/532 [08:05<07:15,  1.67s/it]predicting train subjects:  51%|█████     | 272/532 [08:06<07:19,  1.69s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:08<07:23,  1.71s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:10<07:32,  1.75s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:12<08:08,  1.90s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:15<08:36,  2.02s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:17<08:49,  2.08s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:19<09:04,  2.14s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:21<09:08,  2.17s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:24<09:18,  2.22s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:26<09:05,  2.17s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:28<08:59,  2.16s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:30<08:54,  2.15s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:32<08:38,  2.09s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:34<08:30,  2.07s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:36<08:28,  2.07s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:38<07:50,  1.92s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:39<07:28,  1.84s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:41<07:15,  1.79s/it]predicting train subjects:  55%|█████▍    | 290/532 [08:43<07:10,  1.78s/it]predicting train subjects:  55%|█████▍    | 291/532 [08:44<07:07,  1.78s/it]predicting train subjects:  55%|█████▍    | 292/532 [08:46<07:00,  1.75s/it]predicting train subjects:  55%|█████▌    | 293/532 [08:48<07:12,  1.81s/it]predicting train subjects:  55%|█████▌    | 294/532 [08:50<07:21,  1.85s/it]predicting train subjects:  55%|█████▌    | 295/532 [08:52<07:35,  1.92s/it]predicting train subjects:  56%|█████▌    | 296/532 [08:54<07:29,  1.91s/it]predicting train subjects:  56%|█████▌    | 297/532 [08:56<07:24,  1.89s/it]predicting train subjects:  56%|█████▌    | 298/532 [08:58<07:20,  1.88s/it]predicting train subjects:  56%|█████▌    | 299/532 [08:59<06:55,  1.78s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:01<06:40,  1.73s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:02<06:34,  1.71s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:04<06:30,  1.70s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:06<06:18,  1.65s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:07<06:12,  1.63s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:10<06:52,  1.82s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:12<07:31,  2.00s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:14<07:56,  2.12s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:17<08:04,  2.16s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:19<08:18,  2.23s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:21<08:31,  2.31s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:25<09:24,  2.55s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:28<10:06,  2.76s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:31<10:32,  2.89s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:34<10:57,  3.01s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:38<11:08,  3.08s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:41<11:06,  3.09s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:42<09:40,  2.70s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:44<08:33,  2.40s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:46<07:55,  2.23s/it]predicting train subjects:  60%|██████    | 320/532 [09:48<07:35,  2.15s/it]predicting train subjects:  60%|██████    | 321/532 [09:50<07:24,  2.11s/it]predicting train subjects:  61%|██████    | 322/532 [09:52<07:10,  2.05s/it]predicting train subjects:  61%|██████    | 323/532 [09:55<07:50,  2.25s/it]predicting train subjects:  61%|██████    | 324/532 [09:57<08:18,  2.40s/it]predicting train subjects:  61%|██████    | 325/532 [10:00<08:34,  2.48s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:03<08:37,  2.51s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:05<08:55,  2.61s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:08<09:03,  2.66s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:10<08:23,  2.48s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:12<07:52,  2.34s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:15<07:49,  2.33s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:17<07:23,  2.22s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:19<07:12,  2.17s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:21<06:58,  2.12s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:23<07:16,  2.22s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:25<07:21,  2.25s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:28<07:31,  2.32s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:30<07:35,  2.35s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:32<07:23,  2.30s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:35<07:25,  2.32s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:37<06:49,  2.14s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:38<06:27,  2.04s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:40<06:25,  2.04s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:42<06:12,  1.98s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:44<05:55,  1.90s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:46<05:52,  1.89s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:48<05:55,  1.92s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:50<05:52,  1.92s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:52<05:56,  1.95s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:54<05:59,  1.98s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:56<06:07,  2.03s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:58<05:58,  1.99s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:00<05:58,  2.00s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:02<05:54,  1.99s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:04<05:47,  1.96s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:06<05:45,  1.96s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:08<05:40,  1.94s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:10<05:41,  1.96s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:11<05:24,  1.88s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:13<05:20,  1.86s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:15<05:08,  1.80s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:17<05:04,  1.79s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:18<04:53,  1.74s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:20<04:49,  1.72s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:21<04:41,  1.69s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:23<04:37,  1.67s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:25<04:33,  1.66s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:26<04:31,  1.66s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:28<04:32,  1.67s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:30<04:33,  1.69s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:32<05:12,  1.94s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:35<05:32,  2.08s/it]predicting train subjects:  70%|███████   | 373/532 [11:37<05:48,  2.19s/it]predicting train subjects:  70%|███████   | 374/532 [11:39<05:50,  2.22s/it]predicting train subjects:  70%|███████   | 375/532 [11:42<05:50,  2.23s/it]predicting train subjects:  71%|███████   | 376/532 [11:44<05:55,  2.28s/it]predicting train subjects:  71%|███████   | 377/532 [11:46<05:38,  2.19s/it]predicting train subjects:  71%|███████   | 378/532 [11:48<05:30,  2.15s/it]predicting train subjects:  71%|███████   | 379/532 [11:50<05:16,  2.07s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:52<05:04,  2.00s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:54<05:07,  2.03s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:56<05:02,  2.01s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:58<05:02,  2.03s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:00<04:59,  2.02s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:02<04:54,  2.00s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:04<04:49,  1.99s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:06<04:46,  1.97s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:08<04:41,  1.96s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:10<04:41,  1.97s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:12<04:44,  2.01s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:14<04:47,  2.04s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:16<04:49,  2.07s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:18<04:50,  2.09s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:20<04:44,  2.06s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:22<04:40,  2.04s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:24<04:36,  2.04s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:26<04:29,  2.00s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:28<04:25,  1.98s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:30<04:24,  1.99s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:32<04:25,  2.01s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:34<04:31,  2.07s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:37<04:31,  2.09s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:39<04:32,  2.11s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:41<04:42,  2.21s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:43<04:39,  2.20s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:45<04:35,  2.18s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:47<04:19,  2.08s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:49<04:11,  2.03s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:51<04:01,  1.96s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:53<03:57,  1.94s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:55<03:54,  1.94s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:57<03:49,  1.91s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:59<03:47,  1.91s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:00<03:41,  1.88s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:02<03:35,  1.84s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:04<03:32,  1.83s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:06<03:27,  1.81s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:07<03:20,  1.76s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:09<03:24,  1.81s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:11<03:30,  1.88s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:13<03:33,  1.93s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:15<03:34,  1.95s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:17<03:30,  1.93s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:19<03:27,  1.92s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:21<03:27,  1.94s/it]predicting train subjects:  80%|████████  | 426/532 [13:23<03:24,  1.93s/it]predicting train subjects:  80%|████████  | 427/532 [13:25<03:23,  1.93s/it]predicting train subjects:  80%|████████  | 428/532 [13:27<03:19,  1.92s/it]predicting train subjects:  81%|████████  | 429/532 [13:29<03:18,  1.93s/it]predicting train subjects:  81%|████████  | 430/532 [13:31<03:15,  1.92s/it]predicting train subjects:  81%|████████  | 431/532 [13:33<03:19,  1.97s/it]predicting train subjects:  81%|████████  | 432/532 [13:35<03:19,  2.00s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:37<03:18,  2.01s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:39<03:18,  2.03s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:41<03:17,  2.03s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:43<03:16,  2.05s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:45<03:00,  1.90s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:46<02:49,  1.80s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:48<02:41,  1.73s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:49<02:34,  1.68s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:51<02:29,  1.65s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:53<02:27,  1.64s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:54<02:21,  1.60s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:56<02:17,  1.56s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:57<02:11,  1.52s/it]predicting train subjects:  84%|████████▍ | 446/532 [13:58<02:08,  1.49s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:00<02:05,  1.48s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:01<02:02,  1.46s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:03<02:06,  1.52s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:05<02:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:06<02:09,  1.60s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:08<02:08,  1.60s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:10<02:07,  1.62s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:11<02:06,  1.63s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:13<02:12,  1.72s/it]predicting train subjects:  86%|████████▌ | 456/532 [14:15<02:13,  1.76s/it]predicting train subjects:  86%|████████▌ | 457/532 [14:17<02:14,  1.79s/it]predicting train subjects:  86%|████████▌ | 458/532 [14:19<02:13,  1.81s/it]predicting train subjects:  86%|████████▋ | 459/532 [14:21<02:12,  1.82s/it]predicting train subjects:  86%|████████▋ | 460/532 [14:22<02:11,  1.83s/it]predicting train subjects:  87%|████████▋ | 461/532 [14:25<02:18,  1.95s/it]predicting train subjects:  87%|████████▋ | 462/532 [14:27<02:22,  2.04s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:29<02:24,  2.10s/it]predicting train subjects:  87%|████████▋ | 464/532 [14:31<02:27,  2.17s/it]predicting train subjects:  87%|████████▋ | 465/532 [14:34<02:28,  2.21s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:36<02:27,  2.24s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:38<02:17,  2.11s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:40<02:10,  2.04s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:42<02:03,  1.96s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:43<01:59,  1.92s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:45<01:56,  1.91s/it]predicting train subjects:  89%|████████▊ | 472/532 [14:47<01:52,  1.88s/it]predicting train subjects:  89%|████████▉ | 473/532 [14:49<01:54,  1.94s/it]predicting train subjects:  89%|████████▉ | 474/532 [14:51<01:53,  1.95s/it]predicting train subjects:  89%|████████▉ | 475/532 [14:53<01:52,  1.97s/it]predicting train subjects:  89%|████████▉ | 476/532 [14:55<01:50,  1.97s/it]predicting train subjects:  90%|████████▉ | 477/532 [14:57<01:46,  1.94s/it]predicting train subjects:  90%|████████▉ | 478/532 [14:59<01:45,  1.95s/it]predicting train subjects:  90%|█████████ | 479/532 [15:01<01:39,  1.87s/it]predicting train subjects:  90%|█████████ | 480/532 [15:02<01:33,  1.80s/it]predicting train subjects:  90%|█████████ | 481/532 [15:04<01:29,  1.76s/it]predicting train subjects:  91%|█████████ | 482/532 [15:06<01:25,  1.72s/it]predicting train subjects:  91%|█████████ | 483/532 [15:07<01:23,  1.71s/it]predicting train subjects:  91%|█████████ | 484/532 [15:09<01:21,  1.69s/it]predicting train subjects:  91%|█████████ | 485/532 [15:11<01:26,  1.84s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:13<01:29,  1.95s/it]predicting train subjects:  92%|█████████▏| 487/532 [15:15<01:30,  2.01s/it]predicting train subjects:  92%|█████████▏| 488/532 [15:18<01:30,  2.07s/it]predicting train subjects:  92%|█████████▏| 489/532 [15:20<01:30,  2.11s/it]predicting train subjects:  92%|█████████▏| 490/532 [15:22<01:29,  2.14s/it]predicting train subjects:  92%|█████████▏| 491/532 [15:24<01:24,  2.05s/it]predicting train subjects:  92%|█████████▏| 492/532 [15:26<01:18,  1.97s/it]predicting train subjects:  93%|█████████▎| 493/532 [15:27<01:15,  1.93s/it]predicting train subjects:  93%|█████████▎| 494/532 [15:29<01:11,  1.89s/it]predicting train subjects:  93%|█████████▎| 495/532 [15:31<01:08,  1.86s/it]predicting train subjects:  93%|█████████▎| 496/532 [15:33<01:06,  1.85s/it]predicting train subjects:  93%|█████████▎| 497/532 [15:35<01:05,  1.88s/it]predicting train subjects:  94%|█████████▎| 498/532 [15:37<01:04,  1.89s/it]predicting train subjects:  94%|█████████▍| 499/532 [15:39<01:02,  1.89s/it]predicting train subjects:  94%|█████████▍| 500/532 [15:41<01:00,  1.89s/it]predicting train subjects:  94%|█████████▍| 501/532 [15:42<00:58,  1.90s/it]predicting train subjects:  94%|█████████▍| 502/532 [15:45<00:57,  1.93s/it]predicting train subjects:  95%|█████████▍| 503/532 [15:46<00:55,  1.91s/it]predicting train subjects:  95%|█████████▍| 504/532 [15:48<00:52,  1.88s/it]predicting train subjects:  95%|█████████▍| 505/532 [15:50<00:49,  1.83s/it]predicting train subjects:  95%|█████████▌| 506/532 [15:52<00:46,  1.80s/it]predicting train subjects:  95%|█████████▌| 507/532 [15:53<00:43,  1.75s/it]predicting train subjects:  95%|█████████▌| 508/532 [15:55<00:41,  1.72s/it]predicting train subjects:  96%|█████████▌| 509/532 [15:57<00:42,  1.84s/it]predicting train subjects:  96%|█████████▌| 510/532 [15:59<00:42,  1.93s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:01<00:41,  1.98s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:03<00:40,  2.02s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:06<00:39,  2.08s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:08<00:37,  2.10s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:09<00:33,  2.00s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:11<00:30,  1.91s/it]predicting train subjects:  97%|█████████▋| 517/532 [16:13<00:27,  1.86s/it]predicting train subjects:  97%|█████████▋| 518/532 [16:15<00:25,  1.81s/it]predicting train subjects:  98%|█████████▊| 519/532 [16:16<00:23,  1.78s/it]predicting train subjects:  98%|█████████▊| 520/532 [16:18<00:20,  1.74s/it]predicting train subjects:  98%|█████████▊| 521/532 [16:20<00:19,  1.78s/it]predicting train subjects:  98%|█████████▊| 522/532 [16:22<00:18,  1.83s/it]predicting train subjects:  98%|█████████▊| 523/532 [16:24<00:16,  1.87s/it]predicting train subjects:  98%|█████████▊| 524/532 [16:26<00:14,  1.86s/it]predicting train subjects:  99%|█████████▊| 525/532 [16:28<00:13,  1.88s/it]predicting train subjects:  99%|█████████▉| 526/532 [16:29<00:11,  1.87s/it]predicting train subjects:  99%|█████████▉| 527/532 [16:31<00:09,  1.82s/it]predicting train subjects:  99%|█████████▉| 528/532 [16:33<00:07,  1.79s/it]predicting train subjects:  99%|█████████▉| 529/532 [16:35<00:05,  1.78s/it]predicting train subjects: 100%|█████████▉| 530/532 [16:36<00:03,  1.76s/it]predicting train subjects: 100%|█████████▉| 531/532 [16:38<00:01,  1.75s/it]predicting train subjects: 100%|██████████| 532/532 [16:40<00:00,  1.74s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<14:26,  1.63s/it]Loading train:   0%|          | 2/532 [00:02<13:05,  1.48s/it]Loading train:   1%|          | 3/532 [00:03<12:21,  1.40s/it]Loading train:   1%|          | 4/532 [00:05<11:33,  1.31s/it]Loading train:   1%|          | 5/532 [00:06<11:02,  1.26s/it]Loading train:   1%|          | 6/532 [00:07<10:48,  1.23s/it]Loading train:   1%|▏         | 7/532 [00:08<10:10,  1.16s/it]Loading train:   2%|▏         | 8/532 [00:09<09:49,  1.13s/it]Loading train:   2%|▏         | 9/532 [00:10<10:13,  1.17s/it]Loading train:   2%|▏         | 10/532 [00:11<10:12,  1.17s/it]Loading train:   2%|▏         | 11/532 [00:12<09:35,  1.10s/it]Loading train:   2%|▏         | 12/532 [00:14<10:20,  1.19s/it]Loading train:   2%|▏         | 13/532 [00:15<10:07,  1.17s/it]Loading train:   3%|▎         | 14/532 [00:16<09:29,  1.10s/it]Loading train:   3%|▎         | 15/532 [00:17<09:15,  1.08s/it]Loading train:   3%|▎         | 16/532 [00:18<09:16,  1.08s/it]Loading train:   3%|▎         | 17/532 [00:19<08:57,  1.04s/it]Loading train:   3%|▎         | 18/532 [00:20<09:17,  1.08s/it]Loading train:   4%|▎         | 19/532 [00:21<08:50,  1.03s/it]Loading train:   4%|▍         | 20/532 [00:22<08:44,  1.02s/it]Loading train:   4%|▍         | 21/532 [00:23<09:03,  1.06s/it]Loading train:   4%|▍         | 22/532 [00:24<09:05,  1.07s/it]Loading train:   4%|▍         | 23/532 [00:25<08:57,  1.06s/it]Loading train:   5%|▍         | 24/532 [00:26<08:37,  1.02s/it]Loading train:   5%|▍         | 25/532 [00:27<09:19,  1.10s/it]Loading train:   5%|▍         | 26/532 [00:28<09:10,  1.09s/it]Loading train:   5%|▌         | 27/532 [00:30<09:46,  1.16s/it]Loading train:   5%|▌         | 28/532 [00:31<09:42,  1.16s/it]Loading train:   5%|▌         | 29/532 [00:32<09:29,  1.13s/it]Loading train:   6%|▌         | 30/532 [00:33<09:01,  1.08s/it]Loading train:   6%|▌         | 31/532 [00:34<09:04,  1.09s/it]Loading train:   6%|▌         | 32/532 [00:35<08:57,  1.08s/it]Loading train:   6%|▌         | 33/532 [00:36<08:47,  1.06s/it]Loading train:   6%|▋         | 34/532 [00:37<09:23,  1.13s/it]Loading train:   7%|▋         | 35/532 [00:38<08:58,  1.08s/it]Loading train:   7%|▋         | 36/532 [00:40<09:01,  1.09s/it]Loading train:   7%|▋         | 37/532 [00:41<08:59,  1.09s/it]Loading train:   7%|▋         | 38/532 [00:42<09:01,  1.10s/it]Loading train:   7%|▋         | 39/532 [00:43<08:49,  1.07s/it]Loading train:   8%|▊         | 40/532 [00:44<08:33,  1.04s/it]Loading train:   8%|▊         | 41/532 [00:45<08:46,  1.07s/it]Loading train:   8%|▊         | 42/532 [00:46<08:49,  1.08s/it]Loading train:   8%|▊         | 43/532 [00:47<08:22,  1.03s/it]Loading train:   8%|▊         | 44/532 [00:48<08:15,  1.02s/it]Loading train:   8%|▊         | 45/532 [00:49<08:14,  1.02s/it]Loading train:   9%|▊         | 46/532 [00:50<08:36,  1.06s/it]Loading train:   9%|▉         | 47/532 [00:51<09:08,  1.13s/it]Loading train:   9%|▉         | 48/532 [00:53<09:24,  1.17s/it]Loading train:   9%|▉         | 49/532 [00:54<08:49,  1.10s/it]Loading train:   9%|▉         | 50/532 [00:55<09:01,  1.12s/it]Loading train:  10%|▉         | 51/532 [00:56<08:50,  1.10s/it]Loading train:  10%|▉         | 52/532 [00:57<08:37,  1.08s/it]Loading train:  10%|▉         | 53/532 [00:58<08:31,  1.07s/it]Loading train:  10%|█         | 54/532 [00:59<08:46,  1.10s/it]Loading train:  10%|█         | 55/532 [01:00<08:57,  1.13s/it]Loading train:  11%|█         | 56/532 [01:01<08:44,  1.10s/it]Loading train:  11%|█         | 57/532 [01:02<08:26,  1.07s/it]Loading train:  11%|█         | 58/532 [01:03<08:26,  1.07s/it]Loading train:  11%|█         | 59/532 [01:05<09:00,  1.14s/it]Loading train:  11%|█▏        | 60/532 [01:06<08:29,  1.08s/it]Loading train:  11%|█▏        | 61/532 [01:06<08:08,  1.04s/it]Loading train:  12%|█▏        | 62/532 [01:08<08:26,  1.08s/it]Loading train:  12%|█▏        | 63/532 [01:09<08:52,  1.14s/it]Loading train:  12%|█▏        | 64/532 [01:10<08:37,  1.11s/it]Loading train:  12%|█▏        | 65/532 [01:11<08:32,  1.10s/it]Loading train:  12%|█▏        | 66/532 [01:12<08:54,  1.15s/it]Loading train:  13%|█▎        | 67/532 [01:14<08:58,  1.16s/it]Loading train:  13%|█▎        | 68/532 [01:15<08:39,  1.12s/it]Loading train:  13%|█▎        | 69/532 [01:16<08:30,  1.10s/it]Loading train:  13%|█▎        | 70/532 [01:17<08:23,  1.09s/it]Loading train:  13%|█▎        | 71/532 [01:18<08:06,  1.05s/it]Loading train:  14%|█▎        | 72/532 [01:19<07:58,  1.04s/it]Loading train:  14%|█▎        | 73/532 [01:20<08:16,  1.08s/it]Loading train:  14%|█▍        | 74/532 [01:21<08:40,  1.14s/it]Loading train:  14%|█▍        | 75/532 [01:23<09:50,  1.29s/it]Loading train:  14%|█▍        | 76/532 [01:24<09:12,  1.21s/it]Loading train:  14%|█▍        | 77/532 [01:25<08:52,  1.17s/it]Loading train:  15%|█▍        | 78/532 [01:26<08:38,  1.14s/it]Loading train:  15%|█▍        | 79/532 [01:27<08:20,  1.10s/it]Loading train:  15%|█▌        | 80/532 [01:28<08:51,  1.18s/it]Loading train:  15%|█▌        | 81/532 [01:30<09:25,  1.25s/it]Loading train:  15%|█▌        | 82/532 [01:31<09:29,  1.27s/it]Loading train:  16%|█▌        | 83/532 [01:32<09:19,  1.25s/it]Loading train:  16%|█▌        | 84/532 [01:33<09:06,  1.22s/it]Loading train:  16%|█▌        | 85/532 [01:35<09:15,  1.24s/it]Loading train:  16%|█▌        | 86/532 [01:36<08:38,  1.16s/it]Loading train:  16%|█▋        | 87/532 [01:37<09:07,  1.23s/it]Loading train:  17%|█▋        | 88/532 [01:38<08:43,  1.18s/it]Loading train:  17%|█▋        | 89/532 [01:40<09:18,  1.26s/it]Loading train:  17%|█▋        | 90/532 [01:41<09:52,  1.34s/it]Loading train:  17%|█▋        | 91/532 [01:43<10:11,  1.39s/it]Loading train:  17%|█▋        | 92/532 [01:44<10:15,  1.40s/it]Loading train:  17%|█▋        | 93/532 [01:45<10:13,  1.40s/it]Loading train:  18%|█▊        | 94/532 [01:47<09:51,  1.35s/it]Loading train:  18%|█▊        | 95/532 [01:48<10:22,  1.42s/it]Loading train:  18%|█▊        | 96/532 [01:50<10:48,  1.49s/it]Loading train:  18%|█▊        | 97/532 [01:52<11:11,  1.54s/it]Loading train:  18%|█▊        | 98/532 [01:53<11:27,  1.58s/it]Loading train:  19%|█▊        | 99/532 [01:55<12:04,  1.67s/it]Loading train:  19%|█▉        | 100/532 [01:57<11:54,  1.65s/it]Loading train:  19%|█▉        | 101/532 [01:58<11:40,  1.62s/it]Loading train:  19%|█▉        | 102/532 [02:00<11:39,  1.63s/it]Loading train:  19%|█▉        | 103/532 [02:01<11:36,  1.62s/it]Loading train:  20%|█▉        | 104/532 [02:03<11:56,  1.67s/it]Loading train:  20%|█▉        | 105/532 [02:05<11:32,  1.62s/it]Loading train:  20%|█▉        | 106/532 [02:06<10:56,  1.54s/it]Loading train:  20%|██        | 107/532 [02:08<10:45,  1.52s/it]Loading train:  20%|██        | 108/532 [02:09<10:14,  1.45s/it]Loading train:  20%|██        | 109/532 [02:10<09:51,  1.40s/it]Loading train:  21%|██        | 110/532 [02:12<09:44,  1.38s/it]Loading train:  21%|██        | 111/532 [02:13<09:15,  1.32s/it]Loading train:  21%|██        | 112/532 [02:14<09:49,  1.40s/it]Loading train:  21%|██        | 113/532 [02:16<09:54,  1.42s/it]Loading train:  21%|██▏       | 114/532 [02:17<09:52,  1.42s/it]Loading train:  22%|██▏       | 115/532 [02:18<09:34,  1.38s/it]Loading train:  22%|██▏       | 116/532 [02:20<09:27,  1.37s/it]Loading train:  22%|██▏       | 117/532 [02:21<09:30,  1.37s/it]Loading train:  22%|██▏       | 118/532 [02:23<09:26,  1.37s/it]Loading train:  22%|██▏       | 119/532 [02:24<09:44,  1.42s/it]Loading train:  23%|██▎       | 120/532 [02:26<09:50,  1.43s/it]Loading train:  23%|██▎       | 121/532 [02:27<09:42,  1.42s/it]Loading train:  23%|██▎       | 122/532 [02:28<09:23,  1.37s/it]Loading train:  23%|██▎       | 123/532 [02:29<09:08,  1.34s/it]Loading train:  23%|██▎       | 124/532 [02:31<09:34,  1.41s/it]Loading train:  23%|██▎       | 125/532 [02:33<10:26,  1.54s/it]Loading train:  24%|██▎       | 126/532 [02:34<10:08,  1.50s/it]Loading train:  24%|██▍       | 127/532 [02:36<10:01,  1.48s/it]Loading train:  24%|██▍       | 128/532 [02:37<09:59,  1.48s/it]Loading train:  24%|██▍       | 129/532 [02:39<09:58,  1.49s/it]Loading train:  24%|██▍       | 130/532 [02:40<10:12,  1.52s/it]Loading train:  25%|██▍       | 131/532 [02:42<10:55,  1.63s/it]Loading train:  25%|██▍       | 132/532 [02:44<11:12,  1.68s/it]Loading train:  25%|██▌       | 133/532 [02:46<11:06,  1.67s/it]Loading train:  25%|██▌       | 134/532 [02:47<10:55,  1.65s/it]Loading train:  25%|██▌       | 135/532 [02:49<10:40,  1.61s/it]Loading train:  26%|██▌       | 136/532 [02:51<11:25,  1.73s/it]Loading train:  26%|██▌       | 137/532 [02:53<12:00,  1.82s/it]Loading train:  26%|██▌       | 138/532 [02:54<11:33,  1.76s/it]Loading train:  26%|██▌       | 139/532 [02:56<11:08,  1.70s/it]Loading train:  26%|██▋       | 140/532 [02:58<11:10,  1.71s/it]Loading train:  27%|██▋       | 141/532 [02:59<11:14,  1.72s/it]Loading train:  27%|██▋       | 142/532 [03:01<10:44,  1.65s/it]Loading train:  27%|██▋       | 143/532 [03:03<10:44,  1.66s/it]Loading train:  27%|██▋       | 144/532 [03:04<10:08,  1.57s/it]Loading train:  27%|██▋       | 145/532 [03:05<09:50,  1.53s/it]Loading train:  27%|██▋       | 146/532 [03:07<09:34,  1.49s/it]Loading train:  28%|██▊       | 147/532 [03:08<09:07,  1.42s/it]Loading train:  28%|██▊       | 148/532 [03:09<08:59,  1.40s/it]Loading train:  28%|██▊       | 149/532 [03:11<09:15,  1.45s/it]Loading train:  28%|██▊       | 150/532 [03:13<09:24,  1.48s/it]Loading train:  28%|██▊       | 151/532 [03:14<09:15,  1.46s/it]Loading train:  29%|██▊       | 152/532 [03:15<08:50,  1.40s/it]Loading train:  29%|██▉       | 153/532 [03:17<09:18,  1.47s/it]Loading train:  29%|██▉       | 154/532 [03:18<08:49,  1.40s/it]Loading train:  29%|██▉       | 155/532 [03:20<09:48,  1.56s/it]Loading train:  29%|██▉       | 156/532 [03:22<10:27,  1.67s/it]Loading train:  30%|██▉       | 157/532 [03:24<11:23,  1.82s/it]Loading train:  30%|██▉       | 158/532 [03:26<11:05,  1.78s/it]Loading train:  30%|██▉       | 159/532 [03:27<10:45,  1.73s/it]Loading train:  30%|███       | 160/532 [03:29<10:58,  1.77s/it]Loading train:  30%|███       | 161/532 [03:31<11:04,  1.79s/it]Loading train:  30%|███       | 162/532 [03:32<09:59,  1.62s/it]Loading train:  31%|███       | 163/532 [03:34<09:40,  1.57s/it]Loading train:  31%|███       | 164/532 [03:35<09:14,  1.51s/it]Loading train:  31%|███       | 165/532 [03:37<09:14,  1.51s/it]Loading train:  31%|███       | 166/532 [03:38<09:04,  1.49s/it]Loading train:  31%|███▏      | 167/532 [03:39<08:51,  1.46s/it]Loading train:  32%|███▏      | 168/532 [03:41<09:28,  1.56s/it]Loading train:  32%|███▏      | 169/532 [03:43<09:15,  1.53s/it]Loading train:  32%|███▏      | 170/532 [03:44<08:58,  1.49s/it]Loading train:  32%|███▏      | 171/532 [03:46<08:46,  1.46s/it]Loading train:  32%|███▏      | 172/532 [03:47<08:44,  1.46s/it]Loading train:  33%|███▎      | 173/532 [03:49<09:10,  1.53s/it]Loading train:  33%|███▎      | 174/532 [03:50<09:13,  1.55s/it]Loading train:  33%|███▎      | 175/532 [03:51<08:32,  1.44s/it]Loading train:  33%|███▎      | 176/532 [03:53<08:03,  1.36s/it]Loading train:  33%|███▎      | 177/532 [03:54<08:10,  1.38s/it]Loading train:  33%|███▎      | 178/532 [03:55<07:52,  1.33s/it]Loading train:  34%|███▎      | 179/532 [03:57<08:02,  1.37s/it]Loading train:  34%|███▍      | 180/532 [03:58<08:27,  1.44s/it]Loading train:  34%|███▍      | 181/532 [04:00<08:30,  1.45s/it]Loading train:  34%|███▍      | 182/532 [04:01<08:15,  1.42s/it]Loading train:  34%|███▍      | 183/532 [04:02<07:53,  1.36s/it]Loading train:  35%|███▍      | 184/532 [04:04<08:00,  1.38s/it]Loading train:  35%|███▍      | 185/532 [04:05<07:52,  1.36s/it]Loading train:  35%|███▍      | 186/532 [04:07<08:07,  1.41s/it]Loading train:  35%|███▌      | 187/532 [04:08<07:58,  1.39s/it]Loading train:  35%|███▌      | 188/532 [04:09<07:53,  1.38s/it]Loading train:  36%|███▌      | 189/532 [04:11<07:49,  1.37s/it]Loading train:  36%|███▌      | 190/532 [04:12<07:43,  1.36s/it]Loading train:  36%|███▌      | 191/532 [04:14<08:52,  1.56s/it]Loading train:  36%|███▌      | 192/532 [04:16<09:00,  1.59s/it]Loading train:  36%|███▋      | 193/532 [04:17<09:12,  1.63s/it]Loading train:  36%|███▋      | 194/532 [04:19<09:22,  1.66s/it]Loading train:  37%|███▋      | 195/532 [04:21<09:46,  1.74s/it]Loading train:  37%|███▋      | 196/532 [04:23<09:12,  1.64s/it]Loading train:  37%|███▋      | 197/532 [04:24<08:55,  1.60s/it]Loading train:  37%|███▋      | 198/532 [04:26<08:53,  1.60s/it]Loading train:  37%|███▋      | 199/532 [04:27<08:33,  1.54s/it]Loading train:  38%|███▊      | 200/532 [04:29<08:44,  1.58s/it]Loading train:  38%|███▊      | 201/532 [04:30<08:45,  1.59s/it]Loading train:  38%|███▊      | 202/532 [04:32<08:44,  1.59s/it]Loading train:  38%|███▊      | 203/532 [04:33<08:34,  1.56s/it]Loading train:  38%|███▊      | 204/532 [04:35<08:28,  1.55s/it]Loading train:  39%|███▊      | 205/532 [04:36<08:12,  1.51s/it]Loading train:  39%|███▊      | 206/532 [04:38<07:51,  1.45s/it]Loading train:  39%|███▉      | 207/532 [04:39<07:40,  1.42s/it]Loading train:  39%|███▉      | 208/532 [04:40<07:44,  1.43s/it]Loading train:  39%|███▉      | 209/532 [04:42<07:32,  1.40s/it]Loading train:  39%|███▉      | 210/532 [04:43<07:44,  1.44s/it]Loading train:  40%|███▉      | 211/532 [04:45<07:32,  1.41s/it]Loading train:  40%|███▉      | 212/532 [04:46<07:27,  1.40s/it]Loading train:  40%|████      | 213/532 [04:47<07:12,  1.36s/it]Loading train:  40%|████      | 214/532 [04:49<06:58,  1.32s/it]Loading train:  40%|████      | 215/532 [04:50<07:39,  1.45s/it]Loading train:  41%|████      | 216/532 [04:52<08:11,  1.56s/it]Loading train:  41%|████      | 217/532 [04:54<08:17,  1.58s/it]Loading train:  41%|████      | 218/532 [04:56<08:37,  1.65s/it]Loading train:  41%|████      | 219/532 [04:57<08:16,  1.59s/it]Loading train:  41%|████▏     | 220/532 [04:58<08:11,  1.57s/it]Loading train:  42%|████▏     | 221/532 [05:00<08:04,  1.56s/it]Loading train:  42%|████▏     | 222/532 [05:01<07:26,  1.44s/it]Loading train:  42%|████▏     | 223/532 [05:03<07:20,  1.42s/it]Loading train:  42%|████▏     | 224/532 [05:04<06:53,  1.34s/it]Loading train:  42%|████▏     | 225/532 [05:05<06:47,  1.33s/it]Loading train:  42%|████▏     | 226/532 [05:06<06:46,  1.33s/it]Loading train:  43%|████▎     | 227/532 [05:08<06:42,  1.32s/it]Loading train:  43%|████▎     | 228/532 [05:09<06:40,  1.32s/it]Loading train:  43%|████▎     | 229/532 [05:10<06:32,  1.30s/it]Loading train:  43%|████▎     | 230/532 [05:12<06:56,  1.38s/it]Loading train:  43%|████▎     | 231/532 [05:13<07:10,  1.43s/it]Loading train:  44%|████▎     | 232/532 [05:15<06:46,  1.35s/it]Loading train:  44%|████▍     | 233/532 [05:16<06:49,  1.37s/it]Loading train:  44%|████▍     | 234/532 [05:17<06:36,  1.33s/it]Loading train:  44%|████▍     | 235/532 [05:19<06:44,  1.36s/it]Loading train:  44%|████▍     | 236/532 [05:20<06:35,  1.34s/it]Loading train:  45%|████▍     | 237/532 [05:21<06:40,  1.36s/it]Loading train:  45%|████▍     | 238/532 [05:23<06:44,  1.37s/it]Loading train:  45%|████▍     | 239/532 [05:24<06:58,  1.43s/it]Loading train:  45%|████▌     | 240/532 [05:26<06:51,  1.41s/it]Loading train:  45%|████▌     | 241/532 [05:27<07:02,  1.45s/it]Loading train:  45%|████▌     | 242/532 [05:29<06:59,  1.45s/it]Loading train:  46%|████▌     | 243/532 [05:30<06:54,  1.43s/it]Loading train:  46%|████▌     | 244/532 [05:31<06:51,  1.43s/it]Loading train:  46%|████▌     | 245/532 [05:33<06:51,  1.43s/it]Loading train:  46%|████▌     | 246/532 [05:34<06:48,  1.43s/it]Loading train:  46%|████▋     | 247/532 [05:36<06:39,  1.40s/it]Loading train:  47%|████▋     | 248/532 [05:37<06:23,  1.35s/it]Loading train:  47%|████▋     | 249/532 [05:38<06:17,  1.33s/it]Loading train:  47%|████▋     | 250/532 [05:39<06:09,  1.31s/it]Loading train:  47%|████▋     | 251/532 [05:41<06:06,  1.30s/it]Loading train:  47%|████▋     | 252/532 [05:42<06:07,  1.31s/it]Loading train:  48%|████▊     | 253/532 [05:43<05:57,  1.28s/it]Loading train:  48%|████▊     | 254/532 [05:45<06:16,  1.36s/it]Loading train:  48%|████▊     | 255/532 [05:46<06:02,  1.31s/it]Loading train:  48%|████▊     | 256/532 [05:47<05:50,  1.27s/it]Loading train:  48%|████▊     | 257/532 [05:49<06:16,  1.37s/it]Loading train:  48%|████▊     | 258/532 [05:50<06:23,  1.40s/it]Loading train:  49%|████▊     | 259/532 [05:52<07:03,  1.55s/it]Loading train:  49%|████▉     | 260/532 [05:53<06:28,  1.43s/it]Loading train:  49%|████▉     | 261/532 [05:54<06:11,  1.37s/it]Loading train:  49%|████▉     | 262/532 [05:56<06:44,  1.50s/it]Loading train:  49%|████▉     | 263/532 [05:58<06:32,  1.46s/it]Loading train:  50%|████▉     | 264/532 [05:59<05:59,  1.34s/it]Loading train:  50%|████▉     | 265/532 [06:00<06:03,  1.36s/it]Loading train:  50%|█████     | 266/532 [06:02<06:25,  1.45s/it]Loading train:  50%|█████     | 267/532 [06:03<06:02,  1.37s/it]Loading train:  50%|█████     | 268/532 [06:04<05:57,  1.35s/it]Loading train:  51%|█████     | 269/532 [06:06<06:00,  1.37s/it]Loading train:  51%|█████     | 270/532 [06:07<06:15,  1.43s/it]Loading train:  51%|█████     | 271/532 [06:09<06:18,  1.45s/it]Loading train:  51%|█████     | 272/532 [06:10<06:12,  1.43s/it]Loading train:  51%|█████▏    | 273/532 [06:12<06:08,  1.42s/it]Loading train:  52%|█████▏    | 274/532 [06:13<06:07,  1.42s/it]Loading train:  52%|█████▏    | 275/532 [06:15<06:32,  1.53s/it]Loading train:  52%|█████▏    | 276/532 [06:16<06:39,  1.56s/it]Loading train:  52%|█████▏    | 277/532 [06:18<06:39,  1.57s/it]Loading train:  52%|█████▏    | 278/532 [06:19<06:29,  1.53s/it]Loading train:  52%|█████▏    | 279/532 [06:21<06:33,  1.55s/it]Loading train:  53%|█████▎    | 280/532 [06:23<06:48,  1.62s/it]Loading train:  53%|█████▎    | 281/532 [06:24<06:33,  1.57s/it]Loading train:  53%|█████▎    | 282/532 [06:26<06:50,  1.64s/it]Loading train:  53%|█████▎    | 283/532 [06:27<06:29,  1.56s/it]Loading train:  53%|█████▎    | 284/532 [06:29<06:17,  1.52s/it]Loading train:  54%|█████▎    | 285/532 [06:30<06:15,  1.52s/it]Loading train:  54%|█████▍    | 286/532 [06:32<06:20,  1.55s/it]Loading train:  54%|█████▍    | 287/532 [06:34<06:17,  1.54s/it]Loading train:  54%|█████▍    | 288/532 [06:35<06:10,  1.52s/it]Loading train:  54%|█████▍    | 289/532 [06:36<05:41,  1.40s/it]Loading train:  55%|█████▍    | 290/532 [06:38<05:42,  1.41s/it]Loading train:  55%|█████▍    | 291/532 [06:39<05:49,  1.45s/it]Loading train:  55%|█████▍    | 292/532 [06:41<05:59,  1.50s/it]Loading train:  55%|█████▌    | 293/532 [06:42<06:03,  1.52s/it]Loading train:  55%|█████▌    | 294/532 [06:44<05:53,  1.49s/it]Loading train:  55%|█████▌    | 295/532 [06:45<05:58,  1.51s/it]Loading train:  56%|█████▌    | 296/532 [06:47<05:47,  1.47s/it]Loading train:  56%|█████▌    | 297/532 [06:48<05:45,  1.47s/it]Loading train:  56%|█████▌    | 298/532 [06:50<05:46,  1.48s/it]Loading train:  56%|█████▌    | 299/532 [06:51<05:30,  1.42s/it]Loading train:  56%|█████▋    | 300/532 [06:52<05:21,  1.39s/it]Loading train:  57%|█████▋    | 301/532 [06:53<05:13,  1.36s/it]Loading train:  57%|█████▋    | 302/532 [06:55<04:50,  1.26s/it]Loading train:  57%|█████▋    | 303/532 [06:56<05:06,  1.34s/it]Loading train:  57%|█████▋    | 304/532 [06:57<04:58,  1.31s/it]Loading train:  57%|█████▋    | 305/532 [06:59<05:23,  1.43s/it]Loading train:  58%|█████▊    | 306/532 [07:01<05:40,  1.51s/it]Loading train:  58%|█████▊    | 307/532 [07:02<05:38,  1.51s/it]Loading train:  58%|█████▊    | 308/532 [07:04<05:50,  1.56s/it]Loading train:  58%|█████▊    | 309/532 [07:06<05:59,  1.61s/it]Loading train:  58%|█████▊    | 310/532 [07:07<06:11,  1.67s/it]Loading train:  58%|█████▊    | 311/532 [07:10<06:41,  1.82s/it]Loading train:  59%|█████▊    | 312/532 [07:11<06:47,  1.85s/it]Loading train:  59%|█████▉    | 313/532 [07:13<06:45,  1.85s/it]Loading train:  59%|█████▉    | 314/532 [07:15<07:01,  1.93s/it]Loading train:  59%|█████▉    | 315/532 [07:18<07:15,  2.01s/it]Loading train:  59%|█████▉    | 316/532 [07:20<07:08,  1.98s/it]Loading train:  60%|█████▉    | 317/532 [07:21<06:21,  1.77s/it]Loading train:  60%|█████▉    | 318/532 [07:22<06:03,  1.70s/it]Loading train:  60%|█████▉    | 319/532 [07:24<05:34,  1.57s/it]Loading train:  60%|██████    | 320/532 [07:25<05:22,  1.52s/it]Loading train:  60%|██████    | 321/532 [07:27<05:24,  1.54s/it]Loading train:  61%|██████    | 322/532 [07:28<05:09,  1.47s/it]Loading train:  61%|██████    | 323/532 [07:30<05:26,  1.56s/it]Loading train:  61%|██████    | 324/532 [07:32<05:45,  1.66s/it]Loading train:  61%|██████    | 325/532 [07:33<05:53,  1.71s/it]Loading train:  61%|██████▏   | 326/532 [07:35<06:02,  1.76s/it]Loading train:  61%|██████▏   | 327/532 [07:37<05:57,  1.75s/it]Loading train:  62%|██████▏   | 328/532 [07:39<05:54,  1.74s/it]Loading train:  62%|██████▏   | 329/532 [07:40<05:18,  1.57s/it]Loading train:  62%|██████▏   | 330/532 [07:41<04:51,  1.45s/it]Loading train:  62%|██████▏   | 331/532 [07:43<04:53,  1.46s/it]Loading train:  62%|██████▏   | 332/532 [07:44<04:45,  1.43s/it]Loading train:  63%|██████▎   | 333/532 [07:45<04:45,  1.43s/it]Loading train:  63%|██████▎   | 334/532 [07:47<04:36,  1.40s/it]Loading train:  63%|██████▎   | 335/532 [07:48<04:36,  1.40s/it]Loading train:  63%|██████▎   | 336/532 [07:50<04:49,  1.48s/it]Loading train:  63%|██████▎   | 337/532 [07:51<04:46,  1.47s/it]Loading train:  64%|██████▎   | 338/532 [07:52<04:33,  1.41s/it]Loading train:  64%|██████▎   | 339/532 [07:54<04:28,  1.39s/it]Loading train:  64%|██████▍   | 340/532 [07:55<04:38,  1.45s/it]Loading train:  64%|██████▍   | 341/532 [07:57<04:31,  1.42s/it]Loading train:  64%|██████▍   | 342/532 [07:58<04:21,  1.38s/it]Loading train:  64%|██████▍   | 343/532 [07:59<04:23,  1.39s/it]Loading train:  65%|██████▍   | 344/532 [08:01<04:23,  1.40s/it]Loading train:  65%|██████▍   | 345/532 [08:02<04:02,  1.30s/it]Loading train:  65%|██████▌   | 346/532 [08:03<04:03,  1.31s/it]Loading train:  65%|██████▌   | 347/532 [08:05<04:11,  1.36s/it]Loading train:  65%|██████▌   | 348/532 [08:06<04:14,  1.38s/it]Loading train:  66%|██████▌   | 349/532 [08:08<04:19,  1.42s/it]Loading train:  66%|██████▌   | 350/532 [08:09<04:11,  1.38s/it]Loading train:  66%|██████▌   | 351/532 [08:11<04:19,  1.43s/it]Loading train:  66%|██████▌   | 352/532 [08:12<04:12,  1.40s/it]Loading train:  66%|██████▋   | 353/532 [08:13<04:10,  1.40s/it]Loading train:  67%|██████▋   | 354/532 [08:15<04:08,  1.39s/it]Loading train:  67%|██████▋   | 355/532 [08:16<04:10,  1.41s/it]Loading train:  67%|██████▋   | 356/532 [08:17<03:56,  1.35s/it]Loading train:  67%|██████▋   | 357/532 [08:19<04:04,  1.40s/it]Loading train:  67%|██████▋   | 358/532 [08:20<03:56,  1.36s/it]Loading train:  67%|██████▋   | 359/532 [08:21<03:46,  1.31s/it]Loading train:  68%|██████▊   | 360/532 [08:23<03:45,  1.31s/it]Loading train:  68%|██████▊   | 361/532 [08:24<03:36,  1.26s/it]Loading train:  68%|██████▊   | 362/532 [08:25<03:37,  1.28s/it]Loading train:  68%|██████▊   | 363/532 [08:26<03:38,  1.29s/it]Loading train:  68%|██████▊   | 364/532 [08:27<03:26,  1.23s/it]Loading train:  69%|██████▊   | 365/532 [08:29<03:18,  1.19s/it]Loading train:  69%|██████▉   | 366/532 [08:30<03:25,  1.24s/it]Loading train:  69%|██████▉   | 367/532 [08:31<03:36,  1.31s/it]Loading train:  69%|██████▉   | 368/532 [08:33<03:33,  1.30s/it]Loading train:  69%|██████▉   | 369/532 [08:34<03:25,  1.26s/it]Loading train:  70%|██████▉   | 370/532 [08:35<03:34,  1.33s/it]Loading train:  70%|██████▉   | 371/532 [08:37<03:47,  1.41s/it]Loading train:  70%|██████▉   | 372/532 [08:39<03:54,  1.46s/it]Loading train:  70%|███████   | 373/532 [08:40<04:02,  1.53s/it]Loading train:  70%|███████   | 374/532 [08:42<03:57,  1.50s/it]Loading train:  70%|███████   | 375/532 [08:43<03:57,  1.51s/it]Loading train:  71%|███████   | 376/532 [08:45<03:59,  1.54s/it]Loading train:  71%|███████   | 377/532 [08:46<03:45,  1.46s/it]Loading train:  71%|███████   | 378/532 [08:48<03:49,  1.49s/it]Loading train:  71%|███████   | 379/532 [08:49<03:37,  1.42s/it]Loading train:  71%|███████▏  | 380/532 [08:50<03:32,  1.40s/it]Loading train:  72%|███████▏  | 381/532 [08:52<03:30,  1.39s/it]Loading train:  72%|███████▏  | 382/532 [08:53<03:17,  1.32s/it]Loading train:  72%|███████▏  | 383/532 [08:54<03:19,  1.34s/it]Loading train:  72%|███████▏  | 384/532 [08:55<03:19,  1.35s/it]Loading train:  72%|███████▏  | 385/532 [08:57<03:24,  1.39s/it]Loading train:  73%|███████▎  | 386/532 [08:58<03:26,  1.42s/it]Loading train:  73%|███████▎  | 387/532 [09:00<03:31,  1.46s/it]Loading train:  73%|███████▎  | 388/532 [09:01<03:21,  1.40s/it]Loading train:  73%|███████▎  | 389/532 [09:03<03:33,  1.50s/it]Loading train:  73%|███████▎  | 390/532 [09:04<03:18,  1.40s/it]Loading train:  73%|███████▎  | 391/532 [09:05<03:11,  1.36s/it]Loading train:  74%|███████▎  | 392/532 [09:07<03:09,  1.36s/it]Loading train:  74%|███████▍  | 393/532 [09:08<03:10,  1.37s/it]Loading train:  74%|███████▍  | 394/532 [09:09<03:03,  1.33s/it]Loading train:  74%|███████▍  | 395/532 [09:11<03:07,  1.37s/it]Loading train:  74%|███████▍  | 396/532 [09:12<03:04,  1.36s/it]Loading train:  75%|███████▍  | 397/532 [09:14<03:00,  1.34s/it]Loading train:  75%|███████▍  | 398/532 [09:15<03:07,  1.40s/it]Loading train:  75%|███████▌  | 399/532 [09:17<03:12,  1.44s/it]Loading train:  75%|███████▌  | 400/532 [09:18<03:11,  1.45s/it]Loading train:  75%|███████▌  | 401/532 [09:20<03:14,  1.49s/it]Loading train:  76%|███████▌  | 402/532 [09:21<03:17,  1.52s/it]Loading train:  76%|███████▌  | 403/532 [09:23<03:14,  1.51s/it]Loading train:  76%|███████▌  | 404/532 [09:24<03:17,  1.54s/it]Loading train:  76%|███████▌  | 405/532 [09:26<03:11,  1.51s/it]Loading train:  76%|███████▋  | 406/532 [09:27<03:10,  1.51s/it]Loading train:  77%|███████▋  | 407/532 [09:29<03:19,  1.60s/it]Loading train:  77%|███████▋  | 408/532 [09:30<03:09,  1.53s/it]Loading train:  77%|███████▋  | 409/532 [09:32<02:56,  1.43s/it]Loading train:  77%|███████▋  | 410/532 [09:33<02:51,  1.41s/it]Loading train:  77%|███████▋  | 411/532 [09:34<02:49,  1.40s/it]Loading train:  77%|███████▋  | 412/532 [09:36<02:44,  1.37s/it]Loading train:  78%|███████▊  | 413/532 [09:37<02:40,  1.35s/it]Loading train:  78%|███████▊  | 414/532 [09:38<02:42,  1.38s/it]Loading train:  78%|███████▊  | 415/532 [09:40<02:33,  1.31s/it]Loading train:  78%|███████▊  | 416/532 [09:41<02:28,  1.28s/it]Loading train:  78%|███████▊  | 417/532 [09:42<02:28,  1.29s/it]Loading train:  79%|███████▊  | 418/532 [09:43<02:24,  1.27s/it]Loading train:  79%|███████▉  | 419/532 [09:45<02:34,  1.37s/it]Loading train:  79%|███████▉  | 420/532 [09:47<02:49,  1.51s/it]Loading train:  79%|███████▉  | 421/532 [09:48<02:47,  1.51s/it]Loading train:  79%|███████▉  | 422/532 [09:50<02:43,  1.48s/it]Loading train:  80%|███████▉  | 423/532 [09:51<02:42,  1.49s/it]Loading train:  80%|███████▉  | 424/532 [09:53<02:42,  1.50s/it]Loading train:  80%|███████▉  | 425/532 [09:54<02:35,  1.45s/it]Loading train:  80%|████████  | 426/532 [09:56<02:36,  1.47s/it]Loading train:  80%|████████  | 427/532 [09:57<02:34,  1.48s/it]Loading train:  80%|████████  | 428/532 [09:59<02:34,  1.49s/it]Loading train:  81%|████████  | 429/532 [10:00<02:30,  1.46s/it]Loading train:  81%|████████  | 430/532 [10:02<02:32,  1.49s/it]Loading train:  81%|████████  | 431/532 [10:03<02:29,  1.48s/it]Loading train:  81%|████████  | 432/532 [10:04<02:23,  1.44s/it]Loading train:  81%|████████▏ | 433/532 [10:06<02:24,  1.46s/it]Loading train:  82%|████████▏ | 434/532 [10:07<02:23,  1.46s/it]Loading train:  82%|████████▏ | 435/532 [10:09<02:26,  1.51s/it]Loading train:  82%|████████▏ | 436/532 [10:10<02:25,  1.51s/it]Loading train:  82%|████████▏ | 437/532 [10:12<02:14,  1.42s/it]Loading train:  82%|████████▏ | 438/532 [10:13<02:05,  1.34s/it]Loading train:  83%|████████▎ | 439/532 [10:14<02:00,  1.30s/it]Loading train:  83%|████████▎ | 440/532 [10:15<01:52,  1.22s/it]Loading train:  83%|████████▎ | 441/532 [10:16<01:51,  1.23s/it]Loading train:  83%|████████▎ | 442/532 [10:17<01:46,  1.18s/it]Loading train:  83%|████████▎ | 443/532 [10:19<01:50,  1.24s/it]Loading train:  83%|████████▎ | 444/532 [10:20<01:48,  1.23s/it]Loading train:  84%|████████▎ | 445/532 [10:21<01:45,  1.22s/it]Loading train:  84%|████████▍ | 446/532 [10:23<01:47,  1.25s/it]Loading train:  84%|████████▍ | 447/532 [10:24<01:49,  1.28s/it]Loading train:  84%|████████▍ | 448/532 [10:25<01:44,  1.25s/it]Loading train:  84%|████████▍ | 449/532 [10:26<01:41,  1.22s/it]Loading train:  85%|████████▍ | 450/532 [10:27<01:38,  1.20s/it]Loading train:  85%|████████▍ | 451/532 [10:29<01:41,  1.26s/it]Loading train:  85%|████████▍ | 452/532 [10:30<01:39,  1.25s/it]Loading train:  85%|████████▌ | 453/532 [10:31<01:33,  1.18s/it]Loading train:  85%|████████▌ | 454/532 [10:32<01:33,  1.19s/it]Loading train:  86%|████████▌ | 455/532 [10:34<01:36,  1.26s/it]Loading train:  86%|████████▌ | 456/532 [10:35<01:41,  1.33s/it]Loading train:  86%|████████▌ | 457/532 [10:37<01:46,  1.42s/it]Loading train:  86%|████████▌ | 458/532 [10:38<01:41,  1.38s/it]Loading train:  86%|████████▋ | 459/532 [10:40<01:44,  1.43s/it]Loading train:  86%|████████▋ | 460/532 [10:41<01:42,  1.43s/it]Loading train:  87%|████████▋ | 461/532 [10:43<01:46,  1.50s/it]Loading train:  87%|████████▋ | 462/532 [10:44<01:46,  1.52s/it]Loading train:  87%|████████▋ | 463/532 [10:46<01:51,  1.61s/it]Loading train:  87%|████████▋ | 464/532 [10:48<01:46,  1.57s/it]Loading train:  87%|████████▋ | 465/532 [10:49<01:43,  1.54s/it]Loading train:  88%|████████▊ | 466/532 [10:50<01:38,  1.49s/it]Loading train:  88%|████████▊ | 467/532 [10:51<01:29,  1.38s/it]Loading train:  88%|████████▊ | 468/532 [10:53<01:31,  1.43s/it]Loading train:  88%|████████▊ | 469/532 [10:54<01:25,  1.35s/it]Loading train:  88%|████████▊ | 470/532 [10:55<01:18,  1.26s/it]Loading train:  89%|████████▊ | 471/532 [10:56<01:14,  1.22s/it]Loading train:  89%|████████▊ | 472/532 [10:58<01:15,  1.27s/it]Loading train:  89%|████████▉ | 473/532 [10:59<01:18,  1.33s/it]Loading train:  89%|████████▉ | 474/532 [11:01<01:17,  1.34s/it]Loading train:  89%|████████▉ | 475/532 [11:02<01:16,  1.35s/it]Loading train:  89%|████████▉ | 476/532 [11:04<01:24,  1.50s/it]Loading train:  90%|████████▉ | 477/532 [11:05<01:24,  1.54s/it]Loading train:  90%|████████▉ | 478/532 [11:07<01:23,  1.55s/it]Loading train:  90%|█████████ | 479/532 [11:09<01:30,  1.71s/it]Loading train:  90%|█████████ | 480/532 [11:11<01:25,  1.64s/it]Loading train:  90%|█████████ | 481/532 [11:12<01:24,  1.66s/it]Loading train:  91%|█████████ | 482/532 [11:14<01:24,  1.68s/it]Loading train:  91%|█████████ | 483/532 [11:15<01:18,  1.61s/it]Loading train:  91%|█████████ | 484/532 [11:17<01:18,  1.64s/it]Loading train:  91%|█████████ | 485/532 [11:19<01:21,  1.74s/it]Loading train:  91%|█████████▏| 486/532 [11:21<01:20,  1.74s/it]Loading train:  92%|█████████▏| 487/532 [11:23<01:18,  1.74s/it]Loading train:  92%|█████████▏| 488/532 [11:25<01:19,  1.80s/it]Loading train:  92%|█████████▏| 489/532 [11:27<01:19,  1.85s/it]Loading train:  92%|█████████▏| 490/532 [11:29<01:20,  1.91s/it]Loading train:  92%|█████████▏| 491/532 [11:30<01:15,  1.84s/it]Loading train:  92%|█████████▏| 492/532 [11:32<01:11,  1.79s/it]Loading train:  93%|█████████▎| 493/532 [11:34<01:13,  1.89s/it]Loading train:  93%|█████████▎| 494/532 [11:36<01:08,  1.80s/it]Loading train:  93%|█████████▎| 495/532 [11:37<01:06,  1.79s/it]Loading train:  93%|█████████▎| 496/532 [11:39<01:02,  1.72s/it]Loading train:  93%|█████████▎| 497/532 [11:41<01:03,  1.82s/it]Loading train:  94%|█████████▎| 498/532 [11:43<01:05,  1.93s/it]Loading train:  94%|█████████▍| 499/532 [11:45<01:04,  1.96s/it]Loading train:  94%|█████████▍| 500/532 [11:48<01:06,  2.07s/it]Loading train:  94%|█████████▍| 501/532 [11:49<01:01,  1.99s/it]Loading train:  94%|█████████▍| 502/532 [11:51<00:58,  1.95s/it]Loading train:  95%|█████████▍| 503/532 [11:53<00:54,  1.89s/it]Loading train:  95%|█████████▍| 504/532 [11:55<00:54,  1.93s/it]Loading train:  95%|█████████▍| 505/532 [11:57<00:50,  1.86s/it]Loading train:  95%|█████████▌| 506/532 [11:58<00:47,  1.84s/it]Loading train:  95%|█████████▌| 507/532 [12:00<00:46,  1.84s/it]Loading train:  95%|█████████▌| 508/532 [12:02<00:44,  1.87s/it]Loading train:  96%|█████████▌| 509/532 [12:05<00:45,  2.00s/it]Loading train:  96%|█████████▌| 510/532 [12:07<00:46,  2.09s/it]Loading train:  96%|█████████▌| 511/532 [12:09<00:45,  2.17s/it]Loading train:  96%|█████████▌| 512/532 [12:11<00:42,  2.14s/it]Loading train:  96%|█████████▋| 513/532 [12:14<00:44,  2.36s/it]Loading train:  97%|█████████▋| 514/532 [12:16<00:40,  2.22s/it]Loading train:  97%|█████████▋| 515/532 [12:18<00:33,  2.00s/it]Loading train:  97%|█████████▋| 516/532 [12:19<00:31,  1.94s/it]Loading train:  97%|█████████▋| 517/532 [12:21<00:28,  1.88s/it]Loading train:  97%|█████████▋| 518/532 [12:23<00:25,  1.86s/it]Loading train:  98%|█████████▊| 519/532 [12:24<00:22,  1.73s/it]Loading train:  98%|█████████▊| 520/532 [12:27<00:22,  1.88s/it]Loading train:  98%|█████████▊| 521/532 [12:29<00:21,  1.92s/it]Loading train:  98%|█████████▊| 522/532 [12:31<00:20,  2.05s/it]Loading train:  98%|█████████▊| 523/532 [12:33<00:19,  2.11s/it]Loading train:  98%|█████████▊| 524/532 [12:35<00:15,  1.98s/it]Loading train:  99%|█████████▊| 525/532 [12:37<00:14,  2.05s/it]Loading train:  99%|█████████▉| 526/532 [12:39<00:11,  1.95s/it]Loading train:  99%|█████████▉| 527/532 [12:40<00:09,  1.86s/it]Loading train:  99%|█████████▉| 528/532 [12:42<00:07,  1.89s/it]Loading train:  99%|█████████▉| 529/532 [12:44<00:05,  1.86s/it]Loading train: 100%|█████████▉| 530/532 [12:46<00:03,  1.89s/it]Loading train: 100%|█████████▉| 531/532 [12:48<00:01,  1.89s/it]Loading train: 100%|██████████| 532/532 [12:50<00:00,  1.96s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/532 [00:00<00:32, 16.05it/s]concatenating: train:   1%|          | 5/532 [00:00<00:32, 16.25it/s]concatenating: train:   1%|▏         | 7/532 [00:00<00:31, 16.70it/s]concatenating: train:   2%|▏         | 10/532 [00:00<00:28, 18.28it/s]concatenating: train:   2%|▏         | 12/532 [00:00<00:29, 17.76it/s]concatenating: train:   3%|▎         | 14/532 [00:00<00:30, 16.72it/s]concatenating: train:   3%|▎         | 16/532 [00:00<00:31, 16.38it/s]concatenating: train:   3%|▎         | 18/532 [00:01<00:29, 17.14it/s]concatenating: train:   4%|▍         | 21/532 [00:01<00:27, 18.37it/s]concatenating: train:   5%|▍         | 24/532 [00:01<00:25, 20.28it/s]concatenating: train:   5%|▌         | 27/532 [00:01<00:23, 21.87it/s]concatenating: train:   6%|▌         | 30/532 [00:01<00:22, 21.93it/s]concatenating: train:   6%|▌         | 33/532 [00:01<00:21, 22.77it/s]concatenating: train:   7%|▋         | 37/532 [00:01<00:19, 24.79it/s]concatenating: train:   8%|▊         | 40/532 [00:01<00:20, 24.37it/s]concatenating: train:   8%|▊         | 43/532 [00:02<00:19, 25.05it/s]concatenating: train:   9%|▊         | 46/532 [00:02<00:20, 23.18it/s]concatenating: train:   9%|▉         | 49/532 [00:02<00:19, 24.63it/s]concatenating: train:  10%|▉         | 52/532 [00:02<00:19, 25.24it/s]concatenating: train:  11%|█         | 56/532 [00:02<00:17, 26.57it/s]concatenating: train:  11%|█         | 59/532 [00:02<00:17, 26.35it/s]concatenating: train:  12%|█▏        | 63/532 [00:02<00:16, 28.12it/s]concatenating: train:  13%|█▎        | 67/532 [00:02<00:15, 30.31it/s]concatenating: train:  13%|█▎        | 71/532 [00:02<00:15, 30.31it/s]concatenating: train:  14%|█▍        | 75/532 [00:03<00:15, 29.24it/s]concatenating: train:  15%|█▍        | 78/532 [00:03<00:22, 20.35it/s]concatenating: train:  15%|█▌        | 81/532 [00:03<00:23, 19.09it/s]concatenating: train:  16%|█▌        | 84/532 [00:03<00:22, 19.89it/s]concatenating: train:  16%|█▋        | 87/532 [00:03<00:24, 18.52it/s]concatenating: train:  17%|█▋        | 90/532 [00:04<00:22, 19.46it/s]concatenating: train:  17%|█▋        | 93/532 [00:04<00:20, 21.38it/s]concatenating: train:  18%|█▊        | 97/532 [00:04<00:18, 23.45it/s]concatenating: train:  19%|█▉        | 100/532 [00:04<00:17, 24.60it/s]concatenating: train:  19%|█▉        | 103/532 [00:04<00:17, 24.24it/s]concatenating: train:  20%|█▉        | 106/532 [00:04<00:17, 23.99it/s]concatenating: train:  21%|██        | 110/532 [00:04<00:15, 26.61it/s]concatenating: train:  21%|██        | 113/532 [00:05<00:21, 19.27it/s]concatenating: train:  22%|██▏       | 117/532 [00:05<00:19, 21.22it/s]concatenating: train:  23%|██▎       | 120/532 [00:05<00:18, 22.22it/s]concatenating: train:  23%|██▎       | 124/532 [00:05<00:18, 22.53it/s]concatenating: train:  24%|██▍       | 127/532 [00:05<00:19, 20.89it/s]concatenating: train:  25%|██▍       | 132/532 [00:05<00:17, 23.07it/s]concatenating: train:  25%|██▌       | 135/532 [00:05<00:18, 21.03it/s]concatenating: train:  26%|██▌       | 138/532 [00:06<00:17, 22.48it/s]concatenating: train:  27%|██▋       | 141/532 [00:06<00:17, 21.94it/s]concatenating: train:  27%|██▋       | 144/532 [00:06<00:19, 20.06it/s]concatenating: train:  28%|██▊       | 147/532 [00:06<00:17, 21.69it/s]concatenating: train:  28%|██▊       | 150/532 [00:06<00:17, 22.39it/s]concatenating: train:  29%|██▉       | 153/532 [00:06<00:15, 23.77it/s]concatenating: train:  29%|██▉       | 156/532 [00:06<00:14, 25.10it/s]concatenating: train:  30%|██▉       | 159/532 [00:06<00:15, 24.15it/s]concatenating: train:  31%|███       | 164/532 [00:07<00:13, 28.13it/s]concatenating: train:  32%|███▏      | 170/532 [00:07<00:10, 33.12it/s]concatenating: train:  33%|███▎      | 174/532 [00:07<00:10, 33.41it/s]concatenating: train:  33%|███▎      | 178/532 [00:07<00:18, 19.51it/s]concatenating: train:  34%|███▍      | 181/532 [00:07<00:19, 18.16it/s]concatenating: train:  35%|███▍      | 184/532 [00:08<00:17, 19.94it/s]concatenating: train:  35%|███▌      | 187/532 [00:08<00:17, 19.72it/s]concatenating: train:  36%|███▌      | 190/532 [00:08<00:15, 21.42it/s]concatenating: train:  36%|███▋      | 193/532 [00:08<00:14, 22.79it/s]concatenating: train:  37%|███▋      | 197/532 [00:08<00:13, 24.99it/s]concatenating: train:  38%|███▊      | 200/532 [00:08<00:13, 24.50it/s]concatenating: train:  38%|███▊      | 203/532 [00:08<00:13, 25.14it/s]concatenating: train:  39%|███▊      | 206/532 [00:08<00:12, 25.10it/s]concatenating: train:  39%|███▉      | 209/532 [00:09<00:13, 23.65it/s]concatenating: train:  40%|███▉      | 212/532 [00:09<00:14, 22.73it/s]concatenating: train:  40%|████      | 215/532 [00:09<00:13, 22.94it/s]concatenating: train:  41%|████      | 218/532 [00:09<00:14, 22.07it/s]concatenating: train:  42%|████▏     | 221/532 [00:09<00:16, 18.75it/s]concatenating: train:  42%|████▏     | 224/532 [00:09<00:15, 20.11it/s]concatenating: train:  43%|████▎     | 228/532 [00:09<00:13, 22.98it/s]concatenating: train:  44%|████▎     | 232/532 [00:10<00:12, 24.60it/s]concatenating: train:  44%|████▍     | 235/532 [00:10<00:11, 25.94it/s]concatenating: train:  45%|████▍     | 238/532 [00:10<00:13, 22.47it/s]concatenating: train:  45%|████▌     | 241/532 [00:10<00:18, 15.82it/s]concatenating: train:  46%|████▌     | 243/532 [00:10<00:20, 13.94it/s]concatenating: train:  46%|████▌     | 245/532 [00:10<00:20, 13.81it/s]concatenating: train:  46%|████▋     | 247/532 [00:11<00:18, 15.08it/s]concatenating: train:  47%|████▋     | 250/532 [00:11<00:16, 16.89it/s]concatenating: train:  47%|████▋     | 252/532 [00:11<00:16, 17.17it/s]concatenating: train:  48%|████▊     | 255/532 [00:11<00:14, 18.67it/s]concatenating: train:  48%|████▊     | 258/532 [00:11<00:13, 20.88it/s]concatenating: train:  49%|████▉     | 262/532 [00:11<00:11, 24.20it/s]concatenating: train:  50%|████▉     | 265/532 [00:11<00:13, 19.78it/s]concatenating: train:  50%|█████     | 268/532 [00:12<00:14, 18.33it/s]concatenating: train:  51%|█████     | 271/532 [00:12<00:13, 18.73it/s]concatenating: train:  52%|█████▏    | 274/532 [00:12<00:12, 20.57it/s]concatenating: train:  52%|█████▏    | 278/532 [00:12<00:11, 22.32it/s]concatenating: train:  53%|█████▎    | 281/532 [00:12<00:11, 22.64it/s]concatenating: train:  53%|█████▎    | 284/532 [00:12<00:10, 23.75it/s]concatenating: train:  54%|█████▍    | 288/532 [00:12<00:09, 25.59it/s]concatenating: train:  55%|█████▍    | 291/532 [00:12<00:09, 24.90it/s]concatenating: train:  55%|█████▌    | 294/532 [00:13<00:09, 25.97it/s]concatenating: train:  56%|█████▌    | 297/532 [00:13<00:09, 24.42it/s]concatenating: train:  56%|█████▋    | 300/532 [00:13<00:09, 24.11it/s]concatenating: train:  57%|█████▋    | 303/532 [00:13<00:09, 25.11it/s]concatenating: train:  58%|█████▊    | 306/532 [00:13<00:09, 25.08it/s]concatenating: train:  58%|█████▊    | 309/532 [00:13<00:09, 24.56it/s]concatenating: train:  59%|█████▊    | 312/532 [00:13<00:08, 24.94it/s]concatenating: train:  59%|█████▉    | 315/532 [00:13<00:08, 24.96it/s]concatenating: train:  60%|█████▉    | 319/532 [00:14<00:08, 26.35it/s]concatenating: train:  61%|██████    | 322/532 [00:14<00:07, 26.76it/s]concatenating: train:  61%|██████    | 325/532 [00:14<00:07, 26.77it/s]concatenating: train:  62%|██████▏   | 328/532 [00:14<00:07, 26.78it/s]concatenating: train:  62%|██████▏   | 331/532 [00:14<00:08, 24.91it/s]concatenating: train:  63%|██████▎   | 335/532 [00:14<00:07, 27.62it/s]concatenating: train:  64%|██████▍   | 340/532 [00:14<00:06, 28.82it/s]concatenating: train:  64%|██████▍   | 343/532 [00:14<00:07, 26.96it/s]concatenating: train:  65%|██████▌   | 346/532 [00:15<00:09, 20.01it/s]concatenating: train:  66%|██████▌   | 349/532 [00:15<00:10, 17.93it/s]concatenating: train:  66%|██████▌   | 352/532 [00:15<00:10, 17.66it/s]concatenating: train:  67%|██████▋   | 354/532 [00:15<00:10, 16.99it/s]concatenating: train:  67%|██████▋   | 356/532 [00:15<00:10, 17.24it/s]concatenating: train:  67%|██████▋   | 359/532 [00:15<00:09, 18.18it/s]concatenating: train:  68%|██████▊   | 363/532 [00:16<00:07, 21.57it/s]concatenating: train:  69%|██████▉   | 367/532 [00:16<00:07, 22.53it/s]concatenating: train:  70%|██████▉   | 370/532 [00:16<00:07, 21.06it/s]concatenating: train:  70%|███████   | 373/532 [00:16<00:07, 20.31it/s]concatenating: train:  71%|███████   | 376/532 [00:16<00:07, 20.64it/s]concatenating: train:  71%|███████   | 379/532 [00:16<00:07, 20.52it/s]concatenating: train:  72%|███████▏  | 382/532 [00:16<00:06, 22.07it/s]concatenating: train:  73%|███████▎  | 386/532 [00:17<00:06, 23.19it/s]concatenating: train:  73%|███████▎  | 389/532 [00:17<00:06, 22.84it/s]concatenating: train:  74%|███████▎  | 392/532 [00:17<00:06, 23.23it/s]concatenating: train:  74%|███████▍  | 395/532 [00:17<00:05, 23.29it/s]concatenating: train:  75%|███████▍  | 398/532 [00:17<00:05, 23.78it/s]concatenating: train:  75%|███████▌  | 401/532 [00:17<00:05, 23.45it/s]concatenating: train:  76%|███████▌  | 404/532 [00:17<00:05, 23.90it/s]concatenating: train:  77%|███████▋  | 407/532 [00:17<00:05, 24.70it/s]concatenating: train:  77%|███████▋  | 410/532 [00:18<00:04, 24.79it/s]concatenating: train:  78%|███████▊  | 413/532 [00:18<00:04, 24.85it/s]concatenating: train:  78%|███████▊  | 416/532 [00:18<00:04, 23.49it/s]concatenating: train:  79%|███████▉  | 419/532 [00:18<00:04, 24.39it/s]concatenating: train:  79%|███████▉  | 422/532 [00:18<00:04, 22.99it/s]concatenating: train:  80%|███████▉  | 425/532 [00:18<00:04, 21.91it/s]concatenating: train:  80%|████████  | 428/532 [00:18<00:04, 22.75it/s]concatenating: train:  81%|████████  | 431/532 [00:18<00:04, 23.60it/s]concatenating: train:  82%|████████▏ | 435/532 [00:19<00:03, 25.09it/s]concatenating: train:  82%|████████▏ | 438/532 [00:19<00:03, 25.06it/s]concatenating: train:  83%|████████▎ | 441/532 [00:19<00:03, 25.82it/s]concatenating: train:  83%|████████▎ | 444/532 [00:19<00:03, 22.98it/s]concatenating: train:  84%|████████▍ | 448/532 [00:19<00:03, 24.60it/s]concatenating: train:  85%|████████▍ | 451/532 [00:19<00:03, 23.33it/s]concatenating: train:  85%|████████▌ | 454/532 [00:19<00:03, 23.15it/s]concatenating: train:  86%|████████▌ | 457/532 [00:20<00:03, 21.63it/s]concatenating: train:  86%|████████▋ | 460/532 [00:20<00:03, 21.38it/s]concatenating: train:  87%|████████▋ | 463/532 [00:20<00:03, 20.86it/s]concatenating: train:  88%|████████▊ | 466/532 [00:20<00:03, 21.57it/s]concatenating: train:  88%|████████▊ | 469/532 [00:20<00:03, 19.82it/s]concatenating: train:  89%|████████▊ | 472/532 [00:20<00:02, 20.12it/s]concatenating: train:  89%|████████▉ | 475/532 [00:20<00:02, 20.33it/s]concatenating: train:  90%|████████▉ | 478/532 [00:21<00:02, 21.53it/s]concatenating: train:  90%|█████████ | 481/532 [00:21<00:02, 22.47it/s]concatenating: train:  91%|█████████ | 485/532 [00:21<00:01, 25.47it/s]concatenating: train:  92%|█████████▏| 489/532 [00:21<00:01, 26.75it/s]concatenating: train:  92%|█████████▏| 492/532 [00:21<00:01, 27.05it/s]concatenating: train:  93%|█████████▎| 495/532 [00:21<00:01, 26.40it/s]concatenating: train:  94%|█████████▎| 498/532 [00:21<00:01, 26.80it/s]concatenating: train:  94%|█████████▍| 501/532 [00:21<00:01, 23.97it/s]concatenating: train:  95%|█████████▍| 504/532 [00:22<00:01, 23.58it/s]concatenating: train:  95%|█████████▌| 507/532 [00:22<00:01, 24.70it/s]concatenating: train:  96%|█████████▌| 510/532 [00:22<00:00, 25.55it/s]concatenating: train:  97%|█████████▋| 514/532 [00:22<00:00, 26.81it/s]concatenating: train:  97%|█████████▋| 517/532 [00:22<00:00, 23.52it/s]concatenating: train:  98%|█████████▊| 520/532 [00:22<00:00, 23.28it/s]concatenating: train:  98%|█████████▊| 523/532 [00:22<00:00, 24.71it/s]concatenating: train:  99%|█████████▉| 527/532 [00:22<00:00, 26.37it/s]concatenating: train: 100%|█████████▉| 530/532 [00:23<00:00, 23.95it/s]concatenating: train: 100%|██████████| 532/532 [00:23<00:00, 22.96it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:25,  1.84s/it]Loading test:  13%|█▎        | 2/15 [00:04<00:25,  1.94s/it]Loading test:  20%|██        | 3/15 [00:06<00:23,  1.98s/it]Loading test:  27%|██▋       | 4/15 [00:08<00:21,  1.97s/it]Loading test:  33%|███▎      | 5/15 [00:10<00:21,  2.15s/it]Loading test:  40%|████      | 6/15 [00:12<00:19,  2.13s/it]Loading test:  47%|████▋     | 7/15 [00:15<00:17,  2.22s/it]Loading test:  53%|█████▎    | 8/15 [00:16<00:14,  2.10s/it]Loading test:  60%|██████    | 9/15 [00:18<00:11,  1.87s/it]Loading test:  67%|██████▋   | 10/15 [00:19<00:08,  1.72s/it]Loading test:  73%|███████▎  | 11/15 [00:20<00:06,  1.59s/it]Loading test:  80%|████████  | 12/15 [00:22<00:04,  1.57s/it]Loading test:  87%|████████▋ | 13/15 [00:23<00:03,  1.50s/it]Loading test:  93%|█████████▎| 14/15 [00:25<00:01,  1.53s/it]Loading test: 100%|██████████| 15/15 [00:27<00:00,  1.61s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  33%|███▎      | 5/15 [00:00<00:00, 48.44it/s]concatenating: validation:  73%|███████▎  | 11/15 [00:00<00:00, 50.37it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 50.80it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 19:39:21.858174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 19:39:21.858322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 19:39:21.858339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 19:39:21.858350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 19:39:21.858843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 29s - loss: 12.2816 - acc: 0.6536 - mDice: 0.0386 - val_loss: 2.4771 - val_acc: 0.9217 - val_mDice: 0.1448

Epoch 00001: val_mDice improved from -inf to 0.14480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 2.4780 - acc: 0.9096 - mDice: 0.1963 - val_loss: 1.4787 - val_acc: 0.9261 - val_mDice: 0.3627

Epoch 00002: val_mDice improved from 0.14480 to 0.36272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 19s - loss: 1.7663 - acc: 0.9214 - mDice: 0.3247 - val_loss: 0.9861 - val_acc: 0.9472 - val_mDice: 0.5219

Epoch 00003: val_mDice improved from 0.36272 to 0.52185, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 1.3941 - acc: 0.9338 - mDice: 0.4227 - val_loss: 0.7684 - val_acc: 0.9658 - val_mDice: 0.6126

Epoch 00004: val_mDice improved from 0.52185 to 0.61261, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 21s - loss: 1.1685 - acc: 0.9406 - mDice: 0.4948 - val_loss: 0.6966 - val_acc: 0.9684 - val_mDice: 0.6551

Epoch 00005: val_mDice improved from 0.61261 to 0.65513, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 19s - loss: 1.0482 - acc: 0.9438 - mDice: 0.5382 - val_loss: 0.6167 - val_acc: 0.9710 - val_mDice: 0.6907

Epoch 00006: val_mDice improved from 0.65513 to 0.69073, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 0.9726 - acc: 0.9462 - mDice: 0.5666 - val_loss: 0.5874 - val_acc: 0.9716 - val_mDice: 0.7081

Epoch 00007: val_mDice improved from 0.69073 to 0.70808, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 20s - loss: 0.9188 - acc: 0.9482 - mDice: 0.5879 - val_loss: 0.5692 - val_acc: 0.9727 - val_mDice: 0.7152

Epoch 00008: val_mDice improved from 0.70808 to 0.71520, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 20s - loss: 0.8777 - acc: 0.9502 - mDice: 0.6037 - val_loss: 0.5642 - val_acc: 0.9730 - val_mDice: 0.7252

Epoch 00009: val_mDice improved from 0.71520 to 0.72518, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 19s - loss: 0.8458 - acc: 0.9516 - mDice: 0.6166 - val_loss: 0.5425 - val_acc: 0.9741 - val_mDice: 0.7350

Epoch 00010: val_mDice improved from 0.72518 to 0.73499, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 19s - loss: 0.8188 - acc: 0.9531 - mDice: 0.6274 - val_loss: 0.5464 - val_acc: 0.9738 - val_mDice: 0.7352

Epoch 00011: val_mDice improved from 0.73499 to 0.73515, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 21s - loss: 0.7966 - acc: 0.9542 - mDice: 0.6368 - val_loss: 0.5525 - val_acc: 0.9745 - val_mDice: 0.7392

Epoch 00012: val_mDice improved from 0.73515 to 0.73919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 20s - loss: 0.7794 - acc: 0.9551 - mDice: 0.6445 - val_loss: 0.5289 - val_acc: 0.9743 - val_mDice: 0.7427

Epoch 00013: val_mDice improved from 0.73919 to 0.74266, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 19s - loss: 0.7586 - acc: 0.9558 - mDice: 0.6532 - val_loss: 0.5328 - val_acc: 0.9747 - val_mDice: 0.7461

Epoch 00014: val_mDice improved from 0.74266 to 0.74610, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 20s - loss: 0.7434 - acc: 0.9565 - mDice: 0.6604 - val_loss: 0.5259 - val_acc: 0.9749 - val_mDice: 0.7511

Epoch 00015: val_mDice improved from 0.74610 to 0.75114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 21s - loss: 0.7295 - acc: 0.9571 - mDice: 0.6665 - val_loss: 0.5119 - val_acc: 0.9750 - val_mDice: 0.7551

Epoch 00016: val_mDice improved from 0.75114 to 0.75513, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 19s - loss: 0.7132 - acc: 0.9577 - mDice: 0.6733 - val_loss: 0.5041 - val_acc: 0.9750 - val_mDice: 0.7562

Epoch 00017: val_mDice improved from 0.75513 to 0.75618, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 19s - loss: 0.7036 - acc: 0.9580 - mDice: 0.6778 - val_loss: 0.5180 - val_acc: 0.9744 - val_mDice: 0.7550

Epoch 00018: val_mDice did not improve from 0.75618
Epoch 19/300
 - 21s - loss: 0.6943 - acc: 0.9585 - mDice: 0.6821 - val_loss: 0.5074 - val_acc: 0.9750 - val_mDice: 0.7568

Epoch 00019: val_mDice improved from 0.75618 to 0.75683, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 19s - loss: 0.6836 - acc: 0.9591 - mDice: 0.6865 - val_loss: 0.5042 - val_acc: 0.9748 - val_mDice: 0.7590

Epoch 00020: val_mDice improved from 0.75683 to 0.75898, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 19s - loss: 0.6749 - acc: 0.9596 - mDice: 0.6904 - val_loss: 0.5024 - val_acc: 0.9754 - val_mDice: 0.7604

Epoch 00021: val_mDice improved from 0.75898 to 0.76036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 19s - loss: 0.6665 - acc: 0.9598 - mDice: 0.6936 - val_loss: 0.4918 - val_acc: 0.9746 - val_mDice: 0.7666

Epoch 00022: val_mDice improved from 0.76036 to 0.76661, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 21s - loss: 0.6599 - acc: 0.9601 - mDice: 0.6972 - val_loss: 0.4955 - val_acc: 0.9752 - val_mDice: 0.7651

Epoch 00023: val_mDice did not improve from 0.76661
Epoch 24/300
 - 19s - loss: 0.6509 - acc: 0.9603 - mDice: 0.7008 - val_loss: 0.4933 - val_acc: 0.9749 - val_mDice: 0.7663

Epoch 00024: val_mDice did not improve from 0.76661
Epoch 25/300
 - 19s - loss: 0.6476 - acc: 0.9604 - mDice: 0.7024 - val_loss: 0.4957 - val_acc: 0.9753 - val_mDice: 0.7637

Epoch 00025: val_mDice did not improve from 0.76661
Epoch 26/300
 - 19s - loss: 0.6391 - acc: 0.9607 - mDice: 0.7059 - val_loss: 0.4787 - val_acc: 0.9759 - val_mDice: 0.7712

Epoch 00026: val_mDice improved from 0.76661 to 0.77124, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 20s - loss: 0.6379 - acc: 0.9607 - mDice: 0.7069 - val_loss: 0.4841 - val_acc: 0.9754 - val_mDice: 0.7679

Epoch 00027: val_mDice did not improve from 0.77124
Epoch 28/300
 - 20s - loss: 0.6319 - acc: 0.9607 - mDice: 0.7089 - val_loss: 0.4739 - val_acc: 0.9763 - val_mDice: 0.7728

Epoch 00028: val_mDice improved from 0.77124 to 0.77283, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 19s - loss: 0.6286 - acc: 0.9607 - mDice: 0.7103 - val_loss: 0.4930 - val_acc: 0.9756 - val_mDice: 0.7666

Epoch 00029: val_mDice did not improve from 0.77283
Epoch 30/300
 - 19s - loss: 0.6237 - acc: 0.9609 - mDice: 0.7125 - val_loss: 0.4852 - val_acc: 0.9754 - val_mDice: 0.7667

Epoch 00030: val_mDice did not improve from 0.77283
Epoch 31/300
 - 19s - loss: 0.6205 - acc: 0.9609 - mDice: 0.7138 - val_loss: 0.4864 - val_acc: 0.9760 - val_mDice: 0.7712

Epoch 00031: val_mDice did not improve from 0.77283
Epoch 32/300
 - 21s - loss: 0.6157 - acc: 0.9610 - mDice: 0.7160 - val_loss: 0.4910 - val_acc: 0.9760 - val_mDice: 0.7693

Epoch 00032: val_mDice did not improve from 0.77283
Epoch 33/300
 - 20s - loss: 0.6117 - acc: 0.9611 - mDice: 0.7171 - val_loss: 0.4998 - val_acc: 0.9763 - val_mDice: 0.7690

Epoch 00033: val_mDice did not improve from 0.77283
Epoch 34/300
 - 19s - loss: 0.6097 - acc: 0.9612 - mDice: 0.7183 - val_loss: 0.4834 - val_acc: 0.9760 - val_mDice: 0.7739

Epoch 00034: val_mDice improved from 0.77283 to 0.77387, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 35/300
 - 19s - loss: 0.6078 - acc: 0.9612 - mDice: 0.7194 - val_loss: 0.4809 - val_acc: 0.9762 - val_mDice: 0.7732

Epoch 00035: val_mDice did not improve from 0.77387
Epoch 36/300
 - 19s - loss: 0.6049 - acc: 0.9612 - mDice: 0.7203 - val_loss: 0.4845 - val_acc: 0.9762 - val_mDice: 0.7711

Epoch 00036: val_mDice did not improve from 0.77387
Epoch 37/300
 - 21s - loss: 0.6035 - acc: 0.9613 - mDice: 0.7210 - val_loss: 0.4774 - val_acc: 0.9762 - val_mDice: 0.7739

Epoch 00037: val_mDice improved from 0.77387 to 0.77394, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 38/300
 - 19s - loss: 0.5986 - acc: 0.9614 - mDice: 0.7226 - val_loss: 0.4771 - val_acc: 0.9767 - val_mDice: 0.7759

Epoch 00038: val_mDice improved from 0.77394 to 0.77589, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 39/300
 - 19s - loss: 0.5969 - acc: 0.9615 - mDice: 0.7237 - val_loss: 0.4845 - val_acc: 0.9761 - val_mDice: 0.7745

Epoch 00039: val_mDice did not improve from 0.77589
Epoch 40/300
 - 19s - loss: 0.5966 - acc: 0.9615 - mDice: 0.7237 - val_loss: 0.4962 - val_acc: 0.9763 - val_mDice: 0.7704

Epoch 00040: val_mDice did not improve from 0.77589
Epoch 41/300
 - 19s - loss: 0.5920 - acc: 0.9616 - mDice: 0.7254 - val_loss: 0.4764 - val_acc: 0.9767 - val_mDice: 0.7760

Epoch 00041: val_mDice improved from 0.77589 to 0.77603, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 42/300
 - 20s - loss: 0.5930 - acc: 0.9616 - mDice: 0.7253 - val_loss: 0.4764 - val_acc: 0.9771 - val_mDice: 0.7755

Epoch 00042: val_mDice did not improve from 0.77603
Epoch 43/300
 - 19s - loss: 0.5886 - acc: 0.9616 - mDice: 0.7270 - val_loss: 0.4900 - val_acc: 0.9762 - val_mDice: 0.7711

Epoch 00043: val_mDice did not improve from 0.77603
Epoch 44/300
 - 19s - loss: 0.5878 - acc: 0.9617 - mDice: 0.7276 - val_loss: 0.4693 - val_acc: 0.9769 - val_mDice: 0.7790

Epoch 00044: val_mDice improved from 0.77603 to 0.77896, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 19s - loss: 0.5861 - acc: 0.9617 - mDice: 0.7278 - val_loss: 0.4724 - val_acc: 0.9769 - val_mDice: 0.7782

Epoch 00045: val_mDice did not improve from 0.77896
Epoch 46/300
 - 19s - loss: 0.5841 - acc: 0.9617 - mDice: 0.7288 - val_loss: 0.4789 - val_acc: 0.9770 - val_mDice: 0.7787

Epoch 00046: val_mDice did not improve from 0.77896
Epoch 47/300
 - 21s - loss: 0.5829 - acc: 0.9617 - mDice: 0.7295 - val_loss: 0.4745 - val_acc: 0.9775 - val_mDice: 0.7782

Epoch 00047: val_mDice did not improve from 0.77896
Epoch 48/300
 - 19s - loss: 0.5807 - acc: 0.9618 - mDice: 0.7304 - val_loss: 0.4848 - val_acc: 0.9768 - val_mDice: 0.7764

Epoch 00048: val_mDice did not improve from 0.77896
Epoch 49/300
 - 19s - loss: 0.5804 - acc: 0.9619 - mDice: 0.7305 - val_loss: 0.4723 - val_acc: 0.9769 - val_mDice: 0.7787

Epoch 00049: val_mDice did not improve from 0.77896
Epoch 50/300
 - 19s - loss: 0.5794 - acc: 0.9619 - mDice: 0.7308 - val_loss: 0.4741 - val_acc: 0.9767 - val_mDice: 0.7762

Epoch 00050: val_mDice did not improve from 0.77896
Epoch 51/300
 - 20s - loss: 0.5776 - acc: 0.9619 - mDice: 0.7316 - val_loss: 0.4750 - val_acc: 0.9770 - val_mDice: 0.7804

Epoch 00051: val_mDice improved from 0.77896 to 0.78040, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 52/300
 - 21s - loss: 0.5766 - acc: 0.9620 - mDice: 0.7321 - val_loss: 0.4702 - val_acc: 0.9767 - val_mDice: 0.7769

Epoch 00052: val_mDice did not improve from 0.78040
Epoch 53/300
 - 19s - loss: 0.5748 - acc: 0.9620 - mDice: 0.7327 - val_loss: 0.4664 - val_acc: 0.9769 - val_mDice: 0.7811

Epoch 00053: val_mDice improved from 0.78040 to 0.78107, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 54/300
 - 19s - loss: 0.5758 - acc: 0.9620 - mDice: 0.7322 - val_loss: 0.4828 - val_acc: 0.9766 - val_mDice: 0.7763

Epoch 00054: val_mDice did not improve from 0.78107
Epoch 55/300
 - 19s - loss: 0.5737 - acc: 0.9620 - mDice: 0.7332 - val_loss: 0.4698 - val_acc: 0.9770 - val_mDice: 0.7791

Epoch 00055: val_mDice did not improve from 0.78107
Epoch 56/300
 - 19s - loss: 0.5707 - acc: 0.9621 - mDice: 0.7343 - val_loss: 0.4700 - val_acc: 0.9768 - val_mDice: 0.7781

Epoch 00056: val_mDice did not improve from 0.78107
Epoch 57/300
 - 21s - loss: 0.5709 - acc: 0.9621 - mDice: 0.7344 - val_loss: 0.4743 - val_acc: 0.9771 - val_mDice: 0.7775

Epoch 00057: val_mDice did not improve from 0.78107
Epoch 58/300
 - 19s - loss: 0.5692 - acc: 0.9621 - mDice: 0.7348 - val_loss: 0.4678 - val_acc: 0.9764 - val_mDice: 0.7790

Epoch 00058: val_mDice did not improve from 0.78107
Epoch 59/300
 - 19s - loss: 0.5699 - acc: 0.9622 - mDice: 0.7351 - val_loss: 0.4702 - val_acc: 0.9767 - val_mDice: 0.7787

Epoch 00059: val_mDice did not improve from 0.78107
Epoch 60/300
 - 19s - loss: 0.5669 - acc: 0.9622 - mDice: 0.7359 - val_loss: 0.4819 - val_acc: 0.9771 - val_mDice: 0.7789

Epoch 00060: val_mDice did not improve from 0.78107
Epoch 61/300
 - 20s - loss: 0.5666 - acc: 0.9621 - mDice: 0.7364 - val_loss: 0.4684 - val_acc: 0.9772 - val_mDice: 0.7791

Epoch 00061: val_mDice did not improve from 0.78107
Epoch 62/300
 - 21s - loss: 0.5662 - acc: 0.9622 - mDice: 0.7367 - val_loss: 0.4726 - val_acc: 0.9771 - val_mDice: 0.7813

Epoch 00062: val_mDice improved from 0.78107 to 0.78126, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 63/300
 - 20s - loss: 0.5645 - acc: 0.9623 - mDice: 0.7372 - val_loss: 0.4816 - val_acc: 0.9766 - val_mDice: 0.7762

Epoch 00063: val_mDice did not improve from 0.78126
Epoch 64/300
 - 20s - loss: 0.5641 - acc: 0.9622 - mDice: 0.7371 - val_loss: 0.4654 - val_acc: 0.9775 - val_mDice: 0.7826

Epoch 00064: val_mDice improved from 0.78126 to 0.78265, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 65/300
 - 20s - loss: 0.5635 - acc: 0.9623 - mDice: 0.7373 - val_loss: 0.4709 - val_acc: 0.9771 - val_mDice: 0.7777

Epoch 00065: val_mDice did not improve from 0.78265
Epoch 66/300
 - 20s - loss: 0.5618 - acc: 0.9623 - mDice: 0.7383 - val_loss: 0.4702 - val_acc: 0.9772 - val_mDice: 0.7818

Epoch 00066: val_mDice did not improve from 0.78265
Epoch 67/300
 - 21s - loss: 0.5604 - acc: 0.9623 - mDice: 0.7388 - val_loss: 0.4622 - val_acc: 0.9773 - val_mDice: 0.7826

Epoch 00067: val_mDice did not improve from 0.78265
Epoch 68/300
 - 20s - loss: 0.5598 - acc: 0.9623 - mDice: 0.7389 - val_loss: 0.4831 - val_acc: 0.9768 - val_mDice: 0.7769

Epoch 00068: val_mDice did not improve from 0.78265
Epoch 69/300
 - 19s - loss: 0.5592 - acc: 0.9623 - mDice: 0.7394 - val_loss: 0.4685 - val_acc: 0.9774 - val_mDice: 0.7824

Epoch 00069: val_mDice did not improve from 0.78265
Epoch 70/300
 - 20s - loss: 0.5601 - acc: 0.9624 - mDice: 0.7389 - val_loss: 0.4690 - val_acc: 0.9776 - val_mDice: 0.7823

Epoch 00070: val_mDice did not improve from 0.78265
Epoch 71/300
 - 20s - loss: 0.5589 - acc: 0.9624 - mDice: 0.7393 - val_loss: 0.4601 - val_acc: 0.9777 - val_mDice: 0.7828

Epoch 00071: val_mDice improved from 0.78265 to 0.78285, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 72/300
 - 21s - loss: 0.5588 - acc: 0.9624 - mDice: 0.7394 - val_loss: 0.4614 - val_acc: 0.9774 - val_mDice: 0.7844

Epoch 00072: val_mDice improved from 0.78285 to 0.78438, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 73/300
 - 19s - loss: 0.5560 - acc: 0.9624 - mDice: 0.7406 - val_loss: 0.4650 - val_acc: 0.9777 - val_mDice: 0.7806

Epoch 00073: val_mDice did not improve from 0.78438
Epoch 74/300
 - 19s - loss: 0.5571 - acc: 0.9625 - mDice: 0.7399 - val_loss: 0.4729 - val_acc: 0.9776 - val_mDice: 0.7803

Epoch 00074: val_mDice did not improve from 0.78438
Epoch 75/300
 - 19s - loss: 0.5543 - acc: 0.9625 - mDice: 0.7410 - val_loss: 0.4686 - val_acc: 0.9775 - val_mDice: 0.7795

Epoch 00075: val_mDice did not improve from 0.78438
Epoch 76/300
 - 20s - loss: 0.5553 - acc: 0.9625 - mDice: 0.7408 - val_loss: 0.4846 - val_acc: 0.9775 - val_mDice: 0.7779

Epoch 00076: val_mDice did not improve from 0.78438
Epoch 77/300
 - 20s - loss: 0.5534 - acc: 0.9626 - mDice: 0.7417 - val_loss: 0.4646 - val_acc: 0.9776 - val_mDice: 0.7821

Epoch 00077: val_mDice did not improve from 0.78438
Epoch 78/300
 - 19s - loss: 0.5536 - acc: 0.9625 - mDice: 0.7412 - val_loss: 0.4589 - val_acc: 0.9779 - val_mDice: 0.7840

Epoch 00078: val_mDice did not improve from 0.78438
Epoch 79/300
 - 19s - loss: 0.5522 - acc: 0.9626 - mDice: 0.7421 - val_loss: 0.4652 - val_acc: 0.9777 - val_mDice: 0.7825

Epoch 00079: val_mDice did not improve from 0.78438
Epoch 80/300
 - 20s - loss: 0.5530 - acc: 0.9626 - mDice: 0.7416 - val_loss: 0.4587 - val_acc: 0.9779 - val_mDice: 0.7850

Epoch 00080: val_mDice improved from 0.78438 to 0.78503, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 81/300
 - 20s - loss: 0.5510 - acc: 0.9626 - mDice: 0.7423 - val_loss: 0.4619 - val_acc: 0.9782 - val_mDice: 0.7853

Epoch 00081: val_mDice improved from 0.78503 to 0.78525, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 82/300
 - 19s - loss: 0.5529 - acc: 0.9626 - mDice: 0.7417 - val_loss: 0.4730 - val_acc: 0.9774 - val_mDice: 0.7792

Epoch 00082: val_mDice did not improve from 0.78525
Epoch 83/300
 - 19s - loss: 0.5504 - acc: 0.9627 - mDice: 0.7425 - val_loss: 0.4718 - val_acc: 0.9775 - val_mDice: 0.7835

Epoch 00083: val_mDice did not improve from 0.78525
Epoch 84/300
 - 19s - loss: 0.5521 - acc: 0.9626 - mDice: 0.7423 - val_loss: 0.4708 - val_acc: 0.9781 - val_mDice: 0.7807

Epoch 00084: val_mDice did not improve from 0.78525
Epoch 85/300
 - 20s - loss: 0.5499 - acc: 0.9627 - mDice: 0.7432 - val_loss: 0.4710 - val_acc: 0.9776 - val_mDice: 0.7804

Epoch 00085: val_mDice did not improve from 0.78525
Epoch 86/300
 - 19s - loss: 0.5495 - acc: 0.9627 - mDice: 0.7433 - val_loss: 0.4755 - val_acc: 0.9777 - val_mDice: 0.7785

Epoch 00086: val_mDice did not improve from 0.78525
Epoch 87/300
 - 19s - loss: 0.5497 - acc: 0.9627 - mDice: 0.7433 - val_loss: 0.4700 - val_acc: 0.9778 - val_mDice: 0.7817

Epoch 00087: val_mDice did not improve from 0.78525
Epoch 88/300
 - 19s - loss: 0.5490 - acc: 0.9627 - mDice: 0.7431 - val_loss: 0.4686 - val_acc: 0.9775 - val_mDice: 0.7801

Epoch 00088: val_mDice did not improve from 0.78525
Epoch 89/300
 - 20s - loss: 0.5489 - acc: 0.9627 - mDice: 0.7432 - val_loss: 0.4705 - val_acc: 0.9781 - val_mDice: 0.7833

Epoch 00089: val_mDice did not improve from 0.78525
Epoch 90/300
 - 21s - loss: 0.5490 - acc: 0.9627 - mDice: 0.7436 - val_loss: 0.4682 - val_acc: 0.9781 - val_mDice: 0.7818

Epoch 00090: val_mDice did not improve from 0.78525
Epoch 91/300
 - 19s - loss: 0.5479 - acc: 0.9627 - mDice: 0.7435 - val_loss: 0.4635 - val_acc: 0.9778 - val_mDice: 0.7836

Epoch 00091: val_mDice did not improve from 0.78525
Epoch 92/300
 - 19s - loss: 0.5481 - acc: 0.9627 - mDice: 0.7440 - val_loss: 0.4628 - val_acc: 0.9777 - val_mDice: 0.7852

Epoch 00092: val_mDice did not improve from 0.78525
Epoch 93/300
 - 19s - loss: 0.5465 - acc: 0.9628 - mDice: 0.7442 - val_loss: 0.4776 - val_acc: 0.9778 - val_mDice: 0.7797

Epoch 00093: val_mDice did not improve from 0.78525
Epoch 94/300
 - 20s - loss: 0.5447 - acc: 0.9628 - mDice: 0.7450 - val_loss: 0.4649 - val_acc: 0.9782 - val_mDice: 0.7839

Epoch 00094: val_mDice did not improve from 0.78525
Epoch 95/300
 - 21s - loss: 0.5444 - acc: 0.9627 - mDice: 0.7452 - val_loss: 0.4662 - val_acc: 0.9781 - val_mDice: 0.7834

Epoch 00095: val_mDice did not improve from 0.78525
Epoch 96/300
 - 19s - loss: 0.5437 - acc: 0.9628 - mDice: 0.7454 - val_loss: 0.4727 - val_acc: 0.9771 - val_mDice: 0.7804

Epoch 00096: val_mDice did not improve from 0.78525
Epoch 97/300
 - 19s - loss: 0.5440 - acc: 0.9625 - mDice: 0.7451 - val_loss: 0.4676 - val_acc: 0.9778 - val_mDice: 0.7833

Epoch 00097: val_mDice did not improve from 0.78525
Epoch 98/300
 - 19s - loss: 0.5434 - acc: 0.9621 - mDice: 0.7463 - val_loss: 0.4611 - val_acc: 0.9779 - val_mDice: 0.7866

Epoch 00098: val_mDice improved from 0.78525 to 0.78661, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 99/300
 - 20s - loss: 0.5424 - acc: 0.9620 - mDice: 0.7464 - val_loss: 0.4645 - val_acc: 0.9775 - val_mDice: 0.7831

Epoch 00099: val_mDice did not improve from 0.78661
Epoch 100/300
 - 21s - loss: 0.5421 - acc: 0.9619 - mDice: 0.7465 - val_loss: 0.4666 - val_acc: 0.9773 - val_mDice: 0.7827

Epoch 00100: val_mDice did not improve from 0.78661
Epoch 101/300
 - 19s - loss: 0.5418 - acc: 0.9618 - mDice: 0.7467 - val_loss: 0.4713 - val_acc: 0.9773 - val_mDice: 0.7804

Epoch 00101: val_mDice did not improve from 0.78661
Epoch 102/300
 - 19s - loss: 0.5400 - acc: 0.9618 - mDice: 0.7475 - val_loss: 0.4672 - val_acc: 0.9776 - val_mDice: 0.7832

Epoch 00102: val_mDice did not improve from 0.78661
Epoch 103/300
 - 19s - loss: 0.5392 - acc: 0.9618 - mDice: 0.7478 - val_loss: 0.4728 - val_acc: 0.9769 - val_mDice: 0.7806

Epoch 00103: val_mDice did not improve from 0.78661
Epoch 104/300
 - 20s - loss: 0.5407 - acc: 0.9617 - mDice: 0.7474 - val_loss: 0.4675 - val_acc: 0.9770 - val_mDice: 0.7843

Epoch 00104: val_mDice did not improve from 0.78661
Epoch 105/300
 - 19s - loss: 0.5388 - acc: 0.9618 - mDice: 0.7480 - val_loss: 0.4762 - val_acc: 0.9772 - val_mDice: 0.7806

Epoch 00105: val_mDice did not improve from 0.78661
Epoch 106/300
 - 19s - loss: 0.5395 - acc: 0.9618 - mDice: 0.7478 - val_loss: 0.4594 - val_acc: 0.9778 - val_mDice: 0.7856

Epoch 00106: val_mDice did not improve from 0.78661
Epoch 107/300
 - 19s - loss: 0.5388 - acc: 0.9617 - mDice: 0.7481 - val_loss: 0.4615 - val_acc: 0.9774 - val_mDice: 0.7832

Epoch 00107: val_mDice did not improve from 0.78661
Epoch 108/300
 - 19s - loss: 0.5384 - acc: 0.9618 - mDice: 0.7480 - val_loss: 0.4657 - val_acc: 0.9777 - val_mDice: 0.7838

Epoch 00108: val_mDice did not improve from 0.78661
Epoch 109/300
 - 20s - loss: 0.5375 - acc: 0.9617 - mDice: 0.7482 - val_loss: 0.4672 - val_acc: 0.9774 - val_mDice: 0.7834

Epoch 00109: val_mDice did not improve from 0.78661
Epoch 110/300
 - 19s - loss: 0.5374 - acc: 0.9618 - mDice: 0.7484 - val_loss: 0.4636 - val_acc: 0.9776 - val_mDice: 0.7853

Epoch 00110: val_mDice did not improve from 0.78661
Epoch 111/300
 - 19s - loss: 0.5390 - acc: 0.9618 - mDice: 0.7479 - val_loss: 0.4669 - val_acc: 0.9777 - val_mDice: 0.7841

Epoch 00111: val_mDice did not improve from 0.78661
Epoch 112/300
 - 19s - loss: 0.5367 - acc: 0.9619 - mDice: 0.7491 - val_loss: 0.4721 - val_acc: 0.9776 - val_mDice: 0.7824

Epoch 00112: val_mDice did not improve from 0.78661
Epoch 113/300
 - 19s - loss: 0.5367 - acc: 0.9618 - mDice: 0.7486 - val_loss: 0.4692 - val_acc: 0.9775 - val_mDice: 0.7843

Epoch 00113: val_mDice did not improve from 0.78661
Epoch 114/300
 - 20s - loss: 0.5358 - acc: 0.9618 - mDice: 0.7491 - val_loss: 0.4630 - val_acc: 0.9776 - val_mDice: 0.7834

Epoch 00114: val_mDice did not improve from 0.78661
Epoch 115/300
 - 19s - loss: 0.5362 - acc: 0.9617 - mDice: 0.7488 - val_loss: 0.4655 - val_acc: 0.9772 - val_mDice: 0.7838

Epoch 00115: val_mDice did not improve from 0.78661
Epoch 116/300
 - 19s - loss: 0.5354 - acc: 0.9618 - mDice: 0.7492 - val_loss: 0.4679 - val_acc: 0.9780 - val_mDice: 0.7834

Epoch 00116: val_mDice did not improve from 0.78661
Epoch 117/300
 - 19s - loss: 0.5344 - acc: 0.9618 - mDice: 0.7498 - val_loss: 0.4714 - val_acc: 0.9780 - val_mDice: 0.7817

Epoch 00117: val_mDice did not improve from 0.78661
Epoch 118/300
 - 19s - loss: 0.5333 - acc: 0.9619 - mDice: 0.7499 - val_loss: 0.4751 - val_acc: 0.9774 - val_mDice: 0.7828

Epoch 00118: val_mDice did not improve from 0.78661
Epoch 119/300
 - 21s - loss: 0.5332 - acc: 0.9619 - mDice: 0.7503 - val_loss: 0.4600 - val_acc: 0.9774 - val_mDice: 0.7863

Epoch 00119: val_mDice did not improve from 0.78661
Epoch 120/300
 - 19s - loss: 0.5349 - acc: 0.9619 - mDice: 0.7495 - val_loss: 0.4628 - val_acc: 0.9777 - val_mDice: 0.7820

Epoch 00120: val_mDice did not improve from 0.78661
Epoch 121/300
 - 19s - loss: 0.5326 - acc: 0.9619 - mDice: 0.7502 - val_loss: 0.4749 - val_acc: 0.9775 - val_mDice: 0.7805

Epoch 00121: val_mDice did not improve from 0.78661
Epoch 122/300
 - 19s - loss: 0.5343 - acc: 0.9619 - mDice: 0.7498 - val_loss: 0.4640 - val_acc: 0.9780 - val_mDice: 0.7860

Epoch 00122: val_mDice did not improve from 0.78661
Epoch 123/300
 - 19s - loss: 0.5337 - acc: 0.9618 - mDice: 0.7499 - val_loss: 0.4723 - val_acc: 0.9778 - val_mDice: 0.7832

Epoch 00123: val_mDice did not improve from 0.78661
Epoch 124/300
 - 20s - loss: 0.5327 - acc: 0.9618 - mDice: 0.7509 - val_loss: 0.4620 - val_acc: 0.9779 - val_mDice: 0.7851

Epoch 00124: val_mDice did not improve from 0.78661
Epoch 125/300
 - 19s - loss: 0.5315 - acc: 0.9617 - mDice: 0.7513 - val_loss: 0.4715 - val_acc: 0.9776 - val_mDice: 0.7813

Epoch 00125: val_mDice did not improve from 0.78661
Epoch 126/300
 - 19s - loss: 0.5316 - acc: 0.9616 - mDice: 0.7511 - val_loss: 0.4745 - val_acc: 0.9777 - val_mDice: 0.7825

Epoch 00126: val_mDice did not improve from 0.78661
Epoch 127/300
 - 20s - loss: 0.5299 - acc: 0.9616 - mDice: 0.7516 - val_loss: 0.4625 - val_acc: 0.9779 - val_mDice: 0.7865

Epoch 00127: val_mDice did not improve from 0.78661
Epoch 128/300
 - 20s - loss: 0.5316 - acc: 0.9616 - mDice: 0.7510 - val_loss: 0.4724 - val_acc: 0.9775 - val_mDice: 0.7846

Epoch 00128: val_mDice did not improve from 0.78661
Restoring model weights from the end of the best epoch
Epoch 00128: early stopping
{'val_loss': [2.4770843005893894, 1.478668920149867, 0.9860861275587288, 0.7683880473684108, 0.6965565342529147, 0.6166911494867229, 0.5873883438860792, 0.569171966475476, 0.5641899804581799, 0.5424712266161715, 0.5464451723915628, 0.552481802316888, 0.528910717635701, 0.5327979145404355, 0.5258782542588418, 0.5119086839527783, 0.5040660010279763, 0.5180393138475585, 0.5073657895758426, 0.5041888133844724, 0.5024248313916111, 0.4917832539485089, 0.49548844031997263, 0.49329775039748636, 0.4956641882135157, 0.4786923464668301, 0.4841115905281437, 0.473884665067966, 0.4930294080415377, 0.48522164408882584, 0.4864273713776694, 0.49103978002526566, 0.4997722432401773, 0.48340365176845507, 0.4808870594875485, 0.4844667981652653, 0.4773633627392067, 0.4770653848185505, 0.4845140731986708, 0.49618336299993676, 0.4764232632422472, 0.4763597859256162, 0.4900194768197027, 0.4693351709682752, 0.4723584692237055, 0.4789395728778052, 0.47447168943928736, 0.48483389016275436, 0.4723420204331385, 0.4740685261747539, 0.4749559202184372, 0.4701596570150279, 0.46642936586226474, 0.48278210348266076, 0.46977050376381296, 0.47002392226082373, 0.4742791626229498, 0.46783192543422475, 0.4701838927925925, 0.48190479394206076, 0.4683691828797107, 0.4725820497216578, 0.4815924605594946, 0.46538687650387256, 0.47093153888719125, 0.4701520531477697, 0.4621802286097878, 0.48308972729864014, 0.46847695653529603, 0.46904574511466995, 0.4601164501394896, 0.461428630708787, 0.46496480592633177, 0.4728797720312703, 0.4686178625921716, 0.48458118836700115, 0.46456965413502005, 0.4589243664091955, 0.46519649357864606, 0.45870255310592023, 0.4619168577671543, 0.4730251480059235, 0.4717886892019534, 0.4708337423356079, 0.47102765675914793, 0.4754526402620585, 0.4699594698946296, 0.46857803570965867, 0.47053706298425596, 0.4682261593816696, 0.46351276834805805, 0.4627619253162014, 0.47756633574625534, 0.4648618782390874, 0.4661793375101375, 0.47265610018873855, 0.467598662318583, 0.46112915169220836, 0.4644995197054033, 0.46662409614360245, 0.4713151018501435, 0.46719043671900273, 0.47277615006371054, 0.467458436455889, 0.47618434442086116, 0.4594249055789105, 0.4615298697822972, 0.4656938889262846, 0.46719857844282847, 0.4636089481928523, 0.46685090082840774, 0.47211425949053376, 0.46923968380449727, 0.4629761009516485, 0.46546692289681135, 0.4678661846954633, 0.47135740881487803, 0.47508716158822595, 0.46001512845603304, 0.4628343043927684, 0.4749100246112044, 0.46396398719619303, 0.47225338257503213, 0.46195245887103836, 0.47148779806583907, 0.47454643397139323, 0.4624878181946167, 0.47236466515421005], 'val_acc': [0.9217279151743287, 0.9260592346836046, 0.9471907265661179, 0.965762290730688, 0.9683699148358206, 0.9709551544750438, 0.9715728358710637, 0.9727298852952027, 0.9729911761879306, 0.9740820654405529, 0.9738424935208017, 0.9744884856468138, 0.9743315002374482, 0.9747270638482612, 0.9748725241551828, 0.9749577466179343, 0.9749761800770912, 0.974444374642013, 0.9749886673424389, 0.9747938685372887, 0.975376006742503, 0.9746220870283735, 0.97524734559566, 0.9749360291212336, 0.9752934090985356, 0.9759071383190844, 0.9753654724058106, 0.9762954571667839, 0.975605051829965, 0.9753532979879586, 0.9760496335255965, 0.9759601264792207, 0.9763490991326678, 0.9760048755428248, 0.9761559162346571, 0.9762174651349661, 0.9762424750962863, 0.9766564447321266, 0.9760825424248466, 0.9762790075765675, 0.9766982491171396, 0.9770730615154263, 0.9762263432744855, 0.9769381467402904, 0.9769128044323286, 0.9770108644684279, 0.9775034980877265, 0.9768130938581145, 0.976879239389894, 0.9766646777390203, 0.9770329240305874, 0.9767449701164529, 0.9769239988489417, 0.9765817409821462, 0.9769825643184138, 0.9767989427066562, 0.9770704368811766, 0.9763961568459392, 0.9767360978820375, 0.9771148635630023, 0.9771866004287397, 0.9771352626221836, 0.9766130165049904, 0.9774890257232083, 0.9771346068480682, 0.977226738467182, 0.9773284374621877, 0.9768196731898069, 0.977419914783462, 0.9775515474894222, 0.9777499867912662, 0.9774080703133031, 0.9777322211624792, 0.977581496824298, 0.9774531546761008, 0.9774975705319022, 0.97763841809134, 0.977861878611109, 0.9777252988426555, 0.9778631838236553, 0.9782478743539383, 0.9774383467048314, 0.9775067948581511, 0.9780760959205982, 0.9775709632872551, 0.9777243140435194, 0.9778368528413329, 0.9774771781774744, 0.978093215863156, 0.9780770946828451, 0.9778421230237427, 0.9777246403620339, 0.9777812474283272, 0.9781962065996892, 0.9780863025240115, 0.9771086141174915, 0.9777601849060925, 0.977908918855114, 0.9774979071843489, 0.9772682093983465, 0.9772912428105948, 0.9776331549827528, 0.97691115783095, 0.9769842119654881, 0.9772241183847835, 0.9777562198747176, 0.9773610059567895, 0.9776555292992646, 0.9774432710080693, 0.9775782148781452, 0.9776864789341748, 0.9776055171270734, 0.9775219306242109, 0.9776456697437417, 0.9771849506902744, 0.978007321571787, 0.9780171969357658, 0.9773715318664062, 0.9774060925955128, 0.9776759389384243, 0.9775466095921425, 0.9779701358393619, 0.9778246752863944, 0.9779490715332937, 0.9776206542463863, 0.977707521526683, 0.9779006982120321, 0.9775469432305256], 'val_mDice': [0.14479886596662955, 0.3627221854355559, 0.521853994289788, 0.6126093378500057, 0.6551265718398079, 0.690727384958966, 0.7080802776004016, 0.7152017491520742, 0.7251821838173211, 0.7349883754063932, 0.7351531717922419, 0.7391872917166435, 0.7426578138634885, 0.746097304995707, 0.7511431031059801, 0.7551320687905184, 0.7561758695126072, 0.7549592338971433, 0.7568255344288514, 0.7589784792333195, 0.7603553344098654, 0.7666067107666141, 0.7650990808465287, 0.7662905317464972, 0.7636550111913336, 0.7712404847268104, 0.7679108086016156, 0.7728296309801816, 0.7666113022311184, 0.7666609119335565, 0.7712082022606896, 0.7693098496234331, 0.7690378212215239, 0.773872552395359, 0.773206372194615, 0.7711132510158669, 0.773939168059543, 0.7758882690386384, 0.7745343958507258, 0.7703925435142005, 0.7760271801545032, 0.7755434280578566, 0.7711326342741156, 0.7789635952904251, 0.7781912625389572, 0.7787245783274388, 0.7782410760905105, 0.7763511913110597, 0.7787086534303286, 0.7762153969829666, 0.7804028215300065, 0.776871033743316, 0.7810654828422948, 0.7762821664874152, 0.7790529596916294, 0.7781344269574365, 0.7774667133364761, 0.7789887384241456, 0.7787053249199694, 0.7788991593478019, 0.7790542658883598, 0.7812604578778962, 0.7762427513321364, 0.7826481511964395, 0.7777441553041047, 0.7818180485037458, 0.7826404221532761, 0.7769275947990063, 0.7823921510924742, 0.782321850704827, 0.782846354724699, 0.7843847686907333, 0.7806498006647462, 0.7803144053901067, 0.779516690225178, 0.7779081239296802, 0.7820774116260225, 0.7839676483742839, 0.7824876280145872, 0.7850320118991706, 0.7852529804034868, 0.7791650853166885, 0.7835144033988071, 0.7807321116651175, 0.7803686795712009, 0.7784505851251545, 0.7817482325806829, 0.7800837350457568, 0.7832695169468537, 0.7817630251125655, 0.7836157619891644, 0.7852308331259263, 0.7796797993505457, 0.7839110071075959, 0.783371647198995, 0.7804167848253398, 0.7833323817627103, 0.7866051425259671, 0.783053179335914, 0.7826819352198189, 0.7804431786109051, 0.7832333416638606, 0.7806117669347639, 0.7843275882142247, 0.7805937844779346, 0.7855567469562417, 0.7831687406858793, 0.7838303262850326, 0.7834445132313621, 0.7852902938337887, 0.7840672885178289, 0.7823768713895012, 0.7843116601800278, 0.7834242669052384, 0.7838046756814262, 0.7834058619259066, 0.7817237465128195, 0.7827680364358782, 0.7862510126318601, 0.7819545328063492, 0.7805390110694956, 0.7859571935960752, 0.7832255683324162, 0.7850891106884054, 0.781289679224154, 0.7825040753288781, 0.7865172559385821, 0.7845899792401537], 'loss': [12.281632933577917, 2.4779531559398644, 1.766260727681264, 1.3941369752967048, 1.1685038816396451, 1.0482170445653685, 0.9726420166044324, 0.9188422122589864, 0.8777164632647141, 0.8458426083603365, 0.8187591603569863, 0.7966361653201187, 0.7794023815134075, 0.7585560111504681, 0.7434358118555271, 0.7294976864804622, 0.7131567607354172, 0.7036480497126651, 0.6943059140838129, 0.6836085678684362, 0.674868438283441, 0.666546942319624, 0.6598803114358639, 0.6509214186827835, 0.647593165365016, 0.6391169489113334, 0.6378528040221861, 0.63186814175291, 0.6285912784153219, 0.6236959362559595, 0.620521839148451, 0.6157273005152307, 0.611719764920331, 0.6096766686806794, 0.6077926859583467, 0.6049429677909047, 0.6034709819680841, 0.5985548081063757, 0.5969415027670454, 0.5966036942898018, 0.5920020902259326, 0.5929835707141415, 0.588636305961684, 0.5878125878074502, 0.5861195781890322, 0.5841314722558095, 0.5828676931195251, 0.5806673476554797, 0.5804039470892349, 0.5793531688736765, 0.5775564957311338, 0.5766451436379431, 0.5747675115541994, 0.5758430611405362, 0.573675164956878, 0.5707032954191746, 0.5709001866436415, 0.569217635462328, 0.5698899299525577, 0.5669269498596904, 0.5665995727896206, 0.5661650920201806, 0.5644919842638205, 0.5640595005916359, 0.5635176687820561, 0.5617652646013909, 0.5603768407999544, 0.5597506469542239, 0.5592334619784429, 0.5601379005698848, 0.5589140428509096, 0.5587955811925113, 0.5559508355002087, 0.5571430125604075, 0.5543122909320748, 0.5552526534080562, 0.5533712595836456, 0.5535708841159744, 0.5521639547023165, 0.5529881253009313, 0.551032971579191, 0.5529447399953512, 0.5504490697699912, 0.5520799246342848, 0.5499144070382502, 0.5494712247665156, 0.549706437727532, 0.548959799425853, 0.5488818697871586, 0.5490482628366843, 0.5479447792851615, 0.548090208340494, 0.5465475179918745, 0.5446699641507936, 0.5444435994900408, 0.5436684886211138, 0.5439886751958172, 0.5434082451543177, 0.5424306422884834, 0.5420609145310262, 0.5418333752658676, 0.5399579697295024, 0.5392335714838629, 0.5406781053533126, 0.5387538331724278, 0.5395213500757846, 0.5387766669758585, 0.538401382932351, 0.5375270168238049, 0.5373811368757767, 0.5389503685911886, 0.5366650429615007, 0.5367476382829536, 0.5357509428407914, 0.5361973947696592, 0.5353616051836745, 0.5343887074084221, 0.5332543411309263, 0.5332443754428721, 0.5348811902591599, 0.5325968958666992, 0.5343372763797609, 0.5337204844798739, 0.5326558522985065, 0.5314915707458993, 0.5315945581089263, 0.5299031901059186, 0.5315703729833542], 'acc': [0.6536372892143961, 0.9096474518618209, 0.9213583856956299, 0.9338244546960184, 0.9405894058542773, 0.9438321506504458, 0.9462456067422138, 0.9481939168627802, 0.9502269041788786, 0.9516336931258703, 0.9530868634905427, 0.9541528223165613, 0.9550738624635846, 0.9558291936122861, 0.9564556577608812, 0.9570831253658424, 0.9576690147379745, 0.957997136784249, 0.9584598224303135, 0.9590568484897286, 0.9595549306964601, 0.9597859665491657, 0.960089117829544, 0.9602723551844252, 0.9603621095867353, 0.9606677070989624, 0.9606653170053788, 0.9607008651044848, 0.9607455228916466, 0.9609403863054544, 0.9609273526544414, 0.9610095471321668, 0.9610809191815859, 0.9611789540242887, 0.9611980870867903, 0.9612359463001225, 0.9613221800210568, 0.9614149988096199, 0.9615012476061021, 0.9614828554875589, 0.961576473863819, 0.9615656507094947, 0.961638362553742, 0.9616529566947845, 0.9617158445917339, 0.9617443181661538, 0.9617491368820936, 0.9618346718179317, 0.9619040896976823, 0.961915609544463, 0.9618846786415091, 0.9619585139343726, 0.9619732705539469, 0.9619690733235521, 0.9620089993033855, 0.9620758860071946, 0.9620701738906584, 0.9621424016304508, 0.9621777962052455, 0.9622152857900605, 0.9621479233238843, 0.9622113903909245, 0.9622536212640074, 0.962236381549382, 0.9622837130824677, 0.9623247177682858, 0.9623302087554335, 0.9623049245989348, 0.9623296671816806, 0.9623601214396575, 0.9624331570380567, 0.9624197160554211, 0.9624368047512087, 0.9624789567232303, 0.9624786608282353, 0.9624954630245535, 0.962582733107547, 0.9625382091354464, 0.9625880734175123, 0.9625895212964736, 0.9626298761820491, 0.9625756345673282, 0.9626886419985725, 0.9626466300768245, 0.9626662615577218, 0.9626852713893642, 0.9627213901883525, 0.962714536586638, 0.9627146885663819, 0.9627085186813337, 0.9627286642967786, 0.9627220666875468, 0.9627833461630506, 0.9627703976696649, 0.9627437806439793, 0.9627922956787489, 0.9624991191652074, 0.9620864718177309, 0.9619969183301937, 0.961881824864503, 0.9618081596164166, 0.9618089304623468, 0.9618439339910967, 0.9617256309142226, 0.9617785615185892, 0.9618000291271884, 0.9617427096165875, 0.9617527327490274, 0.961749622531116, 0.9617591030719543, 0.9618052744569316, 0.9618881241729159, 0.9618118336726295, 0.9617701458822778, 0.9617475555439624, 0.9618234583578162, 0.9618475908720041, 0.961870552347815, 0.9618509216142891, 0.9618913817724579, 0.9619386842292392, 0.9618653155523409, 0.9618162325936398, 0.9617722037159118, 0.9616887697548293, 0.9615988068715012, 0.9615753996349445, 0.9616435806934037], 'mDice': [0.03856329231807468, 0.19634521192067386, 0.32465436000128706, 0.4227467845384221, 0.4948020626970769, 0.5381776022475461, 0.5665524178781799, 0.5878568007022406, 0.6037455387493578, 0.6166345395178051, 0.6274206753075479, 0.6368100401223176, 0.6445341549897382, 0.653164115325346, 0.6604214341323872, 0.6664718713656741, 0.6733320938934425, 0.6778106898574747, 0.6820898434698425, 0.6865116521655616, 0.6903933171571682, 0.6936191852903605, 0.6971828071149175, 0.7008483428957356, 0.7023886202527369, 0.7059489509385726, 0.7068578949443247, 0.7089234290798895, 0.7103371660180384, 0.7124809231355533, 0.7138113003230363, 0.7159989712942691, 0.717071008263723, 0.7182674968131607, 0.7194256202429212, 0.7203113424242724, 0.7210461268895902, 0.7226306532572129, 0.7236562026324294, 0.7237255976354987, 0.7254147308380131, 0.7252578549220506, 0.7269730319733662, 0.7276448982482825, 0.7277971460778245, 0.7288145819825262, 0.729543197445406, 0.730408119869198, 0.7304882326329953, 0.7308346100003844, 0.7316457623367182, 0.7321404756638723, 0.7326718651582155, 0.7322087553611142, 0.733247070614865, 0.7342759081037283, 0.7344299878543392, 0.7348248624904132, 0.7350575943707224, 0.7359043217969448, 0.7363973539015659, 0.7366677746443638, 0.7372268133198188, 0.7370982015292343, 0.7373441958629575, 0.7383130552277862, 0.7387918957896354, 0.7388670765929385, 0.7393627878815, 0.7388777943180773, 0.739285823209547, 0.7394470367335977, 0.7406327547080653, 0.7398709778231085, 0.7409721870595469, 0.7408367493982841, 0.7417037861427488, 0.7412405328289945, 0.74207946957083, 0.7416224844748404, 0.742254158428127, 0.7417347541722643, 0.7425206735577138, 0.7422707733687735, 0.7431789331043823, 0.7433351432619444, 0.7433113093902309, 0.7431306210272005, 0.7432343667052315, 0.7435694590712721, 0.7435036406814269, 0.7440289458469471, 0.7442229977578231, 0.7450263243189056, 0.7451540861062569, 0.7454015025453065, 0.7450890369893032, 0.7462769441283458, 0.7463752201299892, 0.7464540070214191, 0.746726190742058, 0.7474982273772248, 0.7478496094990779, 0.747365010028128, 0.747979070388932, 0.7477525541968582, 0.7480663082068366, 0.7479813651535202, 0.7481606347566008, 0.7484087551198143, 0.7479452375996104, 0.7491476066376732, 0.7486302664079499, 0.7490930545008322, 0.7488362629501296, 0.7492211064248601, 0.7497874375015448, 0.7498882581246962, 0.7502785587270931, 0.7494982660585466, 0.7501507145651832, 0.749811461746536, 0.7499077292552905, 0.7509316818680546, 0.7513450277230322, 0.7510778451694746, 0.7515984647579229, 0.7509727394250574]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:40,  2.90s/it]predicting test subjects:  13%|█▎        | 2/15 [00:04<00:33,  2.59s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:29,  2.47s/it]predicting test subjects:  27%|██▋       | 4/15 [00:09<00:26,  2.39s/it]predicting test subjects:  33%|███▎      | 5/15 [00:11<00:23,  2.40s/it]predicting test subjects:  40%|████      | 6/15 [00:14<00:22,  2.45s/it]predicting test subjects:  47%|████▋     | 7/15 [00:15<00:17,  2.23s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:18<00:16,  2.32s/it]predicting test subjects:  60%|██████    | 9/15 [00:20<00:14,  2.34s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:22<00:10,  2.15s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:24<00:08,  2.06s/it]predicting test subjects:  80%|████████  | 12/15 [00:26<00:06,  2.18s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:28<00:04,  2.17s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:30<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 15/15 [00:32<00:00,  2.08s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:03<27:07,  3.07s/it]predicting train subjects:   0%|          | 2/532 [00:05<24:13,  2.74s/it]predicting train subjects:   1%|          | 3/532 [00:07<22:14,  2.52s/it]predicting train subjects:   1%|          | 4/532 [00:08<20:36,  2.34s/it]predicting train subjects:   1%|          | 5/532 [00:10<19:33,  2.23s/it]predicting train subjects:   1%|          | 6/532 [00:12<18:34,  2.12s/it]predicting train subjects:   1%|▏         | 7/532 [00:14<17:50,  2.04s/it]predicting train subjects:   2%|▏         | 8/532 [00:16<17:29,  2.00s/it]predicting train subjects:   2%|▏         | 9/532 [00:18<17:48,  2.04s/it]predicting train subjects:   2%|▏         | 10/532 [00:20<17:53,  2.06s/it]predicting train subjects:   2%|▏         | 11/532 [00:22<17:18,  1.99s/it]predicting train subjects:   2%|▏         | 12/532 [00:25<18:15,  2.11s/it]predicting train subjects:   2%|▏         | 13/532 [00:26<17:15,  2.00s/it]predicting train subjects:   3%|▎         | 14/532 [00:28<16:17,  1.89s/it]predicting train subjects:   3%|▎         | 15/532 [00:30<16:13,  1.88s/it]predicting train subjects:   3%|▎         | 16/532 [00:32<16:34,  1.93s/it]predicting train subjects:   3%|▎         | 17/532 [00:33<15:52,  1.85s/it]predicting train subjects:   3%|▎         | 18/532 [00:36<17:26,  2.04s/it]predicting train subjects:   4%|▎         | 19/532 [00:38<16:12,  1.90s/it]predicting train subjects:   4%|▍         | 20/532 [00:39<16:13,  1.90s/it]predicting train subjects:   4%|▍         | 21/532 [00:42<16:50,  1.98s/it]predicting train subjects:   4%|▍         | 22/532 [00:43<16:04,  1.89s/it]predicting train subjects:   4%|▍         | 23/532 [00:45<16:09,  1.90s/it]predicting train subjects:   5%|▍         | 24/532 [00:47<15:28,  1.83s/it]predicting train subjects:   5%|▍         | 25/532 [00:49<16:34,  1.96s/it]predicting train subjects:   5%|▍         | 26/532 [00:51<15:54,  1.89s/it]predicting train subjects:   5%|▌         | 27/532 [00:53<17:24,  2.07s/it]predicting train subjects:   5%|▌         | 28/532 [00:55<17:20,  2.06s/it]predicting train subjects:   5%|▌         | 29/532 [00:58<17:34,  2.10s/it]predicting train subjects:   6%|▌         | 30/532 [00:59<16:34,  1.98s/it]predicting train subjects:   6%|▌         | 31/532 [01:01<16:19,  1.95s/it]predicting train subjects:   6%|▌         | 32/532 [01:03<16:10,  1.94s/it]predicting train subjects:   6%|▌         | 33/532 [01:05<15:28,  1.86s/it]predicting train subjects:   6%|▋         | 34/532 [01:07<16:35,  2.00s/it]predicting train subjects:   7%|▋         | 35/532 [01:09<16:19,  1.97s/it]predicting train subjects:   7%|▋         | 36/532 [01:11<16:32,  2.00s/it]predicting train subjects:   7%|▋         | 37/532 [01:13<16:29,  2.00s/it]predicting train subjects:   7%|▋         | 38/532 [01:15<16:47,  2.04s/it]predicting train subjects:   7%|▋         | 39/532 [01:17<16:46,  2.04s/it]predicting train subjects:   8%|▊         | 40/532 [01:19<16:05,  1.96s/it]predicting train subjects:   8%|▊         | 41/532 [01:21<16:16,  1.99s/it]predicting train subjects:   8%|▊         | 42/532 [01:23<16:10,  1.98s/it]predicting train subjects:   8%|▊         | 43/532 [01:25<15:17,  1.88s/it]predicting train subjects:   8%|▊         | 44/532 [01:26<14:33,  1.79s/it]predicting train subjects:   8%|▊         | 45/532 [01:28<14:10,  1.75s/it]predicting train subjects:   9%|▊         | 46/532 [01:30<14:33,  1.80s/it]predicting train subjects:   9%|▉         | 47/532 [01:32<15:36,  1.93s/it]predicting train subjects:   9%|▉         | 48/532 [01:34<15:55,  1.97s/it]predicting train subjects:   9%|▉         | 49/532 [01:36<15:24,  1.91s/it]predicting train subjects:   9%|▉         | 50/532 [01:38<16:03,  2.00s/it]predicting train subjects:  10%|▉         | 51/532 [01:40<15:57,  1.99s/it]predicting train subjects:  10%|▉         | 52/532 [01:42<15:42,  1.96s/it]predicting train subjects:  10%|▉         | 53/532 [01:44<15:33,  1.95s/it]predicting train subjects:  10%|█         | 54/532 [01:46<16:06,  2.02s/it]predicting train subjects:  10%|█         | 55/532 [01:48<16:19,  2.05s/it]predicting train subjects:  11%|█         | 56/532 [01:50<16:08,  2.04s/it]predicting train subjects:  11%|█         | 57/532 [01:52<15:53,  2.01s/it]predicting train subjects:  11%|█         | 58/532 [01:54<16:13,  2.05s/it]predicting train subjects:  11%|█         | 59/532 [01:57<16:45,  2.13s/it]predicting train subjects:  11%|█▏        | 60/532 [01:58<15:33,  1.98s/it]predicting train subjects:  11%|█▏        | 61/532 [02:00<14:47,  1.88s/it]predicting train subjects:  12%|█▏        | 62/532 [02:02<16:23,  2.09s/it]predicting train subjects:  12%|█▏        | 63/532 [02:05<16:47,  2.15s/it]predicting train subjects:  12%|█▏        | 64/532 [02:06<15:47,  2.03s/it]predicting train subjects:  12%|█▏        | 65/532 [02:08<15:19,  1.97s/it]predicting train subjects:  12%|█▏        | 66/532 [02:11<16:39,  2.14s/it]predicting train subjects:  13%|█▎        | 67/532 [02:13<17:04,  2.20s/it]predicting train subjects:  13%|█▎        | 68/532 [02:15<16:46,  2.17s/it]predicting train subjects:  13%|█▎        | 69/532 [02:17<16:11,  2.10s/it]predicting train subjects:  13%|█▎        | 70/532 [02:19<15:43,  2.04s/it]predicting train subjects:  13%|█▎        | 71/532 [02:21<14:58,  1.95s/it]predicting train subjects:  14%|█▎        | 72/532 [02:23<14:20,  1.87s/it]predicting train subjects:  14%|█▎        | 73/532 [02:25<14:45,  1.93s/it]predicting train subjects:  14%|█▍        | 74/532 [02:27<15:48,  2.07s/it]predicting train subjects:  14%|█▍        | 75/532 [02:30<18:09,  2.38s/it]predicting train subjects:  14%|█▍        | 76/532 [02:32<16:45,  2.21s/it]predicting train subjects:  14%|█▍        | 77/532 [02:34<16:15,  2.14s/it]predicting train subjects:  15%|█▍        | 78/532 [02:36<16:32,  2.19s/it]predicting train subjects:  15%|█▍        | 79/532 [02:38<16:06,  2.13s/it]predicting train subjects:  15%|█▌        | 80/532 [02:40<15:47,  2.10s/it]predicting train subjects:  15%|█▌        | 81/532 [02:42<15:29,  2.06s/it]predicting train subjects:  15%|█▌        | 82/532 [02:44<15:16,  2.04s/it]predicting train subjects:  16%|█▌        | 83/532 [02:46<14:21,  1.92s/it]predicting train subjects:  16%|█▌        | 84/532 [02:47<13:43,  1.84s/it]predicting train subjects:  16%|█▌        | 85/532 [02:49<13:23,  1.80s/it]predicting train subjects:  16%|█▌        | 86/532 [02:51<13:15,  1.78s/it]predicting train subjects:  16%|█▋        | 87/532 [02:53<13:18,  1.79s/it]predicting train subjects:  17%|█▋        | 88/532 [02:54<13:09,  1.78s/it]predicting train subjects:  17%|█▋        | 89/532 [02:56<13:24,  1.82s/it]predicting train subjects:  17%|█▋        | 90/532 [02:58<13:43,  1.86s/it]predicting train subjects:  17%|█▋        | 91/532 [03:00<13:44,  1.87s/it]predicting train subjects:  17%|█▋        | 92/532 [03:02<13:56,  1.90s/it]predicting train subjects:  17%|█▋        | 93/532 [03:04<13:54,  1.90s/it]predicting train subjects:  18%|█▊        | 94/532 [03:06<13:50,  1.90s/it]predicting train subjects:  18%|█▊        | 95/532 [03:08<14:24,  1.98s/it]predicting train subjects:  18%|█▊        | 96/532 [03:10<14:30,  2.00s/it]predicting train subjects:  18%|█▊        | 97/532 [03:12<14:48,  2.04s/it]predicting train subjects:  18%|█▊        | 98/532 [03:14<14:52,  2.06s/it]predicting train subjects:  19%|█▊        | 99/532 [03:17<14:57,  2.07s/it]predicting train subjects:  19%|█▉        | 100/532 [03:19<14:56,  2.07s/it]predicting train subjects:  19%|█▉        | 101/532 [03:20<14:04,  1.96s/it]predicting train subjects:  19%|█▉        | 102/532 [03:22<13:28,  1.88s/it]predicting train subjects:  19%|█▉        | 103/532 [03:24<13:05,  1.83s/it]predicting train subjects:  20%|█▉        | 104/532 [03:26<13:00,  1.82s/it]predicting train subjects:  20%|█▉        | 105/532 [03:27<12:50,  1.80s/it]predicting train subjects:  20%|█▉        | 106/532 [03:29<12:38,  1.78s/it]predicting train subjects:  20%|██        | 107/532 [03:31<12:30,  1.77s/it]predicting train subjects:  20%|██        | 108/532 [03:33<12:35,  1.78s/it]predicting train subjects:  20%|██        | 109/532 [03:34<12:25,  1.76s/it]predicting train subjects:  21%|██        | 110/532 [03:36<12:11,  1.73s/it]predicting train subjects:  21%|██        | 111/532 [03:38<12:13,  1.74s/it]predicting train subjects:  21%|██        | 112/532 [03:40<12:22,  1.77s/it]predicting train subjects:  21%|██        | 113/532 [03:42<13:03,  1.87s/it]predicting train subjects:  21%|██▏       | 114/532 [03:44<13:19,  1.91s/it]predicting train subjects:  22%|██▏       | 115/532 [03:46<13:48,  1.99s/it]predicting train subjects:  22%|██▏       | 116/532 [03:48<14:05,  2.03s/it]predicting train subjects:  22%|██▏       | 117/532 [03:50<14:16,  2.06s/it]predicting train subjects:  22%|██▏       | 118/532 [03:52<14:15,  2.07s/it]predicting train subjects:  22%|██▏       | 119/532 [03:54<14:41,  2.13s/it]predicting train subjects:  23%|██▎       | 120/532 [03:57<14:30,  2.11s/it]predicting train subjects:  23%|██▎       | 121/532 [03:59<14:18,  2.09s/it]predicting train subjects:  23%|██▎       | 122/532 [04:00<13:54,  2.04s/it]predicting train subjects:  23%|██▎       | 123/532 [04:02<13:37,  2.00s/it]predicting train subjects:  23%|██▎       | 124/532 [04:04<13:44,  2.02s/it]predicting train subjects:  23%|██▎       | 125/532 [04:07<13:51,  2.04s/it]predicting train subjects:  24%|██▎       | 126/532 [04:09<13:51,  2.05s/it]predicting train subjects:  24%|██▍       | 127/532 [04:11<14:09,  2.10s/it]predicting train subjects:  24%|██▍       | 128/532 [04:13<14:21,  2.13s/it]predicting train subjects:  24%|██▍       | 129/532 [04:15<14:17,  2.13s/it]predicting train subjects:  24%|██▍       | 130/532 [04:17<14:15,  2.13s/it]predicting train subjects:  25%|██▍       | 131/532 [04:20<14:41,  2.20s/it]predicting train subjects:  25%|██▍       | 132/532 [04:22<14:57,  2.24s/it]predicting train subjects:  25%|██▌       | 133/532 [04:24<15:10,  2.28s/it]predicting train subjects:  25%|██▌       | 134/532 [04:27<15:24,  2.32s/it]predicting train subjects:  25%|██▌       | 135/532 [04:29<15:32,  2.35s/it]predicting train subjects:  26%|██▌       | 136/532 [04:32<15:31,  2.35s/it]predicting train subjects:  26%|██▌       | 137/532 [04:34<15:44,  2.39s/it]predicting train subjects:  26%|██▌       | 138/532 [04:36<15:38,  2.38s/it]predicting train subjects:  26%|██▌       | 139/532 [04:39<15:38,  2.39s/it]predicting train subjects:  26%|██▋       | 140/532 [04:41<15:34,  2.38s/it]predicting train subjects:  27%|██▋       | 141/532 [04:44<15:33,  2.39s/it]predicting train subjects:  27%|██▋       | 142/532 [04:46<16:02,  2.47s/it]predicting train subjects:  27%|██▋       | 143/532 [04:49<15:54,  2.45s/it]predicting train subjects:  27%|██▋       | 144/532 [04:51<14:48,  2.29s/it]predicting train subjects:  27%|██▋       | 145/532 [04:52<13:51,  2.15s/it]predicting train subjects:  27%|██▋       | 146/532 [04:54<13:15,  2.06s/it]predicting train subjects:  28%|██▊       | 147/532 [04:56<13:02,  2.03s/it]predicting train subjects:  28%|██▊       | 148/532 [04:58<12:37,  1.97s/it]predicting train subjects:  28%|██▊       | 149/532 [05:00<13:00,  2.04s/it]predicting train subjects:  28%|██▊       | 150/532 [05:02<12:50,  2.02s/it]predicting train subjects:  28%|██▊       | 151/532 [05:04<12:40,  2.00s/it]predicting train subjects:  29%|██▊       | 152/532 [05:06<12:41,  2.00s/it]predicting train subjects:  29%|██▉       | 153/532 [05:08<12:30,  1.98s/it]predicting train subjects:  29%|██▉       | 154/532 [05:10<12:24,  1.97s/it]predicting train subjects:  29%|██▉       | 155/532 [05:13<13:32,  2.16s/it]predicting train subjects:  29%|██▉       | 156/532 [05:15<14:12,  2.27s/it]predicting train subjects:  30%|██▉       | 157/532 [05:18<15:17,  2.45s/it]predicting train subjects:  30%|██▉       | 158/532 [05:20<15:13,  2.44s/it]predicting train subjects:  30%|██▉       | 159/532 [05:23<15:09,  2.44s/it]predicting train subjects:  30%|███       | 160/532 [05:25<15:10,  2.45s/it]predicting train subjects:  30%|███       | 161/532 [05:27<14:19,  2.32s/it]predicting train subjects:  30%|███       | 162/532 [05:29<13:47,  2.24s/it]predicting train subjects:  31%|███       | 163/532 [05:31<13:21,  2.17s/it]predicting train subjects:  31%|███       | 164/532 [05:33<13:01,  2.12s/it]predicting train subjects:  31%|███       | 165/532 [05:35<12:44,  2.08s/it]predicting train subjects:  31%|███       | 166/532 [05:38<12:46,  2.10s/it]predicting train subjects:  31%|███▏      | 167/532 [05:40<12:46,  2.10s/it]predicting train subjects:  32%|███▏      | 168/532 [05:42<12:38,  2.08s/it]predicting train subjects:  32%|███▏      | 169/532 [05:44<12:23,  2.05s/it]predicting train subjects:  32%|███▏      | 170/532 [05:46<12:04,  2.00s/it]predicting train subjects:  32%|███▏      | 171/532 [05:48<11:55,  1.98s/it]predicting train subjects:  32%|███▏      | 172/532 [05:50<11:58,  2.00s/it]predicting train subjects:  33%|███▎      | 173/532 [05:52<12:04,  2.02s/it]predicting train subjects:  33%|███▎      | 174/532 [05:54<12:01,  2.01s/it]predicting train subjects:  33%|███▎      | 175/532 [05:56<11:47,  1.98s/it]predicting train subjects:  33%|███▎      | 176/532 [05:57<11:40,  1.97s/it]predicting train subjects:  33%|███▎      | 177/532 [05:59<11:31,  1.95s/it]predicting train subjects:  33%|███▎      | 178/532 [06:01<11:24,  1.93s/it]predicting train subjects:  34%|███▎      | 179/532 [06:03<11:17,  1.92s/it]predicting train subjects:  34%|███▍      | 180/532 [06:05<11:08,  1.90s/it]predicting train subjects:  34%|███▍      | 181/532 [06:07<11:03,  1.89s/it]predicting train subjects:  34%|███▍      | 182/532 [06:09<10:55,  1.87s/it]predicting train subjects:  34%|███▍      | 183/532 [06:11<10:55,  1.88s/it]predicting train subjects:  35%|███▍      | 184/532 [06:13<10:58,  1.89s/it]predicting train subjects:  35%|███▍      | 185/532 [06:14<10:52,  1.88s/it]predicting train subjects:  35%|███▍      | 186/532 [06:16<10:57,  1.90s/it]predicting train subjects:  35%|███▌      | 187/532 [06:18<10:45,  1.87s/it]predicting train subjects:  35%|███▌      | 188/532 [06:20<11:00,  1.92s/it]predicting train subjects:  36%|███▌      | 189/532 [06:22<10:40,  1.87s/it]predicting train subjects:  36%|███▌      | 190/532 [06:24<10:40,  1.87s/it]predicting train subjects:  36%|███▌      | 191/532 [06:26<11:56,  2.10s/it]predicting train subjects:  36%|███▌      | 192/532 [06:29<12:40,  2.24s/it]predicting train subjects:  36%|███▋      | 193/532 [06:31<13:00,  2.30s/it]predicting train subjects:  36%|███▋      | 194/532 [06:34<13:10,  2.34s/it]predicting train subjects:  37%|███▋      | 195/532 [06:36<13:21,  2.38s/it]predicting train subjects:  37%|███▋      | 196/532 [06:39<13:48,  2.46s/it]predicting train subjects:  37%|███▋      | 197/532 [06:41<13:16,  2.38s/it]predicting train subjects:  37%|███▋      | 198/532 [06:43<13:07,  2.36s/it]predicting train subjects:  37%|███▋      | 199/532 [06:46<12:48,  2.31s/it]predicting train subjects:  38%|███▊      | 200/532 [06:48<12:35,  2.27s/it]predicting train subjects:  38%|███▊      | 201/532 [06:50<12:32,  2.27s/it]predicting train subjects:  38%|███▊      | 202/532 [06:53<12:42,  2.31s/it]predicting train subjects:  38%|███▊      | 203/532 [06:54<11:59,  2.19s/it]predicting train subjects:  38%|███▊      | 204/532 [06:56<11:29,  2.10s/it]predicting train subjects:  39%|███▊      | 205/532 [06:58<11:03,  2.03s/it]predicting train subjects:  39%|███▊      | 206/532 [07:00<10:41,  1.97s/it]predicting train subjects:  39%|███▉      | 207/532 [07:02<10:34,  1.95s/it]predicting train subjects:  39%|███▉      | 208/532 [07:04<10:33,  1.96s/it]predicting train subjects:  39%|███▉      | 209/532 [07:06<10:11,  1.89s/it]predicting train subjects:  39%|███▉      | 210/532 [07:07<09:52,  1.84s/it]predicting train subjects:  40%|███▉      | 211/532 [07:09<10:09,  1.90s/it]predicting train subjects:  40%|███▉      | 212/532 [07:11<09:51,  1.85s/it]predicting train subjects:  40%|████      | 213/532 [07:13<09:38,  1.81s/it]predicting train subjects:  40%|████      | 214/532 [07:15<09:29,  1.79s/it]predicting train subjects:  40%|████      | 215/532 [07:17<10:30,  1.99s/it]predicting train subjects:  41%|████      | 216/532 [07:19<10:55,  2.07s/it]predicting train subjects:  41%|████      | 217/532 [07:22<11:27,  2.18s/it]predicting train subjects:  41%|████      | 218/532 [07:24<11:40,  2.23s/it]predicting train subjects:  41%|████      | 219/532 [07:26<11:45,  2.26s/it]predicting train subjects:  41%|████▏     | 220/532 [07:29<12:00,  2.31s/it]predicting train subjects:  42%|████▏     | 221/532 [07:31<11:08,  2.15s/it]predicting train subjects:  42%|████▏     | 222/532 [07:32<10:18,  2.00s/it]predicting train subjects:  42%|████▏     | 223/532 [07:34<09:54,  1.92s/it]predicting train subjects:  42%|████▏     | 224/532 [07:36<09:36,  1.87s/it]predicting train subjects:  42%|████▏     | 225/532 [07:38<09:24,  1.84s/it]predicting train subjects:  42%|████▏     | 226/532 [07:39<09:26,  1.85s/it]predicting train subjects:  43%|████▎     | 227/532 [07:41<09:33,  1.88s/it]predicting train subjects:  43%|████▎     | 228/532 [07:43<09:07,  1.80s/it]predicting train subjects:  43%|████▎     | 229/532 [07:45<08:42,  1.73s/it]predicting train subjects:  43%|████▎     | 230/532 [07:46<08:29,  1.69s/it]predicting train subjects:  43%|████▎     | 231/532 [07:48<08:31,  1.70s/it]predicting train subjects:  44%|████▎     | 232/532 [07:49<08:19,  1.66s/it]predicting train subjects:  44%|████▍     | 233/532 [07:51<08:38,  1.73s/it]predicting train subjects:  44%|████▍     | 234/532 [07:53<09:07,  1.84s/it]predicting train subjects:  44%|████▍     | 235/532 [07:55<09:12,  1.86s/it]predicting train subjects:  44%|████▍     | 236/532 [07:58<09:47,  1.99s/it]predicting train subjects:  45%|████▍     | 237/532 [07:59<09:39,  1.96s/it]predicting train subjects:  45%|████▍     | 238/532 [08:01<09:28,  1.93s/it]predicting train subjects:  45%|████▍     | 239/532 [08:03<09:39,  1.98s/it]predicting train subjects:  45%|████▌     | 240/532 [08:06<09:58,  2.05s/it]predicting train subjects:  45%|████▌     | 241/532 [08:08<10:06,  2.08s/it]predicting train subjects:  45%|████▌     | 242/532 [08:10<10:11,  2.11s/it]predicting train subjects:  46%|████▌     | 243/532 [08:12<10:09,  2.11s/it]predicting train subjects:  46%|████▌     | 244/532 [08:14<10:09,  2.12s/it]predicting train subjects:  46%|████▌     | 245/532 [08:16<09:28,  1.98s/it]predicting train subjects:  46%|████▌     | 246/532 [08:18<08:54,  1.87s/it]predicting train subjects:  46%|████▋     | 247/532 [08:19<08:36,  1.81s/it]predicting train subjects:  47%|████▋     | 248/532 [08:21<08:23,  1.77s/it]predicting train subjects:  47%|████▋     | 249/532 [08:23<08:15,  1.75s/it]predicting train subjects:  47%|████▋     | 250/532 [08:25<09:08,  1.94s/it]predicting train subjects:  47%|████▋     | 251/532 [08:27<08:52,  1.89s/it]predicting train subjects:  47%|████▋     | 252/532 [08:28<08:35,  1.84s/it]predicting train subjects:  48%|████▊     | 253/532 [08:30<08:36,  1.85s/it]predicting train subjects:  48%|████▊     | 254/532 [08:32<08:27,  1.83s/it]predicting train subjects:  48%|████▊     | 255/532 [08:34<08:17,  1.80s/it]predicting train subjects:  48%|████▊     | 256/532 [08:36<08:13,  1.79s/it]predicting train subjects:  48%|████▊     | 257/532 [08:38<08:41,  1.90s/it]predicting train subjects:  48%|████▊     | 258/532 [08:40<09:02,  1.98s/it]predicting train subjects:  49%|████▊     | 259/532 [08:42<09:24,  2.07s/it]predicting train subjects:  49%|████▉     | 260/532 [08:44<09:36,  2.12s/it]predicting train subjects:  49%|████▉     | 261/532 [08:47<09:44,  2.16s/it]predicting train subjects:  49%|████▉     | 262/532 [08:49<09:49,  2.18s/it]predicting train subjects:  49%|████▉     | 263/532 [08:50<08:57,  2.00s/it]predicting train subjects:  50%|████▉     | 264/532 [08:52<08:31,  1.91s/it]predicting train subjects:  50%|████▉     | 265/532 [08:54<08:03,  1.81s/it]predicting train subjects:  50%|█████     | 266/532 [08:55<07:43,  1.74s/it]predicting train subjects:  50%|█████     | 267/532 [08:57<07:22,  1.67s/it]predicting train subjects:  50%|█████     | 268/532 [08:58<07:08,  1.62s/it]predicting train subjects:  51%|█████     | 269/532 [09:01<07:54,  1.80s/it]predicting train subjects:  51%|█████     | 270/532 [09:02<07:57,  1.82s/it]predicting train subjects:  51%|█████     | 271/532 [09:04<07:51,  1.81s/it]predicting train subjects:  51%|█████     | 272/532 [09:06<07:56,  1.83s/it]predicting train subjects:  51%|█████▏    | 273/532 [09:08<07:54,  1.83s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:10<07:45,  1.81s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:12<08:40,  2.03s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:15<09:03,  2.12s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:17<09:36,  2.26s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:19<09:36,  2.27s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:22<09:47,  2.32s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:24<09:49,  2.34s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:27<09:47,  2.34s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:29<09:40,  2.32s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:31<09:31,  2.30s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:33<09:20,  2.26s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:36<09:21,  2.28s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:38<09:14,  2.25s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:40<09:21,  2.29s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:42<08:36,  2.12s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:44<08:13,  2.03s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:47<09:33,  2.37s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:49<08:46,  2.19s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:50<08:14,  2.06s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:52<08:03,  2.02s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:54<07:46,  1.96s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:56<07:41,  1.95s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:58<07:33,  1.92s/it]predicting train subjects:  56%|█████▌    | 297/532 [10:00<07:32,  1.92s/it]predicting train subjects:  56%|█████▌    | 298/532 [10:02<07:28,  1.92s/it]predicting train subjects:  56%|█████▌    | 299/532 [10:03<07:03,  1.82s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:05<06:50,  1.77s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:07<06:46,  1.76s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:08<06:39,  1.74s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:10<06:23,  1.67s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:12<06:17,  1.65s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:14<06:57,  1.84s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:16<07:30,  1.99s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:20<09:31,  2.54s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:22<09:22,  2.51s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:25<09:03,  2.44s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:27<09:04,  2.45s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:30<09:47,  2.66s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:33<10:12,  2.78s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:36<10:26,  2.86s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:40<10:41,  2.94s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:43<10:49,  2.99s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:46<10:50,  3.01s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:48<09:35,  2.68s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:49<08:35,  2.41s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:51<07:49,  2.20s/it]predicting train subjects:  60%|██████    | 320/532 [10:53<07:23,  2.09s/it]predicting train subjects:  60%|██████    | 321/532 [10:55<07:02,  2.00s/it]predicting train subjects:  61%|██████    | 322/532 [10:56<06:40,  1.91s/it]predicting train subjects:  61%|██████    | 323/532 [10:59<07:11,  2.06s/it]predicting train subjects:  61%|██████    | 324/532 [11:01<07:31,  2.17s/it]predicting train subjects:  61%|██████    | 325/532 [11:04<07:55,  2.30s/it]predicting train subjects:  61%|██████▏   | 326/532 [11:07<08:10,  2.38s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:09<08:35,  2.52s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:12<08:29,  2.50s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:14<07:47,  2.30s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:16<07:32,  2.24s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:18<07:05,  2.12s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:19<06:47,  2.04s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:22<06:48,  2.05s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:23<06:36,  2.00s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:26<07:06,  2.17s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:28<06:59,  2.14s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:30<06:56,  2.13s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:32<06:50,  2.11s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:34<06:52,  2.14s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:37<06:50,  2.14s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:38<06:20,  1.99s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:40<06:02,  1.91s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:42<05:44,  1.83s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:43<05:28,  1.75s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:45<05:21,  1.72s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:46<05:21,  1.73s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:48<05:25,  1.76s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:50<05:26,  1.77s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:52<05:32,  1.82s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:54<05:35,  1.84s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:56<05:34,  1.85s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:58<05:32,  1.85s/it]predicting train subjects:  66%|██████▋   | 353/532 [12:00<05:33,  1.86s/it]predicting train subjects:  67%|██████▋   | 354/532 [12:02<05:41,  1.92s/it]predicting train subjects:  67%|██████▋   | 355/532 [12:04<05:46,  1.96s/it]predicting train subjects:  67%|██████▋   | 356/532 [12:06<05:50,  1.99s/it]predicting train subjects:  67%|██████▋   | 357/532 [12:08<05:51,  2.01s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:10<05:39,  1.95s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:11<05:19,  1.85s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:13<05:04,  1.77s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:14<04:55,  1.73s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:16<04:46,  1.68s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:18<04:40,  1.66s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:19<04:34,  1.64s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:21<04:34,  1.64s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:23<04:35,  1.66s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:24<04:35,  1.67s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:26<04:36,  1.68s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:28<04:34,  1.69s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:29<04:30,  1.67s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:32<05:03,  1.89s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:34<05:25,  2.03s/it]predicting train subjects:  70%|███████   | 373/532 [12:37<05:44,  2.17s/it]predicting train subjects:  70%|███████   | 374/532 [12:39<05:54,  2.24s/it]predicting train subjects:  70%|███████   | 375/532 [12:41<06:05,  2.33s/it]predicting train subjects:  71%|███████   | 376/532 [12:44<06:01,  2.31s/it]predicting train subjects:  71%|███████   | 377/532 [12:46<05:39,  2.19s/it]predicting train subjects:  71%|███████   | 378/532 [12:48<05:24,  2.11s/it]predicting train subjects:  71%|███████   | 379/532 [12:50<05:16,  2.07s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:51<05:03,  1.99s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:53<05:00,  1.99s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:55<04:51,  1.94s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:57<05:04,  2.05s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:59<04:59,  2.03s/it]predicting train subjects:  72%|███████▏  | 385/532 [13:02<05:00,  2.04s/it]predicting train subjects:  73%|███████▎  | 386/532 [13:03<04:53,  2.01s/it]predicting train subjects:  73%|███████▎  | 387/532 [13:05<04:51,  2.01s/it]predicting train subjects:  73%|███████▎  | 388/532 [13:07<04:46,  1.99s/it]predicting train subjects:  73%|███████▎  | 389/532 [13:09<04:44,  1.99s/it]predicting train subjects:  73%|███████▎  | 390/532 [13:11<04:43,  1.99s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:13<04:40,  1.99s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:15<04:38,  1.99s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:17<04:38,  2.00s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:19<04:34,  1.99s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:22<04:49,  2.11s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:24<04:42,  2.08s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:26<04:41,  2.08s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:28<04:33,  2.04s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:30<04:29,  2.03s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:32<04:26,  2.02s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:34<04:26,  2.03s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:36<04:24,  2.04s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:38<04:24,  2.05s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:40<04:24,  2.07s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:42<04:22,  2.07s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:44<04:21,  2.08s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:46<04:09,  2.00s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:48<04:01,  1.94s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:50<03:56,  1.93s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:52<03:52,  1.91s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:54<03:50,  1.91s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:55<03:47,  1.90s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:57<03:40,  1.85s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:59<03:41,  1.88s/it]predicting train subjects:  78%|███████▊  | 415/532 [14:01<03:35,  1.84s/it]predicting train subjects:  78%|███████▊  | 416/532 [14:03<03:32,  1.83s/it]predicting train subjects:  78%|███████▊  | 417/532 [14:04<03:27,  1.81s/it]predicting train subjects:  79%|███████▊  | 418/532 [14:06<03:23,  1.78s/it]predicting train subjects:  79%|███████▉  | 419/532 [14:09<03:41,  1.96s/it]predicting train subjects:  79%|███████▉  | 420/532 [14:11<03:40,  1.97s/it]predicting train subjects:  79%|███████▉  | 421/532 [14:13<03:41,  1.99s/it]predicting train subjects:  79%|███████▉  | 422/532 [14:15<03:43,  2.03s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:17<03:42,  2.05s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:19<03:42,  2.06s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:21<03:38,  2.04s/it]predicting train subjects:  80%|████████  | 426/532 [14:23<03:33,  2.01s/it]predicting train subjects:  80%|████████  | 427/532 [14:25<03:32,  2.02s/it]predicting train subjects:  80%|████████  | 428/532 [14:27<03:30,  2.03s/it]predicting train subjects:  81%|████████  | 429/532 [14:29<03:28,  2.03s/it]predicting train subjects:  81%|████████  | 430/532 [14:31<03:25,  2.02s/it]predicting train subjects:  81%|████████  | 431/532 [14:33<03:28,  2.07s/it]predicting train subjects:  81%|████████  | 432/532 [14:35<03:31,  2.11s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:38<03:33,  2.15s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:40<03:30,  2.15s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:42<03:27,  2.14s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:44<03:24,  2.13s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:46<03:07,  1.98s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:47<02:54,  1.86s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:49<02:47,  1.80s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:50<02:41,  1.75s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:52<02:34,  1.70s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:54<02:29,  1.66s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:55<02:25,  1.64s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:57<02:23,  1.63s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:58<02:19,  1.61s/it]predicting train subjects:  84%|████████▍ | 446/532 [15:00<02:16,  1.59s/it]predicting train subjects:  84%|████████▍ | 447/532 [15:01<02:15,  1.59s/it]predicting train subjects:  84%|████████▍ | 448/532 [15:03<02:12,  1.58s/it]predicting train subjects:  84%|████████▍ | 449/532 [15:05<02:22,  1.71s/it]predicting train subjects:  85%|████████▍ | 450/532 [15:07<02:20,  1.72s/it]predicting train subjects:  85%|████████▍ | 451/532 [15:08<02:17,  1.70s/it]predicting train subjects:  85%|████████▍ | 452/532 [15:10<02:14,  1.68s/it]predicting train subjects:  85%|████████▌ | 453/532 [15:12<02:12,  1.68s/it]predicting train subjects:  85%|████████▌ | 454/532 [15:14<02:16,  1.75s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:16<02:19,  1.81s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:18<02:19,  1.83s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:20<02:23,  1.91s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:21<02:20,  1.90s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:23<02:19,  1.91s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:25<02:17,  1.91s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:28<02:22,  2.01s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:30<02:25,  2.08s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:32<02:26,  2.12s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:34<02:24,  2.13s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:36<02:24,  2.16s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:39<02:22,  2.16s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:40<02:12,  2.04s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:42<02:05,  1.97s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:44<02:02,  1.94s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:46<01:57,  1.90s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:48<01:54,  1.88s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:49<01:51,  1.86s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:52<01:54,  1.95s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:54<01:53,  1.96s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:56<01:52,  1.98s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:58<01:53,  2.02s/it]predicting train subjects:  90%|████████▉ | 477/532 [16:00<01:54,  2.07s/it]predicting train subjects:  90%|████████▉ | 478/532 [16:02<01:51,  2.07s/it]predicting train subjects:  90%|█████████ | 479/532 [16:04<01:44,  1.98s/it]predicting train subjects:  90%|█████████ | 480/532 [16:07<01:56,  2.24s/it]predicting train subjects:  90%|█████████ | 481/532 [16:08<01:47,  2.11s/it]predicting train subjects:  91%|█████████ | 482/532 [16:10<01:39,  1.99s/it]predicting train subjects:  91%|█████████ | 483/532 [16:12<01:33,  1.90s/it]predicting train subjects:  91%|█████████ | 484/532 [16:14<01:28,  1.84s/it]predicting train subjects:  91%|█████████ | 485/532 [16:16<01:30,  1.93s/it]predicting train subjects:  91%|█████████▏| 486/532 [16:18<01:30,  1.97s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:20<01:31,  2.04s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:22<01:31,  2.08s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:25<01:33,  2.19s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:27<01:31,  2.17s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:28<01:24,  2.05s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:30<01:19,  1.98s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:32<01:15,  1.94s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:34<01:12,  1.92s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:36<01:09,  1.89s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:38<01:10,  1.96s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:40<01:08,  1.96s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:42<01:05,  1.94s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:44<01:02,  1.91s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:46<01:01,  1.93s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:48<01:01,  1.97s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:49<00:57,  1.93s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:51<00:53,  1.86s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:53<00:51,  1.85s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:55<00:49,  1.83s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:57<00:47,  1.81s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:58<00:45,  1.80s/it]predicting train subjects:  95%|█████████▌| 508/532 [17:00<00:43,  1.79s/it]predicting train subjects:  96%|█████████▌| 509/532 [17:02<00:45,  1.97s/it]predicting train subjects:  96%|█████████▌| 510/532 [17:05<00:45,  2.07s/it]predicting train subjects:  96%|█████████▌| 511/532 [17:07<00:44,  2.10s/it]predicting train subjects:  96%|█████████▌| 512/532 [17:09<00:42,  2.14s/it]predicting train subjects:  96%|█████████▋| 513/532 [17:11<00:41,  2.16s/it]predicting train subjects:  97%|█████████▋| 514/532 [17:14<00:39,  2.19s/it]predicting train subjects:  97%|█████████▋| 515/532 [17:15<00:35,  2.08s/it]predicting train subjects:  97%|█████████▋| 516/532 [17:17<00:32,  2.01s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:19<00:29,  1.98s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:21<00:27,  1.95s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:23<00:24,  1.91s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:25<00:23,  1.94s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:27<00:21,  1.97s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:29<00:20,  2.01s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:31<00:18,  2.04s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:33<00:16,  2.03s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:35<00:14,  2.00s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:37<00:12,  2.02s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:39<00:09,  1.94s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:41<00:07,  1.89s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:42<00:05,  1.85s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:44<00:03,  1.82s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:46<00:01,  1.79s/it]predicting train subjects: 100%|██████████| 532/532 [17:48<00:00,  1.79s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<14:42,  1.66s/it]Loading train:   0%|          | 2/532 [00:02<12:55,  1.46s/it]Loading train:   1%|          | 3/532 [00:03<12:18,  1.40s/it]Loading train:   1%|          | 4/532 [00:04<10:57,  1.24s/it]Loading train:   1%|          | 5/532 [00:05<10:37,  1.21s/it]Loading train:   1%|          | 6/532 [00:07<10:53,  1.24s/it]Loading train:   1%|▏         | 7/532 [00:08<10:18,  1.18s/it]Loading train:   2%|▏         | 8/532 [00:09<09:35,  1.10s/it]Loading train:   2%|▏         | 9/532 [00:10<10:31,  1.21s/it]Loading train:   2%|▏         | 10/532 [00:11<09:48,  1.13s/it]Loading train:   2%|▏         | 11/532 [00:12<09:01,  1.04s/it]Loading train:   2%|▏         | 12/532 [00:13<09:57,  1.15s/it]Loading train:   2%|▏         | 13/532 [00:14<09:10,  1.06s/it]Loading train:   3%|▎         | 14/532 [00:15<08:26,  1.02it/s]Loading train:   3%|▎         | 15/532 [00:16<08:34,  1.01it/s]Loading train:   3%|▎         | 16/532 [00:17<08:27,  1.02it/s]Loading train:   3%|▎         | 17/532 [00:18<08:01,  1.07it/s]Loading train:   3%|▎         | 18/532 [00:21<12:53,  1.50s/it]Loading train:   4%|▎         | 19/532 [00:21<11:10,  1.31s/it]Loading train:   4%|▍         | 20/532 [00:22<10:27,  1.23s/it]Loading train:   4%|▍         | 21/532 [00:24<10:43,  1.26s/it]Loading train:   4%|▍         | 22/532 [00:25<10:29,  1.23s/it]Loading train:   4%|▍         | 23/532 [00:26<09:57,  1.17s/it]Loading train:   5%|▍         | 24/532 [00:27<09:04,  1.07s/it]Loading train:   5%|▍         | 25/532 [00:28<09:26,  1.12s/it]Loading train:   5%|▍         | 26/532 [00:29<09:00,  1.07s/it]Loading train:   5%|▌         | 27/532 [00:30<09:56,  1.18s/it]Loading train:   5%|▌         | 28/532 [00:33<13:17,  1.58s/it]Loading train:   5%|▌         | 29/532 [00:34<12:05,  1.44s/it]Loading train:   6%|▌         | 30/532 [00:35<10:56,  1.31s/it]Loading train:   6%|▌         | 31/532 [00:36<10:03,  1.21s/it]Loading train:   6%|▌         | 32/532 [00:37<09:55,  1.19s/it]Loading train:   6%|▌         | 33/532 [00:38<09:19,  1.12s/it]Loading train:   6%|▋         | 34/532 [00:40<09:52,  1.19s/it]Loading train:   7%|▋         | 35/532 [00:41<09:18,  1.12s/it]Loading train:   7%|▋         | 36/532 [00:42<09:11,  1.11s/it]Loading train:   7%|▋         | 37/532 [00:43<08:43,  1.06s/it]Loading train:   7%|▋         | 38/532 [00:44<09:00,  1.09s/it]Loading train:   7%|▋         | 39/532 [00:45<08:52,  1.08s/it]Loading train:   8%|▊         | 40/532 [00:46<08:25,  1.03s/it]Loading train:   8%|▊         | 41/532 [00:47<08:45,  1.07s/it]Loading train:   8%|▊         | 42/532 [00:48<08:53,  1.09s/it]Loading train:   8%|▊         | 43/532 [00:49<08:17,  1.02s/it]Loading train:   8%|▊         | 44/532 [00:50<07:51,  1.04it/s]Loading train:   8%|▊         | 45/532 [00:50<07:29,  1.08it/s]Loading train:   9%|▊         | 46/532 [00:52<07:53,  1.03it/s]Loading train:   9%|▉         | 47/532 [00:53<08:20,  1.03s/it]Loading train:   9%|▉         | 48/532 [00:54<08:40,  1.08s/it]Loading train:   9%|▉         | 49/532 [00:55<08:15,  1.03s/it]Loading train:   9%|▉         | 50/532 [00:56<08:26,  1.05s/it]Loading train:  10%|▉         | 51/532 [00:57<08:10,  1.02s/it]Loading train:  10%|▉         | 52/532 [00:58<08:03,  1.01s/it]Loading train:  10%|▉         | 53/532 [00:59<07:49,  1.02it/s]Loading train:  10%|█         | 54/532 [01:00<07:58,  1.00s/it]Loading train:  10%|█         | 55/532 [01:01<08:10,  1.03s/it]Loading train:  11%|█         | 56/532 [01:02<08:01,  1.01s/it]Loading train:  11%|█         | 57/532 [01:03<09:08,  1.15s/it]Loading train:  11%|█         | 58/532 [01:04<08:56,  1.13s/it]Loading train:  11%|█         | 59/532 [01:06<09:14,  1.17s/it]Loading train:  11%|█▏        | 60/532 [01:07<08:19,  1.06s/it]Loading train:  11%|█▏        | 61/532 [01:07<07:44,  1.01it/s]Loading train:  12%|█▏        | 62/532 [01:09<08:33,  1.09s/it]Loading train:  12%|█▏        | 63/532 [01:10<08:43,  1.12s/it]Loading train:  12%|█▏        | 64/532 [01:11<09:06,  1.17s/it]Loading train:  12%|█▏        | 65/532 [01:12<08:40,  1.11s/it]Loading train:  12%|█▏        | 66/532 [01:13<09:07,  1.17s/it]Loading train:  13%|█▎        | 67/532 [01:15<09:08,  1.18s/it]Loading train:  13%|█▎        | 68/532 [01:16<08:34,  1.11s/it]Loading train:  13%|█▎        | 69/532 [01:17<08:16,  1.07s/it]Loading train:  13%|█▎        | 70/532 [01:17<07:54,  1.03s/it]Loading train:  13%|█▎        | 71/532 [01:18<07:26,  1.03it/s]Loading train:  14%|█▎        | 72/532 [01:19<07:22,  1.04it/s]Loading train:  14%|█▎        | 73/532 [01:20<07:39,  1.00s/it]Loading train:  14%|█▍        | 74/532 [01:22<08:09,  1.07s/it]Loading train:  14%|█▍        | 75/532 [01:23<08:57,  1.18s/it]Loading train:  14%|█▍        | 76/532 [01:24<08:19,  1.10s/it]Loading train:  14%|█▍        | 77/532 [01:25<07:52,  1.04s/it]Loading train:  15%|█▍        | 78/532 [01:26<07:45,  1.03s/it]Loading train:  15%|█▍        | 79/532 [01:27<07:30,  1.01it/s]Loading train:  15%|█▌        | 80/532 [01:28<07:22,  1.02it/s]Loading train:  15%|█▌        | 81/532 [01:29<07:02,  1.07it/s]Loading train:  15%|█▌        | 82/532 [01:29<06:59,  1.07it/s]Loading train:  16%|█▌        | 83/532 [01:30<06:39,  1.12it/s]Loading train:  16%|█▌        | 84/532 [01:31<06:48,  1.10it/s]Loading train:  16%|█▌        | 85/532 [01:32<06:33,  1.14it/s]Loading train:  16%|█▌        | 86/532 [01:33<06:11,  1.20it/s]Loading train:  16%|█▋        | 87/532 [01:34<06:03,  1.23it/s]Loading train:  17%|█▋        | 88/532 [01:34<05:56,  1.24it/s]Loading train:  17%|█▋        | 89/532 [01:35<06:26,  1.15it/s]Loading train:  17%|█▋        | 90/532 [01:36<06:33,  1.12it/s]Loading train:  17%|█▋        | 91/532 [01:37<06:44,  1.09it/s]Loading train:  17%|█▋        | 92/532 [01:38<06:43,  1.09it/s]Loading train:  17%|█▋        | 93/532 [01:39<06:38,  1.10it/s]Loading train:  18%|█▊        | 94/532 [01:40<06:48,  1.07it/s]Loading train:  18%|█▊        | 95/532 [01:41<07:07,  1.02it/s]Loading train:  18%|█▊        | 96/532 [01:42<07:17,  1.00s/it]Loading train:  18%|█▊        | 97/532 [01:43<07:26,  1.03s/it]Loading train:  18%|█▊        | 98/532 [01:44<07:48,  1.08s/it]Loading train:  19%|█▊        | 99/532 [01:46<07:58,  1.11s/it]Loading train:  19%|█▉        | 100/532 [01:47<07:52,  1.09s/it]Loading train:  19%|█▉        | 101/532 [01:48<07:35,  1.06s/it]Loading train:  19%|█▉        | 102/532 [01:48<07:05,  1.01it/s]Loading train:  19%|█▉        | 103/532 [01:49<06:36,  1.08it/s]Loading train:  20%|█▉        | 104/532 [01:50<06:12,  1.15it/s]Loading train:  20%|█▉        | 105/532 [01:51<06:09,  1.15it/s]Loading train:  20%|█▉        | 106/532 [01:52<05:51,  1.21it/s]Loading train:  20%|██        | 107/532 [01:52<05:57,  1.19it/s]Loading train:  20%|██        | 108/532 [01:53<05:43,  1.23it/s]Loading train:  20%|██        | 109/532 [01:54<05:48,  1.21it/s]Loading train:  21%|██        | 110/532 [01:55<05:45,  1.22it/s]Loading train:  21%|██        | 111/532 [01:56<06:04,  1.15it/s]Loading train:  21%|██        | 112/532 [01:57<05:55,  1.18it/s]Loading train:  21%|██        | 113/532 [01:58<06:15,  1.12it/s]Loading train:  21%|██▏       | 114/532 [01:59<06:21,  1.10it/s]Loading train:  22%|██▏       | 115/532 [02:00<06:30,  1.07it/s]Loading train:  22%|██▏       | 116/532 [02:01<06:31,  1.06it/s]Loading train:  22%|██▏       | 117/532 [02:02<06:32,  1.06it/s]Loading train:  22%|██▏       | 118/532 [02:02<06:28,  1.06it/s]Loading train:  22%|██▏       | 119/532 [02:03<06:38,  1.04it/s]Loading train:  23%|██▎       | 120/532 [02:04<06:32,  1.05it/s]Loading train:  23%|██▎       | 121/532 [02:05<06:25,  1.07it/s]Loading train:  23%|██▎       | 122/532 [02:06<06:26,  1.06it/s]Loading train:  23%|██▎       | 123/532 [02:07<06:11,  1.10it/s]Loading train:  23%|██▎       | 124/532 [02:08<06:01,  1.13it/s]Loading train:  23%|██▎       | 125/532 [02:09<06:14,  1.09it/s]Loading train:  24%|██▎       | 126/532 [02:10<06:40,  1.01it/s]Loading train:  24%|██▍       | 127/532 [02:11<06:46,  1.00s/it]Loading train:  24%|██▍       | 128/532 [02:12<06:37,  1.02it/s]Loading train:  24%|██▍       | 129/532 [02:13<06:47,  1.01s/it]Loading train:  24%|██▍       | 130/532 [02:14<06:54,  1.03s/it]Loading train:  25%|██▍       | 131/532 [02:15<07:25,  1.11s/it]Loading train:  25%|██▍       | 132/532 [02:17<07:40,  1.15s/it]Loading train:  25%|██▌       | 133/532 [02:18<07:30,  1.13s/it]Loading train:  25%|██▌       | 134/532 [02:19<07:28,  1.13s/it]Loading train:  25%|██▌       | 135/532 [02:20<07:40,  1.16s/it]Loading train:  26%|██▌       | 136/532 [02:21<07:38,  1.16s/it]Loading train:  26%|██▌       | 137/532 [02:23<07:57,  1.21s/it]Loading train:  26%|██▌       | 138/532 [02:24<08:00,  1.22s/it]Loading train:  26%|██▌       | 139/532 [02:25<07:57,  1.21s/it]Loading train:  26%|██▋       | 140/532 [02:26<07:47,  1.19s/it]Loading train:  27%|██▋       | 141/532 [02:28<08:02,  1.24s/it]Loading train:  27%|██▋       | 142/532 [02:29<07:57,  1.22s/it]Loading train:  27%|██▋       | 143/532 [02:30<07:15,  1.12s/it]Loading train:  27%|██▋       | 144/532 [02:30<06:42,  1.04s/it]Loading train:  27%|██▋       | 145/532 [02:31<06:11,  1.04it/s]Loading train:  27%|██▋       | 146/532 [02:32<05:57,  1.08it/s]Loading train:  28%|██▊       | 147/532 [02:33<05:43,  1.12it/s]Loading train:  28%|██▊       | 148/532 [02:34<05:32,  1.16it/s]Loading train:  28%|██▊       | 149/532 [02:35<05:41,  1.12it/s]Loading train:  28%|██▊       | 150/532 [02:36<05:33,  1.15it/s]Loading train:  28%|██▊       | 151/532 [02:37<06:21,  1.00s/it]Loading train:  29%|██▊       | 152/532 [02:38<06:13,  1.02it/s]Loading train:  29%|██▉       | 153/532 [02:39<05:50,  1.08it/s]Loading train:  29%|██▉       | 154/532 [02:40<06:03,  1.04it/s]Loading train:  29%|██▉       | 155/532 [02:41<06:55,  1.10s/it]Loading train:  29%|██▉       | 156/532 [02:42<07:14,  1.16s/it]Loading train:  30%|██▉       | 157/532 [02:44<07:27,  1.19s/it]Loading train:  30%|██▉       | 158/532 [02:45<07:29,  1.20s/it]Loading train:  30%|██▉       | 159/532 [02:46<07:32,  1.21s/it]Loading train:  30%|███       | 160/532 [02:47<07:40,  1.24s/it]Loading train:  30%|███       | 161/532 [02:48<07:06,  1.15s/it]Loading train:  30%|███       | 162/532 [02:49<06:19,  1.03s/it]Loading train:  31%|███       | 163/532 [02:50<05:51,  1.05it/s]Loading train:  31%|███       | 164/532 [02:51<05:26,  1.13it/s]Loading train:  31%|███       | 165/532 [02:51<05:12,  1.18it/s]Loading train:  31%|███       | 166/532 [02:52<05:10,  1.18it/s]Loading train:  31%|███▏      | 167/532 [02:54<06:06,  1.00s/it]Loading train:  32%|███▏      | 168/532 [02:55<06:12,  1.02s/it]Loading train:  32%|███▏      | 169/532 [02:56<06:42,  1.11s/it]Loading train:  32%|███▏      | 170/532 [02:57<07:11,  1.19s/it]Loading train:  32%|███▏      | 171/532 [02:59<07:24,  1.23s/it]Loading train:  32%|███▏      | 172/532 [03:00<07:33,  1.26s/it]Loading train:  33%|███▎      | 173/532 [03:01<07:20,  1.23s/it]Loading train:  33%|███▎      | 174/532 [03:02<07:33,  1.27s/it]Loading train:  33%|███▎      | 175/532 [03:04<07:23,  1.24s/it]Loading train:  33%|███▎      | 176/532 [03:05<07:18,  1.23s/it]Loading train:  33%|███▎      | 177/532 [03:06<06:50,  1.16s/it]Loading train:  33%|███▎      | 178/532 [03:07<06:55,  1.17s/it]Loading train:  34%|███▎      | 179/532 [03:08<07:12,  1.23s/it]Loading train:  34%|███▍      | 180/532 [03:10<07:09,  1.22s/it]Loading train:  34%|███▍      | 181/532 [03:11<07:14,  1.24s/it]Loading train:  34%|███▍      | 182/532 [03:12<07:06,  1.22s/it]Loading train:  34%|███▍      | 183/532 [03:13<07:00,  1.21s/it]Loading train:  35%|███▍      | 184/532 [03:15<08:33,  1.48s/it]Loading train:  35%|███▍      | 185/532 [03:16<07:46,  1.34s/it]Loading train:  35%|███▍      | 186/532 [03:17<07:18,  1.27s/it]Loading train:  35%|███▌      | 187/532 [03:19<07:22,  1.28s/it]Loading train:  35%|███▌      | 188/532 [03:20<07:06,  1.24s/it]Loading train:  36%|███▌      | 189/532 [03:21<07:08,  1.25s/it]Loading train:  36%|███▌      | 190/532 [03:22<07:02,  1.24s/it]Loading train:  36%|███▌      | 191/532 [03:24<07:56,  1.40s/it]Loading train:  36%|███▌      | 192/532 [03:26<08:27,  1.49s/it]Loading train:  36%|███▋      | 193/532 [03:27<08:28,  1.50s/it]Loading train:  36%|███▋      | 194/532 [03:29<08:53,  1.58s/it]Loading train:  37%|███▋      | 195/532 [03:31<09:03,  1.61s/it]Loading train:  37%|███▋      | 196/532 [03:32<08:49,  1.58s/it]Loading train:  37%|███▋      | 197/532 [03:34<08:13,  1.47s/it]Loading train:  37%|███▋      | 198/532 [03:35<07:52,  1.42s/it]Loading train:  37%|███▋      | 199/532 [03:36<07:50,  1.41s/it]Loading train:  38%|███▊      | 200/532 [03:38<07:33,  1.37s/it]Loading train:  38%|███▊      | 201/532 [03:39<07:40,  1.39s/it]Loading train:  38%|███▊      | 202/532 [03:40<07:26,  1.35s/it]Loading train:  38%|███▊      | 203/532 [03:41<07:03,  1.29s/it]Loading train:  38%|███▊      | 204/532 [03:42<06:44,  1.23s/it]Loading train:  39%|███▊      | 205/532 [03:44<06:26,  1.18s/it]Loading train:  39%|███▊      | 206/532 [03:45<06:23,  1.18s/it]Loading train:  39%|███▉      | 207/532 [03:46<06:19,  1.17s/it]Loading train:  39%|███▉      | 208/532 [03:47<06:16,  1.16s/it]Loading train:  39%|███▉      | 209/532 [03:48<05:57,  1.11s/it]Loading train:  39%|███▉      | 210/532 [03:49<05:42,  1.07s/it]Loading train:  40%|███▉      | 211/532 [03:50<05:37,  1.05s/it]Loading train:  40%|███▉      | 212/532 [03:51<05:26,  1.02s/it]Loading train:  40%|████      | 213/532 [03:52<05:19,  1.00s/it]Loading train:  40%|████      | 214/532 [03:53<05:23,  1.02s/it]Loading train:  40%|████      | 215/532 [03:55<06:28,  1.23s/it]Loading train:  41%|████      | 216/532 [03:56<06:37,  1.26s/it]Loading train:  41%|████      | 217/532 [03:57<06:47,  1.29s/it]Loading train:  41%|████      | 218/532 [03:59<06:50,  1.31s/it]Loading train:  41%|████      | 219/532 [04:00<06:50,  1.31s/it]Loading train:  41%|████▏     | 220/532 [04:02<07:18,  1.41s/it]Loading train:  42%|████▏     | 221/532 [04:03<06:56,  1.34s/it]Loading train:  42%|████▏     | 222/532 [04:04<06:46,  1.31s/it]Loading train:  42%|████▏     | 223/532 [04:05<06:25,  1.25s/it]Loading train:  42%|████▏     | 224/532 [04:06<06:08,  1.20s/it]Loading train:  42%|████▏     | 225/532 [04:07<05:54,  1.15s/it]Loading train:  42%|████▏     | 226/532 [04:08<05:49,  1.14s/it]Loading train:  43%|████▎     | 227/532 [04:09<05:37,  1.11s/it]Loading train:  43%|████▎     | 228/532 [04:10<05:27,  1.08s/it]Loading train:  43%|████▎     | 229/532 [04:11<05:19,  1.05s/it]Loading train:  43%|████▎     | 230/532 [04:12<05:07,  1.02s/it]Loading train:  43%|████▎     | 231/532 [04:13<05:16,  1.05s/it]Loading train:  44%|████▎     | 232/532 [04:15<05:21,  1.07s/it]Loading train:  44%|████▍     | 233/532 [04:16<05:56,  1.19s/it]Loading train:  44%|████▍     | 234/532 [04:17<05:44,  1.15s/it]Loading train:  44%|████▍     | 235/532 [04:19<06:20,  1.28s/it]Loading train:  44%|████▍     | 236/532 [04:20<06:25,  1.30s/it]Loading train:  45%|████▍     | 237/532 [04:21<06:20,  1.29s/it]Loading train:  45%|████▍     | 238/532 [04:23<06:10,  1.26s/it]Loading train:  45%|████▍     | 239/532 [04:24<06:04,  1.24s/it]Loading train:  45%|████▌     | 240/532 [04:25<06:47,  1.39s/it]Loading train:  45%|████▌     | 241/532 [04:27<06:34,  1.36s/it]Loading train:  45%|████▌     | 242/532 [04:28<06:20,  1.31s/it]Loading train:  46%|████▌     | 243/532 [04:29<06:11,  1.29s/it]Loading train:  46%|████▌     | 244/532 [04:30<05:53,  1.23s/it]Loading train:  46%|████▌     | 245/532 [04:31<05:27,  1.14s/it]Loading train:  46%|████▌     | 246/532 [04:32<05:05,  1.07s/it]Loading train:  46%|████▋     | 247/532 [04:33<04:47,  1.01s/it]Loading train:  47%|████▋     | 248/532 [04:34<04:57,  1.05s/it]Loading train:  47%|████▋     | 249/532 [04:35<04:54,  1.04s/it]Loading train:  47%|████▋     | 250/532 [04:36<05:07,  1.09s/it]Loading train:  47%|████▋     | 251/532 [04:38<05:23,  1.15s/it]Loading train:  47%|████▋     | 252/532 [04:39<05:31,  1.19s/it]Loading train:  48%|████▊     | 253/532 [04:40<05:16,  1.13s/it]Loading train:  48%|████▊     | 254/532 [04:41<04:59,  1.08s/it]Loading train:  48%|████▊     | 255/532 [04:42<04:51,  1.05s/it]Loading train:  48%|████▊     | 256/532 [04:43<05:01,  1.09s/it]Loading train:  48%|████▊     | 257/532 [04:44<05:23,  1.18s/it]Loading train:  48%|████▊     | 258/532 [04:46<05:32,  1.21s/it]Loading train:  49%|████▊     | 259/532 [04:47<05:41,  1.25s/it]Loading train:  49%|████▉     | 260/532 [04:48<05:50,  1.29s/it]Loading train:  49%|████▉     | 261/532 [04:50<05:54,  1.31s/it]Loading train:  49%|████▉     | 262/532 [04:51<05:56,  1.32s/it]Loading train:  49%|████▉     | 263/532 [04:52<05:42,  1.27s/it]Loading train:  50%|████▉     | 264/532 [04:53<05:27,  1.22s/it]Loading train:  50%|████▉     | 265/532 [04:54<05:10,  1.16s/it]Loading train:  50%|█████     | 266/532 [04:56<05:03,  1.14s/it]Loading train:  50%|█████     | 267/532 [04:57<05:06,  1.16s/it]Loading train:  50%|█████     | 268/532 [04:58<05:03,  1.15s/it]Loading train:  51%|█████     | 269/532 [04:59<05:21,  1.22s/it]Loading train:  51%|█████     | 270/532 [05:00<05:16,  1.21s/it]Loading train:  51%|█████     | 271/532 [05:02<05:14,  1.20s/it]Loading train:  51%|█████     | 272/532 [05:03<05:18,  1.22s/it]Loading train:  51%|█████▏    | 273/532 [05:05<05:48,  1.35s/it]Loading train:  52%|█████▏    | 274/532 [05:06<05:29,  1.28s/it]Loading train:  52%|█████▏    | 275/532 [05:07<05:55,  1.38s/it]Loading train:  52%|█████▏    | 276/532 [05:09<06:11,  1.45s/it]Loading train:  52%|█████▏    | 277/532 [05:10<06:24,  1.51s/it]Loading train:  52%|█████▏    | 278/532 [05:12<06:46,  1.60s/it]Loading train:  52%|█████▏    | 279/532 [05:14<06:41,  1.59s/it]Loading train:  53%|█████▎    | 280/532 [05:15<06:38,  1.58s/it]Loading train:  53%|█████▎    | 281/532 [05:17<06:57,  1.66s/it]Loading train:  53%|█████▎    | 282/532 [05:19<06:40,  1.60s/it]Loading train:  53%|█████▎    | 283/532 [05:20<06:18,  1.52s/it]Loading train:  53%|█████▎    | 284/532 [05:22<06:14,  1.51s/it]Loading train:  54%|█████▎    | 285/532 [05:23<06:00,  1.46s/it]Loading train:  54%|█████▍    | 286/532 [05:25<06:11,  1.51s/it]Loading train:  54%|█████▍    | 287/532 [05:26<06:08,  1.50s/it]Loading train:  54%|█████▍    | 288/532 [05:27<05:55,  1.45s/it]Loading train:  54%|█████▍    | 289/532 [05:29<05:31,  1.37s/it]Loading train:  55%|█████▍    | 290/532 [05:30<05:25,  1.34s/it]Loading train:  55%|█████▍    | 291/532 [05:31<05:18,  1.32s/it]Loading train:  55%|█████▍    | 292/532 [05:32<05:18,  1.33s/it]Loading train:  55%|█████▌    | 293/532 [05:34<05:12,  1.31s/it]Loading train:  55%|█████▌    | 294/532 [05:35<05:19,  1.34s/it]Loading train:  55%|█████▌    | 295/532 [05:36<05:11,  1.32s/it]Loading train:  56%|█████▌    | 296/532 [05:38<05:26,  1.38s/it]Loading train:  56%|█████▌    | 297/532 [05:39<05:12,  1.33s/it]Loading train:  56%|█████▌    | 298/532 [05:40<04:52,  1.25s/it]Loading train:  56%|█████▌    | 299/532 [05:41<04:51,  1.25s/it]Loading train:  56%|█████▋    | 300/532 [05:43<04:45,  1.23s/it]Loading train:  57%|█████▋    | 301/532 [05:44<04:43,  1.23s/it]Loading train:  57%|█████▋    | 302/532 [05:45<04:23,  1.15s/it]Loading train:  57%|█████▋    | 303/532 [05:46<04:15,  1.12s/it]Loading train:  57%|█████▋    | 304/532 [05:47<04:28,  1.18s/it]Loading train:  57%|█████▋    | 305/532 [05:49<05:01,  1.33s/it]Loading train:  58%|█████▊    | 306/532 [05:50<05:03,  1.34s/it]Loading train:  58%|█████▊    | 307/532 [05:52<05:21,  1.43s/it]Loading train:  58%|█████▊    | 308/532 [05:53<05:11,  1.39s/it]Loading train:  58%|█████▊    | 309/532 [05:55<05:23,  1.45s/it]Loading train:  58%|█████▊    | 310/532 [05:57<05:47,  1.56s/it]Loading train:  58%|█████▊    | 311/532 [05:59<06:46,  1.84s/it]Loading train:  59%|█████▊    | 312/532 [06:01<07:07,  1.95s/it]Loading train:  59%|█████▉    | 313/532 [06:03<07:23,  2.02s/it]Loading train:  59%|█████▉    | 314/532 [06:05<07:12,  1.99s/it]Loading train:  59%|█████▉    | 315/532 [06:07<07:11,  1.99s/it]Loading train:  59%|█████▉    | 316/532 [06:09<07:17,  2.02s/it]Loading train:  60%|█████▉    | 317/532 [06:11<06:21,  1.78s/it]Loading train:  60%|█████▉    | 318/532 [06:12<05:42,  1.60s/it]Loading train:  60%|█████▉    | 319/532 [06:13<05:16,  1.49s/it]Loading train:  60%|██████    | 320/532 [06:14<04:50,  1.37s/it]Loading train:  60%|██████    | 321/532 [06:16<04:52,  1.39s/it]Loading train:  61%|██████    | 322/532 [06:17<04:34,  1.31s/it]Loading train:  61%|██████    | 323/532 [06:18<04:57,  1.43s/it]Loading train:  61%|██████    | 324/532 [06:20<04:57,  1.43s/it]Loading train:  61%|██████    | 325/532 [06:21<04:51,  1.41s/it]Loading train:  61%|██████▏   | 326/532 [06:23<05:11,  1.51s/it]Loading train:  61%|██████▏   | 327/532 [06:24<05:08,  1.50s/it]Loading train:  62%|██████▏   | 328/532 [06:26<05:04,  1.49s/it]Loading train:  62%|██████▏   | 329/532 [06:27<04:56,  1.46s/it]Loading train:  62%|██████▏   | 330/532 [06:29<04:48,  1.43s/it]Loading train:  62%|██████▏   | 331/532 [06:30<05:08,  1.54s/it]Loading train:  62%|██████▏   | 332/532 [06:31<04:36,  1.38s/it]Loading train:  63%|██████▎   | 333/532 [06:33<04:25,  1.33s/it]Loading train:  63%|██████▎   | 334/532 [06:34<04:11,  1.27s/it]Loading train:  63%|██████▎   | 335/532 [06:35<04:31,  1.38s/it]Loading train:  63%|██████▎   | 336/532 [06:37<04:35,  1.40s/it]Loading train:  63%|██████▎   | 337/532 [06:39<04:46,  1.47s/it]Loading train:  64%|██████▎   | 338/532 [06:40<04:46,  1.48s/it]Loading train:  64%|██████▎   | 339/532 [06:41<04:37,  1.44s/it]Loading train:  64%|██████▍   | 340/532 [06:43<04:50,  1.51s/it]Loading train:  64%|██████▍   | 341/532 [06:44<04:25,  1.39s/it]Loading train:  64%|██████▍   | 342/532 [06:47<05:24,  1.71s/it]Loading train:  64%|██████▍   | 343/532 [06:48<04:46,  1.52s/it]Loading train:  65%|██████▍   | 344/532 [06:49<04:15,  1.36s/it]Loading train:  65%|██████▍   | 345/532 [06:50<03:55,  1.26s/it]Loading train:  65%|██████▌   | 346/532 [06:51<03:49,  1.24s/it]Loading train:  65%|██████▌   | 347/532 [06:52<03:46,  1.22s/it]Loading train:  65%|██████▌   | 348/532 [06:53<03:33,  1.16s/it]Loading train:  66%|██████▌   | 349/532 [06:54<03:31,  1.16s/it]Loading train:  66%|██████▌   | 350/532 [06:55<03:34,  1.18s/it]Loading train:  66%|██████▌   | 351/532 [06:57<03:44,  1.24s/it]Loading train:  66%|██████▌   | 352/532 [06:58<03:51,  1.29s/it]Loading train:  66%|██████▋   | 353/532 [07:00<03:59,  1.34s/it]Loading train:  67%|██████▋   | 354/532 [07:01<03:48,  1.29s/it]Loading train:  67%|██████▋   | 355/532 [07:02<03:59,  1.35s/it]Loading train:  67%|██████▋   | 356/532 [07:04<03:53,  1.33s/it]Loading train:  67%|██████▋   | 357/532 [07:05<03:47,  1.30s/it]Loading train:  67%|██████▋   | 358/532 [07:06<03:34,  1.23s/it]Loading train:  67%|██████▋   | 359/532 [07:08<03:56,  1.37s/it]Loading train:  68%|██████▊   | 360/532 [07:09<03:46,  1.31s/it]Loading train:  68%|██████▊   | 361/532 [07:10<03:37,  1.27s/it]Loading train:  68%|██████▊   | 362/532 [07:11<03:31,  1.24s/it]Loading train:  68%|██████▊   | 363/532 [07:12<03:23,  1.20s/it]Loading train:  68%|██████▊   | 364/532 [07:13<03:01,  1.08s/it]Loading train:  69%|██████▊   | 365/532 [07:14<02:57,  1.06s/it]Loading train:  69%|██████▉   | 366/532 [07:15<02:58,  1.07s/it]Loading train:  69%|██████▉   | 367/532 [07:16<02:57,  1.07s/it]Loading train:  69%|██████▉   | 368/532 [07:18<03:09,  1.16s/it]Loading train:  69%|██████▉   | 369/532 [07:19<03:05,  1.14s/it]Loading train:  70%|██████▉   | 370/532 [07:20<03:02,  1.12s/it]Loading train:  70%|██████▉   | 371/532 [07:21<03:11,  1.19s/it]Loading train:  70%|██████▉   | 372/532 [07:23<03:28,  1.31s/it]Loading train:  70%|███████   | 373/532 [07:24<03:41,  1.39s/it]Loading train:  70%|███████   | 374/532 [07:26<04:00,  1.52s/it]Loading train:  70%|███████   | 375/532 [07:28<04:12,  1.61s/it]Loading train:  71%|███████   | 376/532 [07:30<04:10,  1.61s/it]Loading train:  71%|███████   | 377/532 [07:31<04:01,  1.56s/it]Loading train:  71%|███████   | 378/532 [07:32<03:45,  1.46s/it]Loading train:  71%|███████   | 379/532 [07:33<03:28,  1.36s/it]Loading train:  71%|███████▏  | 380/532 [07:34<03:14,  1.28s/it]Loading train:  72%|███████▏  | 381/532 [07:36<03:06,  1.23s/it]Loading train:  72%|███████▏  | 382/532 [07:37<03:06,  1.24s/it]Loading train:  72%|███████▏  | 383/532 [07:38<03:20,  1.35s/it]Loading train:  72%|███████▏  | 384/532 [07:40<03:19,  1.35s/it]Loading train:  72%|███████▏  | 385/532 [07:41<03:21,  1.37s/it]Loading train:  73%|███████▎  | 386/532 [07:43<03:21,  1.38s/it]Loading train:  73%|███████▎  | 387/532 [07:44<03:21,  1.39s/it]Loading train:  73%|███████▎  | 388/532 [07:45<03:14,  1.35s/it]Loading train:  73%|███████▎  | 389/532 [07:47<03:22,  1.41s/it]Loading train:  73%|███████▎  | 390/532 [07:48<03:14,  1.37s/it]Loading train:  73%|███████▎  | 391/532 [07:49<03:08,  1.34s/it]Loading train:  74%|███████▎  | 392/532 [07:51<03:06,  1.33s/it]Loading train:  74%|███████▍  | 393/532 [07:52<03:11,  1.38s/it]Loading train:  74%|███████▍  | 394/532 [07:53<03:01,  1.31s/it]Loading train:  74%|███████▍  | 395/532 [07:55<03:01,  1.33s/it]Loading train:  74%|███████▍  | 396/532 [07:56<03:09,  1.39s/it]Loading train:  75%|███████▍  | 397/532 [07:58<03:09,  1.40s/it]Loading train:  75%|███████▍  | 398/532 [07:59<03:16,  1.47s/it]Loading train:  75%|███████▌  | 399/532 [08:01<03:06,  1.40s/it]Loading train:  75%|███████▌  | 400/532 [08:02<03:03,  1.39s/it]Loading train:  75%|███████▌  | 401/532 [08:03<03:05,  1.42s/it]Loading train:  76%|███████▌  | 402/532 [08:05<02:59,  1.38s/it]Loading train:  76%|███████▌  | 403/532 [08:06<03:12,  1.49s/it]Loading train:  76%|███████▌  | 404/532 [08:08<03:08,  1.47s/it]Loading train:  76%|███████▌  | 405/532 [08:09<03:04,  1.45s/it]Loading train:  76%|███████▋  | 406/532 [08:11<03:02,  1.45s/it]Loading train:  77%|███████▋  | 407/532 [08:12<03:05,  1.49s/it]Loading train:  77%|███████▋  | 408/532 [08:13<02:44,  1.33s/it]Loading train:  77%|███████▋  | 409/532 [08:14<02:27,  1.20s/it]Loading train:  77%|███████▋  | 410/532 [08:15<02:24,  1.19s/it]Loading train:  77%|███████▋  | 411/532 [08:16<02:21,  1.17s/it]Loading train:  77%|███████▋  | 412/532 [08:18<02:24,  1.20s/it]Loading train:  78%|███████▊  | 413/532 [08:19<02:26,  1.23s/it]Loading train:  78%|███████▊  | 414/532 [08:20<02:19,  1.18s/it]Loading train:  78%|███████▊  | 415/532 [08:21<02:06,  1.08s/it]Loading train:  78%|███████▊  | 416/532 [08:22<02:03,  1.07s/it]Loading train:  78%|███████▊  | 417/532 [08:23<02:05,  1.09s/it]Loading train:  79%|███████▊  | 418/532 [08:24<02:05,  1.10s/it]Loading train:  79%|███████▉  | 419/532 [08:26<02:12,  1.17s/it]Loading train:  79%|███████▉  | 420/532 [08:27<02:17,  1.22s/it]Loading train:  79%|███████▉  | 421/532 [08:28<02:17,  1.24s/it]Loading train:  79%|███████▉  | 422/532 [08:29<02:12,  1.21s/it]Loading train:  80%|███████▉  | 423/532 [08:31<02:14,  1.24s/it]Loading train:  80%|███████▉  | 424/532 [08:32<02:06,  1.17s/it]Loading train:  80%|███████▉  | 425/532 [08:33<02:11,  1.23s/it]Loading train:  80%|████████  | 426/532 [08:34<02:18,  1.30s/it]Loading train:  80%|████████  | 427/532 [08:35<02:08,  1.23s/it]Loading train:  80%|████████  | 428/532 [08:37<02:01,  1.17s/it]Loading train:  81%|████████  | 429/532 [08:38<01:55,  1.12s/it]Loading train:  81%|████████  | 430/532 [08:39<02:03,  1.21s/it]Loading train:  81%|████████  | 431/532 [08:40<02:06,  1.25s/it]Loading train:  81%|████████  | 432/532 [08:42<02:08,  1.29s/it]Loading train:  81%|████████▏ | 433/532 [08:43<02:20,  1.42s/it]Loading train:  82%|████████▏ | 434/532 [08:45<02:18,  1.41s/it]Loading train:  82%|████████▏ | 435/532 [08:46<02:12,  1.37s/it]Loading train:  82%|████████▏ | 436/532 [08:48<02:15,  1.41s/it]Loading train:  82%|████████▏ | 437/532 [08:49<02:01,  1.28s/it]Loading train:  82%|████████▏ | 438/532 [08:50<01:54,  1.22s/it]Loading train:  83%|████████▎ | 439/532 [08:51<01:51,  1.20s/it]Loading train:  83%|████████▎ | 440/532 [08:52<01:41,  1.11s/it]Loading train:  83%|████████▎ | 441/532 [08:53<01:37,  1.08s/it]Loading train:  83%|████████▎ | 442/532 [08:54<01:40,  1.11s/it]Loading train:  83%|████████▎ | 443/532 [08:55<01:37,  1.09s/it]Loading train:  83%|████████▎ | 444/532 [08:56<01:32,  1.05s/it]Loading train:  84%|████████▎ | 445/532 [08:57<01:43,  1.19s/it]Loading train:  84%|████████▍ | 446/532 [08:58<01:38,  1.15s/it]Loading train:  84%|████████▍ | 447/532 [08:59<01:34,  1.11s/it]Loading train:  84%|████████▍ | 448/532 [09:00<01:31,  1.09s/it]Loading train:  84%|████████▍ | 449/532 [09:01<01:27,  1.05s/it]Loading train:  85%|████████▍ | 450/532 [09:03<01:31,  1.12s/it]Loading train:  85%|████████▍ | 451/532 [09:04<01:28,  1.09s/it]Loading train:  85%|████████▍ | 452/532 [09:05<01:32,  1.16s/it]Loading train:  85%|████████▌ | 453/532 [09:06<01:32,  1.18s/it]Loading train:  85%|████████▌ | 454/532 [09:08<01:35,  1.23s/it]Loading train:  86%|████████▌ | 455/532 [09:09<01:39,  1.29s/it]Loading train:  86%|████████▌ | 456/532 [09:10<01:40,  1.32s/it]Loading train:  86%|████████▌ | 457/532 [09:12<01:41,  1.35s/it]Loading train:  86%|████████▌ | 458/532 [09:13<01:32,  1.26s/it]Loading train:  86%|████████▋ | 459/532 [09:14<01:28,  1.22s/it]Loading train:  86%|████████▋ | 460/532 [09:15<01:27,  1.21s/it]Loading train:  87%|████████▋ | 461/532 [09:17<01:33,  1.31s/it]Loading train:  87%|████████▋ | 462/532 [09:18<01:33,  1.34s/it]Loading train:  87%|████████▋ | 463/532 [09:20<01:32,  1.34s/it]Loading train:  87%|████████▋ | 464/532 [09:21<01:28,  1.30s/it]Loading train:  87%|████████▋ | 465/532 [09:22<01:32,  1.38s/it]Loading train:  88%|████████▊ | 466/532 [09:24<01:38,  1.49s/it]Loading train:  88%|████████▊ | 467/532 [09:25<01:30,  1.39s/it]Loading train:  88%|████████▊ | 468/532 [09:26<01:23,  1.31s/it]Loading train:  88%|████████▊ | 469/532 [09:28<01:23,  1.32s/it]Loading train:  88%|████████▊ | 470/532 [09:29<01:16,  1.24s/it]Loading train:  89%|████████▊ | 471/532 [09:30<01:12,  1.20s/it]Loading train:  89%|████████▊ | 472/532 [09:31<01:16,  1.27s/it]Loading train:  89%|████████▉ | 473/532 [09:33<01:14,  1.27s/it]Loading train:  89%|████████▉ | 474/532 [09:34<01:13,  1.27s/it]Loading train:  89%|████████▉ | 475/532 [09:35<01:16,  1.34s/it]Loading train:  89%|████████▉ | 476/532 [09:36<01:10,  1.26s/it]Loading train:  90%|████████▉ | 477/532 [09:38<01:07,  1.23s/it]Loading train:  90%|████████▉ | 478/532 [09:39<01:06,  1.24s/it]Loading train:  90%|█████████ | 479/532 [09:40<01:06,  1.25s/it]Loading train:  90%|█████████ | 480/532 [09:41<01:00,  1.16s/it]Loading train:  90%|█████████ | 481/532 [09:42<00:56,  1.11s/it]Loading train:  91%|█████████ | 482/532 [09:43<00:56,  1.13s/it]Loading train:  91%|█████████ | 483/532 [09:44<00:54,  1.11s/it]Loading train:  91%|█████████ | 484/532 [09:45<00:52,  1.10s/it]Loading train:  91%|█████████ | 485/532 [09:47<00:57,  1.22s/it]Loading train:  91%|█████████▏| 486/532 [09:48<00:54,  1.18s/it]Loading train:  92%|█████████▏| 487/532 [09:49<00:55,  1.23s/it]Loading train:  92%|█████████▏| 488/532 [09:50<00:53,  1.22s/it]Loading train:  92%|█████████▏| 489/532 [09:52<00:51,  1.19s/it]Loading train:  92%|█████████▏| 490/532 [09:53<00:51,  1.23s/it]Loading train:  92%|█████████▏| 491/532 [09:54<00:53,  1.30s/it]Loading train:  92%|█████████▏| 492/532 [09:55<00:49,  1.23s/it]Loading train:  93%|█████████▎| 493/532 [09:57<00:47,  1.23s/it]Loading train:  93%|█████████▎| 494/532 [09:58<00:45,  1.20s/it]Loading train:  93%|█████████▎| 495/532 [09:59<00:44,  1.20s/it]Loading train:  93%|█████████▎| 496/532 [10:00<00:43,  1.21s/it]Loading train:  93%|█████████▎| 497/532 [10:02<00:43,  1.24s/it]Loading train:  94%|█████████▎| 498/532 [10:03<00:41,  1.22s/it]Loading train:  94%|█████████▍| 499/532 [10:04<00:38,  1.17s/it]Loading train:  94%|█████████▍| 500/532 [10:05<00:36,  1.15s/it]Loading train:  94%|█████████▍| 501/532 [10:06<00:35,  1.13s/it]Loading train:  94%|█████████▍| 502/532 [10:07<00:34,  1.16s/it]Loading train:  95%|█████████▍| 503/532 [10:09<00:35,  1.23s/it]Loading train:  95%|█████████▍| 504/532 [10:10<00:33,  1.21s/it]Loading train:  95%|█████████▍| 505/532 [10:11<00:31,  1.17s/it]Loading train:  95%|█████████▌| 506/532 [10:12<00:29,  1.12s/it]Loading train:  95%|█████████▌| 507/532 [10:13<00:26,  1.07s/it]Loading train:  95%|█████████▌| 508/532 [10:14<00:25,  1.07s/it]Loading train:  96%|█████████▌| 509/532 [10:15<00:26,  1.14s/it]Loading train:  96%|█████████▌| 510/532 [10:16<00:26,  1.20s/it]Loading train:  96%|█████████▌| 511/532 [10:18<00:25,  1.20s/it]Loading train:  96%|█████████▌| 512/532 [10:19<00:24,  1.21s/it]Loading train:  96%|█████████▋| 513/532 [10:20<00:23,  1.22s/it]Loading train:  97%|█████████▋| 514/532 [10:22<00:25,  1.40s/it]Loading train:  97%|█████████▋| 515/532 [10:23<00:23,  1.36s/it]Loading train:  97%|█████████▋| 516/532 [10:24<00:20,  1.27s/it]Loading train:  97%|█████████▋| 517/532 [10:25<00:18,  1.23s/it]Loading train:  97%|█████████▋| 518/532 [10:27<00:16,  1.19s/it]Loading train:  98%|█████████▊| 519/532 [10:28<00:15,  1.20s/it]Loading train:  98%|█████████▊| 520/532 [10:29<00:13,  1.17s/it]Loading train:  98%|█████████▊| 521/532 [10:30<00:13,  1.23s/it]Loading train:  98%|█████████▊| 522/532 [10:31<00:11,  1.19s/it]Loading train:  98%|█████████▊| 523/532 [10:33<00:11,  1.28s/it]Loading train:  98%|█████████▊| 524/532 [10:34<00:09,  1.22s/it]Loading train:  99%|█████████▊| 525/532 [10:35<00:08,  1.24s/it]Loading train:  99%|█████████▉| 526/532 [10:36<00:07,  1.23s/it]Loading train:  99%|█████████▉| 527/532 [10:38<00:06,  1.23s/it]Loading train:  99%|█████████▉| 528/532 [10:39<00:04,  1.16s/it]Loading train:  99%|█████████▉| 529/532 [10:40<00:03,  1.12s/it]Loading train: 100%|█████████▉| 530/532 [10:41<00:02,  1.12s/it]Loading train: 100%|█████████▉| 531/532 [10:42<00:01,  1.15s/it]Loading train: 100%|██████████| 532/532 [10:43<00:00,  1.09s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/532 [00:00<00:19, 27.56it/s]concatenating: train:   2%|▏         | 8/532 [00:00<00:16, 31.39it/s]concatenating: train:   6%|▌         | 30/532 [00:00<00:11, 42.20it/s]concatenating: train:   9%|▉         | 47/532 [00:00<00:08, 54.17it/s]concatenating: train:  14%|█▍        | 75/532 [00:00<00:06, 71.41it/s]concatenating: train:  20%|█▉        | 105/532 [00:00<00:04, 92.24it/s]concatenating: train:  23%|██▎       | 125/532 [00:00<00:03, 109.43it/s]concatenating: train:  27%|██▋       | 145/532 [00:01<00:05, 75.59it/s] concatenating: train:  30%|███       | 160/532 [00:01<00:05, 73.14it/s]concatenating: train:  33%|███▎      | 173/532 [00:01<00:04, 83.56it/s]concatenating: train:  35%|███▍      | 186/532 [00:01<00:03, 93.47it/s]concatenating: train:  39%|███▉      | 209/532 [00:01<00:02, 112.34it/s]concatenating: train:  45%|████▍     | 237/532 [00:01<00:02, 136.74it/s]concatenating: train:  49%|████▉     | 260/532 [00:01<00:01, 152.68it/s]concatenating: train:  53%|█████▎    | 280/532 [00:02<00:03, 75.57it/s] concatenating: train:  55%|█████▌    | 295/532 [00:02<00:02, 88.11it/s]concatenating: train:  61%|██████    | 323/532 [00:02<00:01, 110.63it/s]concatenating: train:  64%|██████▍   | 342/532 [00:02<00:01, 126.07it/s]concatenating: train:  69%|██████▉   | 366/532 [00:02<00:01, 146.22it/s]concatenating: train:  74%|███████▍  | 393/532 [00:03<00:00, 169.42it/s]concatenating: train:  78%|███████▊  | 416/532 [00:03<00:00, 152.93it/s]concatenating: train:  82%|████████▏ | 436/532 [00:03<00:00, 106.61it/s]concatenating: train:  86%|████████▌ | 456/532 [00:03<00:00, 122.90it/s]concatenating: train:  90%|█████████ | 481/532 [00:03<00:00, 144.94it/s]concatenating: train:  95%|█████████▌| 507/532 [00:03<00:00, 167.03it/s]concatenating: train: 100%|██████████| 532/532 [00:03<00:00, 135.69it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:16,  1.16s/it]Loading test:  13%|█▎        | 2/15 [00:02<00:15,  1.20s/it]Loading test:  20%|██        | 3/15 [00:03<00:15,  1.27s/it]Loading test:  27%|██▋       | 4/15 [00:05<00:14,  1.31s/it]Loading test:  33%|███▎      | 5/15 [00:06<00:13,  1.33s/it]Loading test:  40%|████      | 6/15 [00:08<00:12,  1.38s/it]Loading test:  47%|████▋     | 7/15 [00:08<00:09,  1.20s/it]Loading test:  53%|█████▎    | 8/15 [00:10<00:08,  1.27s/it]Loading test:  60%|██████    | 9/15 [00:11<00:07,  1.23s/it]Loading test:  67%|██████▋   | 10/15 [00:12<00:05,  1.19s/it]Loading test:  73%|███████▎  | 11/15 [00:14<00:05,  1.27s/it]Loading test:  80%|████████  | 12/15 [00:15<00:03,  1.22s/it]Loading test:  87%|████████▋ | 13/15 [00:16<00:02,  1.29s/it]Loading test:  93%|█████████▎| 14/15 [00:17<00:01,  1.20s/it]Loading test: 100%|██████████| 15/15 [00:18<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  47%|████▋     | 7/15 [00:00<00:00, 63.71it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 80.38it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 20:51:41.166506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 20:51:41.166666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 20:51:41.166683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 20:51:41.166696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 20:51:41.167260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 25s - loss: 22.0450 - acc: 0.6054 - mDice: 0.0291 - val_loss: 3.9499 - val_acc: 0.9111 - val_mDice: 0.1285

Epoch 00001: val_mDice improved from -inf to 0.12847, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 4.3341 - acc: 0.8886 - mDice: 0.1337 - val_loss: 2.1909 - val_acc: 0.9141 - val_mDice: 0.3199

Epoch 00002: val_mDice improved from 0.12847 to 0.31985, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 2.9695 - acc: 0.9047 - mDice: 0.2436 - val_loss: 1.7107 - val_acc: 0.9275 - val_mDice: 0.4237

Epoch 00003: val_mDice improved from 0.31985 to 0.42370, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 17s - loss: 2.4417 - acc: 0.9147 - mDice: 0.3187 - val_loss: 1.3325 - val_acc: 0.9474 - val_mDice: 0.5205

Epoch 00004: val_mDice improved from 0.42370 to 0.52051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 17s - loss: 2.0925 - acc: 0.9222 - mDice: 0.3780 - val_loss: 1.1234 - val_acc: 0.9563 - val_mDice: 0.5850

Epoch 00005: val_mDice improved from 0.52051 to 0.58505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 1.8110 - acc: 0.9276 - mDice: 0.4335 - val_loss: 0.9961 - val_acc: 0.9625 - val_mDice: 0.6253

Epoch 00006: val_mDice improved from 0.58505 to 0.62526, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 17s - loss: 1.6149 - acc: 0.9321 - mDice: 0.4794 - val_loss: 0.9058 - val_acc: 0.9647 - val_mDice: 0.6611

Epoch 00007: val_mDice improved from 0.62526 to 0.66109, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 17s - loss: 1.4868 - acc: 0.9353 - mDice: 0.5108 - val_loss: 0.8412 - val_acc: 0.9655 - val_mDice: 0.6866

Epoch 00008: val_mDice improved from 0.66109 to 0.68662, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 16s - loss: 1.3897 - acc: 0.9378 - mDice: 0.5356 - val_loss: 0.7985 - val_acc: 0.9674 - val_mDice: 0.7006

Epoch 00009: val_mDice improved from 0.68662 to 0.70062, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 16s - loss: 1.3207 - acc: 0.9396 - mDice: 0.5540 - val_loss: 0.7803 - val_acc: 0.9685 - val_mDice: 0.7102

Epoch 00010: val_mDice improved from 0.70062 to 0.71017, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 16s - loss: 1.2638 - acc: 0.9410 - mDice: 0.5707 - val_loss: 0.7659 - val_acc: 0.9688 - val_mDice: 0.7154

Epoch 00011: val_mDice improved from 0.71017 to 0.71543, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 15s - loss: 1.2154 - acc: 0.9422 - mDice: 0.5852 - val_loss: 0.7604 - val_acc: 0.9691 - val_mDice: 0.7256

Epoch 00012: val_mDice improved from 0.71543 to 0.72558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 15s - loss: 1.1760 - acc: 0.9434 - mDice: 0.5970 - val_loss: 0.7257 - val_acc: 0.9694 - val_mDice: 0.7320

Epoch 00013: val_mDice improved from 0.72558 to 0.73205, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 16s - loss: 1.1443 - acc: 0.9447 - mDice: 0.6063 - val_loss: 0.7285 - val_acc: 0.9707 - val_mDice: 0.7328

Epoch 00014: val_mDice improved from 0.73205 to 0.73283, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 1.1189 - acc: 0.9457 - mDice: 0.6142 - val_loss: 0.7374 - val_acc: 0.9699 - val_mDice: 0.7308

Epoch 00015: val_mDice did not improve from 0.73283
Epoch 16/300
 - 15s - loss: 1.0979 - acc: 0.9465 - mDice: 0.6205 - val_loss: 0.7222 - val_acc: 0.9709 - val_mDice: 0.7361

Epoch 00016: val_mDice improved from 0.73283 to 0.73606, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 15s - loss: 1.0717 - acc: 0.9473 - mDice: 0.6283 - val_loss: 0.6951 - val_acc: 0.9712 - val_mDice: 0.7435

Epoch 00017: val_mDice improved from 0.73606 to 0.74349, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 16s - loss: 1.0597 - acc: 0.9478 - mDice: 0.6321 - val_loss: 0.6887 - val_acc: 0.9714 - val_mDice: 0.7468

Epoch 00018: val_mDice improved from 0.74349 to 0.74680, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 16s - loss: 1.0386 - acc: 0.9485 - mDice: 0.6380 - val_loss: 0.6890 - val_acc: 0.9720 - val_mDice: 0.7451

Epoch 00019: val_mDice did not improve from 0.74680
Epoch 20/300
 - 15s - loss: 1.0219 - acc: 0.9491 - mDice: 0.6433 - val_loss: 0.6865 - val_acc: 0.9717 - val_mDice: 0.7466

Epoch 00020: val_mDice did not improve from 0.74680
Epoch 21/300
 - 15s - loss: 1.0100 - acc: 0.9494 - mDice: 0.6471 - val_loss: 0.6823 - val_acc: 0.9722 - val_mDice: 0.7489

Epoch 00021: val_mDice improved from 0.74680 to 0.74893, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 15s - loss: 0.9975 - acc: 0.9499 - mDice: 0.6508 - val_loss: 0.6727 - val_acc: 0.9715 - val_mDice: 0.7528

Epoch 00022: val_mDice improved from 0.74893 to 0.75284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 16s - loss: 0.9806 - acc: 0.9505 - mDice: 0.6554 - val_loss: 0.6582 - val_acc: 0.9725 - val_mDice: 0.7576

Epoch 00023: val_mDice improved from 0.75284 to 0.75759, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 15s - loss: 0.9680 - acc: 0.9508 - mDice: 0.6598 - val_loss: 0.6536 - val_acc: 0.9726 - val_mDice: 0.7589

Epoch 00024: val_mDice improved from 0.75759 to 0.75894, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 15s - loss: 0.9614 - acc: 0.9512 - mDice: 0.6620 - val_loss: 0.6565 - val_acc: 0.9725 - val_mDice: 0.7588

Epoch 00025: val_mDice did not improve from 0.75894
Epoch 26/300
 - 15s - loss: 0.9472 - acc: 0.9515 - mDice: 0.6663 - val_loss: 0.6893 - val_acc: 0.9722 - val_mDice: 0.7493

Epoch 00026: val_mDice did not improve from 0.75894
Epoch 27/300
 - 15s - loss: 0.9400 - acc: 0.9518 - mDice: 0.6688 - val_loss: 0.6512 - val_acc: 0.9732 - val_mDice: 0.7626

Epoch 00027: val_mDice improved from 0.75894 to 0.76255, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 16s - loss: 0.9332 - acc: 0.9520 - mDice: 0.6710 - val_loss: 0.6610 - val_acc: 0.9726 - val_mDice: 0.7580

Epoch 00028: val_mDice did not improve from 0.76255
Epoch 29/300
 - 15s - loss: 0.9201 - acc: 0.9523 - mDice: 0.6748 - val_loss: 0.6431 - val_acc: 0.9728 - val_mDice: 0.7610

Epoch 00029: val_mDice did not improve from 0.76255
Epoch 30/300
 - 15s - loss: 0.9163 - acc: 0.9523 - mDice: 0.6764 - val_loss: 0.6538 - val_acc: 0.9726 - val_mDice: 0.7603

Epoch 00030: val_mDice did not improve from 0.76255
Epoch 31/300
 - 15s - loss: 0.9050 - acc: 0.9524 - mDice: 0.6798 - val_loss: 0.6374 - val_acc: 0.9737 - val_mDice: 0.7648

Epoch 00031: val_mDice improved from 0.76255 to 0.76477, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 15s - loss: 0.8982 - acc: 0.9525 - mDice: 0.6825 - val_loss: 0.6379 - val_acc: 0.9733 - val_mDice: 0.7656

Epoch 00032: val_mDice improved from 0.76477 to 0.76561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 15s - loss: 0.8847 - acc: 0.9526 - mDice: 0.6860 - val_loss: 0.6421 - val_acc: 0.9734 - val_mDice: 0.7654

Epoch 00033: val_mDice did not improve from 0.76561
Epoch 34/300
 - 16s - loss: 0.8855 - acc: 0.9524 - mDice: 0.6866 - val_loss: 0.6299 - val_acc: 0.9724 - val_mDice: 0.7678

Epoch 00034: val_mDice improved from 0.76561 to 0.76777, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 15s - loss: 0.8766 - acc: 0.9524 - mDice: 0.6894 - val_loss: 0.6244 - val_acc: 0.9724 - val_mDice: 0.7702

Epoch 00035: val_mDice improved from 0.76777 to 0.77023, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 15s - loss: 0.8713 - acc: 0.9524 - mDice: 0.6911 - val_loss: 0.6341 - val_acc: 0.9726 - val_mDice: 0.7658

Epoch 00036: val_mDice did not improve from 0.77023
Epoch 37/300
 - 15s - loss: 0.8669 - acc: 0.9526 - mDice: 0.6924 - val_loss: 0.6367 - val_acc: 0.9724 - val_mDice: 0.7647

Epoch 00037: val_mDice did not improve from 0.77023
Epoch 38/300
 - 15s - loss: 0.8614 - acc: 0.9525 - mDice: 0.6944 - val_loss: 0.6325 - val_acc: 0.9732 - val_mDice: 0.7671

Epoch 00038: val_mDice did not improve from 0.77023
Epoch 39/300
 - 15s - loss: 0.8556 - acc: 0.9527 - mDice: 0.6956 - val_loss: 0.6454 - val_acc: 0.9729 - val_mDice: 0.7653

Epoch 00039: val_mDice did not improve from 0.77023
Epoch 40/300
 - 17s - loss: 0.8536 - acc: 0.9526 - mDice: 0.6968 - val_loss: 0.6227 - val_acc: 0.9732 - val_mDice: 0.7731

Epoch 00040: val_mDice improved from 0.77023 to 0.77312, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 15s - loss: 0.8474 - acc: 0.9528 - mDice: 0.6989 - val_loss: 0.6253 - val_acc: 0.9728 - val_mDice: 0.7696

Epoch 00041: val_mDice did not improve from 0.77312
Epoch 42/300
 - 15s - loss: 0.8424 - acc: 0.9528 - mDice: 0.7003 - val_loss: 0.6341 - val_acc: 0.9732 - val_mDice: 0.7684

Epoch 00042: val_mDice did not improve from 0.77312
Epoch 43/300
 - 15s - loss: 0.8404 - acc: 0.9530 - mDice: 0.7012 - val_loss: 0.6191 - val_acc: 0.9733 - val_mDice: 0.7752

Epoch 00043: val_mDice improved from 0.77312 to 0.77518, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 44/300
 - 15s - loss: 0.8367 - acc: 0.9529 - mDice: 0.7022 - val_loss: 0.6206 - val_acc: 0.9725 - val_mDice: 0.7731

Epoch 00044: val_mDice did not improve from 0.77518
Epoch 45/300
 - 15s - loss: 0.8327 - acc: 0.9529 - mDice: 0.7036 - val_loss: 0.6023 - val_acc: 0.9741 - val_mDice: 0.7797

Epoch 00045: val_mDice improved from 0.77518 to 0.77969, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 16s - loss: 0.8301 - acc: 0.9530 - mDice: 0.7045 - val_loss: 0.6221 - val_acc: 0.9735 - val_mDice: 0.7738

Epoch 00046: val_mDice did not improve from 0.77969
Epoch 47/300
 - 15s - loss: 0.8247 - acc: 0.9530 - mDice: 0.7064 - val_loss: 0.6045 - val_acc: 0.9734 - val_mDice: 0.7774

Epoch 00047: val_mDice did not improve from 0.77969
Epoch 48/300
 - 15s - loss: 0.8190 - acc: 0.9531 - mDice: 0.7079 - val_loss: 0.6226 - val_acc: 0.9730 - val_mDice: 0.7704

Epoch 00048: val_mDice did not improve from 0.77969
Epoch 49/300
 - 15s - loss: 0.8162 - acc: 0.9531 - mDice: 0.7086 - val_loss: 0.6249 - val_acc: 0.9731 - val_mDice: 0.7727

Epoch 00049: val_mDice did not improve from 0.77969
Epoch 50/300
 - 15s - loss: 0.8127 - acc: 0.9532 - mDice: 0.7100 - val_loss: 0.6112 - val_acc: 0.9738 - val_mDice: 0.7762

Epoch 00050: val_mDice did not improve from 0.77969
Epoch 51/300
 - 15s - loss: 0.8099 - acc: 0.9531 - mDice: 0.7108 - val_loss: 0.6082 - val_acc: 0.9736 - val_mDice: 0.7770

Epoch 00051: val_mDice did not improve from 0.77969
Epoch 52/300
 - 16s - loss: 0.8071 - acc: 0.9530 - mDice: 0.7118 - val_loss: 0.6127 - val_acc: 0.9739 - val_mDice: 0.7786

Epoch 00052: val_mDice did not improve from 0.77969
Epoch 53/300
 - 15s - loss: 0.8093 - acc: 0.9527 - mDice: 0.7112 - val_loss: 0.6007 - val_acc: 0.9738 - val_mDice: 0.7794

Epoch 00053: val_mDice did not improve from 0.77969
Epoch 54/300
 - 15s - loss: 0.8015 - acc: 0.9528 - mDice: 0.7138 - val_loss: 0.6130 - val_acc: 0.9738 - val_mDice: 0.7777

Epoch 00054: val_mDice did not improve from 0.77969
Epoch 55/300
 - 15s - loss: 0.7976 - acc: 0.9528 - mDice: 0.7151 - val_loss: 0.6052 - val_acc: 0.9732 - val_mDice: 0.7793

Epoch 00055: val_mDice did not improve from 0.77969
Epoch 56/300
 - 15s - loss: 0.7967 - acc: 0.9529 - mDice: 0.7157 - val_loss: 0.6326 - val_acc: 0.9733 - val_mDice: 0.7738

Epoch 00056: val_mDice did not improve from 0.77969
Epoch 57/300
 - 15s - loss: 0.7948 - acc: 0.9529 - mDice: 0.7164 - val_loss: 0.6003 - val_acc: 0.9737 - val_mDice: 0.7803

Epoch 00057: val_mDice improved from 0.77969 to 0.78029, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 16s - loss: 0.7926 - acc: 0.9530 - mDice: 0.7170 - val_loss: 0.5993 - val_acc: 0.9740 - val_mDice: 0.7819

Epoch 00058: val_mDice improved from 0.78029 to 0.78193, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 59/300
 - 15s - loss: 0.7904 - acc: 0.9531 - mDice: 0.7176 - val_loss: 0.6070 - val_acc: 0.9741 - val_mDice: 0.7790

Epoch 00059: val_mDice did not improve from 0.78193
Epoch 60/300
 - 15s - loss: 0.7859 - acc: 0.9532 - mDice: 0.7192 - val_loss: 0.5984 - val_acc: 0.9743 - val_mDice: 0.7812

Epoch 00060: val_mDice did not improve from 0.78193
Epoch 61/300
 - 15s - loss: 0.7882 - acc: 0.9531 - mDice: 0.7184 - val_loss: 0.6017 - val_acc: 0.9742 - val_mDice: 0.7808

Epoch 00061: val_mDice did not improve from 0.78193
Epoch 62/300
 - 15s - loss: 0.7812 - acc: 0.9534 - mDice: 0.7205 - val_loss: 0.5917 - val_acc: 0.9743 - val_mDice: 0.7822

Epoch 00062: val_mDice improved from 0.78193 to 0.78222, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 63/300
 - 15s - loss: 0.7797 - acc: 0.9535 - mDice: 0.7211 - val_loss: 0.5912 - val_acc: 0.9743 - val_mDice: 0.7829

Epoch 00063: val_mDice improved from 0.78222 to 0.78288, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 64/300
 - 17s - loss: 0.7804 - acc: 0.9535 - mDice: 0.7210 - val_loss: 0.5936 - val_acc: 0.9741 - val_mDice: 0.7817

Epoch 00064: val_mDice did not improve from 0.78288
Epoch 65/300
 - 16s - loss: 0.7770 - acc: 0.9537 - mDice: 0.7216 - val_loss: 0.5914 - val_acc: 0.9748 - val_mDice: 0.7848

Epoch 00065: val_mDice improved from 0.78288 to 0.78481, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 66/300
 - 15s - loss: 0.7751 - acc: 0.9537 - mDice: 0.7225 - val_loss: 0.5953 - val_acc: 0.9744 - val_mDice: 0.7820

Epoch 00066: val_mDice did not improve from 0.78481
Epoch 67/300
 - 15s - loss: 0.7723 - acc: 0.9539 - mDice: 0.7234 - val_loss: 0.5870 - val_acc: 0.9749 - val_mDice: 0.7849

Epoch 00067: val_mDice improved from 0.78481 to 0.78488, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 68/300
 - 15s - loss: 0.7719 - acc: 0.9539 - mDice: 0.7236 - val_loss: 0.5916 - val_acc: 0.9747 - val_mDice: 0.7847

Epoch 00068: val_mDice did not improve from 0.78488
Epoch 69/300
 - 15s - loss: 0.7722 - acc: 0.9540 - mDice: 0.7238 - val_loss: 0.5842 - val_acc: 0.9745 - val_mDice: 0.7841

Epoch 00069: val_mDice did not improve from 0.78488
Epoch 70/300
 - 16s - loss: 0.7719 - acc: 0.9540 - mDice: 0.7237 - val_loss: 0.5909 - val_acc: 0.9746 - val_mDice: 0.7822

Epoch 00070: val_mDice did not improve from 0.78488
Epoch 71/300
 - 15s - loss: 0.7666 - acc: 0.9541 - mDice: 0.7253 - val_loss: 0.6141 - val_acc: 0.9746 - val_mDice: 0.7781

Epoch 00071: val_mDice did not improve from 0.78488
Epoch 72/300
 - 15s - loss: 0.7644 - acc: 0.9542 - mDice: 0.7259 - val_loss: 0.6001 - val_acc: 0.9751 - val_mDice: 0.7837

Epoch 00072: val_mDice did not improve from 0.78488
Epoch 73/300
 - 15s - loss: 0.7637 - acc: 0.9544 - mDice: 0.7262 - val_loss: 0.5958 - val_acc: 0.9756 - val_mDice: 0.7835

Epoch 00073: val_mDice did not improve from 0.78488
Epoch 74/300
 - 15s - loss: 0.7617 - acc: 0.9544 - mDice: 0.7269 - val_loss: 0.6049 - val_acc: 0.9751 - val_mDice: 0.7792

Epoch 00074: val_mDice did not improve from 0.78488
Epoch 75/300
 - 15s - loss: 0.7602 - acc: 0.9544 - mDice: 0.7273 - val_loss: 0.6036 - val_acc: 0.9749 - val_mDice: 0.7805

Epoch 00075: val_mDice did not improve from 0.78488
Epoch 76/300
 - 16s - loss: 0.7588 - acc: 0.9545 - mDice: 0.7278 - val_loss: 0.6094 - val_acc: 0.9755 - val_mDice: 0.7805

Epoch 00076: val_mDice did not improve from 0.78488
Epoch 77/300
 - 15s - loss: 0.7599 - acc: 0.9544 - mDice: 0.7274 - val_loss: 0.5944 - val_acc: 0.9753 - val_mDice: 0.7815

Epoch 00077: val_mDice did not improve from 0.78488
Epoch 78/300
 - 15s - loss: 0.7570 - acc: 0.9546 - mDice: 0.7283 - val_loss: 0.5965 - val_acc: 0.9758 - val_mDice: 0.7837

Epoch 00078: val_mDice did not improve from 0.78488
Epoch 79/300
 - 15s - loss: 0.7578 - acc: 0.9547 - mDice: 0.7282 - val_loss: 0.5989 - val_acc: 0.9760 - val_mDice: 0.7838

Epoch 00079: val_mDice did not improve from 0.78488
Epoch 80/300
 - 15s - loss: 0.7515 - acc: 0.9548 - mDice: 0.7299 - val_loss: 0.6054 - val_acc: 0.9760 - val_mDice: 0.7812

Epoch 00080: val_mDice did not improve from 0.78488
Epoch 81/300
 - 15s - loss: 0.7555 - acc: 0.9548 - mDice: 0.7291 - val_loss: 0.5948 - val_acc: 0.9757 - val_mDice: 0.7830

Epoch 00081: val_mDice did not improve from 0.78488
Epoch 82/300
 - 15s - loss: 0.7518 - acc: 0.9549 - mDice: 0.7300 - val_loss: 0.5900 - val_acc: 0.9759 - val_mDice: 0.7830

Epoch 00082: val_mDice did not improve from 0.78488
Epoch 83/300
 - 16s - loss: 0.7526 - acc: 0.9548 - mDice: 0.7297 - val_loss: 0.5914 - val_acc: 0.9755 - val_mDice: 0.7833

Epoch 00083: val_mDice did not improve from 0.78488
Epoch 84/300
 - 15s - loss: 0.7523 - acc: 0.9549 - mDice: 0.7297 - val_loss: 0.5849 - val_acc: 0.9759 - val_mDice: 0.7854

Epoch 00084: val_mDice improved from 0.78488 to 0.78536, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 85/300
 - 15s - loss: 0.7500 - acc: 0.9550 - mDice: 0.7306 - val_loss: 0.5906 - val_acc: 0.9757 - val_mDice: 0.7844

Epoch 00085: val_mDice did not improve from 0.78536
Epoch 86/300
 - 15s - loss: 0.7479 - acc: 0.9549 - mDice: 0.7309 - val_loss: 0.5822 - val_acc: 0.9760 - val_mDice: 0.7865

Epoch 00086: val_mDice improved from 0.78536 to 0.78650, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 87/300
 - 15s - loss: 0.7473 - acc: 0.9550 - mDice: 0.7315 - val_loss: 0.5946 - val_acc: 0.9755 - val_mDice: 0.7847

Epoch 00087: val_mDice did not improve from 0.78650
Epoch 88/300
 - 15s - loss: 0.7462 - acc: 0.9551 - mDice: 0.7316 - val_loss: 0.5953 - val_acc: 0.9756 - val_mDice: 0.7838

Epoch 00088: val_mDice did not improve from 0.78650
Epoch 89/300
 - 16s - loss: 0.7438 - acc: 0.9552 - mDice: 0.7326 - val_loss: 0.5898 - val_acc: 0.9759 - val_mDice: 0.7856

Epoch 00089: val_mDice did not improve from 0.78650
Epoch 90/300
 - 15s - loss: 0.7452 - acc: 0.9552 - mDice: 0.7319 - val_loss: 0.5846 - val_acc: 0.9757 - val_mDice: 0.7861

Epoch 00090: val_mDice did not improve from 0.78650
Epoch 91/300
 - 15s - loss: 0.7431 - acc: 0.9552 - mDice: 0.7327 - val_loss: 0.5874 - val_acc: 0.9761 - val_mDice: 0.7869

Epoch 00091: val_mDice improved from 0.78650 to 0.78693, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 92/300
 - 15s - loss: 0.7431 - acc: 0.9552 - mDice: 0.7328 - val_loss: 0.6039 - val_acc: 0.9755 - val_mDice: 0.7798

Epoch 00092: val_mDice did not improve from 0.78693
Epoch 93/300
 - 15s - loss: 0.7403 - acc: 0.9552 - mDice: 0.7334 - val_loss: 0.5932 - val_acc: 0.9760 - val_mDice: 0.7832

Epoch 00093: val_mDice did not improve from 0.78693
Epoch 94/300
 - 15s - loss: 0.7404 - acc: 0.9553 - mDice: 0.7332 - val_loss: 0.5904 - val_acc: 0.9761 - val_mDice: 0.7855

Epoch 00094: val_mDice did not improve from 0.78693
Epoch 95/300
 - 16s - loss: 0.7406 - acc: 0.9554 - mDice: 0.7336 - val_loss: 0.6040 - val_acc: 0.9762 - val_mDice: 0.7826

Epoch 00095: val_mDice did not improve from 0.78693
Epoch 96/300
 - 15s - loss: 0.7416 - acc: 0.9554 - mDice: 0.7334 - val_loss: 0.5892 - val_acc: 0.9760 - val_mDice: 0.7853

Epoch 00096: val_mDice did not improve from 0.78693
Epoch 97/300
 - 15s - loss: 0.7386 - acc: 0.9554 - mDice: 0.7339 - val_loss: 0.5958 - val_acc: 0.9758 - val_mDice: 0.7846

Epoch 00097: val_mDice did not improve from 0.78693
Epoch 98/300
 - 15s - loss: 0.7369 - acc: 0.9555 - mDice: 0.7345 - val_loss: 0.5932 - val_acc: 0.9757 - val_mDice: 0.7837

Epoch 00098: val_mDice did not improve from 0.78693
Epoch 99/300
 - 15s - loss: 0.7363 - acc: 0.9556 - mDice: 0.7347 - val_loss: 0.5906 - val_acc: 0.9761 - val_mDice: 0.7854

Epoch 00099: val_mDice did not improve from 0.78693
Epoch 100/300
 - 15s - loss: 0.7360 - acc: 0.9557 - mDice: 0.7351 - val_loss: 0.5952 - val_acc: 0.9760 - val_mDice: 0.7858

Epoch 00100: val_mDice did not improve from 0.78693
Epoch 101/300
 - 16s - loss: 0.7330 - acc: 0.9557 - mDice: 0.7354 - val_loss: 0.5944 - val_acc: 0.9762 - val_mDice: 0.7836

Epoch 00101: val_mDice did not improve from 0.78693
Epoch 102/300
 - 15s - loss: 0.7323 - acc: 0.9557 - mDice: 0.7361 - val_loss: 0.6084 - val_acc: 0.9761 - val_mDice: 0.7844

Epoch 00102: val_mDice did not improve from 0.78693
Epoch 103/300
 - 15s - loss: 0.7340 - acc: 0.9557 - mDice: 0.7356 - val_loss: 0.5839 - val_acc: 0.9761 - val_mDice: 0.7890

Epoch 00103: val_mDice improved from 0.78693 to 0.78896, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 104/300
 - 15s - loss: 0.7325 - acc: 0.9557 - mDice: 0.7358 - val_loss: 0.5971 - val_acc: 0.9761 - val_mDice: 0.7855

Epoch 00104: val_mDice did not improve from 0.78896
Epoch 105/300
 - 15s - loss: 0.7333 - acc: 0.9558 - mDice: 0.7357 - val_loss: 0.5825 - val_acc: 0.9763 - val_mDice: 0.7880

Epoch 00105: val_mDice did not improve from 0.78896
Epoch 106/300
 - 15s - loss: 0.7308 - acc: 0.9559 - mDice: 0.7365 - val_loss: 0.5842 - val_acc: 0.9758 - val_mDice: 0.7867

Epoch 00106: val_mDice did not improve from 0.78896
Epoch 107/300
 - 16s - loss: 0.7302 - acc: 0.9559 - mDice: 0.7366 - val_loss: 0.5819 - val_acc: 0.9764 - val_mDice: 0.7883

Epoch 00107: val_mDice did not improve from 0.78896
Epoch 108/300
 - 15s - loss: 0.7285 - acc: 0.9559 - mDice: 0.7371 - val_loss: 0.5923 - val_acc: 0.9760 - val_mDice: 0.7866

Epoch 00108: val_mDice did not improve from 0.78896
Epoch 109/300
 - 15s - loss: 0.7279 - acc: 0.9559 - mDice: 0.7372 - val_loss: 0.5811 - val_acc: 0.9762 - val_mDice: 0.7874

Epoch 00109: val_mDice did not improve from 0.78896
Epoch 110/300
 - 15s - loss: 0.7280 - acc: 0.9561 - mDice: 0.7375 - val_loss: 0.5830 - val_acc: 0.9761 - val_mDice: 0.7885

Epoch 00110: val_mDice did not improve from 0.78896
Epoch 111/300
 - 15s - loss: 0.7243 - acc: 0.9560 - mDice: 0.7386 - val_loss: 0.5824 - val_acc: 0.9765 - val_mDice: 0.7885

Epoch 00111: val_mDice did not improve from 0.78896
Epoch 112/300
 - 15s - loss: 0.7252 - acc: 0.9560 - mDice: 0.7383 - val_loss: 0.5883 - val_acc: 0.9764 - val_mDice: 0.7860

Epoch 00112: val_mDice did not improve from 0.78896
Epoch 113/300
 - 16s - loss: 0.7251 - acc: 0.9561 - mDice: 0.7382 - val_loss: 0.5985 - val_acc: 0.9760 - val_mDice: 0.7836

Epoch 00113: val_mDice did not improve from 0.78896
Epoch 114/300
 - 16s - loss: 0.7247 - acc: 0.9561 - mDice: 0.7385 - val_loss: 0.5866 - val_acc: 0.9763 - val_mDice: 0.7857

Epoch 00114: val_mDice did not improve from 0.78896
Epoch 115/300
 - 15s - loss: 0.7220 - acc: 0.9561 - mDice: 0.7392 - val_loss: 0.6020 - val_acc: 0.9761 - val_mDice: 0.7829

Epoch 00115: val_mDice did not improve from 0.78896
Epoch 116/300
 - 15s - loss: 0.7239 - acc: 0.9562 - mDice: 0.7387 - val_loss: 0.6024 - val_acc: 0.9759 - val_mDice: 0.7851

Epoch 00116: val_mDice did not improve from 0.78896
Epoch 117/300
 - 15s - loss: 0.7223 - acc: 0.9562 - mDice: 0.7390 - val_loss: 0.5879 - val_acc: 0.9759 - val_mDice: 0.7887

Epoch 00117: val_mDice did not improve from 0.78896
Epoch 118/300
 - 15s - loss: 0.7221 - acc: 0.9562 - mDice: 0.7392 - val_loss: 0.5946 - val_acc: 0.9762 - val_mDice: 0.7852

Epoch 00118: val_mDice did not improve from 0.78896
Epoch 119/300
 - 15s - loss: 0.7193 - acc: 0.9564 - mDice: 0.7399 - val_loss: 0.6070 - val_acc: 0.9760 - val_mDice: 0.7830

Epoch 00119: val_mDice did not improve from 0.78896
Epoch 120/300
 - 16s - loss: 0.7194 - acc: 0.9564 - mDice: 0.7401 - val_loss: 0.5952 - val_acc: 0.9759 - val_mDice: 0.7849

Epoch 00120: val_mDice did not improve from 0.78896
Epoch 121/300
 - 15s - loss: 0.7222 - acc: 0.9562 - mDice: 0.7393 - val_loss: 0.5860 - val_acc: 0.9766 - val_mDice: 0.7863

Epoch 00121: val_mDice did not improve from 0.78896
Epoch 122/300
 - 15s - loss: 0.7193 - acc: 0.9563 - mDice: 0.7400 - val_loss: 0.5818 - val_acc: 0.9760 - val_mDice: 0.7889

Epoch 00122: val_mDice did not improve from 0.78896
Epoch 123/300
 - 15s - loss: 0.7176 - acc: 0.9564 - mDice: 0.7406 - val_loss: 0.5784 - val_acc: 0.9759 - val_mDice: 0.7878

Epoch 00123: val_mDice did not improve from 0.78896
Epoch 124/300
 - 15s - loss: 0.7194 - acc: 0.9565 - mDice: 0.7401 - val_loss: 0.5842 - val_acc: 0.9765 - val_mDice: 0.7877

Epoch 00124: val_mDice did not improve from 0.78896
Epoch 125/300
 - 15s - loss: 0.7173 - acc: 0.9565 - mDice: 0.7408 - val_loss: 0.5871 - val_acc: 0.9761 - val_mDice: 0.7851

Epoch 00125: val_mDice did not improve from 0.78896
Epoch 126/300
 - 16s - loss: 0.7191 - acc: 0.9564 - mDice: 0.7402 - val_loss: 0.5861 - val_acc: 0.9756 - val_mDice: 0.7845

Epoch 00126: val_mDice did not improve from 0.78896
Epoch 127/300
 - 15s - loss: 0.7151 - acc: 0.9565 - mDice: 0.7411 - val_loss: 0.5794 - val_acc: 0.9764 - val_mDice: 0.7901

Epoch 00127: val_mDice improved from 0.78896 to 0.79006, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 128/300
 - 15s - loss: 0.7182 - acc: 0.9565 - mDice: 0.7403 - val_loss: 0.5944 - val_acc: 0.9765 - val_mDice: 0.7854

Epoch 00128: val_mDice did not improve from 0.79006
Epoch 129/300
 - 15s - loss: 0.7138 - acc: 0.9566 - mDice: 0.7420 - val_loss: 0.5876 - val_acc: 0.9761 - val_mDice: 0.7851

Epoch 00129: val_mDice did not improve from 0.79006
Epoch 130/300
 - 15s - loss: 0.7125 - acc: 0.9566 - mDice: 0.7420 - val_loss: 0.5798 - val_acc: 0.9764 - val_mDice: 0.7883

Epoch 00130: val_mDice did not improve from 0.79006
Epoch 131/300
 - 15s - loss: 0.7125 - acc: 0.9566 - mDice: 0.7422 - val_loss: 0.6051 - val_acc: 0.9763 - val_mDice: 0.7834

Epoch 00131: val_mDice did not improve from 0.79006
Epoch 132/300
 - 16s - loss: 0.7145 - acc: 0.9565 - mDice: 0.7418 - val_loss: 0.5867 - val_acc: 0.9763 - val_mDice: 0.7872

Epoch 00132: val_mDice did not improve from 0.79006
Epoch 133/300
 - 15s - loss: 0.7109 - acc: 0.9566 - mDice: 0.7427 - val_loss: 0.5814 - val_acc: 0.9766 - val_mDice: 0.7870

Epoch 00133: val_mDice did not improve from 0.79006
Epoch 134/300
 - 15s - loss: 0.7101 - acc: 0.9566 - mDice: 0.7428 - val_loss: 0.5920 - val_acc: 0.9765 - val_mDice: 0.7866

Epoch 00134: val_mDice did not improve from 0.79006
Epoch 135/300
 - 15s - loss: 0.7110 - acc: 0.9567 - mDice: 0.7429 - val_loss: 0.5955 - val_acc: 0.9759 - val_mDice: 0.7847

Epoch 00135: val_mDice did not improve from 0.79006
Epoch 136/300
 - 15s - loss: 0.7110 - acc: 0.9567 - mDice: 0.7426 - val_loss: 0.5824 - val_acc: 0.9764 - val_mDice: 0.7888

Epoch 00136: val_mDice did not improve from 0.79006
Epoch 137/300
 - 15s - loss: 0.7104 - acc: 0.9567 - mDice: 0.7432 - val_loss: 0.5886 - val_acc: 0.9763 - val_mDice: 0.7857

Epoch 00137: val_mDice did not improve from 0.79006
Epoch 138/300
 - 16s - loss: 0.7091 - acc: 0.9567 - mDice: 0.7432 - val_loss: 0.5800 - val_acc: 0.9764 - val_mDice: 0.7890

Epoch 00138: val_mDice did not improve from 0.79006
Epoch 139/300
 - 16s - loss: 0.7108 - acc: 0.9567 - mDice: 0.7428 - val_loss: 0.5773 - val_acc: 0.9764 - val_mDice: 0.7901

Epoch 00139: val_mDice improved from 0.79006 to 0.79013, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 140/300
 - 15s - loss: 0.7096 - acc: 0.9568 - mDice: 0.7432 - val_loss: 0.5858 - val_acc: 0.9766 - val_mDice: 0.7877

Epoch 00140: val_mDice did not improve from 0.79013
Epoch 141/300
 - 15s - loss: 0.7083 - acc: 0.9568 - mDice: 0.7436 - val_loss: 0.5932 - val_acc: 0.9764 - val_mDice: 0.7855

Epoch 00141: val_mDice did not improve from 0.79013
Epoch 142/300
 - 15s - loss: 0.7081 - acc: 0.9568 - mDice: 0.7438 - val_loss: 0.5911 - val_acc: 0.9763 - val_mDice: 0.7852

Epoch 00142: val_mDice did not improve from 0.79013
Epoch 143/300
 - 15s - loss: 0.7070 - acc: 0.9568 - mDice: 0.7441 - val_loss: 0.5990 - val_acc: 0.9758 - val_mDice: 0.7828

Epoch 00143: val_mDice did not improve from 0.79013
Epoch 144/300
 - 16s - loss: 0.7063 - acc: 0.9568 - mDice: 0.7443 - val_loss: 0.5804 - val_acc: 0.9764 - val_mDice: 0.7870

Epoch 00144: val_mDice did not improve from 0.79013
Epoch 145/300
 - 16s - loss: 0.7065 - acc: 0.9568 - mDice: 0.7440 - val_loss: 0.5812 - val_acc: 0.9764 - val_mDice: 0.7880

Epoch 00145: val_mDice did not improve from 0.79013
Epoch 146/300
 - 15s - loss: 0.7086 - acc: 0.9568 - mDice: 0.7436 - val_loss: 0.6005 - val_acc: 0.9763 - val_mDice: 0.7850

Epoch 00146: val_mDice did not improve from 0.79013
Epoch 147/300
 - 15s - loss: 0.7072 - acc: 0.9568 - mDice: 0.7437 - val_loss: 0.6074 - val_acc: 0.9763 - val_mDice: 0.7832

Epoch 00147: val_mDice did not improve from 0.79013
Epoch 148/300
 - 15s - loss: 0.7069 - acc: 0.9568 - mDice: 0.7440 - val_loss: 0.5774 - val_acc: 0.9765 - val_mDice: 0.7887

Epoch 00148: val_mDice did not improve from 0.79013
Epoch 149/300
 - 15s - loss: 0.7034 - acc: 0.9569 - mDice: 0.7450 - val_loss: 0.5969 - val_acc: 0.9766 - val_mDice: 0.7863

Epoch 00149: val_mDice did not improve from 0.79013
Epoch 150/300
 - 15s - loss: 0.7051 - acc: 0.9569 - mDice: 0.7445 - val_loss: 0.5814 - val_acc: 0.9762 - val_mDice: 0.7898

Epoch 00150: val_mDice did not improve from 0.79013
Epoch 151/300
 - 17s - loss: 0.7056 - acc: 0.9568 - mDice: 0.7449 - val_loss: 0.6060 - val_acc: 0.9766 - val_mDice: 0.7848

Epoch 00151: val_mDice did not improve from 0.79013
Epoch 152/300
 - 15s - loss: 0.7027 - acc: 0.9569 - mDice: 0.7452 - val_loss: 0.5914 - val_acc: 0.9764 - val_mDice: 0.7862

Epoch 00152: val_mDice did not improve from 0.79013
Epoch 153/300
 - 15s - loss: 0.7053 - acc: 0.9569 - mDice: 0.7448 - val_loss: 0.5761 - val_acc: 0.9760 - val_mDice: 0.7893

Epoch 00153: val_mDice did not improve from 0.79013
Epoch 154/300
 - 15s - loss: 0.7034 - acc: 0.9569 - mDice: 0.7451 - val_loss: 0.5963 - val_acc: 0.9762 - val_mDice: 0.7848

Epoch 00154: val_mDice did not improve from 0.79013
Epoch 155/300
 - 15s - loss: 0.7010 - acc: 0.9570 - mDice: 0.7459 - val_loss: 0.5838 - val_acc: 0.9762 - val_mDice: 0.7873

Epoch 00155: val_mDice did not improve from 0.79013
Epoch 156/300
 - 15s - loss: 0.7016 - acc: 0.9569 - mDice: 0.7456 - val_loss: 0.5772 - val_acc: 0.9761 - val_mDice: 0.7879

Epoch 00156: val_mDice did not improve from 0.79013
Epoch 157/300
 - 17s - loss: 0.7015 - acc: 0.9569 - mDice: 0.7455 - val_loss: 0.5848 - val_acc: 0.9764 - val_mDice: 0.7873

Epoch 00157: val_mDice did not improve from 0.79013
Epoch 158/300
 - 16s - loss: 0.7023 - acc: 0.9570 - mDice: 0.7455 - val_loss: 0.5924 - val_acc: 0.9757 - val_mDice: 0.7843

Epoch 00158: val_mDice did not improve from 0.79013
Epoch 159/300
 - 16s - loss: 0.7005 - acc: 0.9570 - mDice: 0.7461 - val_loss: 0.5811 - val_acc: 0.9764 - val_mDice: 0.7875

Epoch 00159: val_mDice did not improve from 0.79013
Epoch 160/300
 - 16s - loss: 0.7015 - acc: 0.9569 - mDice: 0.7456 - val_loss: 0.5887 - val_acc: 0.9761 - val_mDice: 0.7864

Epoch 00160: val_mDice did not improve from 0.79013
Epoch 161/300
 - 16s - loss: 0.7013 - acc: 0.9570 - mDice: 0.7459 - val_loss: 0.5886 - val_acc: 0.9763 - val_mDice: 0.7869

Epoch 00161: val_mDice did not improve from 0.79013
Epoch 162/300
 - 16s - loss: 0.6997 - acc: 0.9570 - mDice: 0.7464 - val_loss: 0.5879 - val_acc: 0.9765 - val_mDice: 0.7871

Epoch 00162: val_mDice did not improve from 0.79013
Epoch 163/300
 - 17s - loss: 0.7003 - acc: 0.9570 - mDice: 0.7464 - val_loss: 0.5889 - val_acc: 0.9762 - val_mDice: 0.7856

Epoch 00163: val_mDice did not improve from 0.79013
Epoch 164/300
 - 17s - loss: 0.7002 - acc: 0.9570 - mDice: 0.7461 - val_loss: 0.5889 - val_acc: 0.9765 - val_mDice: 0.7892

Epoch 00164: val_mDice did not improve from 0.79013
Epoch 165/300
 - 16s - loss: 0.6989 - acc: 0.9571 - mDice: 0.7468 - val_loss: 0.5740 - val_acc: 0.9765 - val_mDice: 0.7905

Epoch 00165: val_mDice improved from 0.79013 to 0.79051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 166/300
 - 16s - loss: 0.7002 - acc: 0.9570 - mDice: 0.7463 - val_loss: 0.5930 - val_acc: 0.9759 - val_mDice: 0.7859

Epoch 00166: val_mDice did not improve from 0.79051
Epoch 167/300
 - 16s - loss: 0.6990 - acc: 0.9570 - mDice: 0.7461 - val_loss: 0.5962 - val_acc: 0.9763 - val_mDice: 0.7839

Epoch 00167: val_mDice did not improve from 0.79051
Epoch 168/300
 - 16s - loss: 0.7002 - acc: 0.9570 - mDice: 0.7462 - val_loss: 0.5780 - val_acc: 0.9766 - val_mDice: 0.7899

Epoch 00168: val_mDice did not improve from 0.79051
Epoch 169/300
 - 17s - loss: 0.6962 - acc: 0.9571 - mDice: 0.7472 - val_loss: 0.5753 - val_acc: 0.9764 - val_mDice: 0.7896

Epoch 00169: val_mDice did not improve from 0.79051
Epoch 170/300
 - 17s - loss: 0.6959 - acc: 0.9571 - mDice: 0.7477 - val_loss: 0.5866 - val_acc: 0.9761 - val_mDice: 0.7878

Epoch 00170: val_mDice did not improve from 0.79051
Epoch 171/300
 - 16s - loss: 0.6963 - acc: 0.9571 - mDice: 0.7474 - val_loss: 0.5890 - val_acc: 0.9764 - val_mDice: 0.7863

Epoch 00171: val_mDice did not improve from 0.79051
Epoch 172/300
 - 16s - loss: 0.6963 - acc: 0.9571 - mDice: 0.7472 - val_loss: 0.5889 - val_acc: 0.9762 - val_mDice: 0.7874

Epoch 00172: val_mDice did not improve from 0.79051
Epoch 173/300
 - 16s - loss: 0.6959 - acc: 0.9571 - mDice: 0.7476 - val_loss: 0.5820 - val_acc: 0.9765 - val_mDice: 0.7877

Epoch 00173: val_mDice did not improve from 0.79051
Epoch 174/300
 - 16s - loss: 0.6963 - acc: 0.9571 - mDice: 0.7473 - val_loss: 0.5963 - val_acc: 0.9762 - val_mDice: 0.7852

Epoch 00174: val_mDice did not improve from 0.79051
Epoch 175/300
 - 15s - loss: 0.6951 - acc: 0.9571 - mDice: 0.7476 - val_loss: 0.5831 - val_acc: 0.9765 - val_mDice: 0.7871

Epoch 00175: val_mDice did not improve from 0.79051
Epoch 176/300
 - 16s - loss: 0.6957 - acc: 0.9572 - mDice: 0.7477 - val_loss: 0.5830 - val_acc: 0.9760 - val_mDice: 0.7875

Epoch 00176: val_mDice did not improve from 0.79051
Epoch 177/300
 - 15s - loss: 0.6958 - acc: 0.9571 - mDice: 0.7472 - val_loss: 0.5902 - val_acc: 0.9765 - val_mDice: 0.7890

Epoch 00177: val_mDice did not improve from 0.79051
Epoch 178/300
 - 15s - loss: 0.6941 - acc: 0.9571 - mDice: 0.7481 - val_loss: 0.5941 - val_acc: 0.9762 - val_mDice: 0.7847

Epoch 00178: val_mDice did not improve from 0.79051
Epoch 179/300
 - 15s - loss: 0.6964 - acc: 0.9571 - mDice: 0.7475 - val_loss: 0.5761 - val_acc: 0.9761 - val_mDice: 0.7893

Epoch 00179: val_mDice did not improve from 0.79051
Epoch 180/300
 - 15s - loss: 0.6951 - acc: 0.9572 - mDice: 0.7478 - val_loss: 0.5836 - val_acc: 0.9766 - val_mDice: 0.7889

Epoch 00180: val_mDice did not improve from 0.79051
Epoch 181/300
 - 15s - loss: 0.6948 - acc: 0.9572 - mDice: 0.7478 - val_loss: 0.5850 - val_acc: 0.9763 - val_mDice: 0.7881

Epoch 00181: val_mDice did not improve from 0.79051
Epoch 182/300
 - 16s - loss: 0.6956 - acc: 0.9573 - mDice: 0.7479 - val_loss: 0.5887 - val_acc: 0.9763 - val_mDice: 0.7858

Epoch 00182: val_mDice did not improve from 0.79051
Epoch 183/300
 - 15s - loss: 0.6953 - acc: 0.9572 - mDice: 0.7476 - val_loss: 0.5771 - val_acc: 0.9764 - val_mDice: 0.7896

Epoch 00183: val_mDice did not improve from 0.79051
Epoch 184/300
 - 15s - loss: 0.6928 - acc: 0.9573 - mDice: 0.7483 - val_loss: 0.5854 - val_acc: 0.9764 - val_mDice: 0.7873

Epoch 00184: val_mDice did not improve from 0.79051
Epoch 185/300
 - 15s - loss: 0.6945 - acc: 0.9572 - mDice: 0.7477 - val_loss: 0.5857 - val_acc: 0.9764 - val_mDice: 0.7888

Epoch 00185: val_mDice did not improve from 0.79051
Epoch 186/300
 - 15s - loss: 0.6924 - acc: 0.9572 - mDice: 0.7486 - val_loss: 0.5940 - val_acc: 0.9760 - val_mDice: 0.7865

Epoch 00186: val_mDice did not improve from 0.79051
Epoch 187/300
 - 15s - loss: 0.6929 - acc: 0.9572 - mDice: 0.7485 - val_loss: 0.5759 - val_acc: 0.9764 - val_mDice: 0.7907

Epoch 00187: val_mDice improved from 0.79051 to 0.79071, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 188/300
 - 15s - loss: 0.6937 - acc: 0.9572 - mDice: 0.7481 - val_loss: 0.5873 - val_acc: 0.9764 - val_mDice: 0.7897

Epoch 00188: val_mDice did not improve from 0.79071
Epoch 189/300
 - 16s - loss: 0.6923 - acc: 0.9572 - mDice: 0.7486 - val_loss: 0.5826 - val_acc: 0.9762 - val_mDice: 0.7876

Epoch 00189: val_mDice did not improve from 0.79071
Epoch 190/300
 - 15s - loss: 0.6922 - acc: 0.9572 - mDice: 0.7486 - val_loss: 0.5836 - val_acc: 0.9759 - val_mDice: 0.7881

Epoch 00190: val_mDice did not improve from 0.79071
Epoch 191/300
 - 15s - loss: 0.6915 - acc: 0.9573 - mDice: 0.7491 - val_loss: 0.5755 - val_acc: 0.9767 - val_mDice: 0.7926

Epoch 00191: val_mDice improved from 0.79071 to 0.79264, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 192/300
 - 15s - loss: 0.6917 - acc: 0.9573 - mDice: 0.7487 - val_loss: 0.5841 - val_acc: 0.9765 - val_mDice: 0.7904

Epoch 00192: val_mDice did not improve from 0.79264
Epoch 193/300
 - 15s - loss: 0.6916 - acc: 0.9573 - mDice: 0.7489 - val_loss: 0.5835 - val_acc: 0.9766 - val_mDice: 0.7898

Epoch 00193: val_mDice did not improve from 0.79264
Epoch 194/300
 - 15s - loss: 0.6900 - acc: 0.9573 - mDice: 0.7492 - val_loss: 0.5818 - val_acc: 0.9766 - val_mDice: 0.7910

Epoch 00194: val_mDice did not improve from 0.79264
Epoch 195/300
 - 15s - loss: 0.6885 - acc: 0.9574 - mDice: 0.7496 - val_loss: 0.5793 - val_acc: 0.9763 - val_mDice: 0.7886

Epoch 00195: val_mDice did not improve from 0.79264
Epoch 196/300
 - 16s - loss: 0.6903 - acc: 0.9573 - mDice: 0.7492 - val_loss: 0.5733 - val_acc: 0.9768 - val_mDice: 0.7926

Epoch 00196: val_mDice improved from 0.79264 to 0.79265, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 197/300
 - 15s - loss: 0.6945 - acc: 0.9572 - mDice: 0.7479 - val_loss: 0.5791 - val_acc: 0.9767 - val_mDice: 0.7911

Epoch 00197: val_mDice did not improve from 0.79265
Epoch 198/300
 - 15s - loss: 0.6906 - acc: 0.9573 - mDice: 0.7492 - val_loss: 0.5728 - val_acc: 0.9765 - val_mDice: 0.7890

Epoch 00198: val_mDice did not improve from 0.79265
Epoch 199/300
 - 15s - loss: 0.6901 - acc: 0.9574 - mDice: 0.7494 - val_loss: 0.5830 - val_acc: 0.9762 - val_mDice: 0.7904

Epoch 00199: val_mDice did not improve from 0.79265
Epoch 200/300
 - 15s - loss: 0.6885 - acc: 0.9574 - mDice: 0.7499 - val_loss: 0.5870 - val_acc: 0.9765 - val_mDice: 0.7895

Epoch 00200: val_mDice did not improve from 0.79265
Epoch 201/300
 - 15s - loss: 0.6879 - acc: 0.9574 - mDice: 0.7499 - val_loss: 0.5759 - val_acc: 0.9765 - val_mDice: 0.7906

Epoch 00201: val_mDice did not improve from 0.79265
Epoch 202/300
 - 16s - loss: 0.6881 - acc: 0.9573 - mDice: 0.7498 - val_loss: 0.5766 - val_acc: 0.9765 - val_mDice: 0.7904

Epoch 00202: val_mDice did not improve from 0.79265
Epoch 203/300
 - 16s - loss: 0.6897 - acc: 0.9574 - mDice: 0.7492 - val_loss: 0.5805 - val_acc: 0.9764 - val_mDice: 0.7903

Epoch 00203: val_mDice did not improve from 0.79265
Epoch 204/300
 - 15s - loss: 0.6898 - acc: 0.9573 - mDice: 0.7495 - val_loss: 0.5788 - val_acc: 0.9763 - val_mDice: 0.7895

Epoch 00204: val_mDice did not improve from 0.79265
Epoch 205/300
 - 15s - loss: 0.6888 - acc: 0.9574 - mDice: 0.7498 - val_loss: 0.5832 - val_acc: 0.9764 - val_mDice: 0.7907

Epoch 00205: val_mDice did not improve from 0.79265
Epoch 206/300
 - 15s - loss: 0.6877 - acc: 0.9574 - mDice: 0.7502 - val_loss: 0.5821 - val_acc: 0.9764 - val_mDice: 0.7890

Epoch 00206: val_mDice did not improve from 0.79265
Epoch 207/300
 - 15s - loss: 0.6881 - acc: 0.9574 - mDice: 0.7497 - val_loss: 0.5891 - val_acc: 0.9764 - val_mDice: 0.7885

Epoch 00207: val_mDice did not improve from 0.79265
Epoch 208/300
 - 15s - loss: 0.6866 - acc: 0.9575 - mDice: 0.7504 - val_loss: 0.5895 - val_acc: 0.9763 - val_mDice: 0.7892

Epoch 00208: val_mDice did not improve from 0.79265
Epoch 209/300
 - 16s - loss: 0.6874 - acc: 0.9574 - mDice: 0.7501 - val_loss: 0.5735 - val_acc: 0.9764 - val_mDice: 0.7912

Epoch 00209: val_mDice did not improve from 0.79265
Epoch 210/300
 - 15s - loss: 0.6878 - acc: 0.9575 - mDice: 0.7501 - val_loss: 0.5708 - val_acc: 0.9763 - val_mDice: 0.7910

Epoch 00210: val_mDice did not improve from 0.79265
Epoch 211/300
 - 15s - loss: 0.6858 - acc: 0.9575 - mDice: 0.7508 - val_loss: 0.5737 - val_acc: 0.9763 - val_mDice: 0.7920

Epoch 00211: val_mDice did not improve from 0.79265
Epoch 212/300
 - 15s - loss: 0.6877 - acc: 0.9574 - mDice: 0.7498 - val_loss: 0.5847 - val_acc: 0.9765 - val_mDice: 0.7908

Epoch 00212: val_mDice did not improve from 0.79265
Epoch 213/300
 - 15s - loss: 0.6881 - acc: 0.9574 - mDice: 0.7500 - val_loss: 0.5880 - val_acc: 0.9767 - val_mDice: 0.7883

Epoch 00213: val_mDice did not improve from 0.79265
Epoch 214/300
 - 15s - loss: 0.6879 - acc: 0.9575 - mDice: 0.7499 - val_loss: 0.5718 - val_acc: 0.9766 - val_mDice: 0.7943

Epoch 00214: val_mDice improved from 0.79265 to 0.79426, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 215/300
 - 16s - loss: 0.6860 - acc: 0.9575 - mDice: 0.7507 - val_loss: 0.5857 - val_acc: 0.9763 - val_mDice: 0.7884

Epoch 00215: val_mDice did not improve from 0.79426
Epoch 216/300
 - 16s - loss: 0.6864 - acc: 0.9574 - mDice: 0.7505 - val_loss: 0.5747 - val_acc: 0.9765 - val_mDice: 0.7924

Epoch 00216: val_mDice did not improve from 0.79426
Epoch 217/300
 - 15s - loss: 0.6829 - acc: 0.9576 - mDice: 0.7516 - val_loss: 0.5875 - val_acc: 0.9765 - val_mDice: 0.7879

Epoch 00217: val_mDice did not improve from 0.79426
Epoch 218/300
 - 15s - loss: 0.6854 - acc: 0.9575 - mDice: 0.7506 - val_loss: 0.5798 - val_acc: 0.9764 - val_mDice: 0.7896

Epoch 00218: val_mDice did not improve from 0.79426
Epoch 219/300
 - 15s - loss: 0.6872 - acc: 0.9575 - mDice: 0.7502 - val_loss: 0.5794 - val_acc: 0.9764 - val_mDice: 0.7904

Epoch 00219: val_mDice did not improve from 0.79426
Epoch 220/300
 - 15s - loss: 0.6845 - acc: 0.9575 - mDice: 0.7512 - val_loss: 0.5842 - val_acc: 0.9765 - val_mDice: 0.7897

Epoch 00220: val_mDice did not improve from 0.79426
Epoch 221/300
 - 16s - loss: 0.6835 - acc: 0.9576 - mDice: 0.7514 - val_loss: 0.5809 - val_acc: 0.9760 - val_mDice: 0.7882

Epoch 00221: val_mDice did not improve from 0.79426
Epoch 222/300
 - 15s - loss: 0.6842 - acc: 0.9576 - mDice: 0.7514 - val_loss: 0.5854 - val_acc: 0.9762 - val_mDice: 0.7886

Epoch 00222: val_mDice did not improve from 0.79426
Epoch 223/300
 - 15s - loss: 0.6844 - acc: 0.9575 - mDice: 0.7511 - val_loss: 0.5841 - val_acc: 0.9764 - val_mDice: 0.7899

Epoch 00223: val_mDice did not improve from 0.79426
Epoch 224/300
 - 15s - loss: 0.6838 - acc: 0.9576 - mDice: 0.7514 - val_loss: 0.5804 - val_acc: 0.9762 - val_mDice: 0.7902

Epoch 00224: val_mDice did not improve from 0.79426
Epoch 225/300
 - 15s - loss: 0.6837 - acc: 0.9575 - mDice: 0.7514 - val_loss: 0.5920 - val_acc: 0.9764 - val_mDice: 0.7888

Epoch 00225: val_mDice did not improve from 0.79426
Epoch 226/300
 - 15s - loss: 0.6827 - acc: 0.9576 - mDice: 0.7517 - val_loss: 0.5723 - val_acc: 0.9762 - val_mDice: 0.7920

Epoch 00226: val_mDice did not improve from 0.79426
Epoch 227/300
 - 16s - loss: 0.6836 - acc: 0.9576 - mDice: 0.7514 - val_loss: 0.5693 - val_acc: 0.9766 - val_mDice: 0.7921

Epoch 00227: val_mDice did not improve from 0.79426
Epoch 228/300
 - 15s - loss: 0.6831 - acc: 0.9576 - mDice: 0.7515 - val_loss: 0.5875 - val_acc: 0.9764 - val_mDice: 0.7885

Epoch 00228: val_mDice did not improve from 0.79426
Epoch 229/300
 - 15s - loss: 0.6834 - acc: 0.9576 - mDice: 0.7516 - val_loss: 0.5750 - val_acc: 0.9765 - val_mDice: 0.7930

Epoch 00229: val_mDice did not improve from 0.79426
Epoch 230/300
 - 15s - loss: 0.6844 - acc: 0.9576 - mDice: 0.7510 - val_loss: 0.5737 - val_acc: 0.9764 - val_mDice: 0.7910

Epoch 00230: val_mDice did not improve from 0.79426
Epoch 231/300
 - 15s - loss: 0.6850 - acc: 0.9576 - mDice: 0.7510 - val_loss: 0.5910 - val_acc: 0.9763 - val_mDice: 0.7880

Epoch 00231: val_mDice did not improve from 0.79426
Epoch 232/300
 - 15s - loss: 0.6829 - acc: 0.9576 - mDice: 0.7515 - val_loss: 0.5755 - val_acc: 0.9764 - val_mDice: 0.7901

Epoch 00232: val_mDice did not improve from 0.79426
Epoch 233/300
 - 16s - loss: 0.6835 - acc: 0.9576 - mDice: 0.7515 - val_loss: 0.5804 - val_acc: 0.9766 - val_mDice: 0.7899

Epoch 00233: val_mDice did not improve from 0.79426
Epoch 234/300
 - 16s - loss: 0.6822 - acc: 0.9576 - mDice: 0.7519 - val_loss: 0.5754 - val_acc: 0.9765 - val_mDice: 0.7926

Epoch 00234: val_mDice did not improve from 0.79426
Epoch 235/300
 - 16s - loss: 0.6849 - acc: 0.9576 - mDice: 0.7509 - val_loss: 0.5644 - val_acc: 0.9765 - val_mDice: 0.7932

Epoch 00235: val_mDice did not improve from 0.79426
Epoch 236/300
 - 16s - loss: 0.6815 - acc: 0.9577 - mDice: 0.7518 - val_loss: 0.5731 - val_acc: 0.9765 - val_mDice: 0.7919

Epoch 00236: val_mDice did not improve from 0.79426
Epoch 237/300
 - 16s - loss: 0.6813 - acc: 0.9577 - mDice: 0.7521 - val_loss: 0.5691 - val_acc: 0.9764 - val_mDice: 0.7930

Epoch 00237: val_mDice did not improve from 0.79426
Epoch 238/300
 - 16s - loss: 0.6831 - acc: 0.9577 - mDice: 0.7514 - val_loss: 0.5825 - val_acc: 0.9765 - val_mDice: 0.7903

Epoch 00238: val_mDice did not improve from 0.79426
Epoch 239/300
 - 17s - loss: 0.6804 - acc: 0.9578 - mDice: 0.7526 - val_loss: 0.5753 - val_acc: 0.9763 - val_mDice: 0.7896

Epoch 00239: val_mDice did not improve from 0.79426
Epoch 240/300
 - 17s - loss: 0.6838 - acc: 0.9576 - mDice: 0.7514 - val_loss: 0.5743 - val_acc: 0.9765 - val_mDice: 0.7918

Epoch 00240: val_mDice did not improve from 0.79426
Epoch 241/300
 - 16s - loss: 0.6801 - acc: 0.9577 - mDice: 0.7524 - val_loss: 0.5788 - val_acc: 0.9765 - val_mDice: 0.7925

Epoch 00241: val_mDice did not improve from 0.79426
Epoch 242/300
 - 16s - loss: 0.6799 - acc: 0.9578 - mDice: 0.7525 - val_loss: 0.5740 - val_acc: 0.9764 - val_mDice: 0.7903

Epoch 00242: val_mDice did not improve from 0.79426
Epoch 243/300
 - 16s - loss: 0.6799 - acc: 0.9577 - mDice: 0.7524 - val_loss: 0.5754 - val_acc: 0.9761 - val_mDice: 0.7919

Epoch 00243: val_mDice did not improve from 0.79426
Epoch 244/300
 - 17s - loss: 0.6809 - acc: 0.9577 - mDice: 0.7521 - val_loss: 0.5805 - val_acc: 0.9764 - val_mDice: 0.7910

Epoch 00244: val_mDice did not improve from 0.79426
Restoring model weights from the end of the best epoch
Epoch 00244: early stopping
{'val_loss': [3.9498629875887046, 2.1909378299813698, 1.7107013422072668, 1.3324712751619845, 1.1233907793443945, 0.9960827120368636, 0.9058127761515666, 0.841221432275219, 0.7984614071611361, 0.7803342827384627, 0.765932391733193, 0.7603851726478349, 0.7256732546382294, 0.7284999931843293, 0.7373987497051487, 0.7221957564563449, 0.6950868648887728, 0.6886559910221134, 0.6890136403651983, 0.6864863388986705, 0.682312484051515, 0.6727102735130565, 0.6581975190207913, 0.6535718208457129, 0.6564786784049707, 0.6893040952657354, 0.6512011256075492, 0.6609542717623585, 0.6431208464508525, 0.6538001164820156, 0.6374368801686802, 0.6379440205796951, 0.6420594880157698, 0.6299404624476375, 0.6244373243491972, 0.6340728029215902, 0.6366690211849179, 0.632484601021651, 0.6454417879426416, 0.6227410038137687, 0.6253128610093062, 0.6341449118666155, 0.6190588859765936, 0.6205686994407633, 0.6022931134135107, 0.6220843787771537, 0.6045129446342247, 0.6225646399027015, 0.6248554094499779, 0.6112416786238263, 0.6082266785976966, 0.6127276426354695, 0.6006720595074874, 0.6130016073191732, 0.6052278498668872, 0.6325770078623022, 0.6002514369144172, 0.5993370223129152, 0.6069818188310298, 0.5984102877770241, 0.6016718728471095, 0.5917391898552437, 0.5912319564756484, 0.5935615294847002, 0.5913656413136132, 0.5953464194320417, 0.5870423286577101, 0.5916104627305049, 0.5842238773570538, 0.590858898389109, 0.6140643012544602, 0.6001218912995343, 0.5958025734642478, 0.6048572420131133, 0.6035844791019319, 0.609431484723971, 0.5944045134713654, 0.5965130363176913, 0.5988771638363233, 0.6054343315126188, 0.5947842771328187, 0.5899552416927156, 0.5913956138601622, 0.584936595759199, 0.5905819561967531, 0.5821938249683548, 0.594604006551062, 0.5953206433562697, 0.5898097344463027, 0.5845755452849953, 0.5873642381549091, 0.6039169328074464, 0.593201028651219, 0.590361879192463, 0.6040244480637549, 0.5892059126302521, 0.5957784272455373, 0.5932314679786065, 0.5905705360410921, 0.595201533949019, 0.5944457142654748, 0.6083747784890273, 0.5838682919164534, 0.5970885840576856, 0.5824893383024446, 0.5842229392386069, 0.5819122470221326, 0.5923406284282832, 0.5810790626571133, 0.5829563136679008, 0.5824360291756728, 0.5882615794301661, 0.5984664263959928, 0.5866266407321333, 0.6019660367488023, 0.6023666927810294, 0.587864666286797, 0.5945567105273162, 0.6070223718305464, 0.5951629430317502, 0.5860449954579291, 0.5818344190690555, 0.5783858361059836, 0.584221448441591, 0.5871201893462028, 0.5860920683047055, 0.5793955801136674, 0.5943519503454332, 0.5876138553887553, 0.5798364634149313, 0.6050910373039949, 0.5866751147594519, 0.5814398961871705, 0.5920297733928701, 0.5955490378273393, 0.5824299081767171, 0.5886382008059792, 0.5799910048504077, 0.577324473114131, 0.5857907384372134, 0.5931565368741175, 0.5910594420399523, 0.5990457169200918, 0.5803546245571599, 0.5812190180817891, 0.6005014813847198, 0.6074234993575118, 0.5773791596424391, 0.5969328855169259, 0.5814245839215331, 0.6059774331656826, 0.591351864050897, 0.5760661957553066, 0.5962502320537668, 0.5837505885083981, 0.5771854439183991, 0.5848293615560749, 0.5924415683180669, 0.5810516274457238, 0.5887297993175594, 0.5885819741942132, 0.5878745692999795, 0.5888570417209753, 0.5888623684801829, 0.5739732590521995, 0.5929937271011735, 0.596235055391315, 0.5780394174197856, 0.5753367524888687, 0.5865773521952973, 0.589010657346521, 0.5889125438587108, 0.5820012381709523, 0.5962868068884463, 0.5830959518994933, 0.5830133237821985, 0.5901860393099291, 0.5941252574874563, 0.5761456820583511, 0.5836430865033859, 0.5849895301833095, 0.5886598568285287, 0.5770974075961826, 0.5854182436617061, 0.5856625622626138, 0.5940114240340483, 0.5758669907472674, 0.5872662220353192, 0.5826130163690537, 0.5836436204834856, 0.5755391046012014, 0.5840580261235497, 0.583537808202063, 0.581840779010357, 0.5792534090513085, 0.5732979045915687, 0.5790502258784322, 0.5728300650635167, 0.5829607445766302, 0.586993523871752, 0.5759490931075989, 0.576587650132724, 0.5804996106557561, 0.578777352619674, 0.5832215873868268, 0.5821487341593355, 0.589056208808309, 0.5895303745994669, 0.5735069839627546, 0.5707797121079818, 0.5737317420791029, 0.584680363928706, 0.5880306181358746, 0.5718355428145934, 0.5856956006772489, 0.5747274434315089, 0.5874501575170795, 0.5798198078973431, 0.5793888653204604, 0.5842346303911327, 0.5809204527594293, 0.5854338028833191, 0.584101392221367, 0.5804210834218245, 0.5920309125329573, 0.5722656966512777, 0.5693367386010912, 0.5874844048898962, 0.5750001497658359, 0.5736711909356143, 0.5910207282470274, 0.5755149274802585, 0.5804255366953899, 0.5754337743422269, 0.5644180198021639, 0.5730907322547557, 0.5691378336589659, 0.5824863569179193, 0.5753390461677826, 0.5743240884821109, 0.5788060650360396, 0.5739928265028553, 0.5754379256643185, 0.5804900882637982], 'val_acc': [0.9111428180143158, 0.9140894927333235, 0.9275107388965694, 0.9474380699318616, 0.9563311507077544, 0.9624770719472888, 0.9647486305194916, 0.9654611050558844, 0.9674281522972094, 0.9685239708067453, 0.9687858696352618, 0.9690623408042693, 0.969407184471774, 0.9706733469803849, 0.9698775690343552, 0.9708583011359029, 0.9712120939851435, 0.9713630466762871, 0.972009749739367, 0.9716783754645416, 0.9721961941157578, 0.9715233256611547, 0.9725283411558986, 0.9725802802662439, 0.9725294577216431, 0.972247757371155, 0.97318739379856, 0.9726109055307921, 0.9728047970309199, 0.9725679434665687, 0.9737223896913243, 0.9733360889506885, 0.973398096217841, 0.972446512882655, 0.9723590896293023, 0.9726307092525838, 0.9724132633376834, 0.9731914926916099, 0.9728866356747431, 0.9732374394924653, 0.9727928481328257, 0.9731855182949395, 0.9732654758832158, 0.9725496228424233, 0.9741150573393582, 0.9735355914581849, 0.9733708374110592, 0.9730289700999202, 0.97309547159919, 0.9737720873946675, 0.9736398217548176, 0.973949923456658, 0.9737959919998223, 0.9738483009941759, 0.9732393332231652, 0.9732946116601645, 0.9737130462180541, 0.9739828006035415, 0.974083686126347, 0.9743044874999142, 0.9742151917807875, 0.9743018711807439, 0.974326900522403, 0.9741270293879384, 0.974785326340077, 0.9743721109073484, 0.9749306576532722, 0.974699023528342, 0.9745428478361643, 0.9746295268171072, 0.9745861918310289, 0.9750901972891367, 0.9756124956117573, 0.9750584200522183, 0.9748577958460641, 0.9754847245182848, 0.9753188407064951, 0.9758220827223337, 0.9759838608321071, 0.9760227211749407, 0.9756928284264617, 0.9758889815509844, 0.9755359176801671, 0.9758762765433541, 0.9757279421616941, 0.9759704207703602, 0.9755056510910208, 0.9755687934652573, 0.9758975727905917, 0.9757286924050437, 0.9760776461742046, 0.9754787416365946, 0.9759569757852068, 0.9760888697602418, 0.9761721743221652, 0.9759734145157786, 0.9758250728013855, 0.9757425080074786, 0.9761239645351215, 0.9759846125420032, 0.9761927099554736, 0.9760806414909229, 0.9761329327819637, 0.9760892277023704, 0.9762640844749022, 0.9757944505746838, 0.9763619607487966, 0.975952494752009, 0.9761960820699199, 0.9760866019554004, 0.9764658388647337, 0.9764135176142406, 0.9759603294630671, 0.9762603356674812, 0.9761344393443558, 0.9758553430568984, 0.9759274587061367, 0.9761893526112467, 0.9760130132648354, 0.9759005534418438, 0.976616770500458, 0.9760186087687112, 0.9759498555966127, 0.9764591138057005, 0.9760836243419949, 0.9756472538141877, 0.976384396502758, 0.976486370307909, 0.9760768931025151, 0.9763881145127, 0.9763473827516257, 0.9763077926970953, 0.9765764224508315, 0.976529712836227, 0.9759222163257364, 0.9763881218454331, 0.9762876117585623, 0.9763597238461875, 0.976418756852041, 0.9766343233874477, 0.9763914841130664, 0.976304796437597, 0.9757828598282249, 0.9764221178626343, 0.9763518722698433, 0.9762524957187565, 0.976268555347027, 0.9764736726330119, 0.9765547501391393, 0.9762263448879464, 0.9765846419208708, 0.9764273355212488, 0.9759842423437349, 0.976228941303984, 0.9762039347985507, 0.9761407873961544, 0.9764206127667888, 0.9756958060398672, 0.9763537388694308, 0.9760989389645823, 0.9763096658961425, 0.9764826436034405, 0.9761740322272262, 0.9764990747917726, 0.9765136510081367, 0.9758777670784868, 0.9763365622564024, 0.9765936154053794, 0.9763873648978705, 0.9761157429700158, 0.9764340685415351, 0.976249875837973, 0.976488241202383, 0.9762117624911357, 0.9765069276251567, 0.9760088993920593, 0.9765319622044824, 0.9761620815483254, 0.9761153745525541, 0.9765696978108116, 0.9762745473422568, 0.9763242338369936, 0.9764490126515943, 0.9763903682805951, 0.9764038077138221, 0.975976762536959, 0.9763608474304052, 0.9763600860832027, 0.976170678863626, 0.9758815015347017, 0.9766892496437515, 0.9765431695537533, 0.9765902364819666, 0.9765984571042924, 0.9762723031069147, 0.9768319651615431, 0.9766645829581209, 0.9764538779200066, 0.9761605954128326, 0.9764575983392753, 0.9764900960695974, 0.9764568480959257, 0.9764194875065179, 0.9762816363143586, 0.9764392966754826, 0.9763787722964697, 0.9763735371440492, 0.9763033086260509, 0.9764385537648662, 0.9762853751702133, 0.9763126566037142, 0.9764777925814812, 0.9766507605467195, 0.9766231231614031, 0.9763261090263541, 0.9764759138305074, 0.9764845070604281, 0.9763914808657131, 0.9763851348042278, 0.9765121494739043, 0.975967812412443, 0.9762397981486127, 0.9763948325532601, 0.9762405497537556, 0.9763866260726338, 0.9761523759427934, 0.9766485202920039, 0.9764008220344101, 0.9764587335511126, 0.9763881233119797, 0.9763361908010942, 0.9763604766036169, 0.9766369347832115, 0.976458718466633, 0.9765196249857938, 0.9765177655094328, 0.9763694388795192, 0.9764807617098669, 0.9762790190524083, 0.9765465289930467, 0.9765330683996472, 0.9764370586205869, 0.9761449066113503, 0.976432190942848], 'val_mDice': [0.1284747120575662, 0.31985367852899854, 0.4236992544679524, 0.5205067161516481, 0.58504550622511, 0.6252575923143665, 0.6610918715465257, 0.6866208227950366, 0.7006184299507543, 0.7101680874196004, 0.7154276976476445, 0.7255799177451376, 0.7320482500408152, 0.7328327580998358, 0.7308056110447446, 0.7360641352950165, 0.7434924046896882, 0.7467965426051135, 0.7451259352410824, 0.7465650468593322, 0.7489257943022649, 0.7528388143004767, 0.7575914013364822, 0.758942887108439, 0.7587774359279023, 0.7493452110273767, 0.7625536556193615, 0.7580386234712517, 0.7609594312409734, 0.7603178742899837, 0.7647671982357916, 0.765614747791592, 0.7654273644063511, 0.7677716375025798, 0.770226147451384, 0.7657919800553883, 0.7647474032085264, 0.7670583641172922, 0.7653162960218419, 0.7731180521013029, 0.769559013298819, 0.7683500634974462, 0.7751799311704921, 0.7730520218872647, 0.7796871937641151, 0.7737756147325981, 0.777355484258521, 0.7704352027293039, 0.7726988782991634, 0.7761809138715372, 0.7769601734744643, 0.7786485184056059, 0.7794356306324106, 0.7776942570515383, 0.7793176923150128, 0.7738122961014142, 0.7802885414636408, 0.7819268041419648, 0.7789949712937662, 0.78116301849144, 0.7807971629819886, 0.7822225246781415, 0.7828804523747919, 0.7816585335873971, 0.7848063100829904, 0.7820457391872976, 0.7848831328231127, 0.7846892636354443, 0.7841175926590637, 0.7822340690188752, 0.7781225364321355, 0.7837290793185913, 0.7834813288938391, 0.7792383319254709, 0.7804678105511859, 0.7805385852530468, 0.781475096050591, 0.7836644645315483, 0.7838205711912816, 0.781158268242184, 0.7829698107364098, 0.7830193396821382, 0.783289277071693, 0.7853634117567266, 0.7844057064274284, 0.786503886087079, 0.7847470334208912, 0.7838303227835255, 0.78563675561982, 0.7860912092959734, 0.7869328771618004, 0.7797839079045663, 0.7831855293736516, 0.7855380654125516, 0.7826242626027609, 0.7853360627573278, 0.7846347158529218, 0.7836716643326731, 0.7854071961345908, 0.7858269233485726, 0.7836487900812722, 0.7844158005630614, 0.7889559275236616, 0.7854594512857327, 0.7879748516216848, 0.786742943137727, 0.7883358089701782, 0.7866186600158839, 0.787415581763524, 0.7884625887828888, 0.7884860746889835, 0.7860387418098316, 0.7836325382306413, 0.7857480174837297, 0.7828947558134847, 0.7850559444963827, 0.7886541365320109, 0.7852358254481284, 0.7829984842369133, 0.784869952759131, 0.7863496136581541, 0.7889332077834225, 0.7877919803813807, 0.7877244073602981, 0.7850538605336356, 0.7844858785505244, 0.790061197192891, 0.7853790831691561, 0.7850665827208119, 0.7883284455443518, 0.7833550003584743, 0.7871693993913688, 0.7870184142266928, 0.7865709708528904, 0.7846592333698105, 0.7887953157374645, 0.7856577974212191, 0.7889962351385026, 0.7901342231485672, 0.7877024769364007, 0.7854527863551108, 0.7851606051196951, 0.7827608839908258, 0.78701871298319, 0.7880351940441634, 0.784971422805518, 0.7832113959039242, 0.7886858580401577, 0.7862890515679425, 0.7898047927812868, 0.7847749248330329, 0.7861678669448477, 0.7892765130435226, 0.7847709018861472, 0.7873485591164373, 0.7879309260363319, 0.7872536945007806, 0.7843083282556181, 0.7874787322037669, 0.7863785004364375, 0.7869276801395919, 0.7871329305670592, 0.7856491507671001, 0.7892300406952105, 0.7905071827145997, 0.7859454049167398, 0.783871400021082, 0.7898508294604993, 0.7895895707795826, 0.7878456726434571, 0.7863071591238145, 0.7874240391283756, 0.7877368830628889, 0.7852166595693632, 0.7871269164688768, 0.7874779992447167, 0.7890277734330752, 0.7847431936875797, 0.7893167847279715, 0.788943497284016, 0.7881139119815324, 0.7858300410171803, 0.7896330216228438, 0.7873141413623294, 0.7887965413514256, 0.7864846265588368, 0.7907051600136111, 0.7897144258546075, 0.787648385564137, 0.7880890611395476, 0.792639150560845, 0.7903976465570487, 0.789787946141248, 0.7909916159557752, 0.7886419342356114, 0.7926481199599738, 0.7910727787311131, 0.7890203023208257, 0.7904461723848889, 0.7895267080967372, 0.7906453046941171, 0.7904011359952247, 0.7902868485408844, 0.7895368892823874, 0.7907230199326112, 0.7889793375883455, 0.7885359635671538, 0.7891702248677218, 0.791211042127626, 0.7909812619271304, 0.7919680931865645, 0.7907708269431009, 0.7883360105155851, 0.7942576260684036, 0.788384064220167, 0.7923975911626497, 0.7879398803509811, 0.7896322889780537, 0.7903979143065601, 0.7897099853609484, 0.7882015481984049, 0.7885881459147314, 0.7898747780620528, 0.7902059859885902, 0.7887962939240601, 0.7919794335725647, 0.7920989666546585, 0.7884765478973857, 0.7930288959052315, 0.7909650244277056, 0.7879925285366173, 0.7900657588861529, 0.7899408959546282, 0.7925700973752093, 0.7932394617261702, 0.7919142979519648, 0.7929996348433, 0.7902994178929522, 0.7896056682238051, 0.7917620658036485, 0.7925013086917321, 0.7903166672047915, 0.7919272814986995, 0.7910047289776257], 'loss': [22.044997740413383, 4.334074122971362, 2.969525061185932, 2.4416560662314084, 2.092545088563362, 1.8109766633333855, 1.6149036591308934, 1.4867506800753247, 1.3896619465563356, 1.3207221398277507, 1.2637665005636338, 1.215366139834747, 1.1759736128160792, 1.14433021953293, 1.1189485999305766, 1.0979163157556564, 1.071716402240623, 1.0597116972430531, 1.0385824893916429, 1.0218738515281898, 1.0099804323198667, 0.9974570718470772, 0.9805820606644048, 0.9679718869068765, 0.9614013323581823, 0.9472350690542533, 0.9399656343757641, 0.9331897950143628, 0.9200990161678102, 0.9162828718420304, 0.9049515901757237, 0.8982313825760062, 0.8846658229209967, 0.8855415851779136, 0.8766478765899309, 0.8712792921681798, 0.8668824768763509, 0.8613893228204481, 0.8556092103356342, 0.8535520987052105, 0.8473928640547591, 0.8424091147948125, 0.8403729953977519, 0.8367038475573858, 0.832720486613598, 0.8301457168291526, 0.8247045675543545, 0.819037483365527, 0.8162438915429877, 0.8127334975559178, 0.8099048689707411, 0.8070936614005316, 0.8092928075669222, 0.8014902347863503, 0.7976337590741197, 0.7966625807233836, 0.7948076802335263, 0.7925554850454102, 0.7904294068305435, 0.7858960446495036, 0.7882023605131238, 0.7811705542674968, 0.7797186638747288, 0.7804352514193442, 0.7770189379333136, 0.7750605473484297, 0.7722774266050816, 0.7718823376926213, 0.7721702655796364, 0.7718500029152265, 0.7665947430759292, 0.7644204267749525, 0.7636814741734127, 0.7616861939616211, 0.7602212018554173, 0.7587833480040432, 0.7599363196214705, 0.7570242519335708, 0.757801640454263, 0.751535115901432, 0.7554620819695073, 0.751785683938454, 0.7526387063139884, 0.7522520528790647, 0.7500367249319942, 0.7479207847440053, 0.7472760927112634, 0.7461592674969271, 0.7438189484537845, 0.7452436554630487, 0.7431315070735353, 0.7431151230372071, 0.7402994183203959, 0.7403885828015501, 0.740603387394799, 0.7415636622319614, 0.7385955027758604, 0.7369334450857994, 0.7363099423527963, 0.7360448263700676, 0.732963929865154, 0.7323342922541223, 0.7340400563255361, 0.7325351647813321, 0.7332545392502836, 0.730813822159679, 0.7301780219785005, 0.7285159282034978, 0.7279258340673642, 0.728000223495647, 0.7243361302527405, 0.7251989369627322, 0.7251206060959501, 0.7246966758123984, 0.7220129904854514, 0.7238793842032177, 0.7222782720149742, 0.7221482168487703, 0.7192727897986811, 0.7193710853118709, 0.7222409976409994, 0.7192612060914552, 0.717633882230496, 0.7194267859828951, 0.7173050997433728, 0.719138282881512, 0.7151421005559924, 0.7182152408441523, 0.7137954579698597, 0.7124689130284911, 0.7125414448351705, 0.7145279445757858, 0.7108970634812863, 0.7100950564755496, 0.7109844903060207, 0.7109631216914177, 0.7103853180114399, 0.7091453125051976, 0.7108447984236667, 0.7096404768273464, 0.7082836946725521, 0.7080827333127947, 0.707043175074374, 0.7062764449416167, 0.7064657201045149, 0.708606126209935, 0.7071806357614911, 0.7069266245731212, 0.7034310471860987, 0.7050940809573353, 0.705583537241622, 0.702728732072811, 0.7052844768441333, 0.7033673272111997, 0.7009599652049658, 0.7016000221344445, 0.7015416387294788, 0.7023382851836438, 0.7004547437066059, 0.7014734689113472, 0.7013275123321622, 0.6997266800886768, 0.7003297217208638, 0.7002004607323341, 0.6989267985070036, 0.7001622911368491, 0.6990251155691726, 0.7001807315439206, 0.6962088141610041, 0.6958859301250514, 0.6963407981558298, 0.6963320667427767, 0.6958546420779288, 0.6962788306222781, 0.6950643979653002, 0.6957388465498457, 0.6957740969125412, 0.6941058935069707, 0.6963504963663598, 0.6951374945868052, 0.6947907836458462, 0.6956378746678225, 0.6952950457856866, 0.6928378390465582, 0.6945409951605487, 0.6924148554902967, 0.6928794257270451, 0.6936834239886527, 0.6922715710685355, 0.6921916819081909, 0.6914543161592104, 0.6917439478253942, 0.6915672694507108, 0.690042805293145, 0.6884585570619557, 0.6902534710335675, 0.6945351310275676, 0.6906240321592694, 0.6900705843601473, 0.6885303513650163, 0.687907180934432, 0.6881037361578303, 0.6897221848628858, 0.689780140755779, 0.6887789143151063, 0.6877108623688597, 0.6880934393902045, 0.6866012211354916, 0.6873620900058656, 0.6877999200229886, 0.6857804502030335, 0.6876952562674825, 0.6881153037033217, 0.6878709502161602, 0.6860159836935593, 0.6863893274422003, 0.6829411168354254, 0.6854228302112769, 0.6871634422307957, 0.6844668642491076, 0.683471173907399, 0.6841663466048921, 0.684418609752298, 0.6837788103217238, 0.6837198751890979, 0.6827195180715657, 0.6836039151370774, 0.6830763873195596, 0.6834357037115191, 0.6844482755878181, 0.6849615402757044, 0.6829384328716565, 0.6835168601882146, 0.6822416938387281, 0.6848847153478237, 0.6814762381523222, 0.6812932126313653, 0.6830793413954649, 0.680435944962925, 0.6838195420860507, 0.6801036081300409, 0.6798772572553198, 0.6799120127443854, 0.6808546432508843], 'acc': [0.60537694940062, 0.8886255245612844, 0.9047139100631059, 0.9147464572816411, 0.9221702452922802, 0.9275951046485569, 0.9321408610952008, 0.9352845207481391, 0.9377538714469587, 0.9395588265140358, 0.9409935143782097, 0.9421760250689261, 0.943421224881044, 0.9446769554759841, 0.9456961903962747, 0.9464665607767516, 0.947342308719675, 0.9478127117707945, 0.9484702160155537, 0.9490682469941213, 0.949439337656594, 0.9498734533303841, 0.9504899816750388, 0.9507605084912909, 0.9511782838086298, 0.9515048081972873, 0.9517580570875144, 0.9520064376811666, 0.9522620288560582, 0.9522530871694805, 0.9523899361133503, 0.9525409653144684, 0.952615651953089, 0.9524262173595393, 0.9523765969022064, 0.9524199789900177, 0.9525536882110057, 0.9525352443484186, 0.9527047340207956, 0.9526404925030051, 0.9528361947989645, 0.9528311051604168, 0.9529704054716602, 0.9529279343381537, 0.9529355393850979, 0.9530131016306234, 0.9530160761816585, 0.9531133439579138, 0.9530979055180343, 0.9532049626650408, 0.9530962379977829, 0.9529687472111109, 0.9526952025028991, 0.9528054366395635, 0.952848843530898, 0.9528803907896851, 0.9529187632017398, 0.9530317062466765, 0.9530612233870402, 0.9532105263391395, 0.9531496443474192, 0.9533571154126631, 0.9535312718338674, 0.9535172992135131, 0.9536591159800063, 0.9537356407939562, 0.9538601896980138, 0.9539362540195143, 0.9540371258445633, 0.9540372809168257, 0.9541469378144061, 0.9542498959430025, 0.9543797712154234, 0.9543761464065397, 0.954361359742296, 0.9544550240996691, 0.9544227879844442, 0.9546465642120726, 0.9547017452629359, 0.9548374754176346, 0.9548378601826993, 0.9548619854438828, 0.9548283085616208, 0.9548610011798543, 0.9549661096110269, 0.9549302280948048, 0.9549739630531517, 0.9550567471376933, 0.9552344984799709, 0.9551997363408374, 0.9551840145936712, 0.9551601015137448, 0.9552416671750817, 0.9553202765888179, 0.9553540075564984, 0.9553814035052053, 0.9554451358923644, 0.9555200902044632, 0.95560827483697, 0.9556549295650312, 0.9556706429793654, 0.9556975385112195, 0.9557298592625804, 0.9557491934603627, 0.9558112722183233, 0.9558954984827038, 0.9559393326041503, 0.9559029352982303, 0.9559494400443156, 0.9560615262893563, 0.9560274524157435, 0.9560465373964604, 0.9560934063064981, 0.9560891722200213, 0.9561480014824878, 0.9561786828166579, 0.9561953186106954, 0.956217806374419, 0.9563510208597578, 0.9563795666942766, 0.9562489921568769, 0.9563456199038497, 0.9564214061313328, 0.9564554489472991, 0.9564644651134363, 0.9564381495862787, 0.9564933842816222, 0.9564772379649711, 0.9566127216772154, 0.9565836645403696, 0.9565962989403122, 0.9565376638736238, 0.9566368246035297, 0.9566401105499143, 0.9566950347437831, 0.9567022255187989, 0.9566781300824347, 0.9567031765444867, 0.9567497788338984, 0.9567861928084819, 0.9567586686847422, 0.9567790032332979, 0.9567925592150556, 0.9567838186232891, 0.9567942523757127, 0.9567802468259743, 0.9568070128359845, 0.9567918741890807, 0.956888982024756, 0.9568885774384699, 0.9568133347407962, 0.9569142740923795, 0.9568928774077113, 0.9569259224165476, 0.9569615054746068, 0.9569405273332683, 0.9569097263428713, 0.9569619662430174, 0.9570416068252071, 0.956936528038879, 0.956958510040499, 0.9570435516025932, 0.9570220178701361, 0.9570040124710862, 0.957070212420349, 0.957037967666335, 0.9570226776396512, 0.9570413378319139, 0.957092271145214, 0.9570983061642407, 0.9571153906443826, 0.9571021260087847, 0.9570619949852477, 0.9571142139093343, 0.9571044780870765, 0.9571894649248419, 0.9570843225834228, 0.9571474542327918, 0.9571369051675325, 0.9572268021700037, 0.9572293897542828, 0.9572629195011698, 0.9571759546596759, 0.9572609835395479, 0.9571900323523014, 0.9572146819399862, 0.9572356389552861, 0.9571938536456425, 0.9572416076266131, 0.9572452037325203, 0.9572608334885816, 0.957255397146634, 0.9572984173411746, 0.9572770722912683, 0.9574031074899809, 0.9573363624031341, 0.9572471401200826, 0.957349404505926, 0.9573542515234836, 0.9573640842081634, 0.9573612995245131, 0.9573221426714194, 0.9573866977772519, 0.9573367051890833, 0.9574338894870403, 0.9573608603710725, 0.9573775838818142, 0.95748339825203, 0.9574112842327863, 0.957456502684181, 0.9575067216056228, 0.957433565835409, 0.957440510470928, 0.9575013396040578, 0.9574717725926848, 0.957398316831523, 0.9575531524030739, 0.957532397646422, 0.9575213143800455, 0.9575405086144474, 0.9575983522060827, 0.9575555694192629, 0.9574658539993378, 0.95758093643738, 0.9575444967324034, 0.9575620544292109, 0.9575745732913493, 0.9576056148030306, 0.9575866069684996, 0.9576005348051316, 0.9575570342489268, 0.9575762727961171, 0.9575913345487996, 0.9576218018479726, 0.9576046121665777, 0.9577020276931216, 0.9576599099850728, 0.9576570538844336, 0.9577723822610007, 0.9575804345927272, 0.9577161487956621, 0.957770144094741, 0.9577246151148754, 0.9577330976978089], 'mDice': [0.029073035684652533, 0.13368263873295783, 0.24356516349220256, 0.31868429026422046, 0.3780208455991939, 0.4335407791488166, 0.4793965985224151, 0.5108361430805503, 0.5355649260178551, 0.5539741959511126, 0.5707027256881745, 0.5852273077569078, 0.5970464255716077, 0.6062665928274604, 0.6142010278589238, 0.6205135091496584, 0.6283430904382477, 0.6321110875711762, 0.6380348842677098, 0.643262013270315, 0.6471464961705705, 0.6508036529428135, 0.6554157036215038, 0.6597665221070459, 0.6619832382415238, 0.6663023680920966, 0.6687775239221679, 0.6709721856811711, 0.6747955287938436, 0.676448119043026, 0.6797594676037678, 0.6824562652926579, 0.6859758324738532, 0.6865643114803913, 0.6893531350903264, 0.6910672921802286, 0.6924226893241702, 0.6943701001131735, 0.695649445179898, 0.6967700106659327, 0.6988992848487968, 0.7002639378762726, 0.7012033729037055, 0.7022211945121106, 0.7036111644047339, 0.7044925334487058, 0.706413988066178, 0.7078682752189743, 0.7086282890382072, 0.7099771833936928, 0.7108303062701392, 0.7118496775963089, 0.7112192139040752, 0.7138343365909553, 0.7150564389208184, 0.7156620061509736, 0.7163528046426316, 0.7170354664028755, 0.7175793394361635, 0.7192497595909959, 0.7184424701187416, 0.720532449914791, 0.7210924708005149, 0.7209552353398261, 0.7216363081808005, 0.7225384251963756, 0.7233652169808462, 0.723574543723966, 0.7237893965804495, 0.72365962323974, 0.7253208859812349, 0.7258676394657486, 0.7262029521184901, 0.7269271711273466, 0.7273221082790804, 0.7278155974080533, 0.7273525495389035, 0.7283446234165587, 0.7281859641789994, 0.7299101671846911, 0.729086125711689, 0.7300332251447453, 0.7297080258383412, 0.7296894661199944, 0.7306480365990693, 0.7308502143663139, 0.7314990979154998, 0.7315530644756073, 0.7325816851642254, 0.7319156204554499, 0.7326922501185167, 0.7327951628874715, 0.7333597792610117, 0.733190054541583, 0.7336294782593052, 0.7334397563060369, 0.7338768551666516, 0.7344649356760501, 0.7346927785656243, 0.7350906189923845, 0.7354148726213513, 0.736059350691086, 0.7356238988485966, 0.7357872973948119, 0.735741173841292, 0.7365426714644328, 0.7365844895354839, 0.7370662622408348, 0.7372177779767517, 0.7375238859913237, 0.7386014595478556, 0.7383033549963789, 0.7382409907174419, 0.7385142929366452, 0.7392050618944431, 0.7386749859611136, 0.738996905785227, 0.7391589148752127, 0.7399290218866079, 0.7400750080476463, 0.7392721357202081, 0.7400166258755079, 0.7405792162070535, 0.7401305550802073, 0.7408246123690555, 0.7401623995973254, 0.7410541950027569, 0.7403361413866517, 0.742027347052825, 0.7420459400755033, 0.7421908636264956, 0.7418494196022338, 0.7427326396027435, 0.7427735094167189, 0.7428601128388757, 0.7425754913643762, 0.7431503554354207, 0.7432213385141968, 0.7427683555931686, 0.7432474630851221, 0.7435859291718234, 0.7438237759410798, 0.7440884578756523, 0.7442889524558417, 0.744007655763283, 0.7436155025693012, 0.7437046187452266, 0.744026948500877, 0.7449545478144096, 0.7445040239906714, 0.7449086618335874, 0.7452479056272717, 0.7447633840382523, 0.7451342681736755, 0.7458545764537278, 0.7455853407614893, 0.7455402350042973, 0.7454869194219376, 0.7461354772137874, 0.7455749990481638, 0.7458691081897066, 0.7464143843183123, 0.7464081680136978, 0.7460584438811202, 0.7468144187665203, 0.7462591793815381, 0.7461130595412385, 0.7462458283160558, 0.7472231379273278, 0.7476667991480478, 0.7473895509849766, 0.7471943604412811, 0.7476468617288236, 0.7472820658759606, 0.7476334047451886, 0.7476622888812853, 0.747187313622086, 0.7480538228210725, 0.7475476137171525, 0.7478325268257715, 0.7478386640884659, 0.7479388612360894, 0.747578293686514, 0.7482634888916261, 0.747714168369953, 0.7486487030892984, 0.7484803473599682, 0.7480529425734633, 0.7486349334234944, 0.7485622232018249, 0.7490602992158202, 0.7486894593841866, 0.7488968207428088, 0.7491862291142934, 0.7495733551179737, 0.7492310532769585, 0.7478699517246462, 0.7491792978359021, 0.7493590864595988, 0.7498922919502352, 0.7498836882982729, 0.749811360394011, 0.7492469519873185, 0.7495220535192988, 0.7497920289288457, 0.7501598162113777, 0.7497353753244012, 0.7504348815864265, 0.7500647350656063, 0.7501332049796712, 0.7508156351573778, 0.749814058503797, 0.7499956327621881, 0.7499007872183906, 0.7506960240441536, 0.7505011104936299, 0.7516340463116234, 0.7506060828128822, 0.7501863166566141, 0.75119303411557, 0.7514164256081296, 0.7514453224054515, 0.751091727762432, 0.7513731419005276, 0.7513687570101901, 0.7516819635537086, 0.7513833086513788, 0.7514881901073681, 0.7516198272278178, 0.7509772696808692, 0.7510110651185123, 0.7514972256267924, 0.7515169739045301, 0.7518544525626465, 0.7509402747657206, 0.7517754785020256, 0.7520939740241489, 0.7513998919527746, 0.752590262426727, 0.7514347045058412, 0.752381644565238, 0.7525286469688222, 0.752372929280924, 0.7520968126132428]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:33,  2.40s/it]predicting test subjects:  13%|█▎        | 2/15 [00:04<00:29,  2.26s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:27,  2.26s/it]predicting test subjects:  27%|██▋       | 4/15 [00:08<00:24,  2.25s/it]predicting test subjects:  33%|███▎      | 5/15 [00:11<00:23,  2.35s/it]predicting test subjects:  40%|████      | 6/15 [00:13<00:21,  2.41s/it]predicting test subjects:  47%|████▋     | 7/15 [00:15<00:17,  2.18s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:18<00:16,  2.36s/it]predicting test subjects:  60%|██████    | 9/15 [00:20<00:13,  2.28s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:22<00:10,  2.12s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:24<00:08,  2.15s/it]predicting test subjects:  80%|████████  | 12/15 [00:26<00:06,  2.21s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:29<00:04,  2.36s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:31<00:02,  2.27s/it]predicting test subjects: 100%|██████████| 15/15 [00:33<00:00,  2.27s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<26:20,  2.98s/it]predicting train subjects:   0%|          | 2/532 [00:04<23:32,  2.66s/it]predicting train subjects:   1%|          | 3/532 [00:06<21:48,  2.47s/it]predicting train subjects:   1%|          | 4/532 [00:08<20:35,  2.34s/it]predicting train subjects:   1%|          | 5/532 [00:11<20:47,  2.37s/it]predicting train subjects:   1%|          | 6/532 [00:13<19:33,  2.23s/it]predicting train subjects:   1%|▏         | 7/532 [00:15<18:34,  2.12s/it]predicting train subjects:   2%|▏         | 8/532 [00:17<18:12,  2.09s/it]predicting train subjects:   2%|▏         | 9/532 [00:19<19:14,  2.21s/it]predicting train subjects:   2%|▏         | 10/532 [00:21<18:39,  2.14s/it]predicting train subjects:   2%|▏         | 11/532 [00:23<17:17,  1.99s/it]predicting train subjects:   2%|▏         | 12/532 [00:25<18:22,  2.12s/it]predicting train subjects:   2%|▏         | 13/532 [00:27<17:31,  2.03s/it]predicting train subjects:   3%|▎         | 14/532 [00:29<16:26,  1.91s/it]predicting train subjects:   3%|▎         | 15/532 [00:31<16:35,  1.93s/it]predicting train subjects:   3%|▎         | 16/532 [00:33<16:54,  1.97s/it]predicting train subjects:   3%|▎         | 17/532 [00:35<17:01,  1.98s/it]predicting train subjects:   3%|▎         | 18/532 [00:37<18:05,  2.11s/it]predicting train subjects:   4%|▎         | 19/532 [00:39<16:46,  1.96s/it]predicting train subjects:   4%|▍         | 20/532 [00:41<17:01,  2.00s/it]predicting train subjects:   4%|▍         | 21/532 [00:43<18:12,  2.14s/it]predicting train subjects:   4%|▍         | 22/532 [00:45<17:27,  2.05s/it]predicting train subjects:   4%|▍         | 23/532 [00:47<18:11,  2.15s/it]predicting train subjects:   5%|▍         | 24/532 [00:49<17:10,  2.03s/it]predicting train subjects:   5%|▍         | 25/532 [00:52<18:59,  2.25s/it]predicting train subjects:   5%|▍         | 26/532 [00:54<18:05,  2.15s/it]predicting train subjects:   5%|▌         | 27/532 [00:57<20:44,  2.46s/it]predicting train subjects:   5%|▌         | 28/532 [00:59<19:58,  2.38s/it]predicting train subjects:   5%|▌         | 29/532 [01:02<20:25,  2.44s/it]predicting train subjects:   6%|▌         | 30/532 [01:04<18:53,  2.26s/it]predicting train subjects:   6%|▌         | 31/532 [01:06<17:58,  2.15s/it]predicting train subjects:   6%|▌         | 32/532 [01:08<17:22,  2.08s/it]predicting train subjects:   6%|▌         | 33/532 [01:09<16:35,  1.99s/it]predicting train subjects:   6%|▋         | 34/532 [01:12<18:26,  2.22s/it]predicting train subjects:   7%|▋         | 35/532 [01:14<18:10,  2.19s/it]predicting train subjects:   7%|▋         | 36/532 [01:17<18:41,  2.26s/it]predicting train subjects:   7%|▋         | 37/532 [01:19<18:22,  2.23s/it]predicting train subjects:   7%|▋         | 38/532 [01:21<18:50,  2.29s/it]predicting train subjects:   7%|▋         | 39/532 [01:23<18:20,  2.23s/it]predicting train subjects:   8%|▊         | 40/532 [01:25<17:06,  2.09s/it]predicting train subjects:   8%|▊         | 41/532 [01:27<17:42,  2.16s/it]predicting train subjects:   8%|▊         | 42/532 [01:30<18:00,  2.20s/it]predicting train subjects:   8%|▊         | 43/532 [01:32<17:08,  2.10s/it]predicting train subjects:   8%|▊         | 44/532 [01:33<16:16,  2.00s/it]predicting train subjects:   8%|▊         | 45/532 [01:35<16:13,  2.00s/it]predicting train subjects:   9%|▊         | 46/532 [01:37<16:28,  2.03s/it]predicting train subjects:   9%|▉         | 47/532 [01:40<17:50,  2.21s/it]predicting train subjects:   9%|▉         | 48/532 [01:42<17:53,  2.22s/it]predicting train subjects:   9%|▉         | 49/532 [01:44<17:16,  2.15s/it]predicting train subjects:   9%|▉         | 50/532 [01:47<17:39,  2.20s/it]predicting train subjects:  10%|▉         | 51/532 [01:48<16:39,  2.08s/it]predicting train subjects:  10%|▉         | 52/532 [01:51<17:08,  2.14s/it]predicting train subjects:  10%|▉         | 53/532 [01:53<16:50,  2.11s/it]predicting train subjects:  10%|█         | 54/532 [01:55<17:35,  2.21s/it]predicting train subjects:  10%|█         | 55/532 [01:57<17:48,  2.24s/it]predicting train subjects:  11%|█         | 56/532 [02:00<17:38,  2.22s/it]predicting train subjects:  11%|█         | 57/532 [02:02<17:22,  2.19s/it]predicting train subjects:  11%|█         | 58/532 [02:04<17:28,  2.21s/it]predicting train subjects:  11%|█         | 59/532 [02:07<18:53,  2.40s/it]predicting train subjects:  11%|█▏        | 60/532 [02:08<16:52,  2.14s/it]predicting train subjects:  11%|█▏        | 61/532 [02:10<16:19,  2.08s/it]predicting train subjects:  12%|█▏        | 62/532 [02:13<18:11,  2.32s/it]predicting train subjects:  12%|█▏        | 63/532 [02:16<19:09,  2.45s/it]predicting train subjects:  12%|█▏        | 64/532 [02:18<17:16,  2.21s/it]predicting train subjects:  12%|█▏        | 65/532 [02:20<17:06,  2.20s/it]predicting train subjects:  12%|█▏        | 66/532 [02:23<18:30,  2.38s/it]predicting train subjects:  13%|█▎        | 67/532 [02:25<19:02,  2.46s/it]predicting train subjects:  13%|█▎        | 68/532 [02:27<18:15,  2.36s/it]predicting train subjects:  13%|█▎        | 69/532 [02:29<17:19,  2.24s/it]predicting train subjects:  13%|█▎        | 70/532 [02:31<16:40,  2.17s/it]predicting train subjects:  13%|█▎        | 71/532 [02:33<16:12,  2.11s/it]predicting train subjects:  14%|█▎        | 72/532 [02:35<15:33,  2.03s/it]predicting train subjects:  14%|█▎        | 73/532 [02:37<16:09,  2.11s/it]predicting train subjects:  14%|█▍        | 74/532 [02:40<17:41,  2.32s/it]predicting train subjects:  14%|█▍        | 75/532 [02:44<19:50,  2.60s/it]predicting train subjects:  14%|█▍        | 76/532 [02:45<18:18,  2.41s/it]predicting train subjects:  14%|█▍        | 77/532 [02:47<17:05,  2.25s/it]predicting train subjects:  15%|█▍        | 78/532 [02:50<17:00,  2.25s/it]predicting train subjects:  15%|█▍        | 79/532 [02:52<16:43,  2.22s/it]predicting train subjects:  15%|█▌        | 80/532 [02:54<16:06,  2.14s/it]predicting train subjects:  15%|█▌        | 81/532 [02:56<15:30,  2.06s/it]predicting train subjects:  15%|█▌        | 82/532 [02:57<14:57,  1.99s/it]predicting train subjects:  16%|█▌        | 83/532 [02:59<13:53,  1.86s/it]predicting train subjects:  16%|█▌        | 84/532 [03:00<13:05,  1.75s/it]predicting train subjects:  16%|█▌        | 85/532 [03:02<12:28,  1.68s/it]predicting train subjects:  16%|█▌        | 86/532 [03:04<12:10,  1.64s/it]predicting train subjects:  16%|█▋        | 87/532 [03:05<11:53,  1.60s/it]predicting train subjects:  17%|█▋        | 88/532 [03:07<11:46,  1.59s/it]predicting train subjects:  17%|█▋        | 89/532 [03:08<12:10,  1.65s/it]predicting train subjects:  17%|█▋        | 90/532 [03:10<12:22,  1.68s/it]predicting train subjects:  17%|█▋        | 91/532 [03:12<12:27,  1.69s/it]predicting train subjects:  17%|█▋        | 92/532 [03:14<12:36,  1.72s/it]predicting train subjects:  17%|█▋        | 93/532 [03:15<12:41,  1.74s/it]predicting train subjects:  18%|█▊        | 94/532 [03:17<13:21,  1.83s/it]predicting train subjects:  18%|█▊        | 95/532 [03:20<13:45,  1.89s/it]predicting train subjects:  18%|█▊        | 96/532 [03:22<14:00,  1.93s/it]predicting train subjects:  18%|█▊        | 97/532 [03:24<14:10,  1.95s/it]predicting train subjects:  18%|█▊        | 98/532 [03:26<14:20,  1.98s/it]predicting train subjects:  19%|█▊        | 99/532 [03:28<14:38,  2.03s/it]predicting train subjects:  19%|█▉        | 100/532 [03:30<14:46,  2.05s/it]predicting train subjects:  19%|█▉        | 101/532 [03:31<13:44,  1.91s/it]predicting train subjects:  19%|█▉        | 102/532 [03:33<12:57,  1.81s/it]predicting train subjects:  19%|█▉        | 103/532 [03:34<12:10,  1.70s/it]predicting train subjects:  20%|█▉        | 104/532 [03:36<11:41,  1.64s/it]predicting train subjects:  20%|█▉        | 105/532 [03:37<11:22,  1.60s/it]predicting train subjects:  20%|█▉        | 106/532 [03:39<11:03,  1.56s/it]predicting train subjects:  20%|██        | 107/532 [03:40<10:48,  1.53s/it]predicting train subjects:  20%|██        | 108/532 [03:42<10:45,  1.52s/it]predicting train subjects:  20%|██        | 109/532 [03:43<10:42,  1.52s/it]predicting train subjects:  21%|██        | 110/532 [03:45<10:40,  1.52s/it]predicting train subjects:  21%|██        | 111/532 [03:46<10:37,  1.51s/it]predicting train subjects:  21%|██        | 112/532 [03:48<10:35,  1.51s/it]predicting train subjects:  21%|██        | 113/532 [03:50<11:16,  1.62s/it]predicting train subjects:  21%|██▏       | 114/532 [03:52<11:34,  1.66s/it]predicting train subjects:  22%|██▏       | 115/532 [03:53<11:37,  1.67s/it]predicting train subjects:  22%|██▏       | 116/532 [03:55<11:42,  1.69s/it]predicting train subjects:  22%|██▏       | 117/532 [03:57<11:51,  1.72s/it]predicting train subjects:  22%|██▏       | 118/532 [03:58<11:55,  1.73s/it]predicting train subjects:  22%|██▏       | 119/532 [04:00<11:57,  1.74s/it]predicting train subjects:  23%|██▎       | 120/532 [04:02<12:00,  1.75s/it]predicting train subjects:  23%|██▎       | 121/532 [04:04<11:50,  1.73s/it]predicting train subjects:  23%|██▎       | 122/532 [04:05<11:43,  1.72s/it]predicting train subjects:  23%|██▎       | 123/532 [04:07<11:39,  1.71s/it]predicting train subjects:  23%|██▎       | 124/532 [04:09<11:30,  1.69s/it]predicting train subjects:  23%|██▎       | 125/532 [04:11<11:46,  1.74s/it]predicting train subjects:  24%|██▎       | 126/532 [04:12<11:50,  1.75s/it]predicting train subjects:  24%|██▍       | 127/532 [04:14<12:09,  1.80s/it]predicting train subjects:  24%|██▍       | 128/532 [04:16<12:05,  1.79s/it]predicting train subjects:  24%|██▍       | 129/532 [04:18<12:13,  1.82s/it]predicting train subjects:  24%|██▍       | 130/532 [04:20<12:18,  1.84s/it]predicting train subjects:  25%|██▍       | 131/532 [04:22<12:58,  1.94s/it]predicting train subjects:  25%|██▍       | 132/532 [04:24<13:23,  2.01s/it]predicting train subjects:  25%|██▌       | 133/532 [04:27<14:15,  2.15s/it]predicting train subjects:  25%|██▌       | 134/532 [04:29<14:13,  2.15s/it]predicting train subjects:  25%|██▌       | 135/532 [04:31<14:16,  2.16s/it]predicting train subjects:  26%|██▌       | 136/532 [04:33<14:21,  2.18s/it]predicting train subjects:  26%|██▌       | 137/532 [04:35<14:24,  2.19s/it]predicting train subjects:  26%|██▌       | 138/532 [04:38<14:26,  2.20s/it]predicting train subjects:  26%|██▌       | 139/532 [04:40<14:11,  2.17s/it]predicting train subjects:  26%|██▋       | 140/532 [04:42<14:05,  2.16s/it]predicting train subjects:  27%|██▋       | 141/532 [04:44<14:12,  2.18s/it]predicting train subjects:  27%|██▋       | 142/532 [04:46<14:03,  2.16s/it]predicting train subjects:  27%|██▋       | 143/532 [04:48<12:48,  1.98s/it]predicting train subjects:  27%|██▋       | 144/532 [04:49<11:56,  1.85s/it]predicting train subjects:  27%|██▋       | 145/532 [04:51<11:22,  1.76s/it]predicting train subjects:  27%|██▋       | 146/532 [04:52<10:55,  1.70s/it]predicting train subjects:  28%|██▊       | 147/532 [04:54<10:47,  1.68s/it]predicting train subjects:  28%|██▊       | 148/532 [04:56<10:28,  1.64s/it]predicting train subjects:  28%|██▊       | 149/532 [04:57<10:28,  1.64s/it]predicting train subjects:  28%|██▊       | 150/532 [04:59<10:32,  1.66s/it]predicting train subjects:  28%|██▊       | 151/532 [05:01<10:27,  1.65s/it]predicting train subjects:  29%|██▊       | 152/532 [05:02<10:26,  1.65s/it]predicting train subjects:  29%|██▉       | 153/532 [05:04<10:22,  1.64s/it]predicting train subjects:  29%|██▉       | 154/532 [05:05<10:20,  1.64s/it]predicting train subjects:  29%|██▉       | 155/532 [05:08<11:21,  1.81s/it]predicting train subjects:  29%|██▉       | 156/532 [05:10<12:04,  1.93s/it]predicting train subjects:  30%|██▉       | 157/532 [05:12<12:29,  2.00s/it]predicting train subjects:  30%|██▉       | 158/532 [05:14<13:08,  2.11s/it]predicting train subjects:  30%|██▉       | 159/532 [05:17<13:28,  2.17s/it]predicting train subjects:  30%|███       | 160/532 [05:19<13:38,  2.20s/it]predicting train subjects:  30%|███       | 161/532 [05:21<12:25,  2.01s/it]predicting train subjects:  30%|███       | 162/532 [05:22<11:34,  1.88s/it]predicting train subjects:  31%|███       | 163/532 [05:24<10:58,  1.79s/it]predicting train subjects:  31%|███       | 164/532 [05:25<10:44,  1.75s/it]predicting train subjects:  31%|███       | 165/532 [05:27<10:36,  1.73s/it]predicting train subjects:  31%|███       | 166/532 [05:29<10:19,  1.69s/it]predicting train subjects:  31%|███▏      | 167/532 [05:30<10:22,  1.71s/it]predicting train subjects:  32%|███▏      | 168/532 [05:32<10:32,  1.74s/it]predicting train subjects:  32%|███▏      | 169/532 [05:34<10:31,  1.74s/it]predicting train subjects:  32%|███▏      | 170/532 [05:36<10:29,  1.74s/it]predicting train subjects:  32%|███▏      | 171/532 [05:37<10:26,  1.73s/it]predicting train subjects:  32%|███▏      | 172/532 [05:39<10:21,  1.73s/it]predicting train subjects:  33%|███▎      | 173/532 [05:41<10:03,  1.68s/it]predicting train subjects:  33%|███▎      | 174/532 [05:42<09:52,  1.65s/it]predicting train subjects:  33%|███▎      | 175/532 [05:44<09:41,  1.63s/it]predicting train subjects:  33%|███▎      | 176/532 [05:45<09:25,  1.59s/it]predicting train subjects:  33%|███▎      | 177/532 [05:47<09:21,  1.58s/it]predicting train subjects:  33%|███▎      | 178/532 [05:49<10:08,  1.72s/it]predicting train subjects:  34%|███▎      | 179/532 [05:51<10:00,  1.70s/it]predicting train subjects:  34%|███▍      | 180/532 [05:52<09:49,  1.68s/it]predicting train subjects:  34%|███▍      | 181/532 [05:54<09:46,  1.67s/it]predicting train subjects:  34%|███▍      | 182/532 [05:56<09:41,  1.66s/it]predicting train subjects:  34%|███▍      | 183/532 [05:57<09:33,  1.64s/it]predicting train subjects:  35%|███▍      | 184/532 [05:59<09:37,  1.66s/it]predicting train subjects:  35%|███▍      | 185/532 [06:00<09:13,  1.60s/it]predicting train subjects:  35%|███▍      | 186/532 [06:02<09:02,  1.57s/it]predicting train subjects:  35%|███▌      | 187/532 [06:03<09:00,  1.57s/it]predicting train subjects:  35%|███▌      | 188/532 [06:05<08:56,  1.56s/it]predicting train subjects:  36%|███▌      | 189/532 [06:06<08:49,  1.54s/it]predicting train subjects:  36%|███▌      | 190/532 [06:08<08:45,  1.54s/it]predicting train subjects:  36%|███▌      | 191/532 [06:10<10:00,  1.76s/it]predicting train subjects:  36%|███▌      | 192/532 [06:13<11:06,  1.96s/it]predicting train subjects:  36%|███▋      | 193/532 [06:15<11:35,  2.05s/it]predicting train subjects:  36%|███▋      | 194/532 [06:17<11:56,  2.12s/it]predicting train subjects:  37%|███▋      | 195/532 [06:19<12:11,  2.17s/it]predicting train subjects:  37%|███▋      | 196/532 [06:22<12:17,  2.19s/it]predicting train subjects:  37%|███▋      | 197/532 [06:24<11:48,  2.11s/it]predicting train subjects:  37%|███▋      | 198/532 [06:26<11:27,  2.06s/it]predicting train subjects:  37%|███▋      | 199/532 [06:28<11:30,  2.07s/it]predicting train subjects:  38%|███▊      | 200/532 [06:30<11:17,  2.04s/it]predicting train subjects:  38%|███▊      | 201/532 [06:32<11:02,  2.00s/it]predicting train subjects:  38%|███▊      | 202/532 [06:33<10:52,  1.98s/it]predicting train subjects:  38%|███▊      | 203/532 [06:35<10:20,  1.89s/it]predicting train subjects:  38%|███▊      | 204/532 [06:37<09:51,  1.80s/it]predicting train subjects:  39%|███▊      | 205/532 [06:38<09:37,  1.77s/it]predicting train subjects:  39%|███▊      | 206/532 [06:40<09:24,  1.73s/it]predicting train subjects:  39%|███▉      | 207/532 [06:42<09:16,  1.71s/it]predicting train subjects:  39%|███▉      | 208/532 [06:43<09:05,  1.68s/it]predicting train subjects:  39%|███▉      | 209/532 [06:45<08:38,  1.60s/it]predicting train subjects:  39%|███▉      | 210/532 [06:46<08:25,  1.57s/it]predicting train subjects:  40%|███▉      | 211/532 [06:48<08:13,  1.54s/it]predicting train subjects:  40%|███▉      | 212/532 [06:49<08:03,  1.51s/it]predicting train subjects:  40%|████      | 213/532 [06:51<07:59,  1.50s/it]predicting train subjects:  40%|████      | 214/532 [06:52<07:52,  1.48s/it]predicting train subjects:  40%|████      | 215/532 [06:54<08:53,  1.68s/it]predicting train subjects:  41%|████      | 216/532 [06:56<09:34,  1.82s/it]predicting train subjects:  41%|████      | 217/532 [06:58<09:58,  1.90s/it]predicting train subjects:  41%|████      | 218/532 [07:01<10:13,  1.95s/it]predicting train subjects:  41%|████      | 219/532 [07:03<10:23,  1.99s/it]predicting train subjects:  41%|████▏     | 220/532 [07:05<10:33,  2.03s/it]predicting train subjects:  42%|████▏     | 221/532 [07:06<09:34,  1.85s/it]predicting train subjects:  42%|████▏     | 222/532 [07:08<08:49,  1.71s/it]predicting train subjects:  42%|████▏     | 223/532 [07:09<08:24,  1.63s/it]predicting train subjects:  42%|████▏     | 224/532 [07:11<08:11,  1.60s/it]predicting train subjects:  42%|████▏     | 225/532 [07:12<07:53,  1.54s/it]predicting train subjects:  42%|████▏     | 226/532 [07:13<07:41,  1.51s/it]predicting train subjects:  43%|████▎     | 227/532 [07:15<07:27,  1.47s/it]predicting train subjects:  43%|████▎     | 228/532 [07:16<07:20,  1.45s/it]predicting train subjects:  43%|████▎     | 229/532 [07:17<07:11,  1.42s/it]predicting train subjects:  43%|████▎     | 230/532 [07:19<07:32,  1.50s/it]predicting train subjects:  43%|████▎     | 231/532 [07:21<07:17,  1.46s/it]predicting train subjects:  44%|████▎     | 232/532 [07:22<07:07,  1.43s/it]predicting train subjects:  44%|████▍     | 233/532 [07:24<07:25,  1.49s/it]predicting train subjects:  44%|████▍     | 234/532 [07:25<07:29,  1.51s/it]predicting train subjects:  44%|████▍     | 235/532 [07:27<07:30,  1.52s/it]predicting train subjects:  44%|████▍     | 236/532 [07:28<07:36,  1.54s/it]predicting train subjects:  45%|████▍     | 237/532 [07:30<07:36,  1.55s/it]predicting train subjects:  45%|████▍     | 238/532 [07:31<07:37,  1.56s/it]predicting train subjects:  45%|████▍     | 239/532 [07:33<07:53,  1.61s/it]predicting train subjects:  45%|████▌     | 240/532 [07:35<08:03,  1.66s/it]predicting train subjects:  45%|████▌     | 241/532 [07:36<08:00,  1.65s/it]predicting train subjects:  45%|████▌     | 242/532 [07:38<07:59,  1.65s/it]predicting train subjects:  46%|████▌     | 243/532 [07:40<08:30,  1.77s/it]predicting train subjects:  46%|████▌     | 244/532 [07:42<08:27,  1.76s/it]predicting train subjects:  46%|████▌     | 245/532 [07:43<07:51,  1.64s/it]predicting train subjects:  46%|████▌     | 246/532 [07:45<07:25,  1.56s/it]predicting train subjects:  46%|████▋     | 247/532 [07:46<07:08,  1.50s/it]predicting train subjects:  47%|████▋     | 248/532 [07:47<06:57,  1.47s/it]predicting train subjects:  47%|████▋     | 249/532 [07:49<06:48,  1.44s/it]predicting train subjects:  47%|████▋     | 250/532 [07:50<06:42,  1.43s/it]predicting train subjects:  47%|████▋     | 251/532 [07:52<06:49,  1.46s/it]predicting train subjects:  47%|████▋     | 252/532 [07:53<06:45,  1.45s/it]predicting train subjects:  48%|████▊     | 253/532 [07:55<06:46,  1.46s/it]predicting train subjects:  48%|████▊     | 254/532 [07:56<06:43,  1.45s/it]predicting train subjects:  48%|████▊     | 255/532 [07:58<06:42,  1.45s/it]predicting train subjects:  48%|████▊     | 256/532 [07:59<06:39,  1.45s/it]predicting train subjects:  48%|████▊     | 257/532 [08:01<07:12,  1.57s/it]predicting train subjects:  48%|████▊     | 258/532 [08:03<07:34,  1.66s/it]predicting train subjects:  49%|████▊     | 259/532 [08:05<08:19,  1.83s/it]predicting train subjects:  49%|████▉     | 260/532 [08:07<08:27,  1.86s/it]predicting train subjects:  49%|████▉     | 261/532 [08:09<08:29,  1.88s/it]predicting train subjects:  49%|████▉     | 262/532 [08:11<08:31,  1.89s/it]predicting train subjects:  49%|████▉     | 263/532 [08:12<07:49,  1.75s/it]predicting train subjects:  50%|████▉     | 264/532 [08:14<07:21,  1.65s/it]predicting train subjects:  50%|████▉     | 265/532 [08:15<06:59,  1.57s/it]predicting train subjects:  50%|█████     | 266/532 [08:16<06:41,  1.51s/it]predicting train subjects:  50%|█████     | 267/532 [08:18<06:36,  1.49s/it]predicting train subjects:  50%|█████     | 268/532 [08:19<06:27,  1.47s/it]predicting train subjects:  51%|█████     | 269/532 [08:21<06:41,  1.53s/it]predicting train subjects:  51%|█████     | 270/532 [08:23<06:55,  1.58s/it]predicting train subjects:  51%|█████     | 271/532 [08:24<06:59,  1.61s/it]predicting train subjects:  51%|█████     | 272/532 [08:26<07:03,  1.63s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:28<07:09,  1.66s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:29<07:12,  1.68s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:31<07:42,  1.80s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:33<08:02,  1.89s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:36<08:20,  1.96s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:38<08:35,  2.03s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:40<08:41,  2.06s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:42<08:46,  2.09s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:44<08:38,  2.07s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:46<08:36,  2.06s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:48<08:28,  2.04s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:50<08:24,  2.03s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:52<08:23,  2.04s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:54<08:19,  2.03s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:56<07:39,  1.87s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:57<07:13,  1.78s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:59<06:55,  1.71s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:00<06:40,  1.65s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:02<06:31,  1.62s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:03<06:23,  1.60s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:05<06:35,  1.65s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:07<06:36,  1.67s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:09<06:36,  1.67s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:10<06:36,  1.68s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:12<06:40,  1.70s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:14<06:37,  1.70s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:15<06:10,  1.59s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:17<05:56,  1.54s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:18<05:43,  1.49s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:19<05:36,  1.46s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:21<05:28,  1.44s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:22<05:26,  1.43s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:24<06:22,  1.68s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:26<06:44,  1.79s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:28<07:01,  1.87s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:31<07:11,  1.93s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:33<07:21,  1.98s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:35<07:28,  2.02s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:38<08:20,  2.26s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:40<08:55,  2.44s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:43<09:20,  2.56s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:46<09:29,  2.61s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:49<09:45,  2.70s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:52<09:52,  2.74s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:53<08:35,  2.40s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:55<07:48,  2.19s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:57<07:05,  2.00s/it]predicting train subjects:  60%|██████    | 320/532 [09:58<06:32,  1.85s/it]predicting train subjects:  60%|██████    | 321/532 [10:00<06:13,  1.77s/it]predicting train subjects:  61%|██████    | 322/532 [10:01<06:02,  1.73s/it]predicting train subjects:  61%|██████    | 323/532 [10:04<06:37,  1.90s/it]predicting train subjects:  61%|██████    | 324/532 [10:06<06:55,  2.00s/it]predicting train subjects:  61%|██████    | 325/532 [10:08<07:08,  2.07s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:10<07:18,  2.13s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:13<07:23,  2.16s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:15<07:20,  2.16s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:16<06:53,  2.04s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:18<06:25,  1.91s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:20<06:06,  1.82s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:21<05:50,  1.75s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:23<05:45,  1.73s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:25<05:39,  1.71s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:27<05:53,  1.79s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:29<06:02,  1.85s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:31<06:05,  1.87s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:33<06:08,  1.90s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:34<06:07,  1.90s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:36<06:11,  1.93s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:38<05:40,  1.78s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:39<05:23,  1.70s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:41<05:07,  1.63s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:42<04:57,  1.58s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:44<04:53,  1.57s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:45<04:50,  1.56s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:47<04:53,  1.58s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:49<04:53,  1.59s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:50<05:01,  1.65s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:52<05:01,  1.66s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:54<05:01,  1.66s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:55<05:00,  1.67s/it]predicting train subjects:  66%|██████▋   | 353/532 [10:57<04:56,  1.66s/it]predicting train subjects:  67%|██████▋   | 354/532 [10:59<04:54,  1.65s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:00<04:52,  1.65s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:02<04:50,  1.65s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:04<04:52,  1.67s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:05<04:50,  1.67s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:07<04:39,  1.62s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:08<04:30,  1.57s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:10<04:25,  1.55s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:11<04:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:13<04:14,  1.51s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:14<04:09,  1.49s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:16<04:04,  1.47s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:17<04:03,  1.46s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:19<04:00,  1.46s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:20<03:58,  1.46s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:21<03:57,  1.46s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:23<03:59,  1.48s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:25<04:26,  1.65s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:27<04:46,  1.79s/it]predicting train subjects:  70%|███████   | 373/532 [11:30<05:13,  1.97s/it]predicting train subjects:  70%|███████   | 374/532 [11:32<05:17,  2.01s/it]predicting train subjects:  70%|███████   | 375/532 [11:34<05:18,  2.03s/it]predicting train subjects:  71%|███████   | 376/532 [11:36<05:17,  2.04s/it]predicting train subjects:  71%|███████   | 377/532 [11:37<04:56,  1.91s/it]predicting train subjects:  71%|███████   | 378/532 [11:39<04:42,  1.83s/it]predicting train subjects:  71%|███████   | 379/532 [11:41<04:32,  1.78s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:42<04:24,  1.74s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:44<04:20,  1.73s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:46<04:15,  1.70s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:48<04:19,  1.74s/it]predicting train subjects:  72%|███████▏  | 384/532 [11:49<04:19,  1.75s/it]predicting train subjects:  72%|███████▏  | 385/532 [11:51<04:19,  1.77s/it]predicting train subjects:  73%|███████▎  | 386/532 [11:53<04:21,  1.79s/it]predicting train subjects:  73%|███████▎  | 387/532 [11:55<04:19,  1.79s/it]predicting train subjects:  73%|███████▎  | 388/532 [11:56<04:14,  1.77s/it]predicting train subjects:  73%|███████▎  | 389/532 [11:58<04:16,  1.80s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:00<04:15,  1.80s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:02<04:11,  1.79s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:04<04:11,  1.79s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:06<04:09,  1.79s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:07<04:07,  1.79s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:09<04:05,  1.80s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:11<04:03,  1.79s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:13<04:02,  1.80s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:14<03:57,  1.77s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:16<03:54,  1.76s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:18<03:52,  1.76s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:20<03:58,  1.82s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:22<03:59,  1.84s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:24<04:05,  1.90s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:26<04:04,  1.91s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:28<04:02,  1.91s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:30<04:00,  1.91s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:31<03:53,  1.87s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:33<03:44,  1.81s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:35<03:38,  1.77s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:36<03:32,  1.75s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:38<03:30,  1.74s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:40<03:26,  1.72s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:41<03:19,  1.68s/it]predicting train subjects:  78%|███████▊  | 414/532 [12:43<03:15,  1.66s/it]predicting train subjects:  78%|███████▊  | 415/532 [12:44<03:09,  1.62s/it]predicting train subjects:  78%|███████▊  | 416/532 [12:46<03:05,  1.60s/it]predicting train subjects:  78%|███████▊  | 417/532 [12:48<03:03,  1.59s/it]predicting train subjects:  79%|███████▊  | 418/532 [12:49<03:00,  1.59s/it]predicting train subjects:  79%|███████▉  | 419/532 [12:51<03:04,  1.64s/it]predicting train subjects:  79%|███████▉  | 420/532 [12:53<03:08,  1.68s/it]predicting train subjects:  79%|███████▉  | 421/532 [12:55<03:14,  1.75s/it]predicting train subjects:  79%|███████▉  | 422/532 [12:57<03:16,  1.79s/it]predicting train subjects:  80%|███████▉  | 423/532 [12:58<03:17,  1.81s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:00<03:13,  1.80s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:02<03:12,  1.80s/it]predicting train subjects:  80%|████████  | 426/532 [13:04<03:14,  1.83s/it]predicting train subjects:  80%|████████  | 427/532 [13:06<03:11,  1.82s/it]predicting train subjects:  80%|████████  | 428/532 [13:07<03:08,  1.81s/it]predicting train subjects:  81%|████████  | 429/532 [13:09<03:09,  1.84s/it]predicting train subjects:  81%|████████  | 430/532 [13:11<03:06,  1.83s/it]predicting train subjects:  81%|████████  | 431/532 [13:13<03:09,  1.87s/it]predicting train subjects:  81%|████████  | 432/532 [13:15<03:10,  1.91s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:17<03:12,  1.94s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:19<03:12,  1.96s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:21<03:12,  1.99s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:23<03:10,  1.99s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:25<02:54,  1.84s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:26<02:42,  1.73s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:28<02:32,  1.64s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:29<02:24,  1.57s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:30<02:19,  1.53s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:32<02:14,  1.50s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:33<02:10,  1.47s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:35<02:08,  1.46s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:36<02:05,  1.44s/it]predicting train subjects:  84%|████████▍ | 446/532 [13:38<02:03,  1.44s/it]predicting train subjects:  84%|████████▍ | 447/532 [13:39<02:01,  1.43s/it]predicting train subjects:  84%|████████▍ | 448/532 [13:40<01:59,  1.42s/it]predicting train subjects:  84%|████████▍ | 449/532 [13:42<02:00,  1.45s/it]predicting train subjects:  85%|████████▍ | 450/532 [13:43<02:00,  1.47s/it]predicting train subjects:  85%|████████▍ | 451/532 [13:45<01:58,  1.47s/it]predicting train subjects:  85%|████████▍ | 452/532 [13:46<01:59,  1.50s/it]predicting train subjects:  85%|████████▌ | 453/532 [13:48<02:01,  1.53s/it]predicting train subjects:  85%|████████▌ | 454/532 [13:50<02:01,  1.56s/it]predicting train subjects:  86%|████████▌ | 455/532 [13:52<02:07,  1.66s/it]predicting train subjects:  86%|████████▌ | 456/532 [13:53<02:08,  1.69s/it]predicting train subjects:  86%|████████▌ | 457/532 [13:55<02:10,  1.74s/it]predicting train subjects:  86%|████████▌ | 458/532 [13:57<02:11,  1.78s/it]predicting train subjects:  86%|████████▋ | 459/532 [13:59<02:08,  1.77s/it]predicting train subjects:  86%|████████▋ | 460/532 [14:01<02:08,  1.78s/it]predicting train subjects:  87%|████████▋ | 461/532 [14:03<02:11,  1.86s/it]predicting train subjects:  87%|████████▋ | 462/532 [14:05<02:13,  1.91s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:07<02:15,  1.96s/it]predicting train subjects:  87%|████████▋ | 464/532 [14:09<02:15,  1.99s/it]predicting train subjects:  87%|████████▋ | 465/532 [14:11<02:14,  2.01s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:13<02:13,  2.03s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:15<02:04,  1.91s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:16<01:57,  1.83s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:18<01:51,  1.77s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:19<01:47,  1.74s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:21<01:44,  1.71s/it]predicting train subjects:  89%|████████▊ | 472/532 [14:23<01:40,  1.68s/it]predicting train subjects:  89%|████████▉ | 473/532 [14:25<01:41,  1.72s/it]predicting train subjects:  89%|████████▉ | 474/532 [14:26<01:42,  1.76s/it]predicting train subjects:  89%|████████▉ | 475/532 [14:28<01:41,  1.78s/it]predicting train subjects:  89%|████████▉ | 476/532 [14:30<01:40,  1.79s/it]predicting train subjects:  90%|████████▉ | 477/532 [14:32<01:39,  1.81s/it]predicting train subjects:  90%|████████▉ | 478/532 [14:34<01:38,  1.82s/it]predicting train subjects:  90%|█████████ | 479/532 [14:35<01:32,  1.74s/it]predicting train subjects:  90%|█████████ | 480/532 [14:37<01:27,  1.68s/it]predicting train subjects:  90%|█████████ | 481/532 [14:38<01:23,  1.65s/it]predicting train subjects:  91%|█████████ | 482/532 [14:40<01:20,  1.61s/it]predicting train subjects:  91%|█████████ | 483/532 [14:41<01:18,  1.59s/it]predicting train subjects:  91%|█████████ | 484/532 [14:43<01:15,  1.57s/it]predicting train subjects:  91%|█████████ | 485/532 [14:45<01:18,  1.68s/it]predicting train subjects:  91%|█████████▏| 486/532 [14:47<01:21,  1.77s/it]predicting train subjects:  92%|█████████▏| 487/532 [14:49<01:23,  1.86s/it]predicting train subjects:  92%|█████████▏| 488/532 [14:51<01:23,  1.90s/it]predicting train subjects:  92%|█████████▏| 489/532 [14:53<01:22,  1.93s/it]predicting train subjects:  92%|█████████▏| 490/532 [14:55<01:22,  1.95s/it]predicting train subjects:  92%|█████████▏| 491/532 [14:57<01:16,  1.86s/it]predicting train subjects:  92%|█████████▏| 492/532 [14:58<01:12,  1.80s/it]predicting train subjects:  93%|█████████▎| 493/532 [15:00<01:08,  1.76s/it]predicting train subjects:  93%|█████████▎| 494/532 [15:02<01:12,  1.91s/it]predicting train subjects:  93%|█████████▎| 495/532 [15:04<01:08,  1.86s/it]predicting train subjects:  93%|█████████▎| 496/532 [15:06<01:04,  1.78s/it]predicting train subjects:  93%|█████████▎| 497/532 [15:07<01:01,  1.75s/it]predicting train subjects:  94%|█████████▎| 498/532 [15:09<00:58,  1.72s/it]predicting train subjects:  94%|█████████▍| 499/532 [15:11<00:56,  1.73s/it]predicting train subjects:  94%|█████████▍| 500/532 [15:12<00:55,  1.72s/it]predicting train subjects:  94%|█████████▍| 501/532 [15:14<00:54,  1.75s/it]predicting train subjects:  94%|█████████▍| 502/532 [15:16<00:52,  1.75s/it]predicting train subjects:  95%|█████████▍| 503/532 [15:17<00:49,  1.71s/it]predicting train subjects:  95%|█████████▍| 504/532 [15:19<00:46,  1.67s/it]predicting train subjects:  95%|█████████▍| 505/532 [15:21<00:44,  1.64s/it]predicting train subjects:  95%|█████████▌| 506/532 [15:22<00:43,  1.66s/it]predicting train subjects:  95%|█████████▌| 507/532 [15:24<00:40,  1.64s/it]predicting train subjects:  95%|█████████▌| 508/532 [15:26<00:39,  1.63s/it]predicting train subjects:  96%|█████████▌| 509/532 [15:28<00:40,  1.75s/it]predicting train subjects:  96%|█████████▌| 510/532 [15:30<00:40,  1.83s/it]predicting train subjects:  96%|█████████▌| 511/532 [15:32<00:39,  1.87s/it]predicting train subjects:  96%|█████████▌| 512/532 [15:34<00:37,  1.90s/it]predicting train subjects:  96%|█████████▋| 513/532 [15:35<00:36,  1.90s/it]predicting train subjects:  97%|█████████▋| 514/532 [15:37<00:34,  1.91s/it]predicting train subjects:  97%|█████████▋| 515/532 [15:39<00:31,  1.83s/it]predicting train subjects:  97%|█████████▋| 516/532 [15:41<00:28,  1.77s/it]predicting train subjects:  97%|█████████▋| 517/532 [15:42<00:26,  1.74s/it]predicting train subjects:  97%|█████████▋| 518/532 [15:44<00:23,  1.71s/it]predicting train subjects:  98%|█████████▊| 519/532 [15:46<00:21,  1.69s/it]predicting train subjects:  98%|█████████▊| 520/532 [15:47<00:20,  1.67s/it]predicting train subjects:  98%|█████████▊| 521/532 [15:49<00:18,  1.72s/it]predicting train subjects:  98%|█████████▊| 522/532 [15:51<00:17,  1.76s/it]predicting train subjects:  98%|█████████▊| 523/532 [15:53<00:16,  1.86s/it]predicting train subjects:  98%|█████████▊| 524/532 [15:55<00:14,  1.87s/it]predicting train subjects:  99%|█████████▊| 525/532 [15:57<00:13,  1.87s/it]predicting train subjects:  99%|█████████▉| 526/532 [15:59<00:11,  1.84s/it]predicting train subjects:  99%|█████████▉| 527/532 [16:00<00:08,  1.78s/it]predicting train subjects:  99%|█████████▉| 528/532 [16:02<00:06,  1.72s/it]predicting train subjects:  99%|█████████▉| 529/532 [16:03<00:04,  1.66s/it]predicting train subjects: 100%|█████████▉| 530/532 [16:05<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 531/532 [16:06<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 532/532 [16:08<00:00,  1.63s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1’: File exists

Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<13:03,  1.48s/it]Loading train:   0%|          | 2/532 [00:02<11:32,  1.31s/it]Loading train:   1%|          | 3/532 [00:03<11:13,  1.27s/it]Loading train:   1%|          | 4/532 [00:04<10:25,  1.18s/it]Loading train:   1%|          | 5/532 [00:05<09:58,  1.14s/it]Loading train:   1%|          | 6/532 [00:06<09:26,  1.08s/it]Loading train:   1%|▏         | 7/532 [00:07<09:01,  1.03s/it]Loading train:   2%|▏         | 8/532 [00:08<08:41,  1.00it/s]Loading train:   2%|▏         | 9/532 [00:09<09:54,  1.14s/it]Loading train:   2%|▏         | 10/532 [00:10<09:00,  1.04s/it]Loading train:   2%|▏         | 11/532 [00:11<08:28,  1.03it/s]Loading train:   2%|▏         | 12/532 [00:12<09:01,  1.04s/it]Loading train:   2%|▏         | 13/532 [00:13<08:16,  1.05it/s]Loading train:   3%|▎         | 14/532 [00:14<07:54,  1.09it/s]Loading train:   3%|▎         | 15/532 [00:15<07:51,  1.10it/s]Loading train:   3%|▎         | 16/532 [00:16<07:59,  1.08it/s]Loading train:   3%|▎         | 17/532 [00:17<07:54,  1.09it/s]Loading train:   3%|▎         | 18/532 [00:18<08:09,  1.05it/s]Loading train:   4%|▎         | 19/532 [00:18<07:40,  1.11it/s]Loading train:   4%|▍         | 20/532 [00:19<07:48,  1.09it/s]Loading train:   4%|▍         | 21/532 [00:20<08:14,  1.03it/s]Loading train:   4%|▍         | 22/532 [00:21<08:07,  1.05it/s]Loading train:   4%|▍         | 23/532 [00:22<08:17,  1.02it/s]Loading train:   5%|▍         | 24/532 [00:23<07:44,  1.09it/s]Loading train:   5%|▍         | 25/532 [00:24<08:29,  1.01s/it]Loading train:   5%|▍         | 26/532 [00:25<08:20,  1.01it/s]Loading train:   5%|▌         | 27/532 [00:26<08:53,  1.06s/it]Loading train:   5%|▌         | 28/532 [00:27<08:43,  1.04s/it]Loading train:   5%|▌         | 29/532 [00:29<08:50,  1.06s/it]Loading train:   6%|▌         | 30/532 [00:29<08:18,  1.01it/s]Loading train:   6%|▌         | 31/532 [00:30<07:54,  1.05it/s]Loading train:   6%|▌         | 32/532 [00:31<07:40,  1.09it/s]Loading train:   6%|▌         | 33/532 [00:32<07:28,  1.11it/s]Loading train:   6%|▋         | 34/532 [00:33<08:03,  1.03it/s]Loading train:   7%|▋         | 35/532 [00:34<07:48,  1.06it/s]Loading train:   7%|▋         | 36/532 [00:35<07:56,  1.04it/s]Loading train:   7%|▋         | 37/532 [00:36<08:02,  1.03it/s]Loading train:   7%|▋         | 38/532 [00:37<08:16,  1.01s/it]Loading train:   7%|▋         | 39/532 [00:38<08:04,  1.02it/s]Loading train:   8%|▊         | 40/532 [00:39<07:52,  1.04it/s]Loading train:   8%|▊         | 41/532 [00:40<08:08,  1.00it/s]Loading train:   8%|▊         | 42/532 [00:41<08:16,  1.01s/it]Loading train:   8%|▊         | 43/532 [00:42<07:43,  1.06it/s]Loading train:   8%|▊         | 44/532 [00:43<07:08,  1.14it/s]Loading train:   8%|▊         | 45/532 [00:43<07:19,  1.11it/s]Loading train:   9%|▊         | 46/532 [00:45<07:36,  1.06it/s]Loading train:   9%|▉         | 47/532 [00:46<08:06,  1.00s/it]Loading train:   9%|▉         | 48/532 [00:47<08:29,  1.05s/it]Loading train:   9%|▉         | 49/532 [00:48<08:01,  1.00it/s]Loading train:   9%|▉         | 50/532 [00:49<08:15,  1.03s/it]Loading train:  10%|▉         | 51/532 [00:50<07:54,  1.01it/s]Loading train:  10%|▉         | 52/532 [00:51<07:52,  1.02it/s]Loading train:  10%|▉         | 53/532 [00:51<07:28,  1.07it/s]Loading train:  10%|█         | 54/532 [00:53<07:50,  1.01it/s]Loading train:  10%|█         | 55/532 [00:54<07:57,  1.00s/it]Loading train:  11%|█         | 56/532 [00:55<07:43,  1.03it/s]Loading train:  11%|█         | 57/532 [00:55<07:37,  1.04it/s]Loading train:  11%|█         | 58/532 [00:57<07:46,  1.02it/s]Loading train:  11%|█         | 59/532 [00:58<08:00,  1.02s/it]Loading train:  11%|█▏        | 60/532 [00:58<07:32,  1.04it/s]Loading train:  11%|█▏        | 61/532 [00:59<07:12,  1.09it/s]Loading train:  12%|█▏        | 62/532 [01:00<07:34,  1.03it/s]Loading train:  12%|█▏        | 63/532 [01:01<07:54,  1.01s/it]Loading train:  12%|█▏        | 64/532 [01:02<07:32,  1.03it/s]Loading train:  12%|█▏        | 65/532 [01:03<07:29,  1.04it/s]Loading train:  12%|█▏        | 66/532 [01:05<08:10,  1.05s/it]Loading train:  13%|█▎        | 67/532 [01:06<08:35,  1.11s/it]Loading train:  13%|█▎        | 68/532 [01:07<08:03,  1.04s/it]Loading train:  13%|█▎        | 69/532 [01:08<07:36,  1.02it/s]Loading train:  13%|█▎        | 70/532 [01:08<07:00,  1.10it/s]Loading train:  13%|█▎        | 71/532 [01:09<06:50,  1.12it/s]Loading train:  14%|█▎        | 72/532 [01:10<06:37,  1.16it/s]Loading train:  14%|█▎        | 73/532 [01:11<06:53,  1.11it/s]Loading train:  14%|█▍        | 74/532 [01:12<07:38,  1.00s/it]Loading train:  14%|█▍        | 75/532 [01:14<08:41,  1.14s/it]Loading train:  14%|█▍        | 76/532 [01:15<08:34,  1.13s/it]Loading train:  14%|█▍        | 77/532 [01:16<08:08,  1.07s/it]Loading train:  15%|█▍        | 78/532 [01:17<07:41,  1.02s/it]Loading train:  15%|█▍        | 79/532 [01:17<07:23,  1.02it/s]Loading train:  15%|█▌        | 80/532 [01:18<07:14,  1.04it/s]Loading train:  15%|█▌        | 81/532 [01:19<07:05,  1.06it/s]Loading train:  15%|█▌        | 82/532 [01:20<06:56,  1.08it/s]Loading train:  16%|█▌        | 83/532 [01:21<06:35,  1.14it/s]Loading train:  16%|█▌        | 84/532 [01:22<06:27,  1.16it/s]Loading train:  16%|█▌        | 85/532 [01:23<06:18,  1.18it/s]Loading train:  16%|█▌        | 86/532 [01:23<06:08,  1.21it/s]Loading train:  16%|█▋        | 87/532 [01:24<05:59,  1.24it/s]Loading train:  17%|█▋        | 88/532 [01:25<05:44,  1.29it/s]Loading train:  17%|█▋        | 89/532 [01:26<06:01,  1.23it/s]Loading train:  17%|█▋        | 90/532 [01:26<06:02,  1.22it/s]Loading train:  17%|█▋        | 91/532 [01:27<06:07,  1.20it/s]Loading train:  17%|█▋        | 92/532 [01:28<06:04,  1.21it/s]Loading train:  17%|█▋        | 93/532 [01:29<06:03,  1.21it/s]Loading train:  18%|█▊        | 94/532 [01:30<06:01,  1.21it/s]Loading train:  18%|█▊        | 95/532 [01:31<06:38,  1.10it/s]Loading train:  18%|█▊        | 96/532 [01:32<06:53,  1.05it/s]Loading train:  18%|█▊        | 97/532 [01:33<07:05,  1.02it/s]Loading train:  18%|█▊        | 98/532 [01:34<07:05,  1.02it/s]Loading train:  19%|█▊        | 99/532 [01:35<07:13,  1.00s/it]Loading train:  19%|█▉        | 100/532 [01:36<07:17,  1.01s/it]Loading train:  19%|█▉        | 101/532 [01:37<07:02,  1.02it/s]Loading train:  19%|█▉        | 102/532 [01:38<06:28,  1.11it/s]Loading train:  19%|█▉        | 103/532 [01:39<06:13,  1.15it/s]Loading train:  20%|█▉        | 104/532 [01:39<05:54,  1.21it/s]Loading train:  20%|█▉        | 105/532 [01:40<05:38,  1.26it/s]Loading train:  20%|█▉        | 106/532 [01:41<05:28,  1.30it/s]Loading train:  20%|██        | 107/532 [01:41<05:24,  1.31it/s]Loading train:  20%|██        | 108/532 [01:42<05:18,  1.33it/s]Loading train:  20%|██        | 109/532 [01:43<05:16,  1.34it/s]Loading train:  21%|██        | 110/532 [01:44<05:13,  1.35it/s]Loading train:  21%|██        | 111/532 [01:44<05:10,  1.36it/s]Loading train:  21%|██        | 112/532 [01:45<05:18,  1.32it/s]Loading train:  21%|██        | 113/532 [01:46<05:45,  1.21it/s]Loading train:  21%|██▏       | 114/532 [01:47<05:49,  1.19it/s]Loading train:  22%|██▏       | 115/532 [01:48<05:49,  1.19it/s]Loading train:  22%|██▏       | 116/532 [01:49<05:54,  1.17it/s]Loading train:  22%|██▏       | 117/532 [01:50<06:03,  1.14it/s]Loading train:  22%|██▏       | 118/532 [01:51<06:04,  1.14it/s]Loading train:  22%|██▏       | 119/532 [01:52<06:32,  1.05it/s]Loading train:  23%|██▎       | 120/532 [01:53<06:26,  1.07it/s]Loading train:  23%|██▎       | 121/532 [01:54<06:28,  1.06it/s]Loading train:  23%|██▎       | 122/532 [01:54<06:22,  1.07it/s]Loading train:  23%|██▎       | 123/532 [01:55<06:22,  1.07it/s]Loading train:  23%|██▎       | 124/532 [01:56<06:16,  1.08it/s]Loading train:  23%|██▎       | 125/532 [01:57<06:47,  1.00s/it]Loading train:  24%|██▎       | 126/532 [01:58<06:33,  1.03it/s]Loading train:  24%|██▍       | 127/532 [01:59<06:21,  1.06it/s]Loading train:  24%|██▍       | 128/532 [02:00<06:16,  1.07it/s]Loading train:  24%|██▍       | 129/532 [02:01<06:13,  1.08it/s]Loading train:  24%|██▍       | 130/532 [02:02<06:12,  1.08it/s]Loading train:  25%|██▍       | 131/532 [02:03<06:31,  1.03it/s]Loading train:  25%|██▍       | 132/532 [02:04<06:52,  1.03s/it]Loading train:  25%|██▌       | 133/532 [02:05<07:03,  1.06s/it]Loading train:  25%|██▌       | 134/532 [02:06<07:06,  1.07s/it]Loading train:  25%|██▌       | 135/532 [02:08<07:04,  1.07s/it]Loading train:  26%|██▌       | 136/532 [02:09<07:04,  1.07s/it]Loading train:  26%|██▌       | 137/532 [02:10<07:20,  1.11s/it]Loading train:  26%|██▌       | 138/532 [02:11<07:18,  1.11s/it]Loading train:  26%|██▌       | 139/532 [02:12<07:26,  1.14s/it]Loading train:  26%|██▋       | 140/532 [02:13<07:29,  1.15s/it]Loading train:  27%|██▋       | 141/532 [02:15<07:38,  1.17s/it]Loading train:  27%|██▋       | 142/532 [02:16<07:39,  1.18s/it]Loading train:  27%|██▋       | 143/532 [02:17<07:11,  1.11s/it]Loading train:  27%|██▋       | 144/532 [02:18<06:43,  1.04s/it]Loading train:  27%|██▋       | 145/532 [02:18<06:23,  1.01it/s]Loading train:  27%|██▋       | 146/532 [02:19<05:58,  1.08it/s]Loading train:  28%|██▊       | 147/532 [02:20<05:39,  1.13it/s]Loading train:  28%|██▊       | 148/532 [02:21<05:41,  1.12it/s]Loading train:  28%|██▊       | 149/532 [02:22<06:10,  1.03it/s]Loading train:  28%|██▊       | 150/532 [02:23<06:01,  1.06it/s]Loading train:  28%|██▊       | 151/532 [02:24<05:42,  1.11it/s]Loading train:  29%|██▊       | 152/532 [02:25<05:33,  1.14it/s]Loading train:  29%|██▉       | 153/532 [02:25<05:35,  1.13it/s]Loading train:  29%|██▉       | 154/532 [02:26<05:22,  1.17it/s]Loading train:  29%|██▉       | 155/532 [02:27<06:03,  1.04it/s]Loading train:  29%|██▉       | 156/532 [02:29<06:35,  1.05s/it]Loading train:  30%|██▉       | 157/532 [02:30<06:42,  1.07s/it]Loading train:  30%|██▉       | 158/532 [02:31<06:54,  1.11s/it]Loading train:  30%|██▉       | 159/532 [02:32<07:03,  1.14s/it]Loading train:  30%|███       | 160/532 [02:33<06:59,  1.13s/it]Loading train:  30%|███       | 161/532 [02:34<06:35,  1.07s/it]Loading train:  30%|███       | 162/532 [02:35<06:12,  1.01s/it]Loading train:  31%|███       | 163/532 [02:36<05:55,  1.04it/s]Loading train:  31%|███       | 164/532 [02:37<05:36,  1.09it/s]Loading train:  31%|███       | 165/532 [02:38<05:21,  1.14it/s]Loading train:  31%|███       | 166/532 [02:38<05:13,  1.17it/s]Loading train:  31%|███▏      | 167/532 [02:39<05:25,  1.12it/s]Loading train:  32%|███▏      | 168/532 [02:40<05:29,  1.10it/s]Loading train:  32%|███▏      | 169/532 [02:41<05:38,  1.07it/s]Loading train:  32%|███▏      | 170/532 [02:42<05:45,  1.05it/s]Loading train:  32%|███▏      | 171/532 [02:43<05:43,  1.05it/s]Loading train:  32%|███▏      | 172/532 [02:44<05:39,  1.06it/s]Loading train:  33%|███▎      | 173/532 [02:45<05:33,  1.08it/s]Loading train:  33%|███▎      | 174/532 [02:46<05:20,  1.12it/s]Loading train:  33%|███▎      | 175/532 [02:47<05:15,  1.13it/s]Loading train:  33%|███▎      | 176/532 [02:48<05:13,  1.13it/s]Loading train:  33%|███▎      | 177/532 [02:48<05:09,  1.15it/s]Loading train:  33%|███▎      | 178/532 [02:49<05:00,  1.18it/s]Loading train:  34%|███▎      | 179/532 [02:50<05:03,  1.16it/s]Loading train:  34%|███▍      | 180/532 [02:51<04:54,  1.19it/s]Loading train:  34%|███▍      | 181/532 [02:52<04:47,  1.22it/s]Loading train:  34%|███▍      | 182/532 [02:52<04:43,  1.24it/s]Loading train:  34%|███▍      | 183/532 [02:53<04:41,  1.24it/s]Loading train:  35%|███▍      | 184/532 [02:54<04:48,  1.21it/s]Loading train:  35%|███▍      | 185/532 [02:55<04:47,  1.21it/s]Loading train:  35%|███▍      | 186/532 [02:56<04:42,  1.22it/s]Loading train:  35%|███▌      | 187/532 [02:57<04:41,  1.23it/s]Loading train:  35%|███▌      | 188/532 [02:57<04:41,  1.22it/s]Loading train:  36%|███▌      | 189/532 [02:58<04:40,  1.22it/s]Loading train:  36%|███▌      | 190/532 [02:59<04:52,  1.17it/s]Loading train:  36%|███▌      | 191/532 [03:00<05:28,  1.04it/s]Loading train:  36%|███▌      | 192/532 [03:02<05:45,  1.02s/it]Loading train:  36%|███▋      | 193/532 [03:03<05:59,  1.06s/it]Loading train:  36%|███▋      | 194/532 [03:04<06:03,  1.08s/it]Loading train:  37%|███▋      | 195/532 [03:05<06:07,  1.09s/it]Loading train:  37%|███▋      | 196/532 [03:06<06:16,  1.12s/it]Loading train:  37%|███▋      | 197/532 [03:07<06:04,  1.09s/it]Loading train:  37%|███▋      | 198/532 [03:08<06:06,  1.10s/it]Loading train:  37%|███▋      | 199/532 [03:09<06:00,  1.08s/it]Loading train:  38%|███▊      | 200/532 [03:10<05:55,  1.07s/it]Loading train:  38%|███▊      | 201/532 [03:11<05:43,  1.04s/it]Loading train:  38%|███▊      | 202/532 [03:12<05:41,  1.03s/it]Loading train:  38%|███▊      | 203/532 [03:13<05:28,  1.00it/s]Loading train:  38%|███▊      | 204/532 [03:14<05:12,  1.05it/s]Loading train:  39%|███▊      | 205/532 [03:15<04:59,  1.09it/s]Loading train:  39%|███▊      | 206/532 [03:16<04:48,  1.13it/s]Loading train:  39%|███▉      | 207/532 [03:17<04:42,  1.15it/s]Loading train:  39%|███▉      | 208/532 [03:17<04:38,  1.16it/s]Loading train:  39%|███▉      | 209/532 [03:18<04:29,  1.20it/s]Loading train:  39%|███▉      | 210/532 [03:19<04:20,  1.24it/s]Loading train:  40%|███▉      | 211/532 [03:20<04:15,  1.25it/s]Loading train:  40%|███▉      | 212/532 [03:20<04:15,  1.25it/s]Loading train:  40%|████      | 213/532 [03:21<04:12,  1.26it/s]Loading train:  40%|████      | 214/532 [03:22<04:11,  1.27it/s]Loading train:  40%|████      | 215/532 [03:23<04:47,  1.10it/s]Loading train:  41%|████      | 216/532 [03:24<05:07,  1.03it/s]Loading train:  41%|████      | 217/532 [03:25<05:20,  1.02s/it]Loading train:  41%|████      | 218/532 [03:27<05:30,  1.05s/it]Loading train:  41%|████      | 219/532 [03:28<05:34,  1.07s/it]Loading train:  41%|████▏     | 220/532 [03:29<05:36,  1.08s/it]Loading train:  42%|████▏     | 221/532 [03:30<05:08,  1.01it/s]Loading train:  42%|████▏     | 222/532 [03:30<04:42,  1.10it/s]Loading train:  42%|████▏     | 223/532 [03:31<04:23,  1.17it/s]Loading train:  42%|████▏     | 224/532 [03:32<04:15,  1.20it/s]Loading train:  42%|████▏     | 225/532 [03:33<04:05,  1.25it/s]Loading train:  42%|████▏     | 226/532 [03:33<03:55,  1.30it/s]Loading train:  43%|████▎     | 227/532 [03:34<03:52,  1.31it/s]Loading train:  43%|████▎     | 228/532 [03:35<03:43,  1.36it/s]Loading train:  43%|████▎     | 229/532 [03:35<03:45,  1.34it/s]Loading train:  43%|████▎     | 230/532 [03:36<03:43,  1.35it/s]Loading train:  43%|████▎     | 231/532 [03:37<03:40,  1.36it/s]Loading train:  44%|████▎     | 232/532 [03:38<03:36,  1.39it/s]Loading train:  44%|████▍     | 233/532 [03:38<03:49,  1.30it/s]Loading train:  44%|████▍     | 234/532 [03:39<03:50,  1.30it/s]Loading train:  44%|████▍     | 235/532 [03:40<03:57,  1.25it/s]Loading train:  44%|████▍     | 236/532 [03:41<04:02,  1.22it/s]Loading train:  45%|████▍     | 237/532 [03:42<04:06,  1.19it/s]Loading train:  45%|████▍     | 238/532 [03:43<04:08,  1.18it/s]Loading train:  45%|████▍     | 239/532 [03:44<04:20,  1.12it/s]Loading train:  45%|████▌     | 240/532 [03:45<04:14,  1.15it/s]Loading train:  45%|████▌     | 241/532 [03:45<04:15,  1.14it/s]Loading train:  45%|████▌     | 242/532 [03:46<04:20,  1.11it/s]Loading train:  46%|████▌     | 243/532 [03:47<04:15,  1.13it/s]Loading train:  46%|████▌     | 244/532 [03:48<04:15,  1.13it/s]Loading train:  46%|████▌     | 245/532 [03:49<04:09,  1.15it/s]Loading train:  46%|████▌     | 246/532 [03:50<03:57,  1.21it/s]Loading train:  46%|████▋     | 247/532 [03:50<03:49,  1.24it/s]Loading train:  47%|████▋     | 248/532 [03:51<03:54,  1.21it/s]Loading train:  47%|████▋     | 249/532 [03:52<03:46,  1.25it/s]Loading train:  47%|████▋     | 250/532 [03:53<03:38,  1.29it/s]Loading train:  47%|████▋     | 251/532 [03:54<03:51,  1.21it/s]Loading train:  47%|████▋     | 252/532 [03:55<03:54,  1.20it/s]Loading train:  48%|████▊     | 253/532 [03:55<03:56,  1.18it/s]Loading train:  48%|████▊     | 254/532 [03:56<03:52,  1.20it/s]Loading train:  48%|████▊     | 255/532 [03:57<03:53,  1.19it/s]Loading train:  48%|████▊     | 256/532 [03:58<03:56,  1.17it/s]Loading train:  48%|████▊     | 257/532 [03:59<04:17,  1.07it/s]Loading train:  48%|████▊     | 258/532 [04:00<04:19,  1.06it/s]Loading train:  49%|████▊     | 259/532 [04:01<04:26,  1.03it/s]Loading train:  49%|████▉     | 260/532 [04:02<04:33,  1.01s/it]Loading train:  49%|████▉     | 261/532 [04:03<04:32,  1.01s/it]Loading train:  49%|████▉     | 262/532 [04:04<04:28,  1.01it/s]Loading train:  49%|████▉     | 263/532 [04:05<04:07,  1.09it/s]Loading train:  50%|████▉     | 264/532 [04:06<03:52,  1.15it/s]Loading train:  50%|████▉     | 265/532 [04:06<03:41,  1.20it/s]Loading train:  50%|█████     | 266/532 [04:07<03:29,  1.27it/s]Loading train:  50%|█████     | 267/532 [04:08<03:22,  1.31it/s]Loading train:  50%|█████     | 268/532 [04:09<03:16,  1.34it/s]Loading train:  51%|█████     | 269/532 [04:09<03:34,  1.23it/s]Loading train:  51%|█████     | 270/532 [04:10<03:39,  1.19it/s]Loading train:  51%|█████     | 271/532 [04:11<03:43,  1.17it/s]Loading train:  51%|█████     | 272/532 [04:12<03:45,  1.15it/s]Loading train:  51%|█████▏    | 273/532 [04:13<03:40,  1.18it/s]Loading train:  52%|█████▏    | 274/532 [04:14<03:44,  1.15it/s]Loading train:  52%|█████▏    | 275/532 [04:15<04:08,  1.04it/s]Loading train:  52%|█████▏    | 276/532 [04:16<04:18,  1.01s/it]Loading train:  52%|█████▏    | 277/532 [04:17<04:23,  1.03s/it]Loading train:  52%|█████▏    | 278/532 [04:18<04:25,  1.05s/it]Loading train:  52%|█████▏    | 279/532 [04:20<04:32,  1.08s/it]Loading train:  53%|█████▎    | 280/532 [04:21<04:36,  1.10s/it]Loading train:  53%|█████▎    | 281/532 [04:22<04:35,  1.10s/it]Loading train:  53%|█████▎    | 282/532 [04:23<04:35,  1.10s/it]Loading train:  53%|█████▎    | 283/532 [04:24<04:32,  1.09s/it]Loading train:  53%|█████▎    | 284/532 [04:25<04:29,  1.09s/it]Loading train:  54%|█████▎    | 285/532 [04:26<04:26,  1.08s/it]Loading train:  54%|█████▍    | 286/532 [04:27<04:23,  1.07s/it]Loading train:  54%|█████▍    | 287/532 [04:28<04:07,  1.01s/it]Loading train:  54%|█████▍    | 288/532 [04:29<03:56,  1.03it/s]Loading train:  54%|█████▍    | 289/532 [04:30<03:40,  1.10it/s]Loading train:  55%|█████▍    | 290/532 [04:30<03:33,  1.14it/s]Loading train:  55%|█████▍    | 291/532 [04:31<03:24,  1.18it/s]Loading train:  55%|█████▍    | 292/532 [04:32<03:20,  1.20it/s]Loading train:  55%|█████▌    | 293/532 [04:33<03:29,  1.14it/s]Loading train:  55%|█████▌    | 294/532 [04:34<03:30,  1.13it/s]Loading train:  55%|█████▌    | 295/532 [04:35<03:38,  1.09it/s]Loading train:  56%|█████▌    | 296/532 [04:36<03:35,  1.09it/s]Loading train:  56%|█████▌    | 297/532 [04:37<03:34,  1.10it/s]Loading train:  56%|█████▌    | 298/532 [04:38<03:32,  1.10it/s]Loading train:  56%|█████▌    | 299/532 [04:38<03:23,  1.15it/s]Loading train:  56%|█████▋    | 300/532 [04:39<03:13,  1.20it/s]Loading train:  57%|█████▋    | 301/532 [04:40<03:10,  1.21it/s]Loading train:  57%|█████▋    | 302/532 [04:41<03:08,  1.22it/s]Loading train:  57%|█████▋    | 303/532 [04:42<03:02,  1.26it/s]Loading train:  57%|█████▋    | 304/532 [04:42<03:05,  1.23it/s]Loading train:  57%|█████▋    | 305/532 [04:44<03:31,  1.07it/s]Loading train:  58%|█████▊    | 306/532 [04:45<03:45,  1.00it/s]Loading train:  58%|█████▊    | 307/532 [04:46<03:46,  1.01s/it]Loading train:  58%|█████▊    | 308/532 [04:47<03:49,  1.03s/it]Loading train:  58%|█████▊    | 309/532 [04:48<03:55,  1.06s/it]Loading train:  58%|█████▊    | 310/532 [04:49<03:59,  1.08s/it]Loading train:  58%|█████▊    | 311/532 [04:51<04:21,  1.18s/it]Loading train:  59%|█████▊    | 312/532 [04:52<04:45,  1.30s/it]Loading train:  59%|█████▉    | 313/532 [04:54<04:55,  1.35s/it]Loading train:  59%|█████▉    | 314/532 [04:55<05:02,  1.39s/it]Loading train:  59%|█████▉    | 315/532 [04:56<05:05,  1.41s/it]Loading train:  59%|█████▉    | 316/532 [04:58<05:10,  1.44s/it]Loading train:  60%|█████▉    | 317/532 [04:59<04:35,  1.28s/it]Loading train:  60%|█████▉    | 318/532 [05:00<04:02,  1.13s/it]Loading train:  60%|█████▉    | 319/532 [05:01<03:43,  1.05s/it]Loading train:  60%|██████    | 320/532 [05:01<03:27,  1.02it/s]Loading train:  60%|██████    | 321/532 [05:02<03:19,  1.06it/s]Loading train:  61%|██████    | 322/532 [05:03<03:09,  1.11it/s]Loading train:  61%|██████    | 323/532 [05:04<03:29,  1.00s/it]Loading train:  61%|██████    | 324/532 [05:05<03:38,  1.05s/it]Loading train:  61%|██████    | 325/532 [05:07<03:45,  1.09s/it]Loading train:  61%|██████▏   | 326/532 [05:08<03:50,  1.12s/it]Loading train:  61%|██████▏   | 327/532 [05:09<03:52,  1.13s/it]Loading train:  62%|██████▏   | 328/532 [05:10<03:58,  1.17s/it]Loading train:  62%|██████▏   | 329/532 [05:11<03:44,  1.11s/it]Loading train:  62%|██████▏   | 330/532 [05:12<03:31,  1.05s/it]Loading train:  62%|██████▏   | 331/532 [05:13<03:18,  1.01it/s]Loading train:  62%|██████▏   | 332/532 [05:14<03:08,  1.06it/s]Loading train:  63%|██████▎   | 333/532 [05:15<03:03,  1.08it/s]Loading train:  63%|██████▎   | 334/532 [05:15<02:57,  1.11it/s]Loading train:  63%|██████▎   | 335/532 [05:17<03:08,  1.05it/s]Loading train:  63%|██████▎   | 336/532 [05:18<03:12,  1.02it/s]Loading train:  63%|██████▎   | 337/532 [05:19<03:12,  1.01it/s]Loading train:  64%|██████▎   | 338/532 [05:20<03:11,  1.01it/s]Loading train:  64%|██████▎   | 339/532 [05:21<03:10,  1.01it/s]Loading train:  64%|██████▍   | 340/532 [05:22<03:13,  1.01s/it]Loading train:  64%|██████▍   | 341/532 [05:23<03:05,  1.03it/s]Loading train:  64%|██████▍   | 342/532 [05:23<02:55,  1.08it/s]Loading train:  64%|██████▍   | 343/532 [05:24<02:45,  1.14it/s]Loading train:  65%|██████▍   | 344/532 [05:25<02:35,  1.21it/s]Loading train:  65%|██████▍   | 345/532 [05:26<02:29,  1.25it/s]Loading train:  65%|██████▌   | 346/532 [05:26<02:31,  1.22it/s]Loading train:  65%|██████▌   | 347/532 [05:27<02:33,  1.21it/s]Loading train:  65%|██████▌   | 348/532 [05:28<02:34,  1.19it/s]Loading train:  66%|██████▌   | 349/532 [05:29<02:35,  1.18it/s]Loading train:  66%|██████▌   | 350/532 [05:30<02:32,  1.20it/s]Loading train:  66%|██████▌   | 351/532 [05:31<02:33,  1.18it/s]Loading train:  66%|██████▌   | 352/532 [05:31<02:27,  1.22it/s]Loading train:  66%|██████▋   | 353/532 [05:32<02:24,  1.23it/s]Loading train:  67%|██████▋   | 354/532 [05:33<02:24,  1.24it/s]Loading train:  67%|██████▋   | 355/532 [05:34<02:26,  1.21it/s]Loading train:  67%|██████▋   | 356/532 [05:35<02:23,  1.23it/s]Loading train:  67%|██████▋   | 357/532 [05:35<02:21,  1.23it/s]Loading train:  67%|██████▋   | 358/532 [05:36<02:21,  1.23it/s]Loading train:  67%|██████▋   | 359/532 [05:37<02:24,  1.20it/s]Loading train:  68%|██████▊   | 360/532 [05:38<02:19,  1.23it/s]Loading train:  68%|██████▊   | 361/532 [05:39<02:15,  1.26it/s]Loading train:  68%|██████▊   | 362/532 [05:39<02:14,  1.26it/s]Loading train:  68%|██████▊   | 363/532 [05:40<02:14,  1.26it/s]Loading train:  68%|██████▊   | 364/532 [05:41<02:14,  1.25it/s]Loading train:  69%|██████▊   | 365/532 [05:42<02:10,  1.28it/s]Loading train:  69%|██████▉   | 366/532 [05:43<02:05,  1.33it/s]Loading train:  69%|██████▉   | 367/532 [05:43<02:00,  1.37it/s]Loading train:  69%|██████▉   | 368/532 [05:44<02:00,  1.36it/s]Loading train:  69%|██████▉   | 369/532 [05:45<02:02,  1.34it/s]Loading train:  70%|██████▉   | 370/532 [05:45<01:58,  1.37it/s]Loading train:  70%|██████▉   | 371/532 [05:47<02:18,  1.17it/s]Loading train:  70%|██████▉   | 372/532 [05:48<02:29,  1.07it/s]Loading train:  70%|███████   | 373/532 [05:49<02:38,  1.00it/s]Loading train:  70%|███████   | 374/532 [05:50<02:42,  1.03s/it]Loading train:  70%|███████   | 375/532 [05:51<02:45,  1.06s/it]Loading train:  71%|███████   | 376/532 [05:52<02:50,  1.09s/it]Loading train:  71%|███████   | 377/532 [05:53<02:41,  1.04s/it]Loading train:  71%|███████   | 378/532 [05:54<02:34,  1.01s/it]Loading train:  71%|███████   | 379/532 [05:55<02:32,  1.00it/s]Loading train:  71%|███████▏  | 380/532 [05:56<02:26,  1.03it/s]Loading train:  72%|███████▏  | 381/532 [05:57<02:24,  1.05it/s]Loading train:  72%|███████▏  | 382/532 [05:58<02:21,  1.06it/s]Loading train:  72%|███████▏  | 383/532 [05:59<02:18,  1.08it/s]Loading train:  72%|███████▏  | 384/532 [06:00<02:13,  1.11it/s]Loading train:  72%|███████▏  | 385/532 [06:00<02:10,  1.12it/s]Loading train:  73%|███████▎  | 386/532 [06:01<02:09,  1.12it/s]Loading train:  73%|███████▎  | 387/532 [06:02<02:09,  1.12it/s]Loading train:  73%|███████▎  | 388/532 [06:03<02:07,  1.13it/s]Loading train:  73%|███████▎  | 389/532 [06:04<02:12,  1.08it/s]Loading train:  73%|███████▎  | 390/532 [06:05<02:12,  1.07it/s]Loading train:  73%|███████▎  | 391/532 [06:06<02:15,  1.04it/s]Loading train:  74%|███████▎  | 392/532 [06:07<02:15,  1.04it/s]Loading train:  74%|███████▍  | 393/532 [06:08<02:16,  1.02it/s]Loading train:  74%|███████▍  | 394/532 [06:09<02:15,  1.02it/s]Loading train:  74%|███████▍  | 395/532 [06:10<02:15,  1.01it/s]Loading train:  74%|███████▍  | 396/532 [06:11<02:17,  1.01s/it]Loading train:  75%|███████▍  | 397/532 [06:12<02:14,  1.00it/s]Loading train:  75%|███████▍  | 398/532 [06:13<02:14,  1.00s/it]Loading train:  75%|███████▌  | 399/532 [06:14<02:10,  1.02it/s]Loading train:  75%|███████▌  | 400/532 [06:15<02:08,  1.03it/s]Loading train:  75%|███████▌  | 401/532 [06:16<02:13,  1.02s/it]Loading train:  76%|███████▌  | 402/532 [06:17<02:12,  1.02s/it]Loading train:  76%|███████▌  | 403/532 [06:18<02:12,  1.03s/it]Loading train:  76%|███████▌  | 404/532 [06:19<02:11,  1.03s/it]Loading train:  76%|███████▌  | 405/532 [06:20<02:10,  1.03s/it]Loading train:  76%|███████▋  | 406/532 [06:21<02:08,  1.02s/it]Loading train:  77%|███████▋  | 407/532 [06:22<02:01,  1.03it/s]Loading train:  77%|███████▋  | 408/532 [06:23<01:55,  1.07it/s]Loading train:  77%|███████▋  | 409/532 [06:24<01:51,  1.11it/s]Loading train:  77%|███████▋  | 410/532 [06:25<01:46,  1.14it/s]Loading train:  77%|███████▋  | 411/532 [06:25<01:44,  1.15it/s]Loading train:  77%|███████▋  | 412/532 [06:26<01:42,  1.17it/s]Loading train:  78%|███████▊  | 413/532 [06:27<01:42,  1.16it/s]Loading train:  78%|███████▊  | 414/532 [06:28<01:45,  1.12it/s]Loading train:  78%|███████▊  | 415/532 [06:29<01:43,  1.13it/s]Loading train:  78%|███████▊  | 416/532 [06:30<01:42,  1.13it/s]Loading train:  78%|███████▊  | 417/532 [06:31<01:43,  1.12it/s]Loading train:  79%|███████▊  | 418/532 [06:32<01:41,  1.13it/s]Loading train:  79%|███████▉  | 419/532 [06:33<01:44,  1.08it/s]Loading train:  79%|███████▉  | 420/532 [06:34<01:45,  1.06it/s]Loading train:  79%|███████▉  | 421/532 [06:35<01:44,  1.06it/s]Loading train:  79%|███████▉  | 422/532 [06:36<01:46,  1.03it/s]Loading train:  80%|███████▉  | 423/532 [06:37<01:45,  1.04it/s]Loading train:  80%|███████▉  | 424/532 [06:37<01:44,  1.04it/s]Loading train:  80%|███████▉  | 425/532 [06:38<01:42,  1.05it/s]Loading train:  80%|████████  | 426/532 [06:39<01:41,  1.04it/s]Loading train:  80%|████████  | 427/532 [06:40<01:40,  1.04it/s]Loading train:  80%|████████  | 428/532 [06:41<01:38,  1.05it/s]Loading train:  81%|████████  | 429/532 [06:42<01:37,  1.06it/s]Loading train:  81%|████████  | 430/532 [06:43<01:37,  1.05it/s]Loading train:  81%|████████  | 431/532 [06:44<01:38,  1.02it/s]Loading train:  81%|████████  | 432/532 [06:45<01:40,  1.00s/it]Loading train:  81%|████████▏ | 433/532 [06:46<01:38,  1.01it/s]Loading train:  82%|████████▏ | 434/532 [06:47<01:38,  1.00s/it]Loading train:  82%|████████▏ | 435/532 [06:48<01:35,  1.02it/s]Loading train:  82%|████████▏ | 436/532 [06:49<01:35,  1.00it/s]Loading train:  82%|████████▏ | 437/532 [06:50<01:27,  1.09it/s]Loading train:  82%|████████▏ | 438/532 [06:51<01:20,  1.17it/s]Loading train:  83%|████████▎ | 439/532 [06:51<01:18,  1.18it/s]Loading train:  83%|████████▎ | 440/532 [06:52<01:14,  1.23it/s]Loading train:  83%|████████▎ | 441/532 [06:53<01:13,  1.24it/s]Loading train:  83%|████████▎ | 442/532 [06:54<01:13,  1.23it/s]Loading train:  83%|████████▎ | 443/532 [06:55<01:10,  1.26it/s]Loading train:  83%|████████▎ | 444/532 [06:55<01:08,  1.29it/s]Loading train:  84%|████████▎ | 445/532 [06:56<01:06,  1.31it/s]Loading train:  84%|████████▍ | 446/532 [06:57<01:03,  1.35it/s]Loading train:  84%|████████▍ | 447/532 [06:57<01:02,  1.36it/s]Loading train:  84%|████████▍ | 448/532 [06:58<01:01,  1.37it/s]Loading train:  84%|████████▍ | 449/532 [06:59<01:03,  1.31it/s]Loading train:  85%|████████▍ | 450/532 [07:00<01:04,  1.26it/s]Loading train:  85%|████████▍ | 451/532 [07:01<01:05,  1.24it/s]Loading train:  85%|████████▍ | 452/532 [07:02<01:05,  1.22it/s]Loading train:  85%|████████▌ | 453/532 [07:02<01:06,  1.19it/s]Loading train:  85%|████████▌ | 454/532 [07:03<01:03,  1.22it/s]Loading train:  86%|████████▌ | 455/532 [07:04<01:08,  1.13it/s]Loading train:  86%|████████▌ | 456/532 [07:05<01:06,  1.14it/s]Loading train:  86%|████████▌ | 457/532 [07:06<01:06,  1.14it/s]Loading train:  86%|████████▌ | 458/532 [07:07<01:07,  1.09it/s]Loading train:  86%|████████▋ | 459/532 [07:08<01:06,  1.10it/s]Loading train:  86%|████████▋ | 460/532 [07:09<01:04,  1.11it/s]Loading train:  87%|████████▋ | 461/532 [07:10<01:08,  1.04it/s]Loading train:  87%|████████▋ | 462/532 [07:11<01:11,  1.03s/it]Loading train:  87%|████████▋ | 463/532 [07:12<01:12,  1.05s/it]Loading train:  87%|████████▋ | 464/532 [07:13<01:12,  1.06s/it]Loading train:  87%|████████▋ | 465/532 [07:14<01:12,  1.09s/it]Loading train:  88%|████████▊ | 466/532 [07:16<01:12,  1.11s/it]Loading train:  88%|████████▊ | 467/532 [07:17<01:09,  1.06s/it]Loading train:  88%|████████▊ | 468/532 [07:17<01:03,  1.01it/s]Loading train:  88%|████████▊ | 469/532 [07:18<01:00,  1.04it/s]Loading train:  88%|████████▊ | 470/532 [07:19<00:59,  1.04it/s]Loading train:  89%|████████▊ | 471/532 [07:20<00:57,  1.06it/s]Loading train:  89%|████████▊ | 472/532 [07:21<00:56,  1.06it/s]Loading train:  89%|████████▉ | 473/532 [07:22<00:56,  1.04it/s]Loading train:  89%|████████▉ | 474/532 [07:23<00:55,  1.05it/s]Loading train:  89%|████████▉ | 475/532 [07:24<00:53,  1.06it/s]Loading train:  89%|████████▉ | 476/532 [07:25<00:53,  1.05it/s]Loading train:  90%|████████▉ | 477/532 [07:26<00:53,  1.03it/s]Loading train:  90%|████████▉ | 478/532 [07:27<00:53,  1.02it/s]Loading train:  90%|█████████ | 479/532 [07:28<00:49,  1.07it/s]Loading train:  90%|█████████ | 480/532 [07:29<00:46,  1.11it/s]Loading train:  90%|█████████ | 481/532 [07:29<00:44,  1.14it/s]Loading train:  91%|█████████ | 482/532 [07:30<00:41,  1.19it/s]Loading train:  91%|█████████ | 483/532 [07:31<00:39,  1.23it/s]Loading train:  91%|█████████ | 484/532 [07:32<00:39,  1.21it/s]Loading train:  91%|█████████ | 485/532 [07:33<00:43,  1.08it/s]Loading train:  91%|█████████▏| 486/532 [07:34<00:44,  1.03it/s]Loading train:  92%|█████████▏| 487/532 [07:35<00:44,  1.01it/s]Loading train:  92%|█████████▏| 488/532 [07:36<00:45,  1.03s/it]Loading train:  92%|█████████▏| 489/532 [07:37<00:43,  1.00s/it]Loading train:  92%|█████████▏| 490/532 [07:38<00:42,  1.01s/it]Loading train:  92%|█████████▏| 491/532 [07:39<00:39,  1.03it/s]Loading train:  92%|█████████▏| 492/532 [07:40<00:37,  1.06it/s]Loading train:  93%|█████████▎| 493/532 [07:41<00:35,  1.10it/s]Loading train:  93%|█████████▎| 494/532 [07:42<00:34,  1.11it/s]Loading train:  93%|█████████▎| 495/532 [07:42<00:32,  1.12it/s]Loading train:  93%|█████████▎| 496/532 [07:43<00:31,  1.13it/s]Loading train:  93%|█████████▎| 497/532 [07:44<00:31,  1.10it/s]Loading train:  94%|█████████▎| 498/532 [07:45<00:31,  1.07it/s]Loading train:  94%|█████████▍| 499/532 [07:46<00:31,  1.04it/s]Loading train:  94%|█████████▍| 500/532 [07:47<00:30,  1.05it/s]Loading train:  94%|█████████▍| 501/532 [07:48<00:29,  1.04it/s]Loading train:  94%|█████████▍| 502/532 [07:49<00:29,  1.02it/s]Loading train:  95%|█████████▍| 503/532 [07:50<00:27,  1.06it/s]Loading train:  95%|█████████▍| 504/532 [07:51<00:25,  1.11it/s]Loading train:  95%|█████████▍| 505/532 [07:52<00:23,  1.16it/s]Loading train:  95%|█████████▌| 506/532 [07:52<00:21,  1.20it/s]Loading train:  95%|█████████▌| 507/532 [07:53<00:20,  1.21it/s]Loading train:  95%|█████████▌| 508/532 [07:54<00:20,  1.19it/s]Loading train:  96%|█████████▌| 509/532 [07:55<00:21,  1.08it/s]Loading train:  96%|█████████▌| 510/532 [07:56<00:21,  1.04it/s]Loading train:  96%|█████████▌| 511/532 [07:57<00:20,  1.01it/s]Loading train:  96%|█████████▌| 512/532 [07:58<00:19,  1.00it/s]Loading train:  96%|█████████▋| 513/532 [07:59<00:19,  1.01s/it]Loading train:  97%|█████████▋| 514/532 [08:00<00:18,  1.00s/it]Loading train:  97%|█████████▋| 515/532 [08:01<00:16,  1.03it/s]Loading train:  97%|█████████▋| 516/532 [08:02<00:14,  1.08it/s]Loading train:  97%|█████████▋| 517/532 [08:03<00:13,  1.09it/s]Loading train:  97%|█████████▋| 518/532 [08:04<00:12,  1.12it/s]Loading train:  98%|█████████▊| 519/532 [08:05<00:11,  1.14it/s]Loading train:  98%|█████████▊| 520/532 [08:05<00:10,  1.18it/s]Loading train:  98%|█████████▊| 521/532 [08:06<00:09,  1.13it/s]Loading train:  98%|█████████▊| 522/532 [08:07<00:09,  1.11it/s]Loading train:  98%|█████████▊| 523/532 [08:08<00:08,  1.12it/s]Loading train:  98%|█████████▊| 524/532 [08:09<00:07,  1.11it/s]Loading train:  99%|█████████▊| 525/532 [08:10<00:06,  1.12it/s]Loading train:  99%|█████████▉| 526/532 [08:11<00:05,  1.11it/s]Loading train:  99%|█████████▉| 527/532 [08:12<00:04,  1.10it/s]Loading train:  99%|█████████▉| 528/532 [08:13<00:03,  1.14it/s]Loading train:  99%|█████████▉| 529/532 [08:14<00:03,  1.03s/it]Loading train: 100%|█████████▉| 530/532 [08:15<00:01,  1.01it/s]Loading train: 100%|█████████▉| 531/532 [08:16<00:00,  1.07it/s]Loading train: 100%|██████████| 532/532 [08:17<00:00,  1.12it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   5%|▌         | 27/532 [00:00<00:01, 262.67it/s]concatenating: train:  10%|▉         | 52/532 [00:00<00:01, 257.71it/s]concatenating: train:  15%|█▌        | 81/532 [00:00<00:01, 265.27it/s]concatenating: train:  19%|█▉        | 103/532 [00:00<00:01, 249.46it/s]concatenating: train:  25%|██▌       | 133/532 [00:00<00:01, 255.40it/s]concatenating: train:  30%|███       | 161/532 [00:00<00:01, 261.50it/s]concatenating: train:  36%|███▌      | 189/532 [00:00<00:01, 264.30it/s]concatenating: train:  41%|████      | 216/532 [00:00<00:01, 265.65it/s]concatenating: train:  45%|████▌     | 242/532 [00:00<00:01, 252.96it/s]concatenating: train:  51%|█████     | 269/532 [00:01<00:01, 256.92it/s]concatenating: train:  56%|█████▌    | 296/532 [00:01<00:00, 260.68it/s]concatenating: train:  61%|██████    | 322/532 [00:01<00:00, 250.07it/s]concatenating: train:  66%|██████▌   | 349/532 [00:01<00:00, 253.36it/s]concatenating: train:  70%|███████   | 375/532 [00:01<00:00, 254.87it/s]concatenating: train:  75%|███████▌  | 401/532 [00:01<00:00, 255.59it/s]concatenating: train:  80%|████████  | 427/532 [00:01<00:00, 256.84it/s]concatenating: train:  85%|████████▌ | 454/532 [00:01<00:00, 258.18it/s]concatenating: train:  90%|█████████ | 481/532 [00:01<00:00, 260.26it/s]concatenating: train:  95%|█████████▌| 508/532 [00:01<00:00, 260.44it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 261.03it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:09,  1.40it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:09,  1.36it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.19it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.13it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.03it/s]Loading test:  40%|████      | 6/15 [00:05<00:09,  1.05s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:07,  1.02it/s]Loading test:  53%|█████▎    | 8/15 [00:07<00:07,  1.04s/it]Loading test:  60%|██████    | 9/15 [00:08<00:06,  1.02s/it]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.05it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.05it/s]Loading test:  80%|████████  | 12/15 [00:11<00:02,  1.04it/s]Loading test:  87%|████████▋ | 13/15 [00:12<00:01,  1.02it/s]Loading test:  93%|█████████▎| 14/15 [00:13<00:00,  1.05it/s]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 474.62it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 6  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-06 22:21:05.549752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 22:21:05.549858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 22:21:05.549872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 22:21:05.549881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 22:21:05.550378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 42, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 27s - loss: 12.8302 - acc: 0.7556 - mDice: 0.0604 - val_loss: 2.4425 - val_acc: 0.9144 - val_mDice: 0.2001

Epoch 00001: val_mDice improved from -inf to 0.20014, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 20s - loss: 2.1516 - acc: 0.9139 - mDice: 0.2754 - val_loss: 1.4221 - val_acc: 0.9396 - val_mDice: 0.4498

Epoch 00002: val_mDice improved from 0.20014 to 0.44984, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 19s - loss: 1.4109 - acc: 0.9329 - mDice: 0.4430 - val_loss: 0.7499 - val_acc: 0.9585 - val_mDice: 0.6578

Epoch 00003: val_mDice improved from 0.44984 to 0.65784, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 1.1353 - acc: 0.9420 - mDice: 0.5287 - val_loss: 0.6437 - val_acc: 0.9636 - val_mDice: 0.7030

Epoch 00004: val_mDice improved from 0.65784 to 0.70297, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 19s - loss: 0.9903 - acc: 0.9470 - mDice: 0.5799 - val_loss: 0.6009 - val_acc: 0.9663 - val_mDice: 0.7253

Epoch 00005: val_mDice improved from 0.70297 to 0.72532, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 19s - loss: 0.8972 - acc: 0.9503 - mDice: 0.6145 - val_loss: 0.5782 - val_acc: 0.9675 - val_mDice: 0.7386

Epoch 00006: val_mDice improved from 0.72532 to 0.73865, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 20s - loss: 0.8293 - acc: 0.9525 - mDice: 0.6402 - val_loss: 0.5507 - val_acc: 0.9703 - val_mDice: 0.7538

Epoch 00007: val_mDice improved from 0.73865 to 0.75376, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 19s - loss: 0.7817 - acc: 0.9541 - mDice: 0.6590 - val_loss: 0.5435 - val_acc: 0.9708 - val_mDice: 0.7574

Epoch 00008: val_mDice improved from 0.75376 to 0.75739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 0.7448 - acc: 0.9551 - mDice: 0.6727 - val_loss: 0.5357 - val_acc: 0.9712 - val_mDice: 0.7625

Epoch 00009: val_mDice improved from 0.75739 to 0.76249, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 19s - loss: 0.7165 - acc: 0.9560 - mDice: 0.6841 - val_loss: 0.5180 - val_acc: 0.9727 - val_mDice: 0.7704

Epoch 00010: val_mDice improved from 0.76249 to 0.77045, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 21s - loss: 0.6928 - acc: 0.9569 - mDice: 0.6938 - val_loss: 0.5037 - val_acc: 0.9732 - val_mDice: 0.7747

Epoch 00011: val_mDice improved from 0.77045 to 0.77475, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 0.6734 - acc: 0.9575 - mDice: 0.7014 - val_loss: 0.5040 - val_acc: 0.9732 - val_mDice: 0.7741

Epoch 00012: val_mDice did not improve from 0.77475
Epoch 13/300
 - 22s - loss: 0.6562 - acc: 0.9580 - mDice: 0.7081 - val_loss: 0.5037 - val_acc: 0.9744 - val_mDice: 0.7745

Epoch 00013: val_mDice did not improve from 0.77475
Epoch 14/300
 - 21s - loss: 0.6417 - acc: 0.9587 - mDice: 0.7138 - val_loss: 0.4898 - val_acc: 0.9739 - val_mDice: 0.7794

Epoch 00014: val_mDice improved from 0.77475 to 0.77938, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 21s - loss: 0.6284 - acc: 0.9591 - mDice: 0.7188 - val_loss: 0.4934 - val_acc: 0.9740 - val_mDice: 0.7801

Epoch 00015: val_mDice improved from 0.77938 to 0.78011, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 22s - loss: 0.6172 - acc: 0.9595 - mDice: 0.7233 - val_loss: 0.4867 - val_acc: 0.9737 - val_mDice: 0.7831

Epoch 00016: val_mDice improved from 0.78011 to 0.78307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 22s - loss: 0.6082 - acc: 0.9599 - mDice: 0.7273 - val_loss: 0.4867 - val_acc: 0.9739 - val_mDice: 0.7821

Epoch 00017: val_mDice did not improve from 0.78307
Epoch 18/300
 - 21s - loss: 0.5974 - acc: 0.9603 - mDice: 0.7318 - val_loss: 0.4918 - val_acc: 0.9730 - val_mDice: 0.7794

Epoch 00018: val_mDice did not improve from 0.78307
Epoch 19/300
 - 22s - loss: 0.5885 - acc: 0.9606 - mDice: 0.7351 - val_loss: 0.4781 - val_acc: 0.9758 - val_mDice: 0.7832

Epoch 00019: val_mDice improved from 0.78307 to 0.78320, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 22s - loss: 0.5832 - acc: 0.9608 - mDice: 0.7372 - val_loss: 0.4799 - val_acc: 0.9759 - val_mDice: 0.7862

Epoch 00020: val_mDice improved from 0.78320 to 0.78617, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 21s - loss: 0.5775 - acc: 0.9610 - mDice: 0.7396 - val_loss: 0.4783 - val_acc: 0.9762 - val_mDice: 0.7866

Epoch 00021: val_mDice improved from 0.78617 to 0.78665, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 22s - loss: 0.5693 - acc: 0.9613 - mDice: 0.7429 - val_loss: 0.4773 - val_acc: 0.9760 - val_mDice: 0.7877

Epoch 00022: val_mDice improved from 0.78665 to 0.78772, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 22s - loss: 0.5634 - acc: 0.9614 - mDice: 0.7456 - val_loss: 0.4747 - val_acc: 0.9759 - val_mDice: 0.7880

Epoch 00023: val_mDice improved from 0.78772 to 0.78801, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 21s - loss: 0.5561 - acc: 0.9617 - mDice: 0.7484 - val_loss: 0.4805 - val_acc: 0.9762 - val_mDice: 0.7874

Epoch 00024: val_mDice did not improve from 0.78801
Epoch 25/300
 - 22s - loss: 0.5519 - acc: 0.9618 - mDice: 0.7501 - val_loss: 0.4699 - val_acc: 0.9756 - val_mDice: 0.7931

Epoch 00025: val_mDice improved from 0.78801 to 0.79307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 22s - loss: 0.5488 - acc: 0.9618 - mDice: 0.7516 - val_loss: 0.4615 - val_acc: 0.9762 - val_mDice: 0.7920

Epoch 00026: val_mDice did not improve from 0.79307
Epoch 27/300
 - 21s - loss: 0.5410 - acc: 0.9620 - mDice: 0.7546 - val_loss: 0.4616 - val_acc: 0.9759 - val_mDice: 0.7943

Epoch 00027: val_mDice improved from 0.79307 to 0.79434, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 22s - loss: 0.5401 - acc: 0.9620 - mDice: 0.7551 - val_loss: 0.4648 - val_acc: 0.9767 - val_mDice: 0.7915

Epoch 00028: val_mDice did not improve from 0.79434
Epoch 29/300
 - 22s - loss: 0.5350 - acc: 0.9621 - mDice: 0.7570 - val_loss: 0.4553 - val_acc: 0.9769 - val_mDice: 0.7956

Epoch 00029: val_mDice improved from 0.79434 to 0.79561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 21s - loss: 0.5273 - acc: 0.9623 - mDice: 0.7606 - val_loss: 0.4499 - val_acc: 0.9770 - val_mDice: 0.7963

Epoch 00030: val_mDice improved from 0.79561 to 0.79626, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 22s - loss: 0.5261 - acc: 0.9624 - mDice: 0.7612 - val_loss: 0.4644 - val_acc: 0.9765 - val_mDice: 0.7912

Epoch 00031: val_mDice did not improve from 0.79626
Epoch 32/300
 - 22s - loss: 0.5218 - acc: 0.9623 - mDice: 0.7627 - val_loss: 0.4501 - val_acc: 0.9767 - val_mDice: 0.7975

Epoch 00032: val_mDice improved from 0.79626 to 0.79753, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 21s - loss: 0.5193 - acc: 0.9623 - mDice: 0.7636 - val_loss: 0.4555 - val_acc: 0.9772 - val_mDice: 0.7973

Epoch 00033: val_mDice did not improve from 0.79753
Epoch 34/300
 - 20s - loss: 0.5153 - acc: 0.9625 - mDice: 0.7656 - val_loss: 0.4564 - val_acc: 0.9770 - val_mDice: 0.7973

Epoch 00034: val_mDice did not improve from 0.79753
Epoch 35/300
 - 20s - loss: 0.5140 - acc: 0.9625 - mDice: 0.7660 - val_loss: 0.4502 - val_acc: 0.9769 - val_mDice: 0.7954

Epoch 00035: val_mDice did not improve from 0.79753
Epoch 36/300
 - 19s - loss: 0.5101 - acc: 0.9625 - mDice: 0.7677 - val_loss: 0.4514 - val_acc: 0.9769 - val_mDice: 0.7984

Epoch 00036: val_mDice improved from 0.79753 to 0.79837, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 19s - loss: 0.5054 - acc: 0.9627 - mDice: 0.7695 - val_loss: 0.4508 - val_acc: 0.9772 - val_mDice: 0.8001

Epoch 00037: val_mDice improved from 0.79837 to 0.80011, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 19s - loss: 0.5055 - acc: 0.9626 - mDice: 0.7693 - val_loss: 0.4529 - val_acc: 0.9760 - val_mDice: 0.7989

Epoch 00038: val_mDice did not improve from 0.80011
Epoch 39/300
 - 20s - loss: 0.5013 - acc: 0.9626 - mDice: 0.7715 - val_loss: 0.4528 - val_acc: 0.9768 - val_mDice: 0.7977

Epoch 00039: val_mDice did not improve from 0.80011
Epoch 40/300
 - 19s - loss: 0.4982 - acc: 0.9627 - mDice: 0.7725 - val_loss: 0.4439 - val_acc: 0.9771 - val_mDice: 0.8026

Epoch 00040: val_mDice improved from 0.80011 to 0.80258, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 41/300
 - 19s - loss: 0.4969 - acc: 0.9627 - mDice: 0.7733 - val_loss: 0.4550 - val_acc: 0.9769 - val_mDice: 0.7984

Epoch 00041: val_mDice did not improve from 0.80258
Epoch 42/300
 - 19s - loss: 0.4965 - acc: 0.9627 - mDice: 0.7734 - val_loss: 0.4527 - val_acc: 0.9759 - val_mDice: 0.7980

Epoch 00042: val_mDice did not improve from 0.80258
Epoch 43/300
 - 20s - loss: 0.4926 - acc: 0.9627 - mDice: 0.7749 - val_loss: 0.4507 - val_acc: 0.9770 - val_mDice: 0.7998

Epoch 00043: val_mDice did not improve from 0.80258
Epoch 44/300
 - 20s - loss: 0.4916 - acc: 0.9628 - mDice: 0.7755 - val_loss: 0.4476 - val_acc: 0.9767 - val_mDice: 0.8001

Epoch 00044: val_mDice did not improve from 0.80258
Epoch 45/300
 - 19s - loss: 0.4903 - acc: 0.9627 - mDice: 0.7758 - val_loss: 0.4463 - val_acc: 0.9767 - val_mDice: 0.8008

Epoch 00045: val_mDice did not improve from 0.80258
Epoch 46/300
 - 19s - loss: 0.4872 - acc: 0.9628 - mDice: 0.7772 - val_loss: 0.4422 - val_acc: 0.9773 - val_mDice: 0.8025

Epoch 00046: val_mDice did not improve from 0.80258
Epoch 47/300
 - 19s - loss: 0.4867 - acc: 0.9628 - mDice: 0.7774 - val_loss: 0.4392 - val_acc: 0.9772 - val_mDice: 0.8037

Epoch 00047: val_mDice improved from 0.80258 to 0.80368, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 19s - loss: 0.4827 - acc: 0.9627 - mDice: 0.7789 - val_loss: 0.4453 - val_acc: 0.9774 - val_mDice: 0.8016

Epoch 00048: val_mDice did not improve from 0.80368
Epoch 49/300
 - 20s - loss: 0.4812 - acc: 0.9628 - mDice: 0.7794 - val_loss: 0.4412 - val_acc: 0.9774 - val_mDice: 0.8037

Epoch 00049: val_mDice improved from 0.80368 to 0.80370, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 50/300
 - 19s - loss: 0.4803 - acc: 0.9628 - mDice: 0.7799 - val_loss: 0.4457 - val_acc: 0.9770 - val_mDice: 0.8020

Epoch 00050: val_mDice did not improve from 0.80370
Epoch 51/300
 - 19s - loss: 0.4787 - acc: 0.9628 - mDice: 0.7807 - val_loss: 0.4518 - val_acc: 0.9770 - val_mDice: 0.8003

Epoch 00051: val_mDice did not improve from 0.80370
Epoch 52/300
 - 19s - loss: 0.4777 - acc: 0.9629 - mDice: 0.7810 - val_loss: 0.4464 - val_acc: 0.9772 - val_mDice: 0.8008

Epoch 00052: val_mDice did not improve from 0.80370
Epoch 53/300
 - 19s - loss: 0.4768 - acc: 0.9629 - mDice: 0.7813 - val_loss: 0.4478 - val_acc: 0.9772 - val_mDice: 0.8017

Epoch 00053: val_mDice did not improve from 0.80370
Epoch 54/300
 - 20s - loss: 0.4746 - acc: 0.9628 - mDice: 0.7820 - val_loss: 0.4402 - val_acc: 0.9771 - val_mDice: 0.8041

Epoch 00054: val_mDice improved from 0.80370 to 0.80412, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 55/300
 - 19s - loss: 0.4738 - acc: 0.9629 - mDice: 0.7827 - val_loss: 0.4506 - val_acc: 0.9776 - val_mDice: 0.8006

Epoch 00055: val_mDice did not improve from 0.80412
Epoch 56/300
 - 19s - loss: 0.4711 - acc: 0.9630 - mDice: 0.7836 - val_loss: 0.4368 - val_acc: 0.9771 - val_mDice: 0.8036

Epoch 00056: val_mDice did not improve from 0.80412
Epoch 57/300
 - 19s - loss: 0.4717 - acc: 0.9629 - mDice: 0.7832 - val_loss: 0.4442 - val_acc: 0.9773 - val_mDice: 0.8017

Epoch 00057: val_mDice did not improve from 0.80412
Epoch 58/300
 - 19s - loss: 0.4708 - acc: 0.9629 - mDice: 0.7836 - val_loss: 0.4412 - val_acc: 0.9776 - val_mDice: 0.8034

Epoch 00058: val_mDice did not improve from 0.80412
Epoch 59/300
 - 19s - loss: 0.4689 - acc: 0.9630 - mDice: 0.7845 - val_loss: 0.4414 - val_acc: 0.9775 - val_mDice: 0.8041

Epoch 00059: val_mDice did not improve from 0.80412
Epoch 60/300
 - 20s - loss: 0.4659 - acc: 0.9630 - mDice: 0.7857 - val_loss: 0.4444 - val_acc: 0.9772 - val_mDice: 0.8027

Epoch 00060: val_mDice did not improve from 0.80412
Epoch 61/300
 - 19s - loss: 0.4666 - acc: 0.9630 - mDice: 0.7854 - val_loss: 0.4429 - val_acc: 0.9775 - val_mDice: 0.8026

Epoch 00061: val_mDice did not improve from 0.80412
Epoch 62/300
 - 19s - loss: 0.4651 - acc: 0.9631 - mDice: 0.7861 - val_loss: 0.4392 - val_acc: 0.9778 - val_mDice: 0.8032

Epoch 00062: val_mDice did not improve from 0.80412
Epoch 63/300
 - 19s - loss: 0.4637 - acc: 0.9630 - mDice: 0.7865 - val_loss: 0.4358 - val_acc: 0.9777 - val_mDice: 0.8046

Epoch 00063: val_mDice improved from 0.80412 to 0.80462, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 64/300
 - 19s - loss: 0.4628 - acc: 0.9630 - mDice: 0.7868 - val_loss: 0.4390 - val_acc: 0.9774 - val_mDice: 0.8036

Epoch 00064: val_mDice did not improve from 0.80462
Epoch 65/300
 - 20s - loss: 0.4620 - acc: 0.9630 - mDice: 0.7871 - val_loss: 0.4432 - val_acc: 0.9772 - val_mDice: 0.8015

Epoch 00065: val_mDice did not improve from 0.80462
Epoch 66/300
 - 19s - loss: 0.4591 - acc: 0.9631 - mDice: 0.7882 - val_loss: 0.4493 - val_acc: 0.9773 - val_mDice: 0.7999

Epoch 00066: val_mDice did not improve from 0.80462
Epoch 67/300
 - 19s - loss: 0.4602 - acc: 0.9631 - mDice: 0.7879 - val_loss: 0.4414 - val_acc: 0.9775 - val_mDice: 0.8032

Epoch 00067: val_mDice did not improve from 0.80462
Epoch 68/300
 - 19s - loss: 0.4581 - acc: 0.9632 - mDice: 0.7887 - val_loss: 0.4394 - val_acc: 0.9777 - val_mDice: 0.8031

Epoch 00068: val_mDice did not improve from 0.80462
Epoch 69/300
 - 19s - loss: 0.4570 - acc: 0.9631 - mDice: 0.7893 - val_loss: 0.4396 - val_acc: 0.9777 - val_mDice: 0.8038

Epoch 00069: val_mDice did not improve from 0.80462
Epoch 70/300
 - 20s - loss: 0.4573 - acc: 0.9631 - mDice: 0.7891 - val_loss: 0.4426 - val_acc: 0.9771 - val_mDice: 0.8029

Epoch 00070: val_mDice did not improve from 0.80462
Epoch 71/300
 - 20s - loss: 0.4550 - acc: 0.9632 - mDice: 0.7899 - val_loss: 0.4359 - val_acc: 0.9777 - val_mDice: 0.8050

Epoch 00071: val_mDice improved from 0.80462 to 0.80503, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 72/300
 - 19s - loss: 0.4561 - acc: 0.9632 - mDice: 0.7896 - val_loss: 0.4343 - val_acc: 0.9777 - val_mDice: 0.8057

Epoch 00072: val_mDice improved from 0.80503 to 0.80574, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 73/300
 - 19s - loss: 0.4536 - acc: 0.9632 - mDice: 0.7905 - val_loss: 0.4474 - val_acc: 0.9777 - val_mDice: 0.8049

Epoch 00073: val_mDice did not improve from 0.80574
Epoch 74/300
 - 19s - loss: 0.4538 - acc: 0.9632 - mDice: 0.7905 - val_loss: 0.4450 - val_acc: 0.9776 - val_mDice: 0.8031

Epoch 00074: val_mDice did not improve from 0.80574
Epoch 75/300
 - 19s - loss: 0.4526 - acc: 0.9632 - mDice: 0.7910 - val_loss: 0.4405 - val_acc: 0.9782 - val_mDice: 0.8025

Epoch 00075: val_mDice did not improve from 0.80574
Epoch 76/300
 - 20s - loss: 0.4517 - acc: 0.9633 - mDice: 0.7912 - val_loss: 0.4390 - val_acc: 0.9773 - val_mDice: 0.8029

Epoch 00076: val_mDice did not improve from 0.80574
Epoch 77/300
 - 19s - loss: 0.4512 - acc: 0.9632 - mDice: 0.7915 - val_loss: 0.4372 - val_acc: 0.9777 - val_mDice: 0.8046

Epoch 00077: val_mDice did not improve from 0.80574
Epoch 78/300
 - 19s - loss: 0.4505 - acc: 0.9632 - mDice: 0.7918 - val_loss: 0.4332 - val_acc: 0.9775 - val_mDice: 0.8068

Epoch 00078: val_mDice improved from 0.80574 to 0.80676, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 19s - loss: 0.4494 - acc: 0.9632 - mDice: 0.7922 - val_loss: 0.4312 - val_acc: 0.9776 - val_mDice: 0.8058

Epoch 00079: val_mDice did not improve from 0.80676
Epoch 80/300
 - 19s - loss: 0.4485 - acc: 0.9633 - mDice: 0.7927 - val_loss: 0.4351 - val_acc: 0.9780 - val_mDice: 0.8046

Epoch 00080: val_mDice did not improve from 0.80676
Epoch 81/300
 - 20s - loss: 0.4493 - acc: 0.9632 - mDice: 0.7922 - val_loss: 0.4406 - val_acc: 0.9777 - val_mDice: 0.8036

Epoch 00081: val_mDice did not improve from 0.80676
Epoch 82/300
 - 19s - loss: 0.4482 - acc: 0.9633 - mDice: 0.7930 - val_loss: 0.4354 - val_acc: 0.9778 - val_mDice: 0.8054

Epoch 00082: val_mDice did not improve from 0.80676
Epoch 83/300
 - 19s - loss: 0.4465 - acc: 0.9633 - mDice: 0.7935 - val_loss: 0.4335 - val_acc: 0.9778 - val_mDice: 0.8067

Epoch 00083: val_mDice did not improve from 0.80676
Epoch 84/300
 - 19s - loss: 0.4467 - acc: 0.9633 - mDice: 0.7933 - val_loss: 0.4400 - val_acc: 0.9779 - val_mDice: 0.8036

Epoch 00084: val_mDice did not improve from 0.80676
Epoch 85/300
 - 20s - loss: 0.4454 - acc: 0.9633 - mDice: 0.7938 - val_loss: 0.4248 - val_acc: 0.9778 - val_mDice: 0.8077

Epoch 00085: val_mDice improved from 0.80676 to 0.80766, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 86/300
 - 19s - loss: 0.4445 - acc: 0.9633 - mDice: 0.7942 - val_loss: 0.4320 - val_acc: 0.9780 - val_mDice: 0.8069

Epoch 00086: val_mDice did not improve from 0.80766
Epoch 87/300
 - 19s - loss: 0.4436 - acc: 0.9633 - mDice: 0.7948 - val_loss: 0.4312 - val_acc: 0.9777 - val_mDice: 0.8066

Epoch 00087: val_mDice did not improve from 0.80766
Epoch 88/300
 - 19s - loss: 0.4444 - acc: 0.9633 - mDice: 0.7942 - val_loss: 0.4304 - val_acc: 0.9780 - val_mDice: 0.8083

Epoch 00088: val_mDice improved from 0.80766 to 0.80828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 89/300
 - 20s - loss: 0.4426 - acc: 0.9634 - mDice: 0.7951 - val_loss: 0.4364 - val_acc: 0.9777 - val_mDice: 0.8064

Epoch 00089: val_mDice did not improve from 0.80828
Epoch 90/300
 - 19s - loss: 0.4419 - acc: 0.9634 - mDice: 0.7954 - val_loss: 0.4308 - val_acc: 0.9776 - val_mDice: 0.8065

Epoch 00090: val_mDice did not improve from 0.80828
Epoch 91/300
 - 19s - loss: 0.4423 - acc: 0.9634 - mDice: 0.7951 - val_loss: 0.4413 - val_acc: 0.9771 - val_mDice: 0.8053

Epoch 00091: val_mDice did not improve from 0.80828
Epoch 92/300
 - 20s - loss: 0.4416 - acc: 0.9634 - mDice: 0.7954 - val_loss: 0.4326 - val_acc: 0.9781 - val_mDice: 0.8066

Epoch 00092: val_mDice did not improve from 0.80828
Epoch 93/300
 - 18s - loss: 0.4404 - acc: 0.9635 - mDice: 0.7959 - val_loss: 0.4369 - val_acc: 0.9778 - val_mDice: 0.8044

Epoch 00093: val_mDice did not improve from 0.80828
Epoch 94/300
 - 19s - loss: 0.4401 - acc: 0.9635 - mDice: 0.7960 - val_loss: 0.4332 - val_acc: 0.9775 - val_mDice: 0.8064

Epoch 00094: val_mDice did not improve from 0.80828
Epoch 95/300
 - 20s - loss: 0.4402 - acc: 0.9634 - mDice: 0.7961 - val_loss: 0.4397 - val_acc: 0.9779 - val_mDice: 0.8047

Epoch 00095: val_mDice did not improve from 0.80828
Epoch 96/300
 - 19s - loss: 0.4396 - acc: 0.9635 - mDice: 0.7963 - val_loss: 0.4294 - val_acc: 0.9780 - val_mDice: 0.8067

Epoch 00096: val_mDice did not improve from 0.80828
Epoch 97/300
 - 19s - loss: 0.4384 - acc: 0.9635 - mDice: 0.7970 - val_loss: 0.4331 - val_acc: 0.9783 - val_mDice: 0.8061

Epoch 00097: val_mDice did not improve from 0.80828
Epoch 98/300
 - 19s - loss: 0.4384 - acc: 0.9635 - mDice: 0.7968 - val_loss: 0.4314 - val_acc: 0.9779 - val_mDice: 0.8074

Epoch 00098: val_mDice did not improve from 0.80828
Epoch 99/300
 - 19s - loss: 0.4369 - acc: 0.9636 - mDice: 0.7976 - val_loss: 0.4371 - val_acc: 0.9784 - val_mDice: 0.8065

Epoch 00099: val_mDice did not improve from 0.80828
Epoch 100/300
 - 20s - loss: 0.4369 - acc: 0.9636 - mDice: 0.7974 - val_loss: 0.4274 - val_acc: 0.9779 - val_mDice: 0.8094

Epoch 00100: val_mDice improved from 0.80828 to 0.80939, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 101/300
 - 19s - loss: 0.4368 - acc: 0.9636 - mDice: 0.7974 - val_loss: 0.4574 - val_acc: 0.9773 - val_mDice: 0.8030

Epoch 00101: val_mDice did not improve from 0.80939
Epoch 102/300
 - 19s - loss: 0.4363 - acc: 0.9636 - mDice: 0.7976 - val_loss: 0.4317 - val_acc: 0.9776 - val_mDice: 0.8073

Epoch 00102: val_mDice did not improve from 0.80939
Epoch 103/300
 - 19s - loss: 0.4355 - acc: 0.9636 - mDice: 0.7979 - val_loss: 0.4296 - val_acc: 0.9780 - val_mDice: 0.8094

Epoch 00103: val_mDice did not improve from 0.80939
Epoch 104/300
 - 19s - loss: 0.4348 - acc: 0.9637 - mDice: 0.7982 - val_loss: 0.4364 - val_acc: 0.9776 - val_mDice: 0.8059

Epoch 00104: val_mDice did not improve from 0.80939
Epoch 105/300
 - 20s - loss: 0.4335 - acc: 0.9637 - mDice: 0.7988 - val_loss: 0.4369 - val_acc: 0.9780 - val_mDice: 0.8062

Epoch 00105: val_mDice did not improve from 0.80939
Epoch 106/300
 - 19s - loss: 0.4342 - acc: 0.9637 - mDice: 0.7986 - val_loss: 0.4330 - val_acc: 0.9780 - val_mDice: 0.8047

Epoch 00106: val_mDice did not improve from 0.80939
Epoch 107/300
 - 19s - loss: 0.4325 - acc: 0.9638 - mDice: 0.7992 - val_loss: 0.4397 - val_acc: 0.9777 - val_mDice: 0.8059

Epoch 00107: val_mDice did not improve from 0.80939
Epoch 108/300
 - 18s - loss: 0.4325 - acc: 0.9638 - mDice: 0.7994 - val_loss: 0.4291 - val_acc: 0.9783 - val_mDice: 0.8082

Epoch 00108: val_mDice did not improve from 0.80939
Epoch 109/300
 - 19s - loss: 0.4321 - acc: 0.9638 - mDice: 0.7994 - val_loss: 0.4328 - val_acc: 0.9780 - val_mDice: 0.8065

Epoch 00109: val_mDice did not improve from 0.80939
Epoch 110/300
 - 19s - loss: 0.4331 - acc: 0.9638 - mDice: 0.7991 - val_loss: 0.4260 - val_acc: 0.9786 - val_mDice: 0.8093

Epoch 00110: val_mDice did not improve from 0.80939
Epoch 111/300
 - 20s - loss: 0.4312 - acc: 0.9639 - mDice: 0.7998 - val_loss: 0.4306 - val_acc: 0.9777 - val_mDice: 0.8082

Epoch 00111: val_mDice did not improve from 0.80939
Epoch 112/300
 - 19s - loss: 0.4320 - acc: 0.9639 - mDice: 0.7995 - val_loss: 0.4309 - val_acc: 0.9784 - val_mDice: 0.8080

Epoch 00112: val_mDice did not improve from 0.80939
Epoch 113/300
 - 18s - loss: 0.4293 - acc: 0.9640 - mDice: 0.8008 - val_loss: 0.4338 - val_acc: 0.9787 - val_mDice: 0.8083

Epoch 00113: val_mDice did not improve from 0.80939
Epoch 114/300
 - 19s - loss: 0.4307 - acc: 0.9639 - mDice: 0.8000 - val_loss: 0.4299 - val_acc: 0.9783 - val_mDice: 0.8106

Epoch 00114: val_mDice improved from 0.80939 to 0.81057, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 115/300
 - 18s - loss: 0.4297 - acc: 0.9639 - mDice: 0.8007 - val_loss: 0.4303 - val_acc: 0.9776 - val_mDice: 0.8089

Epoch 00115: val_mDice did not improve from 0.81057
Epoch 116/300
 - 20s - loss: 0.4283 - acc: 0.9640 - mDice: 0.8011 - val_loss: 0.4306 - val_acc: 0.9786 - val_mDice: 0.8096

Epoch 00116: val_mDice did not improve from 0.81057
Epoch 117/300
 - 19s - loss: 0.4296 - acc: 0.9640 - mDice: 0.8005 - val_loss: 0.4263 - val_acc: 0.9786 - val_mDice: 0.8102

Epoch 00117: val_mDice did not improve from 0.81057
Epoch 118/300
 - 19s - loss: 0.4283 - acc: 0.9640 - mDice: 0.8010 - val_loss: 0.4353 - val_acc: 0.9779 - val_mDice: 0.8077

Epoch 00118: val_mDice did not improve from 0.81057
Epoch 119/300
 - 19s - loss: 0.4274 - acc: 0.9640 - mDice: 0.8015 - val_loss: 0.4266 - val_acc: 0.9778 - val_mDice: 0.8087

Epoch 00119: val_mDice did not improve from 0.81057
Epoch 120/300
 - 19s - loss: 0.4268 - acc: 0.9641 - mDice: 0.8017 - val_loss: 0.4315 - val_acc: 0.9779 - val_mDice: 0.8072

Epoch 00120: val_mDice did not improve from 0.81057
Epoch 121/300
 - 19s - loss: 0.4277 - acc: 0.9641 - mDice: 0.8012 - val_loss: 0.4334 - val_acc: 0.9782 - val_mDice: 0.8085

Epoch 00121: val_mDice did not improve from 0.81057
Epoch 122/300
 - 20s - loss: 0.4269 - acc: 0.9641 - mDice: 0.8016 - val_loss: 0.4322 - val_acc: 0.9784 - val_mDice: 0.8061

Epoch 00122: val_mDice did not improve from 0.81057
Epoch 123/300
 - 19s - loss: 0.4268 - acc: 0.9641 - mDice: 0.8017 - val_loss: 0.4236 - val_acc: 0.9782 - val_mDice: 0.8093

Epoch 00123: val_mDice did not improve from 0.81057
Epoch 124/300
 - 19s - loss: 0.4278 - acc: 0.9642 - mDice: 0.8015 - val_loss: 0.4240 - val_acc: 0.9783 - val_mDice: 0.8104

Epoch 00124: val_mDice did not improve from 0.81057
Epoch 125/300
 - 19s - loss: 0.4268 - acc: 0.9642 - mDice: 0.8018 - val_loss: 0.4282 - val_acc: 0.9782 - val_mDice: 0.8091

Epoch 00125: val_mDice did not improve from 0.81057
Epoch 126/300
 - 19s - loss: 0.4245 - acc: 0.9642 - mDice: 0.8025 - val_loss: 0.4288 - val_acc: 0.9785 - val_mDice: 0.8085

Epoch 00126: val_mDice did not improve from 0.81057
Epoch 127/300
 - 20s - loss: 0.4258 - acc: 0.9642 - mDice: 0.8022 - val_loss: 0.4286 - val_acc: 0.9784 - val_mDice: 0.8090

Epoch 00127: val_mDice did not improve from 0.81057
Epoch 128/300
 - 19s - loss: 0.4257 - acc: 0.9642 - mDice: 0.8022 - val_loss: 0.4332 - val_acc: 0.9781 - val_mDice: 0.8088

Epoch 00128: val_mDice did not improve from 0.81057
Epoch 129/300
 - 19s - loss: 0.4245 - acc: 0.9642 - mDice: 0.8025 - val_loss: 0.4259 - val_acc: 0.9783 - val_mDice: 0.8091

Epoch 00129: val_mDice did not improve from 0.81057
Epoch 130/300
 - 19s - loss: 0.4246 - acc: 0.9643 - mDice: 0.8027 - val_loss: 0.4329 - val_acc: 0.9778 - val_mDice: 0.8085

Epoch 00130: val_mDice did not improve from 0.81057
Epoch 131/300
 - 20s - loss: 0.4248 - acc: 0.9643 - mDice: 0.8025 - val_loss: 0.4276 - val_acc: 0.9783 - val_mDice: 0.8082

Epoch 00131: val_mDice did not improve from 0.81057
Epoch 132/300
 - 19s - loss: 0.4242 - acc: 0.9644 - mDice: 0.8028 - val_loss: 0.4278 - val_acc: 0.9780 - val_mDice: 0.8094

Epoch 00132: val_mDice did not improve from 0.81057
Epoch 133/300
 - 19s - loss: 0.4235 - acc: 0.9644 - mDice: 0.8030 - val_loss: 0.4344 - val_acc: 0.9779 - val_mDice: 0.8078

Epoch 00133: val_mDice did not improve from 0.81057
Epoch 134/300
 - 19s - loss: 0.4220 - acc: 0.9644 - mDice: 0.8038 - val_loss: 0.4253 - val_acc: 0.9778 - val_mDice: 0.8087

Epoch 00134: val_mDice did not improve from 0.81057
Epoch 135/300
 - 19s - loss: 0.4248 - acc: 0.9643 - mDice: 0.8025 - val_loss: 0.4282 - val_acc: 0.9785 - val_mDice: 0.8086

Epoch 00135: val_mDice did not improve from 0.81057
Epoch 136/300
 - 19s - loss: 0.4230 - acc: 0.9644 - mDice: 0.8033 - val_loss: 0.4288 - val_acc: 0.9781 - val_mDice: 0.8106

Epoch 00136: val_mDice did not improve from 0.81057
Epoch 137/300
 - 19s - loss: 0.4222 - acc: 0.9644 - mDice: 0.8036 - val_loss: 0.4344 - val_acc: 0.9780 - val_mDice: 0.8077

Epoch 00137: val_mDice did not improve from 0.81057
Epoch 138/300
 - 19s - loss: 0.4216 - acc: 0.9645 - mDice: 0.8038 - val_loss: 0.4375 - val_acc: 0.9781 - val_mDice: 0.8061

Epoch 00138: val_mDice did not improve from 0.81057
Epoch 139/300
 - 19s - loss: 0.4223 - acc: 0.9645 - mDice: 0.8036 - val_loss: 0.4292 - val_acc: 0.9785 - val_mDice: 0.8088

Epoch 00139: val_mDice did not improve from 0.81057
Epoch 140/300
 - 19s - loss: 0.4213 - acc: 0.9645 - mDice: 0.8038 - val_loss: 0.4307 - val_acc: 0.9785 - val_mDice: 0.8096

Epoch 00140: val_mDice did not improve from 0.81057
Epoch 141/300
 - 20s - loss: 0.4207 - acc: 0.9646 - mDice: 0.8043 - val_loss: 0.4354 - val_acc: 0.9784 - val_mDice: 0.8078

Epoch 00141: val_mDice did not improve from 0.81057
Epoch 142/300
 - 19s - loss: 0.4216 - acc: 0.9646 - mDice: 0.8039 - val_loss: 0.4357 - val_acc: 0.9783 - val_mDice: 0.8070

Epoch 00142: val_mDice did not improve from 0.81057
Epoch 143/300
 - 19s - loss: 0.4211 - acc: 0.9646 - mDice: 0.8040 - val_loss: 0.4376 - val_acc: 0.9781 - val_mDice: 0.8071

Epoch 00143: val_mDice did not improve from 0.81057
Epoch 144/300
 - 19s - loss: 0.4193 - acc: 0.9646 - mDice: 0.8048 - val_loss: 0.4372 - val_acc: 0.9784 - val_mDice: 0.8075

Epoch 00144: val_mDice did not improve from 0.81057
Restoring model weights from the end of the best epoch
Epoch 00144: early stopping
{'val_loss': [2.442493144779989, 1.4221229675697953, 0.749875446704969, 0.6436757314695071, 0.6008913035262121, 0.5782230124898153, 0.5506823073103003, 0.5434950855496812, 0.5356851089490603, 0.5180343181303103, 0.503722173302141, 0.5040307408326292, 0.503657219956999, 0.48978160587075636, 0.4934294678985256, 0.4867320044399941, 0.4867000447152412, 0.4917863562499007, 0.4780545316330374, 0.47992067100250557, 0.4782758847083131, 0.4773207860041971, 0.4747128186568822, 0.48054320212096385, 0.46987259816633514, 0.46153033616608136, 0.46164177276500284, 0.4648147484619323, 0.4553301554836639, 0.44994017767579586, 0.46441838941345476, 0.45013039528507076, 0.45549220724465095, 0.4563962017020134, 0.4502031227497205, 0.4514331146054072, 0.4508075395675555, 0.45291348046635926, 0.45275085899111345, 0.44385985193187244, 0.45504927431067377, 0.45268998938064053, 0.4506997323199494, 0.44758851397527405, 0.44632089648344747, 0.4422039993821758, 0.439219083892156, 0.4452975182092353, 0.441153056817512, 0.4456752930601982, 0.45184160871048495, 0.4464370308265294, 0.44779659542318895, 0.4402261592753946, 0.45055970263807743, 0.43681774604810425, 0.4442091184119656, 0.44121303337894074, 0.44137168542979516, 0.4444483549219288, 0.44285043502507143, 0.4391637824169577, 0.435779846081995, 0.439046491702942, 0.4431873537497978, 0.4493013771429454, 0.4413632315723863, 0.43943366367522985, 0.4396216036522225, 0.4426309770508988, 0.4358507219242723, 0.4342716544458311, 0.44744541669545107, 0.4449924457154862, 0.4404835621379826, 0.43899988495323755, 0.4371707594557984, 0.4331745295083686, 0.4312326440664187, 0.4351332477510792, 0.4405619118311634, 0.43535236606042677, 0.43352284211001985, 0.4400430384972324, 0.424826419720911, 0.4319805184455767, 0.43124823741716883, 0.43042218154423856, 0.43637410745228805, 0.43080715120655216, 0.4413491769196236, 0.4326381366955091, 0.43690675742005647, 0.4331741798413943, 0.439664192599793, 0.42943312431851477, 0.43307038059789843, 0.4314254122237637, 0.4371118823142901, 0.4273645287915452, 0.457384901503994, 0.4317371681944965, 0.4295982555167316, 0.43640830520897694, 0.43686069017403745, 0.43304212697564737, 0.4397017572024097, 0.4291159969894853, 0.43282845126439445, 0.42599028777586273, 0.430570999236956, 0.43087608173285447, 0.4337515159420771, 0.4299009783218985, 0.4303325208490842, 0.4306040114327653, 0.4263214638380155, 0.43530127161169707, 0.42659310608693995, 0.4314799206714108, 0.4334268239262986, 0.4321742243554494, 0.42361039025326297, 0.423958300115311, 0.42822299938495845, 0.42882424899160043, 0.4285808562824171, 0.43320684073722526, 0.4258967397147662, 0.43294490996288926, 0.4275748062215439, 0.4278381295400123, 0.43439119074442617, 0.425322123178064, 0.4282177782630267, 0.4288075364207568, 0.4343996803237967, 0.43753325408452176, 0.429235794976966, 0.43071690936611123, 0.4354306979946894, 0.43569369491649, 0.4376008579992268, 0.43717770339691475], 'val_acc': [0.9144017631060457, 0.9395748846334954, 0.9584938651078367, 0.9635948167271811, 0.9663307458570559, 0.9675156143430161, 0.9703261893089503, 0.9707608198466366, 0.9712158502781227, 0.9726675320161532, 0.9731709663182089, 0.9731746046510461, 0.9744279037599695, 0.9738818978610104, 0.9739845546141063, 0.9737308172330464, 0.9739361201247124, 0.9729649261252521, 0.9758166376858541, 0.9758643189521685, 0.9762152323167618, 0.975994635934699, 0.9758756050508316, 0.9762450701569858, 0.9755960408955404, 0.9762013889338872, 0.9759323939885178, 0.9767405027396059, 0.9769247039540173, 0.9770484570771047, 0.9764842333858961, 0.9767364953478722, 0.9772046298196871, 0.9769687411719805, 0.9769447233578931, 0.9768649927557331, 0.9772493900501564, 0.97599901687609, 0.9768427969658211, 0.9770561117831975, 0.976866457560291, 0.9759101863593271, 0.9770244294649935, 0.9767143003744622, 0.9767496034707108, 0.9772989113036901, 0.9771838616834928, 0.9774117547355287, 0.9774026429816468, 0.9769971325789413, 0.976952365408205, 0.9771951596214347, 0.9771500213505471, 0.9770983286099891, 0.9776341551787233, 0.9770622902537045, 0.9772894423301905, 0.9776465394725539, 0.9775180281841591, 0.9772435663497612, 0.9775129519913295, 0.9778096153311533, 0.9777175208477125, 0.9773585931079029, 0.9772027959562328, 0.9773236537632877, 0.9774677937161432, 0.9776931196859439, 0.977710246223293, 0.9771154310605298, 0.9777419097619514, 0.9777426327744575, 0.9776545505817622, 0.9775748281446222, 0.9781714420612544, 0.9772912565975973, 0.9777404482234014, 0.9775071189011613, 0.9776319869577068, 0.9779523055847377, 0.9777368139730741, 0.9778274677387656, 0.977759742981767, 0.9778875324824085, 0.9777604847738187, 0.9779621391263726, 0.9776905693419992, 0.9780090998296869, 0.9777211595888007, 0.9776170425219078, 0.9771452819647855, 0.9781335890293121, 0.97782418417604, 0.9775067563742807, 0.9778696759922864, 0.9780422147006205, 0.9783116048329497, 0.9779228384364141, 0.978358557371244, 0.9779417433150827, 0.9772632207772504, 0.9775828421115875, 0.9779592401360813, 0.9775595362872294, 0.9780276621857734, 0.9779603130196872, 0.9776818466513124, 0.9783101416613957, 0.9779978190382866, 0.978617742045285, 0.977735355700532, 0.9783833026885986, 0.9787345626582838, 0.978255178830395, 0.977641077074286, 0.9786035447088006, 0.9785933461907792, 0.9778769506167059, 0.9777943418450552, 0.9779111751138347, 0.9782493449237248, 0.9783771160530718, 0.9782427880045486, 0.9782857339676112, 0.9782329707929532, 0.9785361877859455, 0.9783705668906643, 0.9781386840016875, 0.9782613430121173, 0.9778285455213834, 0.9783035851504704, 0.977992008810174, 0.9779366658975001, 0.9778274538582319, 0.9785445606055325, 0.9781132144470738, 0.9780323983055271, 0.9780731711485614, 0.9785423797287353, 0.9784943400180504, 0.9783894897323765, 0.9782872130609539, 0.9780720803019118, 0.978410594267388], 'val_mDice': [0.2001384814103989, 0.4498438210520026, 0.6578352492149562, 0.702969592728027, 0.7253183236677353, 0.7386483525576657, 0.7537619708335563, 0.7573870220412947, 0.762492976776541, 0.7704486148814632, 0.7747496056230101, 0.7740873457634285, 0.7745150295022416, 0.7793809926673158, 0.7801102326340872, 0.7830683613476688, 0.7820765649619168, 0.7793769264874393, 0.7831979867530195, 0.7861669026825526, 0.7866480648517609, 0.7877154827934422, 0.7880146768811631, 0.7874319920801136, 0.793070477573839, 0.792002601982796, 0.7943433396620293, 0.7915121157691903, 0.7956050364938501, 0.7962639229754879, 0.7911961544049929, 0.7975255593861619, 0.7972799776351616, 0.7973082584061034, 0.7953686591697066, 0.7983741931719323, 0.8001079183735259, 0.7988646487667136, 0.7976985683996384, 0.8025849645268427, 0.7984026172389723, 0.79795830094651, 0.7997797927627824, 0.8000757669749325, 0.8008340254221877, 0.8024842490072119, 0.8036800075883734, 0.8015803286474045, 0.8036952202450739, 0.8019938660811071, 0.8003220011110175, 0.8007583622246572, 0.8017421601569816, 0.8041161780488001, 0.800605835571681, 0.8036398442640696, 0.8016892589934884, 0.8033956248466283, 0.8041088462692417, 0.8027186132457158, 0.8025658926735185, 0.8031934883496533, 0.8046152138546722, 0.803614175074721, 0.8015401873686542, 0.7999094487869576, 0.803248505069785, 0.8030807449393076, 0.803771679123787, 0.8028686879432365, 0.8050328391055538, 0.8057380163506286, 0.8048955630766202, 0.8031198753886026, 0.802458790475375, 0.8028892703252296, 0.8046283803574027, 0.8067552071728118, 0.8058469226099041, 0.8045507755181561, 0.8035829063147715, 0.8053894863553244, 0.806676351044276, 0.8035562601808, 0.807662938555626, 0.8069145887681882, 0.8066409479265344, 0.8082760364225466, 0.8064206381366678, 0.8065245069869577, 0.8053210969657114, 0.8065749872220705, 0.8043620476167496, 0.806399162909756, 0.8047246565557507, 0.8066873166659106, 0.8061044546839309, 0.8074149485320261, 0.806521182599133, 0.8093915785828681, 0.8030322255337075, 0.8073482464437616, 0.8093667957064223, 0.8059409832301205, 0.806166704386881, 0.804743377721473, 0.8059455188986373, 0.808175560546248, 0.8064665377956547, 0.8093285164604448, 0.8082000841833141, 0.8080051210645127, 0.8083433590523185, 0.8105650107338004, 0.8089485968628974, 0.8096086815611957, 0.810246321028226, 0.8076731721832328, 0.8087390469361658, 0.8072148757438137, 0.8084817818582875, 0.8061399676211892, 0.8092892418985498, 0.8104149470590565, 0.8091405230025722, 0.8085144313230906, 0.8089983202006719, 0.8087738233886353, 0.8090681886836274, 0.8085132808717963, 0.8081769694204199, 0.8093502084686331, 0.8077852750477725, 0.8086601646795665, 0.8086312045789745, 0.8105578638919412, 0.8076583126636401, 0.806084496517704, 0.8088448390568772, 0.8095980168205418, 0.8078423146515676, 0.8070447302027924, 0.8070991496517234, 0.8075233097762278], 'loss': [12.83019319344293, 2.1515851667849, 1.4109040870081173, 1.1353422745726898, 0.9903226450406659, 0.8971653221526705, 0.829261337595047, 0.7817444111922947, 0.7448313511838751, 0.7164896600211613, 0.6927738717432063, 0.673433468830925, 0.6562350825681084, 0.6417441405706035, 0.6284463298559775, 0.6172421487953423, 0.6081864289679788, 0.5973542386238544, 0.5885462191766863, 0.583176225830293, 0.5775304796009261, 0.5692547351097484, 0.5634254606822995, 0.5561211293226518, 0.5519098341766625, 0.5488483774239163, 0.5409709791389338, 0.5401165814659752, 0.534956295904846, 0.5273125207253528, 0.5261374196579235, 0.5217667383365479, 0.5192585701315976, 0.5153304168250602, 0.513990109380719, 0.5100768634158851, 0.5053696965900086, 0.5055236067865101, 0.5013197698379529, 0.4982060346582021, 0.49686210015100585, 0.4965387476404648, 0.4925772171189075, 0.49160324254606574, 0.49031244278890584, 0.48724267820753736, 0.48669859181226516, 0.48266220099955065, 0.4812289752140465, 0.4802974489670075, 0.4786505805603814, 0.47774318623435924, 0.47677014441718607, 0.4746396942502694, 0.4738045332402952, 0.47105162111332494, 0.47171471174110635, 0.47076686684887314, 0.46889158799835695, 0.4658630480722747, 0.46658057330476155, 0.4651119101736378, 0.46369887888503364, 0.4628418865629125, 0.4619693117283288, 0.45911519648316473, 0.46015100914131585, 0.4580540126766364, 0.45700560810135166, 0.4572649617210412, 0.45497387491931074, 0.4561029853068281, 0.45357028579182196, 0.45378265228206677, 0.45260665785881965, 0.451682418454118, 0.45121199230704456, 0.450535098359271, 0.44938264891402546, 0.44853597960849456, 0.449293525104115, 0.44818809500653645, 0.4464835090601931, 0.4467047006516602, 0.4454311291604647, 0.44452989677232896, 0.44361292579770517, 0.44436533172346954, 0.4426175422729127, 0.44188734221857157, 0.4422890693487917, 0.44163709350497277, 0.4404056379063008, 0.4401402797815145, 0.44023276730252264, 0.43964026882491164, 0.4383780934235074, 0.43836899875123747, 0.4369287385935496, 0.4368555942534412, 0.4368169900049468, 0.4363228103670306, 0.43546497881846274, 0.4348104152413895, 0.43354765443671117, 0.4341700575404457, 0.43252538635452786, 0.4324584220299015, 0.4320554853827185, 0.43305123132408957, 0.43123267256982056, 0.4319960982005299, 0.4293030842472958, 0.4306713268968753, 0.4297494133372865, 0.4283289434355514, 0.4296054001316759, 0.4282514037362144, 0.42742455059938866, 0.4268286732416439, 0.42768457639222546, 0.4268821114312885, 0.42675926980182194, 0.4277806487481125, 0.42675627708504005, 0.42454566984982356, 0.42577045406598435, 0.42572301749011293, 0.42446407644574835, 0.4245617891286987, 0.4247965090900704, 0.42423331115014745, 0.42346777170472816, 0.4219652427521733, 0.4247617520299657, 0.42304340144962715, 0.4222309814874761, 0.4215810412073418, 0.4222690926008244, 0.42127147848947727, 0.42072057863753515, 0.4216074523905558, 0.42114205401405336, 0.4193147079210016], 'acc': [0.7555871577232773, 0.9139232973408036, 0.9329484533451226, 0.9419555651049389, 0.9469897305082371, 0.9502964840003557, 0.9525084682668948, 0.9540762736875584, 0.9551189636326944, 0.9560035259282769, 0.9569223253599068, 0.957531526732878, 0.9580459552211321, 0.9587041711863555, 0.9590916365932296, 0.9594646882129535, 0.9598630579260552, 0.9602731645374426, 0.9605882445773916, 0.9607549225734202, 0.9609823229944995, 0.9612507244306413, 0.9614425832446531, 0.9617243681283071, 0.9617525830608522, 0.9618449970592193, 0.9620223704076823, 0.9620029524416112, 0.962097561007793, 0.9623113343173196, 0.9623620593178398, 0.9623298892412273, 0.9623135691051271, 0.9625273199591374, 0.9624630403010792, 0.9625279643207098, 0.962720165715642, 0.9625602713107626, 0.9626486172095351, 0.9627227440524534, 0.9627151655957775, 0.96272166049982, 0.9627459613901947, 0.9627567278522429, 0.9627390352207366, 0.962827043258355, 0.9627704267398646, 0.9627258673398614, 0.9627684904320325, 0.9627571680717132, 0.9628316846242715, 0.9628777602757769, 0.9629066833255204, 0.9628187249043377, 0.9628667745729705, 0.9629630446663833, 0.9628851863181851, 0.962916652712973, 0.9629873250460267, 0.9630419755103795, 0.9629696020908117, 0.9630908456685899, 0.963023317334761, 0.9630335432902044, 0.9630348244324219, 0.963081236999979, 0.9631236139949738, 0.9631531298421965, 0.9631478936449638, 0.9631413459789323, 0.9631814573769328, 0.963157667470924, 0.963228784935682, 0.9631903744202371, 0.9632282202269888, 0.9632557078041889, 0.9632100849285132, 0.9632382695775669, 0.9632173894347843, 0.9633111057496828, 0.9632245135069456, 0.9632542945516042, 0.9633080299472032, 0.9632541707920347, 0.9632693351570443, 0.9632532704082751, 0.9633099297321448, 0.9632799473720732, 0.96336394346756, 0.9633687669308515, 0.9634128243407604, 0.963446284645787, 0.9634591829110883, 0.9634821871584183, 0.9634410925983343, 0.9635113264728531, 0.9635259029698536, 0.9634955051267133, 0.9636167906452027, 0.963584959165143, 0.963595336331213, 0.9635674374908693, 0.9635667315367773, 0.9637008795244584, 0.9636906512881297, 0.9637416535512219, 0.9637625360754325, 0.9638046223810824, 0.963834295304886, 0.96380994986256, 0.9639169973915493, 0.9638712712555451, 0.9639531129342664, 0.9638877673358008, 0.9639414236961408, 0.9639967053739402, 0.964005232259471, 0.9640036166917905, 0.9640438905870652, 0.9641464142932898, 0.9640737016997663, 0.9641322352908147, 0.9641052601572876, 0.9641607887796956, 0.9642058915187378, 0.9642144661190091, 0.9642060968070278, 0.96423460854192, 0.9642449362610408, 0.964315251756205, 0.9642764925870546, 0.9643753922165454, 0.9643907721022295, 0.9644272953258939, 0.9643350053140356, 0.9643973488165124, 0.964388161896223, 0.9644710356870084, 0.9645121211235514, 0.9645088515837134, 0.9645667819926478, 0.9645725990342567, 0.9646093625121246, 0.9645587690359506], 'mDice': [0.060422957280150805, 0.2754058619612205, 0.443018749101322, 0.5287377678335095, 0.5799307306936962, 0.6145320166144935, 0.6401536889010506, 0.6590279963563578, 0.6727435782079932, 0.6841300797293551, 0.6938305494354297, 0.7014070058841063, 0.7081192493771948, 0.7137921043715251, 0.7187665339331839, 0.7233355818492739, 0.7273025154073507, 0.7317554053297801, 0.7350742831633024, 0.7372255739180276, 0.7395791719118264, 0.7428551372881251, 0.7456159914761913, 0.7483844485729423, 0.7501462776004001, 0.7516037594600439, 0.7546385455702613, 0.7551347491764047, 0.7570428285198192, 0.7606490860273076, 0.7612260396960063, 0.7626655518281855, 0.7636410239271512, 0.765591852687584, 0.7660342768259097, 0.7677440947754147, 0.7694925116575726, 0.7693421823202004, 0.7714793896513092, 0.7725189100938209, 0.773344099530255, 0.7734253969047263, 0.7748806663430268, 0.7754537297522363, 0.7757809683181411, 0.7771716723385084, 0.7773946512348135, 0.7788837551582267, 0.7793631208529558, 0.7798995130883337, 0.7807115150840088, 0.7809882549913459, 0.7813141569211527, 0.7819873946414775, 0.7827295097013665, 0.7835988886121141, 0.7831898092005568, 0.7836370005585314, 0.7844854153675127, 0.7856546471742752, 0.7854125135875311, 0.7861084453030847, 0.7864616812955983, 0.7868166457395036, 0.7871243083061635, 0.7882161281173089, 0.7878950191317446, 0.7887374065693238, 0.7892546558777702, 0.7891210175961252, 0.7899290595067726, 0.7896219953766064, 0.7905352508006565, 0.790541201819856, 0.7909707419010144, 0.7911596751924342, 0.7914739947208951, 0.7918340215522575, 0.7922238873581673, 0.7927397429451861, 0.7922102972894549, 0.7930465728824435, 0.7935216212951739, 0.7933295675976155, 0.7938251402143789, 0.7941653130111812, 0.7947945626501669, 0.7942194768713609, 0.7951056899791844, 0.7954357988093582, 0.7951109028591054, 0.7954098048299311, 0.7958625576755697, 0.795982360598541, 0.7961060725250522, 0.7962857584670869, 0.7969980639051808, 0.7968386890853857, 0.7975865493935788, 0.7974338730626339, 0.7973748067843379, 0.7975797946840673, 0.7979403575320803, 0.7981990391165097, 0.798797295966133, 0.7985683222972741, 0.7991947964062903, 0.7993535230553772, 0.7993992871477251, 0.7990648778434363, 0.799782129498963, 0.7995358875868861, 0.8007546732859919, 0.8000041296168507, 0.8006669513816931, 0.801140186545234, 0.8005412811485852, 0.8010046758492704, 0.8014893063269867, 0.8016775160492159, 0.8012308136768425, 0.8016127790277036, 0.8016510124068426, 0.8014980139252743, 0.8018312439802923, 0.8025043050670252, 0.8021528289498372, 0.8022311039502733, 0.8025316926702096, 0.8027228771379135, 0.8024762233048556, 0.8028191339022235, 0.802998582761462, 0.8037880774871247, 0.802537871999128, 0.8032646894460701, 0.8035677311920167, 0.8037579426151155, 0.8035845396127912, 0.8038293821644258, 0.804268143166576, 0.8038832756506518, 0.8040430086412466, 0.8048153391768716]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:30,  2.17s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:26,  2.02s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:24,  2.00s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:22,  2.00s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:21,  2.11s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.17s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:15,  1.97s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.09s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.03s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.90s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.85s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.91s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:25<00:03,  1.96s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.90s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.94s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<20:37,  2.33s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:05,  2.16s/it]predicting train subjects:   1%|          | 3/532 [00:05<18:02,  2.05s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:20,  1.97s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:10,  1.96s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:45,  1.91s/it]predicting train subjects:   1%|▏         | 7/532 [00:13<16:34,  1.90s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<16:03,  1.84s/it]predicting train subjects:   2%|▏         | 9/532 [00:17<17:00,  1.95s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<16:19,  1.88s/it]predicting train subjects:   2%|▏         | 11/532 [00:20<15:31,  1.79s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:53,  1.95s/it]predicting train subjects:   2%|▏         | 13/532 [00:24<15:35,  1.80s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:41,  1.70s/it]predicting train subjects:   3%|▎         | 15/532 [00:27<14:34,  1.69s/it]predicting train subjects:   3%|▎         | 16/532 [00:29<15:17,  1.78s/it]predicting train subjects:   3%|▎         | 17/532 [00:31<15:01,  1.75s/it]predicting train subjects:   3%|▎         | 18/532 [00:33<15:47,  1.84s/it]predicting train subjects:   4%|▎         | 19/532 [00:34<14:48,  1.73s/it]predicting train subjects:   4%|▍         | 20/532 [00:36<15:21,  1.80s/it]predicting train subjects:   4%|▍         | 21/532 [00:38<16:17,  1.91s/it]predicting train subjects:   4%|▍         | 22/532 [00:40<15:31,  1.83s/it]predicting train subjects:   4%|▍         | 23/532 [00:42<15:25,  1.82s/it]predicting train subjects:   5%|▍         | 24/532 [00:43<14:46,  1.75s/it]predicting train subjects:   5%|▍         | 25/532 [00:45<16:03,  1.90s/it]predicting train subjects:   5%|▍         | 26/532 [00:47<15:36,  1.85s/it]predicting train subjects:   5%|▌         | 27/532 [00:49<16:39,  1.98s/it]predicting train subjects:   5%|▌         | 28/532 [00:51<16:04,  1.91s/it]predicting train subjects:   5%|▌         | 29/532 [00:53<16:34,  1.98s/it]predicting train subjects:   6%|▌         | 30/532 [00:55<15:19,  1.83s/it]predicting train subjects:   6%|▌         | 31/532 [00:57<15:17,  1.83s/it]predicting train subjects:   6%|▌         | 32/532 [00:59<15:20,  1.84s/it]predicting train subjects:   6%|▌         | 33/532 [01:00<14:39,  1.76s/it]predicting train subjects:   6%|▋         | 34/532 [01:02<15:36,  1.88s/it]predicting train subjects:   7%|▋         | 35/532 [01:04<15:22,  1.86s/it]predicting train subjects:   7%|▋         | 36/532 [01:06<15:53,  1.92s/it]predicting train subjects:   7%|▋         | 37/532 [01:08<15:40,  1.90s/it]predicting train subjects:   7%|▋         | 38/532 [01:10<16:00,  1.94s/it]predicting train subjects:   7%|▋         | 39/532 [01:12<15:37,  1.90s/it]predicting train subjects:   8%|▊         | 40/532 [01:14<15:00,  1.83s/it]predicting train subjects:   8%|▊         | 41/532 [01:16<15:21,  1.88s/it]predicting train subjects:   8%|▊         | 42/532 [01:17<15:20,  1.88s/it]predicting train subjects:   8%|▊         | 43/532 [01:19<14:44,  1.81s/it]predicting train subjects:   8%|▊         | 44/532 [01:21<14:00,  1.72s/it]predicting train subjects:   8%|▊         | 45/532 [01:22<13:52,  1.71s/it]predicting train subjects:   9%|▊         | 46/532 [01:24<14:13,  1.76s/it]predicting train subjects:   9%|▉         | 47/532 [01:26<15:24,  1.91s/it]predicting train subjects:   9%|▉         | 48/532 [01:28<15:42,  1.95s/it]predicting train subjects:   9%|▉         | 49/532 [01:30<14:51,  1.85s/it]predicting train subjects:   9%|▉         | 50/532 [01:32<15:53,  1.98s/it]predicting train subjects:  10%|▉         | 51/532 [01:34<15:35,  1.94s/it]predicting train subjects:  10%|▉         | 52/532 [01:36<15:32,  1.94s/it]predicting train subjects:  10%|▉         | 53/532 [01:38<14:57,  1.87s/it]predicting train subjects:  10%|█         | 54/532 [01:40<15:46,  1.98s/it]predicting train subjects:  10%|█         | 55/532 [01:42<15:30,  1.95s/it]predicting train subjects:  11%|█         | 56/532 [01:44<15:20,  1.93s/it]predicting train subjects:  11%|█         | 57/532 [01:46<15:09,  1.91s/it]predicting train subjects:  11%|█         | 58/532 [01:48<14:57,  1.89s/it]predicting train subjects:  11%|█         | 59/532 [01:50<15:47,  2.00s/it]predicting train subjects:  11%|█▏        | 60/532 [01:51<14:27,  1.84s/it]predicting train subjects:  11%|█▏        | 61/532 [01:53<13:59,  1.78s/it]predicting train subjects:  12%|█▏        | 62/532 [01:55<14:42,  1.88s/it]predicting train subjects:  12%|█▏        | 63/532 [01:57<15:11,  1.94s/it]predicting train subjects:  12%|█▏        | 64/532 [01:59<14:19,  1.84s/it]predicting train subjects:  12%|█▏        | 65/532 [02:01<14:24,  1.85s/it]predicting train subjects:  12%|█▏        | 66/532 [02:03<15:42,  2.02s/it]predicting train subjects:  13%|█▎        | 67/532 [02:05<16:04,  2.07s/it]predicting train subjects:  13%|█▎        | 68/532 [02:07<15:35,  2.02s/it]predicting train subjects:  13%|█▎        | 69/532 [02:09<15:27,  2.00s/it]predicting train subjects:  13%|█▎        | 70/532 [02:11<14:47,  1.92s/it]predicting train subjects:  13%|█▎        | 71/532 [02:12<14:15,  1.86s/it]predicting train subjects:  14%|█▎        | 72/532 [02:14<13:29,  1.76s/it]predicting train subjects:  14%|█▎        | 73/532 [02:16<13:43,  1.79s/it]predicting train subjects:  14%|█▍        | 74/532 [02:18<14:58,  1.96s/it]predicting train subjects:  14%|█▍        | 75/532 [02:21<17:04,  2.24s/it]predicting train subjects:  14%|█▍        | 76/532 [02:23<15:52,  2.09s/it]predicting train subjects:  14%|█▍        | 77/532 [02:25<15:31,  2.05s/it]predicting train subjects:  15%|█▍        | 78/532 [02:27<15:06,  2.00s/it]predicting train subjects:  15%|█▍        | 79/532 [02:29<14:50,  1.97s/it]predicting train subjects:  15%|█▌        | 80/532 [02:30<14:39,  1.95s/it]predicting train subjects:  15%|█▌        | 81/532 [02:32<14:42,  1.96s/it]predicting train subjects:  15%|█▌        | 82/532 [02:34<14:23,  1.92s/it]predicting train subjects:  16%|█▌        | 83/532 [02:36<13:55,  1.86s/it]predicting train subjects:  16%|█▌        | 84/532 [02:38<13:18,  1.78s/it]predicting train subjects:  16%|█▌        | 85/532 [02:39<12:50,  1.72s/it]predicting train subjects:  16%|█▌        | 86/532 [02:41<12:31,  1.69s/it]predicting train subjects:  16%|█▋        | 87/532 [02:43<12:37,  1.70s/it]predicting train subjects:  17%|█▋        | 88/532 [02:44<12:26,  1.68s/it]predicting train subjects:  17%|█▋        | 89/532 [02:46<12:39,  1.71s/it]predicting train subjects:  17%|█▋        | 90/532 [02:48<12:33,  1.70s/it]predicting train subjects:  17%|█▋        | 91/532 [02:49<12:38,  1.72s/it]predicting train subjects:  17%|█▋        | 92/532 [02:51<12:49,  1.75s/it]predicting train subjects:  17%|█▋        | 93/532 [02:53<12:47,  1.75s/it]predicting train subjects:  18%|█▊        | 94/532 [02:55<12:44,  1.75s/it]predicting train subjects:  18%|█▊        | 95/532 [02:57<13:36,  1.87s/it]predicting train subjects:  18%|█▊        | 96/532 [02:59<13:56,  1.92s/it]predicting train subjects:  18%|█▊        | 97/532 [03:01<14:24,  1.99s/it]predicting train subjects:  18%|█▊        | 98/532 [03:03<14:34,  2.02s/it]predicting train subjects:  19%|█▊        | 99/532 [03:05<15:06,  2.09s/it]predicting train subjects:  19%|█▉        | 100/532 [03:08<15:20,  2.13s/it]predicting train subjects:  19%|█▉        | 101/532 [03:09<14:05,  1.96s/it]predicting train subjects:  19%|█▉        | 102/532 [03:11<13:08,  1.83s/it]predicting train subjects:  19%|█▉        | 103/532 [03:12<12:32,  1.75s/it]predicting train subjects:  20%|█▉        | 104/532 [03:14<12:04,  1.69s/it]predicting train subjects:  20%|█▉        | 105/532 [03:15<11:49,  1.66s/it]predicting train subjects:  20%|█▉        | 106/532 [03:17<11:45,  1.66s/it]predicting train subjects:  20%|██        | 107/532 [03:19<11:31,  1.63s/it]predicting train subjects:  20%|██        | 108/532 [03:20<11:22,  1.61s/it]predicting train subjects:  20%|██        | 109/532 [03:22<11:14,  1.60s/it]predicting train subjects:  21%|██        | 110/532 [03:23<11:03,  1.57s/it]predicting train subjects:  21%|██        | 111/532 [03:25<11:00,  1.57s/it]predicting train subjects:  21%|██        | 112/532 [03:26<10:50,  1.55s/it]predicting train subjects:  21%|██        | 113/532 [03:28<11:27,  1.64s/it]predicting train subjects:  21%|██▏       | 114/532 [03:30<12:03,  1.73s/it]predicting train subjects:  22%|██▏       | 115/532 [03:32<12:19,  1.77s/it]predicting train subjects:  22%|██▏       | 116/532 [03:34<12:38,  1.82s/it]predicting train subjects:  22%|██▏       | 117/532 [03:36<12:45,  1.84s/it]predicting train subjects:  22%|██▏       | 118/532 [03:38<12:51,  1.86s/it]predicting train subjects:  22%|██▏       | 119/532 [03:40<12:43,  1.85s/it]predicting train subjects:  23%|██▎       | 120/532 [03:41<12:32,  1.83s/it]predicting train subjects:  23%|██▎       | 121/532 [03:43<12:28,  1.82s/it]predicting train subjects:  23%|██▎       | 122/532 [03:45<12:46,  1.87s/it]predicting train subjects:  23%|██▎       | 123/532 [03:47<12:44,  1.87s/it]predicting train subjects:  23%|██▎       | 124/532 [03:49<12:45,  1.88s/it]predicting train subjects:  23%|██▎       | 125/532 [03:51<12:57,  1.91s/it]predicting train subjects:  24%|██▎       | 126/532 [03:53<12:58,  1.92s/it]predicting train subjects:  24%|██▍       | 127/532 [03:55<13:20,  1.98s/it]predicting train subjects:  24%|██▍       | 128/532 [03:57<13:12,  1.96s/it]predicting train subjects:  24%|██▍       | 129/532 [03:59<13:11,  1.97s/it]predicting train subjects:  24%|██▍       | 130/532 [04:01<13:22,  2.00s/it]predicting train subjects:  25%|██▍       | 131/532 [04:03<14:03,  2.10s/it]predicting train subjects:  25%|██▍       | 132/532 [04:06<14:39,  2.20s/it]predicting train subjects:  25%|██▌       | 133/532 [04:08<14:50,  2.23s/it]predicting train subjects:  25%|██▌       | 134/532 [04:10<15:03,  2.27s/it]predicting train subjects:  25%|██▌       | 135/532 [04:13<15:10,  2.29s/it]predicting train subjects:  26%|██▌       | 136/532 [04:15<15:13,  2.31s/it]predicting train subjects:  26%|██▌       | 137/532 [04:17<15:17,  2.32s/it]predicting train subjects:  26%|██▌       | 138/532 [04:20<15:17,  2.33s/it]predicting train subjects:  26%|██▌       | 139/532 [04:22<15:17,  2.34s/it]predicting train subjects:  26%|██▋       | 140/532 [04:24<15:11,  2.32s/it]predicting train subjects:  27%|██▋       | 141/532 [04:27<15:11,  2.33s/it]predicting train subjects:  27%|██▋       | 142/532 [04:29<15:14,  2.34s/it]predicting train subjects:  27%|██▋       | 143/532 [04:31<13:51,  2.14s/it]predicting train subjects:  27%|██▋       | 144/532 [04:32<12:47,  1.98s/it]predicting train subjects:  27%|██▋       | 145/532 [04:34<12:09,  1.88s/it]predicting train subjects:  27%|██▋       | 146/532 [04:36<11:46,  1.83s/it]predicting train subjects:  28%|██▊       | 147/532 [04:37<11:31,  1.80s/it]predicting train subjects:  28%|██▊       | 148/532 [04:39<11:19,  1.77s/it]predicting train subjects:  28%|██▊       | 149/532 [04:41<11:22,  1.78s/it]predicting train subjects:  28%|██▊       | 150/532 [04:43<11:28,  1.80s/it]predicting train subjects:  28%|██▊       | 151/532 [04:45<11:26,  1.80s/it]predicting train subjects:  29%|██▊       | 152/532 [04:46<11:24,  1.80s/it]predicting train subjects:  29%|██▉       | 153/532 [04:48<11:23,  1.80s/it]predicting train subjects:  29%|██▉       | 154/532 [04:50<11:17,  1.79s/it]predicting train subjects:  29%|██▉       | 155/532 [04:52<12:20,  1.97s/it]predicting train subjects:  29%|██▉       | 156/532 [04:55<13:05,  2.09s/it]predicting train subjects:  30%|██▉       | 157/532 [04:57<13:56,  2.23s/it]predicting train subjects:  30%|██▉       | 158/532 [05:00<14:26,  2.32s/it]predicting train subjects:  30%|██▉       | 159/532 [05:02<14:36,  2.35s/it]predicting train subjects:  30%|███       | 160/532 [05:05<14:55,  2.41s/it]predicting train subjects:  30%|███       | 161/532 [05:07<13:45,  2.23s/it]predicting train subjects:  30%|███       | 162/532 [05:08<13:02,  2.11s/it]predicting train subjects:  31%|███       | 163/532 [05:10<12:15,  1.99s/it]predicting train subjects:  31%|███       | 164/532 [05:12<11:49,  1.93s/it]predicting train subjects:  31%|███       | 165/532 [05:14<11:25,  1.87s/it]predicting train subjects:  31%|███       | 166/532 [05:15<11:10,  1.83s/it]predicting train subjects:  31%|███▏      | 167/532 [05:17<11:22,  1.87s/it]predicting train subjects:  32%|███▏      | 168/532 [05:19<11:25,  1.88s/it]predicting train subjects:  32%|███▏      | 169/532 [05:21<11:25,  1.89s/it]predicting train subjects:  32%|███▏      | 170/532 [05:23<11:17,  1.87s/it]predicting train subjects:  32%|███▏      | 171/532 [05:25<11:16,  1.87s/it]predicting train subjects:  32%|███▏      | 172/532 [05:27<11:10,  1.86s/it]predicting train subjects:  33%|███▎      | 173/532 [05:28<10:49,  1.81s/it]predicting train subjects:  33%|███▎      | 174/532 [05:30<10:33,  1.77s/it]predicting train subjects:  33%|███▎      | 175/532 [05:32<10:18,  1.73s/it]predicting train subjects:  33%|███▎      | 176/532 [05:33<10:10,  1.72s/it]predicting train subjects:  33%|███▎      | 177/532 [05:35<10:02,  1.70s/it]predicting train subjects:  33%|███▎      | 178/532 [05:37<09:57,  1.69s/it]predicting train subjects:  34%|███▎      | 179/532 [05:39<10:05,  1.71s/it]predicting train subjects:  34%|███▍      | 180/532 [05:40<10:09,  1.73s/it]predicting train subjects:  34%|███▍      | 181/532 [05:42<10:18,  1.76s/it]predicting train subjects:  34%|███▍      | 182/532 [05:44<10:11,  1.75s/it]predicting train subjects:  34%|███▍      | 183/532 [05:45<09:59,  1.72s/it]predicting train subjects:  35%|███▍      | 184/532 [05:47<10:04,  1.74s/it]predicting train subjects:  35%|███▍      | 185/532 [05:49<09:57,  1.72s/it]predicting train subjects:  35%|███▍      | 186/532 [05:51<09:55,  1.72s/it]predicting train subjects:  35%|███▌      | 187/532 [05:53<10:07,  1.76s/it]predicting train subjects:  35%|███▌      | 188/532 [05:54<10:09,  1.77s/it]predicting train subjects:  36%|███▌      | 189/532 [05:56<10:00,  1.75s/it]predicting train subjects:  36%|███▌      | 190/532 [05:58<10:07,  1.78s/it]predicting train subjects:  36%|███▌      | 191/532 [06:00<11:09,  1.96s/it]predicting train subjects:  36%|███▌      | 192/532 [06:03<11:52,  2.10s/it]predicting train subjects:  36%|███▋      | 193/532 [06:05<12:27,  2.20s/it]predicting train subjects:  36%|███▋      | 194/532 [06:08<12:49,  2.28s/it]predicting train subjects:  37%|███▋      | 195/532 [06:10<12:55,  2.30s/it]predicting train subjects:  37%|███▋      | 196/532 [06:12<13:00,  2.32s/it]predicting train subjects:  37%|███▋      | 197/532 [06:14<12:37,  2.26s/it]predicting train subjects:  37%|███▋      | 198/532 [06:17<12:19,  2.22s/it]predicting train subjects:  37%|███▋      | 199/532 [06:19<12:00,  2.16s/it]predicting train subjects:  38%|███▊      | 200/532 [06:21<11:41,  2.11s/it]predicting train subjects:  38%|███▊      | 201/532 [06:23<11:32,  2.09s/it]predicting train subjects:  38%|███▊      | 202/532 [06:25<11:32,  2.10s/it]predicting train subjects:  38%|███▊      | 203/532 [06:27<11:02,  2.01s/it]predicting train subjects:  38%|███▊      | 204/532 [06:28<10:33,  1.93s/it]predicting train subjects:  39%|███▊      | 205/532 [06:30<10:19,  1.90s/it]predicting train subjects:  39%|███▊      | 206/532 [06:32<10:02,  1.85s/it]predicting train subjects:  39%|███▉      | 207/532 [06:34<09:49,  1.81s/it]predicting train subjects:  39%|███▉      | 208/532 [06:35<09:37,  1.78s/it]predicting train subjects:  39%|███▉      | 209/532 [06:37<09:12,  1.71s/it]predicting train subjects:  39%|███▉      | 210/532 [06:38<09:04,  1.69s/it]predicting train subjects:  40%|███▉      | 211/532 [06:40<08:47,  1.64s/it]predicting train subjects:  40%|███▉      | 212/532 [06:41<08:34,  1.61s/it]predicting train subjects:  40%|████      | 213/532 [06:43<08:30,  1.60s/it]predicting train subjects:  40%|████      | 214/532 [06:45<08:22,  1.58s/it]predicting train subjects:  40%|████      | 215/532 [06:47<09:28,  1.79s/it]predicting train subjects:  41%|████      | 216/532 [06:49<10:11,  1.94s/it]predicting train subjects:  41%|████      | 217/532 [06:51<10:41,  2.04s/it]predicting train subjects:  41%|████      | 218/532 [06:54<11:02,  2.11s/it]predicting train subjects:  41%|████      | 219/532 [06:56<11:20,  2.17s/it]predicting train subjects:  41%|████▏     | 220/532 [06:58<11:25,  2.20s/it]predicting train subjects:  42%|████▏     | 221/532 [07:00<10:20,  2.00s/it]predicting train subjects:  42%|████▏     | 222/532 [07:01<09:32,  1.85s/it]predicting train subjects:  42%|████▏     | 223/532 [07:03<08:58,  1.74s/it]predicting train subjects:  42%|████▏     | 224/532 [07:04<08:45,  1.71s/it]predicting train subjects:  42%|████▏     | 225/532 [07:06<08:31,  1.67s/it]predicting train subjects:  42%|████▏     | 226/532 [07:07<08:12,  1.61s/it]predicting train subjects:  43%|████▎     | 227/532 [07:09<08:01,  1.58s/it]predicting train subjects:  43%|████▎     | 228/532 [07:10<07:51,  1.55s/it]predicting train subjects:  43%|████▎     | 229/532 [07:12<07:45,  1.54s/it]predicting train subjects:  43%|████▎     | 230/532 [07:14<07:42,  1.53s/it]predicting train subjects:  43%|████▎     | 231/532 [07:15<07:39,  1.53s/it]predicting train subjects:  44%|████▎     | 232/532 [07:17<07:40,  1.53s/it]predicting train subjects:  44%|████▍     | 233/532 [07:18<07:54,  1.59s/it]predicting train subjects:  44%|████▍     | 234/532 [07:20<08:07,  1.64s/it]predicting train subjects:  44%|████▍     | 235/532 [07:22<08:17,  1.68s/it]predicting train subjects:  44%|████▍     | 236/532 [07:24<08:23,  1.70s/it]predicting train subjects:  45%|████▍     | 237/532 [07:25<08:27,  1.72s/it]predicting train subjects:  45%|████▍     | 238/532 [07:27<08:32,  1.74s/it]predicting train subjects:  45%|████▍     | 239/532 [07:29<08:44,  1.79s/it]predicting train subjects:  45%|████▌     | 240/532 [07:31<08:57,  1.84s/it]predicting train subjects:  45%|████▌     | 241/532 [07:33<09:08,  1.88s/it]predicting train subjects:  45%|████▌     | 242/532 [07:35<09:10,  1.90s/it]predicting train subjects:  46%|████▌     | 243/532 [07:37<09:16,  1.93s/it]predicting train subjects:  46%|████▌     | 244/532 [07:39<09:13,  1.92s/it]predicting train subjects:  46%|████▌     | 245/532 [07:40<08:37,  1.80s/it]predicting train subjects:  46%|████▌     | 246/532 [07:42<08:08,  1.71s/it]predicting train subjects:  46%|████▋     | 247/532 [07:43<07:46,  1.64s/it]predicting train subjects:  47%|████▋     | 248/532 [07:45<07:31,  1.59s/it]predicting train subjects:  47%|████▋     | 249/532 [07:46<07:19,  1.55s/it]predicting train subjects:  47%|████▋     | 250/532 [07:48<07:12,  1.53s/it]predicting train subjects:  47%|████▋     | 251/532 [07:49<07:17,  1.56s/it]predicting train subjects:  47%|████▋     | 252/532 [07:51<07:17,  1.56s/it]predicting train subjects:  48%|████▊     | 253/532 [07:53<07:20,  1.58s/it]predicting train subjects:  48%|████▊     | 254/532 [07:54<07:21,  1.59s/it]predicting train subjects:  48%|████▊     | 255/532 [07:56<07:24,  1.61s/it]predicting train subjects:  48%|████▊     | 256/532 [07:57<07:17,  1.58s/it]predicting train subjects:  48%|████▊     | 257/532 [07:59<07:52,  1.72s/it]predicting train subjects:  48%|████▊     | 258/532 [08:01<08:16,  1.81s/it]predicting train subjects:  49%|████▊     | 259/532 [08:03<08:34,  1.88s/it]predicting train subjects:  49%|████▉     | 260/532 [08:05<08:43,  1.93s/it]predicting train subjects:  49%|████▉     | 261/532 [08:08<08:52,  1.96s/it]predicting train subjects:  49%|████▉     | 262/532 [08:10<09:02,  2.01s/it]predicting train subjects:  49%|████▉     | 263/532 [08:11<08:23,  1.87s/it]predicting train subjects:  50%|████▉     | 264/532 [08:13<07:47,  1.75s/it]predicting train subjects:  50%|████▉     | 265/532 [08:14<07:23,  1.66s/it]predicting train subjects:  50%|█████     | 266/532 [08:16<07:03,  1.59s/it]predicting train subjects:  50%|█████     | 267/532 [08:17<06:49,  1.55s/it]predicting train subjects:  50%|█████     | 268/532 [08:18<06:46,  1.54s/it]predicting train subjects:  51%|█████     | 269/532 [08:20<07:10,  1.64s/it]predicting train subjects:  51%|█████     | 270/532 [08:22<07:20,  1.68s/it]predicting train subjects:  51%|█████     | 271/532 [08:24<07:28,  1.72s/it]predicting train subjects:  51%|█████     | 272/532 [08:26<07:36,  1.75s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:28<07:38,  1.77s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:30<07:54,  1.84s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:32<08:20,  1.95s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:34<08:39,  2.03s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:36<08:56,  2.11s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:39<09:05,  2.15s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:41<09:09,  2.17s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:43<09:11,  2.19s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:45<09:04,  2.17s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:47<08:57,  2.15s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:49<08:53,  2.14s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:51<08:49,  2.14s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:54<08:45,  2.13s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:56<08:48,  2.15s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:57<08:12,  2.01s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:59<07:43,  1.90s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:01<07:17,  1.80s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:02<07:04,  1.76s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:04<06:59,  1.74s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:06<06:52,  1.72s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:08<07:04,  1.78s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:10<07:15,  1.83s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:12<07:37,  1.93s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:14<07:36,  1.93s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:16<07:38,  1.95s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:18<07:44,  1.98s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:19<07:14,  1.86s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:21<06:51,  1.78s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:23<06:44,  1.75s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:24<06:36,  1.72s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:26<06:27,  1.69s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:28<06:29,  1.71s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:30<07:11,  1.90s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:32<07:43,  2.05s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:35<07:56,  2.12s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:37<08:04,  2.16s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:39<08:19,  2.24s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:42<08:27,  2.29s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:45<09:21,  2.54s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:48<10:02,  2.74s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:51<10:16,  2.81s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:54<10:27,  2.88s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:57<10:27,  2.89s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:00<10:29,  2.91s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:02<09:11,  2.56s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:03<08:11,  2.30s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:05<07:33,  2.13s/it]predicting train subjects:  60%|██████    | 320/532 [10:07<07:08,  2.02s/it]predicting train subjects:  60%|██████    | 321/532 [10:09<06:46,  1.93s/it]predicting train subjects:  61%|██████    | 322/532 [10:10<06:31,  1.87s/it]predicting train subjects:  61%|██████    | 323/532 [10:13<07:07,  2.05s/it]predicting train subjects:  61%|██████    | 324/532 [10:15<07:31,  2.17s/it]predicting train subjects:  61%|██████    | 325/532 [10:18<07:46,  2.25s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:20<07:58,  2.33s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:23<08:08,  2.38s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:25<08:11,  2.41s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:27<07:39,  2.26s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:29<07:10,  2.13s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:31<06:51,  2.04s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:33<06:40,  2.00s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:35<06:29,  1.96s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:36<06:24,  1.94s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:39<06:37,  2.02s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:41<06:46,  2.07s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:43<06:59,  2.15s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:45<06:58,  2.16s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:47<06:56,  2.16s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:50<06:57,  2.17s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:51<06:20,  1.99s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:53<05:59,  1.89s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:55<05:48,  1.84s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:56<05:40,  1.81s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:58<05:28,  1.76s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:00<05:23,  1.74s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:02<05:34,  1.81s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:04<05:39,  1.84s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:06<05:43,  1.88s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:07<05:43,  1.89s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:09<05:41,  1.89s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:11<05:40,  1.89s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:13<05:38,  1.89s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:15<05:35,  1.88s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:17<05:32,  1.88s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:19<05:28,  1.86s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:21<05:24,  1.86s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:23<05:28,  1.89s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:24<05:18,  1.84s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:26<05:13,  1.82s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:28<05:05,  1.78s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:29<04:53,  1.73s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:31<04:52,  1.73s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:33<04:50,  1.73s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:34<04:43,  1.70s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:36<04:41,  1.70s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:38<04:38,  1.69s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:39<04:33,  1.67s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:41<04:32,  1.67s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:43<04:27,  1.65s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:45<05:00,  1.87s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:47<05:17,  1.99s/it]predicting train subjects:  70%|███████   | 373/532 [11:50<05:32,  2.09s/it]predicting train subjects:  70%|███████   | 374/532 [11:52<05:38,  2.14s/it]predicting train subjects:  70%|███████   | 375/532 [11:54<05:42,  2.18s/it]predicting train subjects:  71%|███████   | 376/532 [11:57<05:50,  2.25s/it]predicting train subjects:  71%|███████   | 377/532 [11:58<05:31,  2.14s/it]predicting train subjects:  71%|███████   | 378/532 [12:00<05:21,  2.09s/it]predicting train subjects:  71%|███████   | 379/532 [12:02<05:13,  2.05s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:04<05:03,  2.00s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:06<05:00,  1.99s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:08<04:55,  1.97s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:10<04:57,  2.00s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:12<04:54,  1.99s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:14<04:49,  1.97s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:16<04:48,  1.98s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:18<04:45,  1.97s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:20<04:40,  1.95s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:22<04:45,  2.00s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:24<04:49,  2.04s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:26<04:48,  2.05s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:28<04:45,  2.04s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:31<04:51,  2.09s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:33<04:51,  2.12s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:35<04:43,  2.07s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:37<04:37,  2.04s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:39<04:32,  2.02s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:41<04:26,  1.99s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:42<04:19,  1.95s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:44<04:16,  1.95s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:47<04:24,  2.02s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:49<04:27,  2.06s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:51<04:28,  2.08s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:53<04:29,  2.10s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:55<04:31,  2.14s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:57<04:25,  2.10s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:59<04:11,  2.02s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:01<04:03,  1.97s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:03<03:56,  1.93s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:05<03:53,  1.91s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:06<03:50,  1.90s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:08<03:47,  1.90s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:10<03:38,  1.83s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:12<03:39,  1.86s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:14<03:38,  1.86s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:16<03:32,  1.83s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:17<03:28,  1.81s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:19<03:26,  1.81s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:21<03:31,  1.88s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:23<03:35,  1.93s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:25<03:41,  1.99s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:27<03:39,  2.00s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:30<03:42,  2.04s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:31<03:36,  2.01s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:34<03:37,  2.03s/it]predicting train subjects:  80%|████████  | 426/532 [13:36<03:35,  2.04s/it]predicting train subjects:  80%|████████  | 427/532 [13:38<03:35,  2.05s/it]predicting train subjects:  80%|████████  | 428/532 [13:40<03:31,  2.03s/it]predicting train subjects:  81%|████████  | 429/532 [13:42<03:31,  2.05s/it]predicting train subjects:  81%|████████  | 430/532 [13:44<03:29,  2.06s/it]predicting train subjects:  81%|████████  | 431/532 [13:46<03:31,  2.09s/it]predicting train subjects:  81%|████████  | 432/532 [13:48<03:31,  2.12s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:50<03:29,  2.12s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:52<03:28,  2.13s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:54<03:24,  2.11s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:57<03:25,  2.14s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:58<03:05,  1.95s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:00<02:50,  1.81s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:01<02:42,  1.74s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:03<02:34,  1.68s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:04<02:28,  1.63s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:06<02:24,  1.61s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:07<02:18,  1.56s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:09<02:14,  1.53s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:10<02:09,  1.48s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:12<02:06,  1.47s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:13<02:02,  1.44s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:14<01:59,  1.43s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:16<02:03,  1.49s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:18<02:03,  1.51s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:19<02:05,  1.55s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:21<02:07,  1.59s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:23<02:06,  1.61s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:24<02:05,  1.60s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:26<02:09,  1.68s/it]predicting train subjects:  86%|████████▌ | 456/532 [14:28<02:11,  1.74s/it]predicting train subjects:  86%|████████▌ | 457/532 [14:30<02:13,  1.78s/it]predicting train subjects:  86%|████████▌ | 458/532 [14:32<02:15,  1.83s/it]predicting train subjects:  86%|████████▋ | 459/532 [14:34<02:16,  1.87s/it]predicting train subjects:  86%|████████▋ | 460/532 [14:36<02:14,  1.86s/it]predicting train subjects:  87%|████████▋ | 461/532 [14:38<02:21,  2.00s/it]predicting train subjects:  87%|████████▋ | 462/532 [14:40<02:26,  2.09s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:42<02:27,  2.13s/it]predicting train subjects:  87%|████████▋ | 464/532 [14:45<02:27,  2.17s/it]predicting train subjects:  87%|████████▋ | 465/532 [14:47<02:25,  2.18s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:49<02:24,  2.18s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:51<02:12,  2.04s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:53<02:06,  1.97s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:54<01:59,  1.90s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:56<01:55,  1.87s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:58<01:51,  1.83s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:00<01:49,  1.82s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:01<01:48,  1.84s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:03<01:48,  1.87s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:05<01:46,  1.87s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:07<01:45,  1.88s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:09<01:44,  1.89s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:11<01:44,  1.94s/it]predicting train subjects:  90%|█████████ | 479/532 [15:13<01:38,  1.85s/it]predicting train subjects:  90%|█████████ | 480/532 [15:15<01:33,  1.80s/it]predicting train subjects:  90%|█████████ | 481/532 [15:16<01:29,  1.76s/it]predicting train subjects:  91%|█████████ | 482/532 [15:18<01:26,  1.73s/it]predicting train subjects:  91%|█████████ | 483/532 [15:20<01:24,  1.72s/it]predicting train subjects:  91%|█████████ | 484/532 [15:21<01:22,  1.71s/it]predicting train subjects:  91%|█████████ | 485/532 [15:23<01:27,  1.86s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:26<01:29,  1.95s/it]predicting train subjects:  92%|█████████▏| 487/532 [15:28<01:30,  2.02s/it]predicting train subjects:  92%|█████████▏| 488/532 [15:30<01:30,  2.06s/it]predicting train subjects:  92%|█████████▏| 489/532 [15:32<01:31,  2.12s/it]predicting train subjects:  92%|█████████▏| 490/532 [15:34<01:29,  2.14s/it]predicting train subjects:  92%|█████████▏| 491/532 [15:36<01:23,  2.03s/it]predicting train subjects:  92%|█████████▏| 492/532 [15:38<01:18,  1.95s/it]predicting train subjects:  93%|█████████▎| 493/532 [15:40<01:13,  1.89s/it]predicting train subjects:  93%|█████████▎| 494/532 [15:41<01:10,  1.87s/it]predicting train subjects:  93%|█████████▎| 495/532 [15:43<01:08,  1.84s/it]predicting train subjects:  93%|█████████▎| 496/532 [15:45<01:06,  1.84s/it]predicting train subjects:  93%|█████████▎| 497/532 [15:47<01:05,  1.86s/it]predicting train subjects:  94%|█████████▎| 498/532 [15:49<01:04,  1.90s/it]predicting train subjects:  94%|█████████▍| 499/532 [15:51<01:02,  1.90s/it]predicting train subjects:  94%|█████████▍| 500/532 [15:53<01:00,  1.88s/it]predicting train subjects:  94%|█████████▍| 501/532 [15:55<00:58,  1.88s/it]predicting train subjects:  94%|█████████▍| 502/532 [15:56<00:56,  1.89s/it]predicting train subjects:  95%|█████████▍| 503/532 [15:58<00:53,  1.84s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:00<00:50,  1.79s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:02<00:48,  1.78s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:03<00:45,  1.75s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:05<00:43,  1.75s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:07<00:41,  1.73s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:09<00:42,  1.87s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:11<00:43,  1.96s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:13<00:42,  2.01s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:15<00:41,  2.07s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:18<00:39,  2.10s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:20<00:37,  2.11s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:21<00:33,  1.99s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:23<00:30,  1.93s/it]predicting train subjects:  97%|█████████▋| 517/532 [16:25<00:28,  1.88s/it]predicting train subjects:  97%|█████████▋| 518/532 [16:27<00:25,  1.86s/it]predicting train subjects:  98%|█████████▊| 519/532 [16:29<00:24,  1.85s/it]predicting train subjects:  98%|█████████▊| 520/532 [16:30<00:22,  1.85s/it]predicting train subjects:  98%|█████████▊| 521/532 [16:32<00:20,  1.86s/it]predicting train subjects:  98%|█████████▊| 522/532 [16:34<00:19,  1.90s/it]predicting train subjects:  98%|█████████▊| 523/532 [16:37<00:17,  1.98s/it]predicting train subjects:  98%|█████████▊| 524/532 [16:38<00:15,  1.95s/it]predicting train subjects:  99%|█████████▊| 525/532 [16:40<00:13,  1.94s/it]predicting train subjects:  99%|█████████▉| 526/532 [16:42<00:11,  1.96s/it]predicting train subjects:  99%|█████████▉| 527/532 [16:44<00:09,  1.91s/it]predicting train subjects:  99%|█████████▉| 528/532 [16:46<00:07,  1.86s/it]predicting train subjects:  99%|█████████▉| 529/532 [16:48<00:05,  1.83s/it]predicting train subjects: 100%|█████████▉| 530/532 [16:49<00:03,  1.81s/it]predicting train subjects: 100%|█████████▉| 531/532 [16:51<00:01,  1.79s/it]predicting train subjects: 100%|██████████| 532/532 [16:53<00:00,  1.76s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<13:15,  1.50s/it]Loading train:   0%|          | 2/532 [00:02<12:15,  1.39s/it]Loading train:   1%|          | 3/532 [00:04<12:24,  1.41s/it]Loading train:   1%|          | 4/532 [00:05<11:43,  1.33s/it]Loading train:   1%|          | 5/532 [00:06<11:55,  1.36s/it]Loading train:   1%|          | 6/532 [00:07<11:18,  1.29s/it]Loading train:   1%|▏         | 7/532 [00:09<11:22,  1.30s/it]Loading train:   2%|▏         | 8/532 [00:10<11:28,  1.31s/it]Loading train:   2%|▏         | 9/532 [00:11<11:55,  1.37s/it]Loading train:   2%|▏         | 10/532 [00:12<10:53,  1.25s/it]Loading train:   2%|▏         | 11/532 [00:14<10:33,  1.22s/it]Loading train:   2%|▏         | 12/532 [00:15<10:37,  1.23s/it]Loading train:   2%|▏         | 13/532 [00:16<10:44,  1.24s/it]Loading train:   3%|▎         | 14/532 [00:17<10:14,  1.19s/it]Loading train:   3%|▎         | 15/532 [00:18<10:29,  1.22s/it]Loading train:   3%|▎         | 16/532 [00:20<10:59,  1.28s/it]Loading train:   3%|▎         | 17/532 [00:21<10:44,  1.25s/it]Loading train:   3%|▎         | 18/532 [00:23<11:29,  1.34s/it]Loading train:   4%|▎         | 19/532 [00:23<10:16,  1.20s/it]Loading train:   4%|▍         | 20/532 [00:25<10:02,  1.18s/it]Loading train:   4%|▍         | 21/532 [00:26<10:15,  1.20s/it]Loading train:   4%|▍         | 22/532 [00:27<09:52,  1.16s/it]Loading train:   4%|▍         | 23/532 [00:28<09:36,  1.13s/it]Loading train:   5%|▍         | 24/532 [00:29<09:00,  1.06s/it]Loading train:   5%|▍         | 25/532 [00:30<10:07,  1.20s/it]Loading train:   5%|▍         | 26/532 [00:32<09:53,  1.17s/it]Loading train:   5%|▌         | 27/532 [00:33<10:51,  1.29s/it]Loading train:   5%|▌         | 28/532 [00:34<10:51,  1.29s/it]Loading train:   5%|▌         | 29/532 [00:36<10:44,  1.28s/it]Loading train:   6%|▌         | 30/532 [00:37<10:11,  1.22s/it]Loading train:   6%|▌         | 31/532 [00:38<10:13,  1.22s/it]Loading train:   6%|▌         | 32/532 [00:39<09:52,  1.19s/it]Loading train:   6%|▌         | 33/532 [00:40<09:43,  1.17s/it]Loading train:   6%|▋         | 34/532 [00:42<10:27,  1.26s/it]Loading train:   7%|▋         | 35/532 [00:43<09:45,  1.18s/it]Loading train:   7%|▋         | 36/532 [00:44<09:52,  1.19s/it]Loading train:   7%|▋         | 37/532 [00:45<09:38,  1.17s/it]Loading train:   7%|▋         | 38/532 [00:47<10:32,  1.28s/it]Loading train:   7%|▋         | 39/532 [00:48<10:41,  1.30s/it]Loading train:   8%|▊         | 40/532 [00:49<10:16,  1.25s/it]Loading train:   8%|▊         | 41/532 [00:50<10:17,  1.26s/it]Loading train:   8%|▊         | 42/532 [00:52<10:32,  1.29s/it]Loading train:   8%|▊         | 43/532 [00:53<10:29,  1.29s/it]Loading train:   8%|▊         | 44/532 [00:54<10:28,  1.29s/it]Loading train:   8%|▊         | 45/532 [00:56<10:33,  1.30s/it]Loading train:   9%|▊         | 46/532 [00:57<10:43,  1.32s/it]Loading train:   9%|▉         | 47/532 [00:58<11:03,  1.37s/it]Loading train:   9%|▉         | 48/532 [00:59<10:21,  1.28s/it]Loading train:   9%|▉         | 49/532 [01:01<10:26,  1.30s/it]Loading train:   9%|▉         | 50/532 [01:02<09:58,  1.24s/it]Loading train:  10%|▉         | 51/532 [01:03<09:34,  1.19s/it]Loading train:  10%|▉         | 52/532 [01:04<09:42,  1.21s/it]Loading train:  10%|▉         | 53/532 [01:06<09:56,  1.25s/it]Loading train:  10%|█         | 54/532 [01:07<09:54,  1.24s/it]Loading train:  10%|█         | 55/532 [01:08<10:06,  1.27s/it]Loading train:  11%|█         | 56/532 [01:09<10:13,  1.29s/it]Loading train:  11%|█         | 57/532 [01:11<10:09,  1.28s/it]Loading train:  11%|█         | 58/532 [01:12<09:58,  1.26s/it]Loading train:  11%|█         | 59/532 [01:14<10:43,  1.36s/it]Loading train:  11%|█▏        | 60/532 [01:15<10:05,  1.28s/it]Loading train:  11%|█▏        | 61/532 [01:16<09:40,  1.23s/it]Loading train:  12%|█▏        | 62/532 [01:17<10:31,  1.34s/it]Loading train:  12%|█▏        | 63/532 [01:19<10:43,  1.37s/it]Loading train:  12%|█▏        | 64/532 [01:20<10:02,  1.29s/it]Loading train:  12%|█▏        | 65/532 [01:21<10:27,  1.34s/it]Loading train:  12%|█▏        | 66/532 [01:23<11:27,  1.47s/it]Loading train:  13%|█▎        | 67/532 [01:25<11:21,  1.47s/it]Loading train:  13%|█▎        | 68/532 [01:26<10:34,  1.37s/it]Loading train:  13%|█▎        | 69/532 [01:27<10:33,  1.37s/it]Loading train:  13%|█▎        | 70/532 [01:28<09:54,  1.29s/it]Loading train:  13%|█▎        | 71/532 [01:29<09:27,  1.23s/it]Loading train:  14%|█▎        | 72/532 [01:31<09:26,  1.23s/it]Loading train:  14%|█▎        | 73/532 [01:32<09:36,  1.26s/it]Loading train:  14%|█▍        | 74/532 [01:34<10:30,  1.38s/it]Loading train:  14%|█▍        | 75/532 [01:35<11:05,  1.46s/it]Loading train:  14%|█▍        | 76/532 [01:36<10:19,  1.36s/it]Loading train:  14%|█▍        | 77/532 [01:38<10:18,  1.36s/it]Loading train:  15%|█▍        | 78/532 [01:39<09:47,  1.29s/it]Loading train:  15%|█▍        | 79/532 [01:40<09:48,  1.30s/it]Loading train:  15%|█▌        | 80/532 [01:41<09:17,  1.23s/it]Loading train:  15%|█▌        | 81/532 [01:42<08:54,  1.19s/it]Loading train:  15%|█▌        | 82/532 [01:44<09:17,  1.24s/it]Loading train:  16%|█▌        | 83/532 [01:45<08:54,  1.19s/it]Loading train:  16%|█▌        | 84/532 [01:46<08:35,  1.15s/it]Loading train:  16%|█▌        | 85/532 [01:47<08:14,  1.11s/it]Loading train:  16%|█▌        | 86/532 [01:48<08:11,  1.10s/it]Loading train:  16%|█▋        | 87/532 [01:49<08:16,  1.12s/it]Loading train:  17%|█▋        | 88/532 [01:50<08:15,  1.12s/it]Loading train:  17%|█▋        | 89/532 [01:51<08:35,  1.16s/it]Loading train:  17%|█▋        | 90/532 [01:53<08:36,  1.17s/it]Loading train:  17%|█▋        | 91/532 [01:54<08:47,  1.20s/it]Loading train:  17%|█▋        | 92/532 [01:55<08:59,  1.23s/it]Loading train:  17%|█▋        | 93/532 [01:56<08:35,  1.18s/it]Loading train:  18%|█▊        | 94/532 [01:57<08:30,  1.16s/it]Loading train:  18%|█▊        | 95/532 [01:59<09:12,  1.26s/it]Loading train:  18%|█▊        | 96/532 [02:00<09:04,  1.25s/it]Loading train:  18%|█▊        | 97/532 [02:01<09:20,  1.29s/it]Loading train:  18%|█▊        | 98/532 [02:03<09:31,  1.32s/it]Loading train:  19%|█▊        | 99/532 [02:04<09:40,  1.34s/it]Loading train:  19%|█▉        | 100/532 [02:06<09:43,  1.35s/it]Loading train:  19%|█▉        | 101/532 [02:07<09:17,  1.29s/it]Loading train:  19%|█▉        | 102/532 [02:08<08:52,  1.24s/it]Loading train:  19%|█▉        | 103/532 [02:09<09:06,  1.27s/it]Loading train:  20%|█▉        | 104/532 [02:10<08:29,  1.19s/it]Loading train:  20%|█▉        | 105/532 [02:11<08:10,  1.15s/it]Loading train:  20%|█▉        | 106/532 [02:12<08:02,  1.13s/it]Loading train:  20%|██        | 107/532 [02:13<08:01,  1.13s/it]Loading train:  20%|██        | 108/532 [02:15<08:17,  1.17s/it]Loading train:  20%|██        | 109/532 [02:16<08:17,  1.18s/it]Loading train:  21%|██        | 110/532 [02:17<08:09,  1.16s/it]Loading train:  21%|██        | 111/532 [02:18<08:26,  1.20s/it]Loading train:  21%|██        | 112/532 [02:20<08:21,  1.19s/it]Loading train:  21%|██        | 113/532 [02:21<08:39,  1.24s/it]Loading train:  21%|██▏       | 114/532 [02:22<08:29,  1.22s/it]Loading train:  22%|██▏       | 115/532 [02:24<09:34,  1.38s/it]Loading train:  22%|██▏       | 116/532 [02:25<09:21,  1.35s/it]Loading train:  22%|██▏       | 117/532 [02:26<08:56,  1.29s/it]Loading train:  22%|██▏       | 118/532 [02:27<08:40,  1.26s/it]Loading train:  22%|██▏       | 119/532 [02:28<08:16,  1.20s/it]Loading train:  23%|██▎       | 120/532 [02:30<07:59,  1.16s/it]Loading train:  23%|██▎       | 121/532 [02:31<07:54,  1.16s/it]Loading train:  23%|██▎       | 122/532 [02:32<08:18,  1.22s/it]Loading train:  23%|██▎       | 123/532 [02:34<09:06,  1.34s/it]Loading train:  23%|██▎       | 124/532 [02:35<09:03,  1.33s/it]Loading train:  23%|██▎       | 125/532 [02:36<08:57,  1.32s/it]Loading train:  24%|██▎       | 126/532 [02:38<09:12,  1.36s/it]Loading train:  24%|██▍       | 127/532 [02:39<09:07,  1.35s/it]Loading train:  24%|██▍       | 128/532 [02:40<08:37,  1.28s/it]Loading train:  24%|██▍       | 129/532 [02:42<08:52,  1.32s/it]Loading train:  24%|██▍       | 130/532 [02:43<08:34,  1.28s/it]Loading train:  25%|██▍       | 131/532 [02:44<08:46,  1.31s/it]Loading train:  25%|██▍       | 132/532 [02:46<09:10,  1.38s/it]Loading train:  25%|██▌       | 133/532 [02:47<09:06,  1.37s/it]Loading train:  25%|██▌       | 134/532 [02:49<09:21,  1.41s/it]Loading train:  25%|██▌       | 135/532 [02:50<09:16,  1.40s/it]Loading train:  26%|██▌       | 136/532 [02:52<09:43,  1.47s/it]Loading train:  26%|██▌       | 137/532 [02:53<09:55,  1.51s/it]Loading train:  26%|██▌       | 138/532 [02:54<09:32,  1.45s/it]Loading train:  26%|██▌       | 139/532 [02:56<09:22,  1.43s/it]Loading train:  26%|██▋       | 140/532 [02:57<09:16,  1.42s/it]Loading train:  27%|██▋       | 141/532 [02:59<08:57,  1.37s/it]Loading train:  27%|██▋       | 142/532 [03:00<09:06,  1.40s/it]Loading train:  27%|██▋       | 143/532 [03:01<08:52,  1.37s/it]Loading train:  27%|██▋       | 144/532 [03:02<08:22,  1.30s/it]Loading train:  27%|██▋       | 145/532 [03:04<08:18,  1.29s/it]Loading train:  27%|██▋       | 146/532 [03:05<08:18,  1.29s/it]Loading train:  28%|██▊       | 147/532 [03:06<08:14,  1.28s/it]Loading train:  28%|██▊       | 148/532 [03:08<08:38,  1.35s/it]Loading train:  28%|██▊       | 149/532 [03:09<08:48,  1.38s/it]Loading train:  28%|██▊       | 150/532 [03:11<08:56,  1.41s/it]Loading train:  28%|██▊       | 151/532 [03:12<09:25,  1.48s/it]Loading train:  29%|██▊       | 152/532 [03:14<09:33,  1.51s/it]Loading train:  29%|██▉       | 153/532 [03:15<09:19,  1.48s/it]Loading train:  29%|██▉       | 154/532 [03:17<09:44,  1.55s/it]Loading train:  29%|██▉       | 155/532 [03:19<10:21,  1.65s/it]Loading train:  29%|██▉       | 156/532 [03:21<10:24,  1.66s/it]Loading train:  30%|██▉       | 157/532 [03:22<10:35,  1.70s/it]Loading train:  30%|██▉       | 158/532 [03:24<10:31,  1.69s/it]Loading train:  30%|██▉       | 159/532 [03:26<10:26,  1.68s/it]Loading train:  30%|███       | 160/532 [03:27<10:27,  1.69s/it]Loading train:  30%|███       | 161/532 [03:29<10:40,  1.73s/it]Loading train:  30%|███       | 162/532 [03:31<10:02,  1.63s/it]Loading train:  31%|███       | 163/532 [03:32<09:46,  1.59s/it]Loading train:  31%|███       | 164/532 [03:34<09:37,  1.57s/it]Loading train:  31%|███       | 165/532 [03:35<09:37,  1.57s/it]Loading train:  31%|███       | 166/532 [03:37<09:23,  1.54s/it]Loading train:  31%|███▏      | 167/532 [03:38<09:46,  1.61s/it]Loading train:  32%|███▏      | 168/532 [03:40<09:41,  1.60s/it]Loading train:  32%|███▏      | 169/532 [03:42<09:27,  1.56s/it]Loading train:  32%|███▏      | 170/532 [03:43<09:09,  1.52s/it]Loading train:  32%|███▏      | 171/532 [03:44<09:00,  1.50s/it]Loading train:  32%|███▏      | 172/532 [03:46<08:35,  1.43s/it]Loading train:  33%|███▎      | 173/532 [03:47<08:36,  1.44s/it]Loading train:  33%|███▎      | 174/532 [03:49<08:55,  1.50s/it]Loading train:  33%|███▎      | 175/532 [03:50<08:59,  1.51s/it]Loading train:  33%|███▎      | 176/532 [03:52<08:31,  1.44s/it]Loading train:  33%|███▎      | 177/532 [03:53<08:07,  1.37s/it]Loading train:  33%|███▎      | 178/532 [03:54<07:41,  1.30s/it]Loading train:  34%|███▎      | 179/532 [03:55<08:08,  1.38s/it]Loading train:  34%|███▍      | 180/532 [03:57<08:20,  1.42s/it]Loading train:  34%|███▍      | 181/532 [03:58<08:03,  1.38s/it]Loading train:  34%|███▍      | 182/532 [04:00<08:26,  1.45s/it]Loading train:  34%|███▍      | 183/532 [04:01<08:19,  1.43s/it]Loading train:  35%|███▍      | 184/532 [04:03<08:03,  1.39s/it]Loading train:  35%|███▍      | 185/532 [04:04<08:15,  1.43s/it]Loading train:  35%|███▍      | 186/532 [04:06<08:36,  1.49s/it]Loading train:  35%|███▌      | 187/532 [04:07<08:35,  1.49s/it]Loading train:  35%|███▌      | 188/532 [04:09<08:59,  1.57s/it]Loading train:  36%|███▌      | 189/532 [04:10<08:51,  1.55s/it]Loading train:  36%|███▌      | 190/532 [04:12<08:28,  1.49s/it]Loading train:  36%|███▌      | 191/532 [04:14<09:11,  1.62s/it]Loading train:  36%|███▌      | 192/532 [04:16<09:27,  1.67s/it]Loading train:  36%|███▋      | 193/532 [04:17<09:05,  1.61s/it]Loading train:  36%|███▋      | 194/532 [04:19<09:00,  1.60s/it]Loading train:  37%|███▋      | 195/532 [04:20<09:03,  1.61s/it]Loading train:  37%|███▋      | 196/532 [04:22<09:41,  1.73s/it]Loading train:  37%|███▋      | 197/532 [04:25<10:37,  1.90s/it]Loading train:  37%|███▋      | 198/532 [04:27<10:53,  1.96s/it]Loading train:  37%|███▋      | 199/532 [04:29<10:51,  1.96s/it]Loading train:  38%|███▊      | 200/532 [04:31<10:50,  1.96s/it]Loading train:  38%|███▊      | 201/532 [04:32<10:46,  1.95s/it]Loading train:  38%|███▊      | 202/532 [04:34<10:32,  1.92s/it]Loading train:  38%|███▊      | 203/532 [04:36<10:17,  1.88s/it]Loading train:  38%|███▊      | 204/532 [04:38<09:56,  1.82s/it]Loading train:  39%|███▊      | 205/532 [04:39<09:26,  1.73s/it]Loading train:  39%|███▊      | 206/532 [04:41<09:49,  1.81s/it]Loading train:  39%|███▉      | 207/532 [04:43<09:56,  1.84s/it]Loading train:  39%|███▉      | 208/532 [04:45<09:59,  1.85s/it]Loading train:  39%|███▉      | 209/532 [04:47<09:27,  1.76s/it]Loading train:  39%|███▉      | 210/532 [04:48<08:54,  1.66s/it]Loading train:  40%|███▉      | 211/532 [04:49<08:09,  1.53s/it]Loading train:  40%|███▉      | 212/532 [04:51<08:22,  1.57s/it]Loading train:  40%|████      | 213/532 [04:52<08:16,  1.55s/it]Loading train:  40%|████      | 214/532 [04:54<08:13,  1.55s/it]Loading train:  40%|████      | 215/532 [04:56<09:20,  1.77s/it]Loading train:  41%|████      | 216/532 [04:58<09:54,  1.88s/it]Loading train:  41%|████      | 217/532 [05:00<09:59,  1.90s/it]Loading train:  41%|████      | 218/532 [05:02<10:08,  1.94s/it]Loading train:  41%|████      | 219/532 [05:04<10:03,  1.93s/it]Loading train:  41%|████▏     | 220/532 [05:07<10:49,  2.08s/it]Loading train:  42%|████▏     | 221/532 [05:09<10:23,  2.00s/it]Loading train:  42%|████▏     | 222/532 [05:10<09:44,  1.89s/it]Loading train:  42%|████▏     | 223/532 [05:12<09:36,  1.86s/it]Loading train:  42%|████▏     | 224/532 [05:14<09:14,  1.80s/it]Loading train:  42%|████▏     | 225/532 [05:15<08:59,  1.76s/it]Loading train:  42%|████▏     | 226/532 [05:17<08:47,  1.72s/it]Loading train:  43%|████▎     | 227/532 [05:18<08:21,  1.65s/it]Loading train:  43%|████▎     | 228/532 [05:20<08:33,  1.69s/it]Loading train:  43%|████▎     | 229/532 [05:21<07:39,  1.52s/it]Loading train:  43%|████▎     | 230/532 [05:23<07:41,  1.53s/it]Loading train:  43%|████▎     | 231/532 [05:24<07:36,  1.52s/it]Loading train:  44%|████▎     | 232/532 [05:26<07:15,  1.45s/it]Loading train:  44%|████▍     | 233/532 [05:28<07:52,  1.58s/it]Loading train:  44%|████▍     | 234/532 [05:30<08:26,  1.70s/it]Loading train:  44%|████▍     | 235/532 [05:31<08:13,  1.66s/it]Loading train:  44%|████▍     | 236/532 [05:32<07:49,  1.58s/it]Loading train:  45%|████▍     | 237/532 [05:34<07:42,  1.57s/it]Loading train:  45%|████▍     | 238/532 [05:36<08:08,  1.66s/it]Loading train:  45%|████▍     | 239/532 [05:37<07:55,  1.62s/it]Loading train:  45%|████▌     | 240/532 [05:39<08:20,  1.71s/it]Loading train:  45%|████▌     | 241/532 [05:41<08:23,  1.73s/it]Loading train:  45%|████▌     | 242/532 [05:43<08:06,  1.68s/it]Loading train:  46%|████▌     | 243/532 [05:45<08:21,  1.74s/it]Loading train:  46%|████▌     | 244/532 [05:46<08:10,  1.70s/it]Loading train:  46%|████▌     | 245/532 [05:48<08:14,  1.72s/it]Loading train:  46%|████▌     | 246/532 [05:49<07:54,  1.66s/it]Loading train:  46%|████▋     | 247/532 [05:51<07:13,  1.52s/it]Loading train:  47%|████▋     | 248/532 [05:52<07:09,  1.51s/it]Loading train:  47%|████▋     | 249/532 [05:53<06:49,  1.45s/it]Loading train:  47%|████▋     | 250/532 [05:55<07:39,  1.63s/it]Loading train:  47%|████▋     | 251/532 [05:57<07:52,  1.68s/it]Loading train:  47%|████▋     | 252/532 [05:59<07:34,  1.62s/it]Loading train:  48%|████▊     | 253/532 [06:01<07:41,  1.65s/it]Loading train:  48%|████▊     | 254/532 [06:02<07:37,  1.65s/it]Loading train:  48%|████▊     | 255/532 [06:04<07:21,  1.59s/it]Loading train:  48%|████▊     | 256/532 [06:05<07:25,  1.62s/it]Loading train:  48%|████▊     | 257/532 [06:07<07:53,  1.72s/it]Loading train:  48%|████▊     | 258/532 [06:09<08:05,  1.77s/it]Loading train:  49%|████▊     | 259/532 [06:12<08:59,  1.98s/it]Loading train:  49%|████▉     | 260/532 [06:13<08:51,  1.95s/it]Loading train:  49%|████▉     | 261/532 [06:15<08:43,  1.93s/it]Loading train:  49%|████▉     | 262/532 [06:18<09:05,  2.02s/it]Loading train:  49%|████▉     | 263/532 [06:19<08:52,  1.98s/it]Loading train:  50%|████▉     | 264/532 [06:21<08:49,  1.97s/it]Loading train:  50%|████▉     | 265/532 [06:23<08:12,  1.84s/it]Loading train:  50%|█████     | 266/532 [06:25<07:54,  1.78s/it]Loading train:  50%|█████     | 267/532 [06:26<07:50,  1.78s/it]Loading train:  50%|█████     | 268/532 [06:28<07:19,  1.66s/it]Loading train:  51%|█████     | 269/532 [06:29<07:20,  1.67s/it]Loading train:  51%|█████     | 270/532 [06:31<07:28,  1.71s/it]Loading train:  51%|█████     | 271/532 [06:33<07:16,  1.67s/it]Loading train:  51%|█████     | 272/532 [06:34<07:08,  1.65s/it]Loading train:  51%|█████▏    | 273/532 [06:36<07:11,  1.67s/it]Loading train:  52%|█████▏    | 274/532 [06:38<06:50,  1.59s/it]Loading train:  52%|█████▏    | 275/532 [06:40<07:24,  1.73s/it]Loading train:  52%|█████▏    | 276/532 [06:42<08:06,  1.90s/it]Loading train:  52%|█████▏    | 277/532 [06:44<08:49,  2.08s/it]Loading train:  52%|█████▏    | 278/532 [06:47<09:11,  2.17s/it]Loading train:  52%|█████▏    | 279/532 [06:49<08:52,  2.10s/it]Loading train:  53%|█████▎    | 280/532 [06:51<08:55,  2.12s/it]Loading train:  53%|█████▎    | 281/532 [06:53<08:34,  2.05s/it]Loading train:  53%|█████▎    | 282/532 [06:55<08:24,  2.02s/it]Loading train:  53%|█████▎    | 283/532 [06:57<08:26,  2.04s/it]Loading train:  53%|█████▎    | 284/532 [06:59<08:04,  1.95s/it]Loading train:  54%|█████▎    | 285/532 [07:01<08:27,  2.06s/it]Loading train:  54%|█████▍    | 286/532 [07:03<08:25,  2.05s/it]Loading train:  54%|█████▍    | 287/532 [07:05<08:11,  2.01s/it]Loading train:  54%|█████▍    | 288/532 [07:07<08:06,  2.00s/it]Loading train:  54%|█████▍    | 289/532 [07:08<07:40,  1.89s/it]Loading train:  55%|█████▍    | 290/532 [07:10<07:28,  1.85s/it]Loading train:  55%|█████▍    | 291/532 [07:12<07:35,  1.89s/it]Loading train:  55%|█████▍    | 292/532 [07:14<07:22,  1.85s/it]Loading train:  55%|█████▌    | 293/532 [07:16<07:11,  1.81s/it]Loading train:  55%|█████▌    | 294/532 [07:17<07:01,  1.77s/it]Loading train:  55%|█████▌    | 295/532 [07:19<07:15,  1.84s/it]Loading train:  56%|█████▌    | 296/532 [07:21<06:52,  1.75s/it]Loading train:  56%|█████▌    | 297/532 [07:23<07:00,  1.79s/it]Loading train:  56%|█████▌    | 298/532 [07:25<07:13,  1.85s/it]Loading train:  56%|█████▌    | 299/532 [07:26<06:55,  1.78s/it]Loading train:  56%|█████▋    | 300/532 [07:28<06:34,  1.70s/it]Loading train:  57%|█████▋    | 301/532 [07:30<06:52,  1.79s/it]Loading train:  57%|█████▋    | 302/532 [07:32<06:44,  1.76s/it]Loading train:  57%|█████▋    | 303/532 [07:33<06:38,  1.74s/it]Loading train:  57%|█████▋    | 304/532 [07:35<06:36,  1.74s/it]Loading train:  57%|█████▋    | 305/532 [07:37<06:52,  1.82s/it]Loading train:  58%|█████▊    | 306/532 [07:39<06:55,  1.84s/it]Loading train:  58%|█████▊    | 307/532 [07:41<07:13,  1.93s/it]Loading train:  58%|█████▊    | 308/532 [07:43<07:43,  2.07s/it]Loading train:  58%|█████▊    | 309/532 [07:45<07:34,  2.04s/it]Loading train:  58%|█████▊    | 310/532 [07:47<07:34,  2.05s/it]Loading train:  58%|█████▊    | 311/532 [07:50<08:01,  2.18s/it]Loading train:  59%|█████▊    | 312/532 [07:52<07:39,  2.09s/it]Loading train:  59%|█████▉    | 313/532 [07:54<08:06,  2.22s/it]Loading train:  59%|█████▉    | 314/532 [07:57<08:21,  2.30s/it]Loading train:  59%|█████▉    | 315/532 [07:59<08:42,  2.41s/it]Loading train:  59%|█████▉    | 316/532 [08:02<08:47,  2.44s/it]Loading train:  60%|█████▉    | 317/532 [08:04<08:00,  2.23s/it]Loading train:  60%|█████▉    | 318/532 [08:05<07:19,  2.05s/it]Loading train:  60%|█████▉    | 319/532 [08:07<07:05,  2.00s/it]Loading train:  60%|██████    | 320/532 [08:09<06:49,  1.93s/it]Loading train:  60%|██████    | 321/532 [08:11<06:54,  1.97s/it]Loading train:  61%|██████    | 322/532 [08:13<06:46,  1.94s/it]Loading train:  61%|██████    | 323/532 [08:15<06:55,  1.99s/it]Loading train:  61%|██████    | 324/532 [08:18<07:30,  2.17s/it]Loading train:  61%|██████    | 325/532 [08:20<07:35,  2.20s/it]Loading train:  61%|██████▏   | 326/532 [08:22<07:27,  2.17s/it]Loading train:  61%|██████▏   | 327/532 [08:24<07:30,  2.20s/it]Loading train:  62%|██████▏   | 328/532 [08:27<07:35,  2.23s/it]Loading train:  62%|██████▏   | 329/532 [08:29<07:21,  2.17s/it]Loading train:  62%|██████▏   | 330/532 [08:30<06:46,  2.01s/it]Loading train:  62%|██████▏   | 331/532 [08:32<06:22,  1.90s/it]Loading train:  62%|██████▏   | 332/532 [08:34<06:04,  1.82s/it]Loading train:  63%|██████▎   | 333/532 [08:35<06:04,  1.83s/it]Loading train:  63%|██████▎   | 334/532 [08:37<05:50,  1.77s/it]Loading train:  63%|██████▎   | 335/532 [08:39<05:54,  1.80s/it]Loading train:  63%|██████▎   | 336/532 [08:41<06:03,  1.85s/it]Loading train:  63%|██████▎   | 337/532 [08:43<05:54,  1.82s/it]Loading train:  64%|██████▎   | 338/532 [08:45<06:01,  1.86s/it]Loading train:  64%|██████▎   | 339/532 [08:46<06:02,  1.88s/it]Loading train:  64%|██████▍   | 340/532 [08:48<06:08,  1.92s/it]Loading train:  64%|██████▍   | 341/532 [08:50<05:45,  1.81s/it]Loading train:  64%|██████▍   | 342/532 [08:52<05:28,  1.73s/it]Loading train:  64%|██████▍   | 343/532 [08:53<05:19,  1.69s/it]Loading train:  65%|██████▍   | 344/532 [08:55<05:05,  1.62s/it]Loading train:  65%|██████▍   | 345/532 [08:56<05:15,  1.68s/it]Loading train:  65%|██████▌   | 346/532 [08:58<05:13,  1.68s/it]Loading train:  65%|██████▌   | 347/532 [09:00<04:58,  1.61s/it]Loading train:  65%|██████▌   | 348/532 [09:01<05:01,  1.64s/it]Loading train:  66%|██████▌   | 349/532 [09:03<05:06,  1.67s/it]Loading train:  66%|██████▌   | 350/532 [09:05<04:58,  1.64s/it]Loading train:  66%|██████▌   | 351/532 [09:06<04:52,  1.61s/it]Loading train:  66%|██████▌   | 352/532 [09:08<04:41,  1.56s/it]Loading train:  66%|██████▋   | 353/532 [09:10<04:56,  1.66s/it]Loading train:  67%|██████▋   | 354/532 [09:11<05:05,  1.72s/it]Loading train:  67%|██████▋   | 355/532 [09:13<05:00,  1.70s/it]Loading train:  67%|██████▋   | 356/532 [09:15<04:48,  1.64s/it]Loading train:  67%|██████▋   | 357/532 [09:16<04:47,  1.65s/it]Loading train:  67%|██████▋   | 358/532 [09:18<04:59,  1.72s/it]Loading train:  67%|██████▋   | 359/532 [09:20<04:55,  1.71s/it]Loading train:  68%|██████▊   | 360/532 [09:21<04:29,  1.57s/it]Loading train:  68%|██████▊   | 361/532 [09:23<04:31,  1.59s/it]Loading train:  68%|██████▊   | 362/532 [09:24<04:26,  1.57s/it]Loading train:  68%|██████▊   | 363/532 [09:26<04:35,  1.63s/it]Loading train:  68%|██████▊   | 364/532 [09:28<04:49,  1.72s/it]Loading train:  69%|██████▊   | 365/532 [09:30<05:07,  1.84s/it]Loading train:  69%|██████▉   | 366/532 [09:32<05:08,  1.86s/it]Loading train:  69%|██████▉   | 367/532 [09:34<05:09,  1.88s/it]Loading train:  69%|██████▉   | 368/532 [09:36<05:07,  1.87s/it]Loading train:  69%|██████▉   | 369/532 [09:38<05:17,  1.95s/it]Loading train:  70%|██████▉   | 370/532 [09:40<05:13,  1.93s/it]Loading train:  70%|██████▉   | 371/532 [09:42<05:23,  2.01s/it]Loading train:  70%|██████▉   | 372/532 [09:44<05:26,  2.04s/it]Loading train:  70%|███████   | 373/532 [09:46<05:19,  2.01s/it]Loading train:  70%|███████   | 374/532 [09:48<05:44,  2.18s/it]Loading train:  70%|███████   | 375/532 [09:51<05:42,  2.18s/it]Loading train:  71%|███████   | 376/532 [09:53<05:55,  2.28s/it]Loading train:  71%|███████   | 377/532 [09:55<05:43,  2.21s/it]Loading train:  71%|███████   | 378/532 [09:57<05:17,  2.06s/it]Loading train:  71%|███████   | 379/532 [09:59<05:14,  2.06s/it]Loading train:  71%|███████▏  | 380/532 [10:01<05:08,  2.03s/it]Loading train:  72%|███████▏  | 381/532 [10:03<04:52,  1.94s/it]Loading train:  72%|███████▏  | 382/532 [10:05<04:47,  1.92s/it]Loading train:  72%|███████▏  | 383/532 [10:07<05:23,  2.17s/it]Loading train:  72%|███████▏  | 384/532 [10:09<04:56,  2.01s/it]Loading train:  72%|███████▏  | 385/532 [10:11<04:47,  1.96s/it]Loading train:  73%|███████▎  | 386/532 [10:13<04:40,  1.92s/it]Loading train:  73%|███████▎  | 387/532 [10:15<04:48,  1.99s/it]Loading train:  73%|███████▎  | 388/532 [10:17<04:56,  2.06s/it]Loading train:  73%|███████▎  | 389/532 [10:19<04:55,  2.07s/it]Loading train:  73%|███████▎  | 390/532 [10:22<05:14,  2.22s/it]Loading train:  73%|███████▎  | 391/532 [10:24<05:07,  2.18s/it]Loading train:  74%|███████▎  | 392/532 [10:26<04:59,  2.14s/it]Loading train:  74%|███████▍  | 393/532 [10:27<04:36,  1.99s/it]Loading train:  74%|███████▍  | 394/532 [10:30<04:45,  2.07s/it]Loading train:  74%|███████▍  | 395/532 [10:32<04:35,  2.01s/it]Loading train:  74%|███████▍  | 396/532 [10:34<04:37,  2.04s/it]Loading train:  75%|███████▍  | 397/532 [10:36<04:35,  2.04s/it]Loading train:  75%|███████▍  | 398/532 [10:38<04:43,  2.12s/it]Loading train:  75%|███████▌  | 399/532 [10:40<04:39,  2.10s/it]Loading train:  75%|███████▌  | 400/532 [10:42<04:32,  2.07s/it]Loading train:  75%|███████▌  | 401/532 [10:44<04:30,  2.07s/it]Loading train:  76%|███████▌  | 402/532 [10:47<04:47,  2.21s/it]Loading train:  76%|███████▌  | 403/532 [10:49<04:31,  2.10s/it]Loading train:  76%|███████▌  | 404/532 [10:51<04:32,  2.13s/it]Loading train:  76%|███████▌  | 405/532 [10:53<04:20,  2.05s/it]Loading train:  76%|███████▋  | 406/532 [10:55<04:28,  2.13s/it]Loading train:  77%|███████▋  | 407/532 [10:57<04:24,  2.12s/it]Loading train:  77%|███████▋  | 408/532 [10:59<04:20,  2.10s/it]Loading train:  77%|███████▋  | 409/532 [11:01<04:17,  2.10s/it]Loading train:  77%|███████▋  | 410/532 [11:03<04:04,  2.00s/it]Loading train:  77%|███████▋  | 411/532 [11:05<04:06,  2.04s/it]Loading train:  77%|███████▋  | 412/532 [11:07<04:04,  2.04s/it]Loading train:  78%|███████▊  | 413/532 [11:09<03:54,  1.97s/it]Loading train:  78%|███████▊  | 414/532 [11:11<03:48,  1.94s/it]Loading train:  78%|███████▊  | 415/532 [11:13<03:58,  2.04s/it]Loading train:  78%|███████▊  | 416/532 [11:15<03:53,  2.01s/it]Loading train:  78%|███████▊  | 417/532 [11:17<04:01,  2.10s/it]Loading train:  79%|███████▊  | 418/532 [11:19<03:49,  2.02s/it]Loading train:  79%|███████▉  | 419/532 [11:21<03:37,  1.93s/it]Loading train:  79%|███████▉  | 420/532 [11:23<03:39,  1.96s/it]Loading train:  79%|███████▉  | 421/532 [11:25<03:41,  1.99s/it]Loading train:  79%|███████▉  | 422/532 [11:27<03:56,  2.15s/it]Loading train:  80%|███████▉  | 423/532 [11:30<04:02,  2.22s/it]Loading train:  80%|███████▉  | 424/532 [11:32<04:03,  2.26s/it]Loading train:  80%|███████▉  | 425/532 [11:34<03:53,  2.18s/it]Loading train:  80%|████████  | 426/532 [11:36<03:40,  2.08s/it]Loading train:  80%|████████  | 427/532 [11:38<03:34,  2.04s/it]Loading train:  80%|████████  | 428/532 [11:40<03:37,  2.10s/it]Loading train:  81%|████████  | 429/532 [11:42<03:30,  2.05s/it]Loading train:  81%|████████  | 430/532 [11:44<03:21,  1.98s/it]Loading train:  81%|████████  | 431/532 [11:46<03:28,  2.07s/it]Loading train:  81%|████████  | 432/532 [11:48<03:30,  2.11s/it]Loading train:  81%|████████▏ | 433/532 [11:51<03:37,  2.20s/it]Loading train:  82%|████████▏ | 434/532 [11:53<03:31,  2.16s/it]Loading train:  82%|████████▏ | 435/532 [11:55<03:34,  2.21s/it]Loading train:  82%|████████▏ | 436/532 [11:58<03:36,  2.26s/it]Loading train:  82%|████████▏ | 437/532 [11:59<03:21,  2.13s/it]Loading train:  82%|████████▏ | 438/532 [12:01<03:06,  1.98s/it]Loading train:  83%|████████▎ | 439/532 [12:03<03:01,  1.95s/it]Loading train:  83%|████████▎ | 440/532 [12:05<03:10,  2.07s/it]Loading train:  83%|████████▎ | 441/532 [12:08<03:13,  2.13s/it]Loading train:  83%|████████▎ | 442/532 [12:10<03:10,  2.12s/it]Loading train:  83%|████████▎ | 443/532 [12:12<03:08,  2.11s/it]Loading train:  83%|████████▎ | 444/532 [12:14<03:04,  2.10s/it]Loading train:  84%|████████▎ | 445/532 [12:16<02:55,  2.01s/it]Loading train:  84%|████████▍ | 446/532 [12:17<02:46,  1.94s/it]Loading train:  84%|████████▍ | 447/532 [12:19<02:40,  1.89s/it]Loading train:  84%|████████▍ | 448/532 [12:21<02:39,  1.90s/it]Loading train:  84%|████████▍ | 449/532 [12:23<02:31,  1.83s/it]Loading train:  85%|████████▍ | 450/532 [12:24<02:26,  1.79s/it]Loading train:  85%|████████▍ | 451/532 [12:27<02:34,  1.91s/it]Loading train:  85%|████████▍ | 452/532 [12:29<02:31,  1.90s/it]Loading train:  85%|████████▌ | 453/532 [12:30<02:25,  1.84s/it]Loading train:  85%|████████▌ | 454/532 [12:32<02:23,  1.84s/it]Loading train:  86%|████████▌ | 455/532 [12:34<02:27,  1.92s/it]Loading train:  86%|████████▌ | 456/532 [12:36<02:34,  2.04s/it]Loading train:  86%|████████▌ | 457/532 [12:39<02:41,  2.15s/it]Loading train:  86%|████████▌ | 458/532 [12:41<02:34,  2.09s/it]Loading train:  86%|████████▋ | 459/532 [12:43<02:40,  2.20s/it]Loading train:  86%|████████▋ | 460/532 [12:45<02:34,  2.14s/it]Loading train:  87%|████████▋ | 461/532 [12:47<02:30,  2.12s/it]Loading train:  87%|████████▋ | 462/532 [12:50<02:40,  2.30s/it]Loading train:  87%|████████▋ | 463/532 [12:52<02:35,  2.26s/it]Loading train:  87%|████████▋ | 464/532 [12:54<02:27,  2.17s/it]Loading train:  87%|████████▋ | 465/532 [12:56<02:22,  2.12s/it]Loading train:  88%|████████▊ | 466/532 [12:59<02:28,  2.25s/it]Loading train:  88%|████████▊ | 467/532 [13:01<02:30,  2.31s/it]Loading train:  88%|████████▊ | 468/532 [13:03<02:16,  2.13s/it]Loading train:  88%|████████▊ | 469/532 [13:05<02:05,  1.99s/it]Loading train:  88%|████████▊ | 470/532 [13:06<01:57,  1.90s/it]Loading train:  89%|████████▊ | 471/532 [13:09<02:04,  2.04s/it]Loading train:  89%|████████▊ | 472/532 [13:11<02:01,  2.02s/it]Loading train:  89%|████████▉ | 473/532 [13:13<01:56,  1.98s/it]Loading train:  89%|████████▉ | 474/532 [13:14<01:49,  1.89s/it]Loading train:  89%|████████▉ | 475/532 [13:16<01:52,  1.97s/it]Loading train:  89%|████████▉ | 476/532 [13:18<01:49,  1.95s/it]Loading train:  90%|████████▉ | 477/532 [13:20<01:50,  2.01s/it]Loading train:  90%|████████▉ | 478/532 [13:22<01:48,  2.01s/it]Loading train:  90%|█████████ | 479/532 [13:24<01:44,  1.98s/it]Loading train:  90%|█████████ | 480/532 [13:26<01:38,  1.89s/it]Loading train:  90%|█████████ | 481/532 [13:28<01:38,  1.93s/it]Loading train:  91%|█████████ | 482/532 [13:30<01:41,  2.03s/it]Loading train:  91%|█████████ | 483/532 [13:32<01:37,  2.00s/it]Loading train:  91%|█████████ | 484/532 [13:34<01:29,  1.87s/it]Loading train:  91%|█████████ | 485/532 [13:36<01:29,  1.91s/it]Loading train:  91%|█████████▏| 486/532 [13:38<01:31,  1.99s/it]Loading train:  92%|█████████▏| 487/532 [13:40<01:31,  2.03s/it]Loading train:  92%|█████████▏| 488/532 [13:42<01:29,  2.03s/it]Loading train:  92%|█████████▏| 489/532 [13:45<01:32,  2.14s/it]Loading train:  92%|█████████▏| 490/532 [13:47<01:34,  2.26s/it]Loading train:  92%|█████████▏| 491/532 [13:49<01:30,  2.22s/it]Loading train:  92%|█████████▏| 492/532 [13:51<01:23,  2.10s/it]Loading train:  93%|█████████▎| 493/532 [13:53<01:19,  2.05s/it]Loading train:  93%|█████████▎| 494/532 [13:55<01:18,  2.05s/it]Loading train:  93%|█████████▎| 495/532 [13:57<01:12,  1.95s/it]Loading train:  93%|█████████▎| 496/532 [13:59<01:08,  1.91s/it]Loading train:  93%|█████████▎| 497/532 [14:01<01:10,  2.01s/it]Loading train:  94%|█████████▎| 498/532 [14:03<01:08,  2.02s/it]Loading train:  94%|█████████▍| 499/532 [14:05<01:07,  2.05s/it]Loading train:  94%|█████████▍| 500/532 [14:07<01:04,  2.01s/it]Loading train:  94%|█████████▍| 501/532 [14:09<01:02,  2.03s/it]Loading train:  94%|█████████▍| 502/532 [14:11<01:00,  2.01s/it]Loading train:  95%|█████████▍| 503/532 [14:13<01:01,  2.12s/it]Loading train:  95%|█████████▍| 504/532 [14:15<00:55,  2.00s/it]Loading train:  95%|█████████▍| 505/532 [14:17<00:52,  1.95s/it]Loading train:  95%|█████████▌| 506/532 [14:18<00:46,  1.81s/it]Loading train:  95%|█████████▌| 507/532 [14:20<00:43,  1.75s/it]Loading train:  95%|█████████▌| 508/532 [14:22<00:42,  1.78s/it]Loading train:  96%|█████████▌| 509/532 [14:24<00:42,  1.86s/it]Loading train:  96%|█████████▌| 510/532 [14:26<00:42,  1.93s/it]Loading train:  96%|█████████▌| 511/532 [14:28<00:43,  2.08s/it]Loading train:  96%|█████████▌| 512/532 [14:30<00:40,  2.00s/it]Loading train:  96%|█████████▋| 513/532 [14:32<00:37,  1.99s/it]Loading train:  97%|█████████▋| 514/532 [14:34<00:35,  2.00s/it]Loading train:  97%|█████████▋| 515/532 [14:36<00:32,  1.89s/it]Loading train:  97%|█████████▋| 516/532 [14:37<00:28,  1.79s/it]Loading train:  97%|█████████▋| 517/532 [14:40<00:29,  1.94s/it]Loading train:  97%|█████████▋| 518/532 [14:41<00:26,  1.90s/it]Loading train:  98%|█████████▊| 519/532 [14:43<00:25,  1.95s/it]Loading train:  98%|█████████▊| 520/532 [14:45<00:23,  1.93s/it]Loading train:  98%|█████████▊| 521/532 [14:48<00:22,  2.05s/it]Loading train:  98%|█████████▊| 522/532 [14:50<00:20,  2.07s/it]Loading train:  98%|█████████▊| 523/532 [14:52<00:18,  2.05s/it]Loading train:  98%|█████████▊| 524/532 [14:54<00:17,  2.22s/it]Loading train:  99%|█████████▊| 525/532 [14:57<00:16,  2.36s/it]Loading train:  99%|█████████▉| 526/532 [14:59<00:14,  2.36s/it]Loading train:  99%|█████████▉| 527/532 [15:02<00:11,  2.30s/it]Loading train:  99%|█████████▉| 528/532 [15:04<00:08,  2.18s/it]Loading train:  99%|█████████▉| 529/532 [15:05<00:06,  2.03s/it]Loading train: 100%|█████████▉| 530/532 [15:07<00:04,  2.01s/it]Loading train: 100%|█████████▉| 531/532 [15:09<00:01,  1.97s/it]Loading train: 100%|██████████| 532/532 [15:11<00:00,  2.02s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   0%|          | 2/532 [00:00<00:40, 12.99it/s]concatenating: train:   1%|          | 4/532 [00:00<00:40, 13.14it/s]concatenating: train:   1%|          | 6/532 [00:00<00:39, 13.35it/s]concatenating: train:   2%|▏         | 8/532 [00:00<00:37, 13.97it/s]concatenating: train:   2%|▏         | 12/532 [00:00<00:30, 16.99it/s]concatenating: train:   3%|▎         | 15/532 [00:00<00:26, 19.25it/s]concatenating: train:   4%|▍         | 20/532 [00:00<00:22, 22.96it/s]concatenating: train:   5%|▍         | 25/532 [00:01<00:19, 26.53it/s]concatenating: train:   6%|▌         | 32/532 [00:01<00:15, 31.89it/s]concatenating: train:   7%|▋         | 37/532 [00:01<00:18, 27.15it/s]concatenating: train:   8%|▊         | 41/532 [00:01<00:19, 24.89it/s]concatenating: train:   8%|▊         | 45/532 [00:01<00:19, 24.53it/s]concatenating: train:   9%|▉         | 49/532 [00:01<00:17, 26.88it/s]concatenating: train:  10%|▉         | 53/532 [00:02<00:18, 26.29it/s]concatenating: train:  11%|█▏        | 60/532 [00:02<00:14, 31.82it/s]concatenating: train:  12%|█▏        | 66/532 [00:02<00:13, 35.72it/s]concatenating: train:  13%|█▎        | 71/532 [00:02<00:14, 31.65it/s]concatenating: train:  14%|█▍        | 75/532 [00:02<00:15, 30.38it/s]concatenating: train:  15%|█▍        | 79/532 [00:02<00:16, 28.06it/s]concatenating: train:  16%|█▌        | 83/532 [00:02<00:14, 29.98it/s]concatenating: train:  16%|█▋        | 87/532 [00:03<00:16, 27.59it/s]concatenating: train:  17%|█▋        | 91/532 [00:03<00:15, 29.35it/s]concatenating: train:  18%|█▊        | 95/532 [00:03<00:14, 30.44it/s]concatenating: train:  19%|█▊        | 99/532 [00:03<00:15, 28.58it/s]concatenating: train:  19%|█▉        | 103/532 [00:03<00:14, 29.85it/s]concatenating: train:  21%|██        | 110/532 [00:03<00:11, 35.40it/s]concatenating: train:  22%|██▏       | 117/532 [00:03<00:10, 40.70it/s]concatenating: train:  23%|██▎       | 123/532 [00:03<00:09, 43.47it/s]concatenating: train:  24%|██▍       | 128/532 [00:04<00:12, 32.79it/s]concatenating: train:  25%|██▌       | 133/532 [00:04<00:13, 30.20it/s]concatenating: train:  26%|██▌       | 137/532 [00:04<00:14, 28.19it/s]concatenating: train:  27%|██▋       | 141/532 [00:04<00:14, 27.15it/s]concatenating: train:  27%|██▋       | 146/532 [00:04<00:12, 30.77it/s]concatenating: train:  29%|██▉       | 153/532 [00:04<00:10, 36.29it/s]concatenating: train:  30%|██▉       | 158/532 [00:05<00:10, 35.81it/s]concatenating: train:  31%|███       | 164/532 [00:05<00:09, 39.76it/s]concatenating: train:  32%|███▏      | 169/532 [00:05<00:08, 41.11it/s]concatenating: train:  33%|███▎      | 178/532 [00:05<00:07, 48.17it/s]concatenating: train:  35%|███▍      | 184/532 [00:05<00:07, 47.77it/s]concatenating: train:  36%|███▌      | 190/532 [00:05<00:07, 45.76it/s]concatenating: train:  37%|███▋      | 195/532 [00:05<00:08, 40.17it/s]concatenating: train:  38%|███▊      | 200/532 [00:05<00:08, 38.36it/s]concatenating: train:  39%|███▊      | 205/532 [00:06<00:09, 35.60it/s]concatenating: train:  41%|████      | 216/532 [00:06<00:07, 44.24it/s]concatenating: train:  42%|████▏     | 224/532 [00:06<00:06, 49.94it/s]concatenating: train:  43%|████▎     | 231/532 [00:06<00:05, 52.19it/s]concatenating: train:  45%|████▍     | 238/532 [00:06<00:06, 47.88it/s]concatenating: train:  46%|████▌     | 244/532 [00:06<00:06, 45.66it/s]concatenating: train:  47%|████▋     | 250/532 [00:06<00:06, 41.44it/s]concatenating: train:  48%|████▊     | 255/532 [00:07<00:07, 37.08it/s]concatenating: train:  49%|████▉     | 260/532 [00:07<00:07, 34.53it/s]concatenating: train:  50%|████▉     | 265/532 [00:07<00:07, 37.05it/s]concatenating: train:  51%|█████     | 272/532 [00:07<00:06, 43.10it/s]concatenating: train:  54%|█████▎    | 285/532 [00:07<00:04, 53.91it/s]concatenating: train:  56%|█████▌    | 296/532 [00:07<00:03, 63.21it/s]concatenating: train:  58%|█████▊    | 309/532 [00:07<00:03, 71.50it/s]concatenating: train:  60%|█████▉    | 318/532 [00:08<00:04, 50.76it/s]concatenating: train:  61%|██████▏   | 326/532 [00:08<00:05, 39.70it/s]concatenating: train:  62%|██████▏   | 332/532 [00:08<00:04, 40.60it/s]concatenating: train:  64%|██████▍   | 340/532 [00:08<00:04, 47.26it/s]concatenating: train:  66%|██████▌   | 349/532 [00:08<00:03, 54.69it/s]concatenating: train:  67%|██████▋   | 358/532 [00:08<00:02, 61.06it/s]concatenating: train:  69%|██████▉   | 366/532 [00:09<00:03, 48.86it/s]concatenating: train:  70%|███████   | 373/532 [00:09<00:03, 43.03it/s]concatenating: train:  71%|███████   | 379/532 [00:09<00:04, 35.38it/s]concatenating: train:  72%|███████▏  | 384/532 [00:09<00:03, 37.06it/s]concatenating: train:  73%|███████▎  | 391/532 [00:09<00:03, 42.83it/s]concatenating: train:  75%|███████▍  | 398/532 [00:09<00:02, 47.30it/s]concatenating: train:  76%|███████▌  | 404/532 [00:10<00:02, 47.11it/s]concatenating: train:  77%|███████▋  | 410/532 [00:10<00:02, 42.32it/s]concatenating: train:  78%|███████▊  | 415/532 [00:10<00:03, 38.97it/s]concatenating: train:  79%|███████▉  | 420/532 [00:10<00:03, 35.06it/s]concatenating: train:  80%|███████▉  | 425/532 [00:10<00:02, 38.16it/s]concatenating: train:  81%|████████  | 432/532 [00:10<00:02, 43.21it/s]concatenating: train:  83%|████████▎ | 442/532 [00:10<00:01, 51.72it/s]concatenating: train:  85%|████████▍ | 451/532 [00:10<00:01, 57.96it/s]concatenating: train:  86%|████████▌ | 458/532 [00:11<00:01, 56.39it/s]concatenating: train:  87%|████████▋ | 465/532 [00:11<00:01, 39.57it/s]concatenating: train:  89%|████████▊ | 471/532 [00:11<00:01, 36.12it/s]concatenating: train:  89%|████████▉ | 476/532 [00:11<00:01, 32.11it/s]concatenating: train:  90%|█████████ | 480/532 [00:11<00:01, 32.79it/s]concatenating: train:  91%|█████████ | 484/532 [00:12<00:01, 32.31it/s]concatenating: train:  92%|█████████▏| 488/532 [00:12<00:01, 33.26it/s]concatenating: train:  93%|█████████▎| 494/532 [00:12<00:01, 36.44it/s]concatenating: train:  94%|█████████▍| 500/532 [00:12<00:00, 40.30it/s]concatenating: train:  95%|█████████▍| 505/532 [00:12<00:00, 42.35it/s]concatenating: train:  96%|█████████▌| 512/532 [00:12<00:00, 45.08it/s]concatenating: train:  97%|█████████▋| 517/532 [00:12<00:00, 39.80it/s]concatenating: train:  98%|█████████▊| 522/532 [00:12<00:00, 38.13it/s]concatenating: train:  99%|█████████▉| 527/532 [00:13<00:00, 35.16it/s]concatenating: train: 100%|█████████▉| 531/532 [00:13<00:00, 27.24it/s]concatenating: train: 100%|██████████| 532/532 [00:13<00:00, 39.78it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:02<00:32,  2.34s/it]Loading test:  13%|█▎        | 2/15 [00:04<00:28,  2.19s/it]Loading test:  20%|██        | 3/15 [00:06<00:25,  2.16s/it]Loading test:  27%|██▋       | 4/15 [00:07<00:22,  2.01s/it]Loading test:  33%|███▎      | 5/15 [00:10<00:21,  2.12s/it]Loading test:  40%|████      | 6/15 [00:12<00:20,  2.24s/it]Loading test:  47%|████▋     | 7/15 [00:15<00:17,  2.23s/it]Loading test:  53%|█████▎    | 8/15 [00:18<00:17,  2.48s/it]Loading test:  60%|██████    | 9/15 [00:19<00:13,  2.26s/it]Loading test:  67%|██████▋   | 10/15 [00:21<00:10,  2.14s/it]Loading test:  73%|███████▎  | 11/15 [00:23<00:08,  2.02s/it]Loading test:  80%|████████  | 12/15 [00:25<00:06,  2.01s/it]Loading test:  87%|████████▋ | 13/15 [00:27<00:04,  2.02s/it]Loading test:  93%|█████████▎| 14/15 [00:29<00:02,  2.02s/it]Loading test: 100%|██████████| 15/15 [00:31<00:00,  2.00s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  53%|█████▎    | 8/15 [00:00<00:00, 73.38it/s]concatenating: validation:  87%|████████▋ | 13/15 [00:00<00:00, 63.27it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 58.34it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 23:42:08.038047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 23:42:08.038155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 23:42:08.038170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 23:42:08.038179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 23:42:08.038650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 46s - loss: 8.1860 - acc: 0.8377 - mDice: 0.1336 - val_loss: 1.6706 - val_acc: 0.9341 - val_mDice: 0.3509

Epoch 00001: val_mDice improved from -inf to 0.35093, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 24s - loss: 1.5298 - acc: 0.9356 - mDice: 0.4017 - val_loss: 0.8146 - val_acc: 0.9665 - val_mDice: 0.6182

Epoch 00002: val_mDice improved from 0.35093 to 0.61825, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 23s - loss: 1.1035 - acc: 0.9467 - mDice: 0.5288 - val_loss: 0.6727 - val_acc: 0.9699 - val_mDice: 0.6886

Epoch 00003: val_mDice improved from 0.61825 to 0.68862, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 24s - loss: 0.9326 - acc: 0.9524 - mDice: 0.5911 - val_loss: 0.5836 - val_acc: 0.9747 - val_mDice: 0.7286

Epoch 00004: val_mDice improved from 0.68862 to 0.72859, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 22s - loss: 0.8374 - acc: 0.9553 - mDice: 0.6279 - val_loss: 0.5758 - val_acc: 0.9752 - val_mDice: 0.7384

Epoch 00005: val_mDice improved from 0.72859 to 0.73840, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 22s - loss: 0.7675 - acc: 0.9571 - mDice: 0.6544 - val_loss: 0.5278 - val_acc: 0.9764 - val_mDice: 0.7521

Epoch 00006: val_mDice improved from 0.73840 to 0.75213, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 23s - loss: 0.7250 - acc: 0.9583 - mDice: 0.6714 - val_loss: 0.5092 - val_acc: 0.9761 - val_mDice: 0.7585

Epoch 00007: val_mDice improved from 0.75213 to 0.75849, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 23s - loss: 0.6912 - acc: 0.9594 - mDice: 0.6846 - val_loss: 0.4949 - val_acc: 0.9773 - val_mDice: 0.7639

Epoch 00008: val_mDice improved from 0.75849 to 0.76390, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 22s - loss: 0.6668 - acc: 0.9601 - mDice: 0.6948 - val_loss: 0.5015 - val_acc: 0.9765 - val_mDice: 0.7672

Epoch 00009: val_mDice improved from 0.76390 to 0.76716, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 22s - loss: 0.6442 - acc: 0.9609 - mDice: 0.7045 - val_loss: 0.4767 - val_acc: 0.9767 - val_mDice: 0.7710

Epoch 00010: val_mDice improved from 0.76716 to 0.77102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 22s - loss: 0.6229 - acc: 0.9616 - mDice: 0.7129 - val_loss: 0.4963 - val_acc: 0.9767 - val_mDice: 0.7713

Epoch 00011: val_mDice improved from 0.77102 to 0.77135, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 24s - loss: 0.6103 - acc: 0.9620 - mDice: 0.7184 - val_loss: 0.4851 - val_acc: 0.9775 - val_mDice: 0.7720

Epoch 00012: val_mDice improved from 0.77135 to 0.77202, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 22s - loss: 0.5916 - acc: 0.9627 - mDice: 0.7263 - val_loss: 0.4818 - val_acc: 0.9767 - val_mDice: 0.7759

Epoch 00013: val_mDice improved from 0.77202 to 0.77591, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 22s - loss: 0.5838 - acc: 0.9630 - mDice: 0.7297 - val_loss: 0.4723 - val_acc: 0.9788 - val_mDice: 0.7788

Epoch 00014: val_mDice improved from 0.77591 to 0.77880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 23s - loss: 0.5726 - acc: 0.9634 - mDice: 0.7343 - val_loss: 0.4746 - val_acc: 0.9783 - val_mDice: 0.7803

Epoch 00015: val_mDice improved from 0.77880 to 0.78026, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 23s - loss: 0.5621 - acc: 0.9637 - mDice: 0.7390 - val_loss: 0.4757 - val_acc: 0.9786 - val_mDice: 0.7800

Epoch 00016: val_mDice did not improve from 0.78026
Epoch 17/300
 - 22s - loss: 0.5529 - acc: 0.9640 - mDice: 0.7424 - val_loss: 0.4740 - val_acc: 0.9784 - val_mDice: 0.7815

Epoch 00017: val_mDice improved from 0.78026 to 0.78147, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 22s - loss: 0.5463 - acc: 0.9642 - mDice: 0.7455 - val_loss: 0.4641 - val_acc: 0.9789 - val_mDice: 0.7846

Epoch 00018: val_mDice improved from 0.78147 to 0.78457, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 24s - loss: 0.5406 - acc: 0.9643 - mDice: 0.7479 - val_loss: 0.4579 - val_acc: 0.9787 - val_mDice: 0.7849

Epoch 00019: val_mDice improved from 0.78457 to 0.78487, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 22s - loss: 0.5333 - acc: 0.9644 - mDice: 0.7512 - val_loss: 0.4702 - val_acc: 0.9787 - val_mDice: 0.7839

Epoch 00020: val_mDice did not improve from 0.78487
Epoch 21/300
 - 22s - loss: 0.5280 - acc: 0.9646 - mDice: 0.7534 - val_loss: 0.4617 - val_acc: 0.9786 - val_mDice: 0.7846

Epoch 00021: val_mDice did not improve from 0.78487
Epoch 22/300
 - 22s - loss: 0.5207 - acc: 0.9647 - mDice: 0.7562 - val_loss: 0.4578 - val_acc: 0.9789 - val_mDice: 0.7877

Epoch 00022: val_mDice improved from 0.78487 to 0.78771, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 24s - loss: 0.5166 - acc: 0.9648 - mDice: 0.7579 - val_loss: 0.4521 - val_acc: 0.9791 - val_mDice: 0.7890

Epoch 00023: val_mDice improved from 0.78771 to 0.78897, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 24/300
 - 22s - loss: 0.5120 - acc: 0.9650 - mDice: 0.7601 - val_loss: 0.4563 - val_acc: 0.9786 - val_mDice: 0.7892

Epoch 00024: val_mDice improved from 0.78897 to 0.78920, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 22s - loss: 0.5045 - acc: 0.9653 - mDice: 0.7631 - val_loss: 0.4586 - val_acc: 0.9788 - val_mDice: 0.7883

Epoch 00025: val_mDice did not improve from 0.78920
Epoch 26/300
 - 22s - loss: 0.5040 - acc: 0.9653 - mDice: 0.7638 - val_loss: 0.4559 - val_acc: 0.9791 - val_mDice: 0.7896

Epoch 00026: val_mDice improved from 0.78920 to 0.78955, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 24s - loss: 0.5011 - acc: 0.9654 - mDice: 0.7649 - val_loss: 0.4462 - val_acc: 0.9792 - val_mDice: 0.7916

Epoch 00027: val_mDice improved from 0.78955 to 0.79158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 22s - loss: 0.4961 - acc: 0.9655 - mDice: 0.7669 - val_loss: 0.4523 - val_acc: 0.9791 - val_mDice: 0.7891

Epoch 00028: val_mDice did not improve from 0.79158
Epoch 29/300
 - 22s - loss: 0.4940 - acc: 0.9656 - mDice: 0.7679 - val_loss: 0.4485 - val_acc: 0.9798 - val_mDice: 0.7919

Epoch 00029: val_mDice improved from 0.79158 to 0.79190, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 23s - loss: 0.4901 - acc: 0.9657 - mDice: 0.7693 - val_loss: 0.4614 - val_acc: 0.9776 - val_mDice: 0.7874

Epoch 00030: val_mDice did not improve from 0.79190
Epoch 31/300
 - 23s - loss: 0.4876 - acc: 0.9657 - mDice: 0.7705 - val_loss: 0.4628 - val_acc: 0.9787 - val_mDice: 0.7898

Epoch 00031: val_mDice did not improve from 0.79190
Epoch 32/300
 - 22s - loss: 0.4829 - acc: 0.9659 - mDice: 0.7722 - val_loss: 0.4500 - val_acc: 0.9789 - val_mDice: 0.7903

Epoch 00032: val_mDice did not improve from 0.79190
Epoch 33/300
 - 22s - loss: 0.4825 - acc: 0.9659 - mDice: 0.7728 - val_loss: 0.4491 - val_acc: 0.9785 - val_mDice: 0.7922

Epoch 00033: val_mDice improved from 0.79190 to 0.79221, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 23s - loss: 0.4793 - acc: 0.9659 - mDice: 0.7738 - val_loss: 0.4465 - val_acc: 0.9796 - val_mDice: 0.7930

Epoch 00034: val_mDice improved from 0.79221 to 0.79305, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 35/300
 - 23s - loss: 0.4752 - acc: 0.9661 - mDice: 0.7759 - val_loss: 0.4559 - val_acc: 0.9792 - val_mDice: 0.7881

Epoch 00035: val_mDice did not improve from 0.79305
Epoch 36/300
 - 22s - loss: 0.4734 - acc: 0.9661 - mDice: 0.7763 - val_loss: 0.4634 - val_acc: 0.9794 - val_mDice: 0.7895

Epoch 00036: val_mDice did not improve from 0.79305
Epoch 37/300
 - 22s - loss: 0.4730 - acc: 0.9661 - mDice: 0.7767 - val_loss: 0.4536 - val_acc: 0.9797 - val_mDice: 0.7899

Epoch 00037: val_mDice did not improve from 0.79305
Epoch 38/300
 - 23s - loss: 0.4712 - acc: 0.9661 - mDice: 0.7772 - val_loss: 0.4444 - val_acc: 0.9792 - val_mDice: 0.7937

Epoch 00038: val_mDice improved from 0.79305 to 0.79365, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 39/300
 - 23s - loss: 0.4671 - acc: 0.9663 - mDice: 0.7790 - val_loss: 0.4431 - val_acc: 0.9794 - val_mDice: 0.7945

Epoch 00039: val_mDice improved from 0.79365 to 0.79445, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 40/300
 - 22s - loss: 0.4665 - acc: 0.9664 - mDice: 0.7793 - val_loss: 0.4481 - val_acc: 0.9796 - val_mDice: 0.7935

Epoch 00040: val_mDice did not improve from 0.79445
Epoch 41/300
 - 22s - loss: 0.4651 - acc: 0.9663 - mDice: 0.7797 - val_loss: 0.4534 - val_acc: 0.9790 - val_mDice: 0.7917

Epoch 00041: val_mDice did not improve from 0.79445
Epoch 42/300
 - 24s - loss: 0.4640 - acc: 0.9664 - mDice: 0.7803 - val_loss: 0.4531 - val_acc: 0.9795 - val_mDice: 0.7915

Epoch 00042: val_mDice did not improve from 0.79445
Epoch 43/300
 - 23s - loss: 0.4605 - acc: 0.9664 - mDice: 0.7819 - val_loss: 0.4530 - val_acc: 0.9791 - val_mDice: 0.7928

Epoch 00043: val_mDice did not improve from 0.79445
Epoch 44/300
 - 22s - loss: 0.4602 - acc: 0.9664 - mDice: 0.7820 - val_loss: 0.4477 - val_acc: 0.9796 - val_mDice: 0.7954

Epoch 00044: val_mDice improved from 0.79445 to 0.79541, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 23s - loss: 0.4589 - acc: 0.9664 - mDice: 0.7823 - val_loss: 0.4483 - val_acc: 0.9791 - val_mDice: 0.7927

Epoch 00045: val_mDice did not improve from 0.79541
Epoch 46/300
 - 23s - loss: 0.4576 - acc: 0.9664 - mDice: 0.7830 - val_loss: 0.4445 - val_acc: 0.9797 - val_mDice: 0.7955

Epoch 00046: val_mDice improved from 0.79541 to 0.79552, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 22s - loss: 0.4551 - acc: 0.9665 - mDice: 0.7840 - val_loss: 0.4419 - val_acc: 0.9798 - val_mDice: 0.7964

Epoch 00047: val_mDice improved from 0.79552 to 0.79638, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 48/300
 - 22s - loss: 0.4542 - acc: 0.9665 - mDice: 0.7847 - val_loss: 0.4496 - val_acc: 0.9793 - val_mDice: 0.7941

Epoch 00048: val_mDice did not improve from 0.79638
Epoch 49/300
 - 23s - loss: 0.4535 - acc: 0.9664 - mDice: 0.7847 - val_loss: 0.4396 - val_acc: 0.9799 - val_mDice: 0.7967

Epoch 00049: val_mDice improved from 0.79638 to 0.79667, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 50/300
 - 23s - loss: 0.4508 - acc: 0.9665 - mDice: 0.7860 - val_loss: 0.4519 - val_acc: 0.9796 - val_mDice: 0.7930

Epoch 00050: val_mDice did not improve from 0.79667
Epoch 51/300
 - 22s - loss: 0.4507 - acc: 0.9666 - mDice: 0.7857 - val_loss: 0.4571 - val_acc: 0.9793 - val_mDice: 0.7929

Epoch 00051: val_mDice did not improve from 0.79667
Epoch 52/300
 - 22s - loss: 0.4494 - acc: 0.9665 - mDice: 0.7864 - val_loss: 0.4568 - val_acc: 0.9790 - val_mDice: 0.7913

Epoch 00052: val_mDice did not improve from 0.79667
Epoch 53/300
 - 23s - loss: 0.4491 - acc: 0.9666 - mDice: 0.7866 - val_loss: 0.4525 - val_acc: 0.9790 - val_mDice: 0.7930

Epoch 00053: val_mDice did not improve from 0.79667
Epoch 54/300
 - 23s - loss: 0.4473 - acc: 0.9666 - mDice: 0.7875 - val_loss: 0.4428 - val_acc: 0.9796 - val_mDice: 0.7955

Epoch 00054: val_mDice did not improve from 0.79667
Epoch 55/300
 - 22s - loss: 0.4474 - acc: 0.9666 - mDice: 0.7871 - val_loss: 0.4532 - val_acc: 0.9798 - val_mDice: 0.7940

Epoch 00055: val_mDice did not improve from 0.79667
Epoch 56/300
 - 22s - loss: 0.4449 - acc: 0.9666 - mDice: 0.7881 - val_loss: 0.4526 - val_acc: 0.9797 - val_mDice: 0.7937

Epoch 00056: val_mDice did not improve from 0.79667
Epoch 57/300
 - 24s - loss: 0.4456 - acc: 0.9666 - mDice: 0.7878 - val_loss: 0.4465 - val_acc: 0.9794 - val_mDice: 0.7950

Epoch 00057: val_mDice did not improve from 0.79667
Epoch 58/300
 - 22s - loss: 0.4454 - acc: 0.9666 - mDice: 0.7877 - val_loss: 0.4446 - val_acc: 0.9792 - val_mDice: 0.7961

Epoch 00058: val_mDice did not improve from 0.79667
Epoch 59/300
 - 22s - loss: 0.4429 - acc: 0.9667 - mDice: 0.7890 - val_loss: 0.4498 - val_acc: 0.9801 - val_mDice: 0.7935

Epoch 00059: val_mDice did not improve from 0.79667
Epoch 60/300
 - 23s - loss: 0.4411 - acc: 0.9667 - mDice: 0.7896 - val_loss: 0.4511 - val_acc: 0.9803 - val_mDice: 0.7960

Epoch 00060: val_mDice did not improve from 0.79667
Epoch 61/300
 - 23s - loss: 0.4420 - acc: 0.9667 - mDice: 0.7895 - val_loss: 0.4397 - val_acc: 0.9798 - val_mDice: 0.7976

Epoch 00061: val_mDice improved from 0.79667 to 0.79764, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 62/300
 - 22s - loss: 0.4401 - acc: 0.9668 - mDice: 0.7900 - val_loss: 0.4363 - val_acc: 0.9791 - val_mDice: 0.7978

Epoch 00062: val_mDice improved from 0.79764 to 0.79777, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 63/300
 - 22s - loss: 0.4399 - acc: 0.9668 - mDice: 0.7903 - val_loss: 0.4469 - val_acc: 0.9794 - val_mDice: 0.7929

Epoch 00063: val_mDice did not improve from 0.79777
Epoch 64/300
 - 23s - loss: 0.4396 - acc: 0.9668 - mDice: 0.7907 - val_loss: 0.4570 - val_acc: 0.9793 - val_mDice: 0.7934

Epoch 00064: val_mDice did not improve from 0.79777
Epoch 65/300
 - 24s - loss: 0.4366 - acc: 0.9669 - mDice: 0.7917 - val_loss: 0.4517 - val_acc: 0.9797 - val_mDice: 0.7942

Epoch 00065: val_mDice did not improve from 0.79777
Epoch 66/300
 - 22s - loss: 0.4367 - acc: 0.9669 - mDice: 0.7915 - val_loss: 0.4392 - val_acc: 0.9799 - val_mDice: 0.7979

Epoch 00066: val_mDice improved from 0.79777 to 0.79790, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 67/300
 - 22s - loss: 0.4369 - acc: 0.9668 - mDice: 0.7916 - val_loss: 0.4495 - val_acc: 0.9796 - val_mDice: 0.7966

Epoch 00067: val_mDice did not improve from 0.79790
Epoch 68/300
 - 22s - loss: 0.4364 - acc: 0.9669 - mDice: 0.7917 - val_loss: 0.4436 - val_acc: 0.9796 - val_mDice: 0.7964

Epoch 00068: val_mDice did not improve from 0.79790
Epoch 69/300
 - 24s - loss: 0.4343 - acc: 0.9669 - mDice: 0.7925 - val_loss: 0.4624 - val_acc: 0.9797 - val_mDice: 0.7936

Epoch 00069: val_mDice did not improve from 0.79790
Epoch 70/300
 - 23s - loss: 0.4341 - acc: 0.9669 - mDice: 0.7927 - val_loss: 0.4532 - val_acc: 0.9802 - val_mDice: 0.7945

Epoch 00070: val_mDice did not improve from 0.79790
Epoch 71/300
 - 22s - loss: 0.4328 - acc: 0.9669 - mDice: 0.7931 - val_loss: 0.4446 - val_acc: 0.9799 - val_mDice: 0.7965

Epoch 00071: val_mDice did not improve from 0.79790
Epoch 72/300
 - 22s - loss: 0.4335 - acc: 0.9668 - mDice: 0.7928 - val_loss: 0.4451 - val_acc: 0.9800 - val_mDice: 0.7980

Epoch 00072: val_mDice improved from 0.79790 to 0.79798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 73/300
 - 23s - loss: 0.4336 - acc: 0.9669 - mDice: 0.7929 - val_loss: 0.4481 - val_acc: 0.9800 - val_mDice: 0.7956

Epoch 00073: val_mDice did not improve from 0.79798
Epoch 74/300
 - 23s - loss: 0.4321 - acc: 0.9669 - mDice: 0.7935 - val_loss: 0.4468 - val_acc: 0.9800 - val_mDice: 0.7982

Epoch 00074: val_mDice improved from 0.79798 to 0.79820, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 75/300
 - 22s - loss: 0.4309 - acc: 0.9670 - mDice: 0.7940 - val_loss: 0.4454 - val_acc: 0.9796 - val_mDice: 0.7967

Epoch 00075: val_mDice did not improve from 0.79820
Epoch 76/300
 - 22s - loss: 0.4296 - acc: 0.9670 - mDice: 0.7944 - val_loss: 0.4473 - val_acc: 0.9801 - val_mDice: 0.7964

Epoch 00076: val_mDice did not improve from 0.79820
Epoch 77/300
 - 24s - loss: 0.4301 - acc: 0.9670 - mDice: 0.7942 - val_loss: 0.4408 - val_acc: 0.9799 - val_mDice: 0.7979

Epoch 00077: val_mDice did not improve from 0.79820
Epoch 78/300
 - 22s - loss: 0.4296 - acc: 0.9670 - mDice: 0.7945 - val_loss: 0.4528 - val_acc: 0.9792 - val_mDice: 0.7960

Epoch 00078: val_mDice did not improve from 0.79820
Epoch 79/300
 - 22s - loss: 0.4276 - acc: 0.9671 - mDice: 0.7954 - val_loss: 0.4497 - val_acc: 0.9796 - val_mDice: 0.7943

Epoch 00079: val_mDice did not improve from 0.79820
Epoch 80/300
 - 22s - loss: 0.4282 - acc: 0.9670 - mDice: 0.7950 - val_loss: 0.4538 - val_acc: 0.9800 - val_mDice: 0.7936

Epoch 00080: val_mDice did not improve from 0.79820
Epoch 81/300
 - 23s - loss: 0.4271 - acc: 0.9670 - mDice: 0.7955 - val_loss: 0.4421 - val_acc: 0.9803 - val_mDice: 0.7982

Epoch 00081: val_mDice did not improve from 0.79820
Epoch 82/300
 - 23s - loss: 0.4266 - acc: 0.9670 - mDice: 0.7957 - val_loss: 0.4487 - val_acc: 0.9794 - val_mDice: 0.7969

Epoch 00082: val_mDice did not improve from 0.79820
Epoch 83/300
 - 22s - loss: 0.4275 - acc: 0.9671 - mDice: 0.7955 - val_loss: 0.4462 - val_acc: 0.9803 - val_mDice: 0.7970

Epoch 00083: val_mDice did not improve from 0.79820
Epoch 84/300
 - 22s - loss: 0.4271 - acc: 0.9671 - mDice: 0.7956 - val_loss: 0.4440 - val_acc: 0.9804 - val_mDice: 0.7963

Epoch 00084: val_mDice did not improve from 0.79820
Epoch 85/300
 - 23s - loss: 0.4266 - acc: 0.9671 - mDice: 0.7957 - val_loss: 0.4524 - val_acc: 0.9800 - val_mDice: 0.7954

Epoch 00085: val_mDice did not improve from 0.79820
Epoch 86/300
 - 24s - loss: 0.4256 - acc: 0.9670 - mDice: 0.7959 - val_loss: 0.4532 - val_acc: 0.9794 - val_mDice: 0.7944

Epoch 00086: val_mDice did not improve from 0.79820
Epoch 87/300
 - 22s - loss: 0.4241 - acc: 0.9671 - mDice: 0.7967 - val_loss: 0.4443 - val_acc: 0.9799 - val_mDice: 0.7976

Epoch 00087: val_mDice did not improve from 0.79820
Epoch 88/300
 - 22s - loss: 0.4236 - acc: 0.9670 - mDice: 0.7973 - val_loss: 0.4462 - val_acc: 0.9799 - val_mDice: 0.7965

Epoch 00088: val_mDice did not improve from 0.79820
Epoch 89/300
 - 22s - loss: 0.4257 - acc: 0.9670 - mDice: 0.7961 - val_loss: 0.4441 - val_acc: 0.9799 - val_mDice: 0.7971

Epoch 00089: val_mDice did not improve from 0.79820
Epoch 90/300
 - 24s - loss: 0.4227 - acc: 0.9671 - mDice: 0.7972 - val_loss: 0.4436 - val_acc: 0.9797 - val_mDice: 0.7950

Epoch 00090: val_mDice did not improve from 0.79820
Epoch 91/300
 - 22s - loss: 0.4228 - acc: 0.9671 - mDice: 0.7970 - val_loss: 0.4476 - val_acc: 0.9800 - val_mDice: 0.7954

Epoch 00091: val_mDice did not improve from 0.79820
Epoch 92/300
 - 22s - loss: 0.4229 - acc: 0.9672 - mDice: 0.7971 - val_loss: 0.4387 - val_acc: 0.9799 - val_mDice: 0.7985

Epoch 00092: val_mDice improved from 0.79820 to 0.79851, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 93/300
 - 22s - loss: 0.4216 - acc: 0.9672 - mDice: 0.7975 - val_loss: 0.4524 - val_acc: 0.9796 - val_mDice: 0.7955

Epoch 00093: val_mDice did not improve from 0.79851
Epoch 94/300
 - 23s - loss: 0.4211 - acc: 0.9672 - mDice: 0.7976 - val_loss: 0.4463 - val_acc: 0.9803 - val_mDice: 0.7965

Epoch 00094: val_mDice did not improve from 0.79851
Epoch 95/300
 - 23s - loss: 0.4208 - acc: 0.9672 - mDice: 0.7982 - val_loss: 0.4506 - val_acc: 0.9798 - val_mDice: 0.7966

Epoch 00095: val_mDice did not improve from 0.79851
Epoch 96/300
 - 22s - loss: 0.4216 - acc: 0.9672 - mDice: 0.7977 - val_loss: 0.4424 - val_acc: 0.9794 - val_mDice: 0.7966

Epoch 00096: val_mDice did not improve from 0.79851
Epoch 97/300
 - 22s - loss: 0.4203 - acc: 0.9672 - mDice: 0.7982 - val_loss: 0.4500 - val_acc: 0.9798 - val_mDice: 0.7963

Epoch 00097: val_mDice did not improve from 0.79851
Epoch 98/300
 - 22s - loss: 0.4202 - acc: 0.9672 - mDice: 0.7981 - val_loss: 0.4531 - val_acc: 0.9799 - val_mDice: 0.7946

Epoch 00098: val_mDice did not improve from 0.79851
Epoch 99/300
 - 24s - loss: 0.4193 - acc: 0.9672 - mDice: 0.7988 - val_loss: 0.4435 - val_acc: 0.9799 - val_mDice: 0.7981

Epoch 00099: val_mDice did not improve from 0.79851
Epoch 100/300
 - 22s - loss: 0.4178 - acc: 0.9673 - mDice: 0.7992 - val_loss: 0.4555 - val_acc: 0.9801 - val_mDice: 0.7944

Epoch 00100: val_mDice did not improve from 0.79851
Epoch 101/300
 - 22s - loss: 0.4188 - acc: 0.9673 - mDice: 0.7987 - val_loss: 0.4486 - val_acc: 0.9799 - val_mDice: 0.7950

Epoch 00101: val_mDice did not improve from 0.79851
Epoch 102/300
 - 23s - loss: 0.4186 - acc: 0.9673 - mDice: 0.7990 - val_loss: 0.4378 - val_acc: 0.9800 - val_mDice: 0.7991

Epoch 00102: val_mDice improved from 0.79851 to 0.79914, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 103/300
 - 23s - loss: 0.4183 - acc: 0.9672 - mDice: 0.7989 - val_loss: 0.4665 - val_acc: 0.9792 - val_mDice: 0.7914

Epoch 00103: val_mDice did not improve from 0.79914
Epoch 104/300
 - 22s - loss: 0.4182 - acc: 0.9673 - mDice: 0.7988 - val_loss: 0.4602 - val_acc: 0.9800 - val_mDice: 0.7944

Epoch 00104: val_mDice did not improve from 0.79914
Epoch 105/300
 - 22s - loss: 0.4172 - acc: 0.9673 - mDice: 0.7996 - val_loss: 0.4475 - val_acc: 0.9798 - val_mDice: 0.7974

Epoch 00105: val_mDice did not improve from 0.79914
Epoch 106/300
 - 24s - loss: 0.4173 - acc: 0.9672 - mDice: 0.7995 - val_loss: 0.4761 - val_acc: 0.9792 - val_mDice: 0.7897

Epoch 00106: val_mDice did not improve from 0.79914
Epoch 107/300
 - 22s - loss: 0.4165 - acc: 0.9673 - mDice: 0.8000 - val_loss: 0.4471 - val_acc: 0.9802 - val_mDice: 0.7978

Epoch 00107: val_mDice did not improve from 0.79914
Epoch 108/300
 - 22s - loss: 0.4163 - acc: 0.9673 - mDice: 0.7999 - val_loss: 0.4634 - val_acc: 0.9795 - val_mDice: 0.7940

Epoch 00108: val_mDice did not improve from 0.79914
Epoch 109/300
 - 22s - loss: 0.4153 - acc: 0.9674 - mDice: 0.8003 - val_loss: 0.4546 - val_acc: 0.9798 - val_mDice: 0.7941

Epoch 00109: val_mDice did not improve from 0.79914
Epoch 110/300
 - 23s - loss: 0.4142 - acc: 0.9674 - mDice: 0.8006 - val_loss: 0.4454 - val_acc: 0.9804 - val_mDice: 0.7972

Epoch 00110: val_mDice did not improve from 0.79914
Epoch 111/300
 - 23s - loss: 0.4148 - acc: 0.9674 - mDice: 0.8004 - val_loss: 0.4494 - val_acc: 0.9801 - val_mDice: 0.7953

Epoch 00111: val_mDice did not improve from 0.79914
Epoch 112/300
 - 22s - loss: 0.4144 - acc: 0.9674 - mDice: 0.8006 - val_loss: 0.4468 - val_acc: 0.9799 - val_mDice: 0.7969

Epoch 00112: val_mDice did not improve from 0.79914
Epoch 113/300
 - 22s - loss: 0.4147 - acc: 0.9674 - mDice: 0.8006 - val_loss: 0.4597 - val_acc: 0.9802 - val_mDice: 0.7957

Epoch 00113: val_mDice did not improve from 0.79914
Epoch 114/300
 - 22s - loss: 0.4147 - acc: 0.9674 - mDice: 0.8006 - val_loss: 0.4535 - val_acc: 0.9800 - val_mDice: 0.7960

Epoch 00114: val_mDice did not improve from 0.79914
Epoch 115/300
 - 24s - loss: 0.4140 - acc: 0.9674 - mDice: 0.8009 - val_loss: 0.4479 - val_acc: 0.9801 - val_mDice: 0.7966

Epoch 00115: val_mDice did not improve from 0.79914
Epoch 116/300
 - 22s - loss: 0.4135 - acc: 0.9674 - mDice: 0.8012 - val_loss: 0.4390 - val_acc: 0.9802 - val_mDice: 0.8005

Epoch 00116: val_mDice improved from 0.79914 to 0.80048, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 117/300
 - 22s - loss: 0.4138 - acc: 0.9674 - mDice: 0.8008 - val_loss: 0.4443 - val_acc: 0.9804 - val_mDice: 0.7981

Epoch 00117: val_mDice did not improve from 0.80048
Epoch 118/300
 - 23s - loss: 0.4132 - acc: 0.9675 - mDice: 0.8013 - val_loss: 0.4511 - val_acc: 0.9799 - val_mDice: 0.7972

Epoch 00118: val_mDice did not improve from 0.80048
Epoch 119/300
 - 23s - loss: 0.4125 - acc: 0.9675 - mDice: 0.8014 - val_loss: 0.4542 - val_acc: 0.9804 - val_mDice: 0.7943

Epoch 00119: val_mDice did not improve from 0.80048
Epoch 120/300
 - 22s - loss: 0.4117 - acc: 0.9675 - mDice: 0.8016 - val_loss: 0.4527 - val_acc: 0.9801 - val_mDice: 0.7952

Epoch 00120: val_mDice did not improve from 0.80048
Epoch 121/300
 - 22s - loss: 0.4116 - acc: 0.9675 - mDice: 0.8019 - val_loss: 0.4538 - val_acc: 0.9800 - val_mDice: 0.7955

Epoch 00121: val_mDice did not improve from 0.80048
Epoch 122/300
 - 23s - loss: 0.4104 - acc: 0.9675 - mDice: 0.8023 - val_loss: 0.4529 - val_acc: 0.9801 - val_mDice: 0.7955

Epoch 00122: val_mDice did not improve from 0.80048
Epoch 123/300
 - 24s - loss: 0.4100 - acc: 0.9675 - mDice: 0.8025 - val_loss: 0.4585 - val_acc: 0.9797 - val_mDice: 0.7959

Epoch 00123: val_mDice did not improve from 0.80048
Epoch 124/300
 - 22s - loss: 0.4113 - acc: 0.9675 - mDice: 0.8018 - val_loss: 0.4641 - val_acc: 0.9800 - val_mDice: 0.7943

Epoch 00124: val_mDice did not improve from 0.80048
Epoch 125/300
 - 22s - loss: 0.4100 - acc: 0.9675 - mDice: 0.8025 - val_loss: 0.4492 - val_acc: 0.9804 - val_mDice: 0.7957

Epoch 00125: val_mDice did not improve from 0.80048
Epoch 126/300
 - 22s - loss: 0.4105 - acc: 0.9676 - mDice: 0.8024 - val_loss: 0.4508 - val_acc: 0.9802 - val_mDice: 0.7942

Epoch 00126: val_mDice did not improve from 0.80048
Epoch 127/300
 - 24s - loss: 0.4104 - acc: 0.9675 - mDice: 0.8023 - val_loss: 0.4559 - val_acc: 0.9799 - val_mDice: 0.7964

Epoch 00127: val_mDice did not improve from 0.80048
Epoch 128/300
 - 22s - loss: 0.4082 - acc: 0.9676 - mDice: 0.8031 - val_loss: 0.4485 - val_acc: 0.9798 - val_mDice: 0.7983

Epoch 00128: val_mDice did not improve from 0.80048
Epoch 129/300
 - 22s - loss: 0.4093 - acc: 0.9675 - mDice: 0.8026 - val_loss: 0.4473 - val_acc: 0.9804 - val_mDice: 0.7995

Epoch 00129: val_mDice did not improve from 0.80048
Epoch 130/300
 - 23s - loss: 0.4086 - acc: 0.9676 - mDice: 0.8031 - val_loss: 0.4441 - val_acc: 0.9806 - val_mDice: 0.7980

Epoch 00130: val_mDice did not improve from 0.80048
Epoch 131/300
 - 23s - loss: 0.4094 - acc: 0.9676 - mDice: 0.8027 - val_loss: 0.4423 - val_acc: 0.9801 - val_mDice: 0.7971

Epoch 00131: val_mDice did not improve from 0.80048
Epoch 132/300
 - 22s - loss: 0.4082 - acc: 0.9675 - mDice: 0.8030 - val_loss: 0.4631 - val_acc: 0.9798 - val_mDice: 0.7942

Epoch 00132: val_mDice did not improve from 0.80048
Epoch 133/300
 - 22s - loss: 0.4081 - acc: 0.9675 - mDice: 0.8030 - val_loss: 0.4500 - val_acc: 0.9807 - val_mDice: 0.7994

Epoch 00133: val_mDice did not improve from 0.80048
Epoch 134/300
 - 23s - loss: 0.4079 - acc: 0.9676 - mDice: 0.8031 - val_loss: 0.4501 - val_acc: 0.9802 - val_mDice: 0.7957

Epoch 00134: val_mDice did not improve from 0.80048
Epoch 135/300
 - 23s - loss: 0.4082 - acc: 0.9676 - mDice: 0.8028 - val_loss: 0.4435 - val_acc: 0.9802 - val_mDice: 0.7967

Epoch 00135: val_mDice did not improve from 0.80048
Epoch 136/300
 - 22s - loss: 0.4084 - acc: 0.9676 - mDice: 0.8032 - val_loss: 0.4501 - val_acc: 0.9801 - val_mDice: 0.7981

Epoch 00136: val_mDice did not improve from 0.80048
Epoch 137/300
 - 22s - loss: 0.4072 - acc: 0.9676 - mDice: 0.8036 - val_loss: 0.4512 - val_acc: 0.9799 - val_mDice: 0.7971

Epoch 00137: val_mDice did not improve from 0.80048
Epoch 138/300
 - 23s - loss: 0.4069 - acc: 0.9676 - mDice: 0.8035 - val_loss: 0.4511 - val_acc: 0.9803 - val_mDice: 0.7966

Epoch 00138: val_mDice did not improve from 0.80048
Epoch 139/300
 - 24s - loss: 0.4061 - acc: 0.9676 - mDice: 0.8041 - val_loss: 0.4548 - val_acc: 0.9800 - val_mDice: 0.7980

Epoch 00139: val_mDice did not improve from 0.80048
Epoch 140/300
 - 22s - loss: 0.4056 - acc: 0.9676 - mDice: 0.8042 - val_loss: 0.4511 - val_acc: 0.9803 - val_mDice: 0.7983

Epoch 00140: val_mDice did not improve from 0.80048
Epoch 141/300
 - 22s - loss: 0.4053 - acc: 0.9677 - mDice: 0.8046 - val_loss: 0.4491 - val_acc: 0.9801 - val_mDice: 0.7981

Epoch 00141: val_mDice did not improve from 0.80048
Epoch 142/300
 - 23s - loss: 0.4050 - acc: 0.9676 - mDice: 0.8043 - val_loss: 0.4513 - val_acc: 0.9806 - val_mDice: 0.7978

Epoch 00142: val_mDice did not improve from 0.80048
Epoch 143/300
 - 24s - loss: 0.4052 - acc: 0.9676 - mDice: 0.8046 - val_loss: 0.4492 - val_acc: 0.9801 - val_mDice: 0.7974

Epoch 00143: val_mDice did not improve from 0.80048
Epoch 144/300
 - 22s - loss: 0.4055 - acc: 0.9677 - mDice: 0.8041 - val_loss: 0.4466 - val_acc: 0.9804 - val_mDice: 0.7975

Epoch 00144: val_mDice did not improve from 0.80048
Epoch 145/300
 - 22s - loss: 0.4057 - acc: 0.9676 - mDice: 0.8042 - val_loss: 0.4524 - val_acc: 0.9791 - val_mDice: 0.7957

Epoch 00145: val_mDice did not improve from 0.80048
Epoch 146/300
 - 22s - loss: 0.4042 - acc: 0.9677 - mDice: 0.8052 - val_loss: 0.4525 - val_acc: 0.9805 - val_mDice: 0.7962

Epoch 00146: val_mDice did not improve from 0.80048
Restoring model weights from the end of the best epoch
Epoch 00146: early stopping
{'val_loss': [1.6706216042501885, 0.8145557233546663, 0.6727001381609339, 0.5835755072511017, 0.57581227771761, 0.5277897363722754, 0.5091741779824898, 0.49485715633206323, 0.5014826168524346, 0.47666597729250865, 0.4962921140117665, 0.4851151818276928, 0.4818158423445419, 0.47230895587903426, 0.4745896605638282, 0.47565234091874864, 0.47403537516623456, 0.4640951618567586, 0.4578646660712235, 0.47021444128024686, 0.46172701319058734, 0.45780213621624727, 0.4521474547614992, 0.45627759429323417, 0.4586170405856842, 0.4559374568816678, 0.4462482605371682, 0.45227471381518125, 0.4485046993960291, 0.4613999177550876, 0.46281453388886307, 0.4499697218984519, 0.44912161869530337, 0.4465285140109874, 0.4558982181413747, 0.46339813960472004, 0.4535963018612227, 0.4444016674908322, 0.4430510894740452, 0.4481038827337594, 0.45343731268394594, 0.4530644235042596, 0.45301505661847297, 0.44765436584735435, 0.44833219368145316, 0.44449182117686553, 0.44188516317137255, 0.44955098570561874, 0.4396279703045285, 0.4519001603803152, 0.45707671514974657, 0.45676474496183994, 0.45246133060647237, 0.442815691878552, 0.4532009851575759, 0.45264666196116476, 0.4464549780568594, 0.44459865339892324, 0.4497662621508934, 0.451134043027742, 0.4396749590941627, 0.4363376753495082, 0.44691392982338235, 0.4570404314527325, 0.4516772606916595, 0.4391998980805601, 0.4495288847769746, 0.44363551566106246, 0.46241005704621907, 0.45318851966729967, 0.44462821684139553, 0.4451076337612081, 0.4481465329941827, 0.44681265547302607, 0.44542709688038035, 0.4473104866911629, 0.4407559584045804, 0.45279332134253714, 0.44972555017938803, 0.4537576157119129, 0.44208092257088305, 0.44874587285998435, 0.44621075995812354, 0.44400614475441175, 0.4523782681508453, 0.4532345023133068, 0.4443313969362631, 0.446201201193842, 0.44406876229403314, 0.4436084547217539, 0.4476259345855752, 0.4387160585760701, 0.452417158120926, 0.44625326114542346, 0.45056640212995963, 0.4423777447519411, 0.4499636727343895, 0.45311106792175365, 0.4435236956866533, 0.4554505434629226, 0.44863341267386947, 0.43782233727482694, 0.4665053160197964, 0.4601712804153116, 0.44749625130211484, 0.4761051115790388, 0.4471475363269802, 0.4633887510120069, 0.454615206633559, 0.4453710316996579, 0.4494284701421165, 0.44678647184150505, 0.4596827857819135, 0.4534807120006766, 0.44785672463130655, 0.4390188661337637, 0.4442871574646917, 0.45110950928846505, 0.45416361382625176, 0.4527001093046584, 0.45379748396091046, 0.45285401360292304, 0.4585096030904536, 0.46412247920676036, 0.4492350554072574, 0.4508175259404138, 0.45586824700067163, 0.44851557964264915, 0.4472956545151178, 0.4441139392931518, 0.44229070038003204, 0.46312625274077535, 0.4500142878423165, 0.4500544134554356, 0.4435103138902977, 0.45006653488112924, 0.4511849166992648, 0.45105517762487274, 0.4548047620445582, 0.45113288971784804, 0.44905515850143907, 0.4512721766997417, 0.44922769426438336, 0.4465547510037358, 0.45237962755502437, 0.4525053494670443], 'val_acc': [0.9341216692614481, 0.9665428648546138, 0.9699188878046593, 0.9747395584334776, 0.9752470056215922, 0.976363571374163, 0.9761006319731996, 0.977297494778077, 0.9765396313770637, 0.9767285260622716, 0.97669066936239, 0.977483422579042, 0.9767360894549619, 0.9788079684978914, 0.9783393615785644, 0.9786220450027316, 0.9783689825035348, 0.9789392713791815, 0.9787010273082092, 0.9787378773108601, 0.9785815549339673, 0.9789270880421618, 0.9790610266297717, 0.9786496882714231, 0.9787513675827483, 0.9791100627989715, 0.9792443345943841, 0.9790712383386397, 0.979801126985481, 0.9775910357818761, 0.9787375474246786, 0.9789234695050738, 0.9784637497059455, 0.9795839494965025, 0.9792479534390295, 0.979415119001863, 0.9797343275864427, 0.9792124025592863, 0.9793845202900677, 0.9796296891413236, 0.9789553911447278, 0.9794950944720408, 0.9791107194957596, 0.9796224524362168, 0.9790748563221242, 0.9797096527397817, 0.9798445744042057, 0.9793078440507745, 0.9799360560927967, 0.9795589322153136, 0.979319690673836, 0.9790241637097055, 0.9789962003351611, 0.9796082888594353, 0.9798448981392371, 0.9797211616031894, 0.9794131382700091, 0.9791870671406127, 0.9800555169643879, 0.9803046213830096, 0.9798393136945671, 0.9791492189293183, 0.9794207103973326, 0.979276905180377, 0.9796997696253538, 0.9798909772045226, 0.9795625560423907, 0.9795783480131466, 0.9797405883500696, 0.980205238111494, 0.979895576419476, 0.9799508594507035, 0.9800476145203022, 0.9799505250126708, 0.979605987837194, 0.9800969632294402, 0.979859048368023, 0.9792351118059227, 0.9796425128745836, 0.9800324741408798, 0.9803112064967829, 0.97935424925004, 0.9802621730340892, 0.9803868923393935, 0.9799992395997417, 0.9793621435130959, 0.9799337509492848, 0.9799327672573558, 0.9799110502527472, 0.979719198955717, 0.9800239250263808, 0.9798702342345372, 0.979593156722554, 0.9802753249312087, 0.9797902719893322, 0.9793555663343061, 0.9798165995885221, 0.9799465802800914, 0.9799228989056882, 0.9800617651796686, 0.9799400027937442, 0.980035759347142, 0.9791577713039268, 0.9800123995548677, 0.9798369969868931, 0.979242018870894, 0.9802358411906058, 0.979523380043829, 0.9797955275935162, 0.9804109177476236, 0.9801071742616817, 0.9799143316452963, 0.9801716696244153, 0.9800262236496735, 0.9800821610402519, 0.9801710161262253, 0.9804115674321005, 0.9798541043195931, 0.9803941303977534, 0.9801209954039354, 0.9800104193766174, 0.9801374438254333, 0.9797070180791574, 0.9799548078124615, 0.980350373207108, 0.9802075416557068, 0.9798554261402449, 0.9798379905206623, 0.98035563077966, 0.9806386339406111, 0.9800683382986992, 0.9798248223845065, 0.98069062167769, 0.9802200555555346, 0.9802286086067695, 0.980140093002772, 0.9799202604928622, 0.9802802750692771, 0.9800203049515054, 0.9803319342734275, 0.9801305421734742, 0.9806202102617829, 0.980102563728612, 0.9804464662284181, 0.9791426415659941, 0.9805412270951444], 'val_mDice': [0.35092895109710065, 0.6182464752403944, 0.6886177042689485, 0.728590843416712, 0.7384021348628467, 0.7521263002365121, 0.7584905860593814, 0.7639013826539519, 0.7671609913355549, 0.7710152704526273, 0.7713463989204666, 0.7720227848634631, 0.7759094122024512, 0.7787950775817698, 0.7802609283980694, 0.7799591567248136, 0.7814693951631355, 0.7845690286688515, 0.7848721842278638, 0.7838815418682354, 0.7845506337774059, 0.7877088620320686, 0.7889660656513691, 0.7891988133621413, 0.7883425870423961, 0.789550171055907, 0.7915753000660947, 0.7891189861961931, 0.791900239062137, 0.7874348476083163, 0.7898276892977971, 0.7902757626938008, 0.7922101280391524, 0.7930458013979397, 0.7880632098614246, 0.7894736518554766, 0.7899172839980623, 0.793654390163835, 0.7944503427782049, 0.7934611867209829, 0.7916819140145899, 0.7915047634127709, 0.7928186076836443, 0.7954128925276246, 0.7926836862037548, 0.7955236426324913, 0.7963814472143372, 0.7941225715465959, 0.7966700067092022, 0.7929898762481501, 0.7928840160615919, 0.791289255099892, 0.793003686502868, 0.7955182958067509, 0.7940241022744784, 0.7937084807946094, 0.7949815199963203, 0.7960886551745782, 0.7935296795316525, 0.7960222898006931, 0.7976373119127885, 0.797767071408999, 0.792922858483282, 0.7933997489719568, 0.7942413308180031, 0.7978964106586326, 0.7965860146610114, 0.7964252513997695, 0.7936399125093277, 0.794458010309867, 0.7965103612964737, 0.7979764296174419, 0.7955717389674625, 0.7981971766188418, 0.7966861815890538, 0.7963957107473084, 0.7978625805631387, 0.7960425885961274, 0.7942876874846939, 0.7936279359739754, 0.7981704740455399, 0.7969430853584849, 0.7969738925327581, 0.7963480584638652, 0.7954007284437048, 0.7943982755067548, 0.7975681749536773, 0.7965280804840773, 0.7971190343331257, 0.7949566534798211, 0.7954259007338769, 0.798513505727022, 0.795507760670409, 0.796484839128882, 0.796607379635298, 0.7965865180711382, 0.7962888519215264, 0.7946464774286291, 0.7980657112856767, 0.7944099457148305, 0.7949826595583936, 0.7991406689979467, 0.7913727618838489, 0.7943873909235739, 0.7974425741885591, 0.7896642216833999, 0.7977785684621986, 0.7940312277052793, 0.7941349121070129, 0.7971852952604815, 0.795274135805628, 0.796933465574794, 0.7956937513361282, 0.7959929929183117, 0.7966002137299293, 0.800477059140909, 0.798132950799507, 0.7971579083717275, 0.7942532134252928, 0.7951784137601823, 0.795452942850666, 0.7954707201051269, 0.7959377042280262, 0.7943405914970965, 0.7957385311554829, 0.7942422547822643, 0.7963527602184913, 0.7983293564696061, 0.7995448754667867, 0.7979793481536448, 0.7971421001004237, 0.7941550632748442, 0.7994159008573329, 0.7957018234904459, 0.7966743766707901, 0.7981455867381534, 0.7971451584522692, 0.7965601343119476, 0.7979889478845862, 0.7982771947780015, 0.7980871127977952, 0.7977959664367423, 0.7973578721131087, 0.7975237952051271, 0.7956691092135859, 0.7962428058264056], 'loss': [8.186035701816852, 1.5298009156070407, 1.1034596265643544, 0.9325768580891108, 0.8374182965552177, 0.767504135748638, 0.7250057490195982, 0.6912108469556049, 0.6667830612228399, 0.6441563159504966, 0.6228990567479294, 0.6102799794285002, 0.5916070010586915, 0.5837759472161055, 0.5726092015327461, 0.5620840276294088, 0.5529484519112614, 0.5462654351312618, 0.5406358374960245, 0.5333151738385127, 0.5279849216694305, 0.5206830300335558, 0.516591265758467, 0.5119858349824481, 0.5045298289819922, 0.5039710555486301, 0.5011221760635248, 0.4960830728037419, 0.49399014768607297, 0.49013916867315155, 0.4876468925280192, 0.4829143083000172, 0.4825366096455868, 0.479329282350719, 0.4752184420446806, 0.47342085698452663, 0.4729728552850699, 0.4712463766692332, 0.4670834874150176, 0.4664714140655148, 0.46508071366061393, 0.4640492848502101, 0.46047293185006183, 0.46015834743221534, 0.4589397600158633, 0.45755158922810074, 0.45513270872929573, 0.4542238752312953, 0.4534780901251928, 0.45076501896195176, 0.4507299856451152, 0.44943390860317256, 0.44907306251788953, 0.44732826442800505, 0.4473598887670117, 0.4449047462871031, 0.4455595581848125, 0.4453595611056594, 0.44287561528261904, 0.44113571513715555, 0.4419993330384884, 0.4401045935924679, 0.43991351271760415, 0.4396046339639878, 0.4366351012429674, 0.4367496892720895, 0.4368688811870358, 0.4364104528813764, 0.4343322095393793, 0.4341288009804816, 0.43282627893897835, 0.4335187462916772, 0.4336271202625453, 0.4321444774331698, 0.43088971937161114, 0.42960258920109584, 0.43012839644001355, 0.42957204350401346, 0.4276426415476732, 0.4281756250783427, 0.4271254491444445, 0.4266152037857027, 0.427477632202822, 0.42708051494020877, 0.4265505118054879, 0.4256271436500868, 0.42414366897860206, 0.4235865405878817, 0.42571801196669007, 0.4226769484083095, 0.42279713696430715, 0.4229113846156032, 0.42164318658569877, 0.4210968331758806, 0.4208141016859071, 0.42163130794372655, 0.4203186356703877, 0.4201852727333515, 0.4193343625472672, 0.41775198495769544, 0.4188296489074118, 0.4185701009088067, 0.4183102340709061, 0.4182319747702672, 0.4172073387219908, 0.4173318207235475, 0.41654469791362925, 0.41625563025559964, 0.4153227888053034, 0.41423654435983215, 0.41479329676226095, 0.4143942760586995, 0.41472855078980436, 0.4146770063244075, 0.41400698667242214, 0.41353965522011854, 0.4138256955899855, 0.41316865723387053, 0.4124814167081356, 0.4117285742953594, 0.41164348202401424, 0.4103513654381044, 0.4100211063830984, 0.41131618197590064, 0.4100448179990943, 0.41046708118653624, 0.4103618720450719, 0.40821747087139715, 0.4092611897979683, 0.4085864930142074, 0.40935641350653906, 0.4081639681827319, 0.4080727996185853, 0.40793148414143976, 0.40822466973020494, 0.4083912106453732, 0.4072104850581531, 0.4069226575810271, 0.4060845515780384, 0.40561695901553785, 0.40532030999760144, 0.4050446500748588, 0.40520388185123796, 0.4055422638968462, 0.4057351245013461, 0.40419456544228777], 'acc': [0.8377293870044311, 0.9355679035599601, 0.9466628185285427, 0.9524278972722307, 0.9552821458695696, 0.9571368842640838, 0.9583444300231997, 0.9593574576967794, 0.9601468287420808, 0.9608508869845457, 0.9615546545493794, 0.961977679710386, 0.9626837105932684, 0.9629818816116097, 0.9634058009704087, 0.9637158261667665, 0.9639657798817313, 0.9641676113589556, 0.9642993858898629, 0.964414243520744, 0.9645945871533999, 0.9647068064139344, 0.9647715895734541, 0.9650100810746461, 0.9652595407202046, 0.9652748006481187, 0.9654216429969136, 0.9654700716497906, 0.9655944397021285, 0.9657178360151168, 0.9657327064984962, 0.9658817305452704, 0.9659447889567732, 0.9659351931641544, 0.9661022111869582, 0.9660963277230833, 0.966149894838718, 0.9661097394301152, 0.9662585060608424, 0.9663660712193156, 0.9663446240388667, 0.9663543050602907, 0.9664396334511584, 0.9664444117876918, 0.9664191165985684, 0.9663929476825098, 0.9665294815026578, 0.966524176561152, 0.9664257426790899, 0.9665439426614243, 0.9665645702032705, 0.966512943121309, 0.9665724823177074, 0.9666490303479262, 0.9665885895796713, 0.9666322947388365, 0.9665792984084979, 0.9666397401874834, 0.9667107863616397, 0.9667422400259419, 0.9667162042772226, 0.9667534734800205, 0.9668220533998935, 0.9667883437773707, 0.9668815253115167, 0.9668671131020148, 0.9668061656729259, 0.9668527187440115, 0.9669096286310511, 0.9669410150319316, 0.9669046990265561, 0.9668468755954828, 0.966856441187181, 0.96691205538142, 0.966962245695341, 0.9669786761349131, 0.9669724769244366, 0.966952352940054, 0.9670682096996653, 0.9669707180820504, 0.967015375349611, 0.9669946312676587, 0.9670794251385355, 0.9671322503065989, 0.9670808150072442, 0.9670404876534057, 0.9670539872797799, 0.9670418896437659, 0.9670419460525085, 0.9670984752499349, 0.9671298507391937, 0.9671575927722986, 0.9672155402883699, 0.9672245646622063, 0.9672398814045788, 0.9671534506694383, 0.9671812208962378, 0.96720875246957, 0.9671958047804982, 0.967283043829786, 0.9672903864686062, 0.96727120269162, 0.9672473263265069, 0.9672565124315039, 0.9672873971397905, 0.9672450599477944, 0.9673050551759562, 0.9673498855489576, 0.9673652788790992, 0.9673831937618862, 0.9673519703306672, 0.9674071650929857, 0.967420141502471, 0.9674262518611705, 0.9674125343938417, 0.9674337081360254, 0.9674109246271277, 0.9675105337755533, 0.9674981849515868, 0.9674837715249373, 0.967468921519533, 0.9674952991087908, 0.9675233547745042, 0.967523106383856, 0.9674770500371244, 0.9675614074075424, 0.967538910568942, 0.9675636231714199, 0.9675314948799105, 0.9675576857188621, 0.9675514687921256, 0.967532704888365, 0.9675407669112596, 0.9675907185147706, 0.9675720970884609, 0.967557656066014, 0.9675824361952728, 0.9676128422086495, 0.9675857287504407, 0.967649958976163, 0.9676865353585998, 0.9676487804356013, 0.9676307772846987, 0.967656938876518, 0.9676473138367672, 0.9676676761044902], 'mDice': [0.1335605620962648, 0.40173674208795596, 0.5288057235735312, 0.5911423355262662, 0.6279143534328478, 0.6543604266196525, 0.6713807502281475, 0.6845557173339911, 0.694806066644428, 0.7045033773403336, 0.7128636910746255, 0.7184242991023682, 0.7263338448951773, 0.7296589391098292, 0.7343414308975271, 0.7389559520011247, 0.7423824658677434, 0.7454742103893375, 0.7478593648163322, 0.7512305262751018, 0.7534425669263649, 0.7562119411075489, 0.7579197467996307, 0.7601253017978905, 0.763138888479845, 0.7638024658512779, 0.7649377811729466, 0.7669083149572076, 0.7678901825410699, 0.7693273001022375, 0.770530060108049, 0.772217144993458, 0.7727891841651091, 0.7737566346851146, 0.7758692914599133, 0.776267565667615, 0.77667716251571, 0.7771584438286848, 0.7790124945988484, 0.7792759898641612, 0.7797497344708881, 0.7803049091937464, 0.7818680765778574, 0.7819839432312419, 0.7822576129254276, 0.7830487674692521, 0.7840391996654485, 0.7846887338152927, 0.7847409931876536, 0.7860302545801108, 0.7856800272964708, 0.7864430716591801, 0.7866265012522088, 0.7874691445787055, 0.7871084711504404, 0.7880758175722933, 0.7877967689183666, 0.7877343427403206, 0.7889841847710716, 0.7895967392213082, 0.7895152586540517, 0.790024079063897, 0.7902643680216619, 0.7907419230834323, 0.7917187932085985, 0.7915025656223866, 0.7916264170489392, 0.791726172105606, 0.7925473675327538, 0.792676362191005, 0.7930677731594608, 0.7928335672849, 0.7929269830167563, 0.7935295592480125, 0.7939689407235887, 0.7944046582146707, 0.7941822038221849, 0.7945252392865434, 0.7954095245574977, 0.7949528785688028, 0.7955050889677554, 0.795679533164143, 0.7954854746977527, 0.7955719066429229, 0.7956575900707719, 0.795893140501984, 0.7967378438615218, 0.7973271464074401, 0.7961001078510785, 0.7972150288036453, 0.796951248277364, 0.7970771963866252, 0.7975050717385822, 0.7976098474438105, 0.7982023733525451, 0.7977213350704982, 0.7982460192202496, 0.7981082962539847, 0.7987716540690678, 0.7992100942553385, 0.7986645952155376, 0.7989586322738073, 0.7989091975950301, 0.7987606312384719, 0.799583727216732, 0.7994613490299419, 0.8000010160036636, 0.7999090711626883, 0.8003282927159965, 0.800615834220372, 0.8004187283864419, 0.8005679571204348, 0.800564172011957, 0.8006339006700691, 0.8008661631228732, 0.8011608705020674, 0.8008115876538103, 0.8012636467469231, 0.8014096237962844, 0.8016209726277245, 0.801884338818446, 0.8022564971948085, 0.8024601491476432, 0.8018281568924567, 0.8025156930747396, 0.8023584323265913, 0.8023116083511852, 0.803129644924341, 0.8026283635980963, 0.8030539762654907, 0.8027440523486278, 0.8029973848654144, 0.8030437676283634, 0.8031274436238788, 0.8027911112762335, 0.8031886360270613, 0.8036235602154833, 0.803462941193313, 0.8040732178834392, 0.8042394523763531, 0.8046273778041223, 0.8042863310308709, 0.8045666462301154, 0.8041204833346618, 0.8041572121452654, 0.8051611484662997]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:31,  2.23s/it]predicting test subjects:  13%|█▎        | 2/15 [00:04<00:27,  2.14s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:25,  2.14s/it]predicting test subjects:  27%|██▋       | 4/15 [00:08<00:23,  2.11s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:22,  2.21s/it]predicting test subjects:  40%|████      | 6/15 [00:13<00:20,  2.28s/it]predicting test subjects:  47%|████▋     | 7/15 [00:14<00:16,  2.08s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:17<00:15,  2.21s/it]predicting test subjects:  60%|██████    | 9/15 [00:19<00:13,  2.17s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:21<00:10,  2.03s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:22<00:07,  1.97s/it]predicting test subjects:  80%|████████  | 12/15 [00:25<00:06,  2.05s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:27<00:04,  2.08s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:29<00:02,  2.04s/it]predicting test subjects: 100%|██████████| 15/15 [00:31<00:00,  2.08s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<20:48,  2.35s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:23,  2.20s/it]predicting train subjects:   1%|          | 3/532 [00:06<18:44,  2.13s/it]predicting train subjects:   1%|          | 4/532 [00:08<18:05,  2.06s/it]predicting train subjects:   1%|          | 5/532 [00:10<17:55,  2.04s/it]predicting train subjects:   1%|          | 6/532 [00:11<17:21,  1.98s/it]predicting train subjects:   1%|▏         | 7/532 [00:13<16:49,  1.92s/it]predicting train subjects:   2%|▏         | 8/532 [00:15<16:26,  1.88s/it]predicting train subjects:   2%|▏         | 9/532 [00:17<17:10,  1.97s/it]predicting train subjects:   2%|▏         | 10/532 [00:19<16:51,  1.94s/it]predicting train subjects:   2%|▏         | 11/532 [00:21<16:07,  1.86s/it]predicting train subjects:   2%|▏         | 12/532 [00:23<17:05,  1.97s/it]predicting train subjects:   2%|▏         | 13/532 [00:25<16:17,  1.88s/it]predicting train subjects:   3%|▎         | 14/532 [00:26<15:56,  1.85s/it]predicting train subjects:   3%|▎         | 15/532 [00:28<16:02,  1.86s/it]predicting train subjects:   3%|▎         | 16/532 [00:30<16:15,  1.89s/it]predicting train subjects:   3%|▎         | 17/532 [00:32<15:46,  1.84s/it]predicting train subjects:   3%|▎         | 18/532 [00:34<16:41,  1.95s/it]predicting train subjects:   4%|▎         | 19/532 [00:36<15:35,  1.82s/it]predicting train subjects:   4%|▍         | 20/532 [00:38<15:47,  1.85s/it]predicting train subjects:   4%|▍         | 21/532 [00:40<16:30,  1.94s/it]predicting train subjects:   4%|▍         | 22/532 [00:41<16:05,  1.89s/it]predicting train subjects:   4%|▍         | 23/532 [00:43<16:17,  1.92s/it]predicting train subjects:   5%|▍         | 24/532 [00:45<15:36,  1.84s/it]predicting train subjects:   5%|▍         | 25/532 [00:48<16:58,  2.01s/it]predicting train subjects:   5%|▍         | 26/532 [00:49<16:26,  1.95s/it]predicting train subjects:   5%|▌         | 27/532 [00:52<17:28,  2.08s/it]predicting train subjects:   5%|▌         | 28/532 [00:54<16:53,  2.01s/it]predicting train subjects:   5%|▌         | 29/532 [00:56<17:16,  2.06s/it]predicting train subjects:   6%|▌         | 30/532 [00:58<16:28,  1.97s/it]predicting train subjects:   6%|▌         | 31/532 [00:59<16:27,  1.97s/it]predicting train subjects:   6%|▌         | 32/532 [01:01<16:21,  1.96s/it]predicting train subjects:   6%|▌         | 33/532 [01:03<15:40,  1.88s/it]predicting train subjects:   6%|▋         | 34/532 [01:05<16:47,  2.02s/it]predicting train subjects:   7%|▋         | 35/532 [01:07<16:26,  1.99s/it]predicting train subjects:   7%|▋         | 36/532 [01:09<16:36,  2.01s/it]predicting train subjects:   7%|▋         | 37/532 [01:11<16:25,  1.99s/it]predicting train subjects:   7%|▋         | 38/532 [01:13<16:35,  2.02s/it]predicting train subjects:   7%|▋         | 39/532 [01:15<16:28,  2.01s/it]predicting train subjects:   8%|▊         | 40/532 [01:17<15:45,  1.92s/it]predicting train subjects:   8%|▊         | 41/532 [01:19<16:02,  1.96s/it]predicting train subjects:   8%|▊         | 42/532 [01:21<16:02,  1.96s/it]predicting train subjects:   8%|▊         | 43/532 [01:23<15:09,  1.86s/it]predicting train subjects:   8%|▊         | 44/532 [01:24<14:39,  1.80s/it]predicting train subjects:   8%|▊         | 45/532 [01:26<14:31,  1.79s/it]predicting train subjects:   9%|▊         | 46/532 [01:28<14:59,  1.85s/it]predicting train subjects:   9%|▉         | 47/532 [01:31<16:09,  2.00s/it]predicting train subjects:   9%|▉         | 48/532 [01:33<16:15,  2.02s/it]predicting train subjects:   9%|▉         | 49/532 [01:34<15:29,  1.92s/it]predicting train subjects:   9%|▉         | 50/532 [01:37<16:02,  2.00s/it]predicting train subjects:  10%|▉         | 51/532 [01:38<15:42,  1.96s/it]predicting train subjects:  10%|▉         | 52/532 [01:40<15:28,  1.94s/it]predicting train subjects:  10%|▉         | 53/532 [01:42<15:03,  1.89s/it]predicting train subjects:  10%|█         | 54/532 [01:44<16:00,  2.01s/it]predicting train subjects:  10%|█         | 55/532 [01:46<15:58,  2.01s/it]predicting train subjects:  11%|█         | 56/532 [01:48<16:15,  2.05s/it]predicting train subjects:  11%|█         | 57/532 [01:50<16:05,  2.03s/it]predicting train subjects:  11%|█         | 58/532 [01:53<16:20,  2.07s/it]predicting train subjects:  11%|█         | 59/532 [01:55<17:08,  2.18s/it]predicting train subjects:  11%|█▏        | 60/532 [01:57<16:08,  2.05s/it]predicting train subjects:  11%|█▏        | 61/532 [01:59<15:31,  1.98s/it]predicting train subjects:  12%|█▏        | 62/532 [02:01<16:04,  2.05s/it]predicting train subjects:  12%|█▏        | 63/532 [02:03<16:51,  2.16s/it]predicting train subjects:  12%|█▏        | 64/532 [02:05<16:11,  2.07s/it]predicting train subjects:  12%|█▏        | 65/532 [02:07<16:00,  2.06s/it]predicting train subjects:  12%|█▏        | 66/532 [02:10<16:56,  2.18s/it]predicting train subjects:  13%|█▎        | 67/532 [02:12<17:20,  2.24s/it]predicting train subjects:  13%|█▎        | 68/532 [02:14<17:07,  2.22s/it]predicting train subjects:  13%|█▎        | 69/532 [02:16<16:27,  2.13s/it]predicting train subjects:  13%|█▎        | 70/532 [02:18<15:42,  2.04s/it]predicting train subjects:  13%|█▎        | 71/532 [02:20<15:08,  1.97s/it]predicting train subjects:  14%|█▎        | 72/532 [02:22<14:49,  1.93s/it]predicting train subjects:  14%|█▎        | 73/532 [02:24<15:23,  2.01s/it]predicting train subjects:  14%|█▍        | 74/532 [02:26<16:42,  2.19s/it]predicting train subjects:  14%|█▍        | 75/532 [02:29<18:48,  2.47s/it]predicting train subjects:  14%|█▍        | 76/532 [02:31<17:27,  2.30s/it]predicting train subjects:  14%|█▍        | 77/532 [02:33<16:50,  2.22s/it]predicting train subjects:  15%|█▍        | 78/532 [02:36<16:41,  2.21s/it]predicting train subjects:  15%|█▍        | 79/532 [02:38<16:17,  2.16s/it]predicting train subjects:  15%|█▌        | 80/532 [02:40<16:05,  2.14s/it]predicting train subjects:  15%|█▌        | 81/532 [02:42<16:05,  2.14s/it]predicting train subjects:  15%|█▌        | 82/532 [02:44<15:57,  2.13s/it]predicting train subjects:  16%|█▌        | 83/532 [02:46<15:04,  2.01s/it]predicting train subjects:  16%|█▌        | 84/532 [02:48<14:44,  1.98s/it]predicting train subjects:  16%|█▌        | 85/532 [02:49<14:23,  1.93s/it]predicting train subjects:  16%|█▌        | 86/532 [02:51<13:56,  1.88s/it]predicting train subjects:  16%|█▋        | 87/532 [02:53<13:32,  1.83s/it]predicting train subjects:  17%|█▋        | 88/532 [02:55<13:30,  1.83s/it]predicting train subjects:  17%|█▋        | 89/532 [02:57<13:50,  1.87s/it]predicting train subjects:  17%|█▋        | 90/532 [02:59<13:54,  1.89s/it]predicting train subjects:  17%|█▋        | 91/532 [03:01<14:05,  1.92s/it]predicting train subjects:  17%|█▋        | 92/532 [03:03<14:17,  1.95s/it]predicting train subjects:  17%|█▋        | 93/532 [03:05<14:18,  1.96s/it]predicting train subjects:  18%|█▊        | 94/532 [03:07<14:09,  1.94s/it]predicting train subjects:  18%|█▊        | 95/532 [03:09<14:52,  2.04s/it]predicting train subjects:  18%|█▊        | 96/532 [03:11<15:18,  2.11s/it]predicting train subjects:  18%|█▊        | 97/532 [03:13<15:35,  2.15s/it]predicting train subjects:  18%|█▊        | 98/532 [03:16<15:53,  2.20s/it]predicting train subjects:  19%|█▊        | 99/532 [03:18<15:55,  2.21s/it]predicting train subjects:  19%|█▉        | 100/532 [03:20<16:08,  2.24s/it]predicting train subjects:  19%|█▉        | 101/532 [03:22<15:16,  2.13s/it]predicting train subjects:  19%|█▉        | 102/532 [03:24<14:35,  2.04s/it]predicting train subjects:  19%|█▉        | 103/532 [03:26<14:08,  1.98s/it]predicting train subjects:  20%|█▉        | 104/532 [03:28<13:49,  1.94s/it]predicting train subjects:  20%|█▉        | 105/532 [03:29<13:29,  1.90s/it]predicting train subjects:  20%|█▉        | 106/532 [03:31<13:25,  1.89s/it]predicting train subjects:  20%|██        | 107/532 [03:33<13:19,  1.88s/it]predicting train subjects:  20%|██        | 108/532 [03:35<13:11,  1.87s/it]predicting train subjects:  20%|██        | 109/532 [03:37<12:56,  1.84s/it]predicting train subjects:  21%|██        | 110/532 [03:38<12:48,  1.82s/it]predicting train subjects:  21%|██        | 111/532 [03:40<12:43,  1.81s/it]predicting train subjects:  21%|██        | 112/532 [03:42<12:38,  1.81s/it]predicting train subjects:  21%|██        | 113/532 [03:44<13:08,  1.88s/it]predicting train subjects:  21%|██▏       | 114/532 [03:46<13:34,  1.95s/it]predicting train subjects:  22%|██▏       | 115/532 [03:48<14:04,  2.03s/it]predicting train subjects:  22%|██▏       | 116/532 [03:51<14:13,  2.05s/it]predicting train subjects:  22%|██▏       | 117/532 [03:53<14:13,  2.06s/it]predicting train subjects:  22%|██▏       | 118/532 [03:55<14:11,  2.06s/it]predicting train subjects:  22%|██▏       | 119/532 [03:57<13:55,  2.02s/it]predicting train subjects:  23%|██▎       | 120/532 [03:59<13:49,  2.01s/it]predicting train subjects:  23%|██▎       | 121/532 [04:01<13:48,  2.02s/it]predicting train subjects:  23%|██▎       | 122/532 [04:03<13:55,  2.04s/it]predicting train subjects:  23%|██▎       | 123/532 [04:05<13:56,  2.04s/it]predicting train subjects:  23%|██▎       | 124/532 [04:07<13:39,  2.01s/it]predicting train subjects:  23%|██▎       | 125/532 [04:09<13:51,  2.04s/it]predicting train subjects:  24%|██▎       | 126/532 [04:11<13:58,  2.06s/it]predicting train subjects:  24%|██▍       | 127/532 [04:13<14:21,  2.13s/it]predicting train subjects:  24%|██▍       | 128/532 [04:15<14:15,  2.12s/it]predicting train subjects:  24%|██▍       | 129/532 [04:17<14:19,  2.13s/it]predicting train subjects:  24%|██▍       | 130/532 [04:20<14:20,  2.14s/it]predicting train subjects:  25%|██▍       | 131/532 [04:22<15:06,  2.26s/it]predicting train subjects:  25%|██▍       | 132/532 [04:25<15:38,  2.35s/it]predicting train subjects:  25%|██▌       | 133/532 [04:27<15:51,  2.39s/it]predicting train subjects:  25%|██▌       | 134/532 [04:30<15:54,  2.40s/it]predicting train subjects:  25%|██▌       | 135/532 [04:32<15:58,  2.42s/it]predicting train subjects:  26%|██▌       | 136/532 [04:35<16:07,  2.44s/it]predicting train subjects:  26%|██▌       | 137/532 [04:37<16:18,  2.48s/it]predicting train subjects:  26%|██▌       | 138/532 [04:40<16:24,  2.50s/it]predicting train subjects:  26%|██▌       | 139/532 [04:42<16:17,  2.49s/it]predicting train subjects:  26%|██▋       | 140/532 [04:45<16:12,  2.48s/it]predicting train subjects:  27%|██▋       | 141/532 [04:47<16:11,  2.48s/it]predicting train subjects:  27%|██▋       | 142/532 [04:50<16:09,  2.49s/it]predicting train subjects:  27%|██▋       | 143/532 [04:52<15:06,  2.33s/it]predicting train subjects:  27%|██▋       | 144/532 [04:53<14:20,  2.22s/it]predicting train subjects:  27%|██▋       | 145/532 [04:55<13:50,  2.14s/it]predicting train subjects:  27%|██▋       | 146/532 [04:57<13:10,  2.05s/it]predicting train subjects:  28%|██▊       | 147/532 [04:59<12:53,  2.01s/it]predicting train subjects:  28%|██▊       | 148/532 [05:01<12:41,  1.98s/it]predicting train subjects:  28%|██▊       | 149/532 [05:03<12:40,  1.99s/it]predicting train subjects:  28%|██▊       | 150/532 [05:05<12:43,  2.00s/it]predicting train subjects:  28%|██▊       | 151/532 [05:07<12:32,  1.98s/it]predicting train subjects:  29%|██▊       | 152/532 [05:09<12:18,  1.94s/it]predicting train subjects:  29%|██▉       | 153/532 [05:11<12:18,  1.95s/it]predicting train subjects:  29%|██▉       | 154/532 [05:13<12:19,  1.96s/it]predicting train subjects:  29%|██▉       | 155/532 [05:15<13:27,  2.14s/it]predicting train subjects:  29%|██▉       | 156/532 [05:18<14:14,  2.27s/it]predicting train subjects:  30%|██▉       | 157/532 [05:21<14:42,  2.35s/it]predicting train subjects:  30%|██▉       | 158/532 [05:23<14:49,  2.38s/it]predicting train subjects:  30%|██▉       | 159/532 [05:26<15:02,  2.42s/it]predicting train subjects:  30%|███       | 160/532 [05:28<15:14,  2.46s/it]predicting train subjects:  30%|███       | 161/532 [05:30<14:46,  2.39s/it]predicting train subjects:  30%|███       | 162/532 [05:32<14:13,  2.31s/it]predicting train subjects:  31%|███       | 163/532 [05:35<13:45,  2.24s/it]predicting train subjects:  31%|███       | 164/532 [05:37<13:18,  2.17s/it]predicting train subjects:  31%|███       | 165/532 [05:39<13:22,  2.19s/it]predicting train subjects:  31%|███       | 166/532 [05:41<13:07,  2.15s/it]predicting train subjects:  31%|███▏      | 167/532 [05:43<13:18,  2.19s/it]predicting train subjects:  32%|███▏      | 168/532 [05:45<13:25,  2.21s/it]predicting train subjects:  32%|███▏      | 169/532 [05:47<13:06,  2.17s/it]predicting train subjects:  32%|███▏      | 170/532 [05:49<12:54,  2.14s/it]predicting train subjects:  32%|███▏      | 171/532 [05:52<12:42,  2.11s/it]predicting train subjects:  32%|███▏      | 172/532 [05:54<13:01,  2.17s/it]predicting train subjects:  33%|███▎      | 173/532 [05:56<13:03,  2.18s/it]predicting train subjects:  33%|███▎      | 174/532 [05:58<12:51,  2.15s/it]predicting train subjects:  33%|███▎      | 175/532 [06:00<12:28,  2.10s/it]predicting train subjects:  33%|███▎      | 176/532 [06:02<12:09,  2.05s/it]predicting train subjects:  33%|███▎      | 177/532 [06:04<12:17,  2.08s/it]predicting train subjects:  33%|███▎      | 178/532 [06:06<12:22,  2.10s/it]predicting train subjects:  34%|███▎      | 179/532 [06:08<12:16,  2.09s/it]predicting train subjects:  34%|███▍      | 180/532 [06:10<12:02,  2.05s/it]predicting train subjects:  34%|███▍      | 181/532 [06:13<12:16,  2.10s/it]predicting train subjects:  34%|███▍      | 182/532 [06:15<12:21,  2.12s/it]predicting train subjects:  34%|███▍      | 183/532 [06:17<12:14,  2.11s/it]predicting train subjects:  35%|███▍      | 184/532 [06:19<12:03,  2.08s/it]predicting train subjects:  35%|███▍      | 185/532 [06:21<11:53,  2.06s/it]predicting train subjects:  35%|███▍      | 186/532 [06:23<11:41,  2.03s/it]predicting train subjects:  35%|███▌      | 187/532 [06:25<11:51,  2.06s/it]predicting train subjects:  35%|███▌      | 188/532 [06:27<11:58,  2.09s/it]predicting train subjects:  36%|███▌      | 189/532 [06:29<12:00,  2.10s/it]predicting train subjects:  36%|███▌      | 190/532 [06:31<11:51,  2.08s/it]predicting train subjects:  36%|███▌      | 191/532 [06:34<13:21,  2.35s/it]predicting train subjects:  36%|███▌      | 192/532 [06:37<13:53,  2.45s/it]predicting train subjects:  36%|███▋      | 193/532 [06:40<14:14,  2.52s/it]predicting train subjects:  36%|███▋      | 194/532 [06:42<14:09,  2.51s/it]predicting train subjects:  37%|███▋      | 195/532 [06:45<13:57,  2.49s/it]predicting train subjects:  37%|███▋      | 196/532 [06:47<14:02,  2.51s/it]predicting train subjects:  37%|███▋      | 197/532 [06:50<13:59,  2.51s/it]predicting train subjects:  37%|███▋      | 198/532 [06:52<13:30,  2.43s/it]predicting train subjects:  37%|███▋      | 199/532 [06:54<12:59,  2.34s/it]predicting train subjects:  38%|███▊      | 200/532 [06:56<12:46,  2.31s/it]predicting train subjects:  38%|███▊      | 201/532 [06:58<12:31,  2.27s/it]predicting train subjects:  38%|███▊      | 202/532 [07:00<12:14,  2.22s/it]predicting train subjects:  38%|███▊      | 203/532 [07:02<11:37,  2.12s/it]predicting train subjects:  38%|███▊      | 204/532 [07:04<11:08,  2.04s/it]predicting train subjects:  39%|███▊      | 205/532 [07:06<10:47,  1.98s/it]predicting train subjects:  39%|███▊      | 206/532 [07:08<10:35,  1.95s/it]predicting train subjects:  39%|███▉      | 207/532 [07:10<10:28,  1.93s/it]predicting train subjects:  39%|███▉      | 208/532 [07:12<10:18,  1.91s/it]predicting train subjects:  39%|███▉      | 209/532 [07:13<09:50,  1.83s/it]predicting train subjects:  39%|███▉      | 210/532 [07:15<09:41,  1.80s/it]predicting train subjects:  40%|███▉      | 211/532 [07:17<09:27,  1.77s/it]predicting train subjects:  40%|███▉      | 212/532 [07:18<09:16,  1.74s/it]predicting train subjects:  40%|████      | 213/532 [07:20<09:13,  1.74s/it]predicting train subjects:  40%|████      | 214/532 [07:22<09:08,  1.73s/it]predicting train subjects:  40%|████      | 215/532 [07:24<10:00,  1.89s/it]predicting train subjects:  41%|████      | 216/532 [07:26<10:35,  2.01s/it]predicting train subjects:  41%|████      | 217/532 [07:29<10:54,  2.08s/it]predicting train subjects:  41%|████      | 218/532 [07:31<11:32,  2.20s/it]predicting train subjects:  41%|████      | 219/532 [07:33<11:38,  2.23s/it]predicting train subjects:  41%|████▏     | 220/532 [07:36<11:43,  2.25s/it]predicting train subjects:  42%|████▏     | 221/532 [07:38<10:57,  2.11s/it]predicting train subjects:  42%|████▏     | 222/532 [07:39<10:22,  2.01s/it]predicting train subjects:  42%|████▏     | 223/532 [07:41<09:55,  1.93s/it]predicting train subjects:  42%|████▏     | 224/532 [07:43<09:35,  1.87s/it]predicting train subjects:  42%|████▏     | 225/532 [07:45<09:20,  1.82s/it]predicting train subjects:  42%|████▏     | 226/532 [07:46<09:07,  1.79s/it]predicting train subjects:  43%|████▎     | 227/532 [07:48<08:57,  1.76s/it]predicting train subjects:  43%|████▎     | 228/532 [07:50<08:40,  1.71s/it]predicting train subjects:  43%|████▎     | 229/532 [07:51<08:27,  1.67s/it]predicting train subjects:  43%|████▎     | 230/532 [07:53<08:17,  1.65s/it]predicting train subjects:  43%|████▎     | 231/532 [07:54<08:13,  1.64s/it]predicting train subjects:  44%|████▎     | 232/532 [07:56<08:29,  1.70s/it]predicting train subjects:  44%|████▍     | 233/532 [07:58<08:42,  1.75s/it]predicting train subjects:  44%|████▍     | 234/532 [08:00<08:48,  1.77s/it]predicting train subjects:  44%|████▍     | 235/532 [08:02<08:49,  1.78s/it]predicting train subjects:  44%|████▍     | 236/532 [08:03<08:53,  1.80s/it]predicting train subjects:  45%|████▍     | 237/532 [08:05<09:05,  1.85s/it]predicting train subjects:  45%|████▍     | 238/532 [08:07<09:02,  1.85s/it]predicting train subjects:  45%|████▍     | 239/532 [08:09<09:18,  1.91s/it]predicting train subjects:  45%|████▌     | 240/532 [08:12<09:43,  2.00s/it]predicting train subjects:  45%|████▌     | 241/532 [08:14<09:50,  2.03s/it]predicting train subjects:  45%|████▌     | 242/532 [08:16<09:52,  2.04s/it]predicting train subjects:  46%|████▌     | 243/532 [08:18<09:57,  2.07s/it]predicting train subjects:  46%|████▌     | 244/532 [08:20<09:51,  2.05s/it]predicting train subjects:  46%|████▌     | 245/532 [08:21<09:10,  1.92s/it]predicting train subjects:  46%|████▌     | 246/532 [08:23<08:48,  1.85s/it]predicting train subjects:  46%|████▋     | 247/532 [08:25<08:27,  1.78s/it]predicting train subjects:  47%|████▋     | 248/532 [08:26<08:13,  1.74s/it]predicting train subjects:  47%|████▋     | 249/532 [08:28<08:01,  1.70s/it]predicting train subjects:  47%|████▋     | 250/532 [08:30<07:56,  1.69s/it]predicting train subjects:  47%|████▋     | 251/532 [08:31<07:58,  1.70s/it]predicting train subjects:  47%|████▋     | 252/532 [08:33<07:59,  1.71s/it]predicting train subjects:  48%|████▊     | 253/532 [08:35<08:03,  1.73s/it]predicting train subjects:  48%|████▊     | 254/532 [08:37<08:02,  1.74s/it]predicting train subjects:  48%|████▊     | 255/532 [08:38<08:01,  1.74s/it]predicting train subjects:  48%|████▊     | 256/532 [08:40<08:04,  1.76s/it]predicting train subjects:  48%|████▊     | 257/532 [08:42<08:37,  1.88s/it]predicting train subjects:  48%|████▊     | 258/532 [08:45<08:58,  1.97s/it]predicting train subjects:  49%|████▊     | 259/532 [08:47<09:13,  2.03s/it]predicting train subjects:  49%|████▉     | 260/532 [08:49<09:21,  2.06s/it]predicting train subjects:  49%|████▉     | 261/532 [08:51<09:24,  2.08s/it]predicting train subjects:  49%|████▉     | 262/532 [08:53<09:24,  2.09s/it]predicting train subjects:  49%|████▉     | 263/532 [08:55<08:47,  1.96s/it]predicting train subjects:  50%|████▉     | 264/532 [08:56<08:15,  1.85s/it]predicting train subjects:  50%|████▉     | 265/532 [08:58<07:59,  1.80s/it]predicting train subjects:  50%|█████     | 266/532 [09:00<07:39,  1.73s/it]predicting train subjects:  50%|█████     | 267/532 [09:01<07:27,  1.69s/it]predicting train subjects:  50%|█████     | 268/532 [09:03<07:14,  1.65s/it]predicting train subjects:  51%|█████     | 269/532 [09:05<07:35,  1.73s/it]predicting train subjects:  51%|█████     | 270/532 [09:07<07:51,  1.80s/it]predicting train subjects:  51%|█████     | 271/532 [09:09<08:10,  1.88s/it]predicting train subjects:  51%|█████     | 272/532 [09:11<08:13,  1.90s/it]predicting train subjects:  51%|█████▏    | 273/532 [09:13<08:13,  1.90s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:15<08:19,  1.94s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:17<08:56,  2.09s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:19<09:15,  2.17s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:22<09:24,  2.21s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:24<09:26,  2.23s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:26<09:30,  2.25s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:29<09:34,  2.28s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:31<09:31,  2.28s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:33<09:21,  2.24s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:35<09:18,  2.24s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:37<09:11,  2.22s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:40<09:07,  2.21s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:42<09:00,  2.20s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:44<08:34,  2.10s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:46<08:15,  2.03s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:47<07:57,  1.96s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:49<07:42,  1.91s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:51<07:31,  1.87s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:53<07:23,  1.85s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:55<07:28,  1.88s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:57<07:29,  1.89s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:59<07:33,  1.92s/it]predicting train subjects:  56%|█████▌    | 296/532 [10:01<07:41,  1.95s/it]predicting train subjects:  56%|█████▌    | 297/532 [10:03<07:37,  1.95s/it]predicting train subjects:  56%|█████▌    | 298/532 [10:04<07:33,  1.94s/it]predicting train subjects:  56%|█████▌    | 299/532 [10:06<07:12,  1.85s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:08<06:56,  1.80s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:09<06:40,  1.73s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:11<06:29,  1.70s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:13<06:25,  1.68s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:14<06:20,  1.67s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:17<07:07,  1.88s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:19<07:43,  2.05s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:21<07:57,  2.12s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:24<08:10,  2.19s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:26<08:23,  2.26s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:29<08:30,  2.30s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:31<09:12,  2.50s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:34<09:40,  2.64s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:37<10:00,  2.74s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:40<10:09,  2.79s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:43<10:16,  2.84s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:46<10:20,  2.87s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:48<09:12,  2.57s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:50<08:23,  2.35s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:52<07:45,  2.19s/it]predicting train subjects:  60%|██████    | 320/532 [10:54<07:21,  2.08s/it]predicting train subjects:  60%|██████    | 321/532 [10:55<06:59,  1.99s/it]predicting train subjects:  61%|██████    | 322/532 [10:57<06:47,  1.94s/it]predicting train subjects:  61%|██████    | 323/532 [11:00<07:20,  2.11s/it]predicting train subjects:  61%|██████    | 324/532 [11:02<07:37,  2.20s/it]predicting train subjects:  61%|██████    | 325/532 [11:05<07:54,  2.29s/it]predicting train subjects:  61%|██████▏   | 326/532 [11:07<08:06,  2.36s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:10<08:15,  2.41s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:12<08:20,  2.45s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:14<07:45,  2.29s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:16<07:21,  2.19s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:18<07:04,  2.11s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:20<06:55,  2.08s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:22<06:44,  2.04s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:24<06:38,  2.01s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:26<06:48,  2.07s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:28<06:49,  2.09s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:30<06:49,  2.10s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:32<06:46,  2.09s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:35<06:50,  2.13s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:37<06:48,  2.13s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:39<06:27,  2.03s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:40<06:15,  1.98s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:42<06:05,  1.93s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:44<05:49,  1.86s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:46<05:48,  1.87s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:48<05:42,  1.84s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:50<05:49,  1.89s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:52<05:52,  1.91s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:54<05:52,  1.93s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:56<05:54,  1.95s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:58<05:57,  1.98s/it]predicting train subjects:  66%|██████▌   | 352/532 [12:00<06:08,  2.05s/it]predicting train subjects:  66%|██████▋   | 353/532 [12:02<06:04,  2.03s/it]predicting train subjects:  67%|██████▋   | 354/532 [12:04<05:57,  2.01s/it]predicting train subjects:  67%|██████▋   | 355/532 [12:06<05:55,  2.01s/it]predicting train subjects:  67%|██████▋   | 356/532 [12:08<05:55,  2.02s/it]predicting train subjects:  67%|██████▋   | 357/532 [12:10<05:52,  2.01s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:12<05:46,  1.99s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:13<05:27,  1.89s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:15<05:23,  1.88s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:17<05:08,  1.81s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:19<05:00,  1.77s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:20<04:58,  1.76s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:22<04:50,  1.73s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:24<04:49,  1.73s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:26<04:53,  1.77s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:27<04:49,  1.76s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:29<04:48,  1.76s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:31<04:49,  1.77s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:33<04:46,  1.77s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:35<05:14,  1.95s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:37<05:31,  2.07s/it]predicting train subjects:  70%|███████   | 373/532 [12:40<05:47,  2.19s/it]predicting train subjects:  70%|███████   | 374/532 [12:42<05:58,  2.27s/it]predicting train subjects:  70%|███████   | 375/532 [12:45<05:57,  2.28s/it]predicting train subjects:  71%|███████   | 376/532 [12:47<05:55,  2.28s/it]predicting train subjects:  71%|███████   | 377/532 [12:49<05:38,  2.19s/it]predicting train subjects:  71%|███████   | 378/532 [12:51<05:23,  2.10s/it]predicting train subjects:  71%|███████   | 379/532 [12:53<05:11,  2.03s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:55<05:09,  2.03s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:57<05:04,  2.02s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:59<04:57,  1.98s/it]predicting train subjects:  72%|███████▏  | 383/532 [13:01<04:58,  2.00s/it]predicting train subjects:  72%|███████▏  | 384/532 [13:03<04:56,  2.01s/it]predicting train subjects:  72%|███████▏  | 385/532 [13:05<04:55,  2.01s/it]predicting train subjects:  73%|███████▎  | 386/532 [13:07<04:56,  2.03s/it]predicting train subjects:  73%|███████▎  | 387/532 [13:09<04:53,  2.02s/it]predicting train subjects:  73%|███████▎  | 388/532 [13:11<04:55,  2.05s/it]predicting train subjects:  73%|███████▎  | 389/532 [13:13<04:57,  2.08s/it]predicting train subjects:  73%|███████▎  | 390/532 [13:15<04:56,  2.09s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:17<04:54,  2.09s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:19<04:50,  2.08s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:21<04:48,  2.07s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:23<04:50,  2.10s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:26<04:46,  2.09s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:28<04:46,  2.11s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:30<04:43,  2.10s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:32<04:40,  2.09s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:34<04:37,  2.09s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:36<04:35,  2.09s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:38<04:39,  2.13s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:40<04:41,  2.17s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:43<04:46,  2.22s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:45<04:48,  2.25s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:47<04:43,  2.23s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:50<04:40,  2.23s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:52<04:30,  2.16s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:54<04:23,  2.13s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:56<04:14,  2.07s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:58<04:09,  2.05s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:59<04:04,  2.02s/it]predicting train subjects:  77%|███████▋  | 412/532 [14:01<04:01,  2.02s/it]predicting train subjects:  78%|███████▊  | 413/532 [14:03<03:52,  1.95s/it]predicting train subjects:  78%|███████▊  | 414/532 [14:05<03:44,  1.90s/it]predicting train subjects:  78%|███████▊  | 415/532 [14:07<03:39,  1.87s/it]predicting train subjects:  78%|███████▊  | 416/532 [14:09<03:37,  1.88s/it]predicting train subjects:  78%|███████▊  | 417/532 [14:11<03:32,  1.85s/it]predicting train subjects:  79%|███████▊  | 418/532 [14:12<03:33,  1.87s/it]predicting train subjects:  79%|███████▉  | 419/532 [14:15<03:38,  1.94s/it]predicting train subjects:  79%|███████▉  | 420/532 [14:17<03:43,  2.00s/it]predicting train subjects:  79%|███████▉  | 421/532 [14:19<03:48,  2.05s/it]predicting train subjects:  79%|███████▉  | 422/532 [14:21<03:47,  2.07s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:23<03:43,  2.05s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:25<03:41,  2.05s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:27<03:42,  2.08s/it]predicting train subjects:  80%|████████  | 426/532 [14:29<03:42,  2.10s/it]predicting train subjects:  80%|████████  | 427/532 [14:31<03:40,  2.10s/it]predicting train subjects:  80%|████████  | 428/532 [14:33<03:36,  2.08s/it]predicting train subjects:  81%|████████  | 429/532 [14:36<03:34,  2.08s/it]predicting train subjects:  81%|████████  | 430/532 [14:38<03:32,  2.08s/it]predicting train subjects:  81%|████████  | 431/532 [14:40<03:33,  2.11s/it]predicting train subjects:  81%|████████  | 432/532 [14:42<03:33,  2.14s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:44<03:35,  2.17s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:46<03:33,  2.17s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:49<03:32,  2.19s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:51<03:30,  2.19s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:53<03:15,  2.06s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:54<03:01,  1.93s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:56<02:52,  1.85s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:58<02:46,  1.81s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:59<02:43,  1.80s/it]predicting train subjects:  83%|████████▎ | 442/532 [15:01<02:38,  1.76s/it]predicting train subjects:  83%|████████▎ | 443/532 [15:03<02:34,  1.74s/it]predicting train subjects:  83%|████████▎ | 444/532 [15:04<02:31,  1.72s/it]predicting train subjects:  84%|████████▎ | 445/532 [15:06<02:27,  1.70s/it]predicting train subjects:  84%|████████▍ | 446/532 [15:08<02:24,  1.68s/it]predicting train subjects:  84%|████████▍ | 447/532 [15:09<02:21,  1.67s/it]predicting train subjects:  84%|████████▍ | 448/532 [15:11<02:21,  1.69s/it]predicting train subjects:  84%|████████▍ | 449/532 [15:13<02:22,  1.72s/it]predicting train subjects:  85%|████████▍ | 450/532 [15:15<02:20,  1.71s/it]predicting train subjects:  85%|████████▍ | 451/532 [15:16<02:19,  1.72s/it]predicting train subjects:  85%|████████▍ | 452/532 [15:18<02:17,  1.72s/it]predicting train subjects:  85%|████████▌ | 453/532 [15:20<02:17,  1.74s/it]predicting train subjects:  85%|████████▌ | 454/532 [15:22<02:16,  1.75s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:24<02:19,  1.82s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:26<02:20,  1.85s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:28<02:21,  1.89s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:29<02:21,  1.91s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:31<02:18,  1.90s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:33<02:18,  1.92s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:36<02:24,  2.04s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:38<02:27,  2.10s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:40<02:28,  2.15s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:42<02:27,  2.18s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:45<02:27,  2.20s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:47<02:26,  2.22s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:49<02:16,  2.10s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:50<02:08,  2.00s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:52<02:03,  1.96s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:54<01:58,  1.90s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:56<01:53,  1.86s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:58<01:50,  1.85s/it]predicting train subjects:  89%|████████▉ | 473/532 [16:00<01:52,  1.90s/it]predicting train subjects:  89%|████████▉ | 474/532 [16:02<01:52,  1.95s/it]predicting train subjects:  89%|████████▉ | 475/532 [16:04<01:52,  1.97s/it]predicting train subjects:  89%|████████▉ | 476/532 [16:06<01:51,  1.99s/it]predicting train subjects:  90%|████████▉ | 477/532 [16:08<01:50,  2.00s/it]predicting train subjects:  90%|████████▉ | 478/532 [16:10<01:49,  2.03s/it]predicting train subjects:  90%|█████████ | 479/532 [16:12<01:43,  1.95s/it]predicting train subjects:  90%|█████████ | 480/532 [16:13<01:38,  1.90s/it]predicting train subjects:  90%|█████████ | 481/532 [16:15<01:33,  1.83s/it]predicting train subjects:  91%|█████████ | 482/532 [16:17<01:28,  1.78s/it]predicting train subjects:  91%|█████████ | 483/532 [16:19<01:26,  1.76s/it]predicting train subjects:  91%|█████████ | 484/532 [16:20<01:24,  1.75s/it]predicting train subjects:  91%|█████████ | 485/532 [16:22<01:27,  1.86s/it]predicting train subjects:  91%|█████████▏| 486/532 [16:25<01:30,  1.96s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:27<01:31,  2.04s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:29<01:31,  2.08s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:31<01:30,  2.11s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:33<01:29,  2.13s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:35<01:23,  2.04s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:37<01:19,  1.98s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:39<01:14,  1.92s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:41<01:13,  1.92s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:43<01:10,  1.91s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:44<01:07,  1.88s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:46<01:05,  1.88s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:48<01:03,  1.88s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:50<01:01,  1.88s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:52<01:00,  1.88s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:54<00:58,  1.89s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:56<00:57,  1.92s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:58<00:54,  1.89s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:59<00:52,  1.87s/it]predicting train subjects:  95%|█████████▍| 505/532 [17:01<00:49,  1.83s/it]predicting train subjects:  95%|█████████▌| 506/532 [17:03<00:47,  1.81s/it]predicting train subjects:  95%|█████████▌| 507/532 [17:05<00:45,  1.80s/it]predicting train subjects:  95%|█████████▌| 508/532 [17:07<00:43,  1.79s/it]predicting train subjects:  96%|█████████▌| 509/532 [17:09<00:43,  1.91s/it]predicting train subjects:  96%|█████████▌| 510/532 [17:11<00:44,  2.03s/it]predicting train subjects:  96%|█████████▌| 511/532 [17:13<00:43,  2.08s/it]predicting train subjects:  96%|█████████▌| 512/532 [17:15<00:42,  2.11s/it]predicting train subjects:  96%|█████████▋| 513/532 [17:18<00:41,  2.16s/it]predicting train subjects:  97%|█████████▋| 514/532 [17:20<00:39,  2.18s/it]predicting train subjects:  97%|█████████▋| 515/532 [17:22<00:35,  2.08s/it]predicting train subjects:  97%|█████████▋| 516/532 [17:24<00:32,  2.00s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:25<00:29,  1.96s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:27<00:27,  1.95s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:29<00:24,  1.92s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:31<00:22,  1.87s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:33<00:21,  1.91s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:35<00:19,  1.96s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:37<00:17,  2.00s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:39<00:16,  2.01s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:41<00:14,  2.03s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:43<00:12,  2.05s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:45<00:09,  1.96s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:47<00:07,  1.92s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:49<00:05,  1.88s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:50<00:03,  1.83s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:52<00:01,  1.84s/it]predicting train subjects: 100%|██████████| 532/532 [17:54<00:00,  1.81s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:34,  1.42s/it]Loading train:   0%|          | 2/532 [00:02<11:20,  1.28s/it]Loading train:   1%|          | 3/532 [00:03<10:30,  1.19s/it]Loading train:   1%|          | 4/532 [00:04<09:56,  1.13s/it]Loading train:   1%|          | 5/532 [00:05<09:56,  1.13s/it]Loading train:   1%|          | 6/532 [00:06<09:06,  1.04s/it]Loading train:   1%|▏         | 7/532 [00:07<08:53,  1.02s/it]Loading train:   2%|▏         | 8/532 [00:08<08:33,  1.02it/s]Loading train:   2%|▏         | 9/532 [00:09<08:43,  1.00s/it]Loading train:   2%|▏         | 10/532 [00:10<08:32,  1.02it/s]Loading train:   2%|▏         | 11/532 [00:10<07:57,  1.09it/s]Loading train:   2%|▏         | 12/532 [00:12<08:48,  1.02s/it]Loading train:   2%|▏         | 13/532 [00:12<07:47,  1.11it/s]Loading train:   3%|▎         | 14/532 [00:13<07:38,  1.13it/s]Loading train:   3%|▎         | 15/532 [00:14<07:40,  1.12it/s]Loading train:   3%|▎         | 16/532 [00:15<07:37,  1.13it/s]Loading train:   3%|▎         | 17/532 [00:16<07:24,  1.16it/s]Loading train:   3%|▎         | 18/532 [00:17<07:39,  1.12it/s]Loading train:   4%|▎         | 19/532 [00:18<07:44,  1.11it/s]Loading train:   4%|▍         | 20/532 [00:19<07:41,  1.11it/s]Loading train:   4%|▍         | 21/532 [00:20<08:18,  1.03it/s]Loading train:   4%|▍         | 22/532 [00:20<07:50,  1.08it/s]Loading train:   4%|▍         | 23/532 [00:22<08:08,  1.04it/s]Loading train:   5%|▍         | 24/532 [00:22<07:31,  1.13it/s]Loading train:   5%|▍         | 25/532 [00:23<08:18,  1.02it/s]Loading train:   5%|▍         | 26/532 [00:24<07:58,  1.06it/s]Loading train:   5%|▌         | 27/532 [00:26<08:54,  1.06s/it]Loading train:   5%|▌         | 28/532 [00:26<08:23,  1.00it/s]Loading train:   5%|▌         | 29/532 [00:28<08:34,  1.02s/it]Loading train:   6%|▌         | 30/532 [00:28<08:02,  1.04it/s]Loading train:   6%|▌         | 31/532 [00:29<08:13,  1.02it/s]Loading train:   6%|▌         | 32/532 [00:30<07:56,  1.05it/s]Loading train:   6%|▌         | 33/532 [00:31<07:37,  1.09it/s]Loading train:   6%|▋         | 34/532 [00:32<07:56,  1.05it/s]Loading train:   7%|▋         | 35/532 [00:33<07:43,  1.07it/s]Loading train:   7%|▋         | 36/532 [00:34<07:37,  1.08it/s]Loading train:   7%|▋         | 37/532 [00:35<08:00,  1.03it/s]Loading train:   7%|▋         | 38/532 [00:36<08:05,  1.02it/s]Loading train:   7%|▋         | 39/532 [00:37<08:16,  1.01s/it]Loading train:   8%|▊         | 40/532 [00:38<07:43,  1.06it/s]Loading train:   8%|▊         | 41/532 [00:39<08:01,  1.02it/s]Loading train:   8%|▊         | 42/532 [00:40<07:58,  1.02it/s]Loading train:   8%|▊         | 43/532 [00:41<07:48,  1.04it/s]Loading train:   8%|▊         | 44/532 [00:42<07:16,  1.12it/s]Loading train:   8%|▊         | 45/532 [00:43<07:24,  1.10it/s]Loading train:   9%|▊         | 46/532 [00:44<07:35,  1.07it/s]Loading train:   9%|▉         | 47/532 [00:45<08:12,  1.02s/it]Loading train:   9%|▉         | 48/532 [00:46<08:21,  1.04s/it]Loading train:   9%|▉         | 49/532 [00:47<08:12,  1.02s/it]Loading train:   9%|▉         | 50/532 [00:48<08:29,  1.06s/it]Loading train:  10%|▉         | 51/532 [00:49<08:27,  1.05s/it]Loading train:  10%|▉         | 52/532 [00:50<07:50,  1.02it/s]Loading train:  10%|▉         | 53/532 [00:51<07:34,  1.05it/s]Loading train:  10%|█         | 54/532 [00:52<07:47,  1.02it/s]Loading train:  10%|█         | 55/532 [00:53<07:50,  1.01it/s]Loading train:  11%|█         | 56/532 [00:54<07:47,  1.02it/s]Loading train:  11%|█         | 57/532 [00:55<07:52,  1.01it/s]Loading train:  11%|█         | 58/532 [00:56<08:06,  1.03s/it]Loading train:  11%|█         | 59/532 [00:57<08:47,  1.12s/it]Loading train:  11%|█▏        | 60/532 [00:58<08:08,  1.03s/it]Loading train:  11%|█▏        | 61/532 [00:59<07:57,  1.01s/it]Loading train:  12%|█▏        | 62/532 [01:00<08:07,  1.04s/it]Loading train:  12%|█▏        | 63/532 [01:01<08:24,  1.08s/it]Loading train:  12%|█▏        | 64/532 [01:02<08:05,  1.04s/it]Loading train:  12%|█▏        | 65/532 [01:03<08:11,  1.05s/it]Loading train:  12%|█▏        | 66/532 [01:05<08:49,  1.14s/it]Loading train:  13%|█▎        | 67/532 [01:06<09:05,  1.17s/it]Loading train:  13%|█▎        | 68/532 [01:07<08:27,  1.09s/it]Loading train:  13%|█▎        | 69/532 [01:08<08:07,  1.05s/it]Loading train:  13%|█▎        | 70/532 [01:09<07:38,  1.01it/s]Loading train:  13%|█▎        | 71/532 [01:09<07:23,  1.04it/s]Loading train:  14%|█▎        | 72/532 [01:10<07:31,  1.02it/s]Loading train:  14%|█▎        | 73/532 [01:11<07:32,  1.01it/s]Loading train:  14%|█▍        | 74/532 [01:13<08:13,  1.08s/it]Loading train:  14%|█▍        | 75/532 [01:14<09:11,  1.21s/it]Loading train:  14%|█▍        | 76/532 [01:15<08:59,  1.18s/it]Loading train:  14%|█▍        | 77/532 [01:16<08:35,  1.13s/it]Loading train:  15%|█▍        | 78/532 [01:17<08:08,  1.08s/it]Loading train:  15%|█▍        | 79/532 [01:18<07:53,  1.04s/it]Loading train:  15%|█▌        | 80/532 [01:19<07:29,  1.01it/s]Loading train:  15%|█▌        | 81/532 [01:20<07:15,  1.04it/s]Loading train:  15%|█▌        | 82/532 [01:21<06:54,  1.09it/s]Loading train:  16%|█▌        | 83/532 [01:22<06:29,  1.15it/s]Loading train:  16%|█▌        | 84/532 [01:23<06:29,  1.15it/s]Loading train:  16%|█▌        | 85/532 [01:23<06:12,  1.20it/s]Loading train:  16%|█▌        | 86/532 [01:24<06:00,  1.24it/s]Loading train:  16%|█▋        | 87/532 [01:25<05:58,  1.24it/s]Loading train:  17%|█▋        | 88/532 [01:26<06:03,  1.22it/s]Loading train:  17%|█▋        | 89/532 [01:27<06:40,  1.11it/s]Loading train:  17%|█▋        | 90/532 [01:28<06:15,  1.18it/s]Loading train:  17%|█▋        | 91/532 [01:28<06:19,  1.16it/s]Loading train:  17%|█▋        | 92/532 [01:29<06:18,  1.16it/s]Loading train:  17%|█▋        | 93/532 [01:30<06:11,  1.18it/s]Loading train:  18%|█▊        | 94/532 [01:31<06:22,  1.15it/s]Loading train:  18%|█▊        | 95/532 [01:32<06:54,  1.06it/s]Loading train:  18%|█▊        | 96/532 [01:33<07:04,  1.03it/s]Loading train:  18%|█▊        | 97/532 [01:34<07:26,  1.03s/it]Loading train:  18%|█▊        | 98/532 [01:35<07:27,  1.03s/it]Loading train:  19%|█▊        | 99/532 [01:36<07:37,  1.06s/it]Loading train:  19%|█▉        | 100/532 [01:37<07:25,  1.03s/it]Loading train:  19%|█▉        | 101/532 [01:38<06:58,  1.03it/s]Loading train:  19%|█▉        | 102/532 [01:39<06:29,  1.10it/s]Loading train:  19%|█▉        | 103/532 [01:40<05:56,  1.20it/s]Loading train:  20%|█▉        | 104/532 [01:40<05:43,  1.25it/s]Loading train:  20%|█▉        | 105/532 [01:41<05:31,  1.29it/s]Loading train:  20%|█▉        | 106/532 [01:42<05:29,  1.29it/s]Loading train:  20%|██        | 107/532 [01:43<05:28,  1.30it/s]Loading train:  20%|██        | 108/532 [01:44<05:36,  1.26it/s]Loading train:  20%|██        | 109/532 [01:44<05:43,  1.23it/s]Loading train:  21%|██        | 110/532 [01:45<05:50,  1.20it/s]Loading train:  21%|██        | 111/532 [01:46<05:41,  1.23it/s]Loading train:  21%|██        | 112/532 [01:47<05:35,  1.25it/s]Loading train:  21%|██        | 113/532 [01:48<05:47,  1.20it/s]Loading train:  21%|██▏       | 114/532 [01:49<06:35,  1.06it/s]Loading train:  22%|██▏       | 115/532 [01:50<06:36,  1.05it/s]Loading train:  22%|██▏       | 116/532 [01:51<06:48,  1.02it/s]Loading train:  22%|██▏       | 117/532 [01:52<06:42,  1.03it/s]Loading train:  22%|██▏       | 118/532 [01:53<06:58,  1.01s/it]Loading train:  22%|██▏       | 119/532 [01:54<07:24,  1.08s/it]Loading train:  23%|██▎       | 120/532 [01:55<07:32,  1.10s/it]Loading train:  23%|██▎       | 121/532 [01:56<07:33,  1.10s/it]Loading train:  23%|██▎       | 122/532 [01:58<07:49,  1.14s/it]Loading train:  23%|██▎       | 123/532 [01:59<07:34,  1.11s/it]Loading train:  23%|██▎       | 124/532 [02:00<07:35,  1.12s/it]Loading train:  23%|██▎       | 125/532 [02:01<07:36,  1.12s/it]Loading train:  24%|██▎       | 126/532 [02:02<07:45,  1.15s/it]Loading train:  24%|██▍       | 127/532 [02:03<07:40,  1.14s/it]Loading train:  24%|██▍       | 128/532 [02:05<07:49,  1.16s/it]Loading train:  24%|██▍       | 129/532 [02:06<08:04,  1.20s/it]Loading train:  24%|██▍       | 130/532 [02:07<07:40,  1.15s/it]Loading train:  25%|██▍       | 131/532 [02:08<07:58,  1.19s/it]Loading train:  25%|██▍       | 132/532 [02:10<08:47,  1.32s/it]Loading train:  25%|██▌       | 133/532 [02:11<09:12,  1.39s/it]Loading train:  25%|██▌       | 134/532 [02:13<09:40,  1.46s/it]Loading train:  25%|██▌       | 135/532 [02:14<09:44,  1.47s/it]Loading train:  26%|██▌       | 136/532 [02:16<09:29,  1.44s/it]Loading train:  26%|██▌       | 137/532 [02:17<09:34,  1.45s/it]Loading train:  26%|██▌       | 138/532 [02:19<09:30,  1.45s/it]Loading train:  26%|██▌       | 139/532 [02:20<09:31,  1.45s/it]Loading train:  26%|██▋       | 140/532 [02:22<09:37,  1.47s/it]Loading train:  27%|██▋       | 141/532 [02:23<09:22,  1.44s/it]Loading train:  27%|██▋       | 142/532 [02:24<09:14,  1.42s/it]Loading train:  27%|██▋       | 143/532 [02:25<08:22,  1.29s/it]Loading train:  27%|██▋       | 144/532 [02:27<08:14,  1.27s/it]Loading train:  27%|██▋       | 145/532 [02:28<07:48,  1.21s/it]Loading train:  27%|██▋       | 146/532 [02:29<07:03,  1.10s/it]Loading train:  28%|██▊       | 147/532 [02:30<07:20,  1.14s/it]Loading train:  28%|██▊       | 148/532 [02:31<07:08,  1.12s/it]Loading train:  28%|██▊       | 149/532 [02:32<06:54,  1.08s/it]Loading train:  28%|██▊       | 150/532 [02:33<07:08,  1.12s/it]Loading train:  28%|██▊       | 151/532 [02:34<06:58,  1.10s/it]Loading train:  29%|██▊       | 152/532 [02:35<06:35,  1.04s/it]Loading train:  29%|██▉       | 153/532 [02:36<06:36,  1.05s/it]Loading train:  29%|██▉       | 154/532 [02:37<06:41,  1.06s/it]Loading train:  29%|██▉       | 155/532 [02:39<07:13,  1.15s/it]Loading train:  29%|██▉       | 156/532 [02:40<07:30,  1.20s/it]Loading train:  30%|██▉       | 157/532 [02:41<07:54,  1.27s/it]Loading train:  30%|██▉       | 158/532 [02:43<08:53,  1.43s/it]Loading train:  30%|██▉       | 159/532 [02:45<08:59,  1.45s/it]Loading train:  30%|███       | 160/532 [02:46<09:12,  1.48s/it]Loading train:  30%|███       | 161/532 [02:47<08:20,  1.35s/it]Loading train:  30%|███       | 162/532 [02:48<07:30,  1.22s/it]Loading train:  31%|███       | 163/532 [02:49<07:16,  1.18s/it]Loading train:  31%|███       | 164/532 [02:50<07:10,  1.17s/it]Loading train:  31%|███       | 165/532 [02:51<06:47,  1.11s/it]Loading train:  31%|███       | 166/532 [02:52<06:27,  1.06s/it]Loading train:  31%|███▏      | 167/532 [02:54<06:49,  1.12s/it]Loading train:  32%|███▏      | 168/532 [02:55<07:00,  1.15s/it]Loading train:  32%|███▏      | 169/532 [02:56<07:12,  1.19s/it]Loading train:  32%|███▏      | 170/532 [02:57<07:12,  1.19s/it]Loading train:  32%|███▏      | 171/532 [02:59<07:17,  1.21s/it]Loading train:  32%|███▏      | 172/532 [03:00<07:45,  1.29s/it]Loading train:  33%|███▎      | 173/532 [03:01<07:11,  1.20s/it]Loading train:  33%|███▎      | 174/532 [03:02<06:43,  1.13s/it]Loading train:  33%|███▎      | 175/532 [03:03<06:22,  1.07s/it]Loading train:  33%|███▎      | 176/532 [03:04<06:30,  1.10s/it]Loading train:  33%|███▎      | 177/532 [03:05<06:15,  1.06s/it]Loading train:  33%|███▎      | 178/532 [03:06<06:10,  1.05s/it]Loading train:  34%|███▎      | 179/532 [03:07<06:04,  1.03s/it]Loading train:  34%|███▍      | 180/532 [03:08<06:03,  1.03s/it]Loading train:  34%|███▍      | 181/532 [03:09<06:06,  1.04s/it]Loading train:  34%|███▍      | 182/532 [03:10<06:13,  1.07s/it]Loading train:  34%|███▍      | 183/532 [03:11<06:11,  1.06s/it]Loading train:  35%|███▍      | 184/532 [03:12<05:52,  1.01s/it]Loading train:  35%|███▍      | 185/532 [03:13<05:41,  1.02it/s]Loading train:  35%|███▍      | 186/532 [03:14<05:38,  1.02it/s]Loading train:  35%|███▌      | 187/532 [03:15<05:39,  1.02it/s]Loading train:  35%|███▌      | 188/532 [03:16<05:42,  1.00it/s]Loading train:  36%|███▌      | 189/532 [03:17<05:36,  1.02it/s]Loading train:  36%|███▌      | 190/532 [03:18<05:25,  1.05it/s]Loading train:  36%|███▌      | 191/532 [03:19<06:05,  1.07s/it]Loading train:  36%|███▌      | 192/532 [03:21<06:37,  1.17s/it]Loading train:  36%|███▋      | 193/532 [03:22<06:55,  1.23s/it]Loading train:  36%|███▋      | 194/532 [03:23<06:55,  1.23s/it]Loading train:  37%|███▋      | 195/532 [03:25<07:10,  1.28s/it]Loading train:  37%|███▋      | 196/532 [03:26<07:30,  1.34s/it]Loading train:  37%|███▋      | 197/532 [03:28<07:47,  1.39s/it]Loading train:  37%|███▋      | 198/532 [03:29<07:26,  1.34s/it]Loading train:  37%|███▋      | 199/532 [03:30<07:06,  1.28s/it]Loading train:  38%|███▊      | 200/532 [03:31<07:15,  1.31s/it]Loading train:  38%|███▊      | 201/532 [03:33<07:08,  1.29s/it]Loading train:  38%|███▊      | 202/532 [03:34<06:51,  1.25s/it]Loading train:  38%|███▊      | 203/532 [03:35<06:36,  1.20s/it]Loading train:  38%|███▊      | 204/532 [03:36<06:27,  1.18s/it]Loading train:  39%|███▊      | 205/532 [03:37<06:07,  1.12s/it]Loading train:  39%|███▊      | 206/532 [03:38<06:09,  1.13s/it]Loading train:  39%|███▉      | 207/532 [03:39<05:49,  1.08s/it]Loading train:  39%|███▉      | 208/532 [03:40<05:38,  1.04s/it]Loading train:  39%|███▉      | 209/532 [03:41<05:37,  1.05s/it]Loading train:  39%|███▉      | 210/532 [03:42<05:26,  1.02s/it]Loading train:  40%|███▉      | 211/532 [03:43<05:02,  1.06it/s]Loading train:  40%|███▉      | 212/532 [03:44<04:59,  1.07it/s]Loading train:  40%|████      | 213/532 [03:45<05:10,  1.03it/s]Loading train:  40%|████      | 214/532 [03:46<04:57,  1.07it/s]Loading train:  40%|████      | 215/532 [03:47<06:02,  1.14s/it]Loading train:  41%|████      | 216/532 [03:49<06:27,  1.23s/it]Loading train:  41%|████      | 217/532 [03:50<06:58,  1.33s/it]Loading train:  41%|████      | 218/532 [03:52<07:01,  1.34s/it]Loading train:  41%|████      | 219/532 [03:53<07:24,  1.42s/it]Loading train:  41%|████▏     | 220/532 [03:54<07:04,  1.36s/it]Loading train:  42%|████▏     | 221/532 [03:56<06:31,  1.26s/it]Loading train:  42%|████▏     | 222/532 [03:57<06:32,  1.27s/it]Loading train:  42%|████▏     | 223/532 [03:58<06:24,  1.24s/it]Loading train:  42%|████▏     | 224/532 [03:59<06:08,  1.19s/it]Loading train:  42%|████▏     | 225/532 [04:00<05:48,  1.13s/it]Loading train:  42%|████▏     | 226/532 [04:01<05:33,  1.09s/it]Loading train:  43%|████▎     | 227/532 [04:02<05:20,  1.05s/it]Loading train:  43%|████▎     | 228/532 [04:03<05:32,  1.09s/it]Loading train:  43%|████▎     | 229/532 [04:04<05:17,  1.05s/it]Loading train:  43%|████▎     | 230/532 [04:05<04:57,  1.01it/s]Loading train:  43%|████▎     | 231/532 [04:06<04:49,  1.04it/s]Loading train:  44%|████▎     | 232/532 [04:07<04:58,  1.00it/s]Loading train:  44%|████▍     | 233/532 [04:08<04:45,  1.05it/s]Loading train:  44%|████▍     | 234/532 [04:09<04:52,  1.02it/s]Loading train:  44%|████▍     | 235/532 [04:10<04:43,  1.05it/s]Loading train:  44%|████▍     | 236/532 [04:11<04:57,  1.01s/it]Loading train:  45%|████▍     | 237/532 [04:12<05:22,  1.09s/it]Loading train:  45%|████▍     | 238/532 [04:13<05:28,  1.12s/it]Loading train:  45%|████▍     | 239/532 [04:15<05:34,  1.14s/it]Loading train:  45%|████▌     | 240/532 [04:16<05:43,  1.18s/it]Loading train:  45%|████▌     | 241/532 [04:17<05:15,  1.08s/it]Loading train:  45%|████▌     | 242/532 [04:18<05:16,  1.09s/it]Loading train:  46%|████▌     | 243/532 [04:19<05:19,  1.11s/it]Loading train:  46%|████▌     | 244/532 [04:20<05:37,  1.17s/it]Loading train:  46%|████▌     | 245/532 [04:21<05:17,  1.11s/it]Loading train:  46%|████▌     | 246/532 [04:22<05:10,  1.08s/it]Loading train:  46%|████▋     | 247/532 [04:23<05:11,  1.09s/it]Loading train:  47%|████▋     | 248/532 [04:24<04:58,  1.05s/it]Loading train:  47%|████▋     | 249/532 [04:25<05:06,  1.08s/it]Loading train:  47%|████▋     | 250/532 [04:27<05:10,  1.10s/it]Loading train:  47%|████▋     | 251/532 [04:27<04:51,  1.04s/it]Loading train:  47%|████▋     | 252/532 [04:29<05:00,  1.07s/it]Loading train:  48%|████▊     | 253/532 [04:30<04:46,  1.03s/it]Loading train:  48%|████▊     | 254/532 [04:31<04:44,  1.02s/it]Loading train:  48%|████▊     | 255/532 [04:32<04:52,  1.05s/it]Loading train:  48%|████▊     | 256/532 [04:33<05:29,  1.19s/it]Loading train:  48%|████▊     | 257/532 [04:35<05:39,  1.23s/it]Loading train:  48%|████▊     | 258/532 [04:36<05:35,  1.22s/it]Loading train:  49%|████▊     | 259/532 [04:37<05:50,  1.29s/it]Loading train:  49%|████▉     | 260/532 [04:39<05:59,  1.32s/it]Loading train:  49%|████▉     | 261/532 [04:40<05:42,  1.26s/it]Loading train:  49%|████▉     | 262/532 [04:41<05:38,  1.25s/it]Loading train:  49%|████▉     | 263/532 [04:42<05:22,  1.20s/it]Loading train:  50%|████▉     | 264/532 [04:43<05:10,  1.16s/it]Loading train:  50%|████▉     | 265/532 [04:44<05:01,  1.13s/it]Loading train:  50%|█████     | 266/532 [04:45<04:38,  1.05s/it]Loading train:  50%|█████     | 267/532 [04:46<04:38,  1.05s/it]Loading train:  50%|█████     | 268/532 [04:47<04:32,  1.03s/it]Loading train:  51%|█████     | 269/532 [04:48<04:46,  1.09s/it]Loading train:  51%|█████     | 270/532 [04:49<04:47,  1.10s/it]Loading train:  51%|█████     | 271/532 [04:51<05:29,  1.26s/it]Loading train:  51%|█████     | 272/532 [04:52<05:19,  1.23s/it]Loading train:  51%|█████▏    | 273/532 [04:53<05:18,  1.23s/it]Loading train:  52%|█████▏    | 274/532 [04:54<05:01,  1.17s/it]Loading train:  52%|█████▏    | 275/532 [04:56<05:10,  1.21s/it]Loading train:  52%|█████▏    | 276/532 [04:57<05:31,  1.30s/it]Loading train:  52%|█████▏    | 277/532 [04:59<05:45,  1.35s/it]Loading train:  52%|█████▏    | 278/532 [05:00<05:55,  1.40s/it]Loading train:  52%|█████▏    | 279/532 [05:02<06:02,  1.43s/it]Loading train:  53%|█████▎    | 280/532 [05:03<05:57,  1.42s/it]Loading train:  53%|█████▎    | 281/532 [05:05<05:54,  1.41s/it]Loading train:  53%|█████▎    | 282/532 [05:06<05:40,  1.36s/it]Loading train:  53%|█████▎    | 283/532 [05:07<05:42,  1.38s/it]Loading train:  53%|█████▎    | 284/532 [05:09<05:38,  1.36s/it]Loading train:  54%|█████▎    | 285/532 [05:10<05:27,  1.33s/it]Loading train:  54%|█████▍    | 286/532 [05:11<05:34,  1.36s/it]Loading train:  54%|█████▍    | 287/532 [05:12<05:14,  1.28s/it]Loading train:  54%|█████▍    | 288/532 [05:13<04:59,  1.23s/it]Loading train:  54%|█████▍    | 289/532 [05:14<04:43,  1.17s/it]Loading train:  55%|█████▍    | 290/532 [05:15<04:26,  1.10s/it]Loading train:  55%|█████▍    | 291/532 [05:16<04:21,  1.08s/it]Loading train:  55%|█████▍    | 292/532 [05:18<04:23,  1.10s/it]Loading train:  55%|█████▌    | 293/532 [05:19<04:25,  1.11s/it]Loading train:  55%|█████▌    | 294/532 [05:20<04:20,  1.10s/it]Loading train:  55%|█████▌    | 295/532 [05:21<04:18,  1.09s/it]Loading train:  56%|█████▌    | 296/532 [05:22<04:17,  1.09s/it]Loading train:  56%|█████▌    | 297/532 [05:23<04:22,  1.11s/it]Loading train:  56%|█████▌    | 298/532 [05:24<04:25,  1.14s/it]Loading train:  56%|█████▌    | 299/532 [05:25<04:21,  1.12s/it]Loading train:  56%|█████▋    | 300/532 [05:26<04:16,  1.11s/it]Loading train:  57%|█████▋    | 301/532 [05:27<04:00,  1.04s/it]Loading train:  57%|█████▋    | 302/532 [05:28<03:43,  1.03it/s]Loading train:  57%|█████▋    | 303/532 [05:29<03:34,  1.07it/s]Loading train:  57%|█████▋    | 304/532 [05:30<03:27,  1.10it/s]Loading train:  57%|█████▋    | 305/532 [05:31<04:02,  1.07s/it]Loading train:  58%|█████▊    | 306/532 [05:33<04:26,  1.18s/it]Loading train:  58%|█████▊    | 307/532 [05:34<04:35,  1.22s/it]Loading train:  58%|█████▊    | 308/532 [05:36<04:53,  1.31s/it]Loading train:  58%|█████▊    | 309/532 [05:37<04:49,  1.30s/it]Loading train:  58%|█████▊    | 310/532 [05:38<04:51,  1.31s/it]Loading train:  58%|█████▊    | 311/532 [05:40<05:21,  1.46s/it]Loading train:  59%|█████▊    | 312/532 [05:42<05:37,  1.54s/it]Loading train:  59%|█████▉    | 313/532 [05:43<05:45,  1.58s/it]Loading train:  59%|█████▉    | 314/532 [05:45<05:51,  1.61s/it]Loading train:  59%|█████▉    | 315/532 [05:47<06:00,  1.66s/it]Loading train:  59%|█████▉    | 316/532 [05:49<06:01,  1.67s/it]Loading train:  60%|█████▉    | 317/532 [05:50<05:28,  1.53s/it]Loading train:  60%|█████▉    | 318/532 [05:51<04:53,  1.37s/it]Loading train:  60%|█████▉    | 319/532 [05:52<04:23,  1.24s/it]Loading train:  60%|██████    | 320/532 [05:53<04:12,  1.19s/it]Loading train:  60%|██████    | 321/532 [05:54<04:14,  1.21s/it]Loading train:  61%|██████    | 322/532 [05:55<04:00,  1.15s/it]Loading train:  61%|██████    | 323/532 [05:57<04:37,  1.33s/it]Loading train:  61%|██████    | 324/532 [05:58<04:39,  1.34s/it]Loading train:  61%|██████    | 325/532 [06:00<04:46,  1.38s/it]Loading train:  61%|██████▏   | 326/532 [06:01<05:08,  1.50s/it]Loading train:  61%|██████▏   | 327/532 [06:03<05:12,  1.52s/it]Loading train:  62%|██████▏   | 328/532 [06:04<04:50,  1.43s/it]Loading train:  62%|██████▏   | 329/532 [06:05<04:25,  1.31s/it]Loading train:  62%|██████▏   | 330/532 [06:06<04:13,  1.25s/it]Loading train:  62%|██████▏   | 331/532 [06:08<04:23,  1.31s/it]Loading train:  62%|██████▏   | 332/532 [06:09<04:09,  1.25s/it]Loading train:  63%|██████▎   | 333/532 [06:10<04:00,  1.21s/it]Loading train:  63%|██████▎   | 334/532 [06:11<03:55,  1.19s/it]Loading train:  63%|██████▎   | 335/532 [06:13<04:16,  1.30s/it]Loading train:  63%|██████▎   | 336/532 [06:14<04:16,  1.31s/it]Loading train:  63%|██████▎   | 337/532 [06:15<04:20,  1.33s/it]Loading train:  64%|██████▎   | 338/532 [06:17<04:22,  1.35s/it]Loading train:  64%|██████▎   | 339/532 [06:18<04:19,  1.34s/it]Loading train:  64%|██████▍   | 340/532 [06:19<04:17,  1.34s/it]Loading train:  64%|██████▍   | 341/532 [06:20<03:57,  1.24s/it]Loading train:  64%|██████▍   | 342/532 [06:22<03:46,  1.19s/it]Loading train:  64%|██████▍   | 343/532 [06:23<03:45,  1.20s/it]Loading train:  65%|██████▍   | 344/532 [06:24<03:42,  1.18s/it]Loading train:  65%|██████▍   | 345/532 [06:25<03:34,  1.15s/it]Loading train:  65%|██████▌   | 346/532 [06:26<03:28,  1.12s/it]Loading train:  65%|██████▌   | 347/532 [06:27<03:46,  1.23s/it]Loading train:  65%|██████▌   | 348/532 [06:29<03:45,  1.23s/it]Loading train:  66%|██████▌   | 349/532 [06:30<03:43,  1.22s/it]Loading train:  66%|██████▌   | 350/532 [06:31<03:31,  1.16s/it]Loading train:  66%|██████▌   | 351/532 [06:32<03:34,  1.19s/it]Loading train:  66%|██████▌   | 352/532 [06:33<03:33,  1.19s/it]Loading train:  66%|██████▋   | 353/532 [06:35<03:30,  1.18s/it]Loading train:  67%|██████▋   | 354/532 [06:36<03:25,  1.16s/it]Loading train:  67%|██████▋   | 355/532 [06:37<03:28,  1.18s/it]Loading train:  67%|██████▋   | 356/532 [06:38<03:22,  1.15s/it]Loading train:  67%|██████▋   | 357/532 [06:39<03:25,  1.17s/it]Loading train:  67%|██████▋   | 358/532 [06:40<03:19,  1.15s/it]Loading train:  67%|██████▋   | 359/532 [06:41<03:14,  1.12s/it]Loading train:  68%|██████▊   | 360/532 [06:42<03:13,  1.12s/it]Loading train:  68%|██████▊   | 361/532 [06:43<03:05,  1.09s/it]Loading train:  68%|██████▊   | 362/532 [06:45<03:09,  1.11s/it]Loading train:  68%|██████▊   | 363/532 [06:46<03:01,  1.08s/it]Loading train:  68%|██████▊   | 364/532 [06:47<03:13,  1.15s/it]Loading train:  69%|██████▊   | 365/532 [06:48<03:01,  1.09s/it]Loading train:  69%|██████▉   | 366/532 [06:49<02:57,  1.07s/it]Loading train:  69%|██████▉   | 367/532 [06:50<02:54,  1.06s/it]Loading train:  69%|██████▉   | 368/532 [06:51<02:53,  1.06s/it]Loading train:  69%|██████▉   | 369/532 [06:52<03:00,  1.11s/it]Loading train:  70%|██████▉   | 370/532 [06:53<02:55,  1.09s/it]Loading train:  70%|██████▉   | 371/532 [06:55<03:06,  1.16s/it]Loading train:  70%|██████▉   | 372/532 [06:56<03:15,  1.22s/it]Loading train:  70%|███████   | 373/532 [06:57<03:19,  1.26s/it]Loading train:  70%|███████   | 374/532 [06:59<03:24,  1.29s/it]Loading train:  70%|███████   | 375/532 [07:00<03:20,  1.28s/it]Loading train:  71%|███████   | 376/532 [07:01<03:30,  1.35s/it]Loading train:  71%|███████   | 377/532 [07:03<03:25,  1.33s/it]Loading train:  71%|███████   | 378/532 [07:04<03:06,  1.21s/it]Loading train:  71%|███████   | 379/532 [07:05<03:09,  1.24s/it]Loading train:  71%|███████▏  | 380/532 [07:06<03:00,  1.19s/it]Loading train:  72%|███████▏  | 381/532 [07:07<02:59,  1.19s/it]Loading train:  72%|███████▏  | 382/532 [07:08<02:56,  1.18s/it]Loading train:  72%|███████▏  | 383/532 [07:10<03:01,  1.22s/it]Loading train:  72%|███████▏  | 384/532 [07:11<02:57,  1.20s/it]Loading train:  72%|███████▏  | 385/532 [07:12<02:55,  1.20s/it]Loading train:  73%|███████▎  | 386/532 [07:13<02:50,  1.17s/it]Loading train:  73%|███████▎  | 387/532 [07:14<02:49,  1.17s/it]Loading train:  73%|███████▎  | 388/532 [07:16<02:51,  1.19s/it]Loading train:  73%|███████▎  | 389/532 [07:17<02:58,  1.25s/it]Loading train:  73%|███████▎  | 390/532 [07:18<02:49,  1.19s/it]Loading train:  73%|███████▎  | 391/532 [07:19<02:54,  1.23s/it]Loading train:  74%|███████▎  | 392/532 [07:21<02:58,  1.27s/it]Loading train:  74%|███████▍  | 393/532 [07:22<03:04,  1.33s/it]Loading train:  74%|███████▍  | 394/532 [07:23<03:01,  1.32s/it]Loading train:  74%|███████▍  | 395/532 [07:25<03:05,  1.36s/it]Loading train:  74%|███████▍  | 396/532 [07:26<02:52,  1.27s/it]Loading train:  75%|███████▍  | 397/532 [07:27<02:57,  1.31s/it]Loading train:  75%|███████▍  | 398/532 [07:28<02:44,  1.23s/it]Loading train:  75%|███████▌  | 399/532 [07:30<02:44,  1.24s/it]Loading train:  75%|███████▌  | 400/532 [07:31<02:47,  1.27s/it]Loading train:  75%|███████▌  | 401/532 [07:33<03:06,  1.43s/it]Loading train:  76%|███████▌  | 402/532 [07:34<03:03,  1.41s/it]Loading train:  76%|███████▌  | 403/532 [07:36<03:03,  1.43s/it]Loading train:  76%|███████▌  | 404/532 [07:37<02:57,  1.39s/it]Loading train:  76%|███████▌  | 405/532 [07:38<02:51,  1.35s/it]Loading train:  76%|███████▋  | 406/532 [07:39<02:47,  1.33s/it]Loading train:  77%|███████▋  | 407/532 [07:41<02:47,  1.34s/it]Loading train:  77%|███████▋  | 408/532 [07:42<02:39,  1.29s/it]Loading train:  77%|███████▋  | 409/532 [07:43<02:34,  1.26s/it]Loading train:  77%|███████▋  | 410/532 [07:45<02:36,  1.29s/it]Loading train:  77%|███████▋  | 411/532 [07:46<02:41,  1.33s/it]Loading train:  77%|███████▋  | 412/532 [07:47<02:31,  1.26s/it]Loading train:  78%|███████▊  | 413/532 [07:48<02:31,  1.27s/it]Loading train:  78%|███████▊  | 414/532 [07:49<02:24,  1.22s/it]Loading train:  78%|███████▊  | 415/532 [07:51<02:19,  1.19s/it]Loading train:  78%|███████▊  | 416/532 [07:52<02:24,  1.25s/it]Loading train:  78%|███████▊  | 417/532 [07:53<02:13,  1.16s/it]Loading train:  79%|███████▊  | 418/532 [07:54<02:07,  1.12s/it]Loading train:  79%|███████▉  | 419/532 [07:55<02:08,  1.13s/it]Loading train:  79%|███████▉  | 420/532 [07:56<02:09,  1.16s/it]Loading train:  79%|███████▉  | 421/532 [07:58<02:09,  1.17s/it]Loading train:  79%|███████▉  | 422/532 [07:59<02:06,  1.15s/it]Loading train:  80%|███████▉  | 423/532 [08:00<02:04,  1.14s/it]Loading train:  80%|███████▉  | 424/532 [08:01<02:04,  1.15s/it]Loading train:  80%|███████▉  | 425/532 [08:02<02:03,  1.15s/it]Loading train:  80%|████████  | 426/532 [08:03<01:59,  1.13s/it]Loading train:  80%|████████  | 427/532 [08:04<02:01,  1.15s/it]Loading train:  80%|████████  | 428/532 [08:06<02:04,  1.19s/it]Loading train:  81%|████████  | 429/532 [08:07<01:58,  1.15s/it]Loading train:  81%|████████  | 430/532 [08:08<01:55,  1.13s/it]Loading train:  81%|████████  | 431/532 [08:09<02:05,  1.24s/it]Loading train:  81%|████████  | 432/532 [08:11<02:06,  1.26s/it]Loading train:  81%|████████▏ | 433/532 [08:12<02:08,  1.30s/it]Loading train:  82%|████████▏ | 434/532 [08:13<02:07,  1.30s/it]Loading train:  82%|████████▏ | 435/532 [08:14<02:01,  1.25s/it]Loading train:  82%|████████▏ | 436/532 [08:16<01:58,  1.23s/it]Loading train:  82%|████████▏ | 437/532 [08:17<01:55,  1.22s/it]Loading train:  82%|████████▏ | 438/532 [08:18<01:49,  1.17s/it]Loading train:  83%|████████▎ | 439/532 [08:19<01:40,  1.08s/it]Loading train:  83%|████████▎ | 440/532 [08:20<01:38,  1.07s/it]Loading train:  83%|████████▎ | 441/532 [08:21<01:36,  1.07s/it]Loading train:  83%|████████▎ | 442/532 [08:22<01:35,  1.06s/it]Loading train:  83%|████████▎ | 443/532 [08:23<01:33,  1.05s/it]Loading train:  83%|████████▎ | 444/532 [08:24<01:37,  1.11s/it]Loading train:  84%|████████▎ | 445/532 [08:25<01:29,  1.02s/it]Loading train:  84%|████████▍ | 446/532 [08:26<01:29,  1.04s/it]Loading train:  84%|████████▍ | 447/532 [08:27<01:28,  1.04s/it]Loading train:  84%|████████▍ | 448/532 [08:28<01:27,  1.04s/it]Loading train:  84%|████████▍ | 449/532 [08:29<01:26,  1.04s/it]Loading train:  85%|████████▍ | 450/532 [08:30<01:28,  1.09s/it]Loading train:  85%|████████▍ | 451/532 [08:31<01:27,  1.08s/it]Loading train:  85%|████████▍ | 452/532 [08:32<01:21,  1.02s/it]Loading train:  85%|████████▌ | 453/532 [08:33<01:18,  1.00it/s]Loading train:  85%|████████▌ | 454/532 [08:34<01:20,  1.03s/it]Loading train:  86%|████████▌ | 455/532 [08:36<01:23,  1.09s/it]Loading train:  86%|████████▌ | 456/532 [08:37<01:20,  1.06s/it]Loading train:  86%|████████▌ | 457/532 [08:38<01:17,  1.03s/it]Loading train:  86%|████████▌ | 458/532 [08:39<01:30,  1.22s/it]Loading train:  86%|████████▋ | 459/532 [08:41<01:34,  1.29s/it]Loading train:  86%|████████▋ | 460/532 [08:42<01:35,  1.32s/it]Loading train:  87%|████████▋ | 461/532 [08:43<01:29,  1.26s/it]Loading train:  87%|████████▋ | 462/532 [08:44<01:24,  1.21s/it]Loading train:  87%|████████▋ | 463/532 [08:45<01:17,  1.13s/it]Loading train:  87%|████████▋ | 464/532 [08:46<01:16,  1.12s/it]Loading train:  87%|████████▋ | 465/532 [08:47<01:13,  1.09s/it]Loading train:  88%|████████▊ | 466/532 [08:48<01:13,  1.11s/it]Loading train:  88%|████████▊ | 467/532 [08:49<01:08,  1.05s/it]Loading train:  88%|████████▊ | 468/532 [08:50<01:01,  1.04it/s]Loading train:  88%|████████▊ | 469/532 [08:51<00:58,  1.08it/s]Loading train:  88%|████████▊ | 470/532 [08:52<00:56,  1.09it/s]Loading train:  89%|████████▊ | 471/532 [08:53<00:54,  1.12it/s]Loading train:  89%|████████▊ | 472/532 [08:54<00:52,  1.15it/s]Loading train:  89%|████████▉ | 473/532 [08:54<00:52,  1.13it/s]Loading train:  89%|████████▉ | 474/532 [08:55<00:51,  1.12it/s]Loading train:  89%|████████▉ | 475/532 [08:56<00:51,  1.10it/s]Loading train:  89%|████████▉ | 476/532 [08:57<00:50,  1.11it/s]Loading train:  90%|████████▉ | 477/532 [08:58<00:50,  1.08it/s]Loading train:  90%|████████▉ | 478/532 [08:59<00:49,  1.10it/s]Loading train:  90%|█████████ | 479/532 [09:00<00:46,  1.15it/s]Loading train:  90%|█████████ | 480/532 [09:01<00:43,  1.19it/s]Loading train:  90%|█████████ | 481/532 [09:01<00:42,  1.20it/s]Loading train:  91%|█████████ | 482/532 [09:02<00:40,  1.25it/s]Loading train:  91%|█████████ | 483/532 [09:03<00:39,  1.26it/s]Loading train:  91%|█████████ | 484/532 [09:04<00:38,  1.23it/s]Loading train:  91%|█████████ | 485/532 [09:05<00:40,  1.17it/s]Loading train:  91%|█████████▏| 486/532 [09:06<00:41,  1.10it/s]Loading train:  92%|█████████▏| 487/532 [09:07<00:41,  1.08it/s]Loading train:  92%|█████████▏| 488/532 [09:08<00:41,  1.07it/s]Loading train:  92%|█████████▏| 489/532 [09:09<00:40,  1.07it/s]Loading train:  92%|█████████▏| 490/532 [09:10<00:40,  1.04it/s]Loading train:  92%|█████████▏| 491/532 [09:10<00:37,  1.09it/s]Loading train:  92%|█████████▏| 492/532 [09:11<00:35,  1.13it/s]Loading train:  93%|█████████▎| 493/532 [09:12<00:33,  1.15it/s]Loading train:  93%|█████████▎| 494/532 [09:13<00:32,  1.15it/s]Loading train:  93%|█████████▎| 495/532 [09:14<00:32,  1.15it/s]Loading train:  93%|█████████▎| 496/532 [09:15<00:30,  1.16it/s]Loading train:  93%|█████████▎| 497/532 [09:16<00:30,  1.14it/s]Loading train:  94%|█████████▎| 498/532 [09:17<00:30,  1.11it/s]Loading train:  94%|█████████▍| 499/532 [09:17<00:30,  1.09it/s]Loading train:  94%|█████████▍| 500/532 [09:18<00:29,  1.09it/s]Loading train:  94%|█████████▍| 501/532 [09:19<00:28,  1.10it/s]Loading train:  94%|█████████▍| 502/532 [09:20<00:25,  1.16it/s]Loading train:  95%|█████████▍| 503/532 [09:21<00:24,  1.17it/s]Loading train:  95%|█████████▍| 504/532 [09:22<00:22,  1.22it/s]Loading train:  95%|█████████▍| 505/532 [09:22<00:21,  1.24it/s]Loading train:  95%|█████████▌| 506/532 [09:23<00:20,  1.29it/s]Loading train:  95%|█████████▌| 507/532 [09:24<00:19,  1.30it/s]Loading train:  95%|█████████▌| 508/532 [09:25<00:18,  1.31it/s]Loading train:  96%|█████████▌| 509/532 [09:26<00:18,  1.22it/s]Loading train:  96%|█████████▌| 510/532 [09:26<00:18,  1.19it/s]Loading train:  96%|█████████▌| 511/532 [09:27<00:18,  1.16it/s]Loading train:  96%|█████████▌| 512/532 [09:28<00:17,  1.17it/s]Loading train:  96%|█████████▋| 513/532 [09:29<00:16,  1.13it/s]Loading train:  97%|█████████▋| 514/532 [09:30<00:16,  1.10it/s]Loading train:  97%|█████████▋| 515/532 [09:31<00:15,  1.11it/s]Loading train:  97%|█████████▋| 516/532 [09:32<00:13,  1.15it/s]Loading train:  97%|█████████▋| 517/532 [09:33<00:13,  1.11it/s]Loading train:  97%|█████████▋| 518/532 [09:34<00:12,  1.15it/s]Loading train:  98%|█████████▊| 519/532 [09:34<00:11,  1.17it/s]Loading train:  98%|█████████▊| 520/532 [09:35<00:10,  1.18it/s]Loading train:  98%|█████████▊| 521/532 [09:36<00:09,  1.12it/s]Loading train:  98%|█████████▊| 522/532 [09:37<00:09,  1.10it/s]Loading train:  98%|█████████▊| 523/532 [09:38<00:08,  1.12it/s]Loading train:  98%|█████████▊| 524/532 [09:39<00:07,  1.10it/s]Loading train:  99%|█████████▊| 525/532 [09:40<00:06,  1.09it/s]Loading train:  99%|█████████▉| 526/532 [09:41<00:05,  1.10it/s]Loading train:  99%|█████████▉| 527/532 [09:42<00:04,  1.10it/s]Loading train:  99%|█████████▉| 528/532 [09:42<00:03,  1.14it/s]Loading train:  99%|█████████▉| 529/532 [09:43<00:02,  1.19it/s]Loading train: 100%|█████████▉| 530/532 [09:44<00:01,  1.18it/s]Loading train: 100%|█████████▉| 531/532 [09:45<00:00,  1.20it/s]Loading train: 100%|██████████| 532/532 [09:46<00:00,  1.21it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 24/532 [00:00<00:02, 224.48it/s]concatenating: train:  10%|▉         | 51/532 [00:00<00:02, 233.97it/s]concatenating: train:  15%|█▍        | 79/532 [00:00<00:01, 244.56it/s]concatenating: train:  19%|█▉        | 103/532 [00:00<00:01, 242.13it/s]concatenating: train:  25%|██▍       | 131/532 [00:00<00:01, 250.22it/s]concatenating: train:  30%|███       | 161/532 [00:00<00:01, 261.99it/s]concatenating: train:  36%|███▌      | 190/532 [00:00<00:01, 268.78it/s]concatenating: train:  41%|████▏     | 220/532 [00:00<00:01, 276.66it/s]concatenating: train:  47%|████▋     | 251/532 [00:00<00:00, 283.72it/s]concatenating: train:  53%|█████▎    | 282/532 [00:01<00:00, 288.41it/s]concatenating: train:  58%|█████▊    | 311/532 [00:01<00:00, 283.65it/s]concatenating: train:  64%|██████▍   | 342/532 [00:01<00:00, 289.99it/s]concatenating: train:  70%|██████▉   | 371/532 [00:01<00:00, 287.64it/s]concatenating: train:  75%|███████▌  | 400/532 [00:01<00:00, 286.29it/s]concatenating: train:  81%|████████  | 429/532 [00:01<00:00, 285.84it/s]concatenating: train:  86%|████████▌ | 458/532 [00:01<00:00, 285.55it/s]concatenating: train:  92%|█████████▏| 489/532 [00:01<00:00, 291.35it/s]concatenating: train:  98%|█████████▊| 519/532 [00:01<00:00, 289.15it/s]concatenating: train: 100%|██████████| 532/532 [00:01<00:00, 282.76it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:10,  1.36it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.26it/s]Loading test:  20%|██        | 3/15 [00:02<00:09,  1.23it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.20it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.08it/s]Loading test:  40%|████      | 6/15 [00:05<00:08,  1.01it/s]Loading test:  47%|████▋     | 7/15 [00:06<00:07,  1.10it/s]Loading test:  53%|█████▎    | 8/15 [00:07<00:06,  1.03it/s]Loading test:  60%|██████    | 9/15 [00:08<00:05,  1.03it/s]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.09it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.12it/s]Loading test:  80%|████████  | 12/15 [00:11<00:02,  1.09it/s]Loading test:  87%|████████▋ | 13/15 [00:12<00:01,  1.07it/s]Loading test:  93%|█████████▎| 14/15 [00:12<00:00,  1.13it/s]Loading test: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 187.79it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 01:06:50.182382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 01:06:50.182482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 01:06:50.182499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 01:06:50.182507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 01:06:50.182956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 28s - loss: 15.5006 - acc: 0.7300 - mDice: 0.0582 - val_loss: 3.2992 - val_acc: 0.9112 - val_mDice: 0.1759

Epoch 00001: val_mDice improved from -inf to 0.17588, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 2.6430 - acc: 0.9035 - mDice: 0.2788 - val_loss: 1.6779 - val_acc: 0.9302 - val_mDice: 0.4466

Epoch 00002: val_mDice improved from 0.17588 to 0.44658, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 1.8547 - acc: 0.9246 - mDice: 0.4235 - val_loss: 1.0122 - val_acc: 0.9569 - val_mDice: 0.6264

Epoch 00003: val_mDice improved from 0.44658 to 0.62645, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 1.5092 - acc: 0.9350 - mDice: 0.5079 - val_loss: 0.9297 - val_acc: 0.9633 - val_mDice: 0.6618

Epoch 00004: val_mDice improved from 0.62645 to 0.66180, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 1.3349 - acc: 0.9402 - mDice: 0.5556 - val_loss: 0.8180 - val_acc: 0.9639 - val_mDice: 0.7050

Epoch 00005: val_mDice improved from 0.66180 to 0.70502, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 18s - loss: 1.2178 - acc: 0.9438 - mDice: 0.5884 - val_loss: 0.7372 - val_acc: 0.9685 - val_mDice: 0.7273

Epoch 00006: val_mDice improved from 0.70502 to 0.72730, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 18s - loss: 1.1440 - acc: 0.9459 - mDice: 0.6096 - val_loss: 0.7205 - val_acc: 0.9693 - val_mDice: 0.7299

Epoch 00007: val_mDice improved from 0.72730 to 0.72988, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 1.0715 - acc: 0.9480 - mDice: 0.6305 - val_loss: 0.7056 - val_acc: 0.9696 - val_mDice: 0.7407

Epoch 00008: val_mDice improved from 0.72988 to 0.74068, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 19s - loss: 1.0191 - acc: 0.9494 - mDice: 0.6454 - val_loss: 0.6975 - val_acc: 0.9701 - val_mDice: 0.7482

Epoch 00009: val_mDice improved from 0.74068 to 0.74823, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 0.9778 - acc: 0.9507 - mDice: 0.6576 - val_loss: 0.6808 - val_acc: 0.9710 - val_mDice: 0.7542

Epoch 00010: val_mDice improved from 0.74823 to 0.75422, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 18s - loss: 0.9459 - acc: 0.9515 - mDice: 0.6676 - val_loss: 0.6593 - val_acc: 0.9702 - val_mDice: 0.7610

Epoch 00011: val_mDice improved from 0.75422 to 0.76102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 0.9189 - acc: 0.9524 - mDice: 0.6764 - val_loss: 0.6455 - val_acc: 0.9712 - val_mDice: 0.7632

Epoch 00012: val_mDice improved from 0.76102 to 0.76324, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 0.8977 - acc: 0.9529 - mDice: 0.6829 - val_loss: 0.6400 - val_acc: 0.9716 - val_mDice: 0.7643

Epoch 00013: val_mDice improved from 0.76324 to 0.76427, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 18s - loss: 0.8774 - acc: 0.9536 - mDice: 0.6897 - val_loss: 0.6477 - val_acc: 0.9716 - val_mDice: 0.7692

Epoch 00014: val_mDice improved from 0.76427 to 0.76921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 18s - loss: 0.8523 - acc: 0.9544 - mDice: 0.6969 - val_loss: 0.6405 - val_acc: 0.9727 - val_mDice: 0.7685

Epoch 00015: val_mDice did not improve from 0.76921
Epoch 16/300
 - 18s - loss: 0.8397 - acc: 0.9548 - mDice: 0.7012 - val_loss: 0.6376 - val_acc: 0.9721 - val_mDice: 0.7680

Epoch 00016: val_mDice did not improve from 0.76921
Epoch 17/300
 - 18s - loss: 0.8256 - acc: 0.9552 - mDice: 0.7059 - val_loss: 0.6176 - val_acc: 0.9738 - val_mDice: 0.7749

Epoch 00017: val_mDice improved from 0.76921 to 0.77493, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 19s - loss: 0.8134 - acc: 0.9557 - mDice: 0.7100 - val_loss: 0.6172 - val_acc: 0.9724 - val_mDice: 0.7762

Epoch 00018: val_mDice improved from 0.77493 to 0.77620, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 18s - loss: 0.8016 - acc: 0.9560 - mDice: 0.7135 - val_loss: 0.6179 - val_acc: 0.9731 - val_mDice: 0.7772

Epoch 00019: val_mDice improved from 0.77620 to 0.77725, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 18s - loss: 0.7898 - acc: 0.9564 - mDice: 0.7176 - val_loss: 0.6114 - val_acc: 0.9739 - val_mDice: 0.7784

Epoch 00020: val_mDice improved from 0.77725 to 0.77838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 18s - loss: 0.7842 - acc: 0.9567 - mDice: 0.7195 - val_loss: 0.6245 - val_acc: 0.9730 - val_mDice: 0.7774

Epoch 00021: val_mDice did not improve from 0.77838
Epoch 22/300
 - 19s - loss: 0.7704 - acc: 0.9570 - mDice: 0.7236 - val_loss: 0.6029 - val_acc: 0.9734 - val_mDice: 0.7819

Epoch 00022: val_mDice improved from 0.77838 to 0.78193, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 18s - loss: 0.7598 - acc: 0.9574 - mDice: 0.7271 - val_loss: 0.6067 - val_acc: 0.9731 - val_mDice: 0.7808

Epoch 00023: val_mDice did not improve from 0.78193
Epoch 24/300
 - 18s - loss: 0.7542 - acc: 0.9577 - mDice: 0.7292 - val_loss: 0.6118 - val_acc: 0.9724 - val_mDice: 0.7791

Epoch 00024: val_mDice did not improve from 0.78193
Epoch 25/300
 - 18s - loss: 0.7482 - acc: 0.9579 - mDice: 0.7310 - val_loss: 0.6024 - val_acc: 0.9747 - val_mDice: 0.7851

Epoch 00025: val_mDice improved from 0.78193 to 0.78505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 18s - loss: 0.7366 - acc: 0.9582 - mDice: 0.7347 - val_loss: 0.6191 - val_acc: 0.9744 - val_mDice: 0.7816

Epoch 00026: val_mDice did not improve from 0.78505
Epoch 27/300
 - 19s - loss: 0.7333 - acc: 0.9584 - mDice: 0.7359 - val_loss: 0.5916 - val_acc: 0.9741 - val_mDice: 0.7859

Epoch 00027: val_mDice improved from 0.78505 to 0.78586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 18s - loss: 0.7275 - acc: 0.9586 - mDice: 0.7377 - val_loss: 0.5879 - val_acc: 0.9749 - val_mDice: 0.7868

Epoch 00028: val_mDice improved from 0.78586 to 0.78683, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 18s - loss: 0.7185 - acc: 0.9589 - mDice: 0.7405 - val_loss: 0.5874 - val_acc: 0.9750 - val_mDice: 0.7874

Epoch 00029: val_mDice improved from 0.78683 to 0.78738, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 18s - loss: 0.7130 - acc: 0.9591 - mDice: 0.7423 - val_loss: 0.5790 - val_acc: 0.9749 - val_mDice: 0.7905

Epoch 00030: val_mDice improved from 0.78738 to 0.79051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 18s - loss: 0.7038 - acc: 0.9593 - mDice: 0.7451 - val_loss: 0.5909 - val_acc: 0.9745 - val_mDice: 0.7878

Epoch 00031: val_mDice did not improve from 0.79051
Epoch 32/300
 - 19s - loss: 0.6985 - acc: 0.9597 - mDice: 0.7468 - val_loss: 0.5993 - val_acc: 0.9746 - val_mDice: 0.7858

Epoch 00032: val_mDice did not improve from 0.79051
Epoch 33/300
 - 18s - loss: 0.6958 - acc: 0.9597 - mDice: 0.7478 - val_loss: 0.5688 - val_acc: 0.9749 - val_mDice: 0.7926

Epoch 00033: val_mDice improved from 0.79051 to 0.79263, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 18s - loss: 0.6907 - acc: 0.9599 - mDice: 0.7494 - val_loss: 0.5789 - val_acc: 0.9753 - val_mDice: 0.7897

Epoch 00034: val_mDice did not improve from 0.79263
Epoch 35/300
 - 18s - loss: 0.6870 - acc: 0.9600 - mDice: 0.7508 - val_loss: 0.5878 - val_acc: 0.9747 - val_mDice: 0.7886

Epoch 00035: val_mDice did not improve from 0.79263
Epoch 36/300
 - 18s - loss: 0.6817 - acc: 0.9602 - mDice: 0.7525 - val_loss: 0.5786 - val_acc: 0.9744 - val_mDice: 0.7914

Epoch 00036: val_mDice did not improve from 0.79263
Epoch 37/300
 - 19s - loss: 0.6754 - acc: 0.9604 - mDice: 0.7546 - val_loss: 0.5680 - val_acc: 0.9750 - val_mDice: 0.7884

Epoch 00037: val_mDice did not improve from 0.79263
Epoch 38/300
 - 18s - loss: 0.6754 - acc: 0.9604 - mDice: 0.7548 - val_loss: 0.5847 - val_acc: 0.9745 - val_mDice: 0.7877

Epoch 00038: val_mDice did not improve from 0.79263
Epoch 39/300
 - 18s - loss: 0.6703 - acc: 0.9605 - mDice: 0.7560 - val_loss: 0.5801 - val_acc: 0.9756 - val_mDice: 0.7907

Epoch 00039: val_mDice did not improve from 0.79263
Epoch 40/300
 - 18s - loss: 0.6647 - acc: 0.9607 - mDice: 0.7581 - val_loss: 0.5713 - val_acc: 0.9759 - val_mDice: 0.7944

Epoch 00040: val_mDice improved from 0.79263 to 0.79435, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 18s - loss: 0.6610 - acc: 0.9608 - mDice: 0.7591 - val_loss: 0.5899 - val_acc: 0.9760 - val_mDice: 0.7900

Epoch 00041: val_mDice did not improve from 0.79435
Epoch 42/300
 - 18s - loss: 0.6581 - acc: 0.9609 - mDice: 0.7603 - val_loss: 0.5660 - val_acc: 0.9754 - val_mDice: 0.7913

Epoch 00042: val_mDice did not improve from 0.79435
Epoch 43/300
 - 19s - loss: 0.6559 - acc: 0.9610 - mDice: 0.7609 - val_loss: 0.5716 - val_acc: 0.9767 - val_mDice: 0.7944

Epoch 00043: val_mDice improved from 0.79435 to 0.79442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 44/300
 - 18s - loss: 0.6506 - acc: 0.9611 - mDice: 0.7624 - val_loss: 0.5636 - val_acc: 0.9757 - val_mDice: 0.7952

Epoch 00044: val_mDice improved from 0.79442 to 0.79524, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 45/300
 - 18s - loss: 0.6516 - acc: 0.9611 - mDice: 0.7626 - val_loss: 0.5657 - val_acc: 0.9763 - val_mDice: 0.7950

Epoch 00045: val_mDice did not improve from 0.79524
Epoch 46/300
 - 18s - loss: 0.6446 - acc: 0.9612 - mDice: 0.7645 - val_loss: 0.5644 - val_acc: 0.9768 - val_mDice: 0.7969

Epoch 00046: val_mDice improved from 0.79524 to 0.79687, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 18s - loss: 0.6446 - acc: 0.9613 - mDice: 0.7647 - val_loss: 0.5693 - val_acc: 0.9767 - val_mDice: 0.7960

Epoch 00047: val_mDice did not improve from 0.79687
Epoch 48/300
 - 18s - loss: 0.6422 - acc: 0.9613 - mDice: 0.7654 - val_loss: 0.5644 - val_acc: 0.9761 - val_mDice: 0.7938

Epoch 00048: val_mDice did not improve from 0.79687
Epoch 49/300
 - 19s - loss: 0.6386 - acc: 0.9612 - mDice: 0.7665 - val_loss: 0.5645 - val_acc: 0.9770 - val_mDice: 0.7946

Epoch 00049: val_mDice did not improve from 0.79687
Epoch 50/300
 - 18s - loss: 0.6338 - acc: 0.9612 - mDice: 0.7682 - val_loss: 0.5541 - val_acc: 0.9764 - val_mDice: 0.7996

Epoch 00050: val_mDice improved from 0.79687 to 0.79958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 18s - loss: 0.6326 - acc: 0.9611 - mDice: 0.7687 - val_loss: 0.5777 - val_acc: 0.9765 - val_mDice: 0.7953

Epoch 00051: val_mDice did not improve from 0.79958
Epoch 52/300
 - 18s - loss: 0.6336 - acc: 0.9611 - mDice: 0.7685 - val_loss: 0.5597 - val_acc: 0.9755 - val_mDice: 0.7955

Epoch 00052: val_mDice did not improve from 0.79958
Epoch 53/300
 - 18s - loss: 0.6276 - acc: 0.9612 - mDice: 0.7702 - val_loss: 0.5605 - val_acc: 0.9759 - val_mDice: 0.7979

Epoch 00053: val_mDice did not improve from 0.79958
Epoch 54/300
 - 18s - loss: 0.6286 - acc: 0.9611 - mDice: 0.7700 - val_loss: 0.5606 - val_acc: 0.9765 - val_mDice: 0.7974

Epoch 00054: val_mDice did not improve from 0.79958
Epoch 55/300
 - 19s - loss: 0.6234 - acc: 0.9613 - mDice: 0.7717 - val_loss: 0.5599 - val_acc: 0.9764 - val_mDice: 0.7974

Epoch 00055: val_mDice did not improve from 0.79958
Epoch 56/300
 - 18s - loss: 0.6216 - acc: 0.9614 - mDice: 0.7723 - val_loss: 0.5499 - val_acc: 0.9764 - val_mDice: 0.7989

Epoch 00056: val_mDice did not improve from 0.79958
Epoch 57/300
 - 18s - loss: 0.6211 - acc: 0.9613 - mDice: 0.7724 - val_loss: 0.5636 - val_acc: 0.9764 - val_mDice: 0.7984

Epoch 00057: val_mDice did not improve from 0.79958
Epoch 58/300
 - 18s - loss: 0.6182 - acc: 0.9615 - mDice: 0.7733 - val_loss: 0.5652 - val_acc: 0.9768 - val_mDice: 0.7983

Epoch 00058: val_mDice did not improve from 0.79958
Epoch 59/300
 - 18s - loss: 0.6179 - acc: 0.9615 - mDice: 0.7734 - val_loss: 0.5670 - val_acc: 0.9769 - val_mDice: 0.7976

Epoch 00059: val_mDice did not improve from 0.79958
Epoch 60/300
 - 18s - loss: 0.6153 - acc: 0.9616 - mDice: 0.7744 - val_loss: 0.5618 - val_acc: 0.9767 - val_mDice: 0.7997

Epoch 00060: val_mDice improved from 0.79958 to 0.79972, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 61/300
 - 19s - loss: 0.6147 - acc: 0.9616 - mDice: 0.7746 - val_loss: 0.5702 - val_acc: 0.9767 - val_mDice: 0.7973

Epoch 00061: val_mDice did not improve from 0.79972
Epoch 62/300
 - 18s - loss: 0.6117 - acc: 0.9617 - mDice: 0.7754 - val_loss: 0.5557 - val_acc: 0.9772 - val_mDice: 0.7991

Epoch 00062: val_mDice did not improve from 0.79972
Epoch 63/300
 - 18s - loss: 0.6101 - acc: 0.9617 - mDice: 0.7760 - val_loss: 0.5599 - val_acc: 0.9764 - val_mDice: 0.7986

Epoch 00063: val_mDice did not improve from 0.79972
Epoch 64/300
 - 18s - loss: 0.6071 - acc: 0.9617 - mDice: 0.7772 - val_loss: 0.5546 - val_acc: 0.9770 - val_mDice: 0.7991

Epoch 00064: val_mDice did not improve from 0.79972
Epoch 65/300
 - 19s - loss: 0.6076 - acc: 0.9617 - mDice: 0.7769 - val_loss: 0.5494 - val_acc: 0.9766 - val_mDice: 0.7988

Epoch 00065: val_mDice did not improve from 0.79972
Epoch 66/300
 - 18s - loss: 0.6063 - acc: 0.9618 - mDice: 0.7774 - val_loss: 0.5551 - val_acc: 0.9755 - val_mDice: 0.7991

Epoch 00066: val_mDice did not improve from 0.79972
Epoch 67/300
 - 18s - loss: 0.6045 - acc: 0.9618 - mDice: 0.7777 - val_loss: 0.5691 - val_acc: 0.9767 - val_mDice: 0.7959

Epoch 00067: val_mDice did not improve from 0.79972
Epoch 68/300
 - 18s - loss: 0.6028 - acc: 0.9619 - mDice: 0.7784 - val_loss: 0.5553 - val_acc: 0.9763 - val_mDice: 0.7999

Epoch 00068: val_mDice improved from 0.79972 to 0.79990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 69/300
 - 18s - loss: 0.6013 - acc: 0.9618 - mDice: 0.7787 - val_loss: 0.5595 - val_acc: 0.9766 - val_mDice: 0.7980

Epoch 00069: val_mDice did not improve from 0.79990
Epoch 70/300
 - 19s - loss: 0.5982 - acc: 0.9620 - mDice: 0.7799 - val_loss: 0.5547 - val_acc: 0.9766 - val_mDice: 0.7996

Epoch 00070: val_mDice did not improve from 0.79990
Epoch 71/300
 - 18s - loss: 0.5986 - acc: 0.9619 - mDice: 0.7798 - val_loss: 0.5481 - val_acc: 0.9764 - val_mDice: 0.8011

Epoch 00071: val_mDice improved from 0.79990 to 0.80111, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 72/300
 - 18s - loss: 0.5968 - acc: 0.9620 - mDice: 0.7804 - val_loss: 0.5572 - val_acc: 0.9763 - val_mDice: 0.7987

Epoch 00072: val_mDice did not improve from 0.80111
Epoch 73/300
 - 18s - loss: 0.5977 - acc: 0.9619 - mDice: 0.7798 - val_loss: 0.5468 - val_acc: 0.9773 - val_mDice: 0.8009

Epoch 00073: val_mDice did not improve from 0.80111
Epoch 74/300
 - 18s - loss: 0.5954 - acc: 0.9620 - mDice: 0.7810 - val_loss: 0.5542 - val_acc: 0.9765 - val_mDice: 0.8011

Epoch 00074: val_mDice improved from 0.80111 to 0.80112, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 75/300
 - 18s - loss: 0.5940 - acc: 0.9620 - mDice: 0.7811 - val_loss: 0.5604 - val_acc: 0.9765 - val_mDice: 0.7997

Epoch 00075: val_mDice did not improve from 0.80112
Epoch 76/300
 - 19s - loss: 0.5940 - acc: 0.9620 - mDice: 0.7812 - val_loss: 0.5518 - val_acc: 0.9772 - val_mDice: 0.8016

Epoch 00076: val_mDice improved from 0.80112 to 0.80156, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 77/300
 - 18s - loss: 0.5915 - acc: 0.9621 - mDice: 0.7820 - val_loss: 0.5774 - val_acc: 0.9770 - val_mDice: 0.7979

Epoch 00077: val_mDice did not improve from 0.80156
Epoch 78/300
 - 18s - loss: 0.5900 - acc: 0.9621 - mDice: 0.7825 - val_loss: 0.5606 - val_acc: 0.9772 - val_mDice: 0.8023

Epoch 00078: val_mDice improved from 0.80156 to 0.80226, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 79/300
 - 18s - loss: 0.5885 - acc: 0.9621 - mDice: 0.7829 - val_loss: 0.5480 - val_acc: 0.9776 - val_mDice: 0.8026

Epoch 00079: val_mDice improved from 0.80226 to 0.80262, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 80/300
 - 18s - loss: 0.5875 - acc: 0.9622 - mDice: 0.7834 - val_loss: 0.5434 - val_acc: 0.9773 - val_mDice: 0.8025

Epoch 00080: val_mDice did not improve from 0.80262
Epoch 81/300
 - 19s - loss: 0.5867 - acc: 0.9622 - mDice: 0.7835 - val_loss: 0.5480 - val_acc: 0.9771 - val_mDice: 0.8051

Epoch 00081: val_mDice improved from 0.80262 to 0.80507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 82/300
 - 18s - loss: 0.5848 - acc: 0.9622 - mDice: 0.7842 - val_loss: 0.5593 - val_acc: 0.9771 - val_mDice: 0.7990

Epoch 00082: val_mDice did not improve from 0.80507
Epoch 83/300
 - 18s - loss: 0.5846 - acc: 0.9623 - mDice: 0.7842 - val_loss: 0.5505 - val_acc: 0.9773 - val_mDice: 0.8043

Epoch 00083: val_mDice did not improve from 0.80507
Epoch 84/300
 - 18s - loss: 0.5818 - acc: 0.9623 - mDice: 0.7853 - val_loss: 0.5468 - val_acc: 0.9769 - val_mDice: 0.8026

Epoch 00084: val_mDice did not improve from 0.80507
Epoch 85/300
 - 18s - loss: 0.5852 - acc: 0.9622 - mDice: 0.7842 - val_loss: 0.5633 - val_acc: 0.9768 - val_mDice: 0.8000

Epoch 00085: val_mDice did not improve from 0.80507
Epoch 86/300
 - 18s - loss: 0.5824 - acc: 0.9623 - mDice: 0.7850 - val_loss: 0.5495 - val_acc: 0.9767 - val_mDice: 0.8032

Epoch 00086: val_mDice did not improve from 0.80507
Epoch 87/300
 - 19s - loss: 0.5815 - acc: 0.9623 - mDice: 0.7852 - val_loss: 0.5611 - val_acc: 0.9767 - val_mDice: 0.8033

Epoch 00087: val_mDice did not improve from 0.80507
Epoch 88/300
 - 18s - loss: 0.5805 - acc: 0.9623 - mDice: 0.7856 - val_loss: 0.5511 - val_acc: 0.9772 - val_mDice: 0.8049

Epoch 00088: val_mDice did not improve from 0.80507
Epoch 89/300
 - 17s - loss: 0.5800 - acc: 0.9624 - mDice: 0.7857 - val_loss: 0.5455 - val_acc: 0.9775 - val_mDice: 0.8040

Epoch 00089: val_mDice did not improve from 0.80507
Epoch 90/300
 - 18s - loss: 0.5796 - acc: 0.9624 - mDice: 0.7858 - val_loss: 0.5414 - val_acc: 0.9772 - val_mDice: 0.8036

Epoch 00090: val_mDice did not improve from 0.80507
Epoch 91/300
 - 18s - loss: 0.5748 - acc: 0.9625 - mDice: 0.7875 - val_loss: 0.5463 - val_acc: 0.9768 - val_mDice: 0.8040

Epoch 00091: val_mDice did not improve from 0.80507
Epoch 92/300
 - 18s - loss: 0.5760 - acc: 0.9624 - mDice: 0.7868 - val_loss: 0.5435 - val_acc: 0.9769 - val_mDice: 0.8049

Epoch 00092: val_mDice did not improve from 0.80507
Epoch 93/300
 - 19s - loss: 0.5759 - acc: 0.9625 - mDice: 0.7871 - val_loss: 0.5391 - val_acc: 0.9771 - val_mDice: 0.8047

Epoch 00093: val_mDice did not improve from 0.80507
Epoch 94/300
 - 18s - loss: 0.5732 - acc: 0.9625 - mDice: 0.7882 - val_loss: 0.5542 - val_acc: 0.9769 - val_mDice: 0.8024

Epoch 00094: val_mDice did not improve from 0.80507
Epoch 95/300
 - 18s - loss: 0.5761 - acc: 0.9624 - mDice: 0.7871 - val_loss: 0.5400 - val_acc: 0.9770 - val_mDice: 0.8055

Epoch 00095: val_mDice improved from 0.80507 to 0.80549, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 96/300
 - 18s - loss: 0.5733 - acc: 0.9625 - mDice: 0.7879 - val_loss: 0.5430 - val_acc: 0.9773 - val_mDice: 0.8050

Epoch 00096: val_mDice did not improve from 0.80549
Epoch 97/300
 - 18s - loss: 0.5700 - acc: 0.9627 - mDice: 0.7890 - val_loss: 0.5485 - val_acc: 0.9769 - val_mDice: 0.8045

Epoch 00097: val_mDice did not improve from 0.80549
Epoch 98/300
 - 19s - loss: 0.5718 - acc: 0.9625 - mDice: 0.7887 - val_loss: 0.5484 - val_acc: 0.9773 - val_mDice: 0.8043

Epoch 00098: val_mDice did not improve from 0.80549
Epoch 99/300
 - 18s - loss: 0.5709 - acc: 0.9626 - mDice: 0.7887 - val_loss: 0.5463 - val_acc: 0.9770 - val_mDice: 0.8044

Epoch 00099: val_mDice did not improve from 0.80549
Epoch 100/300
 - 18s - loss: 0.5721 - acc: 0.9626 - mDice: 0.7884 - val_loss: 0.5440 - val_acc: 0.9774 - val_mDice: 0.8051

Epoch 00100: val_mDice did not improve from 0.80549
Epoch 101/300
 - 18s - loss: 0.5691 - acc: 0.9626 - mDice: 0.7892 - val_loss: 0.5424 - val_acc: 0.9770 - val_mDice: 0.8068

Epoch 00101: val_mDice improved from 0.80549 to 0.80680, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 102/300
 - 18s - loss: 0.5678 - acc: 0.9627 - mDice: 0.7896 - val_loss: 0.5429 - val_acc: 0.9777 - val_mDice: 0.8063

Epoch 00102: val_mDice did not improve from 0.80680
Epoch 103/300
 - 19s - loss: 0.5675 - acc: 0.9627 - mDice: 0.7899 - val_loss: 0.5431 - val_acc: 0.9772 - val_mDice: 0.8065

Epoch 00103: val_mDice did not improve from 0.80680
Epoch 104/300
 - 18s - loss: 0.5682 - acc: 0.9627 - mDice: 0.7898 - val_loss: 0.5428 - val_acc: 0.9777 - val_mDice: 0.8059

Epoch 00104: val_mDice did not improve from 0.80680
Epoch 105/300
 - 18s - loss: 0.5669 - acc: 0.9627 - mDice: 0.7901 - val_loss: 0.5379 - val_acc: 0.9775 - val_mDice: 0.8070

Epoch 00105: val_mDice improved from 0.80680 to 0.80702, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_GMean_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 106/300
 - 18s - loss: 0.5683 - acc: 0.9628 - mDice: 0.7897 - val_loss: 0.5454 - val_acc: 0.9774 - val_mDice: 0.8065
